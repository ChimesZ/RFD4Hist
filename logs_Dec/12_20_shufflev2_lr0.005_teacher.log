==> training...
Epoch: [1][0/1250]	Time 31.634 (31.634)	Data 0.614 (0.614)	Loss 1.7993 (1.7993)	Acc@1 18.750 (18.750)	Acc@5 100.000 (100.000)
Epoch: [1][100/1250]	Time 0.226 (0.534)	Data 0.006 (0.011)	Loss 0.8871 (3.0453)	Acc@1 68.750 (55.848)	Acc@5 100.000 (100.000)
Epoch: [1][200/1250]	Time 0.271 (0.379)	Data 0.005 (0.008)	Loss 0.7069 (1.9563)	Acc@1 78.125 (62.041)	Acc@5 100.000 (100.000)
Epoch: [1][300/1250]	Time 0.206 (0.327)	Data 0.005 (0.007)	Loss 0.6754 (1.5847)	Acc@1 78.125 (64.249)	Acc@5 100.000 (100.000)
Epoch: [1][400/1250]	Time 0.215 (0.300)	Data 0.006 (0.007)	Loss 0.7242 (1.3921)	Acc@1 70.312 (65.761)	Acc@5 100.000 (100.000)
Epoch: [1][500/1250]	Time 0.225 (0.284)	Data 0.005 (0.007)	Loss 1.0992 (1.2618)	Acc@1 59.375 (67.163)	Acc@5 100.000 (100.000)
Epoch: [1][600/1250]	Time 0.225 (0.275)	Data 0.006 (0.006)	Loss 0.6323 (1.1702)	Acc@1 73.438 (68.212)	Acc@5 100.000 (100.000)
Epoch: [1][700/1250]	Time 0.242 (0.268)	Data 0.007 (0.006)	Loss 0.5887 (1.1042)	Acc@1 82.812 (69.020)	Acc@5 100.000 (100.000)
Epoch: [1][800/1250]	Time 0.207 (0.262)	Data 0.004 (0.006)	Loss 0.5524 (1.0551)	Acc@1 76.562 (69.565)	Acc@5 100.000 (100.000)
Epoch: [1][900/1250]	Time 0.266 (0.257)	Data 0.007 (0.006)	Loss 0.6388 (1.0140)	Acc@1 81.250 (70.165)	Acc@5 100.000 (100.000)
Epoch: [1][1000/1250]	Time 0.207 (0.253)	Data 0.005 (0.006)	Loss 0.5488 (0.9809)	Acc@1 76.562 (70.645)	Acc@5 100.000 (100.000)
Epoch: [1][1100/1250]	Time 0.219 (0.250)	Data 0.005 (0.006)	Loss 0.6128 (0.9541)	Acc@1 76.562 (70.995)	Acc@5 100.000 (100.000)
Epoch: [1][1200/1250]	Time 0.215 (0.248)	Data 0.005 (0.006)	Loss 0.6005 (0.9310)	Acc@1 76.562 (71.335)	Acc@5 100.000 (100.000)
 * Acc@1 71.504 Acc@5 100.000
epoch 1, total time 308.20
Test: [0/125]	Time 1.209 (1.209)	Loss 1.1418 (1.1418)	Acc@1 62.500 (62.500)	Acc@5 75.000 (75.000)
Test: [100/125]	Time 0.125 (0.131)	Loss 1.5071 (0.8420)	Acc@1 9.375 (70.823)	Acc@5 100.000 (94.090)
 * Acc@1 69.075 Acc@5 94.800
saving the best model!
==> training...
