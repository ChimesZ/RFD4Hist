Files already downloaded and verified
Files already downloaded and verified
==> loading teacher model
==> done
Test: [0/313]	Time 0.391 (0.391)	Loss 1.2691 (1.2691)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.012 (0.017)	Loss 0.9493 (1.2320)	Acc@1 71.875 (72.092)	Acc@5 93.750 (91.925)
Test: [200/313]	Time 0.012 (0.015)	Loss 0.7957 (1.1796)	Acc@1 71.875 (72.326)	Acc@5 100.000 (92.537)
Test: [300/313]	Time 0.013 (0.014)	Loss 1.2957 (1.1765)	Acc@1 65.625 (72.373)	Acc@5 93.750 (92.494)
 * Acc@1 72.410 Acc@5 92.500
teacher accuracy:  tensor(72.4100, device='cuda:0')
==> training...
Epoch: [1][0/782]	Time 0.676 (0.676)	Data 0.518 (0.518)	Loss 46.8120 (46.8120)	Acc@1 0.000 (0.000)	Acc@5 1.562 (1.562)
[epoch:2, iter:783] Loss: 9.761, 47.656, 217.064, 1084.746, 4.810
[epoch:2, iter:803] Loss: 3.294, 25.499, 135.094, 774.849, 4.750
[epoch:2, iter:823] Loss: 3.040, 22.078, 120.903, 726.737, 4.545
[epoch:2, iter:843] Loss: 3.006, 20.455, 114.766, 705.478, 4.572
[epoch:2, iter:863] Loss: 3.001, 19.486, 111.347, 693.098, 4.447
Epoch: [1][100/782]	Time 0.070 (0.077)	Data 0.002 (0.007)	Loss 31.9512 (32.6992)	Acc@1 6.250 (2.831)	Acc@5 20.312 (11.742)
[epoch:2, iter:883] Loss: 3.020, 18.909, 109.145, 684.525, 4.321
[epoch:2, iter:903] Loss: 3.045, 18.522, 107.416, 677.661, 4.108
[epoch:2, iter:923] Loss: 3.021, 18.186, 106.031, 671.940, 4.076
[epoch:2, iter:943] Loss: 2.995, 17.889, 104.929, 667.039, 4.160
[epoch:2, iter:963] Loss: 2.970, 17.638, 104.009, 663.005, 4.128
Epoch: [1][200/782]	Time 0.091 (0.076)	Data 0.003 (0.005)	Loss 30.2451 (30.9464)	Acc@1 9.375 (4.680)	Acc@5 26.562 (18.260)
[epoch:2, iter:983] Loss: 2.947, 17.423, 103.184, 659.164, 3.898
[epoch:2, iter:1003] Loss: 2.925, 17.242, 102.492, 655.940, 3.664
[epoch:2, iter:1023] Loss: 2.908, 17.093, 101.825, 652.843, 3.866
[epoch:2, iter:1043] Loss: 2.881, 16.950, 101.259, 650.115, 3.972
[epoch:2, iter:1063] Loss: 2.860, 16.819, 100.742, 647.710, 3.626
Epoch: [1][300/782]	Time 0.082 (0.078)	Data 0.003 (0.004)	Loss 26.6763 (29.8812)	Acc@1 21.875 (6.468)	Acc@5 51.562 (23.256)
[epoch:2, iter:1083] Loss: 2.837, 16.703, 100.253, 645.529, 3.345
[epoch:2, iter:1103] Loss: 2.821, 16.597, 99.816, 643.295, 4.051
[epoch:2, iter:1123] Loss: 2.804, 16.499, 99.394, 641.271, 3.971
[epoch:2, iter:1143] Loss: 2.791, 16.396, 99.051, 639.505, 3.759
[epoch:2, iter:1163] Loss: 2.775, 16.309, 98.638, 637.553, 3.419
Epoch: [1][400/782]	Time 0.083 (0.077)	Data 0.002 (0.003)	Loss 25.0635 (29.1131)	Acc@1 21.875 (8.085)	Acc@5 42.188 (27.279)
[epoch:2, iter:1183] Loss: 2.763, 16.237, 98.314, 635.936, 3.689
[epoch:2, iter:1203] Loss: 2.750, 16.161, 97.981, 634.130, 3.326
[epoch:2, iter:1223] Loss: 2.735, 16.078, 97.666, 632.498, 3.359
[epoch:2, iter:1243] Loss: 2.721, 16.014, 97.406, 631.121, 3.799
[epoch:2, iter:1263] Loss: 2.709, 15.951, 97.125, 629.690, 3.035
Epoch: [1][500/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 25.7050 (28.4526)	Acc@1 25.000 (9.609)	Acc@5 46.875 (30.530)
[epoch:2, iter:1283] Loss: 2.695, 15.886, 96.852, 628.185, 3.212
[epoch:2, iter:1303] Loss: 2.683, 15.827, 96.599, 626.760, 3.148
[epoch:2, iter:1323] Loss: 2.673, 15.776, 96.366, 625.485, 3.109
[epoch:2, iter:1343] Loss: 2.661, 15.721, 96.122, 624.181, 3.640
[epoch:2, iter:1363] Loss: 2.650, 15.666, 95.872, 622.717, 3.278
Epoch: [1][600/782]	Time 0.092 (0.078)	Data 0.002 (0.003)	Loss 24.5014 (27.8744)	Acc@1 25.000 (11.091)	Acc@5 50.000 (33.587)
[epoch:2, iter:1383] Loss: 2.639, 15.619, 95.658, 621.465, 3.134
[epoch:2, iter:1403] Loss: 2.629, 15.576, 95.412, 620.129, 3.268
[epoch:2, iter:1423] Loss: 2.620, 15.532, 95.187, 618.871, 2.904
[epoch:2, iter:1443] Loss: 2.610, 15.486, 94.986, 617.749, 3.196
[epoch:2, iter:1463] Loss: 2.601, 15.449, 94.797, 616.644, 2.788
Epoch: [1][700/782]	Time 0.062 (0.078)	Data 0.003 (0.003)	Loss 25.2312 (27.3685)	Acc@1 18.750 (12.536)	Acc@5 45.312 (36.225)
[epoch:2, iter:1483] Loss: 2.592, 15.407, 94.583, 615.474, 3.751
[epoch:2, iter:1503] Loss: 2.583, 15.368, 94.383, 614.368, 3.135
[epoch:2, iter:1523] Loss: 2.573, 15.330, 94.205, 613.357, 3.507
[epoch:2, iter:1543] Loss: 2.565, 15.293, 94.011, 612.227, 2.940
[epoch:2, iter:1563] Loss: 2.555, 15.258, 93.826, 611.186, 3.330
 * Acc@1 13.430 Acc@5 38.014
epoch 1, total time 60.78
Test: [0/313]	Time 0.252 (0.252)	Loss 3.6608 (3.6608)	Acc@1 31.250 (31.250)	Acc@5 56.250 (56.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 4.0070 (3.4359)	Acc@1 21.875 (22.803)	Acc@5 46.875 (53.620)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.9202 (3.4145)	Acc@1 25.000 (22.870)	Acc@5 71.875 (54.602)
Test: [300/313]	Time 0.007 (0.007)	Loss 3.6249 (3.4290)	Acc@1 18.750 (22.643)	Acc@5 40.625 (54.288)
 * Acc@1 22.630 Acc@5 54.450
saving the best model!
==> training...
Epoch: [2][0/782]	Time 0.505 (0.505)	Data 0.428 (0.428)	Loss 22.0569 (22.0569)	Acc@1 20.312 (20.312)	Acc@5 56.250 (56.250)
[epoch:3, iter:1565] Loss: 2.144, 13.546, 84.877, 563.071, 2.920
[epoch:3, iter:1585] Loss: 2.256, 13.986, 86.951, 570.901, 3.492
[epoch:3, iter:1605] Loss: 2.227, 13.822, 87.301, 570.721, 2.711
[epoch:3, iter:1625] Loss: 2.225, 13.791, 86.966, 568.218, 2.782
[epoch:3, iter:1645] Loss: 2.216, 13.777, 86.831, 567.835, 2.644
Epoch: [2][100/782]	Time 0.100 (0.084)	Data 0.003 (0.007)	Loss 21.8242 (23.1710)	Acc@1 25.000 (24.969)	Acc@5 64.062 (57.843)
[epoch:3, iter:1665] Loss: 2.201, 13.739, 86.399, 566.278, 2.832
[epoch:3, iter:1685] Loss: 2.192, 13.718, 86.292, 565.506, 3.180
[epoch:3, iter:1705] Loss: 2.180, 13.712, 86.234, 565.091, 3.132
[epoch:3, iter:1725] Loss: 2.172, 13.704, 86.157, 564.786, 2.905
[epoch:3, iter:1745] Loss: 2.170, 13.698, 86.099, 564.409, 2.751
Epoch: [2][200/782]	Time 0.066 (0.079)	Data 0.002 (0.004)	Loss 21.4999 (22.9502)	Acc@1 32.812 (25.832)	Acc@5 70.312 (58.442)
[epoch:3, iter:1765] Loss: 2.168, 13.694, 86.007, 563.922, 2.629
[epoch:3, iter:1785] Loss: 2.166, 13.688, 85.921, 563.301, 2.791
[epoch:3, iter:1805] Loss: 2.161, 13.676, 85.899, 563.013, 2.942
[epoch:3, iter:1825] Loss: 2.155, 13.657, 85.768, 562.336, 2.466
[epoch:3, iter:1845] Loss: 2.146, 13.637, 85.645, 561.629, 2.594
Epoch: [2][300/782]	Time 0.058 (0.077)	Data 0.002 (0.004)	Loss 22.6964 (22.7689)	Acc@1 20.312 (26.838)	Acc@5 53.125 (59.520)
[epoch:3, iter:1865] Loss: 2.140, 13.618, 85.605, 561.286, 3.062
[epoch:3, iter:1885] Loss: 2.135, 13.604, 85.470, 560.628, 2.453
[epoch:3, iter:1905] Loss: 2.129, 13.586, 85.380, 559.979, 2.956
[epoch:3, iter:1925] Loss: 2.125, 13.566, 85.306, 559.532, 2.447
[epoch:3, iter:1945] Loss: 2.118, 13.555, 85.225, 559.027, 3.017
Epoch: [2][400/782]	Time 0.086 (0.077)	Data 0.003 (0.003)	Loss 21.7254 (22.5074)	Acc@1 26.562 (27.572)	Acc@5 60.938 (60.817)
[epoch:3, iter:1965] Loss: 2.114, 13.551, 85.152, 558.534, 3.093
[epoch:3, iter:1985] Loss: 2.107, 13.534, 85.053, 558.090, 2.727
[epoch:3, iter:2005] Loss: 2.102, 13.520, 84.947, 557.418, 3.091
[epoch:3, iter:2025] Loss: 2.098, 13.511, 84.879, 556.993, 3.358
[epoch:3, iter:2045] Loss: 2.094, 13.502, 84.797, 556.396, 2.504
Epoch: [2][500/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 19.5478 (22.2916)	Acc@1 39.062 (28.502)	Acc@5 73.438 (61.836)
[epoch:3, iter:2065] Loss: 2.090, 13.493, 84.761, 555.936, 2.147
[epoch:3, iter:2085] Loss: 2.086, 13.482, 84.672, 555.334, 2.572
[epoch:3, iter:2105] Loss: 2.082, 13.473, 84.642, 554.990, 2.519
[epoch:3, iter:2125] Loss: 2.079, 13.466, 84.588, 554.596, 3.110
[epoch:3, iter:2145] Loss: 2.076, 13.460, 84.537, 554.111, 2.476
Epoch: [2][600/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 20.5849 (22.1034)	Acc@1 34.375 (29.178)	Acc@5 73.438 (62.588)
[epoch:3, iter:2165] Loss: 2.071, 13.442, 84.430, 553.395, 2.507
[epoch:3, iter:2185] Loss: 2.068, 13.432, 84.333, 552.829, 2.393
[epoch:3, iter:2205] Loss: 2.064, 13.416, 84.257, 552.268, 2.288
[epoch:3, iter:2225] Loss: 2.060, 13.405, 84.198, 551.775, 2.714
[epoch:3, iter:2245] Loss: 2.055, 13.392, 84.125, 551.258, 2.211
Epoch: [2][700/782]	Time 0.093 (0.078)	Data 0.003 (0.003)	Loss 20.1055 (21.9033)	Acc@1 35.938 (29.890)	Acc@5 68.750 (63.474)
[epoch:3, iter:2265] Loss: 2.052, 13.378, 84.083, 550.886, 2.631
[epoch:3, iter:2285] Loss: 2.048, 13.365, 83.987, 550.245, 2.240
[epoch:3, iter:2305] Loss: 2.044, 13.353, 83.953, 549.792, 2.923
[epoch:3, iter:2325] Loss: 2.040, 13.339, 83.905, 549.314, 2.425
[epoch:3, iter:2345] Loss: 2.038, 13.329, 83.836, 548.817, 2.506
 * Acc@1 30.408 Acc@5 64.148
epoch 2, total time 61.45
Test: [0/313]	Time 0.238 (0.238)	Loss 2.9022 (2.9022)	Acc@1 46.875 (46.875)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9884 (3.1441)	Acc@1 21.875 (30.229)	Acc@5 65.625 (66.522)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.3979 (3.1744)	Acc@1 31.250 (29.773)	Acc@5 68.750 (66.107)
Test: [300/313]	Time 0.006 (0.007)	Loss 3.1459 (3.2018)	Acc@1 34.375 (29.651)	Acc@5 62.500 (65.583)
 * Acc@1 29.770 Acc@5 65.660
saving the best model!
==> training...
Epoch: [3][0/782]	Time 0.532 (0.532)	Data 0.435 (0.435)	Loss 20.3026 (20.3026)	Acc@1 35.938 (35.938)	Acc@5 73.438 (73.438)
[epoch:4, iter:2347] Loss: 2.000, 12.578, 83.790, 526.238, 2.623
[epoch:4, iter:2367] Loss: 1.902, 12.901, 80.674, 526.396, 2.411
[epoch:4, iter:2387] Loss: 1.902, 12.871, 80.899, 527.658, 2.174
[epoch:4, iter:2407] Loss: 1.899, 12.852, 80.730, 526.121, 2.237
[epoch:4, iter:2427] Loss: 1.897, 12.852, 80.759, 527.115, 2.135
Epoch: [3][100/782]	Time 0.088 (0.086)	Data 0.003 (0.007)	Loss 20.7950 (19.9669)	Acc@1 34.375 (36.525)	Acc@5 75.000 (71.380)
[epoch:4, iter:2447] Loss: 1.887, 12.811, 80.579, 526.627, 2.277
[epoch:4, iter:2467] Loss: 1.885, 12.793, 80.658, 527.272, 2.247
[epoch:4, iter:2487] Loss: 1.882, 12.799, 80.566, 527.122, 2.097
[epoch:4, iter:2507] Loss: 1.881, 12.794, 80.647, 527.445, 2.390
[epoch:4, iter:2527] Loss: 1.878, 12.786, 80.565, 527.100, 2.928
Epoch: [3][200/782]	Time 0.092 (0.084)	Data 0.003 (0.005)	Loss 19.8323 (19.9714)	Acc@1 23.438 (36.264)	Acc@5 65.625 (71.175)
[epoch:4, iter:2547] Loss: 1.875, 12.791, 80.466, 526.752, 2.868
[epoch:4, iter:2567] Loss: 1.872, 12.776, 80.485, 526.742, 2.348
[epoch:4, iter:2587] Loss: 1.871, 12.769, 80.483, 526.591, 2.424
[epoch:4, iter:2607] Loss: 1.868, 12.756, 80.451, 526.331, 2.519
[epoch:4, iter:2627] Loss: 1.865, 12.753, 80.320, 525.857, 2.087
Epoch: [3][300/782]	Time 0.084 (0.083)	Data 0.004 (0.004)	Loss 19.5554 (19.8470)	Acc@1 34.375 (37.017)	Acc@5 64.062 (71.771)
[epoch:4, iter:2647] Loss: 1.863, 12.740, 80.251, 525.422, 2.627
[epoch:4, iter:2667] Loss: 1.863, 12.735, 80.208, 525.150, 2.300
[epoch:4, iter:2687] Loss: 1.859, 12.716, 80.132, 524.557, 2.571
[epoch:4, iter:2707] Loss: 1.857, 12.710, 80.080, 524.263, 2.193
[epoch:4, iter:2727] Loss: 1.856, 12.701, 80.107, 524.045, 2.314
Epoch: [3][400/782]	Time 0.067 (0.081)	Data 0.002 (0.003)	Loss 18.0598 (19.7468)	Acc@1 42.188 (37.625)	Acc@5 81.250 (72.101)
[epoch:4, iter:2747] Loss: 1.855, 12.696, 80.079, 523.685, 1.960
[epoch:4, iter:2767] Loss: 1.853, 12.691, 80.036, 523.340, 2.302
[epoch:4, iter:2787] Loss: 1.852, 12.684, 80.027, 523.088, 2.306
[epoch:4, iter:2807] Loss: 1.851, 12.675, 79.990, 522.795, 2.008
[epoch:4, iter:2827] Loss: 1.850, 12.676, 79.936, 522.430, 2.403
Epoch: [3][500/782]	Time 0.088 (0.079)	Data 0.003 (0.003)	Loss 18.4292 (19.6318)	Acc@1 37.500 (38.298)	Acc@5 70.312 (72.620)
[epoch:4, iter:2847] Loss: 1.849, 12.668, 79.887, 522.166, 2.419
[epoch:4, iter:2867] Loss: 1.847, 12.661, 79.857, 521.945, 2.263
[epoch:4, iter:2887] Loss: 1.846, 12.653, 79.816, 521.662, 2.764
[epoch:4, iter:2907] Loss: 1.844, 12.643, 79.741, 521.237, 2.177
[epoch:4, iter:2927] Loss: 1.842, 12.634, 79.710, 521.036, 2.415
Epoch: [3][600/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 18.7455 (19.5274)	Acc@1 40.625 (38.569)	Acc@5 71.875 (72.985)
[epoch:4, iter:2947] Loss: 1.840, 12.629, 79.672, 520.719, 2.397
[epoch:4, iter:2967] Loss: 1.840, 12.624, 79.619, 520.365, 1.868
[epoch:4, iter:2987] Loss: 1.839, 12.620, 79.572, 520.099, 2.499
[epoch:4, iter:3007] Loss: 1.838, 12.611, 79.558, 519.916, 2.229
[epoch:4, iter:3027] Loss: 1.836, 12.607, 79.513, 519.701, 2.419
Epoch: [3][700/782]	Time 0.082 (0.079)	Data 0.003 (0.003)	Loss 18.1619 (19.4256)	Acc@1 43.750 (39.020)	Acc@5 78.125 (73.290)
[epoch:4, iter:3047] Loss: 1.835, 12.599, 79.465, 519.393, 2.249
[epoch:4, iter:3067] Loss: 1.832, 12.589, 79.399, 518.956, 2.178
[epoch:4, iter:3087] Loss: 1.830, 12.587, 79.353, 518.706, 2.233
[epoch:4, iter:3107] Loss: 1.828, 12.581, 79.299, 518.379, 2.082
[epoch:4, iter:3127] Loss: 1.827, 12.574, 79.282, 518.161, 1.870
 * Acc@1 39.424 Acc@5 73.594
epoch 3, total time 61.91
Test: [0/313]	Time 0.246 (0.246)	Loss 3.2645 (3.2645)	Acc@1 43.750 (43.750)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 3.5012 (3.1611)	Acc@1 31.250 (35.984)	Acc@5 75.000 (69.647)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.1624 (3.1606)	Acc@1 40.625 (36.723)	Acc@5 75.000 (69.185)
Test: [300/313]	Time 0.006 (0.007)	Loss 3.0558 (3.1851)	Acc@1 37.500 (36.701)	Acc@5 78.125 (69.041)
 * Acc@1 36.580 Acc@5 69.020
saving the best model!
==> training...
Epoch: [4][0/782]	Time 0.549 (0.549)	Data 0.478 (0.478)	Loss 18.4883 (18.4883)	Acc@1 43.750 (43.750)	Acc@5 75.000 (75.000)
[epoch:5, iter:3129] Loss: 1.836, 11.762, 80.159, 509.491, 2.240
[epoch:5, iter:3149] Loss: 1.784, 12.239, 77.968, 508.391, 2.430
[epoch:5, iter:3169] Loss: 1.775, 12.265, 77.962, 509.049, 2.304
[epoch:5, iter:3189] Loss: 1.757, 12.249, 77.780, 507.566, 2.480
[epoch:5, iter:3209] Loss: 1.746, 12.184, 77.514, 506.559, 1.450
Epoch: [4][100/782]	Time 0.087 (0.088)	Data 0.003 (0.007)	Loss 17.6964 (18.2827)	Acc@1 39.062 (43.688)	Acc@5 81.250 (76.470)
[epoch:5, iter:3229] Loss: 1.745, 12.179, 77.430, 506.056, 2.148
[epoch:5, iter:3249] Loss: 1.748, 12.183, 77.474, 505.911, 1.949
[epoch:5, iter:3269] Loss: 1.750, 12.181, 77.543, 506.042, 2.115
[epoch:5, iter:3289] Loss: 1.749, 12.186, 77.573, 505.928, 1.897
[epoch:5, iter:3309] Loss: 1.749, 12.186, 77.619, 505.943, 2.286
Epoch: [4][200/782]	Time 0.082 (0.084)	Data 0.002 (0.005)	Loss 18.6549 (18.3232)	Acc@1 43.750 (43.828)	Acc@5 85.938 (76.788)
[epoch:5, iter:3329] Loss: 1.752, 12.199, 77.637, 505.859, 2.024
[epoch:5, iter:3349] Loss: 1.751, 12.192, 77.599, 505.649, 2.005
[epoch:5, iter:3369] Loss: 1.749, 12.192, 77.497, 505.105, 1.897
[epoch:5, iter:3389] Loss: 1.747, 12.195, 77.487, 505.026, 1.944
[epoch:5, iter:3409] Loss: 1.748, 12.189, 77.453, 504.857, 2.303
Epoch: [4][300/782]	Time 0.079 (0.081)	Data 0.002 (0.004)	Loss 17.6631 (18.2348)	Acc@1 45.312 (44.207)	Acc@5 84.375 (77.009)
[epoch:5, iter:3429] Loss: 1.747, 12.177, 77.445, 504.768, 1.785
[epoch:5, iter:3449] Loss: 1.744, 12.174, 77.405, 504.574, 2.293
[epoch:5, iter:3469] Loss: 1.743, 12.165, 77.418, 504.550, 2.253
[epoch:5, iter:3489] Loss: 1.743, 12.183, 77.428, 504.620, 2.732
[epoch:5, iter:3509] Loss: 1.742, 12.180, 77.405, 504.561, 2.279
Epoch: [4][400/782]	Time 0.072 (0.080)	Data 0.002 (0.004)	Loss 18.7189 (18.2330)	Acc@1 51.562 (44.241)	Acc@5 76.562 (77.147)
[epoch:5, iter:3529] Loss: 1.742, 12.173, 77.380, 504.469, 2.060
[epoch:5, iter:3549] Loss: 1.740, 12.162, 77.346, 504.300, 2.135
[epoch:5, iter:3569] Loss: 1.740, 12.164, 77.322, 504.110, 1.985
[epoch:5, iter:3589] Loss: 1.739, 12.161, 77.328, 503.934, 2.076
[epoch:5, iter:3609] Loss: 1.738, 12.156, 77.289, 503.704, 1.762
Epoch: [4][500/782]	Time 0.087 (0.081)	Data 0.002 (0.003)	Loss 17.9748 (18.1723)	Acc@1 59.375 (44.439)	Acc@5 82.812 (77.582)
[epoch:5, iter:3629] Loss: 1.738, 12.153, 77.256, 503.450, 1.818
[epoch:5, iter:3649] Loss: 1.738, 12.150, 77.259, 503.385, 2.225
[epoch:5, iter:3669] Loss: 1.738, 12.152, 77.211, 503.226, 2.051
[epoch:5, iter:3689] Loss: 1.738, 12.147, 77.172, 502.990, 2.088
[epoch:5, iter:3709] Loss: 1.735, 12.140, 77.132, 502.784, 2.171
Epoch: [4][600/782]	Time 0.061 (0.080)	Data 0.002 (0.003)	Loss 16.4428 (18.1091)	Acc@1 50.000 (44.665)	Acc@5 81.250 (77.779)
[epoch:5, iter:3729] Loss: 1.733, 12.131, 77.074, 502.510, 2.002
[epoch:5, iter:3749] Loss: 1.732, 12.126, 77.053, 502.379, 1.889
[epoch:5, iter:3769] Loss: 1.731, 12.125, 77.047, 502.233, 2.431
[epoch:5, iter:3789] Loss: 1.730, 12.122, 77.009, 501.999, 1.843
[epoch:5, iter:3809] Loss: 1.730, 12.118, 76.988, 501.892, 2.035
Epoch: [4][700/782]	Time 0.089 (0.079)	Data 0.003 (0.003)	Loss 18.5495 (18.0538)	Acc@1 46.875 (44.811)	Acc@5 79.688 (77.849)
[epoch:5, iter:3829] Loss: 1.728, 12.109, 76.944, 501.673, 2.047
[epoch:5, iter:3849] Loss: 1.726, 12.102, 76.900, 501.396, 1.957
[epoch:5, iter:3869] Loss: 1.725, 12.090, 76.831, 501.031, 2.240
[epoch:5, iter:3889] Loss: 1.723, 12.083, 76.812, 500.941, 2.902
[epoch:5, iter:3909] Loss: 1.722, 12.079, 76.780, 500.687, 2.504
 * Acc@1 45.094 Acc@5 78.002
epoch 4, total time 62.34
Test: [0/313]	Time 0.251 (0.251)	Loss 3.1026 (3.1026)	Acc@1 46.875 (46.875)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.005 (0.010)	Loss 3.6126 (3.0818)	Acc@1 34.375 (36.850)	Acc@5 68.750 (70.699)
Test: [200/313]	Time 0.010 (0.008)	Loss 2.5747 (3.0783)	Acc@1 43.750 (37.329)	Acc@5 75.000 (70.414)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.3054 (3.0850)	Acc@1 31.250 (37.344)	Acc@5 62.500 (70.338)
 * Acc@1 37.370 Acc@5 70.240
saving the best model!
==> training...
Epoch: [5][0/782]	Time 0.489 (0.489)	Data 0.420 (0.420)	Loss 17.1540 (17.1540)	Acc@1 46.875 (46.875)	Acc@5 79.688 (79.688)
[epoch:6, iter:3911] Loss: 1.709, 12.225, 77.067, 490.695, 2.052
[epoch:6, iter:3931] Loss: 1.688, 11.963, 77.324, 497.243, 2.400
[epoch:6, iter:3951] Loss: 1.679, 11.964, 76.739, 496.055, 1.738
[epoch:6, iter:3971] Loss: 1.677, 11.966, 76.344, 494.194, 1.895
[epoch:6, iter:3991] Loss: 1.673, 11.907, 76.047, 493.790, 2.237
Epoch: [5][100/782]	Time 0.074 (0.078)	Data 0.002 (0.006)	Loss 17.0263 (17.3602)	Acc@1 50.000 (47.494)	Acc@5 89.062 (80.121)
[epoch:6, iter:4011] Loss: 1.669, 11.866, 75.758, 492.775, 1.631
[epoch:6, iter:4031] Loss: 1.667, 11.874, 75.698, 492.653, 1.764
[epoch:6, iter:4051] Loss: 1.669, 11.871, 75.747, 492.905, 2.098
[epoch:6, iter:4071] Loss: 1.669, 11.859, 75.712, 492.654, 2.273
[epoch:6, iter:4091] Loss: 1.669, 11.853, 75.697, 492.497, 1.502
Epoch: [5][200/782]	Time 0.088 (0.077)	Data 0.002 (0.004)	Loss 16.8833 (17.3617)	Acc@1 48.438 (47.715)	Acc@5 81.250 (80.208)
[epoch:6, iter:4111] Loss: 1.672, 11.860, 75.679, 492.290, 1.890
[epoch:6, iter:4131] Loss: 1.670, 11.861, 75.609, 492.115, 2.341
[epoch:6, iter:4151] Loss: 1.673, 11.863, 75.705, 492.128, 1.651
[epoch:6, iter:4171] Loss: 1.674, 11.863, 75.606, 491.636, 1.317
[epoch:6, iter:4191] Loss: 1.675, 11.866, 75.595, 491.679, 2.004
Epoch: [5][300/782]	Time 0.089 (0.078)	Data 0.003 (0.004)	Loss 18.0659 (17.3233)	Acc@1 50.000 (47.872)	Acc@5 75.000 (80.456)
[epoch:6, iter:4211] Loss: 1.674, 11.854, 75.571, 491.487, 2.349
[epoch:6, iter:4231] Loss: 1.672, 11.849, 75.480, 491.292, 2.222
[epoch:6, iter:4251] Loss: 1.669, 11.840, 75.450, 491.217, 1.903
[epoch:6, iter:4271] Loss: 1.670, 11.840, 75.393, 491.066, 1.868
[epoch:6, iter:4291] Loss: 1.669, 11.837, 75.403, 490.900, 2.057
Epoch: [5][400/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 17.6151 (17.2652)	Acc@1 46.875 (48.227)	Acc@5 85.938 (80.603)
[epoch:6, iter:4311] Loss: 1.668, 11.831, 75.392, 490.795, 1.916
[epoch:6, iter:4331] Loss: 1.665, 11.822, 75.365, 490.688, 1.588
[epoch:6, iter:4351] Loss: 1.664, 11.825, 75.375, 490.663, 2.070
[epoch:6, iter:4371] Loss: 1.663, 11.818, 75.359, 490.632, 1.683
[epoch:6, iter:4391] Loss: 1.662, 11.815, 75.378, 490.735, 1.714
Epoch: [5][500/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 18.2259 (17.2473)	Acc@1 42.188 (48.147)	Acc@5 75.000 (80.707)
[epoch:6, iter:4411] Loss: 1.662, 11.826, 75.337, 490.647, 2.402
[epoch:6, iter:4431] Loss: 1.662, 11.822, 75.311, 490.519, 1.727
[epoch:6, iter:4451] Loss: 1.662, 11.819, 75.246, 490.295, 2.502
[epoch:6, iter:4471] Loss: 1.661, 11.812, 75.237, 490.156, 2.219
[epoch:6, iter:4491] Loss: 1.661, 11.805, 75.233, 490.100, 1.886
Epoch: [5][600/782]	Time 0.067 (0.078)	Data 0.002 (0.003)	Loss 16.7414 (17.2114)	Acc@1 53.125 (48.079)	Acc@5 82.812 (80.631)
[epoch:6, iter:4511] Loss: 1.659, 11.802, 75.221, 490.077, 2.007
[epoch:6, iter:4531] Loss: 1.657, 11.797, 75.182, 489.799, 2.108
[epoch:6, iter:4551] Loss: 1.657, 11.793, 75.152, 489.625, 1.663
[epoch:6, iter:4571] Loss: 1.657, 11.796, 75.178, 489.684, 1.429
[epoch:6, iter:4591] Loss: 1.657, 11.796, 75.154, 489.574, 2.033
Epoch: [5][700/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 16.8829 (17.1706)	Acc@1 54.688 (48.146)	Acc@5 82.812 (80.662)
[epoch:6, iter:4611] Loss: 1.656, 11.791, 75.128, 489.390, 1.875
[epoch:6, iter:4631] Loss: 1.655, 11.785, 75.096, 489.278, 1.809
[epoch:6, iter:4651] Loss: 1.655, 11.780, 75.070, 489.153, 1.941
[epoch:6, iter:4671] Loss: 1.654, 11.777, 75.021, 488.912, 1.666
[epoch:6, iter:4691] Loss: 1.653, 11.773, 74.992, 488.739, 1.512
 * Acc@1 48.406 Acc@5 80.754
epoch 5, total time 60.93
Test: [0/313]	Time 0.269 (0.269)	Loss 2.1579 (2.1579)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9872 (2.4583)	Acc@1 37.500 (44.152)	Acc@5 84.375 (77.939)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4760 (2.4547)	Acc@1 59.375 (44.512)	Acc@5 90.625 (77.705)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.9088 (2.4590)	Acc@1 43.750 (44.186)	Acc@5 68.750 (77.409)
 * Acc@1 44.150 Acc@5 77.450
saving the best model!
==> training...
Epoch: [6][0/782]	Time 0.519 (0.519)	Data 0.435 (0.435)	Loss 16.2278 (16.2278)	Acc@1 42.188 (42.188)	Acc@5 76.562 (76.562)
[epoch:7, iter:4693] Loss: 1.608, 11.993, 72.853, 480.234, 2.096
[epoch:7, iter:4713] Loss: 1.664, 11.744, 74.542, 486.161, 1.698
[epoch:7, iter:4733] Loss: 1.662, 11.680, 74.873, 486.124, 2.047
[epoch:7, iter:4753] Loss: 1.646, 11.698, 74.523, 485.279, 1.902
[epoch:7, iter:4773] Loss: 1.645, 11.742, 74.349, 484.580, 1.588
Epoch: [6][100/782]	Time 0.082 (0.076)	Data 0.002 (0.006)	Loss 17.3920 (16.7860)	Acc@1 51.562 (50.062)	Acc@5 81.250 (82.395)
[epoch:7, iter:4793] Loss: 1.643, 11.748, 74.429, 484.918, 2.080
[epoch:7, iter:4813] Loss: 1.644, 11.744, 74.511, 485.209, 1.636
[epoch:7, iter:4833] Loss: 1.639, 11.742, 74.367, 485.027, 2.779
[epoch:7, iter:4853] Loss: 1.635, 11.730, 74.333, 484.727, 1.876
[epoch:7, iter:4873] Loss: 1.637, 11.729, 74.471, 484.878, 1.747
Epoch: [6][200/782]	Time 0.074 (0.076)	Data 0.002 (0.004)	Loss 16.9746 (16.8047)	Acc@1 53.125 (50.124)	Acc@5 82.812 (82.113)
[epoch:7, iter:4893] Loss: 1.636, 11.716, 74.487, 484.963, 1.826
[epoch:7, iter:4913] Loss: 1.634, 11.695, 74.372, 484.503, 1.006
[epoch:7, iter:4933] Loss: 1.632, 11.684, 74.328, 484.286, 2.087
[epoch:7, iter:4953] Loss: 1.633, 11.678, 74.314, 484.186, 2.375
[epoch:7, iter:4973] Loss: 1.633, 11.679, 74.346, 484.192, 2.310
Epoch: [6][300/782]	Time 0.091 (0.077)	Data 0.003 (0.004)	Loss 17.0261 (16.7636)	Acc@1 51.562 (50.119)	Acc@5 81.250 (81.785)
[epoch:7, iter:4993] Loss: 1.632, 11.670, 74.309, 484.024, 2.037
[epoch:7, iter:5013] Loss: 1.629, 11.668, 74.225, 483.748, 1.922
[epoch:7, iter:5033] Loss: 1.628, 11.661, 74.192, 483.650, 1.792
[epoch:7, iter:5053] Loss: 1.627, 11.654, 74.106, 483.242, 1.873
[epoch:7, iter:5073] Loss: 1.625, 11.646, 74.107, 483.006, 2.235
Epoch: [6][400/782]	Time 0.090 (0.075)	Data 0.003 (0.003)	Loss 15.7671 (16.6572)	Acc@1 53.125 (50.351)	Acc@5 82.812 (82.025)
[epoch:7, iter:5093] Loss: 1.623, 11.634, 74.070, 482.674, 1.722
[epoch:7, iter:5113] Loss: 1.622, 11.633, 74.028, 482.512, 1.633
[epoch:7, iter:5133] Loss: 1.621, 11.628, 74.021, 482.375, 2.209
[epoch:7, iter:5153] Loss: 1.622, 11.624, 74.048, 482.370, 1.718
[epoch:7, iter:5173] Loss: 1.621, 11.627, 74.080, 482.511, 1.736
Epoch: [6][500/782]	Time 0.078 (0.076)	Data 0.002 (0.003)	Loss 15.7978 (16.6540)	Acc@1 60.938 (50.409)	Acc@5 81.250 (82.111)
[epoch:7, iter:5193] Loss: 1.622, 11.623, 74.048, 482.424, 1.669
[epoch:7, iter:5213] Loss: 1.621, 11.626, 74.053, 482.395, 2.021
[epoch:7, iter:5233] Loss: 1.621, 11.625, 74.050, 482.274, 2.143
[epoch:7, iter:5253] Loss: 1.621, 11.626, 74.001, 482.146, 2.002
[epoch:7, iter:5273] Loss: 1.621, 11.619, 73.943, 481.969, 1.578
Epoch: [6][600/782]	Time 0.071 (0.075)	Data 0.002 (0.003)	Loss 16.1046 (16.6103)	Acc@1 51.562 (50.445)	Acc@5 78.125 (82.199)
[epoch:7, iter:5293] Loss: 1.620, 11.615, 73.895, 481.743, 1.942
[epoch:7, iter:5313] Loss: 1.619, 11.609, 73.875, 481.644, 2.434
[epoch:7, iter:5333] Loss: 1.619, 11.606, 73.868, 481.502, 2.012
[epoch:7, iter:5353] Loss: 1.619, 11.600, 73.847, 481.368, 2.253
[epoch:7, iter:5373] Loss: 1.618, 11.597, 73.801, 481.181, 1.179
Epoch: [6][700/782]	Time 0.087 (0.075)	Data 0.003 (0.003)	Loss 15.1281 (16.5545)	Acc@1 50.000 (50.646)	Acc@5 98.438 (82.416)
[epoch:7, iter:5393] Loss: 1.617, 11.595, 73.743, 480.976, 1.477
[epoch:7, iter:5413] Loss: 1.616, 11.594, 73.715, 480.843, 1.715
[epoch:7, iter:5433] Loss: 1.615, 11.592, 73.718, 480.825, 1.713
[epoch:7, iter:5453] Loss: 1.614, 11.589, 73.701, 480.718, 1.701
[epoch:7, iter:5473] Loss: 1.614, 11.590, 73.688, 480.623, 1.997
 * Acc@1 50.802 Acc@5 82.424
epoch 6, total time 59.14
Test: [0/313]	Time 0.227 (0.227)	Loss 2.8785 (2.8785)	Acc@1 56.250 (56.250)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.006 (0.009)	Loss 3.1116 (2.5855)	Acc@1 34.375 (44.988)	Acc@5 65.625 (77.754)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.8959 (2.6066)	Acc@1 46.875 (44.185)	Acc@5 90.625 (77.394)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.6224 (2.6065)	Acc@1 37.500 (44.394)	Acc@5 75.000 (77.471)
 * Acc@1 44.440 Acc@5 77.540
saving the best model!
==> training...
Epoch: [7][0/782]	Time 0.513 (0.513)	Data 0.441 (0.441)	Loss 15.9106 (15.9106)	Acc@1 60.938 (60.938)	Acc@5 85.938 (85.938)
[epoch:8, iter:5475] Loss: 1.556, 11.169, 74.590, 479.046, 1.405
[epoch:8, iter:5495] Loss: 1.609, 11.560, 73.983, 479.786, 1.872
[epoch:8, iter:5515] Loss: 1.607, 11.490, 73.386, 477.471, 1.507
[epoch:8, iter:5535] Loss: 1.610, 11.497, 73.237, 477.808, 1.841
[epoch:8, iter:5555] Loss: 1.614, 11.502, 73.253, 477.660, 1.609
Epoch: [7][100/782]	Time 0.092 (0.087)	Data 0.003 (0.007)	Loss 15.4224 (16.2920)	Acc@1 56.250 (52.058)	Acc@5 87.500 (83.586)
[epoch:8, iter:5575] Loss: 1.606, 11.508, 73.352, 477.481, 1.675
[epoch:8, iter:5595] Loss: 1.605, 11.493, 73.333, 476.915, 1.703
[epoch:8, iter:5615] Loss: 1.607, 11.497, 73.343, 477.077, 2.159
[epoch:8, iter:5635] Loss: 1.604, 11.497, 73.309, 477.266, 1.283
[epoch:8, iter:5655] Loss: 1.603, 11.494, 73.173, 476.956, 1.803
Epoch: [7][200/782]	Time 0.074 (0.083)	Data 0.002 (0.005)	Loss 16.1028 (16.2513)	Acc@1 59.375 (52.511)	Acc@5 82.812 (83.170)
[epoch:8, iter:5675] Loss: 1.602, 11.482, 73.191, 476.866, 1.807
[epoch:8, iter:5695] Loss: 1.602, 11.494, 73.265, 477.187, 1.773
[epoch:8, iter:5715] Loss: 1.603, 11.502, 73.298, 477.295, 1.625
[epoch:8, iter:5735] Loss: 1.602, 11.495, 73.313, 477.278, 2.045
[epoch:8, iter:5755] Loss: 1.602, 11.500, 73.323, 477.174, 1.858
Epoch: [7][300/782]	Time 0.099 (0.080)	Data 0.002 (0.004)	Loss 16.1194 (16.2915)	Acc@1 54.688 (52.056)	Acc@5 82.812 (83.171)
[epoch:8, iter:5775] Loss: 1.602, 11.507, 73.336, 477.266, 1.883
[epoch:8, iter:5795] Loss: 1.602, 11.500, 73.371, 477.359, 1.277
[epoch:8, iter:5815] Loss: 1.600, 11.492, 73.317, 477.260, 1.665
[epoch:8, iter:5835] Loss: 1.601, 11.489, 73.283, 477.217, 1.855
[epoch:8, iter:5855] Loss: 1.600, 11.489, 73.257, 477.123, 1.653
Epoch: [7][400/782]	Time 0.097 (0.081)	Data 0.003 (0.003)	Loss 15.4845 (16.2537)	Acc@1 51.562 (52.229)	Acc@5 82.812 (83.428)
[epoch:8, iter:5875] Loss: 1.599, 11.482, 73.264, 477.007, 1.860
[epoch:8, iter:5895] Loss: 1.598, 11.484, 73.228, 476.909, 1.757
[epoch:8, iter:5915] Loss: 1.596, 11.480, 73.173, 476.721, 1.490
[epoch:8, iter:5935] Loss: 1.597, 11.480, 73.190, 476.750, 1.658
[epoch:8, iter:5955] Loss: 1.597, 11.472, 73.187, 476.628, 1.657
Epoch: [7][500/782]	Time 0.092 (0.080)	Data 0.003 (0.003)	Loss 15.2994 (16.2222)	Acc@1 57.812 (52.352)	Acc@5 85.938 (83.564)
[epoch:8, iter:5975] Loss: 1.596, 11.476, 73.195, 476.604, 1.608
[epoch:8, iter:5995] Loss: 1.596, 11.482, 73.218, 476.654, 2.317
[epoch:8, iter:6015] Loss: 1.595, 11.483, 73.207, 476.549, 1.798
[epoch:8, iter:6035] Loss: 1.595, 11.482, 73.141, 476.376, 1.820
[epoch:8, iter:6055] Loss: 1.594, 11.477, 73.089, 476.148, 1.848
Epoch: [7][600/782]	Time 0.087 (0.080)	Data 0.002 (0.003)	Loss 17.5771 (16.2053)	Acc@1 48.438 (52.337)	Acc@5 79.688 (83.491)
[epoch:8, iter:6075] Loss: 1.593, 11.475, 73.073, 476.167, 2.197
[epoch:8, iter:6095] Loss: 1.593, 11.475, 73.079, 476.187, 1.605
[epoch:8, iter:6115] Loss: 1.594, 11.480, 73.096, 476.132, 2.059
[epoch:8, iter:6135] Loss: 1.594, 11.480, 73.114, 476.166, 1.762
[epoch:8, iter:6155] Loss: 1.593, 11.473, 73.113, 476.029, 2.001
Epoch: [7][700/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 16.0057 (16.1964)	Acc@1 51.562 (52.363)	Acc@5 79.688 (83.519)
[epoch:8, iter:6175] Loss: 1.592, 11.472, 73.108, 475.951, 1.838
[epoch:8, iter:6195] Loss: 1.592, 11.469, 73.085, 475.845, 2.278
[epoch:8, iter:6215] Loss: 1.591, 11.465, 73.040, 475.651, 1.565
[epoch:8, iter:6235] Loss: 1.591, 11.459, 72.985, 475.465, 1.720
[epoch:8, iter:6255] Loss: 1.590, 11.458, 72.974, 475.448, 2.021
 * Acc@1 52.546 Acc@5 83.506
epoch 7, total time 61.30
Test: [0/313]	Time 0.283 (0.283)	Loss 2.2521 (2.2521)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.011)	Loss 2.9849 (2.3417)	Acc@1 43.750 (47.896)	Acc@5 81.250 (79.115)
Test: [200/313]	Time 0.009 (0.009)	Loss 2.1931 (2.3314)	Acc@1 50.000 (48.274)	Acc@5 78.125 (78.996)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5244 (2.3369)	Acc@1 40.625 (47.768)	Acc@5 68.750 (78.945)
 * Acc@1 47.880 Acc@5 78.980
saving the best model!
==> training...
Epoch: [8][0/782]	Time 0.586 (0.586)	Data 0.515 (0.515)	Loss 16.3844 (16.3844)	Acc@1 60.938 (60.938)	Acc@5 79.688 (79.688)
[epoch:9, iter:6257] Loss: 1.552, 11.514, 74.448, 477.760, 1.855
[epoch:9, iter:6277] Loss: 1.564, 11.413, 73.083, 473.754, 2.108
[epoch:9, iter:6297] Loss: 1.576, 11.452, 72.628, 472.313, 1.689
[epoch:9, iter:6317] Loss: 1.572, 11.451, 72.732, 472.904, 1.888
[epoch:9, iter:6337] Loss: 1.578, 11.460, 72.841, 472.987, 1.436
Epoch: [8][100/782]	Time 0.070 (0.088)	Data 0.002 (0.007)	Loss 15.0344 (15.8661)	Acc@1 62.500 (54.069)	Acc@5 90.625 (84.236)
[epoch:9, iter:6357] Loss: 1.575, 11.457, 72.759, 472.426, 1.366
[epoch:9, iter:6377] Loss: 1.571, 11.420, 72.750, 472.139, 1.672
[epoch:9, iter:6397] Loss: 1.570, 11.396, 72.638, 471.448, 1.770
[epoch:9, iter:6417] Loss: 1.570, 11.393, 72.594, 471.396, 1.930
[epoch:9, iter:6437] Loss: 1.569, 11.382, 72.498, 471.101, 1.643
Epoch: [8][200/782]	Time 0.076 (0.085)	Data 0.002 (0.005)	Loss 16.5760 (15.8552)	Acc@1 51.562 (54.003)	Acc@5 85.938 (84.624)
[epoch:9, iter:6457] Loss: 1.572, 11.386, 72.574, 471.541, 1.818
[epoch:9, iter:6477] Loss: 1.572, 11.391, 72.541, 471.366, 1.560
[epoch:9, iter:6497] Loss: 1.572, 11.390, 72.502, 471.347, 2.216
[epoch:9, iter:6517] Loss: 1.573, 11.387, 72.483, 471.259, 1.978
[epoch:9, iter:6537] Loss: 1.573, 11.379, 72.466, 471.379, 1.654
Epoch: [8][300/782]	Time 0.089 (0.084)	Data 0.003 (0.004)	Loss 17.5965 (15.8550)	Acc@1 51.562 (53.763)	Acc@5 78.125 (84.603)
[epoch:9, iter:6557] Loss: 1.570, 11.372, 72.415, 471.305, 2.316
[epoch:9, iter:6577] Loss: 1.571, 11.360, 72.369, 471.200, 1.716
[epoch:9, iter:6597] Loss: 1.570, 11.355, 72.360, 471.292, 1.884
[epoch:9, iter:6617] Loss: 1.570, 11.350, 72.396, 471.495, 2.026
[epoch:9, iter:6637] Loss: 1.571, 11.364, 72.362, 471.540, 1.472
Epoch: [8][400/782]	Time 0.092 (0.084)	Data 0.003 (0.004)	Loss 15.6497 (15.8779)	Acc@1 45.312 (53.659)	Acc@5 84.375 (84.648)
[epoch:9, iter:6657] Loss: 1.573, 11.371, 72.352, 471.531, 1.809
[epoch:9, iter:6677] Loss: 1.572, 11.366, 72.280, 471.307, 1.794
[epoch:9, iter:6697] Loss: 1.572, 11.359, 72.250, 471.225, 1.578
[epoch:9, iter:6717] Loss: 1.571, 11.355, 72.254, 471.206, 1.564
[epoch:9, iter:6737] Loss: 1.572, 11.354, 72.258, 471.282, 2.211
Epoch: [8][500/782]	Time 0.065 (0.082)	Data 0.002 (0.003)	Loss 15.5996 (15.8630)	Acc@1 59.375 (53.646)	Acc@5 92.188 (84.487)
[epoch:9, iter:6757] Loss: 1.571, 11.357, 72.247, 471.304, 1.662
[epoch:9, iter:6777] Loss: 1.571, 11.356, 72.221, 471.187, 1.888
[epoch:9, iter:6797] Loss: 1.571, 11.362, 72.267, 471.310, 1.607
[epoch:9, iter:6817] Loss: 1.571, 11.359, 72.260, 471.239, 2.161
[epoch:9, iter:6837] Loss: 1.571, 11.355, 72.218, 471.092, 2.053
Epoch: [8][600/782]	Time 0.079 (0.081)	Data 0.002 (0.003)	Loss 14.9964 (15.8598)	Acc@1 56.250 (53.601)	Acc@5 85.938 (84.424)
[epoch:9, iter:6857] Loss: 1.571, 11.358, 72.210, 471.074, 1.439
[epoch:9, iter:6877] Loss: 1.571, 11.358, 72.236, 471.150, 1.962
[epoch:9, iter:6897] Loss: 1.571, 11.352, 72.227, 471.089, 2.086
[epoch:9, iter:6917] Loss: 1.571, 11.350, 72.231, 471.032, 1.362
[epoch:9, iter:6937] Loss: 1.570, 11.348, 72.218, 470.984, 1.788
Epoch: [8][700/782]	Time 0.089 (0.081)	Data 0.003 (0.003)	Loss 16.1180 (15.8587)	Acc@1 53.125 (53.611)	Acc@5 79.688 (84.386)
[epoch:9, iter:6957] Loss: 1.570, 11.345, 72.213, 470.946, 1.900
[epoch:9, iter:6977] Loss: 1.570, 11.346, 72.190, 470.849, 1.897
[epoch:9, iter:6997] Loss: 1.570, 11.344, 72.200, 470.853, 1.740
[epoch:9, iter:7017] Loss: 1.570, 11.343, 72.189, 470.788, 1.854
[epoch:9, iter:7037] Loss: 1.570, 11.340, 72.167, 470.709, 1.852
 * Acc@1 53.620 Acc@5 84.364
epoch 8, total time 62.99
Test: [0/313]	Time 0.252 (0.252)	Loss 2.3440 (2.3440)	Acc@1 53.125 (53.125)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.1886 (2.3836)	Acc@1 53.125 (46.627)	Acc@5 75.000 (79.548)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.9651 (2.4080)	Acc@1 50.000 (46.269)	Acc@5 87.500 (78.731)
Test: [300/313]	Time 0.005 (0.008)	Loss 3.3431 (2.4018)	Acc@1 34.375 (46.397)	Acc@5 71.875 (78.748)
 * Acc@1 46.440 Acc@5 78.770
==> training...
Epoch: [9][0/782]	Time 0.473 (0.473)	Data 0.409 (0.409)	Loss 15.4743 (15.4743)	Acc@1 64.062 (64.062)	Acc@5 85.938 (85.938)
[epoch:10, iter:7039] Loss: 1.577, 10.911, 74.963, 461.406, 1.644
[epoch:10, iter:7059] Loss: 1.578, 11.317, 72.344, 470.307, 1.310
[epoch:10, iter:7079] Loss: 1.575, 11.282, 72.076, 469.467, 1.169
[epoch:10, iter:7099] Loss: 1.574, 11.292, 72.087, 469.252, 1.299
[epoch:10, iter:7119] Loss: 1.569, 11.337, 72.011, 469.215, 2.036
Epoch: [9][100/782]	Time 0.057 (0.078)	Data 0.002 (0.006)	Loss 15.4794 (15.7139)	Acc@1 57.812 (54.146)	Acc@5 85.938 (84.158)
[epoch:10, iter:7139] Loss: 1.567, 11.311, 71.971, 469.094, 1.568
[epoch:10, iter:7159] Loss: 1.561, 11.259, 71.872, 468.911, 1.471
[epoch:10, iter:7179] Loss: 1.558, 11.264, 71.778, 468.760, 1.395
[epoch:10, iter:7199] Loss: 1.557, 11.273, 71.812, 468.852, 1.568
[epoch:10, iter:7219] Loss: 1.560, 11.275, 71.814, 468.692, 1.761
Epoch: [9][200/782]	Time 0.065 (0.075)	Data 0.002 (0.004)	Loss 14.9958 (15.6425)	Acc@1 54.688 (54.835)	Acc@5 85.938 (84.445)
[epoch:10, iter:7239] Loss: 1.559, 11.282, 71.760, 468.525, 1.651
[epoch:10, iter:7259] Loss: 1.559, 11.281, 71.807, 468.727, 1.603
[epoch:10, iter:7279] Loss: 1.557, 11.278, 71.897, 469.054, 2.241
[epoch:10, iter:7299] Loss: 1.558, 11.279, 71.896, 468.842, 1.824
[epoch:10, iter:7319] Loss: 1.558, 11.288, 71.866, 468.826, 1.545
Epoch: [9][300/782]	Time 0.065 (0.075)	Data 0.002 (0.004)	Loss 15.5450 (15.6663)	Acc@1 51.562 (54.771)	Acc@5 82.812 (84.458)
[epoch:10, iter:7339] Loss: 1.558, 11.283, 71.823, 468.534, 1.866
[epoch:10, iter:7359] Loss: 1.558, 11.272, 71.812, 468.614, 1.706
[epoch:10, iter:7379] Loss: 1.557, 11.265, 71.788, 468.531, 1.425
[epoch:10, iter:7399] Loss: 1.556, 11.263, 71.791, 468.606, 1.740
[epoch:10, iter:7419] Loss: 1.557, 11.262, 71.754, 468.299, 2.036
Epoch: [9][400/782]	Time 0.064 (0.076)	Data 0.002 (0.003)	Loss 16.0108 (15.6487)	Acc@1 59.375 (54.754)	Acc@5 87.500 (84.663)
[epoch:10, iter:7439] Loss: 1.557, 11.255, 71.719, 468.287, 1.385
[epoch:10, iter:7459] Loss: 1.558, 11.255, 71.710, 468.261, 1.776
[epoch:10, iter:7479] Loss: 1.557, 11.252, 71.741, 468.135, 1.499
[epoch:10, iter:7499] Loss: 1.557, 11.239, 71.717, 467.943, 1.607
[epoch:10, iter:7519] Loss: 1.556, 11.227, 71.687, 467.806, 1.537
Epoch: [9][500/782]	Time 0.081 (0.076)	Data 0.003 (0.003)	Loss 17.0358 (15.6051)	Acc@1 37.500 (54.971)	Acc@5 73.438 (84.868)
[epoch:10, iter:7539] Loss: 1.555, 11.225, 71.688, 467.803, 2.615
[epoch:10, iter:7559] Loss: 1.555, 11.226, 71.709, 467.811, 1.665
[epoch:10, iter:7579] Loss: 1.553, 11.225, 71.683, 467.779, 1.514
[epoch:10, iter:7599] Loss: 1.554, 11.226, 71.701, 467.765, 1.977
[epoch:10, iter:7619] Loss: 1.555, 11.229, 71.694, 467.762, 2.089
Epoch: [9][600/782]	Time 0.081 (0.077)	Data 0.002 (0.003)	Loss 14.6707 (15.6182)	Acc@1 57.812 (54.927)	Acc@5 84.375 (84.861)
[epoch:10, iter:7639] Loss: 1.554, 11.233, 71.701, 467.767, 1.397
[epoch:10, iter:7659] Loss: 1.553, 11.229, 71.672, 467.571, 1.365
[epoch:10, iter:7679] Loss: 1.553, 11.231, 71.684, 467.549, 2.181
[epoch:10, iter:7699] Loss: 1.553, 11.231, 71.700, 467.480, 2.102
[epoch:10, iter:7719] Loss: 1.552, 11.229, 71.684, 467.421, 1.975
Epoch: [9][700/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 15.2966 (15.5859)	Acc@1 59.375 (54.993)	Acc@5 85.938 (84.892)
[epoch:10, iter:7739] Loss: 1.552, 11.229, 71.658, 467.338, 1.771
[epoch:10, iter:7759] Loss: 1.551, 11.225, 71.644, 467.268, 1.407
[epoch:10, iter:7779] Loss: 1.550, 11.221, 71.632, 467.197, 1.575
[epoch:10, iter:7799] Loss: 1.549, 11.220, 71.616, 467.171, 2.017
[epoch:10, iter:7819] Loss: 1.549, 11.220, 71.629, 467.229, 2.065
 * Acc@1 54.924 Acc@5 84.874
epoch 9, total time 60.82
Test: [0/313]	Time 0.228 (0.228)	Loss 2.7886 (2.7886)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.9031 (2.4660)	Acc@1 37.500 (47.123)	Acc@5 71.875 (79.579)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.7269 (2.4655)	Acc@1 50.000 (47.326)	Acc@5 93.750 (79.073)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3711 (2.4624)	Acc@1 53.125 (47.446)	Acc@5 75.000 (79.049)
 * Acc@1 47.470 Acc@5 78.990
==> training...
Epoch: [10][0/782]	Time 0.475 (0.475)	Data 0.401 (0.401)	Loss 15.6648 (15.6648)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
[epoch:11, iter:7821] Loss: 1.504, 11.047, 75.372, 470.948, 1.596
[epoch:11, iter:7841] Loss: 1.546, 11.089, 72.136, 465.539, 1.262
[epoch:11, iter:7861] Loss: 1.543, 11.165, 71.794, 464.585, 1.437
[epoch:11, iter:7881] Loss: 1.541, 11.196, 71.624, 465.240, 1.870
[epoch:11, iter:7901] Loss: 1.532, 11.189, 71.413, 465.588, 1.609
Epoch: [10][100/782]	Time 0.077 (0.087)	Data 0.002 (0.006)	Loss 14.3893 (15.3853)	Acc@1 65.625 (55.987)	Acc@5 90.625 (85.582)
[epoch:11, iter:7921] Loss: 1.531, 11.185, 71.234, 465.130, 1.200
[epoch:11, iter:7941] Loss: 1.529, 11.151, 71.220, 464.523, 1.790
[epoch:11, iter:7961] Loss: 1.533, 11.163, 71.255, 464.877, 1.609
[epoch:11, iter:7981] Loss: 1.536, 11.173, 71.186, 464.835, 1.654
[epoch:11, iter:8001] Loss: 1.533, 11.175, 71.176, 464.862, 1.800
Epoch: [10][200/782]	Time 0.078 (0.082)	Data 0.002 (0.004)	Loss 16.3114 (15.3386)	Acc@1 54.688 (56.514)	Acc@5 85.938 (85.953)
[epoch:11, iter:8021] Loss: 1.531, 11.174, 71.115, 464.851, 1.484
[epoch:11, iter:8041] Loss: 1.531, 11.170, 71.090, 464.886, 1.654
[epoch:11, iter:8061] Loss: 1.533, 11.171, 71.087, 464.871, 1.715
[epoch:11, iter:8081] Loss: 1.533, 11.175, 71.042, 464.813, 1.741
[epoch:11, iter:8101] Loss: 1.535, 11.167, 71.074, 464.944, 1.443
Epoch: [10][300/782]	Time 0.081 (0.080)	Data 0.002 (0.004)	Loss 15.1100 (15.3139)	Acc@1 60.938 (56.702)	Acc@5 87.500 (86.005)
[epoch:11, iter:8121] Loss: 1.534, 11.169, 71.080, 464.969, 1.553
[epoch:11, iter:8141] Loss: 1.533, 11.167, 71.140, 465.040, 1.784
[epoch:11, iter:8161] Loss: 1.534, 11.161, 71.173, 464.903, 1.437
[epoch:11, iter:8181] Loss: 1.534, 11.161, 71.152, 464.783, 1.469
[epoch:11, iter:8201] Loss: 1.535, 11.160, 71.084, 464.415, 1.997
Epoch: [10][400/782]	Time 0.072 (0.080)	Data 0.002 (0.003)	Loss 14.3090 (15.3049)	Acc@1 59.375 (56.429)	Acc@5 92.188 (85.938)
[epoch:11, iter:8221] Loss: 1.534, 11.150, 71.102, 464.337, 1.594
[epoch:11, iter:8241] Loss: 1.533, 11.145, 71.078, 464.153, 1.352
[epoch:11, iter:8261] Loss: 1.532, 11.142, 71.073, 464.186, 1.875
[epoch:11, iter:8281] Loss: 1.532, 11.137, 71.104, 464.197, 1.588
[epoch:11, iter:8301] Loss: 1.531, 11.132, 71.093, 464.075, 1.954
Epoch: [10][500/782]	Time 0.075 (0.080)	Data 0.002 (0.003)	Loss 15.6196 (15.3042)	Acc@1 46.875 (56.150)	Acc@5 89.062 (85.850)
[epoch:11, iter:8321] Loss: 1.531, 11.128, 71.066, 464.054, 1.678
[epoch:11, iter:8341] Loss: 1.532, 11.131, 71.077, 464.049, 1.508
[epoch:11, iter:8361] Loss: 1.531, 11.133, 71.081, 463.997, 1.383
[epoch:11, iter:8381] Loss: 1.532, 11.133, 71.076, 463.916, 1.707
[epoch:11, iter:8401] Loss: 1.532, 11.130, 71.066, 463.836, 1.757
Epoch: [10][600/782]	Time 0.089 (0.079)	Data 0.003 (0.003)	Loss 16.2450 (15.3115)	Acc@1 51.562 (56.021)	Acc@5 85.938 (85.821)
[epoch:11, iter:8421] Loss: 1.531, 11.128, 71.046, 463.775, 2.216
[epoch:11, iter:8441] Loss: 1.530, 11.132, 71.034, 463.718, 1.528
[epoch:11, iter:8461] Loss: 1.530, 11.136, 71.024, 463.654, 2.033
[epoch:11, iter:8481] Loss: 1.530, 11.137, 71.035, 463.652, 2.128
[epoch:11, iter:8501] Loss: 1.531, 11.142, 71.052, 463.707, 1.999
Epoch: [10][700/782]	Time 0.076 (0.079)	Data 0.003 (0.003)	Loss 14.6710 (15.3355)	Acc@1 46.875 (55.818)	Acc@5 87.500 (85.764)
[epoch:11, iter:8521] Loss: 1.532, 11.146, 71.075, 463.788, 1.680
[epoch:11, iter:8541] Loss: 1.533, 11.149, 71.093, 463.915, 2.078
[epoch:11, iter:8561] Loss: 1.533, 11.152, 71.092, 463.957, 1.301
[epoch:11, iter:8581] Loss: 1.533, 11.151, 71.115, 464.002, 1.213
[epoch:11, iter:8601] Loss: 1.533, 11.151, 71.138, 463.973, 1.274
 * Acc@1 55.802 Acc@5 85.638
epoch 10, total time 62.53
Test: [0/313]	Time 0.239 (0.239)	Loss 2.8278 (2.8278)	Acc@1 53.125 (53.125)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.1003 (2.2106)	Acc@1 37.500 (48.082)	Acc@5 90.625 (80.941)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.9649 (2.1841)	Acc@1 59.375 (48.414)	Acc@5 84.375 (80.613)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.7538 (2.1782)	Acc@1 40.625 (49.128)	Acc@5 71.875 (80.824)
 * Acc@1 49.140 Acc@5 80.760
saving the best model!
==> training...
Epoch: [11][0/782]	Time 0.514 (0.514)	Data 0.430 (0.430)	Loss 16.7780 (16.7780)	Acc@1 50.000 (50.000)	Acc@5 82.812 (82.812)
[epoch:12, iter:8603] Loss: 1.612, 11.645, 75.902, 483.061, 1.872
[epoch:12, iter:8623] Loss: 1.517, 11.437, 71.334, 464.368, 2.162
[epoch:12, iter:8643] Loss: 1.530, 11.345, 71.172, 462.957, 1.539
[epoch:12, iter:8663] Loss: 1.532, 11.274, 71.024, 462.397, 1.432
[epoch:12, iter:8683] Loss: 1.532, 11.222, 70.882, 462.152, 1.883
Epoch: [11][100/782]	Time 0.074 (0.082)	Data 0.002 (0.006)	Loss 15.9519 (15.2333)	Acc@1 54.688 (56.219)	Acc@5 89.062 (85.752)
[epoch:12, iter:8703] Loss: 1.534, 11.209, 70.915, 462.591, 1.594
[epoch:12, iter:8723] Loss: 1.533, 11.186, 70.989, 462.530, 1.584
[epoch:12, iter:8743] Loss: 1.532, 11.184, 70.865, 462.455, 1.741
[epoch:12, iter:8763] Loss: 1.530, 11.177, 70.805, 462.692, 1.452
[epoch:12, iter:8783] Loss: 1.527, 11.150, 70.681, 462.127, 1.994
Epoch: [11][200/782]	Time 0.091 (0.081)	Data 0.003 (0.004)	Loss 15.4857 (15.2175)	Acc@1 53.125 (56.576)	Acc@5 79.688 (85.930)
[epoch:12, iter:8803] Loss: 1.526, 11.144, 70.685, 462.036, 2.081
[epoch:12, iter:8823] Loss: 1.526, 11.142, 70.784, 462.168, 1.180
[epoch:12, iter:8843] Loss: 1.527, 11.137, 70.766, 462.154, 1.554
[epoch:12, iter:8863] Loss: 1.527, 11.121, 70.770, 462.045, 1.498
[epoch:12, iter:8883] Loss: 1.527, 11.124, 70.783, 462.041, 2.045
Epoch: [11][300/782]	Time 0.072 (0.079)	Data 0.002 (0.004)	Loss 15.9214 (15.2183)	Acc@1 51.562 (56.598)	Acc@5 85.938 (85.979)
[epoch:12, iter:8903] Loss: 1.527, 11.128, 70.811, 462.131, 1.757
[epoch:12, iter:8923] Loss: 1.528, 11.124, 70.769, 461.994, 1.669
[epoch:12, iter:8943] Loss: 1.528, 11.128, 70.785, 462.001, 1.487
[epoch:12, iter:8963] Loss: 1.528, 11.127, 70.748, 461.971, 1.439
[epoch:12, iter:8983] Loss: 1.528, 11.126, 70.739, 461.978, 1.264
Epoch: [11][400/782]	Time 0.084 (0.078)	Data 0.003 (0.003)	Loss 16.1499 (15.2235)	Acc@1 50.000 (56.527)	Acc@5 85.938 (86.027)
[epoch:12, iter:9003] Loss: 1.528, 11.130, 70.766, 462.041, 1.739
[epoch:12, iter:9023] Loss: 1.528, 11.130, 70.777, 462.100, 1.760
[epoch:12, iter:9043] Loss: 1.527, 11.131, 70.798, 462.108, 1.738
[epoch:12, iter:9063] Loss: 1.526, 11.125, 70.821, 462.173, 1.777
[epoch:12, iter:9083] Loss: 1.526, 11.122, 70.808, 462.278, 1.667
Epoch: [11][500/782]	Time 0.088 (0.077)	Data 0.003 (0.003)	Loss 15.1963 (15.2311)	Acc@1 53.125 (56.496)	Acc@5 85.938 (86.034)
[epoch:12, iter:9103] Loss: 1.526, 11.118, 70.763, 462.195, 1.698
[epoch:12, iter:9123] Loss: 1.525, 11.116, 70.762, 462.267, 1.618
[epoch:12, iter:9143] Loss: 1.526, 11.114, 70.758, 462.302, 1.564
[epoch:12, iter:9163] Loss: 1.527, 11.109, 70.757, 462.282, 1.475
[epoch:12, iter:9183] Loss: 1.526, 11.105, 70.771, 462.218, 2.032
Epoch: [11][600/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 16.3456 (15.2477)	Acc@1 51.562 (56.359)	Acc@5 82.812 (85.893)
[epoch:12, iter:9203] Loss: 1.526, 11.102, 70.780, 462.251, 1.966
[epoch:12, iter:9223] Loss: 1.526, 11.100, 70.784, 462.280, 1.571
[epoch:12, iter:9243] Loss: 1.525, 11.098, 70.797, 462.299, 1.330
[epoch:12, iter:9263] Loss: 1.525, 11.094, 70.762, 462.186, 1.628
[epoch:12, iter:9283] Loss: 1.526, 11.097, 70.783, 462.276, 1.781
Epoch: [11][700/782]	Time 0.076 (0.077)	Data 0.002 (0.003)	Loss 14.9430 (15.2347)	Acc@1 53.125 (56.384)	Acc@5 92.188 (85.987)
[epoch:12, iter:9303] Loss: 1.526, 11.095, 70.752, 462.156, 1.466
[epoch:12, iter:9323] Loss: 1.525, 11.092, 70.732, 461.982, 2.240
[epoch:12, iter:9343] Loss: 1.525, 11.093, 70.735, 461.988, 1.369
[epoch:12, iter:9363] Loss: 1.525, 11.092, 70.727, 461.980, 1.705
[epoch:12, iter:9383] Loss: 1.524, 11.091, 70.698, 461.926, 1.579
 * Acc@1 56.298 Acc@5 86.016
epoch 11, total time 60.31
Test: [0/313]	Time 0.274 (0.274)	Loss 2.7385 (2.7385)	Acc@1 59.375 (59.375)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.008 (0.009)	Loss 3.0099 (2.4555)	Acc@1 34.375 (46.813)	Acc@5 78.125 (80.043)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.0676 (2.4597)	Acc@1 56.250 (47.155)	Acc@5 87.500 (79.167)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.3258 (2.4719)	Acc@1 25.000 (47.301)	Acc@5 65.625 (79.080)
 * Acc@1 47.380 Acc@5 79.050
==> training...
Epoch: [12][0/782]	Time 0.539 (0.539)	Data 0.462 (0.462)	Loss 14.7864 (14.7864)	Acc@1 73.438 (73.438)	Acc@5 90.625 (90.625)
[epoch:13, iter:9385] Loss: 1.475, 11.411, 73.556, 465.614, 1.302
[epoch:13, iter:9405] Loss: 1.550, 11.258, 71.231, 463.043, 1.146
[epoch:13, iter:9425] Loss: 1.540, 11.215, 70.845, 463.197, 1.945
[epoch:13, iter:9445] Loss: 1.531, 11.200, 70.420, 461.739, 1.687
[epoch:13, iter:9465] Loss: 1.527, 11.178, 70.434, 461.603, 1.599
Epoch: [12][100/782]	Time 0.062 (0.080)	Data 0.002 (0.007)	Loss 15.3269 (15.1141)	Acc@1 59.375 (56.977)	Acc@5 84.375 (86.046)
[epoch:13, iter:9485] Loss: 1.525, 11.130, 70.240, 460.616, 1.697
[epoch:13, iter:9505] Loss: 1.526, 11.120, 70.367, 460.560, 1.720
[epoch:13, iter:9525] Loss: 1.521, 11.111, 70.237, 459.860, 1.267
[epoch:13, iter:9545] Loss: 1.518, 11.105, 70.158, 459.752, 2.247
[epoch:13, iter:9565] Loss: 1.516, 11.103, 70.211, 459.839, 2.007
Epoch: [12][200/782]	Time 0.083 (0.075)	Data 0.002 (0.004)	Loss 14.4206 (15.0479)	Acc@1 51.562 (57.206)	Acc@5 85.938 (86.334)
[epoch:13, iter:9585] Loss: 1.516, 11.106, 70.220, 459.767, 1.677
[epoch:13, iter:9605] Loss: 1.518, 11.122, 70.354, 460.386, 1.945
[epoch:13, iter:9625] Loss: 1.518, 11.114, 70.415, 460.463, 1.892
[epoch:13, iter:9645] Loss: 1.520, 11.117, 70.563, 460.899, 1.507
[epoch:13, iter:9665] Loss: 1.520, 11.106, 70.563, 460.618, 1.154
Epoch: [12][300/782]	Time 0.078 (0.076)	Data 0.002 (0.004)	Loss 14.2482 (15.0952)	Acc@1 57.812 (57.148)	Acc@5 90.625 (86.379)
[epoch:13, iter:9685] Loss: 1.519, 11.104, 70.490, 460.306, 1.428
[epoch:13, iter:9705] Loss: 1.519, 11.103, 70.469, 460.238, 1.699
[epoch:13, iter:9725] Loss: 1.518, 11.092, 70.414, 459.990, 1.392
[epoch:13, iter:9745] Loss: 1.517, 11.081, 70.376, 459.780, 1.853
[epoch:13, iter:9765] Loss: 1.515, 11.069, 70.332, 459.636, 1.699
Epoch: [12][400/782]	Time 0.073 (0.076)	Data 0.002 (0.003)	Loss 15.5507 (15.0453)	Acc@1 50.000 (57.275)	Acc@5 85.938 (86.526)
[epoch:13, iter:9785] Loss: 1.516, 11.063, 70.322, 459.544, 1.765
[epoch:13, iter:9805] Loss: 1.515, 11.062, 70.293, 459.479, 1.622
[epoch:13, iter:9825] Loss: 1.515, 11.057, 70.264, 459.421, 1.591
[epoch:13, iter:9845] Loss: 1.514, 11.058, 70.264, 459.473, 1.401
[epoch:13, iter:9865] Loss: 1.513, 11.055, 70.258, 459.507, 1.452
Epoch: [12][500/782]	Time 0.068 (0.076)	Data 0.002 (0.003)	Loss 15.4124 (15.0460)	Acc@1 59.375 (57.120)	Acc@5 79.688 (86.502)
[epoch:13, iter:9885] Loss: 1.514, 11.055, 70.275, 459.583, 1.712
[epoch:13, iter:9905] Loss: 1.513, 11.051, 70.266, 459.593, 1.372
[epoch:13, iter:9925] Loss: 1.513, 11.051, 70.266, 459.543, 1.296
[epoch:13, iter:9945] Loss: 1.513, 11.050, 70.342, 459.637, 1.473
[epoch:13, iter:9965] Loss: 1.512, 11.047, 70.315, 459.507, 1.589
Epoch: [12][600/782]	Time 0.075 (0.076)	Data 0.002 (0.003)	Loss 13.9853 (15.0466)	Acc@1 65.625 (57.129)	Acc@5 92.188 (86.481)
[epoch:13, iter:9985] Loss: 1.511, 11.045, 70.320, 459.540, 1.055
[epoch:13, iter:10005] Loss: 1.512, 11.041, 70.349, 459.592, 1.170
[epoch:13, iter:10025] Loss: 1.512, 11.040, 70.330, 459.590, 1.788
[epoch:13, iter:10045] Loss: 1.513, 11.037, 70.347, 459.619, 1.508
[epoch:13, iter:10065] Loss: 1.514, 11.039, 70.369, 459.649, 1.330
Epoch: [12][700/782]	Time 0.070 (0.076)	Data 0.002 (0.003)	Loss 14.4312 (15.0590)	Acc@1 65.625 (57.044)	Acc@5 87.500 (86.452)
[epoch:13, iter:10085] Loss: 1.514, 11.041, 70.375, 459.632, 1.241
[epoch:13, iter:10105] Loss: 1.514, 11.038, 70.371, 459.602, 1.260
[epoch:13, iter:10125] Loss: 1.514, 11.037, 70.368, 459.660, 1.528
[epoch:13, iter:10145] Loss: 1.514, 11.037, 70.383, 459.687, 1.447
[epoch:13, iter:10165] Loss: 1.514, 11.036, 70.382, 459.777, 2.032
 * Acc@1 57.016 Acc@5 86.466
epoch 12, total time 59.58
Test: [0/313]	Time 0.287 (0.287)	Loss 2.5807 (2.5807)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.009 (0.011)	Loss 2.7586 (2.2489)	Acc@1 46.875 (51.423)	Acc@5 68.750 (81.590)
Test: [200/313]	Time 0.005 (0.009)	Loss 1.3695 (2.2135)	Acc@1 53.125 (51.555)	Acc@5 93.750 (81.639)
Test: [300/313]	Time 0.008 (0.009)	Loss 2.1912 (2.2277)	Acc@1 31.250 (51.692)	Acc@5 84.375 (81.343)
 * Acc@1 51.570 Acc@5 81.410
saving the best model!
==> training...
Epoch: [13][0/782]	Time 0.545 (0.545)	Data 0.474 (0.474)	Loss 15.1274 (15.1274)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
[epoch:14, iter:10167] Loss: 1.494, 10.508, 73.592, 466.602, 1.578
[epoch:14, iter:10187] Loss: 1.501, 11.064, 70.193, 457.421, 1.902
[epoch:14, iter:10207] Loss: 1.500, 11.061, 69.915, 456.863, 1.690
[epoch:14, iter:10227] Loss: 1.506, 11.046, 69.788, 457.159, 1.572
[epoch:14, iter:10247] Loss: 1.506, 11.026, 69.955, 457.562, 1.084
Epoch: [13][100/782]	Time 0.063 (0.087)	Data 0.002 (0.007)	Loss 15.4405 (14.9081)	Acc@1 57.812 (57.704)	Acc@5 87.500 (86.603)
[epoch:14, iter:10267] Loss: 1.509, 10.978, 69.991, 457.867, 1.563
[epoch:14, iter:10287] Loss: 1.508, 10.971, 69.913, 457.868, 1.470
[epoch:14, iter:10307] Loss: 1.507, 10.955, 69.935, 458.032, 1.335
[epoch:14, iter:10327] Loss: 1.508, 10.963, 69.880, 457.736, 1.606
[epoch:14, iter:10347] Loss: 1.507, 10.957, 69.950, 457.775, 1.484
Epoch: [13][200/782]	Time 0.069 (0.084)	Data 0.003 (0.005)	Loss 13.7287 (14.8944)	Acc@1 75.000 (57.789)	Acc@5 90.625 (86.816)
[epoch:14, iter:10367] Loss: 1.508, 10.973, 69.947, 457.987, 1.066
[epoch:14, iter:10387] Loss: 1.506, 10.970, 69.879, 457.858, 1.339
[epoch:14, iter:10407] Loss: 1.508, 10.967, 69.825, 457.898, 1.520
[epoch:14, iter:10427] Loss: 1.509, 10.971, 69.848, 457.897, 1.588
[epoch:14, iter:10447] Loss: 1.507, 10.971, 69.832, 457.801, 1.828
Epoch: [13][300/782]	Time 0.079 (0.081)	Data 0.003 (0.004)	Loss 14.9985 (14.9055)	Acc@1 57.812 (57.641)	Acc@5 82.812 (86.773)
[epoch:14, iter:10467] Loss: 1.508, 10.976, 69.851, 458.008, 1.595
[epoch:14, iter:10487] Loss: 1.508, 10.977, 69.863, 457.978, 1.660
[epoch:14, iter:10507] Loss: 1.510, 10.979, 69.880, 458.098, 1.491
[epoch:14, iter:10527] Loss: 1.511, 10.985, 69.943, 458.159, 1.364
[epoch:14, iter:10547] Loss: 1.510, 10.988, 70.016, 458.279, 1.745
Epoch: [13][400/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 15.1090 (14.9406)	Acc@1 62.500 (57.349)	Acc@5 82.812 (86.764)
[epoch:14, iter:10567] Loss: 1.510, 10.989, 70.038, 458.253, 1.752
[epoch:14, iter:10587] Loss: 1.509, 10.991, 70.006, 458.093, 1.488
[epoch:14, iter:10607] Loss: 1.510, 10.994, 70.011, 458.070, 1.685
[epoch:14, iter:10627] Loss: 1.509, 10.991, 70.036, 457.986, 1.462
[epoch:14, iter:10647] Loss: 1.508, 10.986, 70.034, 457.749, 1.145
Epoch: [13][500/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 14.1137 (14.9156)	Acc@1 53.125 (57.376)	Acc@5 89.062 (86.621)
[epoch:14, iter:10667] Loss: 1.507, 10.988, 70.006, 457.641, 1.509
[epoch:14, iter:10687] Loss: 1.506, 10.985, 69.992, 457.518, 1.710
[epoch:14, iter:10707] Loss: 1.506, 10.982, 69.996, 457.541, 1.155
[epoch:14, iter:10727] Loss: 1.505, 10.984, 69.994, 457.616, 1.826
[epoch:14, iter:10747] Loss: 1.505, 10.980, 70.009, 457.662, 1.620
Epoch: [13][600/782]	Time 0.066 (0.079)	Data 0.002 (0.003)	Loss 14.8055 (14.9180)	Acc@1 59.375 (57.516)	Acc@5 87.500 (86.616)
[epoch:14, iter:10767] Loss: 1.504, 10.979, 69.992, 457.674, 1.715
[epoch:14, iter:10787] Loss: 1.505, 10.979, 69.990, 457.712, 2.020
[epoch:14, iter:10807] Loss: 1.504, 10.980, 70.003, 457.716, 1.009
[epoch:14, iter:10827] Loss: 1.505, 10.979, 70.038, 457.830, 1.252
[epoch:14, iter:10847] Loss: 1.506, 10.980, 70.036, 457.813, 1.264
Epoch: [13][700/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 15.0590 (14.9323)	Acc@1 60.938 (57.558)	Acc@5 92.188 (86.555)
[epoch:14, iter:10867] Loss: 1.505, 10.977, 70.051, 457.808, 1.626
[epoch:14, iter:10887] Loss: 1.505, 10.977, 70.098, 457.913, 2.056
[epoch:14, iter:10907] Loss: 1.505, 10.982, 70.127, 457.945, 1.655
[epoch:14, iter:10927] Loss: 1.506, 10.985, 70.135, 457.967, 1.511
[epoch:14, iter:10947] Loss: 1.506, 10.984, 70.115, 457.903, 1.535
 * Acc@1 57.398 Acc@5 86.484
epoch 13, total time 61.56
Test: [0/313]	Time 0.272 (0.272)	Loss 2.8544 (2.8544)	Acc@1 50.000 (50.000)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.3905 (2.2452)	Acc@1 43.750 (50.186)	Acc@5 78.125 (80.755)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5586 (2.2548)	Acc@1 62.500 (50.218)	Acc@5 90.625 (80.115)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.7110 (2.2588)	Acc@1 31.250 (50.343)	Acc@5 78.125 (79.786)
 * Acc@1 50.520 Acc@5 79.930
==> training...
Epoch: [14][0/782]	Time 0.587 (0.587)	Data 0.507 (0.507)	Loss 14.0981 (14.0981)	Acc@1 60.938 (60.938)	Acc@5 90.625 (90.625)
[epoch:15, iter:10949] Loss: 1.450, 10.860, 67.986, 442.917, 1.242
[epoch:15, iter:10969] Loss: 1.532, 11.131, 72.422, 463.822, 1.570
[epoch:15, iter:10989] Loss: 1.520, 11.056, 71.310, 461.223, 1.107
[epoch:15, iter:11009] Loss: 1.517, 11.030, 70.802, 460.087, 1.526
[epoch:15, iter:11029] Loss: 1.507, 10.994, 70.391, 459.027, 1.843
Epoch: [14][100/782]	Time 0.093 (0.083)	Data 0.003 (0.007)	Loss 14.4594 (14.9374)	Acc@1 56.250 (57.967)	Acc@5 87.500 (87.330)
[epoch:15, iter:11049] Loss: 1.506, 10.947, 70.141, 458.149, 1.546
[epoch:15, iter:11069] Loss: 1.499, 10.933, 69.971, 457.807, 1.563
[epoch:15, iter:11089] Loss: 1.498, 10.943, 69.990, 458.087, 1.816
[epoch:15, iter:11109] Loss: 1.496, 10.961, 70.063, 458.232, 1.689
[epoch:15, iter:11129] Loss: 1.499, 10.967, 70.027, 457.877, 1.212
Epoch: [14][200/782]	Time 0.089 (0.081)	Data 0.003 (0.005)	Loss 14.0812 (14.9041)	Acc@1 60.938 (57.432)	Acc@5 85.938 (87.096)
[epoch:15, iter:11149] Loss: 1.498, 10.967, 69.859, 457.414, 1.458
[epoch:15, iter:11169] Loss: 1.501, 10.980, 69.820, 457.361, 1.351
[epoch:15, iter:11189] Loss: 1.501, 10.986, 69.861, 457.517, 1.458
[epoch:15, iter:11209] Loss: 1.499, 10.982, 69.901, 457.483, 1.329
[epoch:15, iter:11229] Loss: 1.497, 10.970, 69.844, 457.140, 1.329
Epoch: [14][300/782]	Time 0.092 (0.081)	Data 0.003 (0.004)	Loss 15.3353 (14.9044)	Acc@1 51.562 (57.641)	Acc@5 82.812 (86.965)
[epoch:15, iter:11249] Loss: 1.497, 10.969, 69.883, 457.194, 1.774
[epoch:15, iter:11269] Loss: 1.499, 10.965, 69.845, 456.906, 1.159
[epoch:15, iter:11289] Loss: 1.500, 10.970, 69.858, 457.050, 1.885
[epoch:15, iter:11309] Loss: 1.500, 10.966, 69.856, 457.037, 1.467
[epoch:15, iter:11329] Loss: 1.501, 10.972, 69.870, 457.119, 1.760
Epoch: [14][400/782]	Time 0.072 (0.081)	Data 0.002 (0.004)	Loss 15.9308 (14.9129)	Acc@1 42.188 (57.349)	Acc@5 75.000 (86.748)
[epoch:15, iter:11349] Loss: 1.501, 10.977, 69.858, 457.108, 2.270
[epoch:15, iter:11369] Loss: 1.501, 10.973, 69.851, 457.003, 2.088
[epoch:15, iter:11389] Loss: 1.500, 10.974, 69.811, 456.814, 1.388
[epoch:15, iter:11409] Loss: 1.500, 10.972, 69.785, 456.687, 0.867
[epoch:15, iter:11429] Loss: 1.500, 10.968, 69.821, 456.782, 1.651
Epoch: [14][500/782]	Time 0.083 (0.080)	Data 0.002 (0.003)	Loss 15.3276 (14.9012)	Acc@1 56.250 (57.600)	Acc@5 84.375 (86.823)
[epoch:15, iter:11449] Loss: 1.500, 10.974, 69.822, 456.852, 1.866
[epoch:15, iter:11469] Loss: 1.501, 10.976, 69.807, 456.834, 2.372
[epoch:15, iter:11489] Loss: 1.502, 10.980, 69.831, 456.839, 2.164
[epoch:15, iter:11509] Loss: 1.502, 10.975, 69.835, 456.804, 1.961
[epoch:15, iter:11529] Loss: 1.502, 10.973, 69.848, 456.813, 1.381
Epoch: [14][600/782]	Time 0.090 (0.079)	Data 0.002 (0.003)	Loss 15.1484 (14.9097)	Acc@1 48.438 (57.516)	Acc@5 85.938 (86.824)
[epoch:15, iter:11549] Loss: 1.502, 10.973, 69.867, 456.854, 1.737
[epoch:15, iter:11569] Loss: 1.501, 10.972, 69.865, 456.844, 1.312
[epoch:15, iter:11589] Loss: 1.501, 10.971, 69.849, 456.852, 1.582
[epoch:15, iter:11609] Loss: 1.501, 10.969, 69.829, 456.808, 1.372
[epoch:15, iter:11629] Loss: 1.501, 10.970, 69.826, 456.748, 1.761
Epoch: [14][700/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 15.3811 (14.8979)	Acc@1 51.562 (57.578)	Acc@5 87.500 (86.885)
[epoch:15, iter:11649] Loss: 1.502, 10.971, 69.811, 456.650, 1.948
[epoch:15, iter:11669] Loss: 1.501, 10.974, 69.802, 456.642, 1.600
[epoch:15, iter:11689] Loss: 1.501, 10.974, 69.796, 456.636, 1.824
[epoch:15, iter:11709] Loss: 1.500, 10.975, 69.826, 456.715, 1.693
[epoch:15, iter:11729] Loss: 1.499, 10.969, 69.838, 456.664, 1.656
 * Acc@1 57.592 Acc@5 86.828
epoch 14, total time 61.09
Test: [0/313]	Time 0.261 (0.261)	Loss 2.6538 (2.6538)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.3082 (2.2468)	Acc@1 46.875 (51.547)	Acc@5 75.000 (80.848)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4938 (2.2415)	Acc@1 68.750 (51.119)	Acc@5 87.500 (80.255)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.3439 (2.2371)	Acc@1 56.250 (51.350)	Acc@5 84.375 (80.554)
 * Acc@1 51.340 Acc@5 80.580
==> training...
Epoch: [15][0/782]	Time 0.580 (0.580)	Data 0.516 (0.516)	Loss 14.7537 (14.7537)	Acc@1 60.938 (60.938)	Acc@5 84.375 (84.375)
[epoch:16, iter:11731] Loss: 1.468, 10.520, 75.382, 458.782, 1.446
[epoch:16, iter:11751] Loss: 1.506, 11.044, 71.136, 457.712, 1.695
[epoch:16, iter:11771] Loss: 1.501, 11.025, 70.112, 456.026, 1.853
[epoch:16, iter:11791] Loss: 1.497, 10.997, 69.578, 455.203, 1.688
[epoch:16, iter:11811] Loss: 1.507, 10.973, 69.386, 454.446, 1.397
Epoch: [15][100/782]	Time 0.101 (0.086)	Data 0.003 (0.007)	Loss 14.0703 (14.6757)	Acc@1 60.938 (59.220)	Acc@5 89.062 (88.011)
[epoch:16, iter:11831] Loss: 1.501, 10.939, 69.398, 454.478, 1.172
[epoch:16, iter:11851] Loss: 1.504, 10.940, 69.481, 455.042, 1.862
[epoch:16, iter:11871] Loss: 1.499, 10.932, 69.388, 455.042, 1.269
[epoch:16, iter:11891] Loss: 1.499, 10.928, 69.345, 454.943, 1.700
[epoch:16, iter:11911] Loss: 1.495, 10.916, 69.335, 454.830, 1.654
Epoch: [15][200/782]	Time 0.080 (0.082)	Data 0.002 (0.005)	Loss 14.8971 (14.7037)	Acc@1 54.688 (59.118)	Acc@5 87.500 (87.632)
[epoch:16, iter:11931] Loss: 1.493, 10.911, 69.383, 454.997, 1.537
[epoch:16, iter:11951] Loss: 1.493, 10.907, 69.353, 454.994, 1.629
[epoch:16, iter:11971] Loss: 1.494, 10.913, 69.355, 455.045, 1.539
[epoch:16, iter:11991] Loss: 1.492, 10.907, 69.358, 455.097, 1.188
[epoch:16, iter:12011] Loss: 1.491, 10.903, 69.381, 454.932, 1.857
Epoch: [15][300/782]	Time 0.089 (0.081)	Data 0.003 (0.004)	Loss 14.3620 (14.7053)	Acc@1 50.000 (59.136)	Acc@5 84.375 (87.599)
[epoch:16, iter:12031] Loss: 1.491, 10.897, 69.470, 454.973, 1.743
[epoch:16, iter:12051] Loss: 1.492, 10.899, 69.482, 454.743, 1.796
[epoch:16, iter:12071] Loss: 1.492, 10.898, 69.526, 454.812, 1.732
[epoch:16, iter:12091] Loss: 1.492, 10.900, 69.571, 454.860, 1.298
[epoch:16, iter:12111] Loss: 1.492, 10.910, 69.531, 454.963, 1.621
Epoch: [15][400/782]	Time 0.076 (0.080)	Data 0.002 (0.004)	Loss 15.2262 (14.7409)	Acc@1 56.250 (58.642)	Acc@5 84.375 (87.325)
[epoch:16, iter:12131] Loss: 1.492, 10.915, 69.515, 455.004, 1.685
[epoch:16, iter:12151] Loss: 1.493, 10.925, 69.521, 455.043, 1.486
[epoch:16, iter:12171] Loss: 1.494, 10.926, 69.511, 454.955, 1.628
[epoch:16, iter:12191] Loss: 1.495, 10.934, 69.564, 455.163, 1.801
[epoch:16, iter:12211] Loss: 1.495, 10.936, 69.568, 455.115, 1.529
Epoch: [15][500/782]	Time 0.065 (0.080)	Data 0.002 (0.003)	Loss 15.5464 (14.7619)	Acc@1 59.375 (58.418)	Acc@5 82.812 (87.169)
[epoch:16, iter:12231] Loss: 1.495, 10.937, 69.579, 455.207, 1.671
[epoch:16, iter:12251] Loss: 1.494, 10.933, 69.540, 455.032, 1.565
[epoch:16, iter:12271] Loss: 1.494, 10.931, 69.545, 455.077, 1.997
[epoch:16, iter:12291] Loss: 1.494, 10.932, 69.575, 455.176, 1.873
[epoch:16, iter:12311] Loss: 1.494, 10.929, 69.582, 455.186, 1.606
Epoch: [15][600/782]	Time 0.064 (0.080)	Data 0.002 (0.003)	Loss 15.2179 (14.7833)	Acc@1 56.250 (58.228)	Acc@5 82.812 (87.053)
[epoch:16, iter:12331] Loss: 1.495, 10.929, 69.588, 455.283, 1.863
[epoch:16, iter:12351] Loss: 1.495, 10.926, 69.586, 455.272, 1.564
[epoch:16, iter:12371] Loss: 1.495, 10.922, 69.566, 455.088, 1.381
[epoch:16, iter:12391] Loss: 1.494, 10.918, 69.539, 455.008, 1.263
[epoch:16, iter:12411] Loss: 1.495, 10.922, 69.566, 455.187, 1.437
Epoch: [15][700/782]	Time 0.063 (0.079)	Data 0.002 (0.003)	Loss 15.8162 (14.7773)	Acc@1 51.562 (58.203)	Acc@5 81.250 (87.070)
[epoch:16, iter:12431] Loss: 1.496, 10.922, 69.557, 455.149, 2.322
[epoch:16, iter:12451] Loss: 1.497, 10.924, 69.565, 455.187, 1.328
[epoch:16, iter:12471] Loss: 1.497, 10.920, 69.528, 455.033, 1.373
[epoch:16, iter:12491] Loss: 1.496, 10.913, 69.487, 454.913, 1.955
[epoch:16, iter:12511] Loss: 1.495, 10.908, 69.473, 454.886, 1.419
 * Acc@1 58.248 Acc@5 87.142
epoch 15, total time 61.71
Test: [0/313]	Time 0.234 (0.234)	Loss 2.0355 (2.0355)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.7259 (2.2892)	Acc@1 43.750 (51.021)	Acc@5 75.000 (81.250)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.6618 (2.2578)	Acc@1 50.000 (51.150)	Acc@5 87.500 (81.328)
Test: [300/313]	Time 0.006 (0.007)	Loss 3.2501 (2.2623)	Acc@1 37.500 (51.277)	Acc@5 81.250 (81.364)
 * Acc@1 51.270 Acc@5 81.450
==> training...
Epoch: [16][0/782]	Time 0.491 (0.491)	Data 0.405 (0.405)	Loss 14.0713 (14.0713)	Acc@1 62.500 (62.500)	Acc@5 93.750 (93.750)
[epoch:17, iter:12513] Loss: 1.498, 10.816, 68.850, 453.915, 1.317
[epoch:17, iter:12533] Loss: 1.480, 10.824, 69.294, 453.015, 1.992
[epoch:17, iter:12553] Loss: 1.470, 10.801, 69.517, 452.778, 1.524
[epoch:17, iter:12573] Loss: 1.470, 10.873, 69.445, 452.283, 1.868
[epoch:17, iter:12593] Loss: 1.469, 10.829, 69.128, 452.095, 1.419
Epoch: [16][100/782]	Time 0.086 (0.085)	Data 0.003 (0.007)	Loss 14.6348 (14.5282)	Acc@1 59.375 (59.097)	Acc@5 90.625 (87.639)
[epoch:17, iter:12613] Loss: 1.472, 10.807, 69.209, 452.198, 1.703
[epoch:17, iter:12633] Loss: 1.470, 10.818, 69.200, 452.361, 1.688
[epoch:17, iter:12653] Loss: 1.472, 10.832, 69.265, 452.741, 1.199
[epoch:17, iter:12673] Loss: 1.472, 10.838, 69.326, 452.969, 1.110
[epoch:17, iter:12693] Loss: 1.474, 10.845, 69.427, 453.284, 1.248
Epoch: [16][200/782]	Time 0.065 (0.082)	Data 0.002 (0.004)	Loss 15.0905 (14.6171)	Acc@1 50.000 (59.010)	Acc@5 82.812 (87.679)
[epoch:17, iter:12713] Loss: 1.476, 10.853, 69.555, 453.938, 1.680
[epoch:17, iter:12733] Loss: 1.477, 10.864, 69.552, 453.936, 1.246
[epoch:17, iter:12753] Loss: 1.479, 10.866, 69.615, 454.043, 1.914
[epoch:17, iter:12773] Loss: 1.481, 10.874, 69.667, 454.194, 1.926
[epoch:17, iter:12793] Loss: 1.485, 10.892, 69.709, 454.284, 1.646
Epoch: [16][300/782]	Time 0.068 (0.079)	Data 0.002 (0.004)	Loss 14.3384 (14.6823)	Acc@1 59.375 (58.690)	Acc@5 89.062 (87.495)
[epoch:17, iter:12813] Loss: 1.487, 10.885, 69.769, 454.484, 1.326
[epoch:17, iter:12833] Loss: 1.487, 10.885, 69.684, 454.355, 1.726
[epoch:17, iter:12853] Loss: 1.488, 10.896, 69.660, 454.439, 1.635
[epoch:17, iter:12873] Loss: 1.489, 10.895, 69.656, 454.312, 1.942
[epoch:17, iter:12893] Loss: 1.490, 10.895, 69.670, 454.381, 1.750
Epoch: [16][400/782]	Time 0.074 (0.080)	Data 0.002 (0.003)	Loss 14.1221 (14.7076)	Acc@1 60.938 (58.487)	Acc@5 92.188 (87.243)
[epoch:17, iter:12913] Loss: 1.491, 10.895, 69.656, 454.361, 1.368
[epoch:17, iter:12933] Loss: 1.491, 10.893, 69.658, 454.279, 1.500
[epoch:17, iter:12953] Loss: 1.491, 10.893, 69.679, 454.381, 1.090
[epoch:17, iter:12973] Loss: 1.491, 10.893, 69.673, 454.385, 1.578
[epoch:17, iter:12993] Loss: 1.492, 10.892, 69.655, 454.329, 1.392
Epoch: [16][500/782]	Time 0.066 (0.081)	Data 0.002 (0.003)	Loss 14.1432 (14.7031)	Acc@1 64.062 (58.667)	Acc@5 93.750 (87.304)
[epoch:17, iter:13013] Loss: 1.492, 10.887, 69.642, 454.321, 1.168
[epoch:17, iter:13033] Loss: 1.491, 10.884, 69.605, 454.328, 1.263
[epoch:17, iter:13053] Loss: 1.490, 10.880, 69.564, 454.213, 1.625
[epoch:17, iter:13073] Loss: 1.491, 10.887, 69.581, 454.202, 1.795
[epoch:17, iter:13093] Loss: 1.491, 10.888, 69.585, 454.296, 1.644
Epoch: [16][600/782]	Time 0.075 (0.081)	Data 0.003 (0.003)	Loss 15.4724 (14.7065)	Acc@1 57.812 (58.689)	Acc@5 85.938 (87.214)
[epoch:17, iter:13113] Loss: 1.491, 10.894, 69.580, 454.298, 1.680
[epoch:17, iter:13133] Loss: 1.491, 10.896, 69.582, 454.343, 1.166
[epoch:17, iter:13153] Loss: 1.491, 10.895, 69.620, 454.373, 1.516
[epoch:17, iter:13173] Loss: 1.491, 10.898, 69.624, 454.313, 1.536
[epoch:17, iter:13193] Loss: 1.492, 10.897, 69.625, 454.352, 2.209
Epoch: [16][700/782]	Time 0.073 (0.080)	Data 0.002 (0.003)	Loss 15.1790 (14.7284)	Acc@1 50.000 (58.557)	Acc@5 92.188 (87.170)
[epoch:17, iter:13213] Loss: 1.492, 10.895, 69.606, 454.287, 1.656
[epoch:17, iter:13233] Loss: 1.491, 10.892, 69.588, 454.249, 1.513
[epoch:17, iter:13253] Loss: 1.491, 10.890, 69.584, 454.096, 1.712
[epoch:17, iter:13273] Loss: 1.491, 10.892, 69.593, 454.058, 1.494
[epoch:17, iter:13293] Loss: 1.492, 10.894, 69.600, 454.034, 1.880
 * Acc@1 58.514 Acc@5 87.172
epoch 16, total time 62.53
Test: [0/313]	Time 0.249 (0.249)	Loss 2.9929 (2.9929)	Acc@1 50.000 (50.000)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.8073 (2.5915)	Acc@1 25.000 (44.214)	Acc@5 81.250 (78.527)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.7677 (2.6364)	Acc@1 37.500 (44.419)	Acc@5 78.125 (77.721)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4946 (2.6233)	Acc@1 46.875 (45.120)	Acc@5 71.875 (77.533)
 * Acc@1 45.120 Acc@5 77.510
==> training...
Epoch: [17][0/782]	Time 0.532 (0.532)	Data 0.453 (0.453)	Loss 15.1944 (15.1944)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
[epoch:18, iter:13295] Loss: 1.385, 10.571, 71.121, 456.761, 1.949
[epoch:18, iter:13315] Loss: 1.497, 10.969, 69.200, 452.791, 1.189
[epoch:18, iter:13335] Loss: 1.493, 10.968, 69.442, 452.179, 1.421
[epoch:18, iter:13355] Loss: 1.486, 10.985, 69.604, 453.122, 1.011
[epoch:18, iter:13375] Loss: 1.486, 10.979, 69.664, 453.288, 1.747
Epoch: [17][100/782]	Time 0.088 (0.081)	Data 0.003 (0.007)	Loss 14.6440 (14.5921)	Acc@1 57.812 (59.561)	Acc@5 84.375 (87.918)
[epoch:18, iter:13395] Loss: 1.480, 10.965, 69.699, 453.520, 1.546
[epoch:18, iter:13415] Loss: 1.478, 10.934, 69.673, 453.546, 1.232
[epoch:18, iter:13435] Loss: 1.478, 10.919, 69.418, 452.588, 1.251
[epoch:18, iter:13455] Loss: 1.478, 10.906, 69.301, 452.539, 1.604
[epoch:18, iter:13475] Loss: 1.478, 10.911, 69.301, 452.076, 1.272
Epoch: [17][200/782]	Time 0.074 (0.079)	Data 0.002 (0.004)	Loss 14.5411 (14.5269)	Acc@1 60.938 (59.974)	Acc@5 84.375 (87.928)
[epoch:18, iter:13495] Loss: 1.478, 10.904, 69.295, 452.229, 1.463
[epoch:18, iter:13515] Loss: 1.477, 10.900, 69.295, 452.420, 1.435
[epoch:18, iter:13535] Loss: 1.478, 10.889, 69.287, 452.505, 1.617
[epoch:18, iter:13555] Loss: 1.478, 10.895, 69.343, 452.605, 1.145
[epoch:18, iter:13575] Loss: 1.477, 10.891, 69.345, 452.650, 1.400
Epoch: [17][300/782]	Time 0.057 (0.076)	Data 0.001 (0.004)	Loss 15.4301 (14.5909)	Acc@1 57.812 (59.318)	Acc@5 89.062 (87.702)
[epoch:18, iter:13595] Loss: 1.476, 10.884, 69.301, 452.543, 1.553
[epoch:18, iter:13615] Loss: 1.476, 10.878, 69.203, 452.249, 1.434
[epoch:18, iter:13635] Loss: 1.474, 10.864, 69.135, 452.183, 1.588
[epoch:18, iter:13655] Loss: 1.473, 10.855, 69.100, 452.134, 1.412
[epoch:18, iter:13675] Loss: 1.473, 10.859, 69.104, 452.229, 1.531
Epoch: [17][400/782]	Time 0.071 (0.075)	Data 0.002 (0.003)	Loss 14.3147 (14.5706)	Acc@1 51.562 (59.204)	Acc@5 87.500 (87.449)
[epoch:18, iter:13695] Loss: 1.472, 10.855, 69.090, 452.141, 1.739
[epoch:18, iter:13715] Loss: 1.472, 10.853, 69.092, 452.138, 1.537
[epoch:18, iter:13735] Loss: 1.474, 10.854, 69.096, 452.249, 1.831
[epoch:18, iter:13755] Loss: 1.474, 10.852, 69.103, 452.133, 1.406
[epoch:18, iter:13775] Loss: 1.473, 10.852, 69.080, 451.983, 1.060
Epoch: [17][500/782]	Time 0.085 (0.075)	Data 0.003 (0.003)	Loss 14.3695 (14.5634)	Acc@1 51.562 (59.007)	Acc@5 90.625 (87.531)
[epoch:18, iter:13795] Loss: 1.473, 10.851, 69.071, 451.890, 1.367
[epoch:18, iter:13815] Loss: 1.474, 10.849, 69.056, 451.810, 1.289
[epoch:18, iter:13835] Loss: 1.474, 10.851, 69.066, 451.774, 1.860
[epoch:18, iter:13855] Loss: 1.475, 10.851, 69.067, 451.790, 1.691
[epoch:18, iter:13875] Loss: 1.477, 10.855, 69.094, 451.921, 1.414
Epoch: [17][600/782]	Time 0.083 (0.075)	Data 0.003 (0.003)	Loss 14.0288 (14.5862)	Acc@1 67.188 (58.920)	Acc@5 87.500 (87.487)
[epoch:18, iter:13895] Loss: 1.477, 10.856, 69.098, 451.969, 1.387
[epoch:18, iter:13915] Loss: 1.478, 10.859, 69.130, 452.070, 1.432
[epoch:18, iter:13935] Loss: 1.478, 10.859, 69.138, 452.098, 1.977
[epoch:18, iter:13955] Loss: 1.479, 10.858, 69.176, 452.093, 1.765
[epoch:18, iter:13975] Loss: 1.479, 10.860, 69.181, 452.145, 1.744
Epoch: [17][700/782]	Time 0.071 (0.076)	Data 0.003 (0.003)	Loss 14.0444 (14.6143)	Acc@1 57.812 (58.809)	Acc@5 90.625 (87.433)
[epoch:18, iter:13995] Loss: 1.479, 10.863, 69.193, 452.216, 1.436
[epoch:18, iter:14015] Loss: 1.480, 10.861, 69.183, 452.219, 1.183
[epoch:18, iter:14035] Loss: 1.480, 10.855, 69.200, 452.222, 1.779
[epoch:18, iter:14055] Loss: 1.480, 10.853, 69.224, 452.259, 1.762
[epoch:18, iter:14075] Loss: 1.479, 10.848, 69.195, 452.162, 1.793
 * Acc@1 58.856 Acc@5 87.462
epoch 17, total time 59.99
Test: [0/313]	Time 0.243 (0.243)	Loss 1.8412 (1.8412)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.3618 (2.1103)	Acc@1 37.500 (52.537)	Acc@5 90.625 (81.807)
Test: [200/313]	Time 0.008 (0.007)	Loss 1.5181 (2.0964)	Acc@1 71.875 (52.503)	Acc@5 90.625 (81.934)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5084 (2.1063)	Acc@1 43.750 (52.409)	Acc@5 81.250 (81.956)
 * Acc@1 52.510 Acc@5 82.000
saving the best model!
==> training...
Epoch: [18][0/782]	Time 0.511 (0.511)	Data 0.431 (0.431)	Loss 14.7784 (14.7784)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
[epoch:19, iter:14077] Loss: 1.479, 10.912, 71.287, 460.295, 1.245
[epoch:19, iter:14097] Loss: 1.473, 10.999, 69.308, 454.827, 1.431
[epoch:19, iter:14117] Loss: 1.471, 10.920, 68.964, 453.353, 1.496
[epoch:19, iter:14137] Loss: 1.473, 10.854, 69.197, 452.914, 1.484
[epoch:19, iter:14157] Loss: 1.476, 10.849, 69.278, 453.033, 1.234
Epoch: [18][100/782]	Time 0.061 (0.083)	Data 0.002 (0.007)	Loss 14.3273 (14.5409)	Acc@1 62.500 (59.035)	Acc@5 84.375 (87.624)
[epoch:19, iter:14177] Loss: 1.471, 10.835, 69.078, 452.326, 1.487
[epoch:19, iter:14197] Loss: 1.472, 10.836, 69.076, 452.169, 1.541
[epoch:19, iter:14217] Loss: 1.473, 10.842, 68.992, 451.763, 1.593
[epoch:19, iter:14237] Loss: 1.472, 10.828, 68.839, 451.280, 1.563
[epoch:19, iter:14257] Loss: 1.471, 10.821, 68.842, 451.311, 2.098
Epoch: [18][200/782]	Time 0.068 (0.077)	Data 0.002 (0.004)	Loss 16.2882 (14.5286)	Acc@1 43.750 (59.196)	Acc@5 81.250 (87.337)
[epoch:19, iter:14277] Loss: 1.469, 10.823, 68.898, 451.722, 2.205
[epoch:19, iter:14297] Loss: 1.471, 10.833, 68.823, 451.548, 1.807
[epoch:19, iter:14317] Loss: 1.472, 10.839, 68.872, 451.511, 1.265
[epoch:19, iter:14337] Loss: 1.474, 10.841, 68.893, 451.436, 1.370
[epoch:19, iter:14357] Loss: 1.477, 10.849, 68.962, 451.692, 1.775
Epoch: [18][300/782]	Time 0.065 (0.077)	Data 0.002 (0.004)	Loss 14.7689 (14.5472)	Acc@1 53.125 (59.074)	Acc@5 85.938 (87.370)
[epoch:19, iter:14377] Loss: 1.477, 10.854, 69.052, 451.944, 1.678
[epoch:19, iter:14397] Loss: 1.478, 10.859, 69.034, 451.752, 1.347
[epoch:19, iter:14417] Loss: 1.478, 10.858, 69.016, 451.655, 1.672
[epoch:19, iter:14437] Loss: 1.479, 10.850, 69.031, 451.659, 1.790
[epoch:19, iter:14457] Loss: 1.479, 10.853, 69.001, 451.669, 1.244
Epoch: [18][400/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 15.7351 (14.5447)	Acc@1 56.250 (58.900)	Acc@5 90.625 (87.527)
[epoch:19, iter:14477] Loss: 1.480, 10.854, 69.000, 451.613, 1.668
[epoch:19, iter:14497] Loss: 1.480, 10.845, 69.012, 451.516, 1.654
[epoch:19, iter:14517] Loss: 1.481, 10.847, 69.009, 451.549, 1.228
[epoch:19, iter:14537] Loss: 1.480, 10.841, 68.986, 451.392, 1.493
[epoch:19, iter:14557] Loss: 1.480, 10.843, 69.028, 451.435, 1.572
Epoch: [18][500/782]	Time 0.085 (0.076)	Data 0.002 (0.003)	Loss 14.1790 (14.5525)	Acc@1 57.812 (58.761)	Acc@5 87.500 (87.488)
[epoch:19, iter:14577] Loss: 1.479, 10.842, 69.008, 451.451, 1.565
[epoch:19, iter:14597] Loss: 1.479, 10.846, 69.013, 451.462, 1.643
[epoch:19, iter:14617] Loss: 1.479, 10.846, 69.012, 451.411, 1.520
[epoch:19, iter:14637] Loss: 1.479, 10.845, 69.016, 451.458, 2.135
[epoch:19, iter:14657] Loss: 1.480, 10.846, 69.012, 451.500, 1.530
Epoch: [18][600/782]	Time 0.088 (0.076)	Data 0.003 (0.003)	Loss 16.0685 (14.5730)	Acc@1 57.812 (58.743)	Acc@5 84.375 (87.438)
[epoch:19, iter:14677] Loss: 1.480, 10.845, 69.035, 451.687, 1.829
[epoch:19, iter:14697] Loss: 1.480, 10.845, 69.047, 451.709, 1.612
[epoch:19, iter:14717] Loss: 1.481, 10.843, 69.043, 451.643, 1.995
[epoch:19, iter:14737] Loss: 1.481, 10.843, 69.048, 451.673, 1.440
[epoch:19, iter:14757] Loss: 1.480, 10.841, 69.031, 451.648, 1.805
Epoch: [18][700/782]	Time 0.065 (0.076)	Data 0.002 (0.003)	Loss 14.9521 (14.5625)	Acc@1 54.688 (58.929)	Acc@5 79.688 (87.520)
[epoch:19, iter:14777] Loss: 1.481, 10.841, 69.031, 451.587, 1.944
[epoch:19, iter:14797] Loss: 1.480, 10.840, 69.044, 451.592, 1.631
[epoch:19, iter:14817] Loss: 1.480, 10.839, 69.058, 451.611, 1.486
[epoch:19, iter:14837] Loss: 1.481, 10.839, 69.071, 451.652, 1.659
[epoch:19, iter:14857] Loss: 1.481, 10.838, 69.047, 451.612, 1.570
 * Acc@1 58.990 Acc@5 87.552
epoch 18, total time 59.55
Test: [0/313]	Time 0.270 (0.270)	Loss 1.9770 (1.9770)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.3525 (2.0787)	Acc@1 50.000 (53.125)	Acc@5 81.250 (83.323)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.3398 (2.0121)	Acc@1 59.375 (53.794)	Acc@5 93.750 (84.002)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.2998 (2.0305)	Acc@1 53.125 (53.665)	Acc@5 78.125 (83.648)
 * Acc@1 53.710 Acc@5 83.670
saving the best model!
==> training...
Epoch: [19][0/782]	Time 0.502 (0.502)	Data 0.433 (0.433)	Loss 14.4565 (14.4565)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
[epoch:20, iter:14859] Loss: 1.477, 10.891, 69.258, 453.241, 1.428
[epoch:20, iter:14879] Loss: 1.502, 11.006, 70.378, 453.877, 1.320
[epoch:20, iter:14899] Loss: 1.495, 10.938, 69.934, 452.536, 1.337
[epoch:20, iter:14919] Loss: 1.492, 10.940, 69.720, 451.418, 1.997
[epoch:20, iter:14939] Loss: 1.489, 10.934, 69.462, 450.646, 1.573
Epoch: [19][100/782]	Time 0.066 (0.083)	Data 0.002 (0.007)	Loss 15.4881 (14.4036)	Acc@1 57.812 (61.092)	Acc@5 84.375 (88.289)
[epoch:20, iter:14959] Loss: 1.481, 10.896, 69.191, 449.834, 1.747
[epoch:20, iter:14979] Loss: 1.479, 10.871, 69.093, 449.611, 1.427
[epoch:20, iter:14999] Loss: 1.477, 10.853, 68.894, 449.493, 1.520
[epoch:20, iter:15019] Loss: 1.477, 10.849, 68.902, 449.872, 1.259
[epoch:20, iter:15039] Loss: 1.477, 10.846, 68.923, 450.150, 2.320
Epoch: [19][200/782]	Time 0.081 (0.083)	Data 0.003 (0.005)	Loss 13.1933 (14.4150)	Acc@1 67.188 (60.215)	Acc@5 95.312 (87.966)
[epoch:20, iter:15059] Loss: 1.473, 10.838, 68.891, 450.111, 1.180
[epoch:20, iter:15079] Loss: 1.473, 10.826, 69.005, 450.377, 1.224
[epoch:20, iter:15099] Loss: 1.474, 10.818, 68.934, 450.151, 1.220
[epoch:20, iter:15119] Loss: 1.474, 10.814, 68.939, 450.008, 1.841
[epoch:20, iter:15139] Loss: 1.476, 10.823, 68.959, 450.107, 1.780
Epoch: [19][300/782]	Time 0.083 (0.081)	Data 0.003 (0.004)	Loss 14.1110 (14.4334)	Acc@1 68.750 (59.837)	Acc@5 89.062 (87.728)
[epoch:20, iter:15159] Loss: 1.475, 10.826, 68.872, 449.954, 1.039
[epoch:20, iter:15179] Loss: 1.474, 10.815, 68.820, 449.849, 1.372
[epoch:20, iter:15199] Loss: 1.472, 10.810, 68.770, 449.647, 1.730
[epoch:20, iter:15219] Loss: 1.473, 10.806, 68.770, 449.622, 1.322
[epoch:20, iter:15239] Loss: 1.475, 10.818, 68.789, 449.757, 1.218
Epoch: [19][400/782]	Time 0.074 (0.081)	Data 0.002 (0.003)	Loss 13.6490 (14.4364)	Acc@1 64.062 (59.874)	Acc@5 89.062 (87.668)
[epoch:20, iter:15259] Loss: 1.476, 10.823, 68.793, 449.693, 1.403
[epoch:20, iter:15279] Loss: 1.475, 10.815, 68.781, 449.623, 1.667
[epoch:20, iter:15299] Loss: 1.474, 10.812, 68.780, 449.681, 1.079
[epoch:20, iter:15319] Loss: 1.474, 10.816, 68.781, 449.705, 1.830
[epoch:20, iter:15339] Loss: 1.475, 10.819, 68.785, 449.788, 1.772
Epoch: [19][500/782]	Time 0.085 (0.081)	Data 0.003 (0.003)	Loss 14.2206 (14.4500)	Acc@1 67.188 (59.696)	Acc@5 89.062 (87.640)
[epoch:20, iter:15359] Loss: 1.475, 10.820, 68.827, 449.834, 1.325
[epoch:20, iter:15379] Loss: 1.475, 10.818, 68.819, 449.815, 1.389
[epoch:20, iter:15399] Loss: 1.475, 10.815, 68.762, 449.706, 1.593
[epoch:20, iter:15419] Loss: 1.475, 10.814, 68.773, 449.847, 1.288
[epoch:20, iter:15439] Loss: 1.476, 10.815, 68.758, 449.810, 1.443
Epoch: [19][600/782]	Time 0.067 (0.080)	Data 0.002 (0.003)	Loss 16.3612 (14.4618)	Acc@1 50.000 (59.458)	Acc@5 78.125 (87.581)
[epoch:20, iter:15459] Loss: 1.475, 10.812, 68.763, 449.882, 2.329
[epoch:20, iter:15479] Loss: 1.475, 10.813, 68.766, 449.951, 1.452
[epoch:20, iter:15499] Loss: 1.475, 10.815, 68.783, 450.015, 1.974
[epoch:20, iter:15519] Loss: 1.476, 10.816, 68.792, 450.173, 1.608
[epoch:20, iter:15539] Loss: 1.476, 10.818, 68.771, 450.169, 1.431
Epoch: [19][700/782]	Time 0.085 (0.079)	Data 0.002 (0.003)	Loss 13.5038 (14.4849)	Acc@1 65.625 (59.333)	Acc@5 92.188 (87.529)
[epoch:20, iter:15559] Loss: 1.476, 10.816, 68.767, 450.141, 1.062
[epoch:20, iter:15579] Loss: 1.476, 10.815, 68.764, 450.146, 2.507
[epoch:20, iter:15599] Loss: 1.475, 10.817, 68.782, 450.262, 1.288
[epoch:20, iter:15619] Loss: 1.475, 10.813, 68.773, 450.148, 1.137
[epoch:20, iter:15639] Loss: 1.475, 10.809, 68.775, 450.151, 1.901
 * Acc@1 59.352 Acc@5 87.526
epoch 19, total time 62.17
Test: [0/313]	Time 0.240 (0.240)	Loss 2.0490 (2.0490)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.5816 (1.9555)	Acc@1 50.000 (54.146)	Acc@5 81.250 (84.499)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4675 (1.9242)	Acc@1 62.500 (54.291)	Acc@5 87.500 (84.904)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.8621 (1.9358)	Acc@1 53.125 (54.381)	Acc@5 84.375 (84.738)
 * Acc@1 54.400 Acc@5 84.710
saving the best model!
==> training...
Epoch: [20][0/782]	Time 0.579 (0.579)	Data 0.513 (0.513)	Loss 14.1073 (14.1073)	Acc@1 62.500 (62.500)	Acc@5 93.750 (93.750)
[epoch:21, iter:15641] Loss: 1.523, 10.702, 70.342, 449.065, 1.248
[epoch:21, iter:15661] Loss: 1.467, 10.733, 68.426, 447.735, 2.054
[epoch:21, iter:15681] Loss: 1.466, 10.771, 68.758, 449.475, 1.282
[epoch:21, iter:15701] Loss: 1.454, 10.786, 68.755, 449.288, 1.617
[epoch:21, iter:15721] Loss: 1.455, 10.762, 68.698, 448.792, 1.130
Epoch: [20][100/782]	Time 0.093 (0.081)	Data 0.003 (0.007)	Loss 13.7420 (14.3038)	Acc@1 65.625 (60.025)	Acc@5 95.312 (88.459)
[epoch:21, iter:15741] Loss: 1.457, 10.770, 68.627, 448.588, 1.056
[epoch:21, iter:15761] Loss: 1.460, 10.781, 68.490, 448.340, 1.580
[epoch:21, iter:15781] Loss: 1.461, 10.784, 68.516, 448.715, 1.306
[epoch:21, iter:15801] Loss: 1.464, 10.783, 68.512, 448.986, 0.809
[epoch:21, iter:15821] Loss: 1.465, 10.775, 68.519, 449.013, 1.600
Epoch: [20][200/782]	Time 0.088 (0.080)	Data 0.003 (0.005)	Loss 13.5880 (14.3873)	Acc@1 60.938 (59.484)	Acc@5 92.188 (88.161)
[epoch:21, iter:15841] Loss: 1.466, 10.774, 68.467, 449.217, 1.380
[epoch:21, iter:15861] Loss: 1.467, 10.768, 68.497, 449.263, 1.662
[epoch:21, iter:15881] Loss: 1.469, 10.772, 68.544, 449.268, 1.559
[epoch:21, iter:15901] Loss: 1.471, 10.782, 68.562, 449.311, 1.451
[epoch:21, iter:15921] Loss: 1.472, 10.782, 68.554, 449.338, 1.075
Epoch: [20][300/782]	Time 0.066 (0.080)	Data 0.002 (0.004)	Loss 13.8205 (14.4151)	Acc@1 62.500 (59.609)	Acc@5 87.500 (87.900)
[epoch:21, iter:15941] Loss: 1.472, 10.780, 68.603, 449.416, 1.330
[epoch:21, iter:15961] Loss: 1.472, 10.781, 68.649, 449.551, 1.452
[epoch:21, iter:15981] Loss: 1.472, 10.785, 68.643, 449.604, 1.850
[epoch:21, iter:16001] Loss: 1.471, 10.781, 68.668, 449.709, 1.827
[epoch:21, iter:16021] Loss: 1.472, 10.780, 68.702, 449.738, 1.578
Epoch: [20][400/782]	Time 0.077 (0.079)	Data 0.003 (0.004)	Loss 14.4027 (14.4442)	Acc@1 64.062 (59.543)	Acc@5 85.938 (87.617)
[epoch:21, iter:16041] Loss: 1.472, 10.784, 68.690, 449.781, 1.556
[epoch:21, iter:16061] Loss: 1.471, 10.776, 68.677, 449.558, 1.495
[epoch:21, iter:16081] Loss: 1.469, 10.770, 68.646, 449.447, 1.062
[epoch:21, iter:16101] Loss: 1.469, 10.764, 68.637, 449.449, 1.431
[epoch:21, iter:16121] Loss: 1.470, 10.765, 68.637, 449.443, 1.670
Epoch: [20][500/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 14.5235 (14.4322)	Acc@1 60.938 (59.625)	Acc@5 87.500 (87.650)
[epoch:21, iter:16141] Loss: 1.469, 10.759, 68.623, 449.422, 1.358
[epoch:21, iter:16161] Loss: 1.469, 10.762, 68.647, 449.448, 1.449
[epoch:21, iter:16181] Loss: 1.469, 10.762, 68.661, 449.433, 1.517
[epoch:21, iter:16201] Loss: 1.469, 10.761, 68.640, 449.439, 1.558
[epoch:21, iter:16221] Loss: 1.468, 10.764, 68.590, 449.343, 1.308
Epoch: [20][600/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 14.8177 (14.4371)	Acc@1 53.125 (59.614)	Acc@5 76.562 (87.612)
[epoch:21, iter:16241] Loss: 1.469, 10.770, 68.570, 449.374, 1.955
[epoch:21, iter:16261] Loss: 1.468, 10.773, 68.580, 449.420, 1.324
[epoch:21, iter:16281] Loss: 1.468, 10.771, 68.546, 449.271, 1.230
[epoch:21, iter:16301] Loss: 1.468, 10.773, 68.545, 449.261, 1.709
[epoch:21, iter:16321] Loss: 1.467, 10.769, 68.517, 449.188, 1.261
Epoch: [20][700/782]	Time 0.085 (0.079)	Data 0.003 (0.003)	Loss 13.6776 (14.4205)	Acc@1 68.750 (59.589)	Acc@5 89.062 (87.634)
[epoch:21, iter:16341] Loss: 1.466, 10.771, 68.481, 449.130, 1.241
[epoch:21, iter:16361] Loss: 1.466, 10.764, 68.449, 448.964, 1.166
[epoch:21, iter:16381] Loss: 1.466, 10.767, 68.453, 449.020, 1.418
[epoch:21, iter:16401] Loss: 1.466, 10.765, 68.432, 448.994, 1.494
[epoch:21, iter:16421] Loss: 1.466, 10.764, 68.443, 448.990, 1.722
 * Acc@1 59.576 Acc@5 87.668
epoch 20, total time 61.57
Test: [0/313]	Time 0.285 (0.285)	Loss 2.3658 (2.3658)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.1399 (2.1923)	Acc@1 37.500 (51.207)	Acc@5 90.625 (81.126)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.7646 (2.2400)	Acc@1 50.000 (50.964)	Acc@5 87.500 (80.426)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.0732 (2.2518)	Acc@1 56.250 (50.882)	Acc@5 87.500 (80.388)
 * Acc@1 50.980 Acc@5 80.370
==> training...
Epoch: [21][0/782]	Time 0.577 (0.577)	Data 0.481 (0.481)	Loss 14.1722 (14.1722)	Acc@1 57.812 (57.812)	Acc@5 84.375 (84.375)
[epoch:22, iter:16423] Loss: 1.539, 10.761, 69.066, 445.470, 1.666
[epoch:22, iter:16443] Loss: 1.487, 10.898, 68.513, 450.670, 1.868
[epoch:22, iter:16463] Loss: 1.479, 10.785, 68.277, 449.144, 1.220
[epoch:22, iter:16483] Loss: 1.470, 10.806, 68.077, 448.890, 1.595
[epoch:22, iter:16503] Loss: 1.471, 10.759, 68.116, 447.979, 1.373
Epoch: [21][100/782]	Time 0.072 (0.079)	Data 0.002 (0.007)	Loss 15.1291 (14.2458)	Acc@1 53.125 (60.009)	Acc@5 81.250 (88.243)
[epoch:22, iter:16523] Loss: 1.462, 10.740, 67.938, 447.297, 1.781
[epoch:22, iter:16543] Loss: 1.464, 10.737, 68.206, 447.589, 1.603
[epoch:22, iter:16563] Loss: 1.466, 10.743, 68.146, 447.647, 1.377
[epoch:22, iter:16583] Loss: 1.465, 10.739, 68.206, 447.636, 1.698
[epoch:22, iter:16603] Loss: 1.465, 10.739, 68.403, 448.223, 1.328
Epoch: [21][200/782]	Time 0.077 (0.080)	Data 0.002 (0.005)	Loss 14.3123 (14.3360)	Acc@1 68.750 (59.950)	Acc@5 93.750 (88.207)
[epoch:22, iter:16623] Loss: 1.468, 10.749, 68.530, 448.520, 1.089
[epoch:22, iter:16643] Loss: 1.468, 10.754, 68.498, 448.413, 1.311
[epoch:22, iter:16663] Loss: 1.470, 10.757, 68.531, 448.710, 1.257
[epoch:22, iter:16683] Loss: 1.469, 10.758, 68.496, 448.582, 1.390
[epoch:22, iter:16703] Loss: 1.470, 10.763, 68.510, 448.622, 1.338
Epoch: [21][300/782]	Time 0.071 (0.080)	Data 0.002 (0.004)	Loss 13.7342 (14.3564)	Acc@1 67.188 (60.091)	Acc@5 90.625 (88.175)
[epoch:22, iter:16723] Loss: 1.470, 10.773, 68.521, 448.607, 1.162
[epoch:22, iter:16743] Loss: 1.470, 10.769, 68.563, 448.787, 1.423
[epoch:22, iter:16763] Loss: 1.471, 10.767, 68.548, 448.945, 1.773
[epoch:22, iter:16783] Loss: 1.471, 10.776, 68.591, 449.057, 1.783
[epoch:22, iter:16803] Loss: 1.471, 10.778, 68.621, 449.029, 1.232
Epoch: [21][400/782]	Time 0.071 (0.079)	Data 0.002 (0.004)	Loss 14.2359 (14.4159)	Acc@1 51.562 (59.578)	Acc@5 82.812 (87.991)
[epoch:22, iter:16823] Loss: 1.473, 10.781, 68.660, 449.199, 1.662
[epoch:22, iter:16843] Loss: 1.472, 10.780, 68.657, 449.228, 1.740
[epoch:22, iter:16863] Loss: 1.473, 10.778, 68.681, 449.253, 1.262
[epoch:22, iter:16883] Loss: 1.471, 10.775, 68.654, 449.160, 1.601
[epoch:22, iter:16903] Loss: 1.471, 10.773, 68.654, 449.194, 1.483
Epoch: [21][500/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 14.9916 (14.4238)	Acc@1 56.250 (59.537)	Acc@5 82.812 (87.965)
[epoch:22, iter:16923] Loss: 1.471, 10.774, 68.685, 449.260, 1.445
[epoch:22, iter:16943] Loss: 1.472, 10.771, 68.720, 449.307, 1.902
[epoch:22, iter:16963] Loss: 1.472, 10.769, 68.740, 449.360, 1.647
[epoch:22, iter:16983] Loss: 1.473, 10.766, 68.761, 449.285, 1.186
[epoch:22, iter:17003] Loss: 1.473, 10.767, 68.756, 449.264, 1.253
Epoch: [21][600/782]	Time 0.083 (0.079)	Data 0.003 (0.003)	Loss 15.4405 (14.4256)	Acc@1 54.688 (59.713)	Acc@5 81.250 (87.830)
[epoch:22, iter:17023] Loss: 1.472, 10.765, 68.743, 449.262, 1.824
[epoch:22, iter:17043] Loss: 1.471, 10.762, 68.740, 449.270, 1.568
[epoch:22, iter:17063] Loss: 1.471, 10.761, 68.719, 449.251, 1.203
[epoch:22, iter:17083] Loss: 1.471, 10.761, 68.747, 449.329, 1.440
[epoch:22, iter:17103] Loss: 1.470, 10.758, 68.746, 449.293, 1.634
Epoch: [21][700/782]	Time 0.093 (0.078)	Data 0.004 (0.003)	Loss 14.3056 (14.4306)	Acc@1 57.812 (59.676)	Acc@5 96.875 (87.781)
[epoch:22, iter:17123] Loss: 1.471, 10.758, 68.743, 449.316, 1.117
[epoch:22, iter:17143] Loss: 1.471, 10.758, 68.754, 449.372, 1.603
[epoch:22, iter:17163] Loss: 1.471, 10.758, 68.730, 449.310, 1.762
[epoch:22, iter:17183] Loss: 1.472, 10.758, 68.733, 449.294, 1.259
[epoch:22, iter:17203] Loss: 1.471, 10.762, 68.754, 449.296, 1.524
 * Acc@1 59.672 Acc@5 87.750
epoch 21, total time 61.73
Test: [0/313]	Time 0.250 (0.250)	Loss 2.0637 (2.0637)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.005 (0.010)	Loss 2.3197 (2.0952)	Acc@1 53.125 (50.928)	Acc@5 78.125 (82.673)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3871 (2.0866)	Acc@1 68.750 (51.710)	Acc@5 87.500 (82.587)
Test: [300/313]	Time 0.007 (0.008)	Loss 3.0418 (2.0853)	Acc@1 31.250 (51.827)	Acc@5 81.250 (82.558)
 * Acc@1 51.910 Acc@5 82.580
==> training...
Epoch: [22][0/782]	Time 0.530 (0.530)	Data 0.435 (0.435)	Loss 14.0727 (14.0727)	Acc@1 59.375 (59.375)	Acc@5 93.750 (93.750)
[epoch:23, iter:17205] Loss: 1.550, 10.634, 68.902, 443.406, 1.366
[epoch:23, iter:17225] Loss: 1.508, 11.008, 69.770, 453.437, 1.175
[epoch:23, iter:17245] Loss: 1.501, 10.889, 69.173, 451.588, 1.680
[epoch:23, iter:17265] Loss: 1.492, 10.858, 69.129, 451.073, 0.987
[epoch:23, iter:17285] Loss: 1.484, 10.841, 69.057, 451.238, 1.597
Epoch: [22][100/782]	Time 0.070 (0.088)	Data 0.002 (0.007)	Loss 15.0118 (14.4935)	Acc@1 50.000 (60.412)	Acc@5 90.625 (88.103)
[epoch:23, iter:17305] Loss: 1.483, 10.862, 69.086, 450.738, 1.704
[epoch:23, iter:17325] Loss: 1.479, 10.847, 69.155, 450.493, 1.368
[epoch:23, iter:17345] Loss: 1.474, 10.838, 69.078, 449.986, 0.939
[epoch:23, iter:17365] Loss: 1.470, 10.798, 68.965, 449.422, 1.369
[epoch:23, iter:17385] Loss: 1.469, 10.789, 68.962, 449.014, 1.515
Epoch: [22][200/782]	Time 0.082 (0.082)	Data 0.002 (0.005)	Loss 14.0043 (14.3624)	Acc@1 57.812 (60.549)	Acc@5 92.188 (88.083)
[epoch:23, iter:17405] Loss: 1.470, 10.781, 68.850, 448.586, 1.567
[epoch:23, iter:17425] Loss: 1.471, 10.784, 68.834, 448.477, 2.109
[epoch:23, iter:17445] Loss: 1.471, 10.787, 68.788, 448.522, 1.282
[epoch:23, iter:17465] Loss: 1.471, 10.783, 68.763, 448.474, 1.555
[epoch:23, iter:17485] Loss: 1.470, 10.778, 68.692, 448.278, 1.932
Epoch: [22][300/782]	Time 0.066 (0.080)	Data 0.002 (0.004)	Loss 14.9253 (14.3618)	Acc@1 51.562 (59.879)	Acc@5 79.688 (88.123)
[epoch:23, iter:17505] Loss: 1.468, 10.768, 68.654, 448.184, 1.934
[epoch:23, iter:17525] Loss: 1.468, 10.766, 68.692, 448.301, 1.457
[epoch:23, iter:17545] Loss: 1.466, 10.759, 68.666, 448.269, 1.321
[epoch:23, iter:17565] Loss: 1.466, 10.754, 68.643, 448.092, 1.290
[epoch:23, iter:17585] Loss: 1.465, 10.751, 68.661, 448.066, 1.418
Epoch: [22][400/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 14.3953 (14.3562)	Acc@1 59.375 (59.772)	Acc@5 85.938 (88.007)
[epoch:23, iter:17605] Loss: 1.465, 10.750, 68.679, 448.168, 1.466
[epoch:23, iter:17625] Loss: 1.464, 10.748, 68.639, 448.176, 1.152
[epoch:23, iter:17645] Loss: 1.465, 10.752, 68.645, 448.200, 1.618
[epoch:23, iter:17665] Loss: 1.464, 10.753, 68.616, 448.091, 1.624
[epoch:23, iter:17685] Loss: 1.464, 10.752, 68.602, 448.109, 1.780
Epoch: [22][500/782]	Time 0.078 (0.078)	Data 0.002 (0.003)	Loss 14.2743 (14.3551)	Acc@1 57.812 (59.815)	Acc@5 89.062 (87.993)
[epoch:23, iter:17705] Loss: 1.465, 10.749, 68.595, 448.150, 1.535
[epoch:23, iter:17725] Loss: 1.464, 10.749, 68.596, 448.201, 2.064
[epoch:23, iter:17745] Loss: 1.464, 10.751, 68.595, 448.340, 1.356
[epoch:23, iter:17765] Loss: 1.465, 10.748, 68.598, 448.392, 1.993
[epoch:23, iter:17785] Loss: 1.465, 10.744, 68.623, 448.574, 2.308
Epoch: [22][600/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 14.6745 (14.3912)	Acc@1 59.375 (59.666)	Acc@5 84.375 (87.833)
[epoch:23, iter:17805] Loss: 1.465, 10.744, 68.628, 448.623, 1.590
[epoch:23, iter:17825] Loss: 1.465, 10.738, 68.615, 448.519, 1.238
[epoch:23, iter:17845] Loss: 1.465, 10.736, 68.594, 448.417, 1.844
[epoch:23, iter:17865] Loss: 1.464, 10.732, 68.542, 448.261, 1.308
[epoch:23, iter:17885] Loss: 1.463, 10.727, 68.514, 448.221, 1.369
Epoch: [22][700/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 14.4281 (14.3676)	Acc@1 53.125 (59.671)	Acc@5 89.062 (87.888)
[epoch:23, iter:17905] Loss: 1.464, 10.728, 68.521, 448.207, 1.289
[epoch:23, iter:17925] Loss: 1.464, 10.728, 68.539, 448.204, 1.339
[epoch:23, iter:17945] Loss: 1.464, 10.727, 68.488, 448.076, 1.410
[epoch:23, iter:17965] Loss: 1.464, 10.726, 68.513, 448.121, 1.410
[epoch:23, iter:17985] Loss: 1.464, 10.728, 68.527, 448.124, 1.408
 * Acc@1 59.756 Acc@5 87.928
epoch 22, total time 60.13
Test: [0/313]	Time 0.253 (0.253)	Loss 2.5386 (2.5386)	Acc@1 62.500 (62.500)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.7787 (2.1837)	Acc@1 46.875 (51.702)	Acc@5 87.500 (82.024)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3312 (2.1736)	Acc@1 65.625 (52.114)	Acc@5 96.875 (81.716)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6076 (2.1491)	Acc@1 40.625 (52.533)	Acc@5 71.875 (81.894)
 * Acc@1 52.580 Acc@5 81.800
==> training...
Epoch: [23][0/782]	Time 0.491 (0.491)	Data 0.427 (0.427)	Loss 15.2113 (15.2113)	Acc@1 59.375 (59.375)	Acc@5 82.812 (82.812)
[epoch:24, iter:17987] Loss: 1.486, 10.987, 72.866, 450.656, 1.836
[epoch:24, iter:18007] Loss: 1.507, 10.919, 68.882, 450.970, 1.512
[epoch:24, iter:18027] Loss: 1.490, 10.813, 68.220, 448.442, 1.200
[epoch:24, iter:18047] Loss: 1.477, 10.784, 67.811, 447.554, 1.286
[epoch:24, iter:18067] Loss: 1.470, 10.741, 67.489, 446.645, 1.526
Epoch: [23][100/782]	Time 0.086 (0.081)	Data 0.002 (0.007)	Loss 14.6449 (14.1229)	Acc@1 59.375 (60.412)	Acc@5 78.125 (88.707)
[epoch:24, iter:18087] Loss: 1.468, 10.714, 67.540, 446.761, 1.577
[epoch:24, iter:18107] Loss: 1.465, 10.705, 67.566, 447.015, 1.669
[epoch:24, iter:18127] Loss: 1.460, 10.713, 67.477, 446.576, 1.202
[epoch:24, iter:18147] Loss: 1.461, 10.702, 67.596, 446.655, 1.233
[epoch:24, iter:18167] Loss: 1.463, 10.708, 67.821, 447.079, 1.014
Epoch: [23][200/782]	Time 0.082 (0.079)	Data 0.003 (0.004)	Loss 14.4946 (14.2193)	Acc@1 59.375 (60.036)	Acc@5 81.250 (88.347)
[epoch:24, iter:18187] Loss: 1.462, 10.715, 67.897, 447.344, 1.726
[epoch:24, iter:18207] Loss: 1.464, 10.726, 67.939, 447.543, 1.170
[epoch:24, iter:18227] Loss: 1.468, 10.730, 68.022, 447.742, 1.929
[epoch:24, iter:18247] Loss: 1.467, 10.727, 68.080, 447.714, 1.427
[epoch:24, iter:18267] Loss: 1.466, 10.720, 68.147, 447.764, 1.304
Epoch: [23][300/782]	Time 0.084 (0.079)	Data 0.002 (0.004)	Loss 13.9619 (14.2781)	Acc@1 64.062 (59.925)	Acc@5 89.062 (88.237)
[epoch:24, iter:18287] Loss: 1.466, 10.713, 68.187, 447.942, 1.283
[epoch:24, iter:18307] Loss: 1.465, 10.710, 68.122, 447.692, 1.486
[epoch:24, iter:18327] Loss: 1.464, 10.707, 68.104, 447.574, 1.798
[epoch:24, iter:18347] Loss: 1.463, 10.704, 68.114, 447.578, 1.605
[epoch:24, iter:18367] Loss: 1.465, 10.710, 68.187, 447.663, 2.067
Epoch: [23][400/782]	Time 0.091 (0.080)	Data 0.002 (0.003)	Loss 14.5900 (14.3027)	Acc@1 57.812 (59.956)	Acc@5 89.062 (88.081)
[epoch:24, iter:18387] Loss: 1.465, 10.709, 68.281, 447.865, 1.533
[epoch:24, iter:18407] Loss: 1.465, 10.715, 68.333, 448.007, 1.811
[epoch:24, iter:18427] Loss: 1.466, 10.710, 68.378, 448.031, 1.392
[epoch:24, iter:18447] Loss: 1.467, 10.717, 68.416, 448.096, 1.429
[epoch:24, iter:18467] Loss: 1.467, 10.717, 68.398, 448.018, 1.183
Epoch: [23][500/782]	Time 0.076 (0.080)	Data 0.002 (0.003)	Loss 15.3337 (14.3205)	Acc@1 51.562 (59.980)	Acc@5 81.250 (87.971)
[epoch:24, iter:18487] Loss: 1.467, 10.717, 68.382, 447.930, 2.146
[epoch:24, iter:18507] Loss: 1.467, 10.719, 68.396, 447.944, 1.419
[epoch:24, iter:18527] Loss: 1.467, 10.712, 68.351, 447.769, 1.592
[epoch:24, iter:18547] Loss: 1.467, 10.708, 68.362, 447.843, 1.427
[epoch:24, iter:18567] Loss: 1.467, 10.709, 68.348, 447.780, 1.219
Epoch: [23][600/782]	Time 0.081 (0.079)	Data 0.003 (0.003)	Loss 15.6677 (14.3235)	Acc@1 54.688 (59.843)	Acc@5 82.812 (87.991)
[epoch:24, iter:18587] Loss: 1.467, 10.704, 68.359, 447.851, 1.773
[epoch:24, iter:18607] Loss: 1.467, 10.704, 68.331, 447.745, 1.501
[epoch:24, iter:18627] Loss: 1.467, 10.700, 68.333, 447.719, 1.184
[epoch:24, iter:18647] Loss: 1.467, 10.702, 68.329, 447.714, 1.323
[epoch:24, iter:18667] Loss: 1.466, 10.705, 68.349, 447.751, 1.869
Epoch: [23][700/782]	Time 0.080 (0.079)	Data 0.003 (0.003)	Loss 14.4848 (14.3269)	Acc@1 67.188 (59.888)	Acc@5 92.188 (88.035)
[epoch:24, iter:18687] Loss: 1.465, 10.705, 68.369, 447.778, 1.203
[epoch:24, iter:18707] Loss: 1.466, 10.706, 68.411, 447.876, 1.491
[epoch:24, iter:18727] Loss: 1.466, 10.710, 68.431, 447.935, 0.885
[epoch:24, iter:18747] Loss: 1.466, 10.708, 68.432, 447.880, 1.471
[epoch:24, iter:18767] Loss: 1.467, 10.708, 68.449, 447.910, 1.818
 * Acc@1 59.790 Acc@5 87.966
epoch 23, total time 60.83
Test: [0/313]	Time 0.241 (0.241)	Loss 2.2892 (2.2892)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.009)	Loss 1.9077 (2.2960)	Acc@1 56.250 (50.866)	Acc@5 87.500 (81.714)
Test: [200/313]	Time 0.011 (0.009)	Loss 1.3190 (2.2717)	Acc@1 65.625 (51.088)	Acc@5 93.750 (81.779)
Test: [300/313]	Time 0.005 (0.008)	Loss 3.1738 (2.2502)	Acc@1 37.500 (51.204)	Acc@5 68.750 (81.665)
 * Acc@1 51.270 Acc@5 81.670
==> training...
Epoch: [24][0/782]	Time 0.585 (0.585)	Data 0.509 (0.509)	Loss 14.9729 (14.9729)	Acc@1 54.688 (54.688)	Acc@5 90.625 (90.625)
[epoch:25, iter:18769] Loss: 1.535, 10.588, 70.487, 457.325, 1.388
[epoch:25, iter:18789] Loss: 1.498, 10.844, 69.503, 449.688, 1.515
[epoch:25, iter:18809] Loss: 1.490, 10.841, 68.886, 448.451, 1.510
[epoch:25, iter:18829] Loss: 1.474, 10.762, 68.411, 446.770, 1.043
[epoch:25, iter:18849] Loss: 1.470, 10.742, 68.294, 446.367, 1.422
Epoch: [24][100/782]	Time 0.057 (0.079)	Data 0.002 (0.007)	Loss 14.5647 (14.1559)	Acc@1 57.812 (60.953)	Acc@5 84.375 (88.722)
[epoch:25, iter:18869] Loss: 1.465, 10.729, 68.218, 446.162, 1.665
[epoch:25, iter:18889] Loss: 1.462, 10.744, 68.168, 446.163, 0.984
[epoch:25, iter:18909] Loss: 1.463, 10.736, 68.106, 445.974, 1.506
[epoch:25, iter:18929] Loss: 1.461, 10.739, 68.228, 446.348, 1.377
[epoch:25, iter:18949] Loss: 1.460, 10.747, 68.260, 446.625, 1.207
Epoch: [24][200/782]	Time 0.089 (0.077)	Data 0.003 (0.005)	Loss 14.4212 (14.1975)	Acc@1 51.562 (60.836)	Acc@5 90.625 (88.441)
[epoch:25, iter:18969] Loss: 1.460, 10.742, 68.229, 446.509, 1.677
[epoch:25, iter:18989] Loss: 1.462, 10.740, 68.211, 446.563, 1.247
[epoch:25, iter:19009] Loss: 1.463, 10.744, 68.211, 446.663, 1.447
[epoch:25, iter:19029] Loss: 1.460, 10.747, 68.189, 446.641, 1.680
[epoch:25, iter:19049] Loss: 1.460, 10.734, 68.164, 446.471, 1.171
Epoch: [24][300/782]	Time 0.088 (0.077)	Data 0.002 (0.004)	Loss 13.7883 (14.2145)	Acc@1 67.188 (60.491)	Acc@5 84.375 (88.559)
[epoch:25, iter:19069] Loss: 1.459, 10.737, 68.191, 446.559, 1.465
[epoch:25, iter:19089] Loss: 1.458, 10.735, 68.143, 446.275, 1.161
[epoch:25, iter:19109] Loss: 1.460, 10.729, 68.130, 446.354, 1.261
[epoch:25, iter:19129] Loss: 1.460, 10.731, 68.112, 446.434, 1.554
[epoch:25, iter:19149] Loss: 1.460, 10.727, 68.088, 446.479, 1.816
Epoch: [24][400/782]	Time 0.075 (0.078)	Data 0.002 (0.004)	Loss 14.6685 (14.2126)	Acc@1 64.062 (60.318)	Acc@5 92.188 (88.404)
[epoch:25, iter:19169] Loss: 1.460, 10.725, 68.065, 446.499, 1.321
[epoch:25, iter:19189] Loss: 1.461, 10.729, 68.118, 446.662, 1.581
[epoch:25, iter:19209] Loss: 1.462, 10.737, 68.142, 446.727, 1.299
[epoch:25, iter:19229] Loss: 1.463, 10.738, 68.157, 446.816, 1.671
[epoch:25, iter:19249] Loss: 1.464, 10.743, 68.136, 446.820, 1.656
Epoch: [24][500/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 14.5833 (14.2515)	Acc@1 60.938 (60.195)	Acc@5 92.188 (88.414)
[epoch:25, iter:19269] Loss: 1.463, 10.742, 68.181, 446.870, 1.382
[epoch:25, iter:19289] Loss: 1.464, 10.739, 68.167, 446.744, 1.591
[epoch:25, iter:19309] Loss: 1.463, 10.736, 68.160, 446.730, 1.180
[epoch:25, iter:19329] Loss: 1.463, 10.740, 68.154, 446.804, 1.243
[epoch:25, iter:19349] Loss: 1.463, 10.735, 68.118, 446.777, 1.300
Epoch: [24][600/782]	Time 0.075 (0.078)	Data 0.003 (0.003)	Loss 14.2703 (14.2517)	Acc@1 56.250 (60.152)	Acc@5 95.312 (88.301)
[epoch:25, iter:19369] Loss: 1.463, 10.728, 68.103, 446.726, 1.334
[epoch:25, iter:19389] Loss: 1.463, 10.728, 68.100, 446.631, 1.497
[epoch:25, iter:19409] Loss: 1.463, 10.730, 68.113, 446.702, 1.303
[epoch:25, iter:19429] Loss: 1.464, 10.731, 68.128, 446.800, 1.589
[epoch:25, iter:19449] Loss: 1.463, 10.727, 68.105, 446.741, 1.361
Epoch: [24][700/782]	Time 0.090 (0.078)	Data 0.003 (0.003)	Loss 14.4171 (14.2642)	Acc@1 59.375 (60.099)	Acc@5 85.938 (88.198)
[epoch:25, iter:19469] Loss: 1.464, 10.728, 68.114, 446.790, 1.480
[epoch:25, iter:19489] Loss: 1.465, 10.728, 68.102, 446.798, 1.550
[epoch:25, iter:19509] Loss: 1.465, 10.728, 68.120, 446.826, 1.416
[epoch:25, iter:19529] Loss: 1.465, 10.727, 68.132, 446.890, 1.123
[epoch:25, iter:19549] Loss: 1.464, 10.723, 68.110, 446.861, 0.998
 * Acc@1 59.998 Acc@5 88.112
epoch 24, total time 60.62
Test: [0/313]	Time 0.263 (0.263)	Loss 1.8344 (1.8344)	Acc@1 65.625 (65.625)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.7814 (2.2652)	Acc@1 40.625 (51.269)	Acc@5 78.125 (81.776)
Test: [200/313]	Time 0.005 (0.008)	Loss 1.7402 (2.2772)	Acc@1 59.375 (51.446)	Acc@5 90.625 (81.608)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5338 (2.2643)	Acc@1 40.625 (52.253)	Acc@5 81.250 (81.821)
 * Acc@1 52.240 Acc@5 81.990
==> training...
Epoch: [25][0/782]	Time 0.552 (0.552)	Data 0.467 (0.467)	Loss 14.5509 (14.5509)	Acc@1 53.125 (53.125)	Acc@5 90.625 (90.625)
[epoch:26, iter:19551] Loss: 1.425, 10.756, 69.173, 442.543, 1.502
[epoch:26, iter:19571] Loss: 1.481, 10.813, 69.336, 448.479, 1.403
[epoch:26, iter:19591] Loss: 1.474, 10.693, 68.702, 446.541, 1.672
[epoch:26, iter:19611] Loss: 1.460, 10.670, 68.696, 447.366, 1.220
[epoch:26, iter:19631] Loss: 1.464, 10.679, 69.039, 448.461, 1.293
Epoch: [25][100/782]	Time 0.084 (0.079)	Data 0.002 (0.007)	Loss 14.1460 (14.4117)	Acc@1 65.625 (60.040)	Acc@5 89.062 (87.639)
[epoch:26, iter:19651] Loss: 1.463, 10.676, 68.889, 448.213, 1.271
[epoch:26, iter:19671] Loss: 1.465, 10.684, 68.890, 448.360, 1.250
[epoch:26, iter:19691] Loss: 1.465, 10.689, 68.751, 447.901, 1.527
[epoch:26, iter:19711] Loss: 1.461, 10.687, 68.653, 447.545, 0.904
[epoch:26, iter:19731] Loss: 1.459, 10.688, 68.533, 447.390, 1.522
Epoch: [25][200/782]	Time 0.071 (0.079)	Data 0.002 (0.005)	Loss 13.5168 (14.2767)	Acc@1 68.750 (60.595)	Acc@5 87.500 (88.075)
[epoch:26, iter:19751] Loss: 1.458, 10.688, 68.440, 446.962, 1.494
[epoch:26, iter:19771] Loss: 1.459, 10.690, 68.385, 446.871, 1.487
[epoch:26, iter:19791] Loss: 1.460, 10.682, 68.372, 446.778, 1.423
[epoch:26, iter:19811] Loss: 1.457, 10.678, 68.332, 446.638, 1.544
[epoch:26, iter:19831] Loss: 1.457, 10.681, 68.347, 446.630, 1.462
Epoch: [25][300/782]	Time 0.066 (0.077)	Data 0.002 (0.004)	Loss 14.0184 (14.2320)	Acc@1 48.438 (60.626)	Acc@5 89.062 (88.222)
[epoch:26, iter:19851] Loss: 1.456, 10.677, 68.250, 446.222, 1.882
[epoch:26, iter:19871] Loss: 1.455, 10.677, 68.191, 446.093, 1.228
[epoch:26, iter:19891] Loss: 1.456, 10.679, 68.184, 446.289, 1.501
[epoch:26, iter:19911] Loss: 1.456, 10.686, 68.234, 446.405, 1.559
[epoch:26, iter:19931] Loss: 1.458, 10.692, 68.294, 446.665, 1.655
Epoch: [25][400/782]	Time 0.065 (0.077)	Data 0.002 (0.003)	Loss 14.4306 (14.2523)	Acc@1 70.312 (60.708)	Acc@5 90.625 (88.229)
[epoch:26, iter:19951] Loss: 1.459, 10.699, 68.305, 446.686, 1.088
[epoch:26, iter:19971] Loss: 1.458, 10.701, 68.328, 446.662, 1.349
[epoch:26, iter:19991] Loss: 1.459, 10.710, 68.388, 446.815, 1.639
[epoch:26, iter:20011] Loss: 1.459, 10.714, 68.388, 446.862, 1.299
[epoch:26, iter:20031] Loss: 1.460, 10.713, 68.398, 446.925, 1.810
Epoch: [25][500/782]	Time 0.081 (0.077)	Data 0.003 (0.003)	Loss 14.6817 (14.2780)	Acc@1 57.812 (60.607)	Acc@5 92.188 (88.252)
[epoch:26, iter:20051] Loss: 1.460, 10.711, 68.431, 446.920, 1.683
[epoch:26, iter:20071] Loss: 1.460, 10.717, 68.450, 447.024, 1.412
[epoch:26, iter:20091] Loss: 1.460, 10.714, 68.439, 447.016, 1.498
[epoch:26, iter:20111] Loss: 1.460, 10.716, 68.451, 447.038, 1.253
[epoch:26, iter:20131] Loss: 1.460, 10.713, 68.448, 447.025, 1.446
Epoch: [25][600/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 14.7441 (14.2961)	Acc@1 60.938 (60.597)	Acc@5 84.375 (88.228)
[epoch:26, iter:20151] Loss: 1.459, 10.715, 68.475, 447.131, 1.413
[epoch:26, iter:20171] Loss: 1.460, 10.720, 68.506, 447.176, 1.633
[epoch:26, iter:20191] Loss: 1.460, 10.718, 68.469, 446.965, 1.237
[epoch:26, iter:20211] Loss: 1.459, 10.713, 68.420, 446.830, 1.398
[epoch:26, iter:20231] Loss: 1.459, 10.711, 68.416, 446.834, 1.683
Epoch: [25][700/782]	Time 0.088 (0.078)	Data 0.002 (0.003)	Loss 14.6598 (14.2685)	Acc@1 48.438 (60.666)	Acc@5 87.500 (88.285)
[epoch:26, iter:20251] Loss: 1.459, 10.707, 68.383, 446.773, 1.915
[epoch:26, iter:20271] Loss: 1.459, 10.704, 68.379, 446.757, 1.217
[epoch:26, iter:20291] Loss: 1.459, 10.703, 68.392, 446.837, 1.714
[epoch:26, iter:20311] Loss: 1.459, 10.703, 68.393, 446.892, 1.509
[epoch:26, iter:20331] Loss: 1.460, 10.698, 68.405, 446.905, 0.846
 * Acc@1 60.458 Acc@5 88.244
epoch 25, total time 60.96
Test: [0/313]	Time 0.245 (0.245)	Loss 2.4192 (2.4192)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.5868 (2.0527)	Acc@1 46.875 (53.342)	Acc@5 84.375 (83.663)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.8914 (2.0415)	Acc@1 53.125 (53.591)	Acc@5 84.375 (83.349)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.1739 (2.0717)	Acc@1 40.625 (53.167)	Acc@5 84.375 (82.973)
 * Acc@1 53.130 Acc@5 83.030
==> training...
Epoch: [26][0/782]	Time 0.582 (0.582)	Data 0.508 (0.508)	Loss 14.1004 (14.1004)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:27, iter:20333] Loss: 1.388, 10.246, 69.482, 451.232, 1.288
[epoch:27, iter:20353] Loss: 1.469, 10.695, 68.975, 446.041, 1.365
[epoch:27, iter:20373] Loss: 1.478, 10.742, 68.615, 445.264, 1.402
[epoch:27, iter:20393] Loss: 1.465, 10.702, 68.553, 445.129, 1.359
[epoch:27, iter:20413] Loss: 1.457, 10.680, 68.470, 445.438, 1.207
Epoch: [26][100/782]	Time 0.069 (0.087)	Data 0.003 (0.008)	Loss 14.6370 (14.1591)	Acc@1 59.375 (61.108)	Acc@5 85.938 (88.645)
[epoch:27, iter:20433] Loss: 1.454, 10.695, 68.310, 444.966, 1.583
[epoch:27, iter:20453] Loss: 1.459, 10.704, 68.260, 445.125, 1.805
[epoch:27, iter:20473] Loss: 1.459, 10.691, 68.176, 444.954, 1.064
[epoch:27, iter:20493] Loss: 1.456, 10.701, 68.158, 444.755, 1.694
[epoch:27, iter:20513] Loss: 1.453, 10.688, 67.941, 444.119, 1.214
Epoch: [26][200/782]	Time 0.073 (0.081)	Data 0.002 (0.005)	Loss 13.4736 (14.0685)	Acc@1 67.188 (61.622)	Acc@5 87.500 (88.915)
[epoch:27, iter:20533] Loss: 1.454, 10.674, 67.901, 444.023, 1.498
[epoch:27, iter:20553] Loss: 1.453, 10.672, 67.864, 444.230, 1.334
[epoch:27, iter:20573] Loss: 1.455, 10.664, 67.882, 444.401, 1.388
[epoch:27, iter:20593] Loss: 1.454, 10.658, 67.885, 444.351, 1.350
[epoch:27, iter:20613] Loss: 1.451, 10.653, 67.898, 444.390, 1.767
Epoch: [26][300/782]	Time 0.077 (0.079)	Data 0.002 (0.004)	Loss 15.3760 (14.1052)	Acc@1 64.062 (61.457)	Acc@5 87.500 (88.704)
[epoch:27, iter:20633] Loss: 1.450, 10.650, 67.924, 444.484, 1.582
[epoch:27, iter:20653] Loss: 1.452, 10.656, 67.987, 444.632, 1.795
[epoch:27, iter:20673] Loss: 1.452, 10.652, 67.957, 444.573, 1.494
[epoch:27, iter:20693] Loss: 1.452, 10.648, 67.975, 444.667, 1.550
[epoch:27, iter:20713] Loss: 1.451, 10.644, 67.938, 444.638, 1.590
Epoch: [26][400/782]	Time 0.089 (0.079)	Data 0.003 (0.004)	Loss 12.8509 (14.1259)	Acc@1 64.062 (61.152)	Acc@5 89.062 (88.533)
[epoch:27, iter:20733] Loss: 1.452, 10.646, 67.919, 444.642, 1.151
[epoch:27, iter:20753] Loss: 1.454, 10.654, 67.926, 444.657, 1.056
[epoch:27, iter:20773] Loss: 1.453, 10.653, 67.913, 444.658, 1.794
[epoch:27, iter:20793] Loss: 1.453, 10.658, 67.921, 444.659, 1.648
[epoch:27, iter:20813] Loss: 1.453, 10.658, 67.963, 444.810, 1.025
Epoch: [26][500/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 13.5524 (14.1309)	Acc@1 73.438 (61.140)	Acc@5 95.312 (88.426)
[epoch:27, iter:20833] Loss: 1.452, 10.661, 67.939, 444.778, 1.002
[epoch:27, iter:20853] Loss: 1.452, 10.662, 67.949, 444.867, 1.504
[epoch:27, iter:20873] Loss: 1.451, 10.659, 67.925, 444.761, 1.246
[epoch:27, iter:20893] Loss: 1.451, 10.657, 67.963, 444.899, 1.804
[epoch:27, iter:20913] Loss: 1.451, 10.655, 67.965, 444.844, 1.710
Epoch: [26][600/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 14.7639 (14.1377)	Acc@1 42.188 (60.911)	Acc@5 87.500 (88.366)
[epoch:27, iter:20933] Loss: 1.450, 10.653, 67.933, 444.731, 1.900
[epoch:27, iter:20953] Loss: 1.450, 10.655, 67.911, 444.722, 1.250
[epoch:27, iter:20973] Loss: 1.449, 10.654, 67.925, 444.805, 1.212
[epoch:27, iter:20993] Loss: 1.450, 10.658, 67.940, 444.926, 1.373
[epoch:27, iter:21013] Loss: 1.450, 10.656, 67.927, 444.917, 1.839
Epoch: [26][700/782]	Time 0.069 (0.078)	Data 0.002 (0.003)	Loss 13.9861 (14.1551)	Acc@1 59.375 (60.788)	Acc@5 82.812 (88.267)
[epoch:27, iter:21033] Loss: 1.450, 10.655, 67.950, 445.010, 1.654
[epoch:27, iter:21053] Loss: 1.451, 10.657, 67.952, 445.044, 1.779
[epoch:27, iter:21073] Loss: 1.452, 10.660, 67.942, 445.071, 1.663
[epoch:27, iter:21093] Loss: 1.452, 10.661, 67.935, 445.112, 1.279
[epoch:27, iter:21113] Loss: 1.452, 10.659, 67.914, 445.125, 1.636
 * Acc@1 60.714 Acc@5 88.248
epoch 26, total time 61.08
Test: [0/313]	Time 0.274 (0.274)	Loss 2.1756 (2.1756)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.0241 (2.1695)	Acc@1 40.625 (52.413)	Acc@5 78.125 (82.364)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.1054 (2.1846)	Acc@1 56.250 (51.975)	Acc@5 78.125 (82.074)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.8446 (2.1894)	Acc@1 25.000 (52.211)	Acc@5 78.125 (81.873)
 * Acc@1 52.270 Acc@5 81.920
==> training...
Epoch: [27][0/782]	Time 0.554 (0.554)	Data 0.481 (0.481)	Loss 14.7686 (14.7686)	Acc@1 59.375 (59.375)	Acc@5 85.938 (85.938)
[epoch:28, iter:21115] Loss: 1.468, 10.748, 71.100, 460.822, 1.538
[epoch:28, iter:21135] Loss: 1.458, 10.754, 67.935, 444.136, 1.270
[epoch:28, iter:21155] Loss: 1.454, 10.684, 68.111, 445.017, 1.527
[epoch:28, iter:21175] Loss: 1.449, 10.674, 67.911, 444.629, 1.632
[epoch:28, iter:21195] Loss: 1.449, 10.660, 67.658, 444.411, 1.489
Epoch: [27][100/782]	Time 0.073 (0.085)	Data 0.002 (0.007)	Loss 13.7112 (14.1092)	Acc@1 71.875 (61.216)	Acc@5 93.750 (89.233)
[epoch:28, iter:21215] Loss: 1.446, 10.674, 67.584, 444.212, 1.069
[epoch:28, iter:21235] Loss: 1.449, 10.672, 67.750, 444.360, 1.966
[epoch:28, iter:21255] Loss: 1.447, 10.667, 67.687, 444.179, 1.213
[epoch:28, iter:21275] Loss: 1.447, 10.671, 67.685, 444.108, 1.533
[epoch:28, iter:21295] Loss: 1.445, 10.676, 67.758, 444.585, 1.317
Epoch: [27][200/782]	Time 0.074 (0.082)	Data 0.002 (0.005)	Loss 13.2257 (14.1517)	Acc@1 68.750 (60.603)	Acc@5 89.062 (88.487)
[epoch:28, iter:21315] Loss: 1.448, 10.692, 67.822, 444.715, 1.115
[epoch:28, iter:21335] Loss: 1.447, 10.690, 67.816, 444.718, 1.202
[epoch:28, iter:21355] Loss: 1.449, 10.684, 67.816, 444.763, 1.238
[epoch:28, iter:21375] Loss: 1.448, 10.682, 67.795, 444.989, 1.119
[epoch:28, iter:21395] Loss: 1.447, 10.669, 67.810, 444.884, 1.631
Epoch: [27][300/782]	Time 0.069 (0.080)	Data 0.002 (0.004)	Loss 13.7231 (14.1510)	Acc@1 65.625 (60.600)	Acc@5 90.625 (88.460)
[epoch:28, iter:21415] Loss: 1.448, 10.667, 67.806, 444.846, 1.311
[epoch:28, iter:21435] Loss: 1.449, 10.668, 67.806, 444.782, 1.433
[epoch:28, iter:21455] Loss: 1.450, 10.671, 67.778, 444.723, 2.057
[epoch:28, iter:21475] Loss: 1.453, 10.673, 67.785, 444.870, 1.192
[epoch:28, iter:21495] Loss: 1.452, 10.669, 67.825, 444.923, 1.166
Epoch: [27][400/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 14.5448 (14.1537)	Acc@1 59.375 (60.630)	Acc@5 85.938 (88.611)
[epoch:28, iter:21515] Loss: 1.453, 10.668, 67.839, 444.936, 1.482
[epoch:28, iter:21535] Loss: 1.453, 10.672, 67.854, 444.948, 1.166
[epoch:28, iter:21555] Loss: 1.453, 10.673, 67.885, 444.876, 1.619
[epoch:28, iter:21575] Loss: 1.454, 10.679, 67.925, 445.059, 1.620
[epoch:28, iter:21595] Loss: 1.454, 10.684, 67.940, 445.097, 1.831
Epoch: [27][500/782]	Time 0.060 (0.078)	Data 0.002 (0.003)	Loss 14.7832 (14.1889)	Acc@1 56.250 (60.451)	Acc@5 87.500 (88.383)
[epoch:28, iter:21615] Loss: 1.455, 10.690, 67.944, 445.201, 1.481
[epoch:28, iter:21635] Loss: 1.456, 10.692, 67.951, 445.231, 1.566
[epoch:28, iter:21655] Loss: 1.458, 10.690, 67.992, 445.337, 1.677
[epoch:28, iter:21675] Loss: 1.456, 10.686, 67.959, 445.289, 1.401
[epoch:28, iter:21695] Loss: 1.456, 10.686, 67.968, 445.288, 1.135
Epoch: [27][600/782]	Time 0.085 (0.078)	Data 0.002 (0.003)	Loss 14.5087 (14.2024)	Acc@1 54.688 (60.441)	Acc@5 76.562 (88.327)
[epoch:28, iter:21715] Loss: 1.456, 10.685, 67.987, 445.355, 2.005
[epoch:28, iter:21735] Loss: 1.456, 10.688, 67.971, 445.345, 1.112
[epoch:28, iter:21755] Loss: 1.455, 10.685, 67.933, 445.198, 1.416
[epoch:28, iter:21775] Loss: 1.456, 10.684, 67.918, 445.169, 1.213
[epoch:28, iter:21795] Loss: 1.455, 10.684, 67.940, 445.229, 1.390
Epoch: [27][700/782]	Time 0.077 (0.079)	Data 0.002 (0.003)	Loss 13.9061 (14.2034)	Acc@1 64.062 (60.405)	Acc@5 85.938 (88.345)
[epoch:28, iter:21815] Loss: 1.456, 10.685, 67.972, 445.342, 1.434
[epoch:28, iter:21835] Loss: 1.455, 10.684, 67.976, 445.313, 1.048
[epoch:28, iter:21855] Loss: 1.455, 10.681, 67.955, 445.303, 1.746
[epoch:28, iter:21875] Loss: 1.455, 10.682, 67.952, 445.364, 1.437
[epoch:28, iter:21895] Loss: 1.456, 10.682, 67.954, 445.394, 1.537
 * Acc@1 60.410 Acc@5 88.356
epoch 27, total time 61.44
Test: [0/313]	Time 0.255 (0.255)	Loss 2.5048 (2.5048)	Acc@1 68.750 (68.750)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.9930 (2.0585)	Acc@1 43.750 (53.806)	Acc@5 90.625 (83.292)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3675 (2.0741)	Acc@1 62.500 (53.514)	Acc@5 93.750 (82.743)
Test: [300/313]	Time 0.009 (0.008)	Loss 2.0107 (2.0871)	Acc@1 46.875 (53.073)	Acc@5 96.875 (82.517)
 * Acc@1 53.030 Acc@5 82.560
==> training...
Epoch: [28][0/782]	Time 0.489 (0.489)	Data 0.420 (0.420)	Loss 14.5826 (14.5826)	Acc@1 56.250 (56.250)	Acc@5 93.750 (93.750)
[epoch:29, iter:21897] Loss: 1.486, 10.505, 71.544, 456.866, 1.412
[epoch:29, iter:21917] Loss: 1.493, 10.862, 69.504, 452.016, 1.552
[epoch:29, iter:21937] Loss: 1.498, 10.851, 68.734, 448.539, 1.320
[epoch:29, iter:21957] Loss: 1.485, 10.816, 67.910, 445.471, 1.604
[epoch:29, iter:21977] Loss: 1.473, 10.779, 67.688, 444.786, 1.473
Epoch: [28][100/782]	Time 0.061 (0.080)	Data 0.002 (0.006)	Loss 13.6460 (14.0846)	Acc@1 59.375 (59.746)	Acc@5 87.500 (89.202)
[epoch:29, iter:21997] Loss: 1.466, 10.773, 67.499, 444.685, 1.331
[epoch:29, iter:22017] Loss: 1.462, 10.739, 67.634, 444.707, 1.921
[epoch:29, iter:22037] Loss: 1.459, 10.738, 67.673, 444.789, 1.732
[epoch:29, iter:22057] Loss: 1.459, 10.720, 67.676, 444.663, 1.519
[epoch:29, iter:22077] Loss: 1.457, 10.720, 67.658, 444.630, 1.577
Epoch: [28][200/782]	Time 0.071 (0.076)	Data 0.002 (0.004)	Loss 14.1401 (14.0790)	Acc@1 65.625 (60.401)	Acc@5 93.750 (88.961)
[epoch:29, iter:22097] Loss: 1.454, 10.710, 67.609, 444.238, 1.153
[epoch:29, iter:22117] Loss: 1.452, 10.691, 67.678, 444.214, 1.766
[epoch:29, iter:22137] Loss: 1.453, 10.691, 67.618, 444.344, 1.376
[epoch:29, iter:22157] Loss: 1.453, 10.694, 67.622, 444.358, 1.120
[epoch:29, iter:22177] Loss: 1.450, 10.685, 67.634, 444.292, 1.034
Epoch: [28][300/782]	Time 0.071 (0.076)	Data 0.002 (0.004)	Loss 15.3260 (14.0828)	Acc@1 50.000 (60.771)	Acc@5 79.688 (88.761)
[epoch:29, iter:22197] Loss: 1.450, 10.674, 67.657, 444.304, 2.043
[epoch:29, iter:22217] Loss: 1.453, 10.677, 67.684, 444.365, 1.355
[epoch:29, iter:22237] Loss: 1.453, 10.677, 67.636, 444.294, 1.521
[epoch:29, iter:22257] Loss: 1.454, 10.691, 67.651, 444.530, 1.760
[epoch:29, iter:22277] Loss: 1.454, 10.687, 67.676, 444.698, 1.413
Epoch: [28][400/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 14.2123 (14.1218)	Acc@1 59.375 (60.758)	Acc@5 82.812 (88.673)
[epoch:29, iter:22297] Loss: 1.454, 10.691, 67.755, 444.918, 1.546
[epoch:29, iter:22317] Loss: 1.456, 10.700, 67.771, 444.844, 1.419
[epoch:29, iter:22337] Loss: 1.457, 10.705, 67.819, 445.025, 1.422
[epoch:29, iter:22357] Loss: 1.458, 10.709, 67.850, 445.090, 1.801
[epoch:29, iter:22377] Loss: 1.458, 10.708, 67.850, 445.082, 1.326
Epoch: [28][500/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 13.7809 (14.1562)	Acc@1 60.938 (60.700)	Acc@5 87.500 (88.570)
[epoch:29, iter:22397] Loss: 1.458, 10.710, 67.861, 445.198, 1.477
[epoch:29, iter:22417] Loss: 1.459, 10.708, 67.883, 445.329, 1.524
[epoch:29, iter:22437] Loss: 1.458, 10.714, 67.874, 445.374, 1.564
[epoch:29, iter:22457] Loss: 1.458, 10.709, 67.868, 445.333, 1.551
[epoch:29, iter:22477] Loss: 1.459, 10.706, 67.893, 445.457, 1.405
Epoch: [28][600/782]	Time 0.079 (0.076)	Data 0.002 (0.003)	Loss 13.9796 (14.1854)	Acc@1 60.938 (60.636)	Acc@5 89.062 (88.462)
[epoch:29, iter:22497] Loss: 1.459, 10.699, 67.898, 445.469, 1.430
[epoch:29, iter:22517] Loss: 1.458, 10.698, 67.867, 445.363, 1.665
[epoch:29, iter:22537] Loss: 1.459, 10.694, 67.890, 445.356, 1.443
[epoch:29, iter:22557] Loss: 1.459, 10.691, 67.872, 445.246, 1.407
[epoch:29, iter:22577] Loss: 1.458, 10.690, 67.869, 445.195, 1.817
Epoch: [28][700/782]	Time 0.076 (0.076)	Data 0.002 (0.003)	Loss 13.6905 (14.1819)	Acc@1 62.500 (60.554)	Acc@5 90.625 (88.463)
[epoch:29, iter:22597] Loss: 1.458, 10.690, 67.900, 445.276, 1.235
[epoch:29, iter:22617] Loss: 1.458, 10.687, 67.911, 445.283, 1.437
[epoch:29, iter:22637] Loss: 1.458, 10.686, 67.942, 445.390, 1.846
[epoch:29, iter:22657] Loss: 1.457, 10.687, 67.972, 445.532, 1.858
[epoch:29, iter:22677] Loss: 1.457, 10.686, 67.983, 445.563, 1.157
 * Acc@1 60.496 Acc@5 88.436
epoch 28, total time 59.69
Test: [0/313]	Time 0.262 (0.262)	Loss 2.9872 (2.9872)	Acc@1 56.250 (56.250)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.2592 (2.1557)	Acc@1 56.250 (52.568)	Acc@5 81.250 (83.261)
Test: [200/313]	Time 0.005 (0.008)	Loss 1.5770 (2.1325)	Acc@1 59.375 (52.254)	Acc@5 84.375 (83.396)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6453 (2.1360)	Acc@1 43.750 (52.782)	Acc@5 78.125 (83.150)
 * Acc@1 52.790 Acc@5 83.210
==> training...
Epoch: [29][0/782]	Time 0.594 (0.594)	Data 0.519 (0.519)	Loss 14.0355 (14.0355)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:30, iter:22679] Loss: 1.485, 10.789, 70.273, 454.370, 1.326
[epoch:30, iter:22699] Loss: 1.443, 10.845, 68.132, 445.603, 1.783
[epoch:30, iter:22719] Loss: 1.450, 10.843, 68.897, 446.734, 1.733
[epoch:30, iter:22739] Loss: 1.447, 10.793, 68.339, 444.934, 1.340
[epoch:30, iter:22759] Loss: 1.444, 10.723, 67.808, 444.176, 1.142
Epoch: [29][100/782]	Time 0.069 (0.082)	Data 0.002 (0.007)	Loss 13.3192 (14.0321)	Acc@1 67.188 (60.968)	Acc@5 98.438 (88.970)
[epoch:30, iter:22779] Loss: 1.441, 10.714, 67.693, 444.094, 0.995
[epoch:30, iter:22799] Loss: 1.442, 10.689, 67.769, 444.068, 1.577
[epoch:30, iter:22819] Loss: 1.442, 10.669, 67.682, 444.057, 1.435
[epoch:30, iter:22839] Loss: 1.441, 10.653, 67.691, 444.026, 1.371
[epoch:30, iter:22859] Loss: 1.436, 10.647, 67.655, 443.935, 1.434
Epoch: [29][200/782]	Time 0.088 (0.081)	Data 0.003 (0.005)	Loss 13.3383 (14.0433)	Acc@1 68.750 (61.326)	Acc@5 87.500 (88.798)
[epoch:30, iter:22879] Loss: 1.437, 10.631, 67.616, 443.711, 1.479
[epoch:30, iter:22899] Loss: 1.439, 10.627, 67.723, 443.855, 1.934
[epoch:30, iter:22919] Loss: 1.441, 10.626, 67.784, 444.167, 1.466
[epoch:30, iter:22939] Loss: 1.442, 10.632, 67.818, 444.060, 1.521
[epoch:30, iter:22959] Loss: 1.444, 10.627, 67.900, 444.406, 1.507
Epoch: [29][300/782]	Time 0.079 (0.081)	Data 0.003 (0.004)	Loss 13.5777 (14.0884)	Acc@1 70.312 (61.104)	Acc@5 92.188 (88.824)
[epoch:30, iter:22979] Loss: 1.445, 10.625, 67.849, 444.286, 1.206
[epoch:30, iter:22999] Loss: 1.446, 10.634, 67.842, 444.323, 1.538
[epoch:30, iter:23019] Loss: 1.445, 10.647, 67.788, 444.197, 1.023
[epoch:30, iter:23039] Loss: 1.445, 10.644, 67.781, 444.228, 1.447
[epoch:30, iter:23059] Loss: 1.446, 10.642, 67.811, 444.274, 1.080
Epoch: [29][400/782]	Time 0.084 (0.080)	Data 0.002 (0.004)	Loss 15.0120 (14.0878)	Acc@1 46.875 (60.941)	Acc@5 89.062 (88.638)
[epoch:30, iter:23079] Loss: 1.446, 10.644, 67.825, 444.331, 1.713
[epoch:30, iter:23099] Loss: 1.448, 10.639, 67.880, 444.442, 1.527
[epoch:30, iter:23119] Loss: 1.449, 10.644, 67.922, 444.616, 1.481
[epoch:30, iter:23139] Loss: 1.449, 10.650, 67.927, 444.599, 1.497
[epoch:30, iter:23159] Loss: 1.451, 10.654, 67.948, 444.671, 1.146
Epoch: [29][500/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 13.9773 (14.1355)	Acc@1 56.250 (60.785)	Acc@5 85.938 (88.620)
[epoch:30, iter:23179] Loss: 1.452, 10.655, 67.997, 444.811, 1.659
[epoch:30, iter:23199] Loss: 1.453, 10.665, 68.005, 444.889, 1.304
[epoch:30, iter:23219] Loss: 1.453, 10.660, 67.986, 444.751, 1.615
[epoch:30, iter:23239] Loss: 1.452, 10.659, 67.958, 444.630, 1.899
[epoch:30, iter:23259] Loss: 1.452, 10.653, 67.932, 444.454, 1.489
Epoch: [29][600/782]	Time 0.087 (0.078)	Data 0.003 (0.003)	Loss 13.8652 (14.1089)	Acc@1 57.812 (60.914)	Acc@5 85.938 (88.605)
[epoch:30, iter:23279] Loss: 1.452, 10.646, 67.892, 444.295, 1.373
[epoch:30, iter:23299] Loss: 1.452, 10.645, 67.858, 444.226, 1.898
[epoch:30, iter:23319] Loss: 1.451, 10.647, 67.872, 444.377, 1.989
[epoch:30, iter:23339] Loss: 1.451, 10.643, 67.874, 444.401, 1.554
[epoch:30, iter:23359] Loss: 1.452, 10.644, 67.893, 444.516, 2.045
Epoch: [29][700/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 14.9549 (14.1439)	Acc@1 51.562 (60.706)	Acc@5 90.625 (88.494)
[epoch:30, iter:23379] Loss: 1.452, 10.646, 67.912, 444.662, 1.731
[epoch:30, iter:23399] Loss: 1.452, 10.646, 67.920, 444.691, 1.498
[epoch:30, iter:23419] Loss: 1.452, 10.645, 67.929, 444.692, 1.218
[epoch:30, iter:23439] Loss: 1.453, 10.646, 67.922, 444.698, 1.267
[epoch:30, iter:23459] Loss: 1.454, 10.646, 67.928, 444.749, 1.919
 * Acc@1 60.574 Acc@5 88.470
epoch 29, total time 60.25
Test: [0/313]	Time 0.229 (0.229)	Loss 1.7824 (1.7824)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.6358 (2.0240)	Acc@1 53.125 (54.239)	Acc@5 90.625 (83.725)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.2235 (1.9968)	Acc@1 65.625 (54.618)	Acc@5 87.500 (83.831)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3924 (2.0137)	Acc@1 53.125 (54.402)	Acc@5 75.000 (83.690)
 * Acc@1 54.460 Acc@5 83.710
saving the best model!
==> training...
Epoch: [30][0/782]	Time 0.547 (0.547)	Data 0.472 (0.472)	Loss 14.6944 (14.6944)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
[epoch:31, iter:23461] Loss: 1.528, 10.732, 69.468, 440.738, 1.812
[epoch:31, iter:23481] Loss: 1.479, 10.739, 68.772, 446.514, 1.176
[epoch:31, iter:23501] Loss: 1.470, 10.714, 68.974, 446.686, 0.947
[epoch:31, iter:23521] Loss: 1.466, 10.690, 68.725, 446.400, 1.293
[epoch:31, iter:23541] Loss: 1.469, 10.696, 68.779, 446.609, 1.490
Epoch: [30][100/782]	Time 0.090 (0.086)	Data 0.003 (0.007)	Loss 13.5579 (14.2791)	Acc@1 56.250 (60.381)	Acc@5 92.188 (88.645)
[epoch:31, iter:23561] Loss: 1.466, 10.715, 68.552, 445.794, 1.201
[epoch:31, iter:23581] Loss: 1.466, 10.691, 68.215, 445.368, 1.452
[epoch:31, iter:23601] Loss: 1.469, 10.684, 68.180, 445.039, 1.640
[epoch:31, iter:23621] Loss: 1.468, 10.704, 68.295, 445.104, 1.310
[epoch:31, iter:23641] Loss: 1.466, 10.713, 68.246, 445.014, 1.473
Epoch: [30][200/782]	Time 0.062 (0.082)	Data 0.002 (0.005)	Loss 13.6430 (14.1975)	Acc@1 65.625 (60.386)	Acc@5 87.500 (88.363)
[epoch:31, iter:23661] Loss: 1.467, 10.716, 68.264, 445.028, 1.392
[epoch:31, iter:23681] Loss: 1.465, 10.706, 68.211, 444.877, 1.470
[epoch:31, iter:23701] Loss: 1.465, 10.709, 68.160, 444.742, 1.523
[epoch:31, iter:23721] Loss: 1.464, 10.714, 68.067, 444.694, 1.352
[epoch:31, iter:23741] Loss: 1.462, 10.702, 68.046, 444.751, 1.572
Epoch: [30][300/782]	Time 0.089 (0.082)	Data 0.003 (0.004)	Loss 14.7482 (14.1620)	Acc@1 54.688 (60.813)	Acc@5 89.062 (88.512)
[epoch:31, iter:23761] Loss: 1.461, 10.700, 68.052, 444.857, 1.470
[epoch:31, iter:23781] Loss: 1.460, 10.701, 68.066, 444.888, 1.412
[epoch:31, iter:23801] Loss: 1.458, 10.698, 68.037, 444.810, 1.124
[epoch:31, iter:23821] Loss: 1.457, 10.693, 67.972, 444.620, 1.086
[epoch:31, iter:23841] Loss: 1.457, 10.687, 67.947, 444.480, 1.210
Epoch: [30][400/782]	Time 0.094 (0.081)	Data 0.003 (0.004)	Loss 14.1969 (14.1470)	Acc@1 51.562 (60.973)	Acc@5 84.375 (88.443)
[epoch:31, iter:23861] Loss: 1.457, 10.684, 67.978, 444.475, 1.631
[epoch:31, iter:23881] Loss: 1.458, 10.687, 67.998, 444.496, 1.935
[epoch:31, iter:23901] Loss: 1.457, 10.684, 67.970, 444.323, 1.356
[epoch:31, iter:23921] Loss: 1.458, 10.691, 67.979, 444.382, 1.581
[epoch:31, iter:23941] Loss: 1.457, 10.691, 67.995, 444.404, 1.912
Epoch: [30][500/782]	Time 0.092 (0.081)	Data 0.003 (0.003)	Loss 12.7603 (14.1453)	Acc@1 76.562 (60.981)	Acc@5 98.438 (88.495)
[epoch:31, iter:23961] Loss: 1.456, 10.688, 67.989, 444.382, 0.890
[epoch:31, iter:23981] Loss: 1.455, 10.683, 67.935, 444.216, 2.126
[epoch:31, iter:24001] Loss: 1.455, 10.680, 67.956, 444.270, 1.748
[epoch:31, iter:24021] Loss: 1.455, 10.685, 67.969, 444.399, 1.494
[epoch:31, iter:24041] Loss: 1.455, 10.687, 67.945, 444.439, 1.511
Epoch: [30][600/782]	Time 0.086 (0.081)	Data 0.003 (0.003)	Loss 14.0909 (14.1477)	Acc@1 57.812 (60.727)	Acc@5 85.938 (88.449)
[epoch:31, iter:24061] Loss: 1.454, 10.686, 67.941, 444.462, 1.576
[epoch:31, iter:24081] Loss: 1.455, 10.684, 67.966, 444.505, 1.286
[epoch:31, iter:24101] Loss: 1.456, 10.689, 67.982, 444.595, 1.346
[epoch:31, iter:24121] Loss: 1.457, 10.693, 68.027, 444.722, 1.543
[epoch:31, iter:24141] Loss: 1.458, 10.696, 68.045, 444.768, 1.381
Epoch: [30][700/782]	Time 0.068 (0.080)	Data 0.002 (0.003)	Loss 13.7551 (14.1765)	Acc@1 67.188 (60.612)	Acc@5 90.625 (88.456)
[epoch:31, iter:24161] Loss: 1.458, 10.695, 68.032, 444.787, 1.330
[epoch:31, iter:24181] Loss: 1.457, 10.691, 68.012, 444.665, 1.215
[epoch:31, iter:24201] Loss: 1.457, 10.691, 68.025, 444.685, 1.235
[epoch:31, iter:24221] Loss: 1.457, 10.690, 68.022, 444.742, 1.283
[epoch:31, iter:24241] Loss: 1.456, 10.682, 67.989, 444.645, 1.229
 * Acc@1 60.636 Acc@5 88.438
epoch 30, total time 61.80
Test: [0/313]	Time 0.252 (0.252)	Loss 2.4582 (2.4582)	Acc@1 56.250 (56.250)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.009 (0.009)	Loss 2.1227 (2.0063)	Acc@1 53.125 (53.465)	Acc@5 87.500 (83.509)
Test: [200/313]	Time 0.010 (0.007)	Loss 1.2936 (2.0129)	Acc@1 56.250 (53.156)	Acc@5 93.750 (83.380)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.0687 (2.0219)	Acc@1 46.875 (53.592)	Acc@5 84.375 (83.119)
 * Acc@1 53.740 Acc@5 83.220
==> training...
Epoch: [31][0/782]	Time 0.610 (0.610)	Data 0.518 (0.518)	Loss 13.8638 (13.8638)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
[epoch:32, iter:24243] Loss: 1.387, 10.947, 66.875, 445.446, 1.341
[epoch:32, iter:24263] Loss: 1.443, 10.613, 66.868, 443.774, 1.245
[epoch:32, iter:24283] Loss: 1.430, 10.645, 66.728, 442.252, 1.678
[epoch:32, iter:24303] Loss: 1.441, 10.678, 67.269, 443.781, 1.331
[epoch:32, iter:24323] Loss: 1.445, 10.668, 67.350, 444.080, 1.563
Epoch: [31][100/782]	Time 0.080 (0.083)	Data 0.002 (0.007)	Loss 13.8289 (14.0180)	Acc@1 60.938 (61.092)	Acc@5 92.188 (88.459)
[epoch:32, iter:24343] Loss: 1.444, 10.639, 67.311, 443.205, 1.471
[epoch:32, iter:24363] Loss: 1.447, 10.658, 67.547, 443.456, 1.615
[epoch:32, iter:24383] Loss: 1.447, 10.638, 67.517, 442.697, 1.804
[epoch:32, iter:24403] Loss: 1.444, 10.639, 67.496, 442.574, 1.454
[epoch:32, iter:24423] Loss: 1.443, 10.621, 67.406, 442.331, 1.741
Epoch: [31][200/782]	Time 0.066 (0.079)	Data 0.002 (0.005)	Loss 12.7311 (13.9710)	Acc@1 78.125 (61.466)	Acc@5 96.875 (88.720)
[epoch:32, iter:24443] Loss: 1.444, 10.612, 67.332, 442.315, 0.827
[epoch:32, iter:24463] Loss: 1.446, 10.605, 67.401, 442.698, 1.332
[epoch:32, iter:24483] Loss: 1.448, 10.622, 67.529, 443.180, 1.471
[epoch:32, iter:24503] Loss: 1.448, 10.615, 67.531, 443.242, 1.524
[epoch:32, iter:24523] Loss: 1.448, 10.619, 67.506, 443.314, 1.604
Epoch: [31][300/782]	Time 0.069 (0.077)	Data 0.002 (0.004)	Loss 13.1931 (14.0294)	Acc@1 67.188 (61.348)	Acc@5 96.875 (88.668)
[epoch:32, iter:24543] Loss: 1.450, 10.614, 67.499, 443.178, 0.945
[epoch:32, iter:24563] Loss: 1.451, 10.616, 67.490, 443.276, 1.477
[epoch:32, iter:24583] Loss: 1.450, 10.615, 67.479, 443.349, 1.583
[epoch:32, iter:24603] Loss: 1.449, 10.617, 67.423, 443.248, 1.655
[epoch:32, iter:24623] Loss: 1.449, 10.617, 67.459, 443.378, 1.611
Epoch: [31][400/782]	Time 0.064 (0.077)	Data 0.002 (0.004)	Loss 14.9294 (14.0620)	Acc@1 53.125 (61.167)	Acc@5 81.250 (88.540)
[epoch:32, iter:24643] Loss: 1.450, 10.626, 67.530, 443.509, 2.017
[epoch:32, iter:24663] Loss: 1.450, 10.629, 67.574, 443.551, 1.333
[epoch:32, iter:24683] Loss: 1.451, 10.634, 67.634, 443.623, 1.474
[epoch:32, iter:24703] Loss: 1.451, 10.635, 67.644, 443.666, 1.582
[epoch:32, iter:24723] Loss: 1.451, 10.634, 67.669, 443.613, 1.393
Epoch: [31][500/782]	Time 0.085 (0.077)	Data 0.003 (0.003)	Loss 13.8145 (14.0907)	Acc@1 60.938 (60.922)	Acc@5 92.188 (88.539)
[epoch:32, iter:24743] Loss: 1.450, 10.632, 67.673, 443.695, 1.152
[epoch:32, iter:24763] Loss: 1.449, 10.628, 67.682, 443.741, 1.457
[epoch:32, iter:24783] Loss: 1.449, 10.633, 67.692, 443.887, 2.124
[epoch:32, iter:24803] Loss: 1.448, 10.638, 67.684, 443.857, 1.604
[epoch:32, iter:24823] Loss: 1.449, 10.639, 67.699, 443.997, 1.624
Epoch: [31][600/782]	Time 0.076 (0.076)	Data 0.002 (0.003)	Loss 14.5249 (14.1155)	Acc@1 57.812 (60.730)	Acc@5 87.500 (88.423)
[epoch:32, iter:24843] Loss: 1.449, 10.638, 67.700, 443.995, 1.795
[epoch:32, iter:24863] Loss: 1.449, 10.640, 67.667, 444.031, 1.710
[epoch:32, iter:24883] Loss: 1.449, 10.639, 67.683, 444.070, 1.927
[epoch:32, iter:24903] Loss: 1.449, 10.637, 67.677, 444.068, 1.739
[epoch:32, iter:24923] Loss: 1.450, 10.638, 67.695, 444.159, 1.492
Epoch: [31][700/782]	Time 0.076 (0.076)	Data 0.003 (0.003)	Loss 13.4132 (14.1242)	Acc@1 65.625 (60.646)	Acc@5 95.312 (88.380)
[epoch:32, iter:24943] Loss: 1.449, 10.637, 67.677, 444.084, 1.019
[epoch:32, iter:24963] Loss: 1.449, 10.636, 67.671, 444.062, 1.415
[epoch:32, iter:24983] Loss: 1.449, 10.633, 67.670, 444.081, 1.716
[epoch:32, iter:25003] Loss: 1.449, 10.631, 67.679, 444.068, 1.305
[epoch:32, iter:25023] Loss: 1.449, 10.629, 67.677, 444.018, 1.159
 * Acc@1 60.656 Acc@5 88.358
epoch 31, total time 59.46
Test: [0/313]	Time 0.226 (0.226)	Loss 1.7001 (1.7001)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.8910 (1.9395)	Acc@1 50.000 (54.920)	Acc@5 84.375 (84.901)
Test: [200/313]	Time 0.007 (0.007)	Loss 1.6660 (1.9404)	Acc@1 59.375 (54.618)	Acc@5 84.375 (84.764)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.7299 (1.9468)	Acc@1 37.500 (54.610)	Acc@5 84.375 (84.697)
 * Acc@1 54.590 Acc@5 84.700
saving the best model!
==> training...
Epoch: [32][0/782]	Time 0.553 (0.553)	Data 0.471 (0.471)	Loss 14.0380 (14.0380)	Acc@1 64.062 (64.062)	Acc@5 92.188 (92.188)
[epoch:33, iter:25025] Loss: 1.371, 10.844, 67.312, 443.066, 1.482
[epoch:33, iter:25045] Loss: 1.422, 10.506, 66.648, 438.045, 1.336
[epoch:33, iter:25065] Loss: 1.434, 10.492, 67.258, 440.011, 1.573
[epoch:33, iter:25085] Loss: 1.431, 10.471, 67.145, 440.157, 1.155
[epoch:33, iter:25105] Loss: 1.437, 10.515, 67.448, 442.115, 1.184
Epoch: [32][100/782]	Time 0.083 (0.079)	Data 0.002 (0.007)	Loss 14.1581 (13.9657)	Acc@1 60.938 (61.726)	Acc@5 92.188 (89.310)
[epoch:33, iter:25125] Loss: 1.437, 10.541, 67.414, 442.079, 1.108
[epoch:33, iter:25145] Loss: 1.442, 10.543, 67.551, 442.303, 1.630
[epoch:33, iter:25165] Loss: 1.442, 10.544, 67.489, 442.092, 1.652
[epoch:33, iter:25185] Loss: 1.441, 10.547, 67.487, 442.154, 1.136
[epoch:33, iter:25205] Loss: 1.437, 10.533, 67.389, 442.078, 1.469
Epoch: [32][200/782]	Time 0.073 (0.079)	Data 0.002 (0.005)	Loss 14.1096 (13.9403)	Acc@1 73.438 (61.715)	Acc@5 95.312 (88.923)
[epoch:33, iter:25225] Loss: 1.436, 10.520, 67.301, 441.826, 1.108
[epoch:33, iter:25245] Loss: 1.438, 10.537, 67.403, 442.055, 1.625
[epoch:33, iter:25265] Loss: 1.439, 10.551, 67.531, 442.331, 1.565
[epoch:33, iter:25285] Loss: 1.441, 10.553, 67.621, 442.333, 1.275
[epoch:33, iter:25305] Loss: 1.443, 10.551, 67.691, 442.515, 1.301
Epoch: [32][300/782]	Time 0.073 (0.078)	Data 0.002 (0.004)	Loss 13.6155 (14.0180)	Acc@1 64.062 (61.275)	Acc@5 89.062 (88.907)
[epoch:33, iter:25325] Loss: 1.444, 10.554, 67.704, 442.595, 1.302
[epoch:33, iter:25345] Loss: 1.445, 10.562, 67.700, 442.574, 1.507
[epoch:33, iter:25365] Loss: 1.446, 10.571, 67.756, 442.828, 1.295
[epoch:33, iter:25385] Loss: 1.445, 10.577, 67.767, 442.825, 1.173
[epoch:33, iter:25405] Loss: 1.445, 10.578, 67.766, 442.917, 1.287
Epoch: [32][400/782]	Time 0.090 (0.078)	Data 0.003 (0.003)	Loss 14.5040 (14.0329)	Acc@1 53.125 (61.378)	Acc@5 85.938 (88.727)
[epoch:33, iter:25425] Loss: 1.446, 10.581, 67.734, 442.810, 1.743
[epoch:33, iter:25445] Loss: 1.445, 10.589, 67.719, 442.741, 1.552
[epoch:33, iter:25465] Loss: 1.446, 10.598, 67.704, 442.759, 1.548
[epoch:33, iter:25485] Loss: 1.445, 10.605, 67.703, 442.881, 1.697
[epoch:33, iter:25505] Loss: 1.445, 10.603, 67.666, 442.809, 1.440
Epoch: [32][500/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 15.7827 (14.0317)	Acc@1 56.250 (61.337)	Acc@5 78.125 (88.676)
[epoch:33, iter:25525] Loss: 1.445, 10.600, 67.655, 442.795, 2.128
[epoch:33, iter:25545] Loss: 1.445, 10.597, 67.628, 442.798, 1.046
[epoch:33, iter:25565] Loss: 1.445, 10.598, 67.635, 442.874, 1.316
[epoch:33, iter:25585] Loss: 1.445, 10.599, 67.641, 442.866, 1.618
[epoch:33, iter:25605] Loss: 1.446, 10.601, 67.657, 442.970, 1.381
Epoch: [32][600/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 13.7237 (14.0670)	Acc@1 68.750 (61.039)	Acc@5 90.625 (88.524)
[epoch:33, iter:25625] Loss: 1.446, 10.608, 67.677, 443.090, 1.063
[epoch:33, iter:25645] Loss: 1.446, 10.608, 67.730, 443.242, 1.244
[epoch:33, iter:25665] Loss: 1.446, 10.612, 67.719, 443.258, 1.530
[epoch:33, iter:25685] Loss: 1.446, 10.613, 67.754, 443.366, 1.421
[epoch:33, iter:25705] Loss: 1.447, 10.616, 67.794, 443.416, 1.516
Epoch: [32][700/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.4210 (14.0863)	Acc@1 59.375 (61.000)	Acc@5 95.312 (88.492)
[epoch:33, iter:25725] Loss: 1.447, 10.617, 67.787, 443.389, 1.196
[epoch:33, iter:25745] Loss: 1.446, 10.614, 67.780, 443.405, 1.476
[epoch:33, iter:25765] Loss: 1.445, 10.612, 67.788, 443.423, 1.416
[epoch:33, iter:25785] Loss: 1.445, 10.611, 67.790, 443.464, 1.146
[epoch:33, iter:25805] Loss: 1.445, 10.610, 67.785, 443.498, 1.308
 * Acc@1 60.844 Acc@5 88.478
epoch 32, total time 61.38
Test: [0/313]	Time 0.290 (0.290)	Loss 2.2379 (2.2379)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.2548 (1.8928)	Acc@1 53.125 (56.281)	Acc@5 87.500 (86.046)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.9965 (1.9071)	Acc@1 75.000 (55.271)	Acc@5 93.750 (85.572)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.9551 (1.9286)	Acc@1 43.750 (55.419)	Acc@5 84.375 (85.289)
 * Acc@1 55.470 Acc@5 85.490
saving the best model!
==> training...
Epoch: [33][0/782]	Time 0.509 (0.509)	Data 0.442 (0.442)	Loss 14.3598 (14.3598)	Acc@1 65.625 (65.625)	Acc@5 89.062 (89.062)
[epoch:34, iter:25807] Loss: 1.430, 10.890, 71.842, 451.476, 1.179
[epoch:34, iter:25827] Loss: 1.480, 10.839, 67.998, 444.291, 1.794
[epoch:34, iter:25847] Loss: 1.470, 10.863, 67.689, 444.462, 1.524
[epoch:34, iter:25867] Loss: 1.471, 10.828, 67.997, 445.481, 1.573
[epoch:34, iter:25887] Loss: 1.469, 10.788, 67.946, 445.041, 1.076
Epoch: [33][100/782]	Time 0.075 (0.080)	Data 0.002 (0.007)	Loss 13.8819 (14.1467)	Acc@1 67.188 (61.293)	Acc@5 90.625 (88.846)
[epoch:34, iter:25907] Loss: 1.460, 10.771, 67.785, 444.832, 1.160
[epoch:34, iter:25927] Loss: 1.453, 10.743, 67.661, 444.090, 1.580
[epoch:34, iter:25947] Loss: 1.452, 10.711, 67.589, 443.582, 1.642
[epoch:34, iter:25967] Loss: 1.447, 10.687, 67.557, 443.143, 1.783
[epoch:34, iter:25987] Loss: 1.443, 10.685, 67.534, 442.985, 1.485
Epoch: [33][200/782]	Time 0.087 (0.079)	Data 0.003 (0.004)	Loss 13.4157 (14.0042)	Acc@1 71.875 (61.676)	Acc@5 93.750 (88.868)
[epoch:34, iter:26007] Loss: 1.441, 10.683, 67.494, 442.733, 1.149
[epoch:34, iter:26027] Loss: 1.445, 10.681, 67.607, 443.112, 1.359
[epoch:34, iter:26047] Loss: 1.446, 10.668, 67.635, 443.133, 1.028
[epoch:34, iter:26067] Loss: 1.445, 10.657, 67.562, 442.806, 1.178
[epoch:34, iter:26087] Loss: 1.444, 10.660, 67.548, 442.654, 1.521
Epoch: [33][300/782]	Time 0.058 (0.078)	Data 0.002 (0.004)	Loss 14.9232 (14.0211)	Acc@1 51.562 (61.581)	Acc@5 82.812 (88.803)
[epoch:34, iter:26107] Loss: 1.444, 10.658, 67.566, 442.795, 1.903
[epoch:34, iter:26127] Loss: 1.443, 10.662, 67.589, 442.934, 1.560
[epoch:34, iter:26147] Loss: 1.442, 10.663, 67.564, 442.872, 1.379
[epoch:34, iter:26167] Loss: 1.441, 10.654, 67.571, 442.784, 1.412
[epoch:34, iter:26187] Loss: 1.442, 10.657, 67.583, 442.946, 1.273
Epoch: [33][400/782]	Time 0.078 (0.079)	Data 0.002 (0.003)	Loss 13.2158 (14.0454)	Acc@1 75.000 (61.238)	Acc@5 95.312 (88.649)
[epoch:34, iter:26207] Loss: 1.442, 10.654, 67.598, 443.093, 0.931
[epoch:34, iter:26227] Loss: 1.442, 10.650, 67.593, 443.042, 1.347
[epoch:34, iter:26247] Loss: 1.443, 10.649, 67.575, 443.090, 1.474
[epoch:34, iter:26267] Loss: 1.444, 10.646, 67.571, 443.099, 1.529
[epoch:34, iter:26287] Loss: 1.445, 10.648, 67.547, 443.050, 1.463
Epoch: [33][500/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 14.4102 (14.0516)	Acc@1 59.375 (61.118)	Acc@5 85.938 (88.623)
[epoch:34, iter:26307] Loss: 1.445, 10.648, 67.561, 443.115, 1.537
[epoch:34, iter:26327] Loss: 1.447, 10.653, 67.578, 443.188, 1.214
[epoch:34, iter:26347] Loss: 1.447, 10.647, 67.565, 443.195, 1.635
[epoch:34, iter:26367] Loss: 1.447, 10.641, 67.559, 443.151, 0.982
[epoch:34, iter:26387] Loss: 1.447, 10.642, 67.591, 443.155, 1.276
Epoch: [33][600/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.6919 (14.0633)	Acc@1 64.062 (61.008)	Acc@5 90.625 (88.649)
[epoch:34, iter:26407] Loss: 1.448, 10.646, 67.598, 443.191, 1.483
[epoch:34, iter:26427] Loss: 1.448, 10.647, 67.568, 443.224, 1.639
[epoch:34, iter:26447] Loss: 1.448, 10.647, 67.566, 443.191, 1.284
[epoch:34, iter:26467] Loss: 1.448, 10.650, 67.606, 443.353, 1.808
[epoch:34, iter:26487] Loss: 1.448, 10.648, 67.631, 443.395, 1.274
Epoch: [33][700/782]	Time 0.062 (0.077)	Data 0.002 (0.003)	Loss 13.5692 (14.0808)	Acc@1 64.062 (60.857)	Acc@5 92.188 (88.586)
[epoch:34, iter:26507] Loss: 1.448, 10.651, 67.619, 443.397, 1.287
[epoch:34, iter:26527] Loss: 1.448, 10.652, 67.615, 443.428, 1.491
[epoch:34, iter:26547] Loss: 1.448, 10.651, 67.601, 443.369, 1.680
[epoch:34, iter:26567] Loss: 1.448, 10.654, 67.610, 443.333, 1.229
[epoch:34, iter:26587] Loss: 1.448, 10.656, 67.623, 443.335, 1.375
 * Acc@1 60.794 Acc@5 88.512
epoch 33, total time 60.59
Test: [0/313]	Time 0.255 (0.255)	Loss 1.7877 (1.7877)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.6954 (1.8567)	Acc@1 56.250 (56.157)	Acc@5 90.625 (85.303)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.1745 (1.8769)	Acc@1 71.875 (55.955)	Acc@5 90.625 (84.997)
Test: [300/313]	Time 0.010 (0.008)	Loss 2.1766 (1.8592)	Acc@1 53.125 (56.167)	Acc@5 87.500 (85.019)
 * Acc@1 56.170 Acc@5 85.000
saving the best model!
==> training...
Epoch: [34][0/782]	Time 0.547 (0.547)	Data 0.468 (0.468)	Loss 14.3847 (14.3847)	Acc@1 54.688 (54.688)	Acc@5 81.250 (81.250)
[epoch:35, iter:26589] Loss: 1.383, 11.338, 69.834, 441.767, 1.848
[epoch:35, iter:26609] Loss: 1.436, 10.549, 68.029, 442.707, 1.662
[epoch:35, iter:26629] Loss: 1.430, 10.574, 67.519, 442.363, 0.959
[epoch:35, iter:26649] Loss: 1.426, 10.567, 67.375, 441.082, 1.779
[epoch:35, iter:26669] Loss: 1.427, 10.589, 67.314, 440.772, 1.647
Epoch: [34][100/782]	Time 0.089 (0.083)	Data 0.003 (0.007)	Loss 14.7460 (13.9463)	Acc@1 62.500 (61.278)	Acc@5 82.812 (88.908)
[epoch:35, iter:26689] Loss: 1.430, 10.574, 67.331, 441.252, 1.578
[epoch:35, iter:26709] Loss: 1.433, 10.585, 67.289, 441.146, 1.362
[epoch:35, iter:26729] Loss: 1.432, 10.579, 67.221, 441.142, 1.365
[epoch:35, iter:26749] Loss: 1.431, 10.574, 67.251, 441.332, 1.211
[epoch:35, iter:26769] Loss: 1.431, 10.594, 67.382, 441.710, 1.256
Epoch: [34][200/782]	Time 0.071 (0.080)	Data 0.002 (0.005)	Loss 13.8991 (13.9567)	Acc@1 64.062 (61.660)	Acc@5 89.062 (88.759)
[epoch:35, iter:26789] Loss: 1.431, 10.590, 67.431, 442.157, 1.477
[epoch:35, iter:26809] Loss: 1.432, 10.587, 67.454, 442.239, 1.491
[epoch:35, iter:26829] Loss: 1.431, 10.574, 67.448, 442.347, 1.945
[epoch:35, iter:26849] Loss: 1.432, 10.578, 67.488, 442.617, 1.889
[epoch:35, iter:26869] Loss: 1.432, 10.587, 67.493, 442.534, 1.582
Epoch: [34][300/782]	Time 0.081 (0.077)	Data 0.003 (0.004)	Loss 13.7165 (14.0152)	Acc@1 65.625 (61.493)	Acc@5 89.062 (88.735)
[epoch:35, iter:26889] Loss: 1.434, 10.599, 67.561, 442.692, 1.314
[epoch:35, iter:26909] Loss: 1.432, 10.603, 67.564, 442.763, 1.411
[epoch:35, iter:26929] Loss: 1.434, 10.603, 67.578, 442.774, 1.272
[epoch:35, iter:26949] Loss: 1.434, 10.603, 67.584, 442.743, 1.507
[epoch:35, iter:26969] Loss: 1.434, 10.595, 67.622, 442.796, 1.375
Epoch: [34][400/782]	Time 0.061 (0.076)	Data 0.002 (0.003)	Loss 14.5479 (14.0271)	Acc@1 59.375 (61.421)	Acc@5 87.500 (88.965)
[epoch:35, iter:26989] Loss: 1.434, 10.597, 67.650, 442.864, 1.463
[epoch:35, iter:27009] Loss: 1.434, 10.596, 67.653, 442.833, 1.981
[epoch:35, iter:27029] Loss: 1.435, 10.599, 67.648, 442.791, 1.172
[epoch:35, iter:27049] Loss: 1.435, 10.601, 67.650, 442.718, 1.436
[epoch:35, iter:27069] Loss: 1.435, 10.604, 67.606, 442.575, 1.519
Epoch: [34][500/782]	Time 0.087 (0.076)	Data 0.003 (0.003)	Loss 14.5884 (14.0282)	Acc@1 56.250 (61.374)	Acc@5 90.625 (88.885)
[epoch:35, iter:27089] Loss: 1.436, 10.613, 67.625, 442.605, 1.465
[epoch:35, iter:27109] Loss: 1.437, 10.617, 67.633, 442.624, 1.713
[epoch:35, iter:27129] Loss: 1.438, 10.617, 67.624, 442.678, 1.441
[epoch:35, iter:27149] Loss: 1.437, 10.613, 67.592, 442.608, 1.484
[epoch:35, iter:27169] Loss: 1.437, 10.609, 67.593, 442.526, 1.318
Epoch: [34][600/782]	Time 0.085 (0.077)	Data 0.003 (0.003)	Loss 13.8616 (14.0224)	Acc@1 53.125 (61.231)	Acc@5 87.500 (88.935)
[epoch:35, iter:27189] Loss: 1.438, 10.610, 67.589, 442.453, 1.604
[epoch:35, iter:27209] Loss: 1.438, 10.609, 67.620, 442.482, 1.355
[epoch:35, iter:27229] Loss: 1.439, 10.615, 67.629, 442.597, 1.417
[epoch:35, iter:27249] Loss: 1.440, 10.615, 67.617, 442.665, 1.249
[epoch:35, iter:27269] Loss: 1.440, 10.612, 67.611, 442.725, 1.310
Epoch: [34][700/782]	Time 0.085 (0.077)	Data 0.003 (0.003)	Loss 13.7435 (14.0447)	Acc@1 65.625 (60.966)	Acc@5 89.062 (88.739)
[epoch:35, iter:27289] Loss: 1.441, 10.613, 67.585, 442.655, 1.167
[epoch:35, iter:27309] Loss: 1.440, 10.610, 67.579, 442.637, 0.909
[epoch:35, iter:27329] Loss: 1.440, 10.612, 67.574, 442.604, 1.492
[epoch:35, iter:27349] Loss: 1.440, 10.608, 67.582, 442.600, 1.577
[epoch:35, iter:27369] Loss: 1.440, 10.607, 67.563, 442.524, 1.141
 * Acc@1 61.086 Acc@5 88.702
epoch 34, total time 60.91
Test: [0/313]	Time 0.259 (0.259)	Loss 2.2441 (2.2441)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.2248 (2.3826)	Acc@1 43.750 (49.536)	Acc@5 90.625 (80.569)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.1801 (2.3916)	Acc@1 71.875 (49.596)	Acc@5 90.625 (80.457)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5395 (2.3777)	Acc@1 46.875 (49.637)	Acc@5 75.000 (80.440)
 * Acc@1 49.730 Acc@5 80.490
==> training...
Epoch: [35][0/782]	Time 0.575 (0.575)	Data 0.494 (0.494)	Loss 14.4944 (14.4944)	Acc@1 59.375 (59.375)	Acc@5 93.750 (93.750)
[epoch:36, iter:27371] Loss: 1.461, 10.550, 70.737, 453.769, 1.395
[epoch:36, iter:27391] Loss: 1.447, 10.816, 68.440, 446.952, 1.399
[epoch:36, iter:27411] Loss: 1.448, 10.680, 67.759, 441.962, 1.012
[epoch:36, iter:27431] Loss: 1.445, 10.608, 67.324, 440.584, 1.272
[epoch:36, iter:27451] Loss: 1.447, 10.651, 67.126, 440.769, 1.341
Epoch: [35][100/782]	Time 0.072 (0.079)	Data 0.002 (0.007)	Loss 13.3721 (13.8008)	Acc@1 71.875 (62.252)	Acc@5 89.062 (89.836)
[epoch:36, iter:27471] Loss: 1.441, 10.627, 66.954, 440.550, 1.123
[epoch:36, iter:27491] Loss: 1.431, 10.585, 66.857, 440.255, 1.515
[epoch:36, iter:27511] Loss: 1.435, 10.576, 66.994, 440.836, 1.070
[epoch:36, iter:27531] Loss: 1.437, 10.596, 67.067, 441.286, 1.477
[epoch:36, iter:27551] Loss: 1.441, 10.599, 67.075, 441.516, 1.292
Epoch: [35][200/782]	Time 0.061 (0.077)	Data 0.002 (0.005)	Loss 12.9709 (13.9040)	Acc@1 71.875 (61.886)	Acc@5 92.188 (89.280)
[epoch:36, iter:27571] Loss: 1.441, 10.595, 67.094, 441.489, 0.987
[epoch:36, iter:27591] Loss: 1.439, 10.591, 67.112, 441.608, 1.817
[epoch:36, iter:27611] Loss: 1.438, 10.586, 67.046, 441.575, 1.305
[epoch:36, iter:27631] Loss: 1.437, 10.580, 67.051, 441.565, 1.380
[epoch:36, iter:27651] Loss: 1.438, 10.584, 67.074, 441.638, 1.830
Epoch: [35][300/782]	Time 0.090 (0.076)	Data 0.003 (0.004)	Loss 13.3897 (13.9156)	Acc@1 65.625 (61.534)	Acc@5 92.188 (89.130)
[epoch:36, iter:27671] Loss: 1.438, 10.586, 67.099, 441.736, 1.227
[epoch:36, iter:27691] Loss: 1.440, 10.588, 67.210, 441.903, 1.410
[epoch:36, iter:27711] Loss: 1.440, 10.593, 67.238, 442.044, 1.426
[epoch:36, iter:27731] Loss: 1.441, 10.593, 67.262, 442.106, 1.133
[epoch:36, iter:27751] Loss: 1.441, 10.595, 67.282, 442.121, 1.487
Epoch: [35][400/782]	Time 0.065 (0.076)	Data 0.002 (0.003)	Loss 13.4780 (13.9601)	Acc@1 62.500 (61.479)	Acc@5 93.750 (88.953)
[epoch:36, iter:27771] Loss: 1.440, 10.595, 67.273, 441.970, 1.207
[epoch:36, iter:27791] Loss: 1.442, 10.592, 67.319, 442.098, 1.473
[epoch:36, iter:27811] Loss: 1.440, 10.589, 67.311, 442.044, 1.019
[epoch:36, iter:27831] Loss: 1.440, 10.587, 67.300, 442.084, 1.032
[epoch:36, iter:27851] Loss: 1.442, 10.588, 67.338, 442.102, 1.627
Epoch: [35][500/782]	Time 0.068 (0.076)	Data 0.002 (0.003)	Loss 13.0226 (13.9676)	Acc@1 67.188 (61.527)	Acc@5 89.062 (89.019)
[epoch:36, iter:27871] Loss: 1.441, 10.588, 67.358, 442.062, 1.322
[epoch:36, iter:27891] Loss: 1.441, 10.587, 67.397, 442.084, 1.142
[epoch:36, iter:27911] Loss: 1.441, 10.582, 67.372, 442.008, 1.063
[epoch:36, iter:27931] Loss: 1.441, 10.582, 67.366, 442.072, 1.115
[epoch:36, iter:27951] Loss: 1.439, 10.584, 67.337, 442.027, 1.573
Epoch: [35][600/782]	Time 0.075 (0.077)	Data 0.002 (0.003)	Loss 14.7366 (13.9749)	Acc@1 53.125 (61.476)	Acc@5 89.062 (88.979)
[epoch:36, iter:27971] Loss: 1.440, 10.583, 67.338, 442.082, 1.680
[epoch:36, iter:27991] Loss: 1.440, 10.583, 67.356, 442.162, 1.191
[epoch:36, iter:28011] Loss: 1.440, 10.584, 67.336, 442.070, 1.517
[epoch:36, iter:28031] Loss: 1.440, 10.582, 67.333, 442.092, 1.584
[epoch:36, iter:28051] Loss: 1.440, 10.583, 67.330, 442.142, 1.288
Epoch: [35][700/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 14.2081 (13.9841)	Acc@1 60.938 (61.430)	Acc@5 93.750 (88.815)
[epoch:36, iter:28071] Loss: 1.440, 10.581, 67.348, 442.181, 1.049
[epoch:36, iter:28091] Loss: 1.440, 10.583, 67.370, 442.212, 1.585
[epoch:36, iter:28111] Loss: 1.441, 10.582, 67.390, 442.258, 1.537
[epoch:36, iter:28131] Loss: 1.440, 10.583, 67.422, 442.395, 1.705
[epoch:36, iter:28151] Loss: 1.440, 10.586, 67.421, 442.395, 1.588
 * Acc@1 61.340 Acc@5 88.744
epoch 35, total time 60.37
Test: [0/313]	Time 0.234 (0.234)	Loss 2.4851 (2.4851)	Acc@1 53.125 (53.125)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.9544 (2.2974)	Acc@1 56.250 (51.207)	Acc@5 90.625 (80.631)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.8797 (2.3273)	Acc@1 59.375 (50.622)	Acc@5 84.375 (79.913)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4661 (2.3318)	Acc@1 50.000 (50.457)	Acc@5 81.250 (79.797)
 * Acc@1 50.480 Acc@5 79.850
==> training...
Epoch: [36][0/782]	Time 0.475 (0.475)	Data 0.410 (0.410)	Loss 13.4229 (13.4229)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
[epoch:37, iter:28153] Loss: 1.464, 10.164, 67.925, 440.810, 1.095
[epoch:37, iter:28173] Loss: 1.459, 10.620, 67.149, 441.710, 1.457
[epoch:37, iter:28193] Loss: 1.451, 10.590, 66.641, 439.978, 1.289
[epoch:37, iter:28213] Loss: 1.448, 10.575, 66.861, 440.380, 1.492
[epoch:37, iter:28233] Loss: 1.441, 10.560, 66.886, 440.717, 1.279
Epoch: [36][100/782]	Time 0.089 (0.079)	Data 0.003 (0.006)	Loss 14.0684 (13.8366)	Acc@1 59.375 (62.005)	Acc@5 87.500 (88.954)
[epoch:37, iter:28253] Loss: 1.439, 10.561, 66.928, 440.428, 1.632
[epoch:37, iter:28273] Loss: 1.442, 10.586, 67.004, 440.565, 1.477
[epoch:37, iter:28293] Loss: 1.441, 10.587, 67.072, 440.820, 1.129
[epoch:37, iter:28313] Loss: 1.440, 10.583, 67.176, 440.984, 1.452
[epoch:37, iter:28333] Loss: 1.437, 10.573, 67.097, 440.835, 1.414
Epoch: [36][200/782]	Time 0.078 (0.076)	Data 0.003 (0.004)	Loss 13.9082 (13.8649)	Acc@1 70.312 (61.940)	Acc@5 87.500 (88.752)
[epoch:37, iter:28353] Loss: 1.436, 10.555, 67.008, 440.556, 1.217
[epoch:37, iter:28373] Loss: 1.436, 10.552, 67.149, 441.203, 1.548
[epoch:37, iter:28393] Loss: 1.438, 10.565, 67.274, 441.413, 1.636
[epoch:37, iter:28413] Loss: 1.440, 10.571, 67.362, 441.565, 1.081
[epoch:37, iter:28433] Loss: 1.438, 10.575, 67.344, 441.603, 1.443
Epoch: [36][300/782]	Time 0.071 (0.074)	Data 0.002 (0.003)	Loss 14.4463 (13.9729)	Acc@1 57.812 (61.254)	Acc@5 84.375 (88.710)
[epoch:37, iter:28453] Loss: 1.439, 10.582, 67.349, 441.591, 1.493
[epoch:37, iter:28473] Loss: 1.440, 10.584, 67.400, 441.619, 1.538
[epoch:37, iter:28493] Loss: 1.440, 10.585, 67.351, 441.466, 1.243
[epoch:37, iter:28513] Loss: 1.441, 10.581, 67.413, 441.621, 1.826
[epoch:37, iter:28533] Loss: 1.441, 10.580, 67.394, 441.568, 0.902
Epoch: [36][400/782]	Time 0.070 (0.075)	Data 0.002 (0.003)	Loss 14.1137 (13.9927)	Acc@1 57.812 (61.070)	Acc@5 81.250 (88.704)
[epoch:37, iter:28553] Loss: 1.441, 10.576, 67.418, 441.756, 1.649
[epoch:37, iter:28573] Loss: 1.440, 10.573, 67.397, 441.694, 1.219
[epoch:37, iter:28593] Loss: 1.440, 10.567, 67.407, 441.670, 1.397
[epoch:37, iter:28613] Loss: 1.439, 10.563, 67.408, 441.483, 1.594
[epoch:37, iter:28633] Loss: 1.439, 10.567, 67.441, 441.669, 1.263
Epoch: [36][500/782]	Time 0.078 (0.074)	Data 0.002 (0.003)	Loss 14.4661 (14.0002)	Acc@1 65.625 (61.287)	Acc@5 89.062 (88.716)
[epoch:37, iter:28653] Loss: 1.439, 10.574, 67.429, 441.696, 1.374
[epoch:37, iter:28673] Loss: 1.439, 10.567, 67.421, 441.651, 1.594
[epoch:37, iter:28693] Loss: 1.440, 10.565, 67.440, 441.792, 1.669
[epoch:37, iter:28713] Loss: 1.439, 10.565, 67.448, 441.779, 1.683
[epoch:37, iter:28733] Loss: 1.440, 10.569, 67.456, 441.876, 1.270
Epoch: [36][600/782]	Time 0.088 (0.075)	Data 0.003 (0.003)	Loss 14.3913 (14.0116)	Acc@1 59.375 (61.294)	Acc@5 84.375 (88.704)
[epoch:37, iter:28753] Loss: 1.440, 10.570, 67.469, 441.965, 1.608
[epoch:37, iter:28773] Loss: 1.441, 10.574, 67.469, 441.949, 1.542
[epoch:37, iter:28793] Loss: 1.441, 10.579, 67.452, 441.902, 1.490
[epoch:37, iter:28813] Loss: 1.440, 10.580, 67.435, 441.909, 1.110
[epoch:37, iter:28833] Loss: 1.439, 10.574, 67.408, 441.875, 1.321
Epoch: [36][700/782]	Time 0.060 (0.075)	Data 0.002 (0.003)	Loss 14.8688 (14.0091)	Acc@1 65.625 (61.310)	Acc@5 92.188 (88.737)
[epoch:37, iter:28853] Loss: 1.440, 10.573, 67.420, 441.906, 1.405
[epoch:37, iter:28873] Loss: 1.439, 10.570, 67.397, 441.895, 1.651
[epoch:37, iter:28893] Loss: 1.439, 10.571, 67.400, 441.919, 1.595
[epoch:37, iter:28913] Loss: 1.439, 10.572, 67.415, 441.893, 1.497
[epoch:37, iter:28933] Loss: 1.439, 10.574, 67.438, 441.986, 1.389
 * Acc@1 61.336 Acc@5 88.682
epoch 36, total time 58.72
Test: [0/313]	Time 0.244 (0.244)	Loss 1.9475 (1.9475)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.8567 (1.9370)	Acc@1 46.875 (56.312)	Acc@5 84.375 (86.170)
Test: [200/313]	Time 0.008 (0.008)	Loss 1.3639 (1.9191)	Acc@1 59.375 (56.079)	Acc@5 96.875 (85.836)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.4234 (1.9136)	Acc@1 53.125 (56.354)	Acc@5 81.250 (85.828)
 * Acc@1 56.330 Acc@5 85.850
saving the best model!
==> training...
Epoch: [37][0/782]	Time 0.574 (0.574)	Data 0.500 (0.500)	Loss 13.0549 (13.0549)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
[epoch:38, iter:28935] Loss: 1.447, 10.445, 67.876, 420.375, 1.216
[epoch:38, iter:28955] Loss: 1.443, 10.694, 68.413, 439.643, 1.351
[epoch:38, iter:28975] Loss: 1.445, 10.746, 68.727, 442.775, 1.545
[epoch:38, iter:28995] Loss: 1.444, 10.739, 68.238, 442.737, 1.504
[epoch:38, iter:29015] Loss: 1.433, 10.662, 67.886, 441.899, 1.409
Epoch: [37][100/782]	Time 0.076 (0.086)	Data 0.003 (0.007)	Loss 13.8897 (13.9700)	Acc@1 62.500 (61.278)	Acc@5 90.625 (88.908)
[epoch:38, iter:29035] Loss: 1.432, 10.656, 67.694, 441.245, 1.268
[epoch:38, iter:29055] Loss: 1.430, 10.620, 67.821, 441.428, 1.213
[epoch:38, iter:29075] Loss: 1.434, 10.621, 67.784, 441.546, 1.279
[epoch:38, iter:29095] Loss: 1.434, 10.613, 67.608, 441.154, 1.427
[epoch:38, iter:29115] Loss: 1.436, 10.603, 67.533, 441.075, 1.134
Epoch: [37][200/782]	Time 0.083 (0.082)	Data 0.002 (0.005)	Loss 14.6002 (13.9498)	Acc@1 59.375 (61.248)	Acc@5 87.500 (88.798)
[epoch:38, iter:29135] Loss: 1.433, 10.598, 67.454, 441.153, 1.357
[epoch:38, iter:29155] Loss: 1.431, 10.584, 67.367, 441.263, 1.141
[epoch:38, iter:29175] Loss: 1.430, 10.581, 67.387, 441.477, 1.531
[epoch:38, iter:29195] Loss: 1.432, 10.582, 67.318, 441.175, 1.431
[epoch:38, iter:29215] Loss: 1.432, 10.580, 67.332, 441.299, 1.356
Epoch: [37][300/782]	Time 0.082 (0.079)	Data 0.002 (0.004)	Loss 13.8404 (13.9578)	Acc@1 60.938 (61.161)	Acc@5 95.312 (88.844)
[epoch:38, iter:29235] Loss: 1.434, 10.582, 67.326, 441.392, 1.223
[epoch:38, iter:29255] Loss: 1.434, 10.586, 67.336, 441.638, 1.580
[epoch:38, iter:29275] Loss: 1.435, 10.590, 67.333, 441.672, 1.529
[epoch:38, iter:29295] Loss: 1.435, 10.589, 67.295, 441.531, 1.592
[epoch:38, iter:29315] Loss: 1.435, 10.590, 67.304, 441.601, 1.496
Epoch: [37][400/782]	Time 0.071 (0.079)	Data 0.002 (0.004)	Loss 12.7388 (13.9538)	Acc@1 68.750 (61.054)	Acc@5 92.188 (88.969)
[epoch:38, iter:29335] Loss: 1.436, 10.588, 67.308, 441.509, 1.070
[epoch:38, iter:29355] Loss: 1.435, 10.585, 67.290, 441.383, 1.368
[epoch:38, iter:29375] Loss: 1.434, 10.583, 67.280, 441.312, 1.412
[epoch:38, iter:29395] Loss: 1.435, 10.578, 67.251, 441.165, 0.945
[epoch:38, iter:29415] Loss: 1.434, 10.578, 67.261, 441.188, 1.236
Epoch: [37][500/782]	Time 0.059 (0.079)	Data 0.002 (0.003)	Loss 14.6776 (13.9483)	Acc@1 56.250 (61.249)	Acc@5 82.812 (88.938)
[epoch:38, iter:29435] Loss: 1.434, 10.576, 67.271, 441.287, 1.919
[epoch:38, iter:29455] Loss: 1.434, 10.578, 67.245, 441.247, 1.485
[epoch:38, iter:29475] Loss: 1.435, 10.578, 67.245, 441.310, 1.734
[epoch:38, iter:29495] Loss: 1.435, 10.577, 67.222, 441.245, 1.482
[epoch:38, iter:29515] Loss: 1.435, 10.576, 67.208, 441.241, 0.974
Epoch: [37][600/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 14.4628 (13.9497)	Acc@1 54.688 (61.174)	Acc@5 92.188 (88.920)
[epoch:38, iter:29535] Loss: 1.435, 10.575, 67.225, 441.223, 1.433
[epoch:38, iter:29555] Loss: 1.434, 10.578, 67.223, 441.211, 1.452
[epoch:38, iter:29575] Loss: 1.434, 10.574, 67.216, 441.172, 1.214
[epoch:38, iter:29595] Loss: 1.434, 10.573, 67.248, 441.266, 1.518
[epoch:38, iter:29615] Loss: 1.435, 10.573, 67.267, 441.253, 0.935
Epoch: [37][700/782]	Time 0.091 (0.077)	Data 0.003 (0.003)	Loss 14.9708 (13.9542)	Acc@1 64.062 (61.180)	Acc@5 87.500 (88.786)
[epoch:38, iter:29635] Loss: 1.435, 10.574, 67.250, 441.240, 1.459
[epoch:38, iter:29655] Loss: 1.434, 10.570, 67.234, 441.215, 1.527
[epoch:38, iter:29675] Loss: 1.435, 10.568, 67.233, 441.215, 1.519
[epoch:38, iter:29695] Loss: 1.436, 10.571, 67.232, 441.259, 1.526
[epoch:38, iter:29715] Loss: 1.436, 10.575, 67.248, 441.376, 1.500
 * Acc@1 61.006 Acc@5 88.704
epoch 37, total time 60.67
Test: [0/313]	Time 0.221 (0.221)	Loss 2.5920 (2.5920)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.010 (0.009)	Loss 1.9870 (2.0876)	Acc@1 50.000 (51.516)	Acc@5 84.375 (84.158)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.6921 (2.0982)	Acc@1 65.625 (51.772)	Acc@5 81.250 (83.784)
Test: [300/313]	Time 0.008 (0.007)	Loss 2.7791 (2.0979)	Acc@1 50.000 (52.274)	Acc@5 75.000 (83.576)
 * Acc@1 52.380 Acc@5 83.610
==> training...
Epoch: [38][0/782]	Time 0.605 (0.605)	Data 0.534 (0.534)	Loss 14.9644 (14.9644)	Acc@1 65.625 (65.625)	Acc@5 95.312 (95.312)
[epoch:39, iter:29717] Loss: 1.455, 10.728, 73.001, 458.782, 1.167
[epoch:39, iter:29737] Loss: 1.443, 10.654, 67.833, 441.526, 1.146
[epoch:39, iter:29757] Loss: 1.428, 10.572, 67.692, 442.823, 1.461
[epoch:39, iter:29777] Loss: 1.428, 10.538, 67.395, 441.892, 1.730
[epoch:39, iter:29797] Loss: 1.421, 10.484, 67.103, 441.149, 1.702
Epoch: [38][100/782]	Time 0.081 (0.089)	Data 0.003 (0.008)	Loss 13.5745 (13.8743)	Acc@1 65.625 (61.262)	Acc@5 89.062 (89.480)
[epoch:39, iter:29817] Loss: 1.426, 10.479, 67.182, 441.314, 1.358
[epoch:39, iter:29837] Loss: 1.428, 10.481, 67.142, 441.233, 1.477
[epoch:39, iter:29857] Loss: 1.429, 10.488, 67.012, 440.916, 0.919
[epoch:39, iter:29877] Loss: 1.432, 10.501, 66.998, 440.857, 1.415
[epoch:39, iter:29897] Loss: 1.431, 10.510, 67.023, 440.845, 1.217
Epoch: [38][200/782]	Time 0.090 (0.085)	Data 0.003 (0.005)	Loss 14.1760 (13.8562)	Acc@1 53.125 (61.637)	Acc@5 85.938 (89.280)
[epoch:39, iter:29917] Loss: 1.432, 10.514, 67.078, 440.614, 1.662
[epoch:39, iter:29937] Loss: 1.433, 10.521, 67.104, 440.710, 1.620
[epoch:39, iter:29957] Loss: 1.435, 10.533, 67.189, 440.741, 1.309
[epoch:39, iter:29977] Loss: 1.438, 10.539, 67.292, 440.787, 1.560
[epoch:39, iter:29997] Loss: 1.438, 10.549, 67.354, 441.013, 1.809
Epoch: [38][300/782]	Time 0.085 (0.084)	Data 0.003 (0.004)	Loss 14.3752 (13.9400)	Acc@1 57.812 (61.431)	Acc@5 89.062 (89.068)
[epoch:39, iter:30017] Loss: 1.439, 10.559, 67.391, 441.190, 1.856
[epoch:39, iter:30037] Loss: 1.439, 10.570, 67.366, 441.283, 1.588
[epoch:39, iter:30057] Loss: 1.439, 10.560, 67.319, 441.202, 1.378
[epoch:39, iter:30077] Loss: 1.438, 10.555, 67.339, 441.230, 1.610
[epoch:39, iter:30097] Loss: 1.437, 10.551, 67.311, 441.093, 1.142
Epoch: [38][400/782]	Time 0.067 (0.083)	Data 0.002 (0.004)	Loss 14.5201 (13.9374)	Acc@1 51.562 (61.436)	Acc@5 84.375 (89.000)
[epoch:39, iter:30117] Loss: 1.437, 10.554, 67.314, 441.281, 1.664
[epoch:39, iter:30137] Loss: 1.436, 10.556, 67.302, 441.276, 1.317
[epoch:39, iter:30157] Loss: 1.436, 10.551, 67.284, 441.276, 1.646
[epoch:39, iter:30177] Loss: 1.437, 10.550, 67.260, 441.112, 1.627
[epoch:39, iter:30197] Loss: 1.438, 10.549, 67.255, 441.028, 1.715
Epoch: [38][500/782]	Time 0.079 (0.082)	Data 0.003 (0.004)	Loss 13.7277 (13.9511)	Acc@1 60.938 (61.228)	Acc@5 92.188 (89.034)
[epoch:39, iter:30217] Loss: 1.437, 10.550, 67.266, 441.093, 1.265
[epoch:39, iter:30237] Loss: 1.439, 10.549, 67.225, 440.921, 1.461
[epoch:39, iter:30257] Loss: 1.438, 10.553, 67.201, 440.856, 1.765
[epoch:39, iter:30277] Loss: 1.438, 10.554, 67.231, 440.856, 1.329
[epoch:39, iter:30297] Loss: 1.438, 10.553, 67.289, 440.995, 1.596
Epoch: [38][600/782]	Time 0.087 (0.081)	Data 0.002 (0.003)	Loss 13.9450 (13.9556)	Acc@1 64.062 (61.130)	Acc@5 90.625 (88.930)
[epoch:39, iter:30317] Loss: 1.438, 10.558, 67.299, 440.982, 1.256
[epoch:39, iter:30337] Loss: 1.439, 10.563, 67.313, 441.005, 1.594
[epoch:39, iter:30357] Loss: 1.439, 10.561, 67.314, 441.019, 1.380
[epoch:39, iter:30377] Loss: 1.439, 10.565, 67.308, 441.091, 1.319
[epoch:39, iter:30397] Loss: 1.440, 10.570, 67.331, 441.264, 2.449
Epoch: [38][700/782]	Time 0.093 (0.081)	Data 0.003 (0.003)	Loss 13.7037 (13.9714)	Acc@1 68.750 (61.196)	Acc@5 93.750 (88.864)
[epoch:39, iter:30417] Loss: 1.440, 10.567, 67.325, 441.233, 1.127
[epoch:39, iter:30437] Loss: 1.440, 10.570, 67.317, 441.153, 1.661
[epoch:39, iter:30457] Loss: 1.440, 10.570, 67.304, 441.166, 1.513
[epoch:39, iter:30477] Loss: 1.441, 10.571, 67.298, 441.138, 1.252
[epoch:39, iter:30497] Loss: 1.441, 10.569, 67.291, 441.184, 1.417
 * Acc@1 61.148 Acc@5 88.824
epoch 38, total time 62.95
Test: [0/313]	Time 0.259 (0.259)	Loss 2.6704 (2.6704)	Acc@1 56.250 (56.250)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.7032 (2.4200)	Acc@1 43.750 (50.340)	Acc@5 78.125 (80.786)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7964 (2.4391)	Acc@1 59.375 (49.891)	Acc@5 90.625 (80.100)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8985 (2.4469)	Acc@1 34.375 (50.010)	Acc@5 75.000 (79.797)
 * Acc@1 50.110 Acc@5 79.850
==> training...
Epoch: [39][0/782]	Time 0.491 (0.491)	Data 0.419 (0.419)	Loss 13.8632 (13.8632)	Acc@1 53.125 (53.125)	Acc@5 82.812 (82.812)
[epoch:40, iter:30499] Loss: 1.527, 10.346, 67.670, 431.483, 1.759
[epoch:40, iter:30519] Loss: 1.438, 10.690, 67.662, 442.641, 1.388
[epoch:40, iter:30539] Loss: 1.441, 10.653, 67.111, 440.150, 1.537
[epoch:40, iter:30559] Loss: 1.440, 10.640, 67.284, 441.657, 1.737
[epoch:40, iter:30579] Loss: 1.439, 10.604, 67.334, 441.163, 1.303
Epoch: [39][100/782]	Time 0.083 (0.083)	Data 0.002 (0.007)	Loss 14.4053 (13.9756)	Acc@1 59.375 (61.510)	Acc@5 82.812 (89.202)
[epoch:40, iter:30599] Loss: 1.439, 10.619, 67.590, 441.985, 1.722
[epoch:40, iter:30619] Loss: 1.439, 10.605, 67.685, 442.407, 1.663
[epoch:40, iter:30639] Loss: 1.440, 10.596, 67.535, 442.036, 1.318
[epoch:40, iter:30659] Loss: 1.438, 10.586, 67.367, 441.599, 1.524
[epoch:40, iter:30679] Loss: 1.439, 10.583, 67.357, 441.196, 1.310
Epoch: [39][200/782]	Time 0.078 (0.082)	Data 0.002 (0.005)	Loss 12.5141 (13.8890)	Acc@1 59.375 (62.220)	Acc@5 85.938 (89.366)
[epoch:40, iter:30699] Loss: 1.438, 10.571, 67.290, 440.785, 1.380
[epoch:40, iter:30719] Loss: 1.436, 10.571, 67.288, 440.760, 1.506
[epoch:40, iter:30739] Loss: 1.436, 10.562, 67.284, 440.915, 1.487
[epoch:40, iter:30759] Loss: 1.438, 10.575, 67.296, 441.243, 1.838
[epoch:40, iter:30779] Loss: 1.438, 10.576, 67.271, 441.230, 1.231
Epoch: [39][300/782]	Time 0.073 (0.082)	Data 0.002 (0.004)	Loss 13.9636 (13.9324)	Acc@1 59.375 (61.602)	Acc@5 85.938 (89.172)
[epoch:40, iter:30799] Loss: 1.438, 10.570, 67.314, 441.336, 1.393
[epoch:40, iter:30819] Loss: 1.437, 10.565, 67.346, 441.255, 1.642
[epoch:40, iter:30839] Loss: 1.437, 10.569, 67.340, 441.107, 1.074
[epoch:40, iter:30859] Loss: 1.438, 10.565, 67.305, 441.020, 1.846
[epoch:40, iter:30879] Loss: 1.436, 10.559, 67.307, 441.193, 1.762
Epoch: [39][400/782]	Time 0.078 (0.079)	Data 0.002 (0.003)	Loss 13.8739 (13.9259)	Acc@1 64.062 (61.549)	Acc@5 90.625 (89.129)
[epoch:40, iter:30899] Loss: 1.438, 10.562, 67.289, 441.161, 1.534
[epoch:40, iter:30919] Loss: 1.438, 10.560, 67.268, 441.075, 1.573
[epoch:40, iter:30939] Loss: 1.439, 10.561, 67.275, 441.100, 1.777
[epoch:40, iter:30959] Loss: 1.439, 10.560, 67.252, 440.965, 1.580
[epoch:40, iter:30979] Loss: 1.438, 10.562, 67.285, 441.102, 1.517
Epoch: [39][500/782]	Time 0.089 (0.078)	Data 0.002 (0.003)	Loss 13.1179 (13.9342)	Acc@1 65.625 (61.362)	Acc@5 90.625 (89.097)
[epoch:40, iter:30999] Loss: 1.438, 10.557, 67.301, 441.174, 1.289
[epoch:40, iter:31019] Loss: 1.438, 10.553, 67.266, 441.073, 1.154
[epoch:40, iter:31039] Loss: 1.438, 10.553, 67.318, 441.149, 1.597
[epoch:40, iter:31059] Loss: 1.439, 10.557, 67.370, 441.272, 1.441
[epoch:40, iter:31079] Loss: 1.438, 10.555, 67.397, 441.367, 1.329
Epoch: [39][600/782]	Time 0.079 (0.078)	Data 0.002 (0.003)	Loss 14.1838 (13.9546)	Acc@1 59.375 (61.275)	Acc@5 85.938 (89.086)
[epoch:40, iter:31099] Loss: 1.438, 10.558, 67.385, 441.361, 1.463
[epoch:40, iter:31119] Loss: 1.438, 10.564, 67.381, 441.362, 1.002
[epoch:40, iter:31139] Loss: 1.437, 10.568, 67.356, 441.376, 1.594
[epoch:40, iter:31159] Loss: 1.437, 10.571, 67.347, 441.405, 1.289
[epoch:40, iter:31179] Loss: 1.436, 10.574, 67.342, 441.464, 1.290
Epoch: [39][700/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 14.2336 (13.9761)	Acc@1 57.812 (61.156)	Acc@5 90.625 (88.942)
[epoch:40, iter:31199] Loss: 1.437, 10.576, 67.336, 441.540, 1.378
[epoch:40, iter:31219] Loss: 1.437, 10.576, 67.321, 441.503, 1.664
[epoch:40, iter:31239] Loss: 1.437, 10.579, 67.328, 441.537, 1.387
[epoch:40, iter:31259] Loss: 1.439, 10.585, 67.341, 441.584, 1.671
[epoch:40, iter:31279] Loss: 1.440, 10.585, 67.371, 441.642, 1.417
 * Acc@1 61.074 Acc@5 88.874
epoch 39, total time 61.77
Test: [0/313]	Time 0.252 (0.252)	Loss 2.2130 (2.2130)	Acc@1 53.125 (53.125)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.7853 (2.0494)	Acc@1 50.000 (53.929)	Acc@5 87.500 (82.766)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.8727 (2.0349)	Acc@1 59.375 (53.747)	Acc@5 81.250 (82.820)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3859 (2.0463)	Acc@1 46.875 (53.623)	Acc@5 84.375 (82.828)
 * Acc@1 53.720 Acc@5 82.810
==> training...
Epoch: [40][0/782]	Time 0.566 (0.566)	Data 0.499 (0.499)	Loss 13.3674 (13.3674)	Acc@1 67.188 (67.188)	Acc@5 89.062 (89.062)
[epoch:41, iter:31281] Loss: 1.384, 10.693, 66.817, 439.122, 1.239
[epoch:41, iter:31301] Loss: 1.450, 10.660, 68.644, 446.011, 1.409
[epoch:41, iter:31321] Loss: 1.447, 10.667, 67.762, 442.591, 1.167
[epoch:41, iter:31341] Loss: 1.438, 10.638, 67.357, 441.375, 1.296
[epoch:41, iter:31361] Loss: 1.430, 10.615, 67.093, 441.058, 1.470
Epoch: [40][100/782]	Time 0.061 (0.078)	Data 0.002 (0.007)	Loss 13.5256 (13.9038)	Acc@1 65.625 (62.113)	Acc@5 90.625 (89.527)
[epoch:41, iter:31381] Loss: 1.431, 10.598, 67.091, 441.119, 1.428
[epoch:41, iter:31401] Loss: 1.432, 10.576, 67.029, 440.907, 1.938
[epoch:41, iter:31421] Loss: 1.434, 10.590, 67.048, 441.017, 1.148
[epoch:41, iter:31441] Loss: 1.436, 10.588, 67.048, 440.873, 1.467
[epoch:41, iter:31461] Loss: 1.437, 10.592, 67.114, 441.061, 1.141
Epoch: [40][200/782]	Time 0.056 (0.067)	Data 0.002 (0.004)	Loss 13.6321 (13.9206)	Acc@1 60.938 (61.878)	Acc@5 90.625 (89.117)
[epoch:41, iter:31481] Loss: 1.437, 10.595, 67.082, 440.841, 1.262
[epoch:41, iter:31501] Loss: 1.436, 10.589, 67.112, 441.066, 1.737
[epoch:41, iter:31521] Loss: 1.439, 10.583, 67.007, 440.681, 1.644
[epoch:41, iter:31541] Loss: 1.439, 10.577, 66.969, 440.692, 1.462
[epoch:41, iter:31561] Loss: 1.439, 10.566, 67.002, 440.874, 1.194
Epoch: [40][300/782]	Time 0.061 (0.068)	Data 0.001 (0.004)	Loss 13.9793 (13.9213)	Acc@1 57.812 (61.830)	Acc@5 90.625 (89.057)
[epoch:41, iter:31581] Loss: 1.440, 10.573, 67.005, 440.886, 1.644
[epoch:41, iter:31601] Loss: 1.440, 10.576, 67.003, 440.892, 1.239
[epoch:41, iter:31621] Loss: 1.440, 10.576, 66.982, 440.610, 1.432
[epoch:41, iter:31641] Loss: 1.438, 10.564, 67.014, 440.542, 1.474
[epoch:41, iter:31661] Loss: 1.440, 10.562, 67.037, 440.535, 1.303
Epoch: [40][400/782]	Time 0.081 (0.071)	Data 0.003 (0.003)	Loss 14.3192 (13.9342)	Acc@1 57.812 (61.600)	Acc@5 87.500 (88.938)
[epoch:41, iter:31681] Loss: 1.440, 10.563, 67.067, 440.634, 1.625
[epoch:41, iter:31701] Loss: 1.439, 10.563, 67.075, 440.679, 1.551
[epoch:41, iter:31721] Loss: 1.440, 10.565, 67.032, 440.689, 1.705
[epoch:41, iter:31741] Loss: 1.440, 10.568, 67.042, 440.754, 1.208
[epoch:41, iter:31761] Loss: 1.440, 10.564, 67.035, 440.698, 1.412
Epoch: [40][500/782]	Time 0.089 (0.072)	Data 0.003 (0.003)	Loss 12.9995 (13.9272)	Acc@1 64.062 (61.555)	Acc@5 96.875 (88.835)
[epoch:41, iter:31781] Loss: 1.438, 10.563, 67.037, 440.629, 0.929
[epoch:41, iter:31801] Loss: 1.437, 10.562, 67.038, 440.616, 1.503
[epoch:41, iter:31821] Loss: 1.437, 10.556, 67.044, 440.445, 1.523
[epoch:41, iter:31841] Loss: 1.437, 10.553, 67.044, 440.338, 1.494
[epoch:41, iter:31861] Loss: 1.435, 10.548, 67.034, 440.349, 1.452
Epoch: [40][600/782]	Time 0.092 (0.074)	Data 0.003 (0.003)	Loss 12.8931 (13.9109)	Acc@1 70.312 (61.619)	Acc@5 95.312 (88.777)
[epoch:41, iter:31881] Loss: 1.436, 10.549, 67.053, 440.416, 0.955
[epoch:41, iter:31901] Loss: 1.437, 10.547, 67.036, 440.364, 1.525
[epoch:41, iter:31921] Loss: 1.436, 10.548, 67.039, 440.398, 1.747
[epoch:41, iter:31941] Loss: 1.436, 10.547, 67.014, 440.241, 1.246
[epoch:41, iter:31961] Loss: 1.436, 10.546, 67.025, 440.297, 1.277
Epoch: [40][700/782]	Time 0.073 (0.074)	Data 0.002 (0.003)	Loss 14.5065 (13.9145)	Acc@1 59.375 (61.519)	Acc@5 92.188 (88.746)
[epoch:41, iter:31981] Loss: 1.436, 10.548, 67.030, 440.318, 1.475
[epoch:41, iter:32001] Loss: 1.436, 10.546, 67.037, 440.352, 1.345
[epoch:41, iter:32021] Loss: 1.436, 10.543, 67.023, 440.363, 1.550
[epoch:41, iter:32041] Loss: 1.435, 10.544, 67.020, 440.420, 1.508
[epoch:41, iter:32061] Loss: 1.435, 10.541, 67.005, 440.359, 1.574
 * Acc@1 61.416 Acc@5 88.664
epoch 40, total time 58.42
Test: [0/313]	Time 0.261 (0.261)	Loss 1.9549 (1.9549)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.010)	Loss 3.2735 (2.2926)	Acc@1 43.750 (53.001)	Acc@5 68.750 (80.631)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.6231 (2.2322)	Acc@1 68.750 (53.591)	Acc@5 90.625 (81.343)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.0978 (2.2306)	Acc@1 50.000 (53.478)	Acc@5 81.250 (81.489)
 * Acc@1 53.560 Acc@5 81.490
==> Saving...
==> training...
Epoch: [41][0/782]	Time 0.570 (0.570)	Data 0.498 (0.498)	Loss 12.9009 (12.9009)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
[epoch:42, iter:32063] Loss: 1.372, 10.513, 67.028, 435.236, 0.903
[epoch:42, iter:32083] Loss: 1.438, 10.598, 69.294, 445.190, 1.455
[epoch:42, iter:32103] Loss: 1.429, 10.536, 68.313, 443.681, 1.345
[epoch:42, iter:32123] Loss: 1.426, 10.539, 67.629, 442.545, 1.380
[epoch:42, iter:32143] Loss: 1.426, 10.569, 67.691, 442.805, 1.640
Epoch: [41][100/782]	Time 0.083 (0.079)	Data 0.002 (0.007)	Loss 13.1427 (13.9426)	Acc@1 68.750 (62.299)	Acc@5 89.062 (88.908)
[epoch:42, iter:32163] Loss: 1.425, 10.589, 67.662, 442.499, 1.090
[epoch:42, iter:32183] Loss: 1.431, 10.571, 67.588, 442.137, 1.392
[epoch:42, iter:32203] Loss: 1.433, 10.561, 67.451, 441.787, 1.261
[epoch:42, iter:32223] Loss: 1.437, 10.574, 67.497, 441.888, 1.334
[epoch:42, iter:32243] Loss: 1.437, 10.552, 67.433, 441.434, 0.971
Epoch: [41][200/782]	Time 0.085 (0.078)	Data 0.002 (0.005)	Loss 13.1321 (13.8696)	Acc@1 62.500 (62.523)	Acc@5 89.062 (89.451)
[epoch:42, iter:32263] Loss: 1.439, 10.559, 67.298, 441.005, 1.298
[epoch:42, iter:32283] Loss: 1.439, 10.550, 67.291, 440.934, 1.820
[epoch:42, iter:32303] Loss: 1.438, 10.551, 67.296, 441.008, 1.504
[epoch:42, iter:32323] Loss: 1.440, 10.561, 67.326, 441.155, 1.210
[epoch:42, iter:32343] Loss: 1.441, 10.564, 67.349, 441.323, 1.482
Epoch: [41][300/782]	Time 0.099 (0.078)	Data 0.002 (0.004)	Loss 14.4207 (13.9162)	Acc@1 54.688 (62.318)	Acc@5 85.938 (89.249)
[epoch:42, iter:32363] Loss: 1.443, 10.572, 67.363, 441.244, 1.474
[epoch:42, iter:32383] Loss: 1.446, 10.579, 67.397, 441.356, 1.400
[epoch:42, iter:32403] Loss: 1.447, 10.582, 67.392, 441.538, 1.727
[epoch:42, iter:32423] Loss: 1.447, 10.578, 67.425, 441.610, 1.503
[epoch:42, iter:32443] Loss: 1.447, 10.576, 67.401, 441.452, 1.762
Epoch: [41][400/782]	Time 0.086 (0.078)	Data 0.002 (0.003)	Loss 13.3736 (13.9532)	Acc@1 62.500 (61.896)	Acc@5 93.750 (89.109)
[epoch:42, iter:32463] Loss: 1.447, 10.578, 67.391, 441.416, 1.121
[epoch:42, iter:32483] Loss: 1.447, 10.579, 67.401, 441.440, 1.386
[epoch:42, iter:32503] Loss: 1.447, 10.578, 67.390, 441.320, 1.863
[epoch:42, iter:32523] Loss: 1.447, 10.584, 67.349, 441.330, 1.899
[epoch:42, iter:32543] Loss: 1.446, 10.581, 67.282, 441.176, 1.758
Epoch: [41][500/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 14.3381 (13.9352)	Acc@1 54.688 (61.854)	Acc@5 82.812 (88.994)
[epoch:42, iter:32563] Loss: 1.445, 10.579, 67.263, 441.130, 1.690
[epoch:42, iter:32583] Loss: 1.444, 10.573, 67.200, 440.935, 1.360
[epoch:42, iter:32603] Loss: 1.443, 10.569, 67.198, 440.830, 1.344
[epoch:42, iter:32623] Loss: 1.442, 10.571, 67.206, 440.915, 1.751
[epoch:42, iter:32643] Loss: 1.443, 10.577, 67.212, 440.972, 1.613
Epoch: [41][600/782]	Time 0.090 (0.076)	Data 0.003 (0.003)	Loss 13.8623 (13.9184)	Acc@1 70.312 (61.977)	Acc@5 93.750 (88.938)
[epoch:42, iter:32663] Loss: 1.442, 10.572, 67.197, 440.947, 1.163
[epoch:42, iter:32683] Loss: 1.441, 10.570, 67.175, 440.877, 1.237
[epoch:42, iter:32703] Loss: 1.440, 10.567, 67.164, 440.825, 1.413
[epoch:42, iter:32723] Loss: 1.439, 10.567, 67.172, 440.852, 1.034
[epoch:42, iter:32743] Loss: 1.440, 10.566, 67.215, 440.937, 0.947
Epoch: [41][700/782]	Time 0.078 (0.076)	Data 0.002 (0.003)	Loss 13.8500 (13.9307)	Acc@1 62.500 (61.825)	Acc@5 92.188 (88.895)
[epoch:42, iter:32763] Loss: 1.440, 10.568, 67.230, 440.994, 1.409
[epoch:42, iter:32783] Loss: 1.440, 10.571, 67.242, 441.077, 1.811
[epoch:42, iter:32803] Loss: 1.440, 10.570, 67.241, 441.084, 1.360
[epoch:42, iter:32823] Loss: 1.439, 10.570, 67.251, 441.116, 1.822
[epoch:42, iter:32843] Loss: 1.438, 10.572, 67.240, 441.144, 1.576
 * Acc@1 61.658 Acc@5 88.742
epoch 41, total time 59.09
Test: [0/313]	Time 0.230 (0.230)	Loss 2.0758 (2.0758)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.9632 (2.1560)	Acc@1 50.000 (51.640)	Acc@5 84.375 (82.952)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.0064 (2.1720)	Acc@1 56.250 (51.897)	Acc@5 81.250 (82.214)
Test: [300/313]	Time 0.008 (0.007)	Loss 2.5329 (2.1754)	Acc@1 46.875 (52.035)	Acc@5 75.000 (82.226)
 * Acc@1 52.100 Acc@5 82.230
==> training...
Epoch: [42][0/782]	Time 0.502 (0.502)	Data 0.437 (0.437)	Loss 13.0752 (13.0752)	Acc@1 71.875 (71.875)	Acc@5 95.312 (95.312)
[epoch:43, iter:32845] Loss: 1.409, 10.428, 64.934, 431.498, 0.948
[epoch:43, iter:32865] Loss: 1.446, 10.566, 67.027, 441.633, 1.467
[epoch:43, iter:32885] Loss: 1.440, 10.542, 66.519, 440.139, 1.243
[epoch:43, iter:32905] Loss: 1.427, 10.512, 66.289, 438.629, 2.011
[epoch:43, iter:32925] Loss: 1.424, 10.499, 66.380, 439.003, 1.863
Epoch: [42][100/782]	Time 0.064 (0.075)	Data 0.002 (0.006)	Loss 12.8684 (13.7942)	Acc@1 64.062 (62.222)	Acc@5 92.188 (89.295)
[epoch:43, iter:32945] Loss: 1.425, 10.512, 66.456, 439.278, 1.083
[epoch:43, iter:32965] Loss: 1.429, 10.509, 66.453, 439.068, 1.018
[epoch:43, iter:32985] Loss: 1.431, 10.522, 66.402, 439.205, 1.053
[epoch:43, iter:33005] Loss: 1.432, 10.514, 66.552, 439.589, 1.348
[epoch:43, iter:33025] Loss: 1.432, 10.529, 66.660, 439.659, 1.201
Epoch: [42][200/782]	Time 0.065 (0.075)	Data 0.004 (0.004)	Loss 13.9519 (13.8427)	Acc@1 59.375 (62.376)	Acc@5 89.062 (89.094)
[epoch:43, iter:33045] Loss: 1.432, 10.527, 66.704, 439.745, 1.512
[epoch:43, iter:33065] Loss: 1.433, 10.539, 66.709, 439.780, 1.140
[epoch:43, iter:33085] Loss: 1.435, 10.541, 66.684, 439.595, 1.212
[epoch:43, iter:33105] Loss: 1.435, 10.549, 66.675, 439.644, 1.482
[epoch:43, iter:33125] Loss: 1.435, 10.548, 66.677, 439.518, 1.672
Epoch: [42][300/782]	Time 0.095 (0.076)	Data 0.003 (0.004)	Loss 14.7817 (13.8136)	Acc@1 51.562 (62.349)	Acc@5 90.625 (89.265)
[epoch:43, iter:33145] Loss: 1.434, 10.543, 66.627, 439.385, 1.556
[epoch:43, iter:33165] Loss: 1.433, 10.540, 66.631, 439.461, 1.253
[epoch:43, iter:33185] Loss: 1.433, 10.534, 66.620, 439.452, 1.158
[epoch:43, iter:33205] Loss: 1.434, 10.538, 66.669, 439.779, 1.472
[epoch:43, iter:33225] Loss: 1.434, 10.539, 66.680, 439.704, 1.240
Epoch: [42][400/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 13.4423 (13.8372)	Acc@1 70.312 (62.336)	Acc@5 93.750 (89.222)
[epoch:43, iter:33245] Loss: 1.435, 10.537, 66.734, 439.806, 1.035
[epoch:43, iter:33265] Loss: 1.435, 10.547, 66.804, 439.916, 2.118
[epoch:43, iter:33285] Loss: 1.437, 10.554, 66.858, 440.000, 1.644
[epoch:43, iter:33305] Loss: 1.438, 10.559, 66.910, 440.183, 1.535
[epoch:43, iter:33325] Loss: 1.438, 10.564, 66.908, 440.172, 1.127
Epoch: [42][500/782]	Time 0.090 (0.077)	Data 0.003 (0.003)	Loss 13.7186 (13.8953)	Acc@1 65.625 (61.873)	Acc@5 90.625 (89.125)
[epoch:43, iter:33345] Loss: 1.439, 10.569, 66.961, 440.397, 1.232
[epoch:43, iter:33365] Loss: 1.438, 10.568, 66.968, 440.417, 1.587
[epoch:43, iter:33385] Loss: 1.438, 10.571, 66.987, 440.555, 1.558
[epoch:43, iter:33405] Loss: 1.437, 10.571, 66.985, 440.595, 1.182
[epoch:43, iter:33425] Loss: 1.437, 10.569, 66.979, 440.582, 1.819
Epoch: [42][600/782]	Time 0.060 (0.077)	Data 0.002 (0.003)	Loss 14.2644 (13.9086)	Acc@1 53.125 (61.728)	Acc@5 85.938 (88.995)
[epoch:43, iter:33445] Loss: 1.438, 10.568, 67.006, 440.595, 1.732
[epoch:43, iter:33465] Loss: 1.437, 10.570, 67.013, 440.580, 1.695
[epoch:43, iter:33485] Loss: 1.437, 10.570, 67.034, 440.687, 1.270
[epoch:43, iter:33505] Loss: 1.438, 10.570, 67.057, 440.747, 1.600
[epoch:43, iter:33525] Loss: 1.438, 10.576, 67.062, 440.731, 1.125
Epoch: [42][700/782]	Time 0.101 (0.077)	Data 0.003 (0.003)	Loss 14.5388 (13.9236)	Acc@1 60.938 (61.613)	Acc@5 87.500 (88.913)
[epoch:43, iter:33545] Loss: 1.437, 10.578, 67.064, 440.697, 1.678
[epoch:43, iter:33565] Loss: 1.436, 10.576, 67.037, 440.672, 1.182
[epoch:43, iter:33585] Loss: 1.437, 10.574, 67.024, 440.724, 1.284
[epoch:43, iter:33605] Loss: 1.436, 10.570, 67.015, 440.759, 1.519
[epoch:43, iter:33625] Loss: 1.436, 10.563, 66.997, 440.676, 1.346
 * Acc@1 61.598 Acc@5 88.836
epoch 42, total time 60.43
Test: [0/313]	Time 0.219 (0.219)	Loss 2.3235 (2.3235)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.9757 (1.8783)	Acc@1 53.125 (56.590)	Acc@5 96.875 (84.313)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.2508 (1.8878)	Acc@1 65.625 (56.126)	Acc@5 90.625 (84.282)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.0209 (1.9048)	Acc@1 43.750 (55.793)	Acc@5 90.625 (84.105)
 * Acc@1 55.900 Acc@5 84.160
==> training...
Epoch: [43][0/782]	Time 0.499 (0.499)	Data 0.432 (0.432)	Loss 14.4863 (14.4863)	Acc@1 54.688 (54.688)	Acc@5 87.500 (87.500)
[epoch:44, iter:33627] Loss: 1.400, 10.648, 70.461, 453.524, 1.745
[epoch:44, iter:33647] Loss: 1.430, 10.593, 66.698, 439.338, 0.902
[epoch:44, iter:33667] Loss: 1.413, 10.493, 66.571, 438.216, 1.476
[epoch:44, iter:33687] Loss: 1.419, 10.450, 66.641, 438.122, 1.264
[epoch:44, iter:33707] Loss: 1.425, 10.466, 66.749, 438.817, 1.363
Epoch: [43][100/782]	Time 0.090 (0.083)	Data 0.003 (0.007)	Loss 13.3518 (13.7273)	Acc@1 62.500 (63.041)	Acc@5 89.062 (90.022)
[epoch:44, iter:33727] Loss: 1.428, 10.485, 66.893, 439.197, 1.237
[epoch:44, iter:33747] Loss: 1.428, 10.487, 66.897, 439.221, 1.197
[epoch:44, iter:33767] Loss: 1.428, 10.506, 67.064, 439.840, 1.876
[epoch:44, iter:33787] Loss: 1.432, 10.521, 67.093, 440.093, 1.581
[epoch:44, iter:33807] Loss: 1.434, 10.540, 67.130, 440.167, 1.640
Epoch: [43][200/782]	Time 0.075 (0.080)	Data 0.002 (0.004)	Loss 14.0164 (13.8411)	Acc@1 53.125 (62.228)	Acc@5 87.500 (89.607)
[epoch:44, iter:33827] Loss: 1.433, 10.541, 67.254, 440.469, 1.726
[epoch:44, iter:33847] Loss: 1.433, 10.549, 67.303, 440.592, 1.345
[epoch:44, iter:33867] Loss: 1.433, 10.560, 67.229, 440.443, 0.979
[epoch:44, iter:33887] Loss: 1.432, 10.562, 67.144, 440.400, 1.509
[epoch:44, iter:33907] Loss: 1.432, 10.569, 67.187, 440.696, 1.173
Epoch: [43][300/782]	Time 0.065 (0.079)	Data 0.002 (0.004)	Loss 13.9395 (13.8901)	Acc@1 57.812 (61.856)	Acc@5 84.375 (89.369)
[epoch:44, iter:33927] Loss: 1.433, 10.574, 67.277, 440.900, 1.585
[epoch:44, iter:33947] Loss: 1.433, 10.571, 67.233, 440.746, 1.526
[epoch:44, iter:33967] Loss: 1.434, 10.571, 67.205, 440.736, 1.513
[epoch:44, iter:33987] Loss: 1.435, 10.568, 67.225, 440.840, 1.755
[epoch:44, iter:34007] Loss: 1.434, 10.564, 67.197, 440.716, 1.385
Epoch: [43][400/782]	Time 0.065 (0.079)	Data 0.002 (0.003)	Loss 12.8121 (13.8864)	Acc@1 60.938 (61.857)	Acc@5 92.188 (89.253)
[epoch:44, iter:34027] Loss: 1.434, 10.566, 67.151, 440.625, 1.240
[epoch:44, iter:34047] Loss: 1.435, 10.569, 67.190, 440.748, 1.338
[epoch:44, iter:34067] Loss: 1.436, 10.572, 67.214, 440.740, 1.535
[epoch:44, iter:34087] Loss: 1.436, 10.567, 67.159, 440.533, 1.481
[epoch:44, iter:34107] Loss: 1.436, 10.568, 67.186, 440.563, 1.622
Epoch: [43][500/782]	Time 0.060 (0.077)	Data 0.002 (0.003)	Loss 14.3592 (13.9008)	Acc@1 62.500 (61.914)	Acc@5 87.500 (89.150)
[epoch:44, iter:34127] Loss: 1.435, 10.557, 67.206, 440.560, 1.441
[epoch:44, iter:34147] Loss: 1.435, 10.557, 67.204, 440.593, 1.475
[epoch:44, iter:34167] Loss: 1.434, 10.560, 67.199, 440.550, 1.590
[epoch:44, iter:34187] Loss: 1.435, 10.561, 67.197, 440.648, 1.641
[epoch:44, iter:34207] Loss: 1.435, 10.563, 67.184, 440.635, 1.752
Epoch: [43][600/782]	Time 0.063 (0.077)	Data 0.002 (0.003)	Loss 13.4942 (13.9105)	Acc@1 71.875 (61.678)	Acc@5 92.188 (89.109)
[epoch:44, iter:34227] Loss: 1.434, 10.564, 67.196, 440.731, 1.116
[epoch:44, iter:34247] Loss: 1.434, 10.565, 67.205, 440.723, 1.301
[epoch:44, iter:34267] Loss: 1.434, 10.559, 67.201, 440.646, 1.380
[epoch:44, iter:34287] Loss: 1.434, 10.559, 67.210, 440.726, 1.472
[epoch:44, iter:34307] Loss: 1.435, 10.556, 67.221, 440.687, 1.359
Epoch: [43][700/782]	Time 0.087 (0.077)	Data 0.003 (0.003)	Loss 14.5919 (13.9195)	Acc@1 60.938 (61.671)	Acc@5 92.188 (89.031)
[epoch:44, iter:34327] Loss: 1.435, 10.557, 67.229, 440.741, 1.387
[epoch:44, iter:34347] Loss: 1.436, 10.560, 67.233, 440.786, 1.166
[epoch:44, iter:34367] Loss: 1.436, 10.560, 67.242, 440.700, 2.011
[epoch:44, iter:34387] Loss: 1.437, 10.558, 67.266, 440.659, 1.260
[epoch:44, iter:34407] Loss: 1.437, 10.557, 67.261, 440.569, 1.704
 * Acc@1 61.792 Acc@5 88.980
epoch 43, total time 60.34
Test: [0/313]	Time 0.255 (0.255)	Loss 2.1507 (2.1507)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.3374 (1.9897)	Acc@1 43.750 (55.569)	Acc@5 87.500 (85.149)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3773 (1.9563)	Acc@1 65.625 (55.706)	Acc@5 90.625 (85.137)
Test: [300/313]	Time 0.005 (0.008)	Loss 2.5154 (1.9615)	Acc@1 43.750 (55.793)	Acc@5 81.250 (84.988)
 * Acc@1 55.920 Acc@5 85.090
==> training...
Epoch: [44][0/782]	Time 0.483 (0.483)	Data 0.411 (0.411)	Loss 14.7374 (14.7374)	Acc@1 56.250 (56.250)	Acc@5 87.500 (87.500)
[epoch:45, iter:34409] Loss: 1.471, 10.635, 71.162, 447.068, 1.746
[epoch:45, iter:34429] Loss: 1.437, 10.593, 67.104, 439.945, 1.198
[epoch:45, iter:34449] Loss: 1.443, 10.573, 66.591, 438.690, 1.612
[epoch:45, iter:34469] Loss: 1.433, 10.551, 66.841, 438.587, 1.070
[epoch:45, iter:34489] Loss: 1.427, 10.524, 66.747, 438.343, 1.498
Epoch: [44][100/782]	Time 0.071 (0.079)	Data 0.002 (0.007)	Loss 12.3814 (13.7529)	Acc@1 67.188 (63.011)	Acc@5 85.938 (89.295)
[epoch:45, iter:34509] Loss: 1.429, 10.538, 66.633, 438.616, 1.230
[epoch:45, iter:34529] Loss: 1.428, 10.565, 66.640, 439.239, 1.687
[epoch:45, iter:34549] Loss: 1.427, 10.543, 66.587, 439.073, 1.262
[epoch:45, iter:34569] Loss: 1.428, 10.545, 66.567, 439.311, 1.200
[epoch:45, iter:34589] Loss: 1.424, 10.528, 66.592, 439.220, 1.583
Epoch: [44][200/782]	Time 0.084 (0.079)	Data 0.002 (0.005)	Loss 14.4095 (13.7518)	Acc@1 54.688 (62.578)	Acc@5 84.375 (89.226)
[epoch:45, iter:34609] Loss: 1.422, 10.519, 66.648, 439.093, 1.740
[epoch:45, iter:34629] Loss: 1.423, 10.512, 66.725, 439.117, 1.060
[epoch:45, iter:34649] Loss: 1.423, 10.512, 66.770, 439.162, 1.857
[epoch:45, iter:34669] Loss: 1.424, 10.507, 66.769, 439.219, 1.330
[epoch:45, iter:34689] Loss: 1.425, 10.509, 66.749, 439.133, 1.255
Epoch: [44][300/782]	Time 0.068 (0.078)	Data 0.002 (0.004)	Loss 14.3882 (13.7842)	Acc@1 56.250 (62.464)	Acc@5 89.062 (89.348)
[epoch:45, iter:34709] Loss: 1.426, 10.514, 66.828, 439.198, 1.603
[epoch:45, iter:34729] Loss: 1.425, 10.514, 66.806, 439.212, 1.376
[epoch:45, iter:34749] Loss: 1.426, 10.514, 66.858, 439.397, 1.172
[epoch:45, iter:34769] Loss: 1.426, 10.512, 66.870, 439.413, 1.254
[epoch:45, iter:34789] Loss: 1.425, 10.508, 66.885, 439.414, 1.340
Epoch: [44][400/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 14.3018 (13.8243)	Acc@1 68.750 (61.978)	Acc@5 90.625 (89.078)
[epoch:45, iter:34809] Loss: 1.426, 10.511, 66.896, 439.555, 1.317
[epoch:45, iter:34829] Loss: 1.427, 10.506, 66.895, 439.600, 1.172
[epoch:45, iter:34849] Loss: 1.426, 10.505, 66.888, 439.558, 1.496
[epoch:45, iter:34869] Loss: 1.427, 10.510, 66.888, 439.591, 1.588
[epoch:45, iter:34889] Loss: 1.427, 10.508, 66.870, 439.602, 1.227
Epoch: [44][500/782]	Time 0.070 (0.076)	Data 0.002 (0.003)	Loss 13.6072 (13.8256)	Acc@1 64.062 (61.904)	Acc@5 87.500 (88.991)
[epoch:45, iter:34909] Loss: 1.427, 10.508, 66.859, 439.560, 1.248
[epoch:45, iter:34929] Loss: 1.426, 10.514, 66.849, 439.600, 1.409
[epoch:45, iter:34949] Loss: 1.426, 10.511, 66.854, 439.678, 1.679
[epoch:45, iter:34969] Loss: 1.427, 10.515, 66.845, 439.648, 1.301
[epoch:45, iter:34989] Loss: 1.428, 10.511, 66.855, 439.592, 1.492
Epoch: [44][600/782]	Time 0.059 (0.077)	Data 0.002 (0.003)	Loss 13.5698 (13.8343)	Acc@1 70.312 (61.972)	Acc@5 93.750 (89.073)
[epoch:45, iter:35009] Loss: 1.428, 10.514, 66.857, 439.624, 0.934
[epoch:45, iter:35029] Loss: 1.429, 10.517, 66.877, 439.692, 1.340
[epoch:45, iter:35049] Loss: 1.429, 10.519, 66.901, 439.812, 1.339
[epoch:45, iter:35069] Loss: 1.429, 10.520, 66.914, 439.871, 1.439
[epoch:45, iter:35089] Loss: 1.429, 10.526, 66.915, 439.919, 1.431
Epoch: [44][700/782]	Time 0.079 (0.076)	Data 0.002 (0.003)	Loss 13.6616 (13.8663)	Acc@1 57.812 (61.831)	Acc@5 89.062 (88.891)
[epoch:45, iter:35109] Loss: 1.429, 10.525, 66.913, 439.949, 1.496
[epoch:45, iter:35129] Loss: 1.429, 10.525, 66.920, 439.963, 1.199
[epoch:45, iter:35149] Loss: 1.430, 10.522, 66.902, 439.899, 1.279
[epoch:45, iter:35169] Loss: 1.430, 10.526, 66.918, 439.908, 1.048
[epoch:45, iter:35189] Loss: 1.430, 10.524, 66.909, 439.923, 1.158
 * Acc@1 61.808 Acc@5 88.942
epoch 44, total time 60.26
Test: [0/313]	Time 0.270 (0.270)	Loss 1.5616 (1.5616)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.9494 (1.8224)	Acc@1 50.000 (57.302)	Acc@5 81.250 (85.458)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.2776 (1.8127)	Acc@1 62.500 (57.074)	Acc@5 93.750 (85.463)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.2680 (1.8170)	Acc@1 59.375 (56.998)	Acc@5 81.250 (85.455)
 * Acc@1 57.090 Acc@5 85.450
saving the best model!
==> training...
Epoch: [45][0/782]	Time 0.473 (0.473)	Data 0.400 (0.400)	Loss 14.8883 (14.8883)	Acc@1 57.812 (57.812)	Acc@5 85.938 (85.938)
[epoch:46, iter:35191] Loss: 1.537, 10.756, 71.148, 449.840, 1.803
[epoch:46, iter:35211] Loss: 1.429, 10.655, 67.056, 437.921, 0.908
[epoch:46, iter:35231] Loss: 1.421, 10.587, 66.882, 438.575, 1.726
[epoch:46, iter:35251] Loss: 1.424, 10.588, 67.000, 439.231, 1.104
[epoch:46, iter:35271] Loss: 1.427, 10.559, 67.102, 440.263, 1.182
Epoch: [45][100/782]	Time 0.080 (0.079)	Data 0.003 (0.006)	Loss 13.6738 (13.8030)	Acc@1 67.188 (62.454)	Acc@5 89.062 (89.991)
[epoch:46, iter:35291] Loss: 1.430, 10.544, 67.138, 440.658, 1.262
[epoch:46, iter:35311] Loss: 1.431, 10.526, 66.938, 440.080, 1.023
[epoch:46, iter:35331] Loss: 1.432, 10.519, 66.873, 439.769, 1.223
[epoch:46, iter:35351] Loss: 1.433, 10.517, 66.902, 439.470, 1.316
[epoch:46, iter:35371] Loss: 1.433, 10.515, 66.953, 439.359, 1.459
Epoch: [45][200/782]	Time 0.070 (0.079)	Data 0.002 (0.004)	Loss 15.2557 (13.7914)	Acc@1 53.125 (62.174)	Acc@5 81.250 (89.894)
[epoch:46, iter:35391] Loss: 1.434, 10.517, 66.937, 439.313, 1.825
[epoch:46, iter:35411] Loss: 1.432, 10.505, 66.924, 439.224, 1.308
[epoch:46, iter:35431] Loss: 1.431, 10.497, 66.894, 439.253, 1.498
[epoch:46, iter:35451] Loss: 1.430, 10.492, 66.853, 439.292, 1.272
[epoch:46, iter:35471] Loss: 1.429, 10.492, 66.792, 439.148, 1.230
Epoch: [45][300/782]	Time 0.089 (0.078)	Data 0.002 (0.004)	Loss 13.2357 (13.7809)	Acc@1 57.812 (61.991)	Acc@5 89.062 (89.659)
[epoch:46, iter:35491] Loss: 1.428, 10.486, 66.776, 439.165, 1.428
[epoch:46, iter:35511] Loss: 1.426, 10.477, 66.741, 439.205, 1.842
[epoch:46, iter:35531] Loss: 1.427, 10.480, 66.789, 439.357, 1.582
[epoch:46, iter:35551] Loss: 1.428, 10.487, 66.785, 439.376, 1.224
[epoch:46, iter:35571] Loss: 1.428, 10.492, 66.804, 439.224, 1.413
Epoch: [45][400/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 12.9699 (13.8012)	Acc@1 73.438 (61.861)	Acc@5 98.438 (89.503)
[epoch:46, iter:35591] Loss: 1.428, 10.495, 66.815, 439.238, 0.844
[epoch:46, iter:35611] Loss: 1.428, 10.496, 66.812, 439.256, 1.412
[epoch:46, iter:35631] Loss: 1.429, 10.502, 66.809, 439.329, 0.877
[epoch:46, iter:35651] Loss: 1.429, 10.504, 66.829, 439.565, 1.854
[epoch:46, iter:35671] Loss: 1.430, 10.503, 66.843, 439.783, 1.307
Epoch: [45][500/782]	Time 0.082 (0.079)	Data 0.003 (0.003)	Loss 14.7058 (13.8491)	Acc@1 56.250 (61.733)	Acc@5 82.812 (89.231)
[epoch:46, iter:35691] Loss: 1.431, 10.507, 66.883, 439.947, 1.679
[epoch:46, iter:35711] Loss: 1.432, 10.508, 66.895, 439.901, 1.387
[epoch:46, iter:35731] Loss: 1.432, 10.507, 66.913, 439.946, 0.994
[epoch:46, iter:35751] Loss: 1.432, 10.510, 66.930, 440.014, 1.539
[epoch:46, iter:35771] Loss: 1.432, 10.518, 66.940, 440.103, 1.441
Epoch: [45][600/782]	Time 0.064 (0.079)	Data 0.002 (0.003)	Loss 13.3779 (13.8794)	Acc@1 62.500 (61.611)	Acc@5 87.500 (89.094)
[epoch:46, iter:35791] Loss: 1.432, 10.522, 66.980, 440.199, 1.236
[epoch:46, iter:35811] Loss: 1.433, 10.521, 66.995, 440.128, 0.961
[epoch:46, iter:35831] Loss: 1.432, 10.521, 66.978, 440.068, 1.809
[epoch:46, iter:35851] Loss: 1.433, 10.527, 66.993, 440.181, 1.223
[epoch:46, iter:35871] Loss: 1.433, 10.527, 67.011, 440.157, 1.067
Epoch: [45][700/782]	Time 0.056 (0.078)	Data 0.002 (0.003)	Loss 14.3070 (13.8812)	Acc@1 57.812 (61.678)	Acc@5 85.938 (89.076)
[epoch:46, iter:35891] Loss: 1.432, 10.529, 67.028, 440.145, 1.752
[epoch:46, iter:35911] Loss: 1.432, 10.527, 67.052, 440.183, 1.956
[epoch:46, iter:35931] Loss: 1.432, 10.530, 67.082, 440.329, 1.419
[epoch:46, iter:35951] Loss: 1.432, 10.534, 67.094, 440.393, 1.561
[epoch:46, iter:35971] Loss: 1.433, 10.534, 67.094, 440.317, 1.425
 * Acc@1 61.586 Acc@5 88.928
epoch 45, total time 60.79
Test: [0/313]	Time 0.243 (0.243)	Loss 2.1605 (2.1605)	Acc@1 65.625 (65.625)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.6609 (2.2945)	Acc@1 43.750 (51.454)	Acc@5 78.125 (81.219)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.0629 (2.2851)	Acc@1 43.750 (50.917)	Acc@5 87.500 (80.286)
Test: [300/313]	Time 0.006 (0.007)	Loss 3.1991 (2.2784)	Acc@1 40.625 (51.391)	Acc@5 75.000 (80.336)
 * Acc@1 51.660 Acc@5 80.460
==> training...
Epoch: [46][0/782]	Time 0.578 (0.578)	Data 0.487 (0.487)	Loss 14.4986 (14.4986)	Acc@1 56.250 (56.250)	Acc@5 87.500 (87.500)
[epoch:47, iter:35973] Loss: 1.417, 10.695, 70.336, 447.022, 1.596
[epoch:47, iter:35993] Loss: 1.426, 10.634, 67.967, 440.146, 1.211
[epoch:47, iter:36013] Loss: 1.430, 10.594, 66.605, 437.009, 1.194
[epoch:47, iter:36033] Loss: 1.424, 10.562, 66.060, 436.480, 1.292
[epoch:47, iter:36053] Loss: 1.420, 10.522, 65.951, 435.846, 1.708
Epoch: [46][100/782]	Time 0.092 (0.085)	Data 0.003 (0.007)	Loss 13.6192 (13.5643)	Acc@1 60.938 (63.320)	Acc@5 85.938 (89.898)
[epoch:47, iter:36073] Loss: 1.416, 10.485, 66.182, 436.291, 1.413
[epoch:47, iter:36093] Loss: 1.420, 10.479, 66.411, 436.870, 1.238
[epoch:47, iter:36113] Loss: 1.426, 10.505, 66.710, 437.874, 0.919
[epoch:47, iter:36133] Loss: 1.422, 10.504, 66.618, 437.912, 1.344
[epoch:47, iter:36153] Loss: 1.424, 10.505, 66.691, 438.386, 1.252
Epoch: [46][200/782]	Time 0.088 (0.085)	Data 0.003 (0.005)	Loss 14.0241 (13.7205)	Acc@1 60.938 (62.974)	Acc@5 85.938 (89.521)
[epoch:47, iter:36173] Loss: 1.423, 10.489, 66.718, 438.488, 1.595
[epoch:47, iter:36193] Loss: 1.422, 10.484, 66.723, 438.760, 1.292
[epoch:47, iter:36213] Loss: 1.422, 10.490, 66.790, 438.787, 1.530
[epoch:47, iter:36233] Loss: 1.423, 10.493, 66.834, 438.763, 1.577
[epoch:47, iter:36253] Loss: 1.425, 10.498, 66.904, 439.119, 0.865
Epoch: [46][300/782]	Time 0.081 (0.083)	Data 0.002 (0.004)	Loss 15.2729 (13.7925)	Acc@1 54.688 (62.417)	Acc@5 85.938 (89.213)
[epoch:47, iter:36273] Loss: 1.427, 10.506, 66.949, 439.369, 1.749
[epoch:47, iter:36293] Loss: 1.426, 10.506, 66.916, 439.383, 1.307
[epoch:47, iter:36313] Loss: 1.426, 10.499, 66.903, 439.437, 1.226
[epoch:47, iter:36333] Loss: 1.425, 10.498, 66.845, 439.249, 1.165
[epoch:47, iter:36353] Loss: 1.424, 10.498, 66.871, 439.296, 0.972
Epoch: [46][400/782]	Time 0.077 (0.080)	Data 0.002 (0.004)	Loss 13.5955 (13.7854)	Acc@1 67.188 (62.449)	Acc@5 95.312 (89.269)
[epoch:47, iter:36373] Loss: 1.424, 10.505, 66.886, 439.329, 1.173
[epoch:47, iter:36393] Loss: 1.424, 10.505, 66.917, 439.393, 1.360
[epoch:47, iter:36413] Loss: 1.425, 10.508, 66.945, 439.443, 1.503
[epoch:47, iter:36433] Loss: 1.426, 10.510, 66.953, 439.467, 1.241
[epoch:47, iter:36453] Loss: 1.427, 10.517, 66.957, 439.480, 1.463
Epoch: [46][500/782]	Time 0.087 (0.079)	Data 0.004 (0.003)	Loss 15.4231 (13.8166)	Acc@1 54.688 (62.201)	Acc@5 87.500 (89.178)
[epoch:47, iter:36473] Loss: 1.427, 10.515, 66.953, 439.493, 1.757
[epoch:47, iter:36493] Loss: 1.427, 10.512, 66.965, 439.508, 1.561
[epoch:47, iter:36513] Loss: 1.427, 10.512, 66.940, 439.469, 1.222
[epoch:47, iter:36533] Loss: 1.426, 10.505, 66.898, 439.341, 1.000
[epoch:47, iter:36553] Loss: 1.427, 10.506, 66.913, 439.411, 1.265
Epoch: [46][600/782]	Time 0.093 (0.080)	Data 0.002 (0.003)	Loss 14.6279 (13.8250)	Acc@1 56.250 (61.920)	Acc@5 93.750 (89.179)
[epoch:47, iter:36573] Loss: 1.428, 10.507, 66.891, 439.445, 1.638
[epoch:47, iter:36593] Loss: 1.428, 10.509, 66.891, 439.460, 1.575
[epoch:47, iter:36613] Loss: 1.428, 10.511, 66.893, 439.550, 1.607
[epoch:47, iter:36633] Loss: 1.429, 10.510, 66.890, 439.618, 1.223
[epoch:47, iter:36653] Loss: 1.429, 10.510, 66.926, 439.801, 2.285
Epoch: [46][700/782]	Time 0.084 (0.079)	Data 0.003 (0.003)	Loss 13.6496 (13.8553)	Acc@1 59.375 (61.662)	Acc@5 89.062 (89.054)
[epoch:47, iter:36673] Loss: 1.428, 10.509, 66.916, 439.761, 1.449
[epoch:47, iter:36693] Loss: 1.428, 10.511, 66.913, 439.770, 1.653
[epoch:47, iter:36713] Loss: 1.428, 10.512, 66.907, 439.793, 1.434
[epoch:47, iter:36733] Loss: 1.429, 10.511, 66.906, 439.781, 1.777
[epoch:47, iter:36753] Loss: 1.428, 10.508, 66.907, 439.767, 1.227
 * Acc@1 61.642 Acc@5 88.968
epoch 46, total time 62.56
Test: [0/313]	Time 0.291 (0.291)	Loss 1.4075 (1.4075)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.0697 (1.9311)	Acc@1 59.375 (55.260)	Acc@5 84.375 (84.499)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.6436 (1.9395)	Acc@1 65.625 (55.675)	Acc@5 87.500 (84.375)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.4607 (1.9447)	Acc@1 40.625 (55.430)	Acc@5 78.125 (83.980)
 * Acc@1 55.460 Acc@5 84.000
==> training...
Epoch: [47][0/782]	Time 0.532 (0.532)	Data 0.465 (0.465)	Loss 13.9210 (13.9210)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
[epoch:48, iter:36755] Loss: 1.451, 10.247, 67.567, 441.728, 1.530
[epoch:48, iter:36775] Loss: 1.438, 10.591, 67.188, 441.994, 0.882
[epoch:48, iter:36795] Loss: 1.439, 10.574, 67.258, 441.508, 1.461
[epoch:48, iter:36815] Loss: 1.432, 10.548, 66.860, 440.102, 1.658
[epoch:48, iter:36835] Loss: 1.431, 10.520, 66.658, 439.573, 1.093
Epoch: [47][100/782]	Time 0.077 (0.081)	Data 0.003 (0.007)	Loss 13.4064 (13.7396)	Acc@1 60.938 (62.608)	Acc@5 87.500 (89.155)
[epoch:48, iter:36855] Loss: 1.429, 10.496, 66.599, 439.179, 1.338
[epoch:48, iter:36875] Loss: 1.422, 10.478, 66.586, 438.873, 1.223
[epoch:48, iter:36895] Loss: 1.419, 10.456, 66.475, 438.439, 1.353
[epoch:48, iter:36915] Loss: 1.420, 10.465, 66.454, 438.610, 1.232
[epoch:48, iter:36935] Loss: 1.421, 10.465, 66.457, 438.781, 1.368
Epoch: [47][200/782]	Time 0.076 (0.079)	Data 0.002 (0.005)	Loss 13.1753 (13.7567)	Acc@1 62.500 (62.570)	Acc@5 92.188 (89.405)
[epoch:48, iter:36955] Loss: 1.423, 10.472, 66.512, 439.095, 1.160
[epoch:48, iter:36975] Loss: 1.425, 10.481, 66.596, 439.342, 1.403
[epoch:48, iter:36995] Loss: 1.426, 10.493, 66.628, 439.523, 1.500
[epoch:48, iter:37015] Loss: 1.426, 10.485, 66.639, 439.257, 1.035
[epoch:48, iter:37035] Loss: 1.425, 10.482, 66.655, 439.215, 0.778
Epoch: [47][300/782]	Time 0.091 (0.079)	Data 0.003 (0.004)	Loss 14.4296 (13.7795)	Acc@1 53.125 (62.386)	Acc@5 81.250 (89.431)
[epoch:48, iter:37055] Loss: 1.426, 10.483, 66.693, 439.283, 1.750
[epoch:48, iter:37075] Loss: 1.426, 10.492, 66.676, 439.239, 0.999
[epoch:48, iter:37095] Loss: 1.426, 10.492, 66.700, 439.189, 2.011
[epoch:48, iter:37115] Loss: 1.424, 10.494, 66.705, 439.173, 1.493
[epoch:48, iter:37135] Loss: 1.424, 10.494, 66.707, 439.149, 1.653
Epoch: [47][400/782]	Time 0.083 (0.080)	Data 0.003 (0.004)	Loss 13.9121 (13.7847)	Acc@1 57.812 (62.562)	Acc@5 87.500 (89.304)
[epoch:48, iter:37155] Loss: 1.424, 10.491, 66.693, 439.060, 1.674
[epoch:48, iter:37175] Loss: 1.423, 10.487, 66.700, 439.053, 1.417
[epoch:48, iter:37195] Loss: 1.425, 10.488, 66.708, 439.097, 1.457
[epoch:48, iter:37215] Loss: 1.425, 10.488, 66.756, 439.266, 2.024
[epoch:48, iter:37235] Loss: 1.427, 10.492, 66.809, 439.481, 1.317
Epoch: [47][500/782]	Time 0.062 (0.080)	Data 0.002 (0.003)	Loss 14.0029 (13.8386)	Acc@1 65.625 (62.148)	Acc@5 92.188 (89.094)
[epoch:48, iter:37255] Loss: 1.428, 10.501, 66.864, 439.617, 1.252
[epoch:48, iter:37275] Loss: 1.427, 10.506, 66.871, 439.597, 1.788
[epoch:48, iter:37295] Loss: 1.428, 10.509, 66.880, 439.707, 1.498
[epoch:48, iter:37315] Loss: 1.429, 10.515, 66.903, 439.896, 1.382
[epoch:48, iter:37335] Loss: 1.429, 10.523, 66.912, 439.984, 1.258
Epoch: [47][600/782]	Time 0.084 (0.080)	Data 0.002 (0.003)	Loss 13.9301 (13.8855)	Acc@1 64.062 (61.832)	Acc@5 89.062 (88.966)
[epoch:48, iter:37355] Loss: 1.429, 10.527, 66.960, 440.118, 1.250
[epoch:48, iter:37375] Loss: 1.429, 10.529, 66.939, 440.015, 1.658
[epoch:48, iter:37395] Loss: 1.430, 10.533, 66.935, 440.011, 1.859
[epoch:48, iter:37415] Loss: 1.430, 10.532, 66.904, 439.879, 1.558
[epoch:48, iter:37435] Loss: 1.430, 10.529, 66.897, 439.866, 1.233
Epoch: [47][700/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 13.5464 (13.8719)	Acc@1 62.500 (61.878)	Acc@5 87.500 (88.996)
[epoch:48, iter:37455] Loss: 1.430, 10.529, 66.877, 439.849, 1.457
[epoch:48, iter:37475] Loss: 1.430, 10.529, 66.874, 439.803, 1.340
[epoch:48, iter:37495] Loss: 1.431, 10.530, 66.871, 439.738, 1.478
[epoch:48, iter:37515] Loss: 1.430, 10.530, 66.893, 439.784, 1.728
[epoch:48, iter:37535] Loss: 1.431, 10.530, 66.922, 439.842, 1.876
 * Acc@1 61.774 Acc@5 88.982
epoch 47, total time 61.88
Test: [0/313]	Time 0.255 (0.255)	Loss 2.9798 (2.9798)	Acc@1 46.875 (46.875)	Acc@5 65.625 (65.625)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.0153 (2.2468)	Acc@1 46.875 (51.516)	Acc@5 87.500 (80.786)
Test: [200/313]	Time 0.008 (0.009)	Loss 1.9982 (2.2745)	Acc@1 62.500 (50.808)	Acc@5 78.125 (80.224)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5753 (2.2631)	Acc@1 37.500 (51.225)	Acc@5 84.375 (80.419)
 * Acc@1 51.190 Acc@5 80.430
==> training...
Epoch: [48][0/782]	Time 0.597 (0.597)	Data 0.514 (0.514)	Loss 14.2146 (14.2146)	Acc@1 57.812 (57.812)	Acc@5 85.938 (85.938)
[epoch:49, iter:37537] Loss: 1.618, 10.932, 69.026, 439.769, 1.500
[epoch:49, iter:37557] Loss: 1.464, 10.625, 67.514, 439.917, 1.082
[epoch:49, iter:37577] Loss: 1.447, 10.615, 67.401, 439.312, 1.617
[epoch:49, iter:37597] Loss: 1.449, 10.614, 67.158, 439.241, 1.635
[epoch:49, iter:37617] Loss: 1.445, 10.619, 67.237, 439.967, 1.160
Epoch: [48][100/782]	Time 0.082 (0.080)	Data 0.003 (0.007)	Loss 14.1360 (13.8747)	Acc@1 54.688 (61.835)	Acc@5 84.375 (89.805)
[epoch:49, iter:37637] Loss: 1.444, 10.620, 67.293, 440.576, 1.797
[epoch:49, iter:37657] Loss: 1.441, 10.613, 67.336, 440.463, 1.748
[epoch:49, iter:37677] Loss: 1.438, 10.594, 67.156, 439.878, 1.913
[epoch:49, iter:37697] Loss: 1.439, 10.584, 67.117, 439.782, 1.301
[epoch:49, iter:37717] Loss: 1.434, 10.557, 67.081, 439.628, 1.311
Epoch: [48][200/782]	Time 0.095 (0.079)	Data 0.002 (0.005)	Loss 13.5775 (13.8239)	Acc@1 70.312 (61.995)	Acc@5 92.188 (89.024)
[epoch:49, iter:37737] Loss: 1.431, 10.546, 66.993, 439.490, 1.166
[epoch:49, iter:37757] Loss: 1.431, 10.547, 67.146, 439.738, 1.388
[epoch:49, iter:37777] Loss: 1.432, 10.540, 67.110, 439.569, 0.902
[epoch:49, iter:37797] Loss: 1.432, 10.539, 67.045, 439.295, 1.646
[epoch:49, iter:37817] Loss: 1.432, 10.542, 67.012, 439.190, 1.387
Epoch: [48][300/782]	Time 0.075 (0.079)	Data 0.002 (0.004)	Loss 13.9804 (13.8026)	Acc@1 68.750 (61.991)	Acc@5 89.062 (89.146)
[epoch:49, iter:37837] Loss: 1.431, 10.539, 66.956, 439.183, 1.263
[epoch:49, iter:37857] Loss: 1.429, 10.536, 66.960, 439.107, 1.592
[epoch:49, iter:37877] Loss: 1.430, 10.536, 66.958, 439.135, 1.170
[epoch:49, iter:37897] Loss: 1.430, 10.533, 66.959, 439.289, 1.449
[epoch:49, iter:37917] Loss: 1.430, 10.532, 66.930, 439.380, 1.303
Epoch: [48][400/782]	Time 0.067 (0.078)	Data 0.002 (0.004)	Loss 12.8809 (13.8199)	Acc@1 73.438 (61.935)	Acc@5 92.188 (89.133)
[epoch:49, iter:37937] Loss: 1.429, 10.535, 66.937, 439.582, 1.147
[epoch:49, iter:37957] Loss: 1.428, 10.532, 66.929, 439.567, 1.175
[epoch:49, iter:37977] Loss: 1.428, 10.532, 66.975, 439.657, 1.157
[epoch:49, iter:37997] Loss: 1.428, 10.529, 66.985, 439.575, 1.430
[epoch:49, iter:38017] Loss: 1.428, 10.532, 67.025, 439.618, 1.593
Epoch: [48][500/782]	Time 0.062 (0.078)	Data 0.002 (0.003)	Loss 13.9177 (13.8278)	Acc@1 67.188 (61.914)	Acc@5 89.062 (89.181)
[epoch:49, iter:38037] Loss: 1.428, 10.528, 67.038, 439.674, 1.239
[epoch:49, iter:38057] Loss: 1.429, 10.534, 67.074, 439.763, 2.042
[epoch:49, iter:38077] Loss: 1.429, 10.537, 67.111, 439.785, 1.367
[epoch:49, iter:38097] Loss: 1.430, 10.540, 67.126, 439.775, 1.608
[epoch:49, iter:38117] Loss: 1.430, 10.540, 67.148, 439.795, 1.220
Epoch: [48][600/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 13.6491 (13.8571)	Acc@1 67.188 (61.850)	Acc@5 92.188 (89.104)
[epoch:49, iter:38137] Loss: 1.430, 10.538, 67.151, 439.842, 1.291
[epoch:49, iter:38157] Loss: 1.430, 10.538, 67.148, 439.929, 1.061
[epoch:49, iter:38177] Loss: 1.430, 10.538, 67.109, 439.820, 1.594
[epoch:49, iter:38197] Loss: 1.430, 10.532, 67.091, 439.753, 1.652
[epoch:49, iter:38217] Loss: 1.430, 10.530, 67.070, 439.770, 1.208
Epoch: [48][700/782]	Time 0.084 (0.078)	Data 0.003 (0.003)	Loss 13.5348 (13.8619)	Acc@1 68.750 (61.762)	Acc@5 93.750 (89.038)
[epoch:49, iter:38237] Loss: 1.429, 10.529, 67.059, 439.864, 1.191
[epoch:49, iter:38257] Loss: 1.429, 10.527, 67.056, 439.860, 1.528
[epoch:49, iter:38277] Loss: 1.429, 10.524, 67.041, 439.860, 1.480
[epoch:49, iter:38297] Loss: 1.429, 10.525, 67.040, 439.932, 1.806
[epoch:49, iter:38317] Loss: 1.429, 10.522, 67.029, 439.859, 1.146
 * Acc@1 61.706 Acc@5 89.004
epoch 48, total time 60.81
Test: [0/313]	Time 0.235 (0.235)	Loss 2.3956 (2.3956)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.2137 (2.0392)	Acc@1 53.125 (55.074)	Acc@5 84.375 (83.756)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4392 (2.0143)	Acc@1 68.750 (54.975)	Acc@5 84.375 (84.064)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.3642 (2.0246)	Acc@1 50.000 (54.921)	Acc@5 84.375 (83.877)
 * Acc@1 55.040 Acc@5 83.920
==> training...
Epoch: [49][0/782]	Time 0.564 (0.564)	Data 0.496 (0.496)	Loss 13.7458 (13.7458)	Acc@1 57.812 (57.812)	Acc@5 92.188 (92.188)
[epoch:50, iter:38319] Loss: 1.409, 10.153, 70.386, 436.989, 1.403
[epoch:50, iter:38339] Loss: 1.435, 10.566, 68.678, 441.188, 1.612
[epoch:50, iter:38359] Loss: 1.430, 10.550, 68.080, 439.069, 1.526
[epoch:50, iter:38379] Loss: 1.423, 10.541, 67.571, 438.358, 1.025
[epoch:50, iter:38399] Loss: 1.423, 10.542, 67.140, 438.394, 1.582
Epoch: [49][100/782]	Time 0.071 (0.076)	Data 0.002 (0.007)	Loss 13.7259 (13.7514)	Acc@1 64.062 (61.726)	Acc@5 90.625 (89.681)
[epoch:50, iter:38419] Loss: 1.422, 10.503, 66.998, 437.532, 1.409
[epoch:50, iter:38439] Loss: 1.424, 10.518, 67.026, 437.719, 1.294
[epoch:50, iter:38459] Loss: 1.429, 10.519, 67.323, 438.778, 1.648
[epoch:50, iter:38479] Loss: 1.430, 10.533, 67.454, 439.166, 1.329
[epoch:50, iter:38499] Loss: 1.430, 10.534, 67.400, 439.023, 1.428
Epoch: [49][200/782]	Time 0.066 (0.076)	Data 0.002 (0.005)	Loss 13.4192 (13.8472)	Acc@1 70.312 (61.451)	Acc@5 92.188 (89.327)
[epoch:50, iter:38519] Loss: 1.429, 10.531, 67.331, 438.962, 0.915
[epoch:50, iter:38539] Loss: 1.428, 10.524, 67.279, 439.039, 1.225
[epoch:50, iter:38559] Loss: 1.429, 10.519, 67.277, 439.179, 1.148
[epoch:50, iter:38579] Loss: 1.427, 10.528, 67.129, 438.900, 1.346
[epoch:50, iter:38599] Loss: 1.428, 10.529, 67.113, 439.105, 1.667
Epoch: [49][300/782]	Time 0.072 (0.075)	Data 0.002 (0.004)	Loss 13.3745 (13.8332)	Acc@1 68.750 (61.654)	Acc@5 89.062 (89.275)
[epoch:50, iter:38619] Loss: 1.428, 10.533, 67.029, 439.138, 1.175
[epoch:50, iter:38639] Loss: 1.427, 10.532, 67.025, 439.265, 0.919
[epoch:50, iter:38659] Loss: 1.428, 10.531, 67.004, 439.372, 1.701
[epoch:50, iter:38679] Loss: 1.428, 10.531, 67.015, 439.370, 1.550
[epoch:50, iter:38699] Loss: 1.428, 10.531, 67.037, 439.428, 0.927
Epoch: [49][400/782]	Time 0.097 (0.076)	Data 0.003 (0.003)	Loss 14.5331 (13.8431)	Acc@1 65.625 (61.970)	Acc@5 89.062 (89.222)
[epoch:50, iter:38719] Loss: 1.430, 10.538, 67.060, 439.526, 1.261
[epoch:50, iter:38739] Loss: 1.432, 10.534, 67.091, 439.564, 1.278
[epoch:50, iter:38759] Loss: 1.433, 10.531, 67.136, 439.582, 1.315
[epoch:50, iter:38779] Loss: 1.434, 10.529, 67.116, 439.482, 1.349
[epoch:50, iter:38799] Loss: 1.434, 10.529, 67.113, 439.450, 1.106
Epoch: [49][500/782]	Time 0.086 (0.077)	Data 0.003 (0.003)	Loss 13.7366 (13.8713)	Acc@1 56.250 (61.561)	Acc@5 89.062 (89.100)
[epoch:50, iter:38819] Loss: 1.434, 10.532, 67.116, 439.443, 1.495
[epoch:50, iter:38839] Loss: 1.434, 10.530, 67.096, 439.407, 1.355
[epoch:50, iter:38859] Loss: 1.433, 10.529, 67.071, 439.356, 1.302
[epoch:50, iter:38879] Loss: 1.433, 10.528, 67.055, 439.367, 1.082
[epoch:50, iter:38899] Loss: 1.432, 10.526, 67.063, 439.420, 1.281
Epoch: [49][600/782]	Time 0.078 (0.077)	Data 0.002 (0.003)	Loss 12.9302 (13.8618)	Acc@1 71.875 (61.574)	Acc@5 89.062 (89.044)
[epoch:50, iter:38919] Loss: 1.431, 10.525, 67.037, 439.319, 1.163
[epoch:50, iter:38939] Loss: 1.432, 10.525, 67.070, 439.486, 1.315
[epoch:50, iter:38959] Loss: 1.431, 10.524, 67.073, 439.475, 1.109
[epoch:50, iter:38979] Loss: 1.432, 10.526, 67.088, 439.570, 1.128
[epoch:50, iter:38999] Loss: 1.432, 10.527, 67.076, 439.548, 1.553
Epoch: [49][700/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 13.4260 (13.8763)	Acc@1 57.812 (61.542)	Acc@5 89.062 (88.969)
[epoch:50, iter:39019] Loss: 1.432, 10.524, 67.051, 439.511, 1.512
[epoch:50, iter:39039] Loss: 1.432, 10.519, 67.018, 439.379, 1.288
[epoch:50, iter:39059] Loss: 1.431, 10.515, 67.035, 439.398, 1.638
[epoch:50, iter:39079] Loss: 1.430, 10.514, 67.048, 439.427, 1.602
[epoch:50, iter:39099] Loss: 1.429, 10.513, 67.017, 439.356, 1.358
 * Acc@1 61.672 Acc@5 88.968
epoch 49, total time 60.32
Test: [0/313]	Time 0.265 (0.265)	Loss 1.6209 (1.6209)	Acc@1 56.250 (56.250)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.7488 (2.0554)	Acc@1 50.000 (54.115)	Acc@5 78.125 (83.354)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7162 (2.0326)	Acc@1 59.375 (54.167)	Acc@5 93.750 (83.551)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5640 (2.0064)	Acc@1 50.000 (54.651)	Acc@5 81.250 (83.794)
 * Acc@1 54.810 Acc@5 83.830
==> training...
Epoch: [50][0/782]	Time 0.596 (0.596)	Data 0.503 (0.503)	Loss 13.7497 (13.7497)	Acc@1 67.188 (67.188)	Acc@5 84.375 (84.375)
[epoch:51, iter:39101] Loss: 1.437, 10.152, 67.235, 436.119, 1.409
[epoch:51, iter:39121] Loss: 1.436, 10.617, 67.202, 440.924, 1.348
[epoch:51, iter:39141] Loss: 1.435, 10.565, 66.960, 440.143, 1.603
[epoch:51, iter:39161] Loss: 1.422, 10.528, 66.720, 438.806, 1.268
[epoch:51, iter:39181] Loss: 1.411, 10.498, 66.474, 437.828, 1.411
Epoch: [50][100/782]	Time 0.087 (0.080)	Data 0.002 (0.007)	Loss 13.7690 (13.7096)	Acc@1 62.500 (63.026)	Acc@5 90.625 (89.325)
[epoch:51, iter:39201] Loss: 1.409, 10.515, 66.429, 438.073, 1.376
[epoch:51, iter:39221] Loss: 1.411, 10.517, 66.562, 438.508, 1.145
[epoch:51, iter:39241] Loss: 1.413, 10.494, 66.548, 437.991, 1.297
[epoch:51, iter:39261] Loss: 1.414, 10.473, 66.556, 437.928, 1.197
[epoch:51, iter:39281] Loss: 1.414, 10.465, 66.646, 437.884, 1.137
Epoch: [50][200/782]	Time 0.085 (0.081)	Data 0.003 (0.005)	Loss 14.1403 (13.7368)	Acc@1 62.500 (62.718)	Acc@5 90.625 (89.397)
[epoch:51, iter:39301] Loss: 1.416, 10.469, 66.707, 438.170, 1.410
[epoch:51, iter:39321] Loss: 1.417, 10.478, 66.732, 438.397, 1.416
[epoch:51, iter:39341] Loss: 1.418, 10.489, 66.708, 438.305, 1.762
[epoch:51, iter:39361] Loss: 1.417, 10.482, 66.733, 438.274, 1.443
[epoch:51, iter:39381] Loss: 1.418, 10.477, 66.734, 438.104, 1.299
Epoch: [50][300/782]	Time 0.062 (0.079)	Data 0.002 (0.004)	Loss 14.5321 (13.7764)	Acc@1 57.812 (62.204)	Acc@5 82.812 (89.249)
[epoch:51, iter:39401] Loss: 1.419, 10.480, 66.815, 438.359, 1.667
[epoch:51, iter:39421] Loss: 1.418, 10.477, 66.860, 438.220, 1.258
[epoch:51, iter:39441] Loss: 1.418, 10.484, 66.861, 438.364, 1.495
[epoch:51, iter:39461] Loss: 1.417, 10.485, 66.872, 438.490, 1.270
[epoch:51, iter:39481] Loss: 1.418, 10.483, 66.887, 438.643, 1.295
Epoch: [50][400/782]	Time 0.064 (0.077)	Data 0.002 (0.003)	Loss 14.2202 (13.7912)	Acc@1 54.688 (62.103)	Acc@5 90.625 (89.413)
[epoch:51, iter:39501] Loss: 1.419, 10.485, 66.865, 438.619, 1.462
[epoch:51, iter:39521] Loss: 1.419, 10.495, 66.857, 438.620, 1.239
[epoch:51, iter:39541] Loss: 1.420, 10.499, 66.831, 438.607, 1.589
[epoch:51, iter:39561] Loss: 1.422, 10.500, 66.833, 438.626, 2.038
[epoch:51, iter:39581] Loss: 1.423, 10.499, 66.828, 438.613, 1.457
Epoch: [50][500/782]	Time 0.064 (0.076)	Data 0.002 (0.003)	Loss 13.4258 (13.7976)	Acc@1 56.250 (62.120)	Acc@5 87.500 (89.371)
[epoch:51, iter:39601] Loss: 1.424, 10.503, 66.850, 438.682, 1.380
[epoch:51, iter:39621] Loss: 1.424, 10.509, 66.880, 438.823, 1.438
[epoch:51, iter:39641] Loss: 1.424, 10.509, 66.880, 438.879, 1.245
[epoch:51, iter:39661] Loss: 1.425, 10.513, 66.891, 438.934, 1.313
[epoch:51, iter:39681] Loss: 1.425, 10.513, 66.893, 438.907, 1.215
Epoch: [50][600/782]	Time 0.083 (0.076)	Data 0.003 (0.003)	Loss 14.2558 (13.8266)	Acc@1 54.688 (62.003)	Acc@5 81.250 (89.237)
[epoch:51, iter:39701] Loss: 1.424, 10.514, 66.906, 439.006, 1.878
[epoch:51, iter:39721] Loss: 1.424, 10.515, 66.893, 439.024, 1.221
[epoch:51, iter:39741] Loss: 1.424, 10.516, 66.862, 438.918, 1.610
[epoch:51, iter:39761] Loss: 1.424, 10.512, 66.836, 438.866, 1.194
[epoch:51, iter:39781] Loss: 1.424, 10.508, 66.820, 438.815, 1.381
Epoch: [50][700/782]	Time 0.080 (0.076)	Data 0.003 (0.003)	Loss 13.3802 (13.8072)	Acc@1 64.062 (62.105)	Acc@5 87.500 (89.230)
[epoch:51, iter:39801] Loss: 1.424, 10.504, 66.824, 438.859, 1.304
[epoch:51, iter:39821] Loss: 1.424, 10.503, 66.804, 438.748, 1.358
[epoch:51, iter:39841] Loss: 1.424, 10.503, 66.785, 438.767, 1.427
[epoch:51, iter:39861] Loss: 1.424, 10.498, 66.797, 438.804, 2.100
[epoch:51, iter:39881] Loss: 1.424, 10.500, 66.789, 438.844, 1.471
 * Acc@1 61.994 Acc@5 89.166
epoch 50, total time 59.85
Test: [0/313]	Time 0.249 (0.249)	Loss 1.8856 (1.8856)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.4451 (2.0725)	Acc@1 50.000 (52.630)	Acc@5 87.500 (83.385)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5467 (1.9997)	Acc@1 65.625 (53.794)	Acc@5 84.375 (84.126)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.8494 (2.0117)	Acc@1 59.375 (53.561)	Acc@5 84.375 (83.596)
 * Acc@1 53.760 Acc@5 83.620
==> training...
Epoch: [51][0/782]	Time 0.547 (0.547)	Data 0.475 (0.475)	Loss 14.9086 (14.9086)	Acc@1 64.062 (64.062)	Acc@5 87.500 (87.500)
[epoch:52, iter:39883] Loss: 1.489, 10.448, 71.970, 451.105, 1.417
[epoch:52, iter:39903] Loss: 1.449, 10.643, 67.430, 441.322, 1.160
[epoch:52, iter:39923] Loss: 1.447, 10.568, 66.873, 438.778, 1.616
[epoch:52, iter:39943] Loss: 1.436, 10.515, 66.697, 438.623, 1.213
[epoch:52, iter:39963] Loss: 1.431, 10.496, 66.626, 438.691, 1.280
Epoch: [51][100/782]	Time 0.088 (0.081)	Data 0.003 (0.007)	Loss 13.1813 (13.6763)	Acc@1 64.062 (63.103)	Acc@5 93.750 (89.681)
[epoch:52, iter:39983] Loss: 1.424, 10.472, 66.579, 437.957, 1.269
[epoch:52, iter:40003] Loss: 1.427, 10.460, 66.671, 438.678, 1.629
[epoch:52, iter:40023] Loss: 1.430, 10.475, 66.786, 438.771, 1.448
[epoch:52, iter:40043] Loss: 1.430, 10.488, 66.719, 438.293, 1.202
[epoch:52, iter:40063] Loss: 1.430, 10.497, 66.714, 438.219, 1.426
Epoch: [51][200/782]	Time 0.072 (0.081)	Data 0.002 (0.005)	Loss 14.9731 (13.7639)	Acc@1 46.875 (62.399)	Acc@5 89.062 (89.366)
[epoch:52, iter:40083] Loss: 1.430, 10.506, 66.874, 438.431, 1.657
[epoch:52, iter:40103] Loss: 1.429, 10.508, 66.864, 438.369, 1.159
[epoch:52, iter:40123] Loss: 1.429, 10.513, 66.812, 438.148, 1.272
[epoch:52, iter:40143] Loss: 1.428, 10.512, 66.792, 438.170, 1.599
[epoch:52, iter:40163] Loss: 1.428, 10.514, 66.862, 438.451, 1.765
Epoch: [51][300/782]	Time 0.083 (0.077)	Data 0.003 (0.004)	Loss 14.1946 (13.7798)	Acc@1 60.938 (62.183)	Acc@5 85.938 (89.338)
[epoch:52, iter:40183] Loss: 1.427, 10.520, 66.843, 438.571, 1.477
[epoch:52, iter:40203] Loss: 1.430, 10.525, 66.881, 438.621, 1.060
[epoch:52, iter:40223] Loss: 1.429, 10.524, 66.858, 438.656, 1.733
[epoch:52, iter:40243] Loss: 1.428, 10.521, 66.809, 438.519, 1.563
[epoch:52, iter:40263] Loss: 1.427, 10.521, 66.816, 438.307, 1.275
Epoch: [51][400/782]	Time 0.064 (0.078)	Data 0.002 (0.004)	Loss 14.6075 (13.7640)	Acc@1 53.125 (62.017)	Acc@5 87.500 (89.413)
[epoch:52, iter:40283] Loss: 1.427, 10.523, 66.819, 438.286, 1.700
[epoch:52, iter:40303] Loss: 1.427, 10.524, 66.804, 438.259, 1.229
[epoch:52, iter:40323] Loss: 1.427, 10.513, 66.777, 438.334, 1.311
[epoch:52, iter:40343] Loss: 1.427, 10.508, 66.771, 438.339, 1.103
[epoch:52, iter:40363] Loss: 1.426, 10.507, 66.817, 438.482, 1.454
Epoch: [51][500/782]	Time 0.061 (0.078)	Data 0.002 (0.003)	Loss 13.2056 (13.7739)	Acc@1 67.188 (61.920)	Acc@5 87.500 (89.343)
[epoch:52, iter:40383] Loss: 1.425, 10.505, 66.850, 438.506, 1.197
[epoch:52, iter:40403] Loss: 1.426, 10.505, 66.841, 438.479, 1.433
[epoch:52, iter:40423] Loss: 1.426, 10.509, 66.855, 438.564, 1.325
[epoch:52, iter:40443] Loss: 1.426, 10.507, 66.857, 438.525, 1.411
[epoch:52, iter:40463] Loss: 1.426, 10.505, 66.832, 438.416, 1.007
Epoch: [51][600/782]	Time 0.063 (0.077)	Data 0.002 (0.003)	Loss 13.0890 (13.7798)	Acc@1 70.312 (61.821)	Acc@5 96.875 (89.260)
[epoch:52, iter:40483] Loss: 1.425, 10.503, 66.815, 438.345, 0.994
[epoch:52, iter:40503] Loss: 1.424, 10.505, 66.793, 438.370, 1.540
[epoch:52, iter:40523] Loss: 1.424, 10.502, 66.786, 438.368, 1.533
[epoch:52, iter:40543] Loss: 1.424, 10.496, 66.801, 438.402, 1.371
[epoch:52, iter:40563] Loss: 1.424, 10.495, 66.765, 438.335, 1.180
Epoch: [51][700/782]	Time 0.088 (0.078)	Data 0.003 (0.003)	Loss 13.6280 (13.7894)	Acc@1 60.938 (61.805)	Acc@5 90.625 (89.232)
[epoch:52, iter:40583] Loss: 1.425, 10.496, 66.777, 438.378, 1.485
[epoch:52, iter:40603] Loss: 1.425, 10.499, 66.779, 438.482, 1.265
[epoch:52, iter:40623] Loss: 1.425, 10.499, 66.776, 438.453, 1.301
[epoch:52, iter:40643] Loss: 1.424, 10.499, 66.792, 438.498, 1.739
[epoch:52, iter:40663] Loss: 1.424, 10.501, 66.818, 438.603, 1.483
 * Acc@1 61.790 Acc@5 89.160
epoch 51, total time 60.73
Test: [0/313]	Time 0.275 (0.275)	Loss 2.0483 (2.0483)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.005 (0.009)	Loss 2.4127 (2.1093)	Acc@1 46.875 (52.970)	Acc@5 78.125 (83.323)
Test: [200/313]	Time 0.010 (0.008)	Loss 1.5881 (2.1083)	Acc@1 62.500 (52.394)	Acc@5 90.625 (83.240)
Test: [300/313]	Time 0.007 (0.008)	Loss 3.1188 (2.1161)	Acc@1 37.500 (52.762)	Acc@5 68.750 (82.984)
 * Acc@1 52.750 Acc@5 83.060
==> training...
Epoch: [52][0/782]	Time 0.532 (0.532)	Data 0.464 (0.464)	Loss 15.0931 (15.0931)	Acc@1 56.250 (56.250)	Acc@5 89.062 (89.062)
[epoch:53, iter:40665] Loss: 1.517, 10.491, 73.721, 460.407, 1.661
[epoch:53, iter:40685] Loss: 1.467, 10.691, 67.115, 442.464, 1.141
[epoch:53, iter:40705] Loss: 1.450, 10.600, 66.633, 441.346, 1.458
[epoch:53, iter:40725] Loss: 1.433, 10.533, 66.278, 438.622, 1.330
[epoch:53, iter:40745] Loss: 1.429, 10.488, 66.381, 438.253, 0.734
Epoch: [52][100/782]	Time 0.087 (0.085)	Data 0.003 (0.007)	Loss 14.1098 (13.6769)	Acc@1 56.250 (63.583)	Acc@5 90.625 (90.439)
[epoch:53, iter:40765] Loss: 1.424, 10.481, 66.387, 437.990, 1.329
[epoch:53, iter:40785] Loss: 1.423, 10.472, 66.318, 437.828, 1.272
[epoch:53, iter:40805] Loss: 1.423, 10.464, 66.428, 438.114, 1.784
[epoch:53, iter:40825] Loss: 1.424, 10.477, 66.559, 438.487, 1.897
[epoch:53, iter:40845] Loss: 1.424, 10.483, 66.631, 438.774, 1.592
Epoch: [52][200/782]	Time 0.066 (0.080)	Data 0.002 (0.005)	Loss 13.2960 (13.7886)	Acc@1 70.312 (62.749)	Acc@5 89.062 (89.397)
[epoch:53, iter:40865] Loss: 1.426, 10.487, 66.632, 438.771, 1.204
[epoch:53, iter:40885] Loss: 1.426, 10.480, 66.596, 438.927, 1.784
[epoch:53, iter:40905] Loss: 1.423, 10.479, 66.654, 438.906, 1.432
[epoch:53, iter:40925] Loss: 1.424, 10.485, 66.695, 438.900, 1.196
[epoch:53, iter:40945] Loss: 1.424, 10.493, 66.667, 438.892, 1.282
Epoch: [52][300/782]	Time 0.091 (0.080)	Data 0.004 (0.004)	Loss 12.8907 (13.8075)	Acc@1 76.562 (62.640)	Acc@5 98.438 (89.301)
[epoch:53, iter:40965] Loss: 1.423, 10.504, 66.672, 439.036, 0.825
[epoch:53, iter:40985] Loss: 1.421, 10.506, 66.712, 438.931, 1.297
[epoch:53, iter:41005] Loss: 1.422, 10.509, 66.746, 438.923, 1.592
[epoch:53, iter:41025] Loss: 1.422, 10.509, 66.741, 438.860, 1.253
[epoch:53, iter:41045] Loss: 1.423, 10.503, 66.751, 438.754, 1.000
Epoch: [52][400/782]	Time 0.076 (0.081)	Data 0.002 (0.004)	Loss 15.3652 (13.8077)	Acc@1 56.250 (62.418)	Acc@5 89.062 (89.261)
[epoch:53, iter:41065] Loss: 1.422, 10.498, 66.753, 438.725, 1.756
[epoch:53, iter:41085] Loss: 1.423, 10.498, 66.766, 438.766, 1.754
[epoch:53, iter:41105] Loss: 1.424, 10.496, 66.831, 438.885, 0.979
[epoch:53, iter:41125] Loss: 1.426, 10.497, 66.864, 439.004, 1.157
[epoch:53, iter:41145] Loss: 1.426, 10.500, 66.871, 439.010, 1.276
Epoch: [52][500/782]	Time 0.057 (0.079)	Data 0.002 (0.003)	Loss 14.1056 (13.8513)	Acc@1 64.062 (62.173)	Acc@5 85.938 (89.150)
[epoch:53, iter:41165] Loss: 1.427, 10.501, 66.930, 439.085, 1.627
[epoch:53, iter:41185] Loss: 1.427, 10.500, 66.919, 439.052, 1.594
[epoch:53, iter:41205] Loss: 1.427, 10.502, 66.935, 439.049, 0.912
[epoch:53, iter:41225] Loss: 1.426, 10.500, 66.915, 439.008, 1.319
[epoch:53, iter:41245] Loss: 1.426, 10.499, 66.870, 438.922, 1.568
Epoch: [52][600/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 13.8947 (13.8423)	Acc@1 59.375 (62.141)	Acc@5 85.938 (89.127)
[epoch:53, iter:41265] Loss: 1.426, 10.500, 66.848, 438.890, 1.541
[epoch:53, iter:41285] Loss: 1.426, 10.495, 66.863, 438.888, 1.256
[epoch:53, iter:41305] Loss: 1.425, 10.495, 66.892, 438.888, 1.653
[epoch:53, iter:41325] Loss: 1.425, 10.498, 66.897, 438.976, 1.155
[epoch:53, iter:41345] Loss: 1.425, 10.498, 66.941, 439.063, 2.033
Epoch: [52][700/782]	Time 0.061 (0.078)	Data 0.002 (0.003)	Loss 14.2468 (13.8550)	Acc@1 65.625 (62.085)	Acc@5 84.375 (89.091)
[epoch:53, iter:41365] Loss: 1.427, 10.501, 66.983, 439.146, 1.629
[epoch:53, iter:41385] Loss: 1.428, 10.505, 67.000, 439.197, 1.375
[epoch:53, iter:41405] Loss: 1.429, 10.507, 67.006, 439.251, 0.845
[epoch:53, iter:41425] Loss: 1.429, 10.507, 66.995, 439.251, 1.101
[epoch:53, iter:41445] Loss: 1.428, 10.501, 66.995, 439.162, 1.408
 * Acc@1 62.170 Acc@5 89.118
epoch 52, total time 61.33
Test: [0/313]	Time 0.223 (0.223)	Loss 1.8732 (1.8732)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.3013 (1.9114)	Acc@1 53.125 (56.467)	Acc@5 84.375 (84.623)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7062 (1.8742)	Acc@1 59.375 (56.048)	Acc@5 90.625 (85.308)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.8972 (1.8758)	Acc@1 62.500 (56.250)	Acc@5 84.375 (85.257)
 * Acc@1 56.350 Acc@5 85.230
==> training...
Epoch: [53][0/782]	Time 0.493 (0.493)	Data 0.419 (0.419)	Loss 14.1483 (14.1483)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
[epoch:54, iter:41447] Loss: 1.379, 10.448, 70.002, 448.366, 1.388
[epoch:54, iter:41467] Loss: 1.426, 10.598, 67.209, 438.749, 1.399
[epoch:54, iter:41487] Loss: 1.429, 10.556, 67.079, 439.750, 1.116
[epoch:54, iter:41507] Loss: 1.431, 10.512, 67.026, 439.432, 1.282
[epoch:54, iter:41527] Loss: 1.430, 10.526, 67.011, 439.240, 1.638
Epoch: [53][100/782]	Time 0.084 (0.084)	Data 0.005 (0.007)	Loss 14.5699 (13.8458)	Acc@1 62.500 (62.082)	Acc@5 90.625 (89.480)
[epoch:54, iter:41547] Loss: 1.430, 10.544, 67.350, 439.970, 1.339
[epoch:54, iter:41567] Loss: 1.428, 10.529, 67.146, 439.310, 1.614
[epoch:54, iter:41587] Loss: 1.429, 10.522, 67.075, 439.093, 1.568
[epoch:54, iter:41607] Loss: 1.429, 10.518, 67.049, 439.063, 1.074
[epoch:54, iter:41627] Loss: 1.428, 10.529, 66.950, 438.845, 1.255
Epoch: [53][200/782]	Time 0.076 (0.082)	Data 0.002 (0.005)	Loss 15.2547 (13.8117)	Acc@1 54.688 (62.002)	Acc@5 84.375 (89.327)
[epoch:54, iter:41647] Loss: 1.430, 10.544, 66.951, 438.948, 1.463
[epoch:54, iter:41667] Loss: 1.430, 10.548, 66.938, 439.017, 1.607
[epoch:54, iter:41687] Loss: 1.429, 10.551, 66.984, 439.231, 1.393
[epoch:54, iter:41707] Loss: 1.430, 10.542, 66.885, 438.844, 1.003
[epoch:54, iter:41727] Loss: 1.430, 10.542, 66.882, 438.726, 1.675
Epoch: [53][300/782]	Time 0.071 (0.081)	Data 0.002 (0.004)	Loss 13.0524 (13.8171)	Acc@1 70.312 (61.965)	Acc@5 84.375 (89.114)
[epoch:54, iter:41747] Loss: 1.430, 10.549, 66.924, 438.787, 1.223
[epoch:54, iter:41767] Loss: 1.429, 10.551, 66.904, 438.674, 0.957
[epoch:54, iter:41787] Loss: 1.429, 10.544, 66.924, 438.648, 1.113
[epoch:54, iter:41807] Loss: 1.431, 10.536, 66.968, 438.669, 1.631
[epoch:54, iter:41827] Loss: 1.431, 10.534, 66.982, 438.675, 1.950
Epoch: [53][400/782]	Time 0.059 (0.079)	Data 0.002 (0.003)	Loss 12.9998 (13.8242)	Acc@1 70.312 (61.997)	Acc@5 89.062 (88.992)
[epoch:54, iter:41847] Loss: 1.431, 10.540, 66.956, 438.687, 1.095
[epoch:54, iter:41867] Loss: 1.431, 10.535, 66.968, 438.826, 1.304
[epoch:54, iter:41887] Loss: 1.430, 10.534, 66.957, 438.957, 1.195
[epoch:54, iter:41907] Loss: 1.431, 10.537, 66.981, 439.102, 1.237
[epoch:54, iter:41927] Loss: 1.429, 10.534, 66.952, 439.160, 1.921
Epoch: [53][500/782]	Time 0.083 (0.079)	Data 0.005 (0.003)	Loss 14.5445 (13.8589)	Acc@1 48.438 (61.674)	Acc@5 85.938 (88.804)
[epoch:54, iter:41947] Loss: 1.430, 10.533, 66.948, 439.166, 1.638
[epoch:54, iter:41967] Loss: 1.430, 10.529, 66.933, 439.158, 1.282
[epoch:54, iter:41987] Loss: 1.429, 10.523, 66.901, 439.063, 1.871
[epoch:54, iter:42007] Loss: 1.428, 10.520, 66.909, 439.069, 1.209
[epoch:54, iter:42027] Loss: 1.427, 10.521, 66.901, 439.093, 1.523
Epoch: [53][600/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 13.8207 (13.8614)	Acc@1 60.938 (61.660)	Acc@5 87.500 (88.761)
[epoch:54, iter:42047] Loss: 1.428, 10.518, 66.902, 439.008, 1.332
[epoch:54, iter:42067] Loss: 1.428, 10.517, 66.930, 439.044, 1.506
[epoch:54, iter:42087] Loss: 1.429, 10.520, 66.908, 438.999, 1.592
[epoch:54, iter:42107] Loss: 1.429, 10.522, 66.902, 438.987, 1.488
[epoch:54, iter:42127] Loss: 1.430, 10.521, 66.932, 439.051, 1.131
Epoch: [53][700/782]	Time 0.062 (0.079)	Data 0.002 (0.003)	Loss 14.5755 (13.8593)	Acc@1 67.188 (61.869)	Acc@5 90.625 (88.869)
[epoch:54, iter:42147] Loss: 1.429, 10.519, 66.932, 439.010, 1.107
[epoch:54, iter:42167] Loss: 1.429, 10.515, 66.932, 438.958, 1.759
[epoch:54, iter:42187] Loss: 1.429, 10.515, 66.954, 438.987, 1.444
[epoch:54, iter:42207] Loss: 1.428, 10.515, 66.946, 439.001, 1.259
[epoch:54, iter:42227] Loss: 1.429, 10.516, 66.938, 438.997, 1.507
 * Acc@1 61.786 Acc@5 88.886
epoch 53, total time 61.33
Test: [0/313]	Time 0.235 (0.235)	Loss 1.8537 (1.8537)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.8775 (2.1645)	Acc@1 46.875 (53.218)	Acc@5 87.500 (83.509)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.1619 (2.1776)	Acc@1 62.500 (53.094)	Acc@5 81.250 (83.520)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.0642 (2.1635)	Acc@1 56.250 (53.499)	Acc@5 87.500 (83.544)
 * Acc@1 53.480 Acc@5 83.640
==> training...
Epoch: [54][0/782]	Time 0.558 (0.558)	Data 0.498 (0.498)	Loss 13.3212 (13.3212)	Acc@1 64.062 (64.062)	Acc@5 87.500 (87.500)
[epoch:55, iter:42229] Loss: 1.508, 10.151, 65.505, 432.136, 1.347
[epoch:55, iter:42249] Loss: 1.444, 10.589, 67.517, 441.672, 1.424
[epoch:55, iter:42269] Loss: 1.445, 10.561, 66.901, 438.613, 1.234
[epoch:55, iter:42289] Loss: 1.441, 10.526, 67.081, 438.852, 1.114
[epoch:55, iter:42309] Loss: 1.435, 10.497, 66.674, 438.311, 1.131
Epoch: [54][100/782]	Time 0.072 (0.080)	Data 0.002 (0.007)	Loss 12.4714 (13.6819)	Acc@1 65.625 (62.995)	Acc@5 93.750 (89.805)
[epoch:55, iter:42329] Loss: 1.432, 10.500, 66.645, 438.435, 1.119
[epoch:55, iter:42349] Loss: 1.433, 10.492, 66.592, 437.912, 1.753
[epoch:55, iter:42369] Loss: 1.430, 10.501, 66.640, 438.001, 1.198
[epoch:55, iter:42389] Loss: 1.429, 10.495, 66.620, 437.802, 1.143
[epoch:55, iter:42409] Loss: 1.426, 10.487, 66.673, 437.912, 1.072
Epoch: [54][200/782]	Time 0.103 (0.077)	Data 0.002 (0.005)	Loss 13.7373 (13.7165)	Acc@1 54.688 (62.407)	Acc@5 92.188 (89.397)
[epoch:55, iter:42429] Loss: 1.426, 10.483, 66.660, 437.929, 1.515
[epoch:55, iter:42449] Loss: 1.426, 10.482, 66.672, 438.060, 1.724
[epoch:55, iter:42469] Loss: 1.428, 10.473, 66.698, 438.253, 1.166
[epoch:55, iter:42489] Loss: 1.430, 10.484, 66.770, 438.444, 1.690
[epoch:55, iter:42509] Loss: 1.430, 10.487, 66.772, 438.415, 1.231
Epoch: [54][300/782]	Time 0.088 (0.078)	Data 0.003 (0.004)	Loss 13.9880 (13.7497)	Acc@1 60.938 (62.246)	Acc@5 87.500 (89.395)
[epoch:55, iter:42529] Loss: 1.429, 10.497, 66.741, 438.576, 1.394
[epoch:55, iter:42549] Loss: 1.431, 10.504, 66.732, 438.724, 1.484
[epoch:55, iter:42569] Loss: 1.429, 10.505, 66.699, 438.708, 1.425
[epoch:55, iter:42589] Loss: 1.429, 10.504, 66.732, 438.682, 1.367
[epoch:55, iter:42609] Loss: 1.429, 10.504, 66.756, 438.754, 1.764
Epoch: [54][400/782]	Time 0.071 (0.078)	Data 0.002 (0.004)	Loss 14.1597 (13.7748)	Acc@1 56.250 (61.943)	Acc@5 87.500 (89.246)
[epoch:55, iter:42629] Loss: 1.429, 10.499, 66.789, 438.716, 1.541
[epoch:55, iter:42649] Loss: 1.429, 10.497, 66.795, 438.667, 1.271
[epoch:55, iter:42669] Loss: 1.428, 10.495, 66.780, 438.678, 1.906
[epoch:55, iter:42689] Loss: 1.427, 10.490, 66.763, 438.525, 1.767
[epoch:55, iter:42709] Loss: 1.427, 10.486, 66.783, 438.432, 1.761
Epoch: [54][500/782]	Time 0.085 (0.079)	Data 0.002 (0.003)	Loss 13.0458 (13.7566)	Acc@1 67.188 (61.995)	Acc@5 93.750 (89.300)
[epoch:55, iter:42729] Loss: 1.427, 10.487, 66.753, 438.288, 1.187
[epoch:55, iter:42749] Loss: 1.427, 10.489, 66.737, 438.258, 1.413
[epoch:55, iter:42769] Loss: 1.428, 10.491, 66.734, 438.297, 1.294
[epoch:55, iter:42789] Loss: 1.429, 10.493, 66.748, 438.360, 1.397
[epoch:55, iter:42809] Loss: 1.429, 10.493, 66.787, 438.452, 1.449
Epoch: [54][600/782]	Time 0.083 (0.079)	Data 0.002 (0.003)	Loss 13.8580 (13.7714)	Acc@1 59.375 (61.998)	Acc@5 87.500 (89.263)
[epoch:55, iter:42829] Loss: 1.428, 10.490, 66.776, 438.426, 1.358
[epoch:55, iter:42849] Loss: 1.428, 10.494, 66.798, 438.542, 1.088
[epoch:55, iter:42869] Loss: 1.427, 10.494, 66.816, 438.569, 1.465
[epoch:55, iter:42889] Loss: 1.427, 10.490, 66.784, 438.450, 1.163
[epoch:55, iter:42909] Loss: 1.427, 10.485, 66.781, 438.388, 1.093
Epoch: [54][700/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.3968 (13.7783)	Acc@1 65.625 (61.947)	Acc@5 92.188 (89.163)
[epoch:55, iter:42929] Loss: 1.427, 10.481, 66.766, 438.339, 1.108
[epoch:55, iter:42949] Loss: 1.427, 10.479, 66.780, 438.368, 1.845
[epoch:55, iter:42969] Loss: 1.427, 10.479, 66.769, 438.371, 1.230
[epoch:55, iter:42989] Loss: 1.427, 10.481, 66.778, 438.355, 1.264
[epoch:55, iter:43009] Loss: 1.427, 10.482, 66.782, 438.414, 1.674
 * Acc@1 61.894 Acc@5 89.112
epoch 54, total time 61.48
Test: [0/313]	Time 0.264 (0.264)	Loss 1.7709 (1.7709)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.5052 (2.1738)	Acc@1 50.000 (53.682)	Acc@5 84.375 (82.704)
Test: [200/313]	Time 0.008 (0.008)	Loss 2.3968 (2.1684)	Acc@1 43.750 (53.762)	Acc@5 84.375 (82.323)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8835 (2.1637)	Acc@1 46.875 (53.520)	Acc@5 78.125 (82.371)
 * Acc@1 53.570 Acc@5 82.490
==> training...
Epoch: [55][0/782]	Time 0.526 (0.526)	Data 0.462 (0.462)	Loss 12.5543 (12.5543)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
[epoch:56, iter:43011] Loss: 1.330, 10.118, 65.215, 418.685, 1.065
[epoch:56, iter:43031] Loss: 1.444, 10.543, 66.528, 439.414, 1.248
[epoch:56, iter:43051] Loss: 1.435, 10.532, 66.481, 437.541, 1.265
[epoch:56, iter:43071] Loss: 1.424, 10.534, 66.618, 438.849, 1.281
[epoch:56, iter:43091] Loss: 1.414, 10.484, 66.053, 436.671, 1.056
Epoch: [55][100/782]	Time 0.092 (0.085)	Data 0.003 (0.007)	Loss 14.2727 (13.6322)	Acc@1 65.625 (63.181)	Acc@5 85.938 (89.821)
[epoch:56, iter:43111] Loss: 1.407, 10.480, 66.140, 436.651, 1.330
[epoch:56, iter:43131] Loss: 1.408, 10.492, 66.215, 436.775, 1.656
[epoch:56, iter:43151] Loss: 1.409, 10.453, 66.178, 436.425, 1.408
[epoch:56, iter:43171] Loss: 1.410, 10.462, 66.196, 436.296, 1.130
[epoch:56, iter:43191] Loss: 1.410, 10.463, 66.284, 436.320, 1.591
Epoch: [55][200/782]	Time 0.061 (0.081)	Data 0.002 (0.005)	Loss 13.3290 (13.6139)	Acc@1 60.938 (63.285)	Acc@5 81.250 (89.607)
[epoch:56, iter:43211] Loss: 1.411, 10.475, 66.218, 436.005, 1.472
[epoch:56, iter:43231] Loss: 1.413, 10.455, 66.177, 436.035, 1.267
[epoch:56, iter:43251] Loss: 1.412, 10.457, 66.232, 436.145, 1.451
[epoch:56, iter:43271] Loss: 1.414, 10.451, 66.308, 436.432, 1.350
[epoch:56, iter:43291] Loss: 1.415, 10.447, 66.267, 436.462, 1.562
Epoch: [55][300/782]	Time 0.092 (0.081)	Data 0.003 (0.004)	Loss 13.2090 (13.6530)	Acc@1 67.188 (62.910)	Acc@5 87.500 (89.374)
[epoch:56, iter:43311] Loss: 1.415, 10.448, 66.302, 436.646, 1.213
[epoch:56, iter:43331] Loss: 1.416, 10.452, 66.323, 436.830, 1.100
[epoch:56, iter:43351] Loss: 1.418, 10.454, 66.374, 437.114, 1.734
[epoch:56, iter:43371] Loss: 1.420, 10.454, 66.402, 437.227, 1.508
[epoch:56, iter:43391] Loss: 1.421, 10.451, 66.443, 437.351, 1.610
Epoch: [55][400/782]	Time 0.089 (0.081)	Data 0.003 (0.004)	Loss 14.0846 (13.6802)	Acc@1 56.250 (63.010)	Acc@5 87.500 (89.429)
[epoch:56, iter:43411] Loss: 1.420, 10.449, 66.406, 437.260, 1.341
[epoch:56, iter:43431] Loss: 1.418, 10.443, 66.382, 437.186, 1.507
[epoch:56, iter:43451] Loss: 1.418, 10.439, 66.364, 437.181, 1.693
[epoch:56, iter:43471] Loss: 1.418, 10.439, 66.361, 437.263, 1.167
[epoch:56, iter:43491] Loss: 1.418, 10.436, 66.390, 437.326, 1.416
Epoch: [55][500/782]	Time 0.075 (0.079)	Data 0.004 (0.003)	Loss 13.8956 (13.6931)	Acc@1 67.188 (62.740)	Acc@5 92.188 (89.381)
[epoch:56, iter:43511] Loss: 1.418, 10.435, 66.414, 437.374, 1.295
[epoch:56, iter:43531] Loss: 1.419, 10.444, 66.459, 437.598, 1.764
[epoch:56, iter:43551] Loss: 1.421, 10.446, 66.512, 437.686, 1.013
[epoch:56, iter:43571] Loss: 1.421, 10.451, 66.513, 437.702, 0.988
[epoch:56, iter:43591] Loss: 1.421, 10.450, 66.538, 437.763, 1.282
Epoch: [55][600/782]	Time 0.098 (0.079)	Data 0.003 (0.003)	Loss 13.5327 (13.7302)	Acc@1 73.438 (62.700)	Acc@5 93.750 (89.335)
[epoch:56, iter:43611] Loss: 1.421, 10.451, 66.531, 437.820, 1.075
[epoch:56, iter:43631] Loss: 1.421, 10.453, 66.526, 437.768, 1.884
[epoch:56, iter:43651] Loss: 1.421, 10.453, 66.519, 437.751, 1.979
[epoch:56, iter:43671] Loss: 1.421, 10.456, 66.533, 437.830, 1.202
[epoch:56, iter:43691] Loss: 1.421, 10.454, 66.543, 437.795, 1.255
Epoch: [55][700/782]	Time 0.060 (0.079)	Data 0.002 (0.003)	Loss 14.8122 (13.7442)	Acc@1 51.562 (62.449)	Acc@5 82.812 (89.239)
[epoch:56, iter:43711] Loss: 1.420, 10.454, 66.548, 437.843, 1.718
[epoch:56, iter:43731] Loss: 1.420, 10.454, 66.542, 437.850, 0.850
[epoch:56, iter:43751] Loss: 1.420, 10.451, 66.532, 437.917, 1.552
[epoch:56, iter:43771] Loss: 1.420, 10.456, 66.568, 437.998, 1.436
[epoch:56, iter:43791] Loss: 1.421, 10.459, 66.576, 438.010, 1.053
 * Acc@1 62.372 Acc@5 89.160
epoch 55, total time 62.02
Test: [0/313]	Time 0.247 (0.247)	Loss 1.6792 (1.6792)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.010)	Loss 3.8887 (2.5887)	Acc@1 37.500 (48.422)	Acc@5 75.000 (77.228)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.2903 (2.5559)	Acc@1 65.625 (49.269)	Acc@5 87.500 (77.830)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.7866 (2.5669)	Acc@1 31.250 (49.086)	Acc@5 84.375 (77.949)
 * Acc@1 49.120 Acc@5 77.890
==> training...
Epoch: [56][0/782]	Time 0.561 (0.561)	Data 0.485 (0.485)	Loss 13.6004 (13.6004)	Acc@1 57.812 (57.812)	Acc@5 89.062 (89.062)
[epoch:57, iter:43793] Loss: 1.400, 10.103, 68.759, 437.276, 1.415
[epoch:57, iter:43813] Loss: 1.460, 10.661, 68.347, 442.587, 1.636
[epoch:57, iter:43833] Loss: 1.453, 10.654, 67.777, 439.990, 1.386
[epoch:57, iter:43853] Loss: 1.441, 10.539, 67.465, 439.251, 1.154
[epoch:57, iter:43873] Loss: 1.434, 10.513, 67.083, 438.230, 1.418
Epoch: [56][100/782]	Time 0.080 (0.085)	Data 0.003 (0.007)	Loss 14.5852 (13.7544)	Acc@1 57.812 (62.949)	Acc@5 90.625 (89.217)
[epoch:57, iter:43893] Loss: 1.433, 10.477, 66.847, 437.964, 1.667
[epoch:57, iter:43913] Loss: 1.430, 10.457, 66.591, 437.541, 1.499
[epoch:57, iter:43933] Loss: 1.428, 10.461, 66.491, 437.251, 1.656
[epoch:57, iter:43953] Loss: 1.428, 10.442, 66.444, 437.100, 1.149
[epoch:57, iter:43973] Loss: 1.425, 10.443, 66.423, 436.987, 1.918
Epoch: [56][200/782]	Time 0.059 (0.078)	Data 0.002 (0.005)	Loss 13.6287 (13.6601)	Acc@1 64.062 (62.780)	Acc@5 90.625 (89.568)
[epoch:57, iter:43993] Loss: 1.424, 10.441, 66.333, 436.893, 1.386
[epoch:57, iter:44013] Loss: 1.422, 10.431, 66.305, 436.813, 1.382
[epoch:57, iter:44033] Loss: 1.419, 10.424, 66.258, 436.679, 1.125
[epoch:57, iter:44053] Loss: 1.420, 10.410, 66.278, 436.510, 1.183
[epoch:57, iter:44073] Loss: 1.419, 10.408, 66.287, 436.417, 2.483
Epoch: [56][300/782]	Time 0.089 (0.078)	Data 0.002 (0.004)	Loss 14.3231 (13.6781)	Acc@1 64.062 (62.287)	Acc@5 96.875 (89.332)
[epoch:57, iter:44093] Loss: 1.419, 10.412, 66.303, 436.623, 1.111
[epoch:57, iter:44113] Loss: 1.419, 10.422, 66.330, 436.856, 1.446
[epoch:57, iter:44133] Loss: 1.419, 10.423, 66.279, 436.846, 1.391
[epoch:57, iter:44153] Loss: 1.421, 10.426, 66.334, 436.901, 1.048
[epoch:57, iter:44173] Loss: 1.421, 10.434, 66.340, 436.850, 1.220
Epoch: [56][400/782]	Time 0.082 (0.078)	Data 0.002 (0.003)	Loss 13.7017 (13.6964)	Acc@1 62.500 (62.293)	Acc@5 89.062 (89.437)
[epoch:57, iter:44193] Loss: 1.422, 10.442, 66.368, 437.049, 1.212
[epoch:57, iter:44213] Loss: 1.423, 10.450, 66.456, 437.429, 1.529
[epoch:57, iter:44233] Loss: 1.423, 10.454, 66.513, 437.465, 1.224
[epoch:57, iter:44253] Loss: 1.423, 10.457, 66.542, 437.618, 1.257
[epoch:57, iter:44273] Loss: 1.425, 10.459, 66.566, 437.728, 1.222
Epoch: [56][500/782]	Time 0.058 (0.077)	Data 0.002 (0.003)	Loss 14.9266 (13.7379)	Acc@1 51.562 (62.179)	Acc@5 78.125 (89.349)
[epoch:57, iter:44293] Loss: 1.424, 10.465, 66.567, 437.704, 2.110
[epoch:57, iter:44313] Loss: 1.423, 10.472, 66.597, 437.763, 1.753
[epoch:57, iter:44333] Loss: 1.423, 10.474, 66.608, 437.803, 1.455
[epoch:57, iter:44353] Loss: 1.424, 10.472, 66.610, 437.721, 1.215
[epoch:57, iter:44373] Loss: 1.425, 10.473, 66.639, 437.760, 1.949
Epoch: [56][600/782]	Time 0.089 (0.077)	Data 0.003 (0.003)	Loss 13.8638 (13.7571)	Acc@1 62.500 (62.152)	Acc@5 87.500 (89.283)
[epoch:57, iter:44393] Loss: 1.425, 10.474, 66.645, 437.794, 1.724
[epoch:57, iter:44413] Loss: 1.423, 10.473, 66.646, 437.822, 1.548
[epoch:57, iter:44433] Loss: 1.424, 10.476, 66.634, 437.880, 1.140
[epoch:57, iter:44453] Loss: 1.424, 10.479, 66.613, 437.866, 1.165
[epoch:57, iter:44473] Loss: 1.423, 10.482, 66.590, 437.865, 1.225
Epoch: [56][700/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 14.0353 (13.7648)	Acc@1 62.500 (62.126)	Acc@5 87.500 (89.196)
[epoch:57, iter:44493] Loss: 1.423, 10.481, 66.599, 437.966, 1.479
[epoch:57, iter:44513] Loss: 1.423, 10.480, 66.618, 438.049, 1.634
[epoch:57, iter:44533] Loss: 1.423, 10.473, 66.592, 437.964, 1.649
[epoch:57, iter:44553] Loss: 1.423, 10.472, 66.613, 437.981, 1.416
[epoch:57, iter:44573] Loss: 1.422, 10.470, 66.596, 437.905, 1.805
 * Acc@1 62.074 Acc@5 89.152
epoch 56, total time 59.99
Test: [0/313]	Time 0.256 (0.256)	Loss 2.7424 (2.7424)	Acc@1 37.500 (37.500)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.4611 (2.0356)	Acc@1 43.750 (52.939)	Acc@5 87.500 (83.540)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.6828 (2.0143)	Acc@1 65.625 (53.607)	Acc@5 93.750 (83.940)
Test: [300/313]	Time 0.008 (0.007)	Loss 2.8379 (2.0088)	Acc@1 37.500 (53.924)	Acc@5 75.000 (83.814)
 * Acc@1 54.090 Acc@5 83.900
==> training...
Epoch: [57][0/782]	Time 0.512 (0.512)	Data 0.444 (0.444)	Loss 13.0126 (13.0126)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
[epoch:58, iter:44575] Loss: 1.368, 10.380, 64.807, 433.333, 1.197
[epoch:58, iter:44595] Loss: 1.403, 10.283, 65.339, 434.978, 1.676
[epoch:58, iter:44615] Loss: 1.400, 10.392, 65.753, 436.465, 1.145
[epoch:58, iter:44635] Loss: 1.411, 10.420, 66.143, 437.350, 1.452
[epoch:58, iter:44655] Loss: 1.412, 10.464, 66.257, 437.635, 1.204
Epoch: [57][100/782]	Time 0.076 (0.086)	Data 0.002 (0.007)	Loss 14.4418 (13.5959)	Acc@1 57.812 (62.670)	Acc@5 79.688 (89.712)
[epoch:58, iter:44675] Loss: 1.412, 10.459, 66.017, 437.254, 1.845
[epoch:58, iter:44695] Loss: 1.414, 10.443, 66.065, 436.973, 1.110
[epoch:58, iter:44715] Loss: 1.414, 10.442, 66.114, 436.908, 1.061
[epoch:58, iter:44735] Loss: 1.413, 10.446, 66.225, 436.833, 1.342
[epoch:58, iter:44755] Loss: 1.412, 10.432, 66.198, 436.710, 1.157
Epoch: [57][200/782]	Time 0.069 (0.084)	Data 0.002 (0.005)	Loss 13.9933 (13.5658)	Acc@1 59.375 (63.106)	Acc@5 85.938 (89.762)
[epoch:58, iter:44775] Loss: 1.411, 10.423, 66.173, 436.388, 1.466
[epoch:58, iter:44795] Loss: 1.412, 10.426, 66.245, 436.664, 1.676
[epoch:58, iter:44815] Loss: 1.413, 10.439, 66.262, 436.733, 0.913
[epoch:58, iter:44835] Loss: 1.413, 10.434, 66.211, 436.576, 1.387
[epoch:58, iter:44855] Loss: 1.412, 10.436, 66.259, 436.630, 1.387
Epoch: [57][300/782]	Time 0.059 (0.080)	Data 0.002 (0.004)	Loss 13.8607 (13.6007)	Acc@1 65.625 (62.910)	Acc@5 90.625 (89.779)
[epoch:58, iter:44875] Loss: 1.413, 10.432, 66.283, 436.694, 1.449
[epoch:58, iter:44895] Loss: 1.412, 10.433, 66.263, 436.707, 1.508
[epoch:58, iter:44915] Loss: 1.414, 10.438, 66.317, 436.979, 1.463
[epoch:58, iter:44935] Loss: 1.415, 10.441, 66.312, 437.008, 1.519
[epoch:58, iter:44955] Loss: 1.417, 10.440, 66.330, 437.046, 1.627
Epoch: [57][400/782]	Time 0.071 (0.078)	Data 0.002 (0.004)	Loss 13.3661 (13.6575)	Acc@1 65.625 (62.625)	Acc@5 90.625 (89.585)
[epoch:58, iter:44975] Loss: 1.417, 10.445, 66.355, 437.079, 1.369
[epoch:58, iter:44995] Loss: 1.416, 10.446, 66.360, 436.997, 1.472
[epoch:58, iter:45015] Loss: 1.417, 10.448, 66.391, 437.030, 1.497
[epoch:58, iter:45035] Loss: 1.417, 10.450, 66.383, 436.972, 1.399
[epoch:58, iter:45055] Loss: 1.417, 10.450, 66.400, 437.112, 1.091
Epoch: [57][500/782]	Time 0.062 (0.079)	Data 0.002 (0.003)	Loss 13.6137 (13.6918)	Acc@1 59.375 (62.425)	Acc@5 89.062 (89.487)
[epoch:58, iter:45075] Loss: 1.418, 10.452, 66.426, 437.223, 1.475
[epoch:58, iter:45095] Loss: 1.418, 10.450, 66.480, 437.273, 1.507
[epoch:58, iter:45115] Loss: 1.419, 10.454, 66.536, 437.468, 1.494
[epoch:58, iter:45135] Loss: 1.419, 10.457, 66.518, 437.387, 1.600
[epoch:58, iter:45155] Loss: 1.419, 10.459, 66.495, 437.331, 1.497
Epoch: [57][600/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 13.8035 (13.7136)	Acc@1 51.562 (62.211)	Acc@5 84.375 (89.465)
[epoch:58, iter:45175] Loss: 1.419, 10.460, 66.540, 437.459, 1.655
[epoch:58, iter:45195] Loss: 1.418, 10.459, 66.549, 437.440, 1.143
[epoch:58, iter:45215] Loss: 1.418, 10.458, 66.552, 437.409, 1.663
[epoch:58, iter:45235] Loss: 1.418, 10.457, 66.597, 437.473, 1.294
[epoch:58, iter:45255] Loss: 1.419, 10.455, 66.625, 437.540, 1.722
Epoch: [57][700/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 13.8305 (13.7359)	Acc@1 60.938 (62.105)	Acc@5 90.625 (89.377)
[epoch:58, iter:45275] Loss: 1.419, 10.461, 66.635, 437.588, 1.422
[epoch:58, iter:45295] Loss: 1.420, 10.463, 66.639, 437.599, 1.653
[epoch:58, iter:45315] Loss: 1.420, 10.464, 66.639, 437.620, 0.986
[epoch:58, iter:45335] Loss: 1.420, 10.461, 66.636, 437.565, 1.448
[epoch:58, iter:45355] Loss: 1.420, 10.463, 66.660, 437.686, 2.181
 * Acc@1 62.022 Acc@5 89.340
epoch 57, total time 60.97
Test: [0/313]	Time 0.262 (0.262)	Loss 1.6374 (1.6374)	Acc@1 65.625 (65.625)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 3.2121 (2.3733)	Acc@1 37.500 (49.474)	Acc@5 84.375 (81.343)
Test: [200/313]	Time 0.006 (0.007)	Loss 2.0136 (2.3372)	Acc@1 53.125 (49.705)	Acc@5 90.625 (81.250)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6178 (2.3457)	Acc@1 37.500 (49.740)	Acc@5 78.125 (81.229)
 * Acc@1 49.860 Acc@5 81.340
==> training...
Epoch: [58][0/782]	Time 0.519 (0.519)	Data 0.441 (0.441)	Loss 14.6418 (14.6418)	Acc@1 50.000 (50.000)	Acc@5 85.938 (85.938)
[epoch:59, iter:45357] Loss: 1.519, 10.296, 68.531, 444.984, 1.863
[epoch:59, iter:45377] Loss: 1.456, 10.558, 68.081, 444.089, 1.603
[epoch:59, iter:45397] Loss: 1.440, 10.562, 67.447, 441.744, 1.174
[epoch:59, iter:45417] Loss: 1.433, 10.534, 66.833, 439.458, 1.253
[epoch:59, iter:45437] Loss: 1.427, 10.454, 66.360, 437.780, 1.245
Epoch: [58][100/782]	Time 0.079 (0.082)	Data 0.003 (0.007)	Loss 13.8419 (13.6169)	Acc@1 76.562 (64.372)	Acc@5 89.062 (89.867)
[epoch:59, iter:45457] Loss: 1.423, 10.444, 66.483, 437.713, 1.225
[epoch:59, iter:45477] Loss: 1.421, 10.443, 66.539, 437.791, 1.600
[epoch:59, iter:45497] Loss: 1.421, 10.445, 66.392, 437.396, 1.538
[epoch:59, iter:45517] Loss: 1.421, 10.443, 66.404, 437.329, 1.340
[epoch:59, iter:45537] Loss: 1.420, 10.445, 66.517, 437.311, 1.309
Epoch: [58][200/782]	Time 0.062 (0.078)	Data 0.002 (0.004)	Loss 13.2205 (13.6456)	Acc@1 68.750 (63.456)	Acc@5 90.625 (89.544)
[epoch:59, iter:45557] Loss: 1.418, 10.445, 66.565, 437.306, 1.139
[epoch:59, iter:45577] Loss: 1.416, 10.445, 66.549, 437.175, 1.611
[epoch:59, iter:45597] Loss: 1.415, 10.445, 66.504, 437.074, 1.132
[epoch:59, iter:45617] Loss: 1.418, 10.467, 66.575, 437.201, 1.070
[epoch:59, iter:45637] Loss: 1.419, 10.476, 66.608, 437.421, 1.072
Epoch: [58][300/782]	Time 0.076 (0.077)	Data 0.002 (0.004)	Loss 12.4922 (13.6937)	Acc@1 67.188 (62.946)	Acc@5 92.188 (89.374)
[epoch:59, iter:45657] Loss: 1.420, 10.475, 66.669, 437.599, 1.066
[epoch:59, iter:45677] Loss: 1.421, 10.475, 66.667, 437.452, 1.205
[epoch:59, iter:45697] Loss: 1.421, 10.477, 66.710, 437.517, 1.023
[epoch:59, iter:45717] Loss: 1.422, 10.483, 66.725, 437.707, 1.332
[epoch:59, iter:45737] Loss: 1.422, 10.485, 66.749, 437.892, 0.982
Epoch: [58][400/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 12.3103 (13.7450)	Acc@1 68.750 (62.395)	Acc@5 93.750 (89.327)
[epoch:59, iter:45757] Loss: 1.423, 10.490, 66.757, 437.950, 1.067
[epoch:59, iter:45777] Loss: 1.423, 10.492, 66.795, 438.003, 1.745
[epoch:59, iter:45797] Loss: 1.422, 10.486, 66.777, 437.975, 0.873
[epoch:59, iter:45817] Loss: 1.421, 10.481, 66.753, 437.950, 1.475
[epoch:59, iter:45837] Loss: 1.422, 10.487, 66.826, 438.121, 1.596
Epoch: [58][500/782]	Time 0.071 (0.077)	Data 0.002 (0.003)	Loss 13.8399 (13.7555)	Acc@1 60.938 (62.244)	Acc@5 84.375 (89.312)
[epoch:59, iter:45857] Loss: 1.421, 10.489, 66.796, 438.161, 1.439
[epoch:59, iter:45877] Loss: 1.421, 10.493, 66.796, 438.226, 1.514
[epoch:59, iter:45897] Loss: 1.421, 10.494, 66.794, 438.244, 1.518
[epoch:59, iter:45917] Loss: 1.421, 10.495, 66.805, 438.360, 1.127
[epoch:59, iter:45937] Loss: 1.421, 10.495, 66.809, 438.335, 1.253
Epoch: [58][600/782]	Time 0.082 (0.077)	Data 0.003 (0.003)	Loss 14.0565 (13.7627)	Acc@1 62.500 (62.162)	Acc@5 90.625 (89.289)
[epoch:59, iter:45957] Loss: 1.422, 10.495, 66.803, 438.257, 1.418
[epoch:59, iter:45977] Loss: 1.421, 10.497, 66.791, 438.198, 1.610
[epoch:59, iter:45997] Loss: 1.422, 10.496, 66.789, 438.200, 1.853
[epoch:59, iter:46017] Loss: 1.422, 10.495, 66.770, 438.201, 1.663
[epoch:59, iter:46037] Loss: 1.423, 10.495, 66.761, 438.143, 0.984
Epoch: [58][700/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.5839 (13.7760)	Acc@1 64.062 (62.019)	Acc@5 90.625 (89.161)
[epoch:59, iter:46057] Loss: 1.424, 10.497, 66.796, 438.182, 1.187
[epoch:59, iter:46077] Loss: 1.424, 10.497, 66.782, 438.146, 2.095
[epoch:59, iter:46097] Loss: 1.425, 10.498, 66.786, 438.195, 1.243
[epoch:59, iter:46117] Loss: 1.425, 10.498, 66.794, 438.207, 1.638
[epoch:59, iter:46137] Loss: 1.425, 10.499, 66.777, 438.179, 1.367
 * Acc@1 62.116 Acc@5 89.172
epoch 58, total time 61.14
Test: [0/313]	Time 0.239 (0.239)	Loss 2.3132 (2.3132)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.4864 (1.9585)	Acc@1 56.250 (55.631)	Acc@5 90.625 (85.736)
Test: [200/313]	Time 0.007 (0.007)	Loss 1.6922 (1.9558)	Acc@1 56.250 (56.063)	Acc@5 90.625 (85.479)
Test: [300/313]	Time 0.009 (0.007)	Loss 2.0566 (1.9751)	Acc@1 53.125 (55.959)	Acc@5 90.625 (85.060)
 * Acc@1 56.040 Acc@5 85.110
==> training...
Epoch: [59][0/782]	Time 0.558 (0.558)	Data 0.473 (0.473)	Loss 14.5095 (14.5095)	Acc@1 46.875 (46.875)	Acc@5 89.062 (89.062)
[epoch:60, iter:46139] Loss: 1.351, 10.849, 68.352, 445.242, 1.823
[epoch:60, iter:46159] Loss: 1.457, 10.681, 66.758, 442.254, 1.302
[epoch:60, iter:46179] Loss: 1.449, 10.603, 66.512, 440.041, 1.190
[epoch:60, iter:46199] Loss: 1.437, 10.532, 66.077, 436.951, 1.204
[epoch:60, iter:46219] Loss: 1.433, 10.524, 66.296, 437.296, 1.451
Epoch: [59][100/782]	Time 0.097 (0.076)	Data 0.003 (0.007)	Loss 13.9462 (13.7074)	Acc@1 64.062 (62.330)	Acc@5 95.312 (89.635)
[epoch:60, iter:46239] Loss: 1.429, 10.493, 66.560, 437.628, 1.393
[epoch:60, iter:46259] Loss: 1.425, 10.481, 66.506, 437.053, 1.381
[epoch:60, iter:46279] Loss: 1.425, 10.475, 66.507, 436.915, 1.308
[epoch:60, iter:46299] Loss: 1.422, 10.471, 66.465, 436.988, 1.292
[epoch:60, iter:46319] Loss: 1.425, 10.459, 66.579, 436.922, 1.100
Epoch: [59][200/782]	Time 0.092 (0.077)	Data 0.003 (0.005)	Loss 14.1207 (13.6936)	Acc@1 57.812 (62.166)	Acc@5 85.938 (89.342)
[epoch:60, iter:46339] Loss: 1.421, 10.462, 66.585, 436.882, 1.650
[epoch:60, iter:46359] Loss: 1.421, 10.453, 66.551, 436.869, 1.439
[epoch:60, iter:46379] Loss: 1.418, 10.451, 66.500, 436.873, 1.941
[epoch:60, iter:46399] Loss: 1.420, 10.454, 66.514, 436.998, 1.287
[epoch:60, iter:46419] Loss: 1.419, 10.452, 66.452, 436.751, 1.205
Epoch: [59][300/782]	Time 0.088 (0.075)	Data 0.002 (0.004)	Loss 13.5219 (13.6481)	Acc@1 62.500 (62.479)	Acc@5 87.500 (89.509)
[epoch:60, iter:46439] Loss: 1.418, 10.449, 66.435, 436.534, 1.363
[epoch:60, iter:46459] Loss: 1.419, 10.446, 66.450, 436.597, 1.545
[epoch:60, iter:46479] Loss: 1.420, 10.448, 66.518, 436.765, 1.225
[epoch:60, iter:46499] Loss: 1.421, 10.450, 66.530, 436.809, 1.483
[epoch:60, iter:46519] Loss: 1.421, 10.456, 66.560, 436.934, 1.465
Epoch: [59][400/782]	Time 0.085 (0.077)	Data 0.004 (0.003)	Loss 14.2734 (13.6851)	Acc@1 64.062 (62.442)	Acc@5 89.062 (89.483)
[epoch:60, iter:46539] Loss: 1.419, 10.456, 66.556, 436.880, 1.558
[epoch:60, iter:46559] Loss: 1.420, 10.457, 66.581, 436.853, 1.744
[epoch:60, iter:46579] Loss: 1.419, 10.460, 66.533, 436.781, 1.265
[epoch:60, iter:46599] Loss: 1.419, 10.458, 66.515, 436.749, 1.348
[epoch:60, iter:46619] Loss: 1.421, 10.461, 66.516, 436.812, 1.179
Epoch: [59][500/782]	Time 0.081 (0.077)	Data 0.003 (0.003)	Loss 13.6963 (13.6840)	Acc@1 64.062 (62.438)	Acc@5 84.375 (89.552)
[epoch:60, iter:46639] Loss: 1.421, 10.460, 66.543, 436.776, 1.599
[epoch:60, iter:46659] Loss: 1.422, 10.464, 66.552, 436.791, 1.306
[epoch:60, iter:46679] Loss: 1.422, 10.462, 66.563, 436.830, 1.701
[epoch:60, iter:46699] Loss: 1.421, 10.464, 66.577, 436.879, 1.430
[epoch:60, iter:46719] Loss: 1.422, 10.467, 66.615, 437.040, 1.296
Epoch: [59][600/782]	Time 0.075 (0.077)	Data 0.002 (0.003)	Loss 14.2508 (13.7174)	Acc@1 62.500 (62.412)	Acc@5 90.625 (89.411)
[epoch:60, iter:46739] Loss: 1.422, 10.468, 66.626, 437.116, 1.345
[epoch:60, iter:46759] Loss: 1.423, 10.469, 66.670, 437.281, 1.896
[epoch:60, iter:46779] Loss: 1.423, 10.474, 66.660, 437.305, 1.523
[epoch:60, iter:46799] Loss: 1.423, 10.475, 66.641, 437.322, 1.474
[epoch:60, iter:46819] Loss: 1.423, 10.478, 66.634, 437.321, 1.261
Epoch: [59][700/782]	Time 0.087 (0.077)	Data 0.003 (0.003)	Loss 12.7783 (13.7457)	Acc@1 65.625 (62.324)	Acc@5 93.750 (89.352)
[epoch:60, iter:46839] Loss: 1.423, 10.477, 66.655, 437.442, 1.082
[epoch:60, iter:46859] Loss: 1.422, 10.480, 66.669, 437.554, 1.112
[epoch:60, iter:46879] Loss: 1.423, 10.482, 66.693, 437.667, 1.536
[epoch:60, iter:46899] Loss: 1.424, 10.484, 66.728, 437.864, 1.664
[epoch:60, iter:46919] Loss: 1.424, 10.484, 66.721, 437.808, 1.734
 * Acc@1 62.272 Acc@5 89.208
epoch 59, total time 59.71
Test: [0/313]	Time 0.243 (0.243)	Loss 1.9011 (1.9011)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.1862 (1.9353)	Acc@1 53.125 (55.662)	Acc@5 84.375 (85.118)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.0832 (1.9121)	Acc@1 65.625 (56.048)	Acc@5 90.625 (85.028)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8598 (1.9169)	Acc@1 50.000 (56.001)	Acc@5 84.375 (85.102)
 * Acc@1 56.040 Acc@5 85.140
==> training...
Epoch: [60][0/782]	Time 0.549 (0.549)	Data 0.457 (0.457)	Loss 13.5725 (13.5725)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
[epoch:61, iter:46921] Loss: 1.391, 10.179, 66.568, 442.068, 1.305
[epoch:61, iter:46941] Loss: 1.425, 10.388, 67.556, 437.415, 1.234
[epoch:61, iter:46961] Loss: 1.421, 10.397, 67.016, 435.514, 1.327
[epoch:61, iter:46981] Loss: 1.416, 10.422, 66.444, 435.081, 1.362
[epoch:61, iter:47001] Loss: 1.416, 10.447, 66.538, 435.883, 1.153
Epoch: [60][100/782]	Time 0.094 (0.086)	Data 0.003 (0.007)	Loss 14.1317 (13.6927)	Acc@1 56.250 (62.345)	Acc@5 92.188 (89.403)
[epoch:61, iter:47021] Loss: 1.418, 10.460, 66.645, 436.824, 1.722
[epoch:61, iter:47041] Loss: 1.419, 10.481, 66.771, 437.541, 1.524
[epoch:61, iter:47061] Loss: 1.419, 10.496, 66.800, 437.838, 1.082
[epoch:61, iter:47081] Loss: 1.422, 10.489, 66.713, 437.814, 0.960
[epoch:61, iter:47101] Loss: 1.423, 10.483, 66.746, 437.675, 1.527
Epoch: [60][200/782]	Time 0.067 (0.084)	Data 0.002 (0.005)	Loss 13.2357 (13.6978)	Acc@1 62.500 (62.562)	Acc@5 95.312 (89.226)
[epoch:61, iter:47121] Loss: 1.421, 10.483, 66.735, 437.663, 1.196
[epoch:61, iter:47141] Loss: 1.421, 10.481, 66.731, 437.890, 1.447
[epoch:61, iter:47161] Loss: 1.423, 10.481, 66.705, 437.829, 1.567
[epoch:61, iter:47181] Loss: 1.423, 10.475, 66.690, 437.783, 1.570
[epoch:61, iter:47201] Loss: 1.424, 10.484, 66.776, 438.201, 1.610
Epoch: [60][300/782]	Time 0.076 (0.083)	Data 0.002 (0.004)	Loss 13.1001 (13.7494)	Acc@1 60.938 (62.209)	Acc@5 89.062 (89.140)
[epoch:61, iter:47221] Loss: 1.422, 10.488, 66.771, 438.406, 1.359
[epoch:61, iter:47241] Loss: 1.422, 10.482, 66.815, 438.449, 1.052
[epoch:61, iter:47261] Loss: 1.423, 10.490, 66.837, 438.429, 1.102
[epoch:61, iter:47281] Loss: 1.423, 10.492, 66.786, 438.317, 1.526
[epoch:61, iter:47301] Loss: 1.423, 10.497, 66.793, 438.271, 1.854
Epoch: [60][400/782]	Time 0.071 (0.081)	Data 0.002 (0.004)	Loss 13.8498 (13.7821)	Acc@1 68.750 (62.099)	Acc@5 87.500 (89.004)
[epoch:61, iter:47321] Loss: 1.422, 10.500, 66.788, 438.414, 1.293
[epoch:61, iter:47341] Loss: 1.423, 10.493, 66.740, 438.283, 1.247
[epoch:61, iter:47361] Loss: 1.421, 10.489, 66.752, 438.215, 1.286
[epoch:61, iter:47381] Loss: 1.421, 10.488, 66.783, 438.177, 1.708
[epoch:61, iter:47401] Loss: 1.422, 10.491, 66.791, 438.311, 1.064
Epoch: [60][500/782]	Time 0.060 (0.081)	Data 0.002 (0.003)	Loss 13.4798 (13.7657)	Acc@1 67.188 (62.360)	Acc@5 92.188 (89.150)
[epoch:61, iter:47421] Loss: 1.421, 10.488, 66.776, 438.285, 1.181
[epoch:61, iter:47441] Loss: 1.421, 10.483, 66.751, 438.122, 1.222
[epoch:61, iter:47461] Loss: 1.421, 10.479, 66.744, 438.114, 1.284
[epoch:61, iter:47481] Loss: 1.420, 10.474, 66.730, 437.987, 0.938
[epoch:61, iter:47501] Loss: 1.420, 10.474, 66.722, 438.016, 1.747
Epoch: [60][600/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 14.2101 (13.7532)	Acc@1 54.688 (62.505)	Acc@5 82.812 (89.130)
[epoch:61, iter:47521] Loss: 1.420, 10.476, 66.738, 438.082, 1.869
[epoch:61, iter:47541] Loss: 1.420, 10.473, 66.717, 438.003, 2.006
[epoch:61, iter:47561] Loss: 1.420, 10.473, 66.733, 438.092, 1.665
[epoch:61, iter:47581] Loss: 1.421, 10.475, 66.750, 438.135, 1.173
[epoch:61, iter:47601] Loss: 1.420, 10.474, 66.745, 438.172, 1.099
Epoch: [60][700/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 12.7779 (13.7555)	Acc@1 73.438 (62.442)	Acc@5 98.438 (89.134)
[epoch:61, iter:47621] Loss: 1.420, 10.471, 66.740, 438.043, 0.932
[epoch:61, iter:47641] Loss: 1.420, 10.471, 66.745, 438.002, 1.400
[epoch:61, iter:47661] Loss: 1.420, 10.472, 66.748, 438.015, 1.803
[epoch:61, iter:47681] Loss: 1.421, 10.472, 66.772, 438.057, 1.382
[epoch:61, iter:47701] Loss: 1.421, 10.474, 66.805, 438.109, 1.612
 * Acc@1 62.318 Acc@5 89.096
epoch 60, total time 61.51
Test: [0/313]	Time 0.276 (0.276)	Loss 1.5647 (1.5647)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.4236 (2.0996)	Acc@1 43.750 (54.641)	Acc@5 81.250 (82.797)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8256 (2.0222)	Acc@1 56.250 (54.726)	Acc@5 87.500 (83.675)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4480 (2.0342)	Acc@1 50.000 (54.693)	Acc@5 84.375 (83.607)
 * Acc@1 54.740 Acc@5 83.640
==> training...
Epoch: [61][0/782]	Time 0.528 (0.528)	Data 0.448 (0.448)	Loss 13.5455 (13.5455)	Acc@1 64.062 (64.062)	Acc@5 85.938 (85.938)
[epoch:62, iter:47703] Loss: 1.474, 10.624, 67.489, 436.101, 1.291
[epoch:62, iter:47723] Loss: 1.417, 10.631, 68.019, 442.473, 1.396
[epoch:62, iter:47743] Loss: 1.409, 10.589, 66.954, 438.371, 1.127
[epoch:62, iter:47763] Loss: 1.409, 10.520, 66.709, 437.141, 1.173
[epoch:62, iter:47783] Loss: 1.406, 10.455, 66.417, 435.877, 1.870
Epoch: [61][100/782]	Time 0.095 (0.088)	Data 0.003 (0.007)	Loss 13.6924 (13.6327)	Acc@1 62.500 (63.335)	Acc@5 89.062 (89.681)
[epoch:62, iter:47803] Loss: 1.403, 10.448, 66.674, 436.782, 1.502
[epoch:62, iter:47823] Loss: 1.405, 10.452, 66.559, 436.751, 1.330
[epoch:62, iter:47843] Loss: 1.407, 10.444, 66.467, 436.654, 1.445
[epoch:62, iter:47863] Loss: 1.410, 10.443, 66.531, 436.868, 1.227
[epoch:62, iter:47883] Loss: 1.407, 10.444, 66.547, 436.933, 1.781
Epoch: [61][200/782]	Time 0.080 (0.084)	Data 0.003 (0.005)	Loss 12.6917 (13.6533)	Acc@1 71.875 (63.308)	Acc@5 93.750 (89.778)
[epoch:62, iter:47903] Loss: 1.405, 10.427, 66.491, 436.878, 1.082
[epoch:62, iter:47923] Loss: 1.406, 10.420, 66.549, 436.960, 1.194
[epoch:62, iter:47943] Loss: 1.408, 10.425, 66.529, 437.139, 1.180
[epoch:62, iter:47963] Loss: 1.411, 10.429, 66.528, 437.450, 1.211
[epoch:62, iter:47983] Loss: 1.412, 10.434, 66.585, 437.651, 1.262
Epoch: [61][300/782]	Time 0.091 (0.084)	Data 0.003 (0.004)	Loss 14.2720 (13.7319)	Acc@1 57.812 (62.614)	Acc@5 82.812 (89.379)
[epoch:62, iter:48003] Loss: 1.413, 10.449, 66.614, 437.733, 1.701
[epoch:62, iter:48023] Loss: 1.416, 10.462, 66.731, 438.177, 1.480
[epoch:62, iter:48043] Loss: 1.416, 10.468, 66.718, 438.078, 1.481
[epoch:62, iter:48063] Loss: 1.416, 10.473, 66.717, 438.080, 1.473
[epoch:62, iter:48083] Loss: 1.415, 10.466, 66.662, 438.009, 1.296
Epoch: [61][400/782]	Time 0.069 (0.083)	Data 0.002 (0.004)	Loss 14.3594 (13.7361)	Acc@1 59.375 (62.835)	Acc@5 85.938 (89.343)
[epoch:62, iter:48103] Loss: 1.414, 10.460, 66.641, 437.889, 1.576
[epoch:62, iter:48123] Loss: 1.413, 10.458, 66.638, 437.844, 1.234
[epoch:62, iter:48143] Loss: 1.413, 10.456, 66.659, 437.902, 1.508
[epoch:62, iter:48163] Loss: 1.413, 10.455, 66.682, 437.840, 1.204
[epoch:62, iter:48183] Loss: 1.413, 10.454, 66.673, 437.707, 1.806
Epoch: [61][500/782]	Time 0.089 (0.083)	Data 0.003 (0.003)	Loss 13.5913 (13.7429)	Acc@1 60.938 (62.703)	Acc@5 84.375 (89.247)
[epoch:62, iter:48203] Loss: 1.414, 10.462, 66.696, 437.688, 1.653
[epoch:62, iter:48223] Loss: 1.415, 10.469, 66.715, 437.709, 1.201
[epoch:62, iter:48243] Loss: 1.415, 10.465, 66.755, 437.750, 1.075
[epoch:62, iter:48263] Loss: 1.415, 10.464, 66.744, 437.702, 1.108
[epoch:62, iter:48283] Loss: 1.416, 10.468, 66.740, 437.726, 1.200
Epoch: [61][600/782]	Time 0.079 (0.082)	Data 0.003 (0.003)	Loss 13.4651 (13.7474)	Acc@1 59.375 (62.581)	Acc@5 90.625 (89.320)
[epoch:62, iter:48303] Loss: 1.417, 10.471, 66.731, 437.755, 1.474
[epoch:62, iter:48323] Loss: 1.418, 10.474, 66.756, 437.806, 1.201
[epoch:62, iter:48343] Loss: 1.418, 10.477, 66.787, 437.786, 1.120
[epoch:62, iter:48363] Loss: 1.419, 10.478, 66.808, 437.811, 1.496
[epoch:62, iter:48383] Loss: 1.419, 10.483, 66.791, 437.762, 1.526
Epoch: [61][700/782]	Time 0.081 (0.081)	Data 0.002 (0.003)	Loss 13.1212 (13.7524)	Acc@1 59.375 (62.507)	Acc@5 92.188 (89.299)
[epoch:62, iter:48403] Loss: 1.420, 10.482, 66.777, 437.801, 1.330
[epoch:62, iter:48423] Loss: 1.420, 10.485, 66.789, 437.838, 1.259
[epoch:62, iter:48443] Loss: 1.420, 10.487, 66.807, 437.870, 1.332
[epoch:62, iter:48463] Loss: 1.420, 10.486, 66.785, 437.732, 1.651
[epoch:62, iter:48483] Loss: 1.420, 10.483, 66.755, 437.687, 0.947
 * Acc@1 62.392 Acc@5 89.258
epoch 61, total time 62.90
Test: [0/313]	Time 0.224 (0.224)	Loss 2.2400 (2.2400)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.009 (0.009)	Loss 2.1428 (2.1165)	Acc@1 43.750 (52.723)	Acc@5 78.125 (82.550)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.7412 (2.1297)	Acc@1 62.500 (52.845)	Acc@5 90.625 (82.229)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.8510 (2.1348)	Acc@1 53.125 (52.855)	Acc@5 87.500 (82.216)
 * Acc@1 52.980 Acc@5 82.270
==> training...
Epoch: [62][0/782]	Time 0.507 (0.507)	Data 0.419 (0.419)	Loss 13.8157 (13.8157)	Acc@1 64.062 (64.062)	Acc@5 92.188 (92.188)
[epoch:63, iter:48485] Loss: 1.390, 10.354, 67.511, 437.600, 1.200
[epoch:63, iter:48505] Loss: 1.428, 10.465, 66.863, 439.578, 1.219
[epoch:63, iter:48525] Loss: 1.427, 10.504, 66.396, 437.510, 1.392
[epoch:63, iter:48545] Loss: 1.416, 10.459, 66.113, 436.473, 1.166
[epoch:63, iter:48565] Loss: 1.418, 10.428, 66.138, 436.043, 1.449
Epoch: [62][100/782]	Time 0.086 (0.084)	Data 0.003 (0.007)	Loss 13.1547 (13.7120)	Acc@1 68.750 (62.546)	Acc@5 92.188 (89.728)
[epoch:63, iter:48585] Loss: 1.419, 10.431, 66.398, 436.441, 1.122
[epoch:63, iter:48605] Loss: 1.422, 10.433, 66.417, 436.828, 1.108
[epoch:63, iter:48625] Loss: 1.421, 10.440, 66.522, 437.263, 1.024
[epoch:63, iter:48645] Loss: 1.420, 10.441, 66.486, 437.287, 1.241
[epoch:63, iter:48665] Loss: 1.416, 10.437, 66.319, 436.793, 1.744
Epoch: [62][200/782]	Time 0.066 (0.080)	Data 0.002 (0.004)	Loss 13.5885 (13.6903)	Acc@1 56.250 (62.912)	Acc@5 90.625 (89.436)
[epoch:63, iter:48685] Loss: 1.415, 10.443, 66.334, 436.633, 1.328
[epoch:63, iter:48705] Loss: 1.415, 10.443, 66.309, 436.557, 1.515
[epoch:63, iter:48725] Loss: 1.416, 10.439, 66.333, 436.591, 1.126
[epoch:63, iter:48745] Loss: 1.418, 10.438, 66.376, 436.842, 1.591
[epoch:63, iter:48765] Loss: 1.416, 10.438, 66.352, 436.676, 1.864
Epoch: [62][300/782]	Time 0.070 (0.079)	Data 0.002 (0.004)	Loss 14.2632 (13.6869)	Acc@1 54.688 (62.713)	Acc@5 79.688 (89.338)
[epoch:63, iter:48785] Loss: 1.416, 10.434, 66.324, 436.713, 1.634
[epoch:63, iter:48805] Loss: 1.414, 10.433, 66.255, 436.556, 1.300
[epoch:63, iter:48825] Loss: 1.412, 10.432, 66.255, 436.499, 1.527
[epoch:63, iter:48845] Loss: 1.411, 10.426, 66.293, 436.402, 1.125
[epoch:63, iter:48865] Loss: 1.411, 10.423, 66.292, 436.282, 1.701
Epoch: [62][400/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 13.7265 (13.6651)	Acc@1 56.250 (62.773)	Acc@5 81.250 (89.172)
[epoch:63, iter:48885] Loss: 1.411, 10.428, 66.337, 436.453, 1.503
[epoch:63, iter:48905] Loss: 1.412, 10.434, 66.411, 436.604, 1.377
[epoch:63, iter:48925] Loss: 1.414, 10.434, 66.413, 436.563, 1.642
[epoch:63, iter:48945] Loss: 1.413, 10.431, 66.447, 436.571, 1.728
[epoch:63, iter:48965] Loss: 1.413, 10.433, 66.493, 436.647, 1.014
Epoch: [62][500/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 13.8264 (13.6913)	Acc@1 46.875 (62.469)	Acc@5 87.500 (89.159)
[epoch:63, iter:48985] Loss: 1.413, 10.434, 66.511, 436.705, 1.637
[epoch:63, iter:49005] Loss: 1.413, 10.437, 66.512, 436.696, 1.344
[epoch:63, iter:49025] Loss: 1.414, 10.435, 66.526, 436.761, 1.460
[epoch:63, iter:49045] Loss: 1.414, 10.441, 66.534, 436.803, 1.056
[epoch:63, iter:49065] Loss: 1.415, 10.441, 66.536, 436.854, 1.265
Epoch: [62][600/782]	Time 0.077 (0.077)	Data 0.002 (0.003)	Loss 13.3093 (13.7051)	Acc@1 56.250 (62.484)	Acc@5 84.375 (89.151)
[epoch:63, iter:49085] Loss: 1.416, 10.448, 66.594, 436.932, 1.522
[epoch:63, iter:49105] Loss: 1.417, 10.451, 66.609, 436.962, 1.710
[epoch:63, iter:49125] Loss: 1.418, 10.456, 66.622, 437.021, 1.385
[epoch:63, iter:49145] Loss: 1.419, 10.458, 66.653, 437.061, 1.502
[epoch:63, iter:49165] Loss: 1.418, 10.459, 66.653, 437.028, 1.435
Epoch: [62][700/782]	Time 0.064 (0.078)	Data 0.002 (0.003)	Loss 13.5857 (13.7287)	Acc@1 64.062 (62.266)	Acc@5 89.062 (89.116)
[epoch:63, iter:49185] Loss: 1.418, 10.460, 66.654, 437.049, 1.336
[epoch:63, iter:49205] Loss: 1.418, 10.460, 66.638, 437.002, 1.120
[epoch:63, iter:49225] Loss: 1.419, 10.463, 66.642, 437.115, 1.344
[epoch:63, iter:49245] Loss: 1.419, 10.465, 66.629, 437.138, 1.288
[epoch:63, iter:49265] Loss: 1.418, 10.462, 66.605, 437.093, 1.192
 * Acc@1 62.178 Acc@5 89.040
epoch 62, total time 61.25
Test: [0/313]	Time 0.279 (0.279)	Loss 1.8703 (1.8703)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.009 (0.011)	Loss 2.3454 (1.9192)	Acc@1 40.625 (56.590)	Acc@5 84.375 (85.149)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.5287 (1.9033)	Acc@1 65.625 (56.234)	Acc@5 93.750 (85.277)
Test: [300/313]	Time 0.010 (0.008)	Loss 1.9984 (1.9201)	Acc@1 40.625 (56.416)	Acc@5 81.250 (85.206)
 * Acc@1 56.470 Acc@5 85.270
==> training...
Epoch: [63][0/782]	Time 0.545 (0.545)	Data 0.467 (0.467)	Loss 13.9270 (13.9270)	Acc@1 59.375 (59.375)	Acc@5 85.938 (85.938)
[epoch:64, iter:49267] Loss: 1.476, 10.461, 66.564, 438.052, 1.521
[epoch:64, iter:49287] Loss: 1.400, 10.351, 65.727, 434.381, 1.488
[epoch:64, iter:49307] Loss: 1.410, 10.456, 66.591, 437.316, 1.026
[epoch:64, iter:49327] Loss: 1.408, 10.487, 66.266, 436.476, 1.503
[epoch:64, iter:49347] Loss: 1.407, 10.498, 66.369, 437.345, 1.410
Epoch: [63][100/782]	Time 0.086 (0.078)	Data 0.002 (0.007)	Loss 12.8321 (13.6726)	Acc@1 68.750 (62.701)	Acc@5 87.500 (89.356)
[epoch:64, iter:49367] Loss: 1.420, 10.535, 66.316, 437.195, 1.194
[epoch:64, iter:49387] Loss: 1.421, 10.528, 66.293, 436.895, 1.811
[epoch:64, iter:49407] Loss: 1.422, 10.506, 66.400, 437.200, 1.263
[epoch:64, iter:49427] Loss: 1.420, 10.495, 66.392, 437.111, 0.784
[epoch:64, iter:49447] Loss: 1.417, 10.485, 66.364, 437.030, 1.447
Epoch: [63][200/782]	Time 0.074 (0.074)	Data 0.002 (0.004)	Loss 14.0849 (13.6699)	Acc@1 56.250 (63.091)	Acc@5 89.062 (89.521)
[epoch:64, iter:49467] Loss: 1.418, 10.495, 66.416, 437.092, 1.424
[epoch:64, iter:49487] Loss: 1.418, 10.481, 66.305, 436.741, 1.296
[epoch:64, iter:49507] Loss: 1.416, 10.472, 66.278, 436.758, 1.324
[epoch:64, iter:49527] Loss: 1.418, 10.479, 66.311, 436.921, 1.649
[epoch:64, iter:49547] Loss: 1.418, 10.476, 66.316, 436.880, 0.787
Epoch: [63][300/782]	Time 0.072 (0.074)	Data 0.002 (0.004)	Loss 13.1220 (13.6554)	Acc@1 59.375 (63.029)	Acc@5 92.188 (89.478)
[epoch:64, iter:49567] Loss: 1.418, 10.472, 66.375, 436.752, 1.322
[epoch:64, iter:49587] Loss: 1.416, 10.470, 66.376, 436.685, 1.128
[epoch:64, iter:49607] Loss: 1.418, 10.473, 66.452, 437.002, 1.301
[epoch:64, iter:49627] Loss: 1.418, 10.467, 66.444, 437.021, 1.017
[epoch:64, iter:49647] Loss: 1.418, 10.469, 66.430, 436.998, 1.355
Epoch: [63][400/782]	Time 0.091 (0.074)	Data 0.002 (0.003)	Loss 14.6615 (13.6873)	Acc@1 59.375 (62.742)	Acc@5 85.938 (89.308)
[epoch:64, iter:49667] Loss: 1.420, 10.465, 66.435, 437.060, 1.437
[epoch:64, iter:49687] Loss: 1.419, 10.468, 66.534, 437.186, 1.404
[epoch:64, iter:49707] Loss: 1.421, 10.474, 66.577, 437.442, 1.404
[epoch:64, iter:49727] Loss: 1.421, 10.483, 66.583, 437.539, 1.431
[epoch:64, iter:49747] Loss: 1.422, 10.488, 66.660, 437.811, 1.312
Epoch: [63][500/782]	Time 0.067 (0.075)	Data 0.002 (0.003)	Loss 14.2707 (13.7442)	Acc@1 60.938 (62.478)	Acc@5 84.375 (89.271)
[epoch:64, iter:49767] Loss: 1.423, 10.484, 66.656, 437.852, 1.656
[epoch:64, iter:49787] Loss: 1.423, 10.484, 66.636, 437.900, 1.572
[epoch:64, iter:49807] Loss: 1.422, 10.480, 66.628, 437.982, 1.442
[epoch:64, iter:49827] Loss: 1.421, 10.473, 66.575, 437.816, 1.204
[epoch:64, iter:49847] Loss: 1.421, 10.472, 66.576, 437.745, 1.414
Epoch: [63][600/782]	Time 0.069 (0.076)	Data 0.002 (0.003)	Loss 13.7993 (13.7390)	Acc@1 56.250 (62.568)	Acc@5 82.812 (89.294)
[epoch:64, iter:49867] Loss: 1.422, 10.473, 66.604, 437.830, 1.655
[epoch:64, iter:49887] Loss: 1.420, 10.464, 66.553, 437.604, 0.757
[epoch:64, iter:49907] Loss: 1.419, 10.461, 66.520, 437.542, 1.278
[epoch:64, iter:49927] Loss: 1.419, 10.459, 66.521, 437.536, 0.961
[epoch:64, iter:49947] Loss: 1.419, 10.455, 66.501, 437.523, 1.487
Epoch: [63][700/782]	Time 0.092 (0.077)	Data 0.006 (0.003)	Loss 12.7401 (13.7196)	Acc@1 64.062 (62.545)	Acc@5 96.875 (89.359)
[epoch:64, iter:49967] Loss: 1.419, 10.455, 66.499, 437.536, 0.947
[epoch:64, iter:49987] Loss: 1.419, 10.456, 66.495, 437.530, 1.410
[epoch:64, iter:50007] Loss: 1.419, 10.454, 66.521, 437.513, 1.475
[epoch:64, iter:50027] Loss: 1.419, 10.456, 66.538, 437.603, 1.713
[epoch:64, iter:50047] Loss: 1.419, 10.461, 66.543, 437.594, 1.274
 * Acc@1 62.382 Acc@5 89.226
epoch 63, total time 60.01
Test: [0/313]	Time 0.214 (0.214)	Loss 2.1726 (2.1726)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.2920 (2.0858)	Acc@1 43.750 (54.950)	Acc@5 81.250 (82.488)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4997 (2.1081)	Acc@1 68.750 (54.384)	Acc@5 90.625 (82.820)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.2630 (2.1077)	Acc@1 53.125 (54.423)	Acc@5 78.125 (82.870)
 * Acc@1 54.420 Acc@5 82.880
==> training...
Epoch: [64][0/782]	Time 0.476 (0.476)	Data 0.407 (0.407)	Loss 14.5295 (14.5295)	Acc@1 51.562 (51.562)	Acc@5 89.062 (89.062)
[epoch:65, iter:50049] Loss: 1.362, 10.485, 70.656, 450.449, 1.776
[epoch:65, iter:50069] Loss: 1.417, 10.618, 65.964, 437.679, 1.010
[epoch:65, iter:50089] Loss: 1.417, 10.562, 66.475, 438.792, 1.445
[epoch:65, iter:50109] Loss: 1.422, 10.585, 66.918, 439.129, 1.984
[epoch:65, iter:50129] Loss: 1.423, 10.584, 66.834, 438.897, 1.020
Epoch: [64][100/782]	Time 0.069 (0.083)	Data 0.002 (0.006)	Loss 13.4915 (13.7721)	Acc@1 57.812 (63.212)	Acc@5 93.750 (89.882)
[epoch:65, iter:50149] Loss: 1.421, 10.574, 66.814, 438.377, 1.580
[epoch:65, iter:50169] Loss: 1.418, 10.546, 66.713, 437.652, 1.200
[epoch:65, iter:50189] Loss: 1.415, 10.534, 66.594, 437.468, 1.817
[epoch:65, iter:50209] Loss: 1.416, 10.535, 66.491, 437.361, 1.525
[epoch:65, iter:50229] Loss: 1.418, 10.529, 66.472, 437.365, 1.573
Epoch: [64][200/782]	Time 0.064 (0.079)	Data 0.002 (0.004)	Loss 14.7093 (13.7360)	Acc@1 51.562 (62.687)	Acc@5 81.250 (89.521)
[epoch:65, iter:50249] Loss: 1.417, 10.512, 66.473, 437.303, 1.845
[epoch:65, iter:50269] Loss: 1.416, 10.511, 66.420, 437.127, 1.413
[epoch:65, iter:50289] Loss: 1.416, 10.509, 66.457, 437.207, 1.273
[epoch:65, iter:50309] Loss: 1.419, 10.514, 66.505, 437.450, 1.190
[epoch:65, iter:50329] Loss: 1.420, 10.513, 66.653, 437.807, 1.760
Epoch: [64][300/782]	Time 0.069 (0.079)	Data 0.002 (0.004)	Loss 15.0921 (13.7548)	Acc@1 56.250 (62.895)	Acc@5 84.375 (89.535)
[epoch:65, iter:50349] Loss: 1.420, 10.512, 66.677, 437.784, 1.802
[epoch:65, iter:50369] Loss: 1.420, 10.515, 66.727, 437.766, 1.097
[epoch:65, iter:50389] Loss: 1.420, 10.510, 66.729, 437.893, 1.437
[epoch:65, iter:50409] Loss: 1.420, 10.506, 66.725, 437.841, 1.307
[epoch:65, iter:50429] Loss: 1.421, 10.507, 66.693, 437.819, 1.270
Epoch: [64][400/782]	Time 0.060 (0.079)	Data 0.002 (0.003)	Loss 12.8724 (13.7552)	Acc@1 70.312 (62.777)	Acc@5 89.062 (89.483)
[epoch:65, iter:50449] Loss: 1.423, 10.508, 66.678, 437.817, 1.020
[epoch:65, iter:50469] Loss: 1.424, 10.515, 66.674, 437.861, 1.214
[epoch:65, iter:50489] Loss: 1.424, 10.516, 66.673, 437.774, 1.747
[epoch:65, iter:50509] Loss: 1.423, 10.514, 66.660, 437.681, 1.523
[epoch:65, iter:50529] Loss: 1.424, 10.514, 66.649, 437.656, 1.617
Epoch: [64][500/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.5088 (13.7597)	Acc@1 62.500 (62.516)	Acc@5 85.938 (89.349)
[epoch:65, iter:50549] Loss: 1.423, 10.512, 66.637, 437.654, 1.373
[epoch:65, iter:50569] Loss: 1.423, 10.513, 66.631, 437.620, 1.586
[epoch:65, iter:50589] Loss: 1.424, 10.515, 66.634, 437.619, 1.009
[epoch:65, iter:50609] Loss: 1.423, 10.516, 66.613, 437.553, 1.244
[epoch:65, iter:50629] Loss: 1.423, 10.510, 66.636, 437.679, 1.499
Epoch: [64][600/782]	Time 0.068 (0.078)	Data 0.002 (0.003)	Loss 14.1595 (13.7670)	Acc@1 53.125 (62.451)	Acc@5 84.375 (89.294)
[epoch:65, iter:50649] Loss: 1.424, 10.511, 66.678, 437.714, 2.095
[epoch:65, iter:50669] Loss: 1.424, 10.505, 66.665, 437.588, 1.351
[epoch:65, iter:50689] Loss: 1.423, 10.504, 66.643, 437.579, 1.283
[epoch:65, iter:50709] Loss: 1.423, 10.503, 66.628, 437.614, 0.942
[epoch:65, iter:50729] Loss: 1.422, 10.498, 66.622, 437.566, 1.139
Epoch: [64][700/782]	Time 0.094 (0.077)	Data 0.003 (0.003)	Loss 13.5018 (13.7601)	Acc@1 71.875 (62.382)	Acc@5 89.062 (89.294)
[epoch:65, iter:50749] Loss: 1.421, 10.495, 66.627, 437.604, 1.193
[epoch:65, iter:50769] Loss: 1.421, 10.496, 66.643, 437.633, 1.542
[epoch:65, iter:50789] Loss: 1.421, 10.492, 66.636, 437.621, 1.138
[epoch:65, iter:50809] Loss: 1.421, 10.496, 66.644, 437.680, 1.993
[epoch:65, iter:50829] Loss: 1.422, 10.500, 66.643, 437.617, 1.395
 * Acc@1 62.256 Acc@5 89.258
epoch 64, total time 60.34
Test: [0/313]	Time 0.254 (0.254)	Loss 2.1568 (2.1568)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.005 (0.009)	Loss 2.3552 (2.3191)	Acc@1 56.250 (50.433)	Acc@5 81.250 (80.693)
Test: [200/313]	Time 0.006 (0.007)	Loss 2.3584 (2.2952)	Acc@1 59.375 (50.902)	Acc@5 81.250 (80.737)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3708 (2.2915)	Acc@1 46.875 (51.007)	Acc@5 78.125 (80.814)
 * Acc@1 51.150 Acc@5 80.870
==> training...
Epoch: [65][0/782]	Time 0.568 (0.568)	Data 0.489 (0.489)	Loss 14.2356 (14.2356)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
[epoch:66, iter:50831] Loss: 1.469, 10.444, 70.604, 443.172, 1.438
[epoch:66, iter:50851] Loss: 1.441, 10.666, 67.740, 441.737, 1.273
[epoch:66, iter:50871] Loss: 1.424, 10.569, 67.406, 439.470, 1.581
[epoch:66, iter:50891] Loss: 1.411, 10.531, 66.987, 439.012, 1.370
[epoch:66, iter:50911] Loss: 1.408, 10.456, 66.919, 438.495, 1.436
Epoch: [65][100/782]	Time 0.093 (0.084)	Data 0.003 (0.007)	Loss 13.9340 (13.7197)	Acc@1 70.312 (62.856)	Acc@5 89.062 (89.341)
[epoch:66, iter:50931] Loss: 1.412, 10.439, 66.684, 437.557, 1.296
[epoch:66, iter:50951] Loss: 1.410, 10.456, 66.756, 437.799, 1.128
[epoch:66, iter:50971] Loss: 1.412, 10.458, 66.787, 437.367, 1.371
[epoch:66, iter:50991] Loss: 1.411, 10.474, 66.777, 437.111, 1.389
[epoch:66, iter:51011] Loss: 1.414, 10.484, 66.735, 436.926, 1.845
Epoch: [65][200/782]	Time 0.073 (0.083)	Data 0.002 (0.005)	Loss 14.0679 (13.6723)	Acc@1 71.875 (62.795)	Acc@5 85.938 (89.280)
[epoch:66, iter:51031] Loss: 1.416, 10.478, 66.623, 436.661, 1.284
[epoch:66, iter:51051] Loss: 1.416, 10.476, 66.569, 436.584, 1.705
[epoch:66, iter:51071] Loss: 1.413, 10.456, 66.474, 436.291, 1.019
[epoch:66, iter:51091] Loss: 1.413, 10.443, 66.462, 436.474, 1.127
[epoch:66, iter:51111] Loss: 1.411, 10.441, 66.339, 436.273, 0.960
Epoch: [65][300/782]	Time 0.092 (0.082)	Data 0.003 (0.004)	Loss 13.5386 (13.6534)	Acc@1 65.625 (62.858)	Acc@5 92.188 (89.623)
[epoch:66, iter:51131] Loss: 1.413, 10.457, 66.364, 436.529, 1.352
[epoch:66, iter:51151] Loss: 1.415, 10.469, 66.438, 436.777, 1.647
[epoch:66, iter:51171] Loss: 1.416, 10.484, 66.493, 437.037, 1.470
[epoch:66, iter:51191] Loss: 1.418, 10.487, 66.571, 437.307, 1.180
[epoch:66, iter:51211] Loss: 1.420, 10.494, 66.635, 437.533, 1.473
Epoch: [65][400/782]	Time 0.086 (0.077)	Data 0.002 (0.004)	Loss 13.5948 (13.7444)	Acc@1 62.500 (62.301)	Acc@5 90.625 (89.401)
[epoch:66, iter:51231] Loss: 1.421, 10.502, 66.648, 437.675, 1.409
[epoch:66, iter:51251] Loss: 1.421, 10.505, 66.659, 437.761, 1.271
[epoch:66, iter:51271] Loss: 1.421, 10.507, 66.635, 437.644, 1.185
[epoch:66, iter:51291] Loss: 1.421, 10.502, 66.633, 437.566, 1.351
[epoch:66, iter:51311] Loss: 1.419, 10.495, 66.651, 437.551, 0.904
Epoch: [65][500/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 13.8514 (13.7378)	Acc@1 65.625 (62.279)	Acc@5 92.188 (89.449)
[epoch:66, iter:51331] Loss: 1.420, 10.492, 66.689, 437.513, 1.213
[epoch:66, iter:51351] Loss: 1.420, 10.490, 66.657, 437.406, 1.642
[epoch:66, iter:51371] Loss: 1.420, 10.486, 66.611, 437.307, 1.451
[epoch:66, iter:51391] Loss: 1.420, 10.482, 66.615, 437.269, 1.401
[epoch:66, iter:51411] Loss: 1.419, 10.482, 66.616, 437.240, 0.961
Epoch: [65][600/782]	Time 0.063 (0.078)	Data 0.002 (0.003)	Loss 12.5581 (13.7131)	Acc@1 70.312 (62.274)	Acc@5 95.312 (89.497)
[epoch:66, iter:51431] Loss: 1.418, 10.479, 66.579, 437.050, 0.980
[epoch:66, iter:51451] Loss: 1.418, 10.475, 66.576, 437.003, 1.378
[epoch:66, iter:51471] Loss: 1.418, 10.471, 66.593, 436.990, 1.492
[epoch:66, iter:51491] Loss: 1.418, 10.469, 66.596, 436.849, 1.541
[epoch:66, iter:51511] Loss: 1.419, 10.473, 66.589, 436.860, 1.263
Epoch: [65][700/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 14.0373 (13.7032)	Acc@1 65.625 (62.360)	Acc@5 90.625 (89.528)
[epoch:66, iter:51531] Loss: 1.419, 10.471, 66.561, 436.798, 1.521
[epoch:66, iter:51551] Loss: 1.418, 10.470, 66.561, 436.850, 1.798
[epoch:66, iter:51571] Loss: 1.419, 10.469, 66.577, 436.895, 1.812
[epoch:66, iter:51591] Loss: 1.419, 10.470, 66.595, 436.913, 1.556
[epoch:66, iter:51611] Loss: 1.419, 10.475, 66.599, 436.953, 1.703
 * Acc@1 62.324 Acc@5 89.378
epoch 65, total time 61.02
Test: [0/313]	Time 0.268 (0.268)	Loss 1.9739 (1.9739)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.4161 (2.0793)	Acc@1 50.000 (53.929)	Acc@5 78.125 (82.611)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.9115 (2.0772)	Acc@1 53.125 (53.187)	Acc@5 90.625 (82.789)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.5145 (2.1094)	Acc@1 34.375 (52.814)	Acc@5 84.375 (82.257)
 * Acc@1 52.900 Acc@5 82.220
==> training...
Epoch: [66][0/782]	Time 0.551 (0.551)	Data 0.487 (0.487)	Loss 15.4997 (15.4997)	Acc@1 53.125 (53.125)	Acc@5 79.688 (79.688)
[epoch:67, iter:51613] Loss: 1.533, 10.641, 70.482, 454.842, 2.052
[epoch:67, iter:51633] Loss: 1.420, 10.663, 66.924, 436.221, 1.419
[epoch:67, iter:51653] Loss: 1.436, 10.615, 66.667, 437.211, 1.477
[epoch:67, iter:51673] Loss: 1.430, 10.582, 66.492, 438.011, 0.993
[epoch:67, iter:51693] Loss: 1.426, 10.563, 66.405, 437.690, 1.291
Epoch: [66][100/782]	Time 0.075 (0.075)	Data 0.002 (0.007)	Loss 13.2923 (13.6787)	Acc@1 65.625 (62.407)	Acc@5 87.500 (89.712)
[epoch:67, iter:51713] Loss: 1.421, 10.499, 66.287, 436.937, 1.201
[epoch:67, iter:51733] Loss: 1.414, 10.482, 66.130, 436.536, 1.237
[epoch:67, iter:51753] Loss: 1.409, 10.464, 66.034, 436.057, 1.530
[epoch:67, iter:51773] Loss: 1.409, 10.439, 66.010, 436.024, 1.674
[epoch:67, iter:51793] Loss: 1.407, 10.434, 66.025, 435.911, 1.059
Epoch: [66][200/782]	Time 0.082 (0.078)	Data 0.002 (0.005)	Loss 14.0381 (13.6066)	Acc@1 64.062 (62.757)	Acc@5 87.500 (89.599)
[epoch:67, iter:51813] Loss: 1.406, 10.426, 66.052, 435.840, 1.474
[epoch:67, iter:51833] Loss: 1.407, 10.428, 66.140, 436.008, 1.226
[epoch:67, iter:51853] Loss: 1.410, 10.436, 66.263, 436.207, 1.483
[epoch:67, iter:51873] Loss: 1.411, 10.443, 66.301, 436.351, 1.464
[epoch:67, iter:51893] Loss: 1.412, 10.440, 66.327, 436.548, 1.377
Epoch: [66][300/782]	Time 0.073 (0.079)	Data 0.002 (0.004)	Loss 14.5153 (13.6954)	Acc@1 51.562 (62.240)	Acc@5 85.938 (89.556)
[epoch:67, iter:51913] Loss: 1.412, 10.450, 66.403, 436.654, 1.702
[epoch:67, iter:51933] Loss: 1.411, 10.448, 66.441, 436.759, 1.530
[epoch:67, iter:51953] Loss: 1.412, 10.453, 66.438, 436.859, 1.059
[epoch:67, iter:51973] Loss: 1.412, 10.455, 66.453, 436.890, 1.448
[epoch:67, iter:51993] Loss: 1.414, 10.460, 66.508, 436.928, 1.414
Epoch: [66][400/782]	Time 0.084 (0.079)	Data 0.002 (0.004)	Loss 14.8694 (13.7082)	Acc@1 53.125 (62.360)	Acc@5 85.938 (89.460)
[epoch:67, iter:52013] Loss: 1.414, 10.457, 66.539, 436.902, 1.983
[epoch:67, iter:52033] Loss: 1.415, 10.458, 66.548, 436.924, 1.137
[epoch:67, iter:52053] Loss: 1.414, 10.453, 66.518, 436.887, 1.509
[epoch:67, iter:52073] Loss: 1.413, 10.452, 66.482, 436.856, 1.664
[epoch:67, iter:52093] Loss: 1.413, 10.454, 66.494, 436.926, 0.723
Epoch: [66][500/782]	Time 0.078 (0.079)	Data 0.002 (0.003)	Loss 14.2292 (13.7130)	Acc@1 62.500 (62.304)	Acc@5 82.812 (89.543)
[epoch:67, iter:52113] Loss: 1.413, 10.453, 66.481, 436.864, 1.826
[epoch:67, iter:52133] Loss: 1.413, 10.454, 66.470, 436.850, 1.156
[epoch:67, iter:52153] Loss: 1.414, 10.457, 66.466, 436.876, 1.543
[epoch:67, iter:52173] Loss: 1.414, 10.459, 66.481, 436.971, 1.503
[epoch:67, iter:52193] Loss: 1.414, 10.459, 66.499, 437.033, 1.503
Epoch: [66][600/782]	Time 0.079 (0.079)	Data 0.003 (0.003)	Loss 13.6153 (13.7286)	Acc@1 51.562 (62.297)	Acc@5 84.375 (89.481)
[epoch:67, iter:52213] Loss: 1.415, 10.461, 66.529, 437.012, 1.848
[epoch:67, iter:52233] Loss: 1.414, 10.461, 66.534, 437.032, 1.369
[epoch:67, iter:52253] Loss: 1.414, 10.462, 66.533, 436.987, 1.101
[epoch:67, iter:52273] Loss: 1.413, 10.464, 66.517, 436.978, 1.472
[epoch:67, iter:52293] Loss: 1.413, 10.461, 66.564, 436.999, 1.765
Epoch: [66][700/782]	Time 0.092 (0.079)	Data 0.003 (0.003)	Loss 14.1792 (13.7282)	Acc@1 54.688 (62.348)	Acc@5 87.500 (89.468)
[epoch:67, iter:52313] Loss: 1.413, 10.462, 66.585, 437.007, 1.696
[epoch:67, iter:52333] Loss: 1.413, 10.459, 66.578, 436.913, 1.640
[epoch:67, iter:52353] Loss: 1.413, 10.456, 66.577, 436.938, 1.265
[epoch:67, iter:52373] Loss: 1.412, 10.455, 66.590, 437.017, 1.757
[epoch:67, iter:52393] Loss: 1.412, 10.454, 66.583, 437.052, 1.074
 * Acc@1 62.208 Acc@5 89.334
epoch 66, total time 62.04
Test: [0/313]	Time 0.294 (0.294)	Loss 2.2572 (2.2572)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.011)	Loss 2.5041 (2.3297)	Acc@1 50.000 (51.918)	Acc@5 78.125 (81.467)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.7272 (2.3232)	Acc@1 56.250 (51.881)	Acc@5 90.625 (81.499)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.8280 (2.3074)	Acc@1 34.375 (51.993)	Acc@5 78.125 (81.292)
 * Acc@1 51.950 Acc@5 81.290
==> training...
Epoch: [67][0/782]	Time 0.553 (0.553)	Data 0.469 (0.469)	Loss 13.6905 (13.6905)	Acc@1 75.000 (75.000)	Acc@5 92.188 (92.188)
[epoch:68, iter:52395] Loss: 1.528, 10.422, 73.412, 436.469, 1.079
[epoch:68, iter:52415] Loss: 1.448, 10.622, 67.856, 437.121, 1.674
[epoch:68, iter:52435] Loss: 1.443, 10.600, 67.515, 438.001, 1.924
[epoch:68, iter:52455] Loss: 1.442, 10.558, 67.369, 437.743, 1.366
[epoch:68, iter:52475] Loss: 1.437, 10.567, 67.153, 437.711, 1.130
Epoch: [67][100/782]	Time 0.094 (0.078)	Data 0.003 (0.007)	Loss 14.2116 (13.7578)	Acc@1 59.375 (62.794)	Acc@5 90.625 (89.929)
[epoch:68, iter:52495] Loss: 1.432, 10.578, 67.030, 437.822, 1.266
[epoch:68, iter:52515] Loss: 1.432, 10.574, 66.921, 437.439, 1.254
[epoch:68, iter:52535] Loss: 1.429, 10.563, 66.942, 437.638, 1.958
[epoch:68, iter:52555] Loss: 1.427, 10.550, 66.863, 437.289, 1.340
[epoch:68, iter:52575] Loss: 1.424, 10.529, 66.870, 436.975, 1.193
Epoch: [67][200/782]	Time 0.068 (0.078)	Data 0.002 (0.005)	Loss 14.7454 (13.7297)	Acc@1 59.375 (62.687)	Acc@5 89.062 (89.964)
[epoch:68, iter:52595] Loss: 1.423, 10.527, 66.938, 437.141, 1.595
[epoch:68, iter:52615] Loss: 1.424, 10.532, 66.951, 437.256, 1.550
[epoch:68, iter:52635] Loss: 1.423, 10.533, 66.972, 437.288, 1.293
[epoch:68, iter:52655] Loss: 1.422, 10.529, 66.907, 437.079, 2.061
[epoch:68, iter:52675] Loss: 1.421, 10.525, 66.928, 437.020, 1.865
Epoch: [67][300/782]	Time 0.118 (0.079)	Data 0.003 (0.004)	Loss 12.5410 (13.7356)	Acc@1 60.938 (62.417)	Acc@5 89.062 (89.540)
[epoch:68, iter:52695] Loss: 1.420, 10.533, 66.868, 437.045, 1.159
[epoch:68, iter:52715] Loss: 1.420, 10.530, 66.855, 437.138, 1.704
[epoch:68, iter:52735] Loss: 1.418, 10.524, 66.814, 437.109, 1.654
[epoch:68, iter:52755] Loss: 1.418, 10.523, 66.810, 437.274, 1.730
[epoch:68, iter:52775] Loss: 1.416, 10.518, 66.782, 437.258, 1.306
Epoch: [67][400/782]	Time 0.061 (0.077)	Data 0.002 (0.003)	Loss 14.6966 (13.7222)	Acc@1 56.250 (62.547)	Acc@5 85.938 (89.444)
[epoch:68, iter:52795] Loss: 1.416, 10.517, 66.772, 437.261, 1.682
[epoch:68, iter:52815] Loss: 1.416, 10.516, 66.774, 437.350, 1.061
[epoch:68, iter:52835] Loss: 1.416, 10.516, 66.775, 437.370, 1.020
[epoch:68, iter:52855] Loss: 1.416, 10.511, 66.783, 437.388, 1.356
[epoch:68, iter:52875] Loss: 1.417, 10.513, 66.783, 437.413, 1.335
Epoch: [67][500/782]	Time 0.086 (0.077)	Data 0.002 (0.003)	Loss 13.0707 (13.7458)	Acc@1 70.312 (62.425)	Acc@5 89.062 (89.290)
[epoch:68, iter:52895] Loss: 1.417, 10.509, 66.811, 437.520, 1.381
[epoch:68, iter:52915] Loss: 1.417, 10.508, 66.780, 437.529, 1.286
[epoch:68, iter:52935] Loss: 1.417, 10.503, 66.794, 437.508, 1.603
[epoch:68, iter:52955] Loss: 1.417, 10.505, 66.777, 437.436, 1.395
[epoch:68, iter:52975] Loss: 1.417, 10.503, 66.779, 437.465, 1.728
Epoch: [67][600/782]	Time 0.061 (0.076)	Data 0.002 (0.003)	Loss 14.2686 (13.7465)	Acc@1 59.375 (62.263)	Acc@5 84.375 (89.361)
[epoch:68, iter:52995] Loss: 1.417, 10.500, 66.765, 437.444, 1.408
[epoch:68, iter:53015] Loss: 1.416, 10.503, 66.789, 437.530, 1.383
[epoch:68, iter:53035] Loss: 1.417, 10.500, 66.795, 437.552, 1.128
[epoch:68, iter:53055] Loss: 1.416, 10.497, 66.785, 437.580, 1.379
[epoch:68, iter:53075] Loss: 1.416, 10.493, 66.776, 437.562, 1.294
Epoch: [67][700/782]	Time 0.084 (0.077)	Data 0.003 (0.003)	Loss 14.1678 (13.7565)	Acc@1 45.312 (62.172)	Acc@5 84.375 (89.261)
[epoch:68, iter:53095] Loss: 1.415, 10.490, 66.792, 437.541, 1.972
[epoch:68, iter:53115] Loss: 1.416, 10.489, 66.828, 437.514, 1.352
[epoch:68, iter:53135] Loss: 1.416, 10.489, 66.821, 437.391, 1.279
[epoch:68, iter:53155] Loss: 1.416, 10.484, 66.821, 437.307, 1.330
[epoch:68, iter:53175] Loss: 1.417, 10.485, 66.817, 437.287, 1.376
 * Acc@1 62.276 Acc@5 89.224
epoch 67, total time 60.28
Test: [0/313]	Time 0.271 (0.271)	Loss 1.8791 (1.8791)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.010)	Loss 2.5527 (1.8708)	Acc@1 43.750 (57.488)	Acc@5 87.500 (85.736)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.3276 (1.8403)	Acc@1 68.750 (57.789)	Acc@5 87.500 (85.945)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.9559 (1.8365)	Acc@1 59.375 (57.755)	Acc@5 84.375 (85.756)
 * Acc@1 57.700 Acc@5 85.790
saving the best model!
==> training...
Epoch: [68][0/782]	Time 0.524 (0.524)	Data 0.457 (0.457)	Loss 14.2728 (14.2728)	Acc@1 53.125 (53.125)	Acc@5 92.188 (92.188)
[epoch:69, iter:53177] Loss: 1.429, 10.512, 69.212, 444.233, 1.351
[epoch:69, iter:53197] Loss: 1.434, 10.616, 66.684, 438.772, 1.612
[epoch:69, iter:53217] Loss: 1.433, 10.527, 65.890, 435.035, 1.341
[epoch:69, iter:53237] Loss: 1.431, 10.459, 65.906, 435.030, 1.008
[epoch:69, iter:53257] Loss: 1.432, 10.451, 66.025, 435.360, 1.707
Epoch: [68][100/782]	Time 0.093 (0.083)	Data 0.004 (0.007)	Loss 13.8047 (13.6216)	Acc@1 46.875 (62.794)	Acc@5 84.375 (89.666)
[epoch:69, iter:53277] Loss: 1.426, 10.451, 66.121, 435.744, 1.789
[epoch:69, iter:53297] Loss: 1.421, 10.464, 66.318, 436.488, 1.376
[epoch:69, iter:53317] Loss: 1.420, 10.465, 66.450, 436.516, 1.478
[epoch:69, iter:53337] Loss: 1.423, 10.461, 66.456, 436.182, 1.394
[epoch:69, iter:53357] Loss: 1.422, 10.459, 66.380, 436.007, 1.206
Epoch: [68][200/782]	Time 0.073 (0.082)	Data 0.002 (0.005)	Loss 13.3252 (13.6224)	Acc@1 60.938 (62.679)	Acc@5 82.812 (89.506)
[epoch:69, iter:53377] Loss: 1.420, 10.440, 66.367, 435.954, 1.465
[epoch:69, iter:53397] Loss: 1.417, 10.439, 66.260, 435.684, 1.419
[epoch:69, iter:53417] Loss: 1.415, 10.430, 66.266, 435.689, 1.409
[epoch:69, iter:53437] Loss: 1.414, 10.425, 66.288, 435.699, 1.253
[epoch:69, iter:53457] Loss: 1.415, 10.430, 66.291, 435.826, 0.946
Epoch: [68][300/782]	Time 0.084 (0.080)	Data 0.003 (0.004)	Loss 14.2075 (13.6117)	Acc@1 59.375 (62.915)	Acc@5 85.938 (89.675)
[epoch:69, iter:53477] Loss: 1.416, 10.438, 66.330, 435.992, 1.792
[epoch:69, iter:53497] Loss: 1.416, 10.438, 66.285, 435.951, 1.248
[epoch:69, iter:53517] Loss: 1.416, 10.441, 66.333, 436.069, 1.449
[epoch:69, iter:53537] Loss: 1.416, 10.448, 66.319, 436.062, 1.325
[epoch:69, iter:53557] Loss: 1.416, 10.446, 66.302, 435.981, 1.661
Epoch: [68][400/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 13.5363 (13.6171)	Acc@1 68.750 (62.753)	Acc@5 85.938 (89.577)
[epoch:69, iter:53577] Loss: 1.416, 10.447, 66.331, 436.066, 1.358
[epoch:69, iter:53597] Loss: 1.416, 10.443, 66.354, 436.192, 1.446
[epoch:69, iter:53617] Loss: 1.416, 10.446, 66.358, 436.165, 1.095
[epoch:69, iter:53637] Loss: 1.416, 10.448, 66.334, 436.047, 1.439
[epoch:69, iter:53657] Loss: 1.416, 10.446, 66.318, 435.979, 1.054
Epoch: [68][500/782]	Time 0.083 (0.079)	Data 0.003 (0.003)	Loss 13.0766 (13.6369)	Acc@1 71.875 (62.684)	Acc@5 87.500 (89.646)
[epoch:69, iter:53677] Loss: 1.417, 10.449, 66.349, 436.178, 1.205
[epoch:69, iter:53697] Loss: 1.416, 10.451, 66.415, 436.292, 1.486
[epoch:69, iter:53717] Loss: 1.417, 10.456, 66.465, 436.447, 1.205
[epoch:69, iter:53737] Loss: 1.417, 10.454, 66.449, 436.369, 1.271
[epoch:69, iter:53757] Loss: 1.417, 10.458, 66.472, 436.567, 1.283
Epoch: [68][600/782]	Time 0.090 (0.079)	Data 0.003 (0.003)	Loss 13.9616 (13.6779)	Acc@1 65.625 (62.630)	Acc@5 87.500 (89.533)
[epoch:69, iter:53777] Loss: 1.417, 10.460, 66.481, 436.580, 1.533
[epoch:69, iter:53797] Loss: 1.417, 10.460, 66.499, 436.536, 1.476
[epoch:69, iter:53817] Loss: 1.418, 10.461, 66.512, 436.574, 1.858
[epoch:69, iter:53837] Loss: 1.417, 10.459, 66.478, 436.580, 1.774
[epoch:69, iter:53857] Loss: 1.417, 10.456, 66.486, 436.572, 1.855
Epoch: [68][700/782]	Time 0.057 (0.078)	Data 0.002 (0.003)	Loss 13.2032 (13.6772)	Acc@1 73.438 (62.698)	Acc@5 96.875 (89.573)
[epoch:69, iter:53877] Loss: 1.417, 10.460, 66.465, 436.532, 1.093
[epoch:69, iter:53897] Loss: 1.418, 10.464, 66.468, 436.596, 1.648
[epoch:69, iter:53917] Loss: 1.417, 10.465, 66.463, 436.602, 1.304
[epoch:69, iter:53937] Loss: 1.417, 10.464, 66.455, 436.635, 1.894
[epoch:69, iter:53957] Loss: 1.417, 10.459, 66.443, 436.648, 1.386
 * Acc@1 62.438 Acc@5 89.444
epoch 68, total time 60.96
Test: [0/313]	Time 0.254 (0.254)	Loss 1.3572 (1.3572)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.8523 (1.8060)	Acc@1 50.000 (56.900)	Acc@5 90.625 (85.520)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.4102 (1.8014)	Acc@1 59.375 (56.903)	Acc@5 90.625 (85.370)
Test: [300/313]	Time 0.005 (0.007)	Loss 2.1687 (1.8110)	Acc@1 53.125 (56.977)	Acc@5 84.375 (85.330)
 * Acc@1 57.000 Acc@5 85.360
==> training...
Epoch: [69][0/782]	Time 0.496 (0.496)	Data 0.410 (0.410)	Loss 13.1854 (13.1854)	Acc@1 60.938 (60.938)	Acc@5 90.625 (90.625)
[epoch:70, iter:53959] Loss: 1.376, 10.375, 66.168, 431.250, 1.147
[epoch:70, iter:53979] Loss: 1.380, 10.362, 66.308, 438.080, 1.411
[epoch:70, iter:53999] Loss: 1.390, 10.420, 66.363, 435.916, 1.281
[epoch:70, iter:54019] Loss: 1.396, 10.386, 66.097, 434.941, 1.137
[epoch:70, iter:54039] Loss: 1.397, 10.373, 66.048, 434.696, 1.049
Epoch: [69][100/782]	Time 0.074 (0.083)	Data 0.002 (0.006)	Loss 13.3506 (13.5691)	Acc@1 62.500 (62.252)	Acc@5 90.625 (89.666)
[epoch:70, iter:54059] Loss: 1.396, 10.398, 66.221, 434.694, 1.412
[epoch:70, iter:54079] Loss: 1.398, 10.388, 66.083, 434.169, 1.194
[epoch:70, iter:54099] Loss: 1.400, 10.377, 66.073, 433.942, 1.602
[epoch:70, iter:54119] Loss: 1.402, 10.381, 66.043, 433.924, 1.364
[epoch:70, iter:54139] Loss: 1.402, 10.380, 66.080, 434.299, 0.979
Epoch: [69][200/782]	Time 0.090 (0.084)	Data 0.003 (0.005)	Loss 14.5018 (13.5390)	Acc@1 57.812 (62.951)	Acc@5 90.625 (89.809)
[epoch:70, iter:54159] Loss: 1.400, 10.382, 66.145, 434.655, 1.600
[epoch:70, iter:54179] Loss: 1.401, 10.378, 66.125, 434.789, 1.328
[epoch:70, iter:54199] Loss: 1.403, 10.378, 66.223, 435.092, 1.114
[epoch:70, iter:54219] Loss: 1.405, 10.389, 66.209, 435.138, 1.773
[epoch:70, iter:54239] Loss: 1.406, 10.399, 66.269, 435.435, 1.537
Epoch: [69][300/782]	Time 0.079 (0.082)	Data 0.002 (0.004)	Loss 13.4757 (13.5897)	Acc@1 62.500 (62.884)	Acc@5 92.188 (89.883)
[epoch:70, iter:54259] Loss: 1.407, 10.405, 66.320, 435.395, 1.343
[epoch:70, iter:54279] Loss: 1.407, 10.407, 66.372, 435.547, 1.712
[epoch:70, iter:54299] Loss: 1.408, 10.413, 66.368, 435.683, 1.319
[epoch:70, iter:54319] Loss: 1.409, 10.427, 66.441, 436.043, 1.299
[epoch:70, iter:54339] Loss: 1.410, 10.429, 66.458, 436.139, 1.171
Epoch: [69][400/782]	Time 0.072 (0.081)	Data 0.002 (0.004)	Loss 12.5403 (13.6525)	Acc@1 73.438 (62.722)	Acc@5 93.750 (89.682)
[epoch:70, iter:54359] Loss: 1.410, 10.428, 66.485, 436.135, 0.896
[epoch:70, iter:54379] Loss: 1.411, 10.431, 66.496, 436.075, 1.618
[epoch:70, iter:54399] Loss: 1.411, 10.435, 66.480, 436.077, 1.482
[epoch:70, iter:54419] Loss: 1.412, 10.436, 66.463, 435.998, 0.978
[epoch:70, iter:54439] Loss: 1.412, 10.436, 66.482, 436.130, 1.289
Epoch: [69][500/782]	Time 0.075 (0.080)	Data 0.002 (0.003)	Loss 13.0671 (13.6634)	Acc@1 65.625 (62.693)	Acc@5 93.750 (89.521)
[epoch:70, iter:54459] Loss: 1.412, 10.438, 66.475, 436.176, 1.274
[epoch:70, iter:54479] Loss: 1.412, 10.437, 66.460, 436.164, 1.703
[epoch:70, iter:54499] Loss: 1.411, 10.432, 66.443, 436.179, 1.084
[epoch:70, iter:54519] Loss: 1.411, 10.434, 66.433, 436.203, 1.503
[epoch:70, iter:54539] Loss: 1.411, 10.435, 66.424, 436.243, 1.345
Epoch: [69][600/782]	Time 0.071 (0.079)	Data 0.002 (0.003)	Loss 12.6805 (13.6594)	Acc@1 71.875 (62.614)	Acc@5 92.188 (89.465)
[epoch:70, iter:54559] Loss: 1.411, 10.435, 66.384, 436.131, 1.051
[epoch:70, iter:54579] Loss: 1.410, 10.435, 66.370, 436.175, 1.450
[epoch:70, iter:54599] Loss: 1.410, 10.434, 66.364, 436.216, 1.534
[epoch:70, iter:54619] Loss: 1.411, 10.433, 66.373, 436.215, 1.442
[epoch:70, iter:54639] Loss: 1.410, 10.432, 66.370, 436.149, 1.030
Epoch: [69][700/782]	Time 0.082 (0.079)	Data 0.002 (0.003)	Loss 13.4044 (13.6711)	Acc@1 65.625 (62.509)	Acc@5 92.188 (89.337)
[epoch:70, iter:54659] Loss: 1.410, 10.434, 66.397, 436.255, 1.164
[epoch:70, iter:54679] Loss: 1.411, 10.440, 66.401, 436.320, 1.691
[epoch:70, iter:54699] Loss: 1.411, 10.441, 66.397, 436.367, 1.742
[epoch:70, iter:54719] Loss: 1.411, 10.443, 66.403, 436.407, 0.967
[epoch:70, iter:54739] Loss: 1.413, 10.443, 66.421, 436.478, 1.345
 * Acc@1 62.358 Acc@5 89.224
epoch 69, total time 62.17
Test: [0/313]	Time 0.252 (0.252)	Loss 2.2965 (2.2965)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.4348 (2.5430)	Acc@1 43.750 (50.309)	Acc@5 87.500 (79.765)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.6681 (2.5321)	Acc@1 46.875 (50.093)	Acc@5 81.250 (79.478)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.1629 (2.5416)	Acc@1 53.125 (49.907)	Acc@5 87.500 (79.444)
 * Acc@1 49.920 Acc@5 79.550
==> training...
Epoch: [70][0/782]	Time 0.514 (0.514)	Data 0.434 (0.434)	Loss 13.7652 (13.7652)	Acc@1 65.625 (65.625)	Acc@5 95.312 (95.312)
[epoch:71, iter:54741] Loss: 1.435, 10.194, 68.120, 441.458, 0.996
[epoch:71, iter:54761] Loss: 1.451, 10.629, 68.250, 441.037, 1.059
[epoch:71, iter:54781] Loss: 1.435, 10.547, 68.256, 438.765, 1.642
[epoch:71, iter:54801] Loss: 1.430, 10.495, 67.558, 436.704, 1.310
[epoch:71, iter:54821] Loss: 1.429, 10.506, 67.371, 436.449, 1.651
Epoch: [70][100/782]	Time 0.083 (0.082)	Data 0.002 (0.007)	Loss 13.3179 (13.6226)	Acc@1 64.062 (64.279)	Acc@5 92.188 (90.316)
[epoch:71, iter:54841] Loss: 1.433, 10.507, 67.373, 437.275, 1.218
[epoch:71, iter:54861] Loss: 1.432, 10.499, 67.163, 436.949, 1.652
[epoch:71, iter:54881] Loss: 1.429, 10.519, 66.903, 436.493, 1.165
[epoch:71, iter:54901] Loss: 1.430, 10.522, 66.869, 436.485, 1.359
[epoch:71, iter:54921] Loss: 1.429, 10.522, 66.784, 436.512, 1.466
Epoch: [70][200/782]	Time 0.077 (0.078)	Data 0.002 (0.004)	Loss 13.7717 (13.6522)	Acc@1 65.625 (63.270)	Acc@5 89.062 (90.143)
[epoch:71, iter:54941] Loss: 1.426, 10.504, 66.698, 436.447, 1.422
[epoch:71, iter:54961] Loss: 1.425, 10.490, 66.745, 436.556, 1.401
[epoch:71, iter:54981] Loss: 1.425, 10.481, 66.790, 436.879, 1.924
[epoch:71, iter:55001] Loss: 1.422, 10.470, 66.703, 436.739, 1.269
[epoch:71, iter:55021] Loss: 1.420, 10.472, 66.649, 436.745, 1.236
Epoch: [70][300/782]	Time 0.077 (0.078)	Data 0.002 (0.004)	Loss 13.3410 (13.6634)	Acc@1 54.688 (63.024)	Acc@5 89.062 (89.976)
[epoch:71, iter:55041] Loss: 1.416, 10.461, 66.561, 436.524, 1.489
[epoch:71, iter:55061] Loss: 1.415, 10.453, 66.506, 436.249, 1.395
[epoch:71, iter:55081] Loss: 1.413, 10.453, 66.523, 436.198, 1.494
[epoch:71, iter:55101] Loss: 1.414, 10.454, 66.503, 436.177, 1.288
[epoch:71, iter:55121] Loss: 1.413, 10.451, 66.490, 436.177, 1.050
Epoch: [70][400/782]	Time 0.098 (0.078)	Data 0.003 (0.003)	Loss 13.8149 (13.6579)	Acc@1 60.938 (62.894)	Acc@5 93.750 (89.787)
[epoch:71, iter:55141] Loss: 1.412, 10.450, 66.466, 436.184, 1.314
[epoch:71, iter:55161] Loss: 1.412, 10.451, 66.469, 436.167, 1.225
[epoch:71, iter:55181] Loss: 1.412, 10.455, 66.468, 436.194, 1.506
[epoch:71, iter:55201] Loss: 1.411, 10.456, 66.463, 436.230, 1.233
[epoch:71, iter:55221] Loss: 1.412, 10.455, 66.471, 436.201, 1.573
Epoch: [70][500/782]	Time 0.069 (0.078)	Data 0.002 (0.003)	Loss 13.2248 (13.6685)	Acc@1 65.625 (62.843)	Acc@5 93.750 (89.658)
[epoch:71, iter:55241] Loss: 1.413, 10.454, 66.470, 436.188, 1.049
[epoch:71, iter:55261] Loss: 1.413, 10.457, 66.455, 436.174, 1.535
[epoch:71, iter:55281] Loss: 1.413, 10.452, 66.437, 436.173, 1.545
[epoch:71, iter:55301] Loss: 1.412, 10.453, 66.383, 436.140, 1.260
[epoch:71, iter:55321] Loss: 1.413, 10.451, 66.390, 436.206, 1.553
Epoch: [70][600/782]	Time 0.079 (0.079)	Data 0.002 (0.003)	Loss 12.7143 (13.6766)	Acc@1 68.750 (62.508)	Acc@5 84.375 (89.432)
[epoch:71, iter:55341] Loss: 1.412, 10.448, 66.397, 436.181, 1.241
[epoch:71, iter:55361] Loss: 1.412, 10.450, 66.391, 436.213, 1.082
[epoch:71, iter:55381] Loss: 1.411, 10.449, 66.388, 436.235, 1.743
[epoch:71, iter:55401] Loss: 1.412, 10.449, 66.404, 436.290, 1.364
[epoch:71, iter:55421] Loss: 1.412, 10.448, 66.419, 436.333, 1.693
Epoch: [70][700/782]	Time 0.077 (0.079)	Data 0.003 (0.003)	Loss 13.8734 (13.6984)	Acc@1 64.062 (62.413)	Acc@5 95.312 (89.388)
[epoch:71, iter:55441] Loss: 1.412, 10.448, 66.443, 436.408, 1.198
[epoch:71, iter:55461] Loss: 1.413, 10.450, 66.454, 436.459, 1.455
[epoch:71, iter:55481] Loss: 1.413, 10.451, 66.439, 436.456, 1.770
[epoch:71, iter:55501] Loss: 1.413, 10.452, 66.425, 436.491, 1.139
[epoch:71, iter:55521] Loss: 1.413, 10.452, 66.419, 436.532, 1.765
 * Acc@1 62.308 Acc@5 89.362
epoch 70, total time 61.38
Test: [0/313]	Time 0.216 (0.216)	Loss 1.8115 (1.8115)	Acc@1 53.125 (53.125)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.0224 (1.9839)	Acc@1 59.375 (54.486)	Acc@5 90.625 (83.571)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8229 (1.9460)	Acc@1 53.125 (55.224)	Acc@5 87.500 (83.909)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5706 (1.9562)	Acc@1 46.875 (55.336)	Acc@5 81.250 (83.991)
 * Acc@1 55.410 Acc@5 84.110
==> training...
Epoch: [71][0/782]	Time 0.608 (0.608)	Data 0.526 (0.526)	Loss 13.4646 (13.4646)	Acc@1 54.688 (54.688)	Acc@5 89.062 (89.062)
[epoch:72, iter:55523] Loss: 1.445, 10.777, 65.611, 436.088, 1.432
[epoch:72, iter:55543] Loss: 1.427, 10.559, 66.533, 438.668, 1.441
[epoch:72, iter:55563] Loss: 1.403, 10.505, 66.504, 435.770, 1.406
[epoch:72, iter:55583] Loss: 1.394, 10.431, 66.219, 434.729, 0.926
[epoch:72, iter:55603] Loss: 1.399, 10.415, 66.306, 435.150, 1.258
Epoch: [71][100/782]	Time 0.073 (0.083)	Data 0.002 (0.007)	Loss 13.3570 (13.5401)	Acc@1 51.562 (63.351)	Acc@5 92.188 (89.496)
[epoch:72, iter:55623] Loss: 1.397, 10.406, 66.316, 435.180, 1.487
[epoch:72, iter:55643] Loss: 1.399, 10.404, 66.406, 435.586, 1.105
[epoch:72, iter:55663] Loss: 1.402, 10.396, 66.496, 436.064, 1.437
[epoch:72, iter:55683] Loss: 1.400, 10.394, 66.490, 436.094, 1.407
[epoch:72, iter:55703] Loss: 1.398, 10.401, 66.426, 435.787, 1.567
Epoch: [71][200/782]	Time 0.078 (0.082)	Data 0.002 (0.005)	Loss 13.8803 (13.6119)	Acc@1 59.375 (62.539)	Acc@5 85.938 (89.630)
[epoch:72, iter:55723] Loss: 1.398, 10.403, 66.411, 435.429, 1.399
[epoch:72, iter:55743] Loss: 1.399, 10.403, 66.368, 435.477, 1.136
[epoch:72, iter:55763] Loss: 1.399, 10.396, 66.379, 435.330, 1.124
[epoch:72, iter:55783] Loss: 1.398, 10.396, 66.386, 435.288, 1.040
[epoch:72, iter:55803] Loss: 1.399, 10.399, 66.416, 435.422, 0.881
Epoch: [71][300/782]	Time 0.063 (0.079)	Data 0.002 (0.004)	Loss 13.5530 (13.6113)	Acc@1 65.625 (62.718)	Acc@5 90.625 (89.670)
[epoch:72, iter:55823] Loss: 1.400, 10.408, 66.462, 435.604, 1.178
[epoch:72, iter:55843] Loss: 1.401, 10.420, 66.428, 435.612, 1.676
[epoch:72, iter:55863] Loss: 1.403, 10.423, 66.454, 435.543, 1.310
[epoch:72, iter:55883] Loss: 1.405, 10.422, 66.428, 435.541, 1.448
[epoch:72, iter:55903] Loss: 1.407, 10.431, 66.461, 435.770, 1.538
Epoch: [71][400/782]	Time 0.068 (0.079)	Data 0.002 (0.004)	Loss 14.6507 (13.6458)	Acc@1 59.375 (62.742)	Acc@5 84.375 (89.647)
[epoch:72, iter:55923] Loss: 1.409, 10.432, 66.427, 435.752, 1.528
[epoch:72, iter:55943] Loss: 1.411, 10.436, 66.451, 435.809, 1.742
[epoch:72, iter:55963] Loss: 1.411, 10.442, 66.508, 435.924, 1.270
[epoch:72, iter:55983] Loss: 1.410, 10.442, 66.484, 435.939, 0.866
[epoch:72, iter:56003] Loss: 1.410, 10.441, 66.500, 435.988, 1.635
Epoch: [71][500/782]	Time 0.077 (0.079)	Data 0.002 (0.003)	Loss 13.8347 (13.6734)	Acc@1 68.750 (62.403)	Acc@5 93.750 (89.527)
[epoch:72, iter:56023] Loss: 1.409, 10.439, 66.494, 435.995, 1.257
[epoch:72, iter:56043] Loss: 1.410, 10.444, 66.500, 436.097, 1.584
[epoch:72, iter:56063] Loss: 1.409, 10.439, 66.452, 436.060, 1.580
[epoch:72, iter:56083] Loss: 1.410, 10.440, 66.449, 436.119, 1.074
[epoch:72, iter:56103] Loss: 1.411, 10.442, 66.458, 436.128, 1.549
Epoch: [71][600/782]	Time 0.076 (0.079)	Data 0.002 (0.003)	Loss 14.1222 (13.6955)	Acc@1 65.625 (62.287)	Acc@5 89.062 (89.499)
[epoch:72, iter:56123] Loss: 1.412, 10.446, 66.473, 436.166, 1.226
[epoch:72, iter:56143] Loss: 1.412, 10.446, 66.465, 436.110, 1.672
[epoch:72, iter:56163] Loss: 1.412, 10.447, 66.495, 436.218, 1.673
[epoch:72, iter:56183] Loss: 1.412, 10.448, 66.502, 436.262, 1.331
[epoch:72, iter:56203] Loss: 1.411, 10.446, 66.494, 436.158, 1.180
Epoch: [71][700/782]	Time 0.077 (0.079)	Data 0.002 (0.003)	Loss 12.8667 (13.6996)	Acc@1 60.938 (62.188)	Acc@5 93.750 (89.453)
[epoch:72, iter:56223] Loss: 1.411, 10.448, 66.466, 436.092, 1.080
[epoch:72, iter:56243] Loss: 1.412, 10.449, 66.481, 436.189, 1.275
[epoch:72, iter:56263] Loss: 1.411, 10.449, 66.498, 436.310, 1.526
[epoch:72, iter:56283] Loss: 1.411, 10.453, 66.526, 436.377, 1.390
[epoch:72, iter:56303] Loss: 1.411, 10.454, 66.520, 436.339, 1.366
 * Acc@1 62.126 Acc@5 89.470
epoch 71, total time 62.15
Test: [0/313]	Time 0.270 (0.270)	Loss 2.4931 (2.4931)	Acc@1 50.000 (50.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.5130 (2.0215)	Acc@1 43.750 (54.208)	Acc@5 78.125 (83.509)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.5281 (2.0307)	Acc@1 59.375 (53.607)	Acc@5 93.750 (83.598)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.4766 (2.0485)	Acc@1 31.250 (53.644)	Acc@5 75.000 (83.399)
 * Acc@1 53.630 Acc@5 83.450
==> training...
Epoch: [72][0/782]	Time 0.557 (0.557)	Data 0.469 (0.469)	Loss 13.0750 (13.0750)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
[epoch:73, iter:56305] Loss: 1.427, 10.469, 69.158, 436.205, 0.960
[epoch:73, iter:56325] Loss: 1.435, 10.452, 66.996, 436.682, 1.301
[epoch:73, iter:56345] Loss: 1.423, 10.488, 66.914, 437.822, 1.564
[epoch:73, iter:56365] Loss: 1.415, 10.429, 66.414, 436.491, 1.179
[epoch:73, iter:56385] Loss: 1.411, 10.444, 66.149, 436.256, 1.275
Epoch: [72][100/782]	Time 0.079 (0.084)	Data 0.002 (0.007)	Loss 13.5494 (13.5141)	Acc@1 60.938 (63.738)	Acc@5 89.062 (90.285)
[epoch:73, iter:56405] Loss: 1.409, 10.412, 65.923, 435.152, 1.540
[epoch:73, iter:56425] Loss: 1.406, 10.382, 65.964, 434.994, 1.298
[epoch:73, iter:56445] Loss: 1.404, 10.384, 66.028, 434.964, 1.597
[epoch:73, iter:56465] Loss: 1.407, 10.383, 66.104, 434.885, 1.513
[epoch:73, iter:56485] Loss: 1.409, 10.395, 66.230, 435.201, 1.288
Epoch: [72][200/782]	Time 0.086 (0.080)	Data 0.002 (0.005)	Loss 13.7941 (13.5461)	Acc@1 64.062 (63.487)	Acc@5 90.625 (90.034)
[epoch:73, iter:56505] Loss: 1.411, 10.397, 66.223, 435.141, 1.291
[epoch:73, iter:56525] Loss: 1.410, 10.401, 66.188, 435.153, 1.389
[epoch:73, iter:56545] Loss: 1.408, 10.398, 66.147, 435.078, 1.323
[epoch:73, iter:56565] Loss: 1.408, 10.389, 66.153, 435.145, 1.191
[epoch:73, iter:56585] Loss: 1.408, 10.389, 66.105, 434.914, 1.361
Epoch: [72][300/782]	Time 0.066 (0.079)	Data 0.002 (0.004)	Loss 13.6798 (13.5290)	Acc@1 59.375 (63.543)	Acc@5 84.375 (89.945)
[epoch:73, iter:56605] Loss: 1.408, 10.393, 66.090, 434.981, 1.459
[epoch:73, iter:56625] Loss: 1.408, 10.393, 66.099, 434.997, 1.278
[epoch:73, iter:56645] Loss: 1.407, 10.397, 66.115, 435.141, 1.591
[epoch:73, iter:56665] Loss: 1.408, 10.401, 66.119, 435.249, 1.873
[epoch:73, iter:56685] Loss: 1.409, 10.407, 66.146, 435.322, 1.076
Epoch: [72][400/782]	Time 0.086 (0.079)	Data 0.002 (0.004)	Loss 13.6233 (13.5675)	Acc@1 62.500 (63.299)	Acc@5 87.500 (89.787)
[epoch:73, iter:56705] Loss: 1.409, 10.402, 66.124, 435.267, 1.405
[epoch:73, iter:56725] Loss: 1.409, 10.401, 66.157, 435.308, 1.184
[epoch:73, iter:56745] Loss: 1.409, 10.403, 66.173, 435.510, 1.928
[epoch:73, iter:56765] Loss: 1.409, 10.405, 66.187, 435.570, 1.651
[epoch:73, iter:56785] Loss: 1.412, 10.409, 66.245, 435.735, 1.262
Epoch: [72][500/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 13.5641 (13.6153)	Acc@1 62.500 (63.152)	Acc@5 92.188 (89.674)
[epoch:73, iter:56805] Loss: 1.412, 10.413, 66.260, 435.788, 1.426
[epoch:73, iter:56825] Loss: 1.411, 10.413, 66.250, 435.654, 0.947
[epoch:73, iter:56845] Loss: 1.413, 10.418, 66.252, 435.786, 1.562
[epoch:73, iter:56865] Loss: 1.413, 10.423, 66.287, 435.856, 1.248
[epoch:73, iter:56885] Loss: 1.413, 10.422, 66.294, 435.854, 1.529
Epoch: [72][600/782]	Time 0.069 (0.079)	Data 0.002 (0.003)	Loss 13.5199 (13.6263)	Acc@1 64.062 (63.111)	Acc@5 79.688 (89.627)
[epoch:73, iter:56905] Loss: 1.412, 10.423, 66.301, 435.880, 1.593
[epoch:73, iter:56925] Loss: 1.412, 10.425, 66.305, 435.916, 0.855
[epoch:73, iter:56945] Loss: 1.412, 10.424, 66.309, 435.884, 1.327
[epoch:73, iter:56965] Loss: 1.413, 10.423, 66.313, 435.874, 1.492
[epoch:73, iter:56985] Loss: 1.413, 10.422, 66.349, 435.913, 1.789
Epoch: [72][700/782]	Time 0.067 (0.079)	Data 0.002 (0.003)	Loss 14.5811 (13.6341)	Acc@1 46.875 (62.932)	Acc@5 89.062 (89.544)
[epoch:73, iter:57005] Loss: 1.413, 10.424, 66.358, 435.911, 1.927
[epoch:73, iter:57025] Loss: 1.413, 10.426, 66.358, 435.951, 1.292
[epoch:73, iter:57045] Loss: 1.413, 10.426, 66.374, 435.984, 1.061
[epoch:73, iter:57065] Loss: 1.413, 10.426, 66.360, 435.942, 1.352
[epoch:73, iter:57085] Loss: 1.413, 10.426, 66.331, 435.889, 1.705
 * Acc@1 62.790 Acc@5 89.378
epoch 72, total time 61.74
Test: [0/313]	Time 0.250 (0.250)	Loss 1.5101 (1.5101)	Acc@1 65.625 (65.625)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.0872 (1.9435)	Acc@1 53.125 (54.517)	Acc@5 93.750 (84.468)
Test: [200/313]	Time 0.012 (0.008)	Loss 1.9169 (1.9545)	Acc@1 56.250 (53.949)	Acc@5 84.375 (84.251)
Test: [300/313]	Time 0.013 (0.008)	Loss 3.2095 (1.9797)	Acc@1 37.500 (54.091)	Acc@5 71.875 (84.136)
 * Acc@1 54.120 Acc@5 84.090
==> training...
Epoch: [73][0/782]	Time 0.535 (0.535)	Data 0.470 (0.470)	Loss 14.1396 (14.1396)	Acc@1 53.125 (53.125)	Acc@5 82.812 (82.812)
[epoch:74, iter:57087] Loss: 1.538, 10.400, 69.128, 445.556, 1.527
[epoch:74, iter:57107] Loss: 1.431, 10.544, 66.771, 439.172, 1.232
[epoch:74, iter:57127] Loss: 1.427, 10.480, 67.074, 439.478, 1.249
[epoch:74, iter:57147] Loss: 1.434, 10.519, 66.804, 438.509, 1.844
[epoch:74, iter:57167] Loss: 1.420, 10.471, 66.222, 436.185, 0.808
Epoch: [73][100/782]	Time 0.090 (0.085)	Data 0.003 (0.007)	Loss 14.0278 (13.5629)	Acc@1 57.812 (63.537)	Acc@5 84.375 (90.517)
[epoch:74, iter:57187] Loss: 1.412, 10.440, 66.098, 435.761, 1.623
[epoch:74, iter:57207] Loss: 1.408, 10.433, 66.140, 435.970, 1.382
[epoch:74, iter:57227] Loss: 1.411, 10.431, 66.114, 435.736, 1.193
[epoch:74, iter:57247] Loss: 1.409, 10.427, 66.049, 435.506, 1.479
[epoch:74, iter:57267] Loss: 1.410, 10.429, 66.059, 435.615, 1.581
Epoch: [73][200/782]	Time 0.079 (0.082)	Data 0.002 (0.005)	Loss 13.2808 (13.5496)	Acc@1 62.500 (63.643)	Acc@5 90.625 (90.190)
[epoch:74, iter:57287] Loss: 1.411, 10.426, 66.039, 435.599, 1.258
[epoch:74, iter:57307] Loss: 1.409, 10.431, 66.039, 435.716, 1.351
[epoch:74, iter:57327] Loss: 1.409, 10.420, 66.089, 435.633, 1.695
[epoch:74, iter:57347] Loss: 1.408, 10.405, 66.086, 435.531, 1.241
[epoch:74, iter:57367] Loss: 1.410, 10.402, 66.142, 435.563, 1.306
Epoch: [73][300/782]	Time 0.069 (0.082)	Data 0.002 (0.004)	Loss 13.4385 (13.5521)	Acc@1 60.938 (63.767)	Acc@5 89.062 (90.059)
[epoch:74, iter:57387] Loss: 1.408, 10.400, 66.094, 435.382, 1.457
[epoch:74, iter:57407] Loss: 1.408, 10.405, 66.075, 435.344, 0.866
[epoch:74, iter:57427] Loss: 1.406, 10.406, 66.043, 435.233, 1.604
[epoch:74, iter:57447] Loss: 1.405, 10.404, 66.028, 435.156, 1.392
[epoch:74, iter:57467] Loss: 1.405, 10.407, 65.966, 434.886, 1.482
Epoch: [73][400/782]	Time 0.077 (0.080)	Data 0.002 (0.004)	Loss 12.9332 (13.5509)	Acc@1 65.625 (63.377)	Acc@5 98.438 (89.928)
[epoch:74, iter:57487] Loss: 1.405, 10.407, 65.998, 434.949, 1.123
[epoch:74, iter:57507] Loss: 1.406, 10.412, 66.058, 435.083, 1.046
[epoch:74, iter:57527] Loss: 1.406, 10.415, 66.098, 435.121, 1.408
[epoch:74, iter:57547] Loss: 1.405, 10.411, 66.140, 435.274, 1.840
[epoch:74, iter:57567] Loss: 1.405, 10.415, 66.137, 435.307, 0.954
Epoch: [73][500/782]	Time 0.076 (0.080)	Data 0.002 (0.003)	Loss 13.5634 (13.5850)	Acc@1 60.938 (63.202)	Acc@5 81.250 (89.886)
[epoch:74, iter:57587] Loss: 1.404, 10.416, 66.147, 435.311, 1.703
[epoch:74, iter:57607] Loss: 1.405, 10.419, 66.185, 435.487, 1.325
[epoch:74, iter:57627] Loss: 1.406, 10.421, 66.195, 435.599, 1.054
[epoch:74, iter:57647] Loss: 1.406, 10.424, 66.212, 435.612, 1.651
[epoch:74, iter:57667] Loss: 1.406, 10.426, 66.229, 435.649, 1.330
Epoch: [73][600/782]	Time 0.082 (0.079)	Data 0.003 (0.003)	Loss 13.7264 (13.6263)	Acc@1 60.938 (62.893)	Acc@5 85.938 (89.619)
[epoch:74, iter:57687] Loss: 1.406, 10.429, 66.240, 435.678, 1.443
[epoch:74, iter:57707] Loss: 1.408, 10.432, 66.222, 435.632, 1.190
[epoch:74, iter:57727] Loss: 1.409, 10.429, 66.218, 435.594, 0.835
[epoch:74, iter:57747] Loss: 1.410, 10.433, 66.265, 435.764, 1.654
[epoch:74, iter:57767] Loss: 1.410, 10.434, 66.285, 435.822, 1.460
Epoch: [73][700/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 13.5724 (13.6467)	Acc@1 57.812 (62.794)	Acc@5 90.625 (89.575)
[epoch:74, iter:57787] Loss: 1.411, 10.436, 66.306, 435.911, 1.328
[epoch:74, iter:57807] Loss: 1.411, 10.435, 66.313, 435.942, 1.387
[epoch:74, iter:57827] Loss: 1.411, 10.436, 66.305, 435.962, 1.370
[epoch:74, iter:57847] Loss: 1.410, 10.436, 66.299, 435.969, 1.298
[epoch:74, iter:57867] Loss: 1.410, 10.432, 66.288, 435.957, 1.402
 * Acc@1 62.690 Acc@5 89.530
epoch 73, total time 61.70
Test: [0/313]	Time 0.246 (0.246)	Loss 1.8506 (1.8506)	Acc@1 53.125 (53.125)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.1521 (2.0957)	Acc@1 50.000 (53.868)	Acc@5 84.375 (83.385)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5532 (2.0703)	Acc@1 68.750 (53.762)	Acc@5 84.375 (83.131)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.6252 (2.0658)	Acc@1 62.500 (53.976)	Acc@5 93.750 (83.316)
 * Acc@1 54.100 Acc@5 83.420
==> training...
Epoch: [74][0/782]	Time 0.558 (0.558)	Data 0.477 (0.477)	Loss 13.8074 (13.8074)	Acc@1 56.250 (56.250)	Acc@5 89.062 (89.062)
[epoch:75, iter:57869] Loss: 1.369, 10.332, 67.780, 434.736, 1.603
[epoch:75, iter:57889] Loss: 1.431, 10.497, 66.914, 436.802, 1.331
[epoch:75, iter:57909] Loss: 1.434, 10.534, 67.268, 437.400, 1.045
[epoch:75, iter:57929] Loss: 1.431, 10.507, 66.902, 436.249, 1.025
[epoch:75, iter:57949] Loss: 1.425, 10.494, 67.054, 436.892, 1.329
Epoch: [74][100/782]	Time 0.083 (0.085)	Data 0.002 (0.007)	Loss 12.8548 (13.6532)	Acc@1 67.188 (62.485)	Acc@5 89.062 (89.496)
[epoch:75, iter:57969] Loss: 1.418, 10.454, 66.738, 436.227, 1.138
[epoch:75, iter:57989] Loss: 1.416, 10.438, 66.544, 435.806, 1.279
[epoch:75, iter:58009] Loss: 1.414, 10.444, 66.568, 435.559, 1.448
[epoch:75, iter:58029] Loss: 1.412, 10.440, 66.574, 435.483, 1.411
[epoch:75, iter:58049] Loss: 1.410, 10.427, 66.500, 434.949, 0.997
Epoch: [74][200/782]	Time 0.085 (0.079)	Data 0.002 (0.005)	Loss 13.3032 (13.6066)	Acc@1 78.125 (62.920)	Acc@5 92.188 (89.754)
[epoch:75, iter:58069] Loss: 1.411, 10.422, 66.552, 435.013, 1.011
[epoch:75, iter:58089] Loss: 1.409, 10.418, 66.505, 434.789, 1.710
[epoch:75, iter:58109] Loss: 1.409, 10.416, 66.573, 434.945, 1.821
[epoch:75, iter:58129] Loss: 1.410, 10.421, 66.591, 435.086, 1.515
[epoch:75, iter:58149] Loss: 1.410, 10.422, 66.568, 435.014, 1.491
Epoch: [74][300/782]	Time 0.070 (0.078)	Data 0.002 (0.004)	Loss 12.8082 (13.6164)	Acc@1 73.438 (62.941)	Acc@5 93.750 (89.592)
[epoch:75, iter:58169] Loss: 1.409, 10.428, 66.547, 434.998, 1.064
[epoch:75, iter:58189] Loss: 1.411, 10.437, 66.492, 434.940, 1.206
[epoch:75, iter:58209] Loss: 1.412, 10.433, 66.453, 434.853, 1.339
[epoch:75, iter:58229] Loss: 1.412, 10.433, 66.502, 435.161, 1.077
[epoch:75, iter:58249] Loss: 1.411, 10.430, 66.511, 435.353, 1.742
Epoch: [74][400/782]	Time 0.062 (0.076)	Data 0.002 (0.003)	Loss 14.0399 (13.6503)	Acc@1 59.375 (62.781)	Acc@5 87.500 (89.522)
[epoch:75, iter:58269] Loss: 1.413, 10.441, 66.553, 435.439, 1.564
[epoch:75, iter:58289] Loss: 1.412, 10.445, 66.585, 435.522, 1.166
[epoch:75, iter:58309] Loss: 1.412, 10.446, 66.613, 435.766, 1.182
[epoch:75, iter:58329] Loss: 1.412, 10.446, 66.580, 435.755, 1.243
[epoch:75, iter:58349] Loss: 1.411, 10.445, 66.551, 435.724, 1.510
Epoch: [74][500/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 14.1304 (13.6615)	Acc@1 57.812 (62.612)	Acc@5 87.500 (89.502)
[epoch:75, iter:58369] Loss: 1.410, 10.442, 66.558, 435.784, 1.483
[epoch:75, iter:58389] Loss: 1.410, 10.442, 66.581, 435.879, 1.635
[epoch:75, iter:58409] Loss: 1.410, 10.443, 66.571, 435.930, 1.518
[epoch:75, iter:58429] Loss: 1.410, 10.443, 66.559, 435.898, 1.069
[epoch:75, iter:58449] Loss: 1.412, 10.447, 66.567, 436.004, 1.560
Epoch: [74][600/782]	Time 0.077 (0.077)	Data 0.002 (0.003)	Loss 13.6997 (13.6710)	Acc@1 59.375 (62.695)	Acc@5 92.188 (89.564)
[epoch:75, iter:58469] Loss: 1.412, 10.447, 66.557, 436.009, 1.470
[epoch:75, iter:58489] Loss: 1.413, 10.445, 66.587, 436.051, 1.526
[epoch:75, iter:58509] Loss: 1.413, 10.445, 66.580, 436.015, 1.557
[epoch:75, iter:58529] Loss: 1.413, 10.445, 66.604, 436.101, 1.397
[epoch:75, iter:58549] Loss: 1.413, 10.446, 66.610, 436.148, 1.272
Epoch: [74][700/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 13.9410 (13.6886)	Acc@1 59.375 (62.638)	Acc@5 95.312 (89.531)
[epoch:75, iter:58569] Loss: 1.413, 10.447, 66.624, 436.161, 1.498
[epoch:75, iter:58589] Loss: 1.413, 10.443, 66.602, 436.075, 1.518
[epoch:75, iter:58609] Loss: 1.413, 10.442, 66.577, 436.052, 1.534
[epoch:75, iter:58629] Loss: 1.413, 10.442, 66.559, 436.059, 1.387
[epoch:75, iter:58649] Loss: 1.413, 10.442, 66.550, 436.021, 1.404
 * Acc@1 62.648 Acc@5 89.526
epoch 74, total time 61.35
Test: [0/313]	Time 0.263 (0.263)	Loss 2.3775 (2.3775)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.010)	Loss 3.0931 (2.3170)	Acc@1 50.000 (51.300)	Acc@5 81.250 (82.611)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.6787 (2.3023)	Acc@1 68.750 (51.819)	Acc@5 90.625 (82.369)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.5271 (2.2901)	Acc@1 37.500 (52.253)	Acc@5 75.000 (82.216)
 * Acc@1 52.290 Acc@5 82.230
==> training...
Epoch: [75][0/782]	Time 0.633 (0.633)	Data 0.550 (0.550)	Loss 13.4926 (13.4926)	Acc@1 70.312 (70.312)	Acc@5 93.750 (93.750)
[epoch:76, iter:58651] Loss: 1.446, 10.684, 68.295, 437.538, 1.117
[epoch:76, iter:58671] Loss: 1.416, 10.631, 67.799, 438.993, 1.163
[epoch:76, iter:58691] Loss: 1.419, 10.501, 67.868, 440.119, 1.361
[epoch:76, iter:58711] Loss: 1.415, 10.479, 67.522, 439.251, 1.306
[epoch:76, iter:58731] Loss: 1.420, 10.510, 67.314, 438.338, 1.121
Epoch: [75][100/782]	Time 0.073 (0.079)	Data 0.002 (0.008)	Loss 13.0763 (13.7653)	Acc@1 62.500 (62.191)	Acc@5 92.188 (89.588)
[epoch:76, iter:58751] Loss: 1.414, 10.478, 67.063, 437.475, 1.079
[epoch:76, iter:58771] Loss: 1.417, 10.470, 66.916, 437.247, 1.127
[epoch:76, iter:58791] Loss: 1.412, 10.448, 66.641, 436.225, 1.189
[epoch:76, iter:58811] Loss: 1.411, 10.432, 66.496, 435.642, 1.097
[epoch:76, iter:58831] Loss: 1.413, 10.429, 66.516, 435.736, 1.049
Epoch: [75][200/782]	Time 0.092 (0.079)	Data 0.003 (0.005)	Loss 14.6669 (13.6295)	Acc@1 59.375 (62.920)	Acc@5 87.500 (89.863)
[epoch:76, iter:58851] Loss: 1.412, 10.431, 66.597, 435.738, 1.463
[epoch:76, iter:58871] Loss: 1.412, 10.422, 66.534, 435.540, 1.202
[epoch:76, iter:58891] Loss: 1.410, 10.422, 66.531, 435.603, 1.170
[epoch:76, iter:58911] Loss: 1.410, 10.416, 66.425, 435.378, 1.121
[epoch:76, iter:58931] Loss: 1.413, 10.422, 66.463, 435.491, 1.194
Epoch: [75][300/782]	Time 0.067 (0.077)	Data 0.002 (0.004)	Loss 13.9306 (13.6242)	Acc@1 65.625 (62.853)	Acc@5 90.625 (89.805)
[epoch:76, iter:58951] Loss: 1.413, 10.416, 66.576, 435.580, 1.354
[epoch:76, iter:58971] Loss: 1.413, 10.417, 66.580, 435.637, 1.293
[epoch:76, iter:58991] Loss: 1.413, 10.420, 66.538, 435.647, 1.468
[epoch:76, iter:59011] Loss: 1.414, 10.420, 66.591, 435.796, 0.929
[epoch:76, iter:59031] Loss: 1.413, 10.418, 66.623, 435.863, 1.236
Epoch: [75][400/782]	Time 0.080 (0.078)	Data 0.002 (0.004)	Loss 13.8547 (13.6413)	Acc@1 60.938 (62.862)	Acc@5 87.500 (89.752)
[epoch:76, iter:59051] Loss: 1.413, 10.417, 66.596, 435.803, 1.383
[epoch:76, iter:59071] Loss: 1.413, 10.417, 66.566, 435.766, 1.333
[epoch:76, iter:59091] Loss: 1.413, 10.425, 66.536, 435.799, 1.467
[epoch:76, iter:59111] Loss: 1.414, 10.425, 66.526, 435.853, 1.209
[epoch:76, iter:59131] Loss: 1.414, 10.423, 66.513, 435.888, 1.368
Epoch: [75][500/782]	Time 0.071 (0.076)	Data 0.002 (0.003)	Loss 14.3029 (13.6413)	Acc@1 57.812 (62.880)	Acc@5 89.062 (89.714)
[epoch:76, iter:59151] Loss: 1.415, 10.427, 66.540, 436.025, 1.589
[epoch:76, iter:59171] Loss: 1.413, 10.429, 66.531, 436.027, 1.435
[epoch:76, iter:59191] Loss: 1.412, 10.422, 66.530, 436.032, 1.330
[epoch:76, iter:59211] Loss: 1.412, 10.419, 66.520, 436.004, 1.615
[epoch:76, iter:59231] Loss: 1.412, 10.418, 66.498, 436.066, 1.470
Epoch: [75][600/782]	Time 0.091 (0.076)	Data 0.004 (0.003)	Loss 14.3928 (13.6595)	Acc@1 59.375 (62.695)	Acc@5 84.375 (89.601)
[epoch:76, iter:59251] Loss: 1.413, 10.418, 66.517, 436.185, 1.629
[epoch:76, iter:59271] Loss: 1.412, 10.414, 66.504, 436.118, 1.541
[epoch:76, iter:59291] Loss: 1.412, 10.413, 66.486, 436.057, 1.134
[epoch:76, iter:59311] Loss: 1.412, 10.414, 66.493, 436.123, 1.616
[epoch:76, iter:59331] Loss: 1.412, 10.415, 66.487, 436.091, 1.181
Epoch: [75][700/782]	Time 0.096 (0.076)	Data 0.003 (0.003)	Loss 13.3312 (13.6496)	Acc@1 62.500 (62.665)	Acc@5 85.938 (89.611)
[epoch:76, iter:59351] Loss: 1.412, 10.414, 66.482, 436.045, 1.391
[epoch:76, iter:59371] Loss: 1.412, 10.415, 66.482, 436.076, 1.629
[epoch:76, iter:59391] Loss: 1.412, 10.414, 66.471, 436.075, 1.142
[epoch:76, iter:59411] Loss: 1.412, 10.410, 66.457, 436.063, 1.348
[epoch:76, iter:59431] Loss: 1.411, 10.412, 66.450, 436.031, 1.022
 * Acc@1 62.598 Acc@5 89.500
epoch 75, total time 59.67
Test: [0/313]	Time 0.248 (0.248)	Loss 2.2386 (2.2386)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9690 (2.1476)	Acc@1 40.625 (53.465)	Acc@5 78.125 (83.880)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.3734 (2.1223)	Acc@1 68.750 (52.985)	Acc@5 96.875 (83.396)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.7480 (2.1292)	Acc@1 37.500 (53.322)	Acc@5 78.125 (83.160)
 * Acc@1 53.310 Acc@5 83.180
==> training...
Epoch: [76][0/782]	Time 0.504 (0.504)	Data 0.431 (0.431)	Loss 13.0249 (13.0249)	Acc@1 65.625 (65.625)	Acc@5 95.312 (95.312)
[epoch:77, iter:59433] Loss: 1.405, 10.565, 65.752, 431.538, 1.156
[epoch:77, iter:59453] Loss: 1.419, 10.493, 66.532, 435.037, 1.711
[epoch:77, iter:59473] Loss: 1.418, 10.405, 66.040, 433.953, 1.533
[epoch:77, iter:59493] Loss: 1.408, 10.416, 66.010, 434.470, 0.984
[epoch:77, iter:59513] Loss: 1.403, 10.406, 66.054, 434.773, 1.096
Epoch: [76][100/782]	Time 0.074 (0.083)	Data 0.002 (0.007)	Loss 13.8060 (13.4938)	Acc@1 57.812 (63.212)	Acc@5 84.375 (89.635)
[epoch:77, iter:59533] Loss: 1.403, 10.381, 65.912, 433.898, 1.514
[epoch:77, iter:59553] Loss: 1.403, 10.369, 65.934, 433.848, 1.042
[epoch:77, iter:59573] Loss: 1.402, 10.361, 65.916, 433.703, 1.264
[epoch:77, iter:59593] Loss: 1.399, 10.360, 65.788, 433.569, 0.792
[epoch:77, iter:59613] Loss: 1.402, 10.368, 65.881, 434.066, 1.455
Epoch: [76][200/782]	Time 0.081 (0.082)	Data 0.003 (0.004)	Loss 13.7481 (13.5487)	Acc@1 54.688 (62.850)	Acc@5 85.938 (89.622)
[epoch:77, iter:59633] Loss: 1.402, 10.377, 65.858, 434.184, 1.611
[epoch:77, iter:59653] Loss: 1.405, 10.381, 65.950, 434.545, 1.629
[epoch:77, iter:59673] Loss: 1.406, 10.383, 65.946, 434.690, 0.946
[epoch:77, iter:59693] Loss: 1.407, 10.383, 65.945, 434.853, 1.305
[epoch:77, iter:59713] Loss: 1.407, 10.387, 65.978, 434.783, 1.622
Epoch: [76][300/782]	Time 0.091 (0.083)	Data 0.003 (0.004)	Loss 15.2999 (13.6112)	Acc@1 54.688 (62.687)	Acc@5 79.688 (89.447)
[epoch:77, iter:59733] Loss: 1.406, 10.398, 66.043, 435.051, 2.057
[epoch:77, iter:59753] Loss: 1.406, 10.400, 66.057, 435.032, 1.069
[epoch:77, iter:59773] Loss: 1.406, 10.397, 66.031, 435.045, 1.276
[epoch:77, iter:59793] Loss: 1.407, 10.409, 66.059, 435.195, 1.909
[epoch:77, iter:59813] Loss: 1.408, 10.412, 66.034, 434.984, 1.270
Epoch: [76][400/782]	Time 0.073 (0.082)	Data 0.002 (0.003)	Loss 14.2388 (13.6150)	Acc@1 54.688 (62.508)	Acc@5 90.625 (89.347)
[epoch:77, iter:59833] Loss: 1.408, 10.411, 66.039, 435.190, 1.755
[epoch:77, iter:59853] Loss: 1.408, 10.410, 66.051, 435.228, 1.444
[epoch:77, iter:59873] Loss: 1.407, 10.410, 66.064, 435.305, 1.401
[epoch:77, iter:59893] Loss: 1.408, 10.406, 66.126, 435.398, 1.092
[epoch:77, iter:59913] Loss: 1.408, 10.407, 66.158, 435.368, 1.461
Epoch: [76][500/782]	Time 0.073 (0.082)	Data 0.002 (0.003)	Loss 14.5507 (13.6285)	Acc@1 60.938 (62.528)	Acc@5 84.375 (89.421)
[epoch:77, iter:59933] Loss: 1.409, 10.409, 66.224, 435.422, 1.583
[epoch:77, iter:59953] Loss: 1.409, 10.410, 66.256, 435.500, 1.262
[epoch:77, iter:59973] Loss: 1.410, 10.410, 66.280, 435.705, 1.690
[epoch:77, iter:59993] Loss: 1.411, 10.412, 66.282, 435.723, 1.011
[epoch:77, iter:60013] Loss: 1.411, 10.412, 66.314, 435.880, 1.363
Epoch: [76][600/782]	Time 0.088 (0.081)	Data 0.003 (0.003)	Loss 14.7064 (13.6676)	Acc@1 54.688 (62.568)	Acc@5 84.375 (89.408)
[epoch:77, iter:60033] Loss: 1.412, 10.412, 66.358, 435.949, 1.939
[epoch:77, iter:60053] Loss: 1.412, 10.412, 66.369, 435.953, 1.419
[epoch:77, iter:60073] Loss: 1.411, 10.412, 66.347, 435.941, 1.639
[epoch:77, iter:60093] Loss: 1.411, 10.411, 66.345, 435.987, 1.656
[epoch:77, iter:60113] Loss: 1.411, 10.406, 66.303, 435.907, 1.139
Epoch: [76][700/782]	Time 0.062 (0.081)	Data 0.002 (0.003)	Loss 14.2298 (13.6719)	Acc@1 67.188 (62.556)	Acc@5 87.500 (89.332)
[epoch:77, iter:60133] Loss: 1.410, 10.403, 66.292, 435.886, 1.486
[epoch:77, iter:60153] Loss: 1.410, 10.403, 66.278, 435.879, 1.838
[epoch:77, iter:60173] Loss: 1.410, 10.407, 66.258, 435.857, 1.021
[epoch:77, iter:60193] Loss: 1.410, 10.405, 66.255, 435.881, 1.582
[epoch:77, iter:60213] Loss: 1.410, 10.407, 66.256, 435.864, 1.192
 * Acc@1 62.584 Acc@5 89.348
epoch 76, total time 62.56
Test: [0/313]	Time 0.262 (0.262)	Loss 1.6690 (1.6690)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.011)	Loss 1.9479 (2.2554)	Acc@1 56.250 (52.197)	Acc@5 81.250 (82.302)
Test: [200/313]	Time 0.008 (0.009)	Loss 1.8943 (2.2756)	Acc@1 62.500 (51.928)	Acc@5 90.625 (82.121)
Test: [300/313]	Time 0.010 (0.009)	Loss 3.1022 (2.2625)	Acc@1 37.500 (51.983)	Acc@5 71.875 (82.299)
 * Acc@1 51.980 Acc@5 82.260
==> training...
Epoch: [77][0/782]	Time 0.573 (0.573)	Data 0.502 (0.502)	Loss 14.3977 (14.3977)	Acc@1 46.875 (46.875)	Acc@5 85.938 (85.938)
[epoch:78, iter:60215] Loss: 1.483, 10.389, 68.627, 441.870, 1.609
[epoch:78, iter:60235] Loss: 1.420, 10.478, 67.719, 439.584, 1.511
[epoch:78, iter:60255] Loss: 1.424, 10.484, 67.273, 437.601, 1.289
[epoch:78, iter:60275] Loss: 1.421, 10.504, 66.912, 436.945, 1.239
[epoch:78, iter:60295] Loss: 1.418, 10.481, 66.744, 436.850, 1.309
Epoch: [77][100/782]	Time 0.070 (0.084)	Data 0.002 (0.007)	Loss 13.1199 (13.7541)	Acc@1 65.625 (62.144)	Acc@5 93.750 (89.217)
[epoch:78, iter:60315] Loss: 1.417, 10.448, 66.938, 437.266, 1.060
[epoch:78, iter:60335] Loss: 1.416, 10.442, 66.900, 437.034, 1.438
[epoch:78, iter:60355] Loss: 1.415, 10.442, 66.728, 436.719, 0.932
[epoch:78, iter:60375] Loss: 1.416, 10.448, 66.634, 436.555, 1.100
[epoch:78, iter:60395] Loss: 1.416, 10.448, 66.607, 436.423, 1.882
Epoch: [77][200/782]	Time 0.063 (0.080)	Data 0.002 (0.005)	Loss 14.2052 (13.6822)	Acc@1 59.375 (62.889)	Acc@5 85.938 (89.428)
[epoch:78, iter:60415] Loss: 1.417, 10.466, 66.593, 436.448, 1.341
[epoch:78, iter:60435] Loss: 1.415, 10.459, 66.560, 436.180, 1.681
[epoch:78, iter:60455] Loss: 1.412, 10.454, 66.559, 436.229, 1.794
[epoch:78, iter:60475] Loss: 1.410, 10.450, 66.482, 436.012, 1.272
[epoch:78, iter:60495] Loss: 1.409, 10.444, 66.467, 435.794, 1.377
Epoch: [77][300/782]	Time 0.079 (0.079)	Data 0.003 (0.004)	Loss 13.3979 (13.6387)	Acc@1 71.875 (62.988)	Acc@5 90.625 (89.426)
[epoch:78, iter:60515] Loss: 1.408, 10.432, 66.470, 435.601, 1.014
[epoch:78, iter:60535] Loss: 1.407, 10.419, 66.369, 435.306, 1.207
[epoch:78, iter:60555] Loss: 1.405, 10.416, 66.310, 435.270, 1.832
[epoch:78, iter:60575] Loss: 1.404, 10.414, 66.257, 435.076, 1.586
[epoch:78, iter:60595] Loss: 1.403, 10.407, 66.207, 435.038, 1.175
Epoch: [77][400/782]	Time 0.087 (0.080)	Data 0.003 (0.004)	Loss 13.5470 (13.5839)	Acc@1 59.375 (63.151)	Acc@5 90.625 (89.398)
[epoch:78, iter:60615] Loss: 1.402, 10.399, 66.170, 435.072, 1.367
[epoch:78, iter:60635] Loss: 1.402, 10.400, 66.163, 435.169, 1.389
[epoch:78, iter:60655] Loss: 1.401, 10.395, 66.090, 434.968, 1.188
[epoch:78, iter:60675] Loss: 1.401, 10.395, 66.091, 435.000, 1.191
[epoch:78, iter:60695] Loss: 1.402, 10.395, 66.124, 435.013, 1.288
Epoch: [77][500/782]	Time 0.084 (0.080)	Data 0.003 (0.003)	Loss 11.9842 (13.5866)	Acc@1 73.438 (62.890)	Acc@5 95.312 (89.393)
[epoch:78, iter:60715] Loss: 1.402, 10.392, 66.084, 434.949, 0.856
[epoch:78, iter:60735] Loss: 1.401, 10.393, 66.091, 435.032, 1.649
[epoch:78, iter:60755] Loss: 1.402, 10.399, 66.125, 435.093, 1.989
[epoch:78, iter:60775] Loss: 1.403, 10.397, 66.118, 434.990, 0.950
[epoch:78, iter:60795] Loss: 1.403, 10.397, 66.133, 435.050, 1.592
Epoch: [77][600/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 13.4521 (13.6071)	Acc@1 70.312 (62.809)	Acc@5 89.062 (89.291)
[epoch:78, iter:60815] Loss: 1.403, 10.401, 66.140, 435.136, 1.313
[epoch:78, iter:60835] Loss: 1.404, 10.401, 66.159, 435.176, 1.095
[epoch:78, iter:60855] Loss: 1.403, 10.399, 66.174, 435.174, 1.545
[epoch:78, iter:60875] Loss: 1.404, 10.403, 66.212, 435.251, 1.226
[epoch:78, iter:60895] Loss: 1.403, 10.404, 66.224, 435.267, 1.237
Epoch: [77][700/782]	Time 0.082 (0.079)	Data 0.002 (0.003)	Loss 13.4130 (13.6273)	Acc@1 62.500 (62.734)	Acc@5 90.625 (89.252)
[epoch:78, iter:60915] Loss: 1.402, 10.403, 66.221, 435.255, 1.318
[epoch:78, iter:60935] Loss: 1.403, 10.406, 66.253, 435.373, 1.456
[epoch:78, iter:60955] Loss: 1.404, 10.405, 66.268, 435.424, 1.558
[epoch:78, iter:60975] Loss: 1.404, 10.411, 66.276, 435.507, 1.008
[epoch:78, iter:60995] Loss: 1.405, 10.417, 66.337, 435.737, 1.726
 * Acc@1 62.654 Acc@5 89.296
epoch 77, total time 61.93
Test: [0/313]	Time 0.288 (0.288)	Loss 2.1515 (2.1515)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.1235 (2.1111)	Acc@1 50.000 (53.311)	Acc@5 90.625 (83.354)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.5302 (2.0813)	Acc@1 68.750 (53.343)	Acc@5 84.375 (83.427)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.0462 (2.0856)	Acc@1 43.750 (53.675)	Acc@5 68.750 (83.212)
 * Acc@1 53.720 Acc@5 83.220
==> training...
Epoch: [78][0/782]	Time 0.499 (0.499)	Data 0.417 (0.417)	Loss 13.8102 (13.8102)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
[epoch:79, iter:60997] Loss: 1.399, 10.956, 68.857, 439.164, 1.402
[epoch:79, iter:61017] Loss: 1.403, 10.514, 66.831, 437.225, 1.262
[epoch:79, iter:61037] Loss: 1.397, 10.530, 66.691, 436.226, 1.144
[epoch:79, iter:61057] Loss: 1.398, 10.512, 66.758, 436.510, 1.551
[epoch:79, iter:61077] Loss: 1.404, 10.495, 66.525, 435.732, 1.293
Epoch: [78][100/782]	Time 0.099 (0.084)	Data 0.004 (0.007)	Loss 12.1519 (13.5806)	Acc@1 71.875 (63.304)	Acc@5 87.500 (89.666)
[epoch:79, iter:61097] Loss: 1.401, 10.485, 66.417, 435.044, 1.118
[epoch:79, iter:61117] Loss: 1.402, 10.479, 66.559, 435.562, 1.596
[epoch:79, iter:61137] Loss: 1.399, 10.453, 66.610, 435.466, 1.378
[epoch:79, iter:61157] Loss: 1.395, 10.448, 66.530, 435.071, 1.019
[epoch:79, iter:61177] Loss: 1.399, 10.449, 66.536, 435.266, 1.494
Epoch: [78][200/782]	Time 0.056 (0.082)	Data 0.002 (0.005)	Loss 13.5139 (13.6246)	Acc@1 62.500 (63.270)	Acc@5 96.875 (89.552)
[epoch:79, iter:61197] Loss: 1.401, 10.461, 66.612, 435.654, 0.903
[epoch:79, iter:61217] Loss: 1.403, 10.465, 66.668, 435.889, 1.115
[epoch:79, iter:61237] Loss: 1.403, 10.460, 66.620, 435.967, 1.367
[epoch:79, iter:61257] Loss: 1.404, 10.451, 66.665, 436.079, 1.235
[epoch:79, iter:61277] Loss: 1.405, 10.452, 66.700, 435.970, 1.841
Epoch: [78][300/782]	Time 0.072 (0.080)	Data 0.002 (0.004)	Loss 13.5611 (13.6641)	Acc@1 64.062 (63.206)	Acc@5 87.500 (89.452)
[epoch:79, iter:61297] Loss: 1.406, 10.454, 66.722, 436.120, 1.337
[epoch:79, iter:61317] Loss: 1.407, 10.458, 66.698, 436.161, 1.658
[epoch:79, iter:61337] Loss: 1.407, 10.457, 66.726, 436.278, 1.326
[epoch:79, iter:61357] Loss: 1.408, 10.454, 66.746, 436.149, 1.333
[epoch:79, iter:61377] Loss: 1.408, 10.452, 66.724, 436.249, 1.391
Epoch: [78][400/782]	Time 0.062 (0.078)	Data 0.002 (0.003)	Loss 14.5799 (13.6757)	Acc@1 46.875 (62.925)	Acc@5 84.375 (89.550)
[epoch:79, iter:61397] Loss: 1.408, 10.462, 66.740, 436.327, 1.751
[epoch:79, iter:61417] Loss: 1.409, 10.461, 66.752, 436.418, 1.412
[epoch:79, iter:61437] Loss: 1.408, 10.461, 66.713, 436.328, 1.418
[epoch:79, iter:61457] Loss: 1.409, 10.469, 66.731, 436.527, 1.354
[epoch:79, iter:61477] Loss: 1.409, 10.471, 66.722, 436.482, 1.145
Epoch: [78][500/782]	Time 0.064 (0.078)	Data 0.002 (0.003)	Loss 12.7346 (13.6878)	Acc@1 65.625 (62.662)	Acc@5 92.188 (89.415)
[epoch:79, iter:61497] Loss: 1.410, 10.466, 66.705, 436.411, 1.057
[epoch:79, iter:61517] Loss: 1.410, 10.461, 66.666, 436.305, 1.235
[epoch:79, iter:61537] Loss: 1.409, 10.457, 66.627, 436.164, 1.023
[epoch:79, iter:61557] Loss: 1.409, 10.461, 66.598, 435.985, 1.570
[epoch:79, iter:61577] Loss: 1.409, 10.460, 66.593, 436.009, 1.321
Epoch: [78][600/782]	Time 0.063 (0.078)	Data 0.002 (0.003)	Loss 13.4493 (13.6661)	Acc@1 70.312 (62.674)	Acc@5 89.062 (89.406)
[epoch:79, iter:61597] Loss: 1.409, 10.458, 66.565, 435.975, 1.106
[epoch:79, iter:61617] Loss: 1.409, 10.457, 66.558, 435.958, 1.248
[epoch:79, iter:61637] Loss: 1.408, 10.453, 66.562, 435.951, 1.357
[epoch:79, iter:61657] Loss: 1.409, 10.452, 66.574, 435.987, 1.732
[epoch:79, iter:61677] Loss: 1.409, 10.450, 66.612, 436.098, 1.356
Epoch: [78][700/782]	Time 0.089 (0.079)	Data 0.003 (0.003)	Loss 13.2905 (13.6904)	Acc@1 64.062 (62.493)	Acc@5 90.625 (89.308)
[epoch:79, iter:61697] Loss: 1.409, 10.450, 66.600, 436.173, 1.226
[epoch:79, iter:61717] Loss: 1.409, 10.447, 66.581, 436.167, 1.282
[epoch:79, iter:61737] Loss: 1.410, 10.446, 66.545, 436.119, 1.570
[epoch:79, iter:61757] Loss: 1.410, 10.443, 66.547, 436.166, 1.253
[epoch:79, iter:61777] Loss: 1.410, 10.440, 66.536, 436.174, 1.317
 * Acc@1 62.516 Acc@5 89.256
epoch 78, total time 61.87
Test: [0/313]	Time 0.276 (0.276)	Loss 1.7937 (1.7937)	Acc@1 65.625 (65.625)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.0830 (1.8898)	Acc@1 53.125 (56.498)	Acc@5 87.500 (85.427)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.4720 (1.8665)	Acc@1 65.625 (57.027)	Acc@5 87.500 (85.215)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.8107 (1.8603)	Acc@1 59.375 (57.361)	Acc@5 87.500 (85.382)
 * Acc@1 57.430 Acc@5 85.390
==> training...
Epoch: [79][0/782]	Time 0.474 (0.474)	Data 0.410 (0.410)	Loss 14.2166 (14.2166)	Acc@1 59.375 (59.375)	Acc@5 89.062 (89.062)
[epoch:80, iter:61779] Loss: 1.370, 10.706, 69.187, 440.665, 1.415
[epoch:80, iter:61799] Loss: 1.378, 10.497, 65.297, 430.878, 1.170
[epoch:80, iter:61819] Loss: 1.389, 10.435, 65.763, 432.679, 1.244
[epoch:80, iter:61839] Loss: 1.387, 10.424, 65.611, 432.516, 0.886
[epoch:80, iter:61859] Loss: 1.390, 10.407, 65.584, 432.616, 1.527
Epoch: [79][100/782]	Time 0.092 (0.086)	Data 0.003 (0.007)	Loss 15.1670 (13.4357)	Acc@1 57.812 (63.274)	Acc@5 76.562 (89.511)
[epoch:80, iter:61879] Loss: 1.395, 10.386, 65.663, 432.395, 2.264
[epoch:80, iter:61899] Loss: 1.394, 10.371, 65.580, 432.696, 1.498
[epoch:80, iter:61919] Loss: 1.394, 10.391, 65.620, 433.196, 1.206
[epoch:80, iter:61939] Loss: 1.395, 10.395, 65.577, 432.940, 1.403
[epoch:80, iter:61959] Loss: 1.398, 10.401, 65.730, 433.441, 1.356
Epoch: [79][200/782]	Time 0.067 (0.081)	Data 0.002 (0.005)	Loss 13.0301 (13.4721)	Acc@1 68.750 (63.612)	Acc@5 92.188 (89.995)
[epoch:80, iter:61979] Loss: 1.400, 10.410, 65.876, 433.715, 1.101
[epoch:80, iter:61999] Loss: 1.399, 10.408, 65.970, 433.761, 1.256
[epoch:80, iter:62019] Loss: 1.400, 10.411, 66.001, 433.678, 1.366
[epoch:80, iter:62039] Loss: 1.402, 10.421, 65.950, 433.690, 1.552
[epoch:80, iter:62059] Loss: 1.402, 10.424, 65.953, 433.944, 1.513
Epoch: [79][300/782]	Time 0.082 (0.080)	Data 0.002 (0.004)	Loss 13.5885 (13.5177)	Acc@1 56.250 (63.341)	Acc@5 87.500 (89.961)
[epoch:80, iter:62079] Loss: 1.403, 10.426, 65.940, 434.087, 1.493
[epoch:80, iter:62099] Loss: 1.404, 10.432, 65.946, 434.054, 1.566
[epoch:80, iter:62119] Loss: 1.404, 10.438, 65.954, 434.110, 1.088
[epoch:80, iter:62139] Loss: 1.404, 10.429, 66.009, 434.268, 1.385
[epoch:80, iter:62159] Loss: 1.405, 10.425, 66.105, 434.465, 1.514
Epoch: [79][400/782]	Time 0.066 (0.080)	Data 0.002 (0.003)	Loss 13.6869 (13.5623)	Acc@1 59.375 (63.155)	Acc@5 85.938 (89.811)
[epoch:80, iter:62179] Loss: 1.405, 10.425, 66.138, 434.556, 1.598
[epoch:80, iter:62199] Loss: 1.405, 10.425, 66.165, 434.627, 1.629
[epoch:80, iter:62219] Loss: 1.406, 10.430, 66.197, 434.714, 1.160
[epoch:80, iter:62239] Loss: 1.406, 10.432, 66.178, 434.637, 1.074
[epoch:80, iter:62259] Loss: 1.407, 10.432, 66.168, 434.622, 1.028
Epoch: [79][500/782]	Time 0.078 (0.079)	Data 0.002 (0.003)	Loss 13.8560 (13.5785)	Acc@1 54.688 (62.893)	Acc@5 89.062 (89.736)
[epoch:80, iter:62279] Loss: 1.408, 10.430, 66.162, 434.656, 1.449
[epoch:80, iter:62299] Loss: 1.408, 10.428, 66.186, 434.757, 0.954
[epoch:80, iter:62319] Loss: 1.408, 10.431, 66.201, 434.858, 1.109
[epoch:80, iter:62339] Loss: 1.408, 10.429, 66.232, 434.916, 1.167
[epoch:80, iter:62359] Loss: 1.408, 10.423, 66.214, 434.919, 1.315
Epoch: [79][600/782]	Time 0.066 (0.079)	Data 0.002 (0.003)	Loss 14.3111 (13.6130)	Acc@1 53.125 (62.770)	Acc@5 84.375 (89.585)
[epoch:80, iter:62379] Loss: 1.409, 10.428, 66.206, 434.988, 1.850
[epoch:80, iter:62399] Loss: 1.410, 10.430, 66.255, 435.205, 1.134
[epoch:80, iter:62419] Loss: 1.410, 10.434, 66.287, 435.312, 1.747
[epoch:80, iter:62439] Loss: 1.410, 10.434, 66.288, 435.386, 1.134
[epoch:80, iter:62459] Loss: 1.411, 10.438, 66.300, 435.498, 1.212
Epoch: [79][700/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.6123 (13.6601)	Acc@1 68.750 (62.600)	Acc@5 87.500 (89.435)
[epoch:80, iter:62479] Loss: 1.413, 10.442, 66.306, 435.572, 1.394
[epoch:80, iter:62499] Loss: 1.413, 10.439, 66.292, 435.558, 1.131
[epoch:80, iter:62519] Loss: 1.413, 10.434, 66.293, 435.558, 1.326
[epoch:80, iter:62539] Loss: 1.413, 10.434, 66.289, 435.611, 1.196
[epoch:80, iter:62559] Loss: 1.412, 10.433, 66.289, 435.620, 1.071
 * Acc@1 62.464 Acc@5 89.386
epoch 79, total time 61.03
Test: [0/313]	Time 0.258 (0.258)	Loss 1.3764 (1.3764)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.1463 (1.8771)	Acc@1 46.875 (55.353)	Acc@5 93.750 (84.499)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.7495 (1.8349)	Acc@1 56.250 (55.597)	Acc@5 93.750 (85.215)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.0395 (1.8604)	Acc@1 59.375 (55.502)	Acc@5 87.500 (85.071)
 * Acc@1 55.630 Acc@5 85.110
==> training...
Epoch: [80][0/782]	Time 0.486 (0.486)	Data 0.410 (0.410)	Loss 14.0347 (14.0347)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
[epoch:81, iter:62561] Loss: 1.391, 10.034, 69.301, 439.000, 1.418
[epoch:81, iter:62581] Loss: 1.430, 10.493, 67.949, 436.503, 1.217
[epoch:81, iter:62601] Loss: 1.415, 10.476, 67.102, 436.315, 1.486
[epoch:81, iter:62621] Loss: 1.410, 10.459, 66.611, 435.017, 1.081
[epoch:81, iter:62641] Loss: 1.414, 10.434, 66.519, 435.274, 1.458
Epoch: [80][100/782]	Time 0.064 (0.082)	Data 0.002 (0.006)	Loss 13.4424 (13.6629)	Acc@1 67.188 (62.546)	Acc@5 89.062 (89.325)
[epoch:81, iter:62661] Loss: 1.412, 10.418, 66.492, 435.203, 1.210
[epoch:81, iter:62681] Loss: 1.409, 10.422, 66.399, 435.474, 1.295
[epoch:81, iter:62701] Loss: 1.409, 10.412, 66.421, 435.377, 1.208
[epoch:81, iter:62721] Loss: 1.406, 10.402, 66.442, 435.488, 1.481
[epoch:81, iter:62741] Loss: 1.408, 10.406, 66.422, 435.091, 1.638
Epoch: [80][200/782]	Time 0.064 (0.080)	Data 0.002 (0.004)	Loss 13.8818 (13.6768)	Acc@1 57.812 (61.870)	Acc@5 92.188 (89.311)
[epoch:81, iter:62761] Loss: 1.409, 10.417, 66.483, 435.254, 1.309
[epoch:81, iter:62781] Loss: 1.409, 10.418, 66.469, 435.205, 1.832
[epoch:81, iter:62801] Loss: 1.411, 10.409, 66.464, 435.455, 1.649
[epoch:81, iter:62821] Loss: 1.411, 10.401, 66.384, 435.102, 1.299
[epoch:81, iter:62841] Loss: 1.411, 10.408, 66.360, 435.030, 1.505
Epoch: [80][300/782]	Time 0.083 (0.080)	Data 0.002 (0.004)	Loss 12.5178 (13.6351)	Acc@1 68.750 (62.246)	Acc@5 96.875 (89.509)
[epoch:81, iter:62861] Loss: 1.411, 10.418, 66.321, 435.016, 0.873
[epoch:81, iter:62881] Loss: 1.411, 10.416, 66.262, 434.926, 1.578
[epoch:81, iter:62901] Loss: 1.410, 10.408, 66.197, 434.640, 1.707
[epoch:81, iter:62921] Loss: 1.409, 10.404, 66.148, 434.373, 1.009
[epoch:81, iter:62941] Loss: 1.410, 10.408, 66.123, 434.295, 1.391
Epoch: [80][400/782]	Time 0.078 (0.080)	Data 0.003 (0.003)	Loss 14.5237 (13.6082)	Acc@1 68.750 (62.469)	Acc@5 95.312 (89.503)
[epoch:81, iter:62961] Loss: 1.410, 10.408, 66.171, 434.488, 1.179
[epoch:81, iter:62981] Loss: 1.411, 10.408, 66.196, 434.621, 1.107
[epoch:81, iter:63001] Loss: 1.411, 10.401, 66.135, 434.419, 0.935
[epoch:81, iter:63021] Loss: 1.409, 10.402, 66.098, 434.427, 1.367
[epoch:81, iter:63041] Loss: 1.410, 10.403, 66.100, 434.563, 1.540
Epoch: [80][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 14.3564 (13.6012)	Acc@1 64.062 (62.435)	Acc@5 85.938 (89.527)
[epoch:81, iter:63061] Loss: 1.410, 10.402, 66.123, 434.611, 1.488
[epoch:81, iter:63081] Loss: 1.409, 10.405, 66.136, 434.645, 1.238
[epoch:81, iter:63101] Loss: 1.409, 10.403, 66.125, 434.539, 1.373
[epoch:81, iter:63121] Loss: 1.409, 10.403, 66.108, 434.489, 1.080
[epoch:81, iter:63141] Loss: 1.408, 10.401, 66.085, 434.467, 1.907
Epoch: [80][600/782]	Time 0.097 (0.078)	Data 0.002 (0.003)	Loss 12.6494 (13.5932)	Acc@1 67.188 (62.586)	Acc@5 95.312 (89.580)
[epoch:81, iter:63161] Loss: 1.408, 10.400, 66.076, 434.473, 1.098
[epoch:81, iter:63181] Loss: 1.409, 10.402, 66.107, 434.624, 1.200
[epoch:81, iter:63201] Loss: 1.410, 10.407, 66.127, 434.759, 1.590
[epoch:81, iter:63221] Loss: 1.410, 10.412, 66.143, 434.835, 1.247
[epoch:81, iter:63241] Loss: 1.410, 10.410, 66.158, 434.865, 0.953
Epoch: [80][700/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 13.2868 (13.6180)	Acc@1 57.812 (62.594)	Acc@5 89.062 (89.531)
[epoch:81, iter:63261] Loss: 1.410, 10.409, 66.173, 434.893, 1.399
[epoch:81, iter:63281] Loss: 1.410, 10.405, 66.217, 434.988, 1.607
[epoch:81, iter:63301] Loss: 1.410, 10.411, 66.254, 435.034, 1.564
[epoch:81, iter:63321] Loss: 1.411, 10.416, 66.298, 435.141, 1.340
[epoch:81, iter:63341] Loss: 1.411, 10.419, 66.305, 435.138, 1.366
 * Acc@1 62.428 Acc@5 89.524
epoch 80, total time 60.86
Test: [0/313]	Time 0.252 (0.252)	Loss 2.1447 (2.1447)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.1677 (2.1627)	Acc@1 53.125 (53.589)	Acc@5 87.500 (83.230)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.6122 (2.1235)	Acc@1 62.500 (54.136)	Acc@5 90.625 (83.069)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4369 (2.1112)	Acc@1 46.875 (54.257)	Acc@5 78.125 (83.295)
 * Acc@1 54.280 Acc@5 83.280
==> Saving...
==> training...
Epoch: [81][0/782]	Time 0.463 (0.463)	Data 0.383 (0.383)	Loss 13.3144 (13.3144)	Acc@1 73.438 (73.438)	Acc@5 95.312 (95.312)
[epoch:82, iter:63343] Loss: 1.492, 10.726, 67.592, 436.609, 0.950
[epoch:82, iter:63363] Loss: 1.425, 10.426, 67.444, 435.511, 1.724
[epoch:82, iter:63383] Loss: 1.429, 10.453, 66.787, 435.119, 1.363
[epoch:82, iter:63403] Loss: 1.417, 10.449, 66.444, 435.409, 1.163
[epoch:82, iter:63423] Loss: 1.414, 10.455, 66.325, 435.183, 1.290
Epoch: [81][100/782]	Time 0.067 (0.076)	Data 0.002 (0.006)	Loss 13.1531 (13.4812)	Acc@1 68.750 (64.155)	Acc@5 93.750 (90.424)
[epoch:82, iter:63443] Loss: 1.408, 10.429, 66.290, 435.190, 1.105
[epoch:82, iter:63463] Loss: 1.406, 10.411, 66.356, 435.134, 1.127
[epoch:82, iter:63483] Loss: 1.402, 10.402, 66.249, 434.714, 1.752
[epoch:82, iter:63503] Loss: 1.403, 10.395, 66.278, 434.727, 1.654
[epoch:82, iter:63523] Loss: 1.405, 10.382, 66.271, 434.660, 1.553
Epoch: [81][200/782]	Time 0.067 (0.075)	Data 0.002 (0.004)	Loss 13.3696 (13.5053)	Acc@1 64.062 (63.627)	Acc@5 90.625 (90.190)
[epoch:82, iter:63543] Loss: 1.405, 10.372, 66.347, 434.613, 1.298
[epoch:82, iter:63563] Loss: 1.404, 10.375, 66.283, 434.578, 1.487
[epoch:82, iter:63583] Loss: 1.405, 10.382, 66.241, 434.594, 1.094
[epoch:82, iter:63603] Loss: 1.406, 10.383, 66.248, 434.698, 1.452
[epoch:82, iter:63623] Loss: 1.407, 10.394, 66.268, 434.848, 1.478
Epoch: [81][300/782]	Time 0.065 (0.075)	Data 0.002 (0.003)	Loss 13.1757 (13.5437)	Acc@1 56.250 (63.061)	Acc@5 92.188 (89.846)
[epoch:82, iter:63643] Loss: 1.406, 10.394, 66.265, 434.805, 1.444
[epoch:82, iter:63663] Loss: 1.406, 10.392, 66.205, 434.543, 1.291
[epoch:82, iter:63683] Loss: 1.405, 10.395, 66.158, 434.557, 1.597
[epoch:82, iter:63703] Loss: 1.407, 10.398, 66.249, 434.623, 1.489
[epoch:82, iter:63723] Loss: 1.407, 10.399, 66.285, 434.636, 1.636
Epoch: [81][400/782]	Time 0.087 (0.076)	Data 0.003 (0.003)	Loss 13.2258 (13.5538)	Acc@1 60.938 (63.116)	Acc@5 92.188 (89.733)
[epoch:82, iter:63743] Loss: 1.407, 10.395, 66.286, 434.561, 1.375
[epoch:82, iter:63763] Loss: 1.406, 10.394, 66.282, 434.595, 1.431
[epoch:82, iter:63783] Loss: 1.405, 10.390, 66.233, 434.486, 1.029
[epoch:82, iter:63803] Loss: 1.406, 10.388, 66.213, 434.369, 1.648
[epoch:82, iter:63823] Loss: 1.406, 10.390, 66.222, 434.443, 1.280
Epoch: [81][500/782]	Time 0.078 (0.076)	Data 0.002 (0.003)	Loss 14.3752 (13.5737)	Acc@1 53.125 (62.968)	Acc@5 82.812 (89.577)
[epoch:82, iter:63843] Loss: 1.408, 10.394, 66.222, 434.464, 1.793
[epoch:82, iter:63863] Loss: 1.408, 10.401, 66.279, 434.655, 1.219
[epoch:82, iter:63883] Loss: 1.408, 10.403, 66.298, 434.735, 1.471
[epoch:82, iter:63903] Loss: 1.408, 10.409, 66.275, 434.707, 1.060
[epoch:82, iter:63923] Loss: 1.409, 10.413, 66.284, 434.797, 1.403
Epoch: [81][600/782]	Time 0.090 (0.077)	Data 0.002 (0.003)	Loss 13.2765 (13.6030)	Acc@1 65.625 (62.789)	Acc@5 82.812 (89.510)
[epoch:82, iter:63943] Loss: 1.410, 10.409, 66.305, 434.899, 1.438
[epoch:82, iter:63963] Loss: 1.409, 10.408, 66.282, 434.841, 0.912
[epoch:82, iter:63983] Loss: 1.409, 10.409, 66.270, 434.892, 1.286
[epoch:82, iter:64003] Loss: 1.409, 10.410, 66.249, 434.879, 1.260
[epoch:82, iter:64023] Loss: 1.410, 10.413, 66.279, 434.968, 1.413
Epoch: [81][700/782]	Time 0.080 (0.076)	Data 0.003 (0.003)	Loss 13.9012 (13.6159)	Acc@1 60.938 (62.681)	Acc@5 82.812 (89.573)
[epoch:82, iter:64043] Loss: 1.410, 10.414, 66.274, 434.997, 1.526
[epoch:82, iter:64063] Loss: 1.410, 10.414, 66.264, 435.018, 1.391
[epoch:82, iter:64083] Loss: 1.410, 10.413, 66.257, 435.085, 1.734
[epoch:82, iter:64103] Loss: 1.410, 10.412, 66.246, 435.042, 1.322
[epoch:82, iter:64123] Loss: 1.411, 10.415, 66.266, 435.164, 1.486
 * Acc@1 62.696 Acc@5 89.548
epoch 81, total time 59.44
Test: [0/313]	Time 0.209 (0.209)	Loss 2.2892 (2.2892)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.3633 (2.3781)	Acc@1 50.000 (49.969)	Acc@5 84.375 (80.724)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.5672 (2.3638)	Acc@1 59.375 (50.202)	Acc@5 84.375 (80.442)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8273 (2.3726)	Acc@1 31.250 (50.218)	Acc@5 78.125 (80.368)
 * Acc@1 50.310 Acc@5 80.460
==> training...
Epoch: [82][0/782]	Time 0.538 (0.538)	Data 0.459 (0.459)	Loss 14.5197 (14.5197)	Acc@1 60.938 (60.938)	Acc@5 85.938 (85.938)
[epoch:83, iter:64125] Loss: 1.343, 10.378, 70.089, 451.982, 1.542
[epoch:83, iter:64145] Loss: 1.401, 10.524, 67.602, 438.007, 1.584
[epoch:83, iter:64165] Loss: 1.408, 10.474, 67.133, 436.889, 1.319
[epoch:83, iter:64185] Loss: 1.405, 10.442, 66.583, 435.569, 1.123
[epoch:83, iter:64205] Loss: 1.405, 10.388, 66.387, 434.723, 1.532
Epoch: [82][100/782]	Time 0.067 (0.086)	Data 0.003 (0.007)	Loss 12.5281 (13.5319)	Acc@1 75.000 (63.614)	Acc@5 95.312 (90.207)
[epoch:83, iter:64225] Loss: 1.407, 10.380, 66.431, 434.309, 0.900
[epoch:83, iter:64245] Loss: 1.405, 10.386, 66.379, 433.993, 1.605
[epoch:83, iter:64265] Loss: 1.406, 10.387, 66.398, 433.970, 1.325
[epoch:83, iter:64285] Loss: 1.404, 10.359, 66.323, 433.573, 1.458
[epoch:83, iter:64305] Loss: 1.407, 10.390, 66.375, 434.046, 1.447
Epoch: [82][200/782]	Time 0.089 (0.082)	Data 0.003 (0.005)	Loss 14.6292 (13.5068)	Acc@1 60.938 (63.542)	Acc@5 87.500 (89.925)
[epoch:83, iter:64325] Loss: 1.406, 10.385, 66.237, 433.733, 1.666
[epoch:83, iter:64345] Loss: 1.403, 10.381, 66.248, 433.863, 1.686
[epoch:83, iter:64365] Loss: 1.404, 10.381, 66.214, 433.884, 1.318
[epoch:83, iter:64385] Loss: 1.407, 10.377, 66.248, 434.027, 1.267
[epoch:83, iter:64405] Loss: 1.407, 10.384, 66.305, 434.172, 1.676
Epoch: [82][300/782]	Time 0.073 (0.078)	Data 0.002 (0.004)	Loss 14.4050 (13.5672)	Acc@1 54.688 (63.258)	Acc@5 84.375 (89.680)
[epoch:83, iter:64425] Loss: 1.407, 10.383, 66.258, 434.262, 1.778
[epoch:83, iter:64445] Loss: 1.407, 10.384, 66.234, 434.265, 1.470
[epoch:83, iter:64465] Loss: 1.407, 10.387, 66.259, 434.423, 1.514
[epoch:83, iter:64485] Loss: 1.406, 10.389, 66.257, 434.420, 1.027
[epoch:83, iter:64505] Loss: 1.406, 10.386, 66.225, 434.426, 1.380
Epoch: [82][400/782]	Time 0.076 (0.077)	Data 0.002 (0.003)	Loss 13.2388 (13.5649)	Acc@1 59.375 (63.256)	Acc@5 92.188 (89.678)
[epoch:83, iter:64525] Loss: 1.406, 10.381, 66.205, 434.438, 1.224
[epoch:83, iter:64545] Loss: 1.407, 10.383, 66.239, 434.617, 0.905
[epoch:83, iter:64565] Loss: 1.407, 10.386, 66.286, 434.767, 2.351
[epoch:83, iter:64585] Loss: 1.406, 10.389, 66.278, 434.836, 1.583
[epoch:83, iter:64605] Loss: 1.406, 10.390, 66.302, 434.898, 1.217
Epoch: [82][500/782]	Time 0.090 (0.077)	Data 0.002 (0.003)	Loss 13.1880 (13.6110)	Acc@1 71.875 (62.806)	Acc@5 87.500 (89.533)
[epoch:83, iter:64625] Loss: 1.406, 10.388, 66.289, 434.840, 1.272
[epoch:83, iter:64645] Loss: 1.407, 10.387, 66.289, 434.823, 1.548
[epoch:83, iter:64665] Loss: 1.407, 10.389, 66.287, 434.848, 1.061
[epoch:83, iter:64685] Loss: 1.408, 10.387, 66.325, 434.886, 1.467
[epoch:83, iter:64705] Loss: 1.407, 10.385, 66.344, 434.842, 1.201
Epoch: [82][600/782]	Time 0.080 (0.077)	Data 0.002 (0.003)	Loss 13.3325 (13.6188)	Acc@1 64.062 (62.765)	Acc@5 89.062 (89.481)
[epoch:83, iter:64725] Loss: 1.408, 10.390, 66.374, 434.857, 1.194
[epoch:83, iter:64745] Loss: 1.407, 10.393, 66.368, 434.820, 1.967
[epoch:83, iter:64765] Loss: 1.406, 10.391, 66.378, 434.797, 1.394
[epoch:83, iter:64785] Loss: 1.406, 10.386, 66.361, 434.787, 1.543
[epoch:83, iter:64805] Loss: 1.406, 10.384, 66.365, 434.862, 0.941
Epoch: [82][700/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 13.7564 (13.6183)	Acc@1 56.250 (62.725)	Acc@5 84.375 (89.461)
[epoch:83, iter:64825] Loss: 1.406, 10.387, 66.344, 434.848, 1.560
[epoch:83, iter:64845] Loss: 1.407, 10.390, 66.352, 434.915, 1.554
[epoch:83, iter:64865] Loss: 1.407, 10.395, 66.379, 434.905, 1.131
[epoch:83, iter:64885] Loss: 1.407, 10.394, 66.392, 434.976, 1.415
[epoch:83, iter:64905] Loss: 1.407, 10.394, 66.380, 434.990, 1.081
 * Acc@1 62.632 Acc@5 89.482
epoch 82, total time 60.14
Test: [0/313]	Time 0.283 (0.283)	Loss 2.6200 (2.6200)	Acc@1 59.375 (59.375)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.8583 (2.0854)	Acc@1 43.750 (54.889)	Acc@5 81.250 (82.704)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.9709 (2.0793)	Acc@1 59.375 (54.586)	Acc@5 90.625 (82.556)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.1635 (2.0948)	Acc@1 46.875 (54.516)	Acc@5 87.500 (82.485)
 * Acc@1 54.650 Acc@5 82.580
==> training...
Epoch: [83][0/782]	Time 0.673 (0.673)	Data 0.590 (0.590)	Loss 13.5709 (13.5709)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
[epoch:84, iter:64907] Loss: 1.488, 10.851, 68.140, 436.384, 1.112
[epoch:84, iter:64927] Loss: 1.443, 10.553, 66.783, 437.509, 1.228
[epoch:84, iter:64947] Loss: 1.412, 10.482, 66.174, 435.100, 1.202
[epoch:84, iter:64967] Loss: 1.404, 10.434, 65.767, 434.572, 1.568
[epoch:84, iter:64987] Loss: 1.404, 10.429, 65.729, 434.036, 1.044
Epoch: [83][100/782]	Time 0.075 (0.091)	Data 0.002 (0.008)	Loss 13.4203 (13.5099)	Acc@1 65.625 (62.980)	Acc@5 93.750 (89.573)
[epoch:84, iter:65007] Loss: 1.405, 10.405, 65.719, 433.853, 1.135
[epoch:84, iter:65027] Loss: 1.403, 10.386, 65.844, 433.939, 1.181
[epoch:84, iter:65047] Loss: 1.404, 10.393, 65.994, 434.625, 1.447
[epoch:84, iter:65067] Loss: 1.401, 10.396, 66.029, 434.741, 1.304
[epoch:84, iter:65087] Loss: 1.404, 10.393, 66.030, 434.826, 1.011
Epoch: [83][200/782]	Time 0.085 (0.085)	Data 0.002 (0.005)	Loss 12.1135 (13.5918)	Acc@1 78.125 (62.687)	Acc@5 93.750 (89.599)
[epoch:84, iter:65107] Loss: 1.403, 10.381, 66.076, 434.725, 0.961
[epoch:84, iter:65127] Loss: 1.404, 10.372, 66.090, 434.685, 1.417
[epoch:84, iter:65147] Loss: 1.402, 10.373, 66.155, 434.769, 1.104
[epoch:84, iter:65167] Loss: 1.402, 10.388, 66.113, 434.691, 1.219
[epoch:84, iter:65187] Loss: 1.402, 10.389, 66.100, 434.725, 1.151
Epoch: [83][300/782]	Time 0.083 (0.083)	Data 0.002 (0.004)	Loss 13.4409 (13.5910)	Acc@1 60.938 (62.671)	Acc@5 90.625 (89.582)
[epoch:84, iter:65207] Loss: 1.401, 10.391, 66.093, 434.720, 1.318
[epoch:84, iter:65227] Loss: 1.399, 10.389, 66.050, 434.532, 1.245
[epoch:84, iter:65247] Loss: 1.399, 10.393, 65.993, 434.388, 1.278
[epoch:84, iter:65267] Loss: 1.398, 10.394, 65.960, 434.346, 1.270
[epoch:84, iter:65287] Loss: 1.398, 10.392, 65.933, 434.304, 1.585
Epoch: [83][400/782]	Time 0.066 (0.082)	Data 0.002 (0.004)	Loss 13.2401 (13.5704)	Acc@1 62.500 (62.745)	Acc@5 90.625 (89.631)
[epoch:84, iter:65307] Loss: 1.398, 10.389, 65.981, 434.415, 1.393
[epoch:84, iter:65327] Loss: 1.400, 10.399, 66.039, 434.647, 1.185
[epoch:84, iter:65347] Loss: 1.400, 10.403, 66.078, 434.725, 1.261
[epoch:84, iter:65367] Loss: 1.401, 10.410, 66.113, 434.879, 1.676
[epoch:84, iter:65387] Loss: 1.402, 10.416, 66.167, 435.127, 1.485
Epoch: [83][500/782]	Time 0.067 (0.080)	Data 0.002 (0.004)	Loss 14.1596 (13.6434)	Acc@1 68.750 (62.556)	Acc@5 87.500 (89.555)
[epoch:84, iter:65407] Loss: 1.404, 10.425, 66.198, 435.218, 1.466
[epoch:84, iter:65427] Loss: 1.405, 10.423, 66.267, 435.382, 1.605
[epoch:84, iter:65447] Loss: 1.405, 10.423, 66.303, 435.451, 2.001
[epoch:84, iter:65467] Loss: 1.405, 10.423, 66.313, 435.501, 1.513
[epoch:84, iter:65487] Loss: 1.406, 10.425, 66.332, 435.450, 1.031
Epoch: [83][600/782]	Time 0.084 (0.079)	Data 0.005 (0.003)	Loss 13.0476 (13.6580)	Acc@1 65.625 (62.562)	Acc@5 89.062 (89.445)
[epoch:84, iter:65507] Loss: 1.407, 10.421, 66.318, 435.373, 1.423
[epoch:84, iter:65527] Loss: 1.406, 10.424, 66.285, 435.300, 1.447
[epoch:84, iter:65547] Loss: 1.406, 10.424, 66.321, 435.365, 1.034
[epoch:84, iter:65567] Loss: 1.407, 10.428, 66.356, 435.438, 1.760
[epoch:84, iter:65587] Loss: 1.408, 10.430, 66.330, 435.401, 1.299
Epoch: [83][700/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 13.2247 (13.6640)	Acc@1 64.062 (62.426)	Acc@5 93.750 (89.406)
[epoch:84, iter:65607] Loss: 1.407, 10.430, 66.332, 435.423, 1.356
[epoch:84, iter:65627] Loss: 1.407, 10.431, 66.315, 435.355, 1.204
[epoch:84, iter:65647] Loss: 1.408, 10.435, 66.318, 435.358, 1.245
[epoch:84, iter:65667] Loss: 1.408, 10.434, 66.307, 435.327, 1.349
[epoch:84, iter:65687] Loss: 1.408, 10.436, 66.352, 435.433, 1.408
 * Acc@1 62.392 Acc@5 89.394
epoch 83, total time 62.31
Test: [0/313]	Time 0.260 (0.260)	Loss 2.5485 (2.5485)	Acc@1 50.000 (50.000)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.3318 (2.0939)	Acc@1 56.250 (53.589)	Acc@5 84.375 (83.168)
Test: [200/313]	Time 0.010 (0.008)	Loss 1.1605 (2.1082)	Acc@1 68.750 (52.861)	Acc@5 93.750 (82.898)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.9050 (2.1128)	Acc@1 50.000 (52.938)	Acc@5 87.500 (82.797)
 * Acc@1 53.050 Acc@5 82.930
==> training...
Epoch: [84][0/782]	Time 0.494 (0.494)	Data 0.413 (0.413)	Loss 12.9226 (12.9226)	Acc@1 71.875 (71.875)	Acc@5 89.062 (89.062)
[epoch:85, iter:65689] Loss: 1.294, 10.728, 65.563, 431.561, 1.212
[epoch:85, iter:65709] Loss: 1.406, 10.535, 66.034, 435.751, 1.684
[epoch:85, iter:65729] Loss: 1.406, 10.401, 65.786, 435.147, 1.326
[epoch:85, iter:65749] Loss: 1.410, 10.373, 66.120, 434.528, 1.263
[epoch:85, iter:65769] Loss: 1.406, 10.386, 66.024, 434.432, 1.025
Epoch: [84][100/782]	Time 0.061 (0.081)	Data 0.002 (0.006)	Loss 12.9354 (13.4897)	Acc@1 57.812 (63.583)	Acc@5 90.625 (90.192)
[epoch:85, iter:65789] Loss: 1.409, 10.389, 66.020, 433.972, 1.319
[epoch:85, iter:65809] Loss: 1.404, 10.385, 65.870, 433.647, 1.413
[epoch:85, iter:65829] Loss: 1.400, 10.383, 65.828, 433.310, 1.324
[epoch:85, iter:65849] Loss: 1.401, 10.359, 65.816, 433.195, 1.812
[epoch:85, iter:65869] Loss: 1.400, 10.373, 65.912, 433.367, 1.932
Epoch: [84][200/782]	Time 0.072 (0.080)	Data 0.002 (0.004)	Loss 13.7136 (13.5098)	Acc@1 56.250 (62.850)	Acc@5 89.062 (89.762)
[epoch:85, iter:65889] Loss: 1.402, 10.386, 65.990, 433.399, 1.561
[epoch:85, iter:65909] Loss: 1.403, 10.400, 66.046, 433.715, 1.429
[epoch:85, iter:65929] Loss: 1.403, 10.400, 66.041, 433.733, 1.400
[epoch:85, iter:65949] Loss: 1.401, 10.397, 66.044, 433.585, 1.303
[epoch:85, iter:65969] Loss: 1.403, 10.400, 66.107, 433.716, 0.863
Epoch: [84][300/782]	Time 0.085 (0.080)	Data 0.003 (0.004)	Loss 13.2965 (13.5160)	Acc@1 53.125 (63.107)	Acc@5 87.500 (89.784)
[epoch:85, iter:65989] Loss: 1.402, 10.399, 66.053, 433.509, 1.358
[epoch:85, iter:66009] Loss: 1.403, 10.399, 66.008, 433.557, 1.322
[epoch:85, iter:66029] Loss: 1.403, 10.399, 66.025, 433.591, 0.998
[epoch:85, iter:66049] Loss: 1.402, 10.405, 65.992, 433.532, 1.279
[epoch:85, iter:66069] Loss: 1.401, 10.403, 65.975, 433.361, 1.723
Epoch: [84][400/782]	Time 0.061 (0.079)	Data 0.002 (0.003)	Loss 13.7104 (13.5269)	Acc@1 54.688 (62.913)	Acc@5 84.375 (89.624)
[epoch:85, iter:66089] Loss: 1.401, 10.400, 65.972, 433.322, 1.426
[epoch:85, iter:66109] Loss: 1.400, 10.395, 65.941, 433.290, 1.834
[epoch:85, iter:66129] Loss: 1.400, 10.389, 65.924, 433.227, 1.271
[epoch:85, iter:66149] Loss: 1.400, 10.382, 65.974, 433.416, 1.400
[epoch:85, iter:66169] Loss: 1.401, 10.382, 66.068, 433.628, 1.520
Epoch: [84][500/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 14.1536 (13.5699)	Acc@1 59.375 (62.852)	Acc@5 92.188 (89.540)
[epoch:85, iter:66189] Loss: 1.402, 10.388, 66.093, 433.787, 1.348
[epoch:85, iter:66209] Loss: 1.403, 10.391, 66.159, 434.047, 1.899
[epoch:85, iter:66229] Loss: 1.403, 10.395, 66.176, 434.109, 1.050
[epoch:85, iter:66249] Loss: 1.403, 10.399, 66.180, 434.144, 1.312
[epoch:85, iter:66269] Loss: 1.403, 10.399, 66.194, 434.186, 1.603
Epoch: [84][600/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 12.5749 (13.6025)	Acc@1 67.188 (62.669)	Acc@5 93.750 (89.491)
[epoch:85, iter:66289] Loss: 1.403, 10.400, 66.193, 434.220, 1.068
[epoch:85, iter:66309] Loss: 1.404, 10.401, 66.188, 434.218, 1.275
[epoch:85, iter:66329] Loss: 1.405, 10.400, 66.201, 434.233, 1.315
[epoch:85, iter:66349] Loss: 1.404, 10.403, 66.196, 434.191, 1.667
[epoch:85, iter:66369] Loss: 1.404, 10.400, 66.205, 434.254, 1.695
Epoch: [84][700/782]	Time 0.058 (0.079)	Data 0.002 (0.003)	Loss 14.2917 (13.6158)	Acc@1 60.938 (62.549)	Acc@5 92.188 (89.412)
[epoch:85, iter:66389] Loss: 1.404, 10.398, 66.201, 434.224, 1.441
[epoch:85, iter:66409] Loss: 1.405, 10.395, 66.209, 434.309, 1.651
[epoch:85, iter:66429] Loss: 1.405, 10.398, 66.197, 434.226, 1.232
[epoch:85, iter:66449] Loss: 1.405, 10.395, 66.187, 434.174, 1.076
[epoch:85, iter:66469] Loss: 1.404, 10.393, 66.199, 434.210, 1.301
 * Acc@1 62.632 Acc@5 89.390
epoch 84, total time 61.35
Test: [0/313]	Time 0.256 (0.256)	Loss 2.5841 (2.5841)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.8292 (2.3427)	Acc@1 50.000 (51.887)	Acc@5 78.125 (82.457)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.6691 (2.3233)	Acc@1 59.375 (51.803)	Acc@5 84.375 (82.198)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.6382 (2.3424)	Acc@1 34.375 (51.890)	Acc@5 84.375 (81.852)
 * Acc@1 51.900 Acc@5 81.920
==> training...
Epoch: [85][0/782]	Time 0.493 (0.493)	Data 0.428 (0.428)	Loss 15.1667 (15.1667)	Acc@1 56.250 (56.250)	Acc@5 87.500 (87.500)
[epoch:86, iter:66471] Loss: 1.521, 10.681, 72.169, 448.298, 1.731
[epoch:86, iter:66491] Loss: 1.430, 10.584, 66.631, 433.390, 1.432
[epoch:86, iter:66511] Loss: 1.423, 10.432, 66.825, 433.941, 1.276
[epoch:86, iter:66531] Loss: 1.420, 10.411, 66.460, 433.863, 1.399
[epoch:86, iter:66551] Loss: 1.418, 10.383, 66.378, 434.306, 1.176
Epoch: [85][100/782]	Time 0.084 (0.082)	Data 0.003 (0.006)	Loss 13.4004 (13.5225)	Acc@1 57.812 (63.335)	Acc@5 87.500 (90.068)
[epoch:86, iter:66571] Loss: 1.414, 10.371, 66.147, 434.167, 1.515
[epoch:86, iter:66591] Loss: 1.413, 10.360, 66.167, 434.169, 1.546
[epoch:86, iter:66611] Loss: 1.417, 10.397, 66.248, 434.488, 1.541
[epoch:86, iter:66631] Loss: 1.415, 10.406, 66.159, 434.312, 1.177
[epoch:86, iter:66651] Loss: 1.412, 10.380, 65.993, 434.010, 1.444
Epoch: [85][200/782]	Time 0.076 (0.081)	Data 0.003 (0.004)	Loss 14.3082 (13.5405)	Acc@1 57.812 (62.757)	Acc@5 81.250 (89.793)
[epoch:86, iter:66671] Loss: 1.412, 10.375, 66.008, 434.069, 1.833
[epoch:86, iter:66691] Loss: 1.412, 10.376, 66.014, 433.895, 1.147
[epoch:86, iter:66711] Loss: 1.412, 10.380, 66.061, 433.974, 1.362
[epoch:86, iter:66731] Loss: 1.411, 10.381, 66.078, 433.917, 1.152
[epoch:86, iter:66751] Loss: 1.409, 10.382, 66.058, 433.956, 1.385
Epoch: [85][300/782]	Time 0.078 (0.079)	Data 0.002 (0.004)	Loss 13.6884 (13.5570)	Acc@1 59.375 (62.614)	Acc@5 87.500 (89.888)
[epoch:86, iter:66771] Loss: 1.410, 10.381, 66.066, 433.978, 1.434
[epoch:86, iter:66791] Loss: 1.408, 10.377, 66.013, 433.728, 1.372
[epoch:86, iter:66811] Loss: 1.407, 10.369, 65.981, 433.688, 1.314
[epoch:86, iter:66831] Loss: 1.407, 10.370, 65.992, 433.650, 1.517
[epoch:86, iter:66851] Loss: 1.408, 10.374, 65.978, 433.747, 1.168
Epoch: [85][400/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 13.4267 (13.5449)	Acc@1 68.750 (62.843)	Acc@5 92.188 (89.865)
[epoch:86, iter:66871] Loss: 1.409, 10.378, 65.974, 433.920, 1.181
[epoch:86, iter:66891] Loss: 1.408, 10.378, 65.981, 434.029, 1.370
[epoch:86, iter:66911] Loss: 1.408, 10.385, 66.010, 434.244, 1.611
[epoch:86, iter:66931] Loss: 1.409, 10.385, 66.022, 434.274, 1.401
[epoch:86, iter:66951] Loss: 1.408, 10.382, 65.997, 434.222, 1.456
Epoch: [85][500/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 13.4869 (13.5693)	Acc@1 64.062 (62.684)	Acc@5 93.750 (89.730)
[epoch:86, iter:66971] Loss: 1.408, 10.387, 65.997, 434.453, 1.170
[epoch:86, iter:66991] Loss: 1.408, 10.392, 65.992, 434.511, 1.889
[epoch:86, iter:67011] Loss: 1.407, 10.393, 65.995, 434.518, 1.428
[epoch:86, iter:67031] Loss: 1.407, 10.390, 66.005, 434.464, 1.427
[epoch:86, iter:67051] Loss: 1.407, 10.394, 66.076, 434.717, 1.893
Epoch: [85][600/782]	Time 0.095 (0.078)	Data 0.003 (0.003)	Loss 13.7959 (13.6005)	Acc@1 54.688 (62.620)	Acc@5 89.062 (89.582)
[epoch:86, iter:67071] Loss: 1.408, 10.400, 66.104, 434.793, 1.546
[epoch:86, iter:67091] Loss: 1.408, 10.396, 66.112, 434.757, 0.952
[epoch:86, iter:67111] Loss: 1.408, 10.396, 66.104, 434.730, 1.693
[epoch:86, iter:67131] Loss: 1.408, 10.397, 66.138, 434.858, 1.459
[epoch:86, iter:67151] Loss: 1.408, 10.400, 66.138, 434.850, 1.377
Epoch: [85][700/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 13.6156 (13.6160)	Acc@1 60.938 (62.605)	Acc@5 93.750 (89.515)
[epoch:86, iter:67171] Loss: 1.409, 10.401, 66.181, 434.914, 1.279
[epoch:86, iter:67191] Loss: 1.409, 10.403, 66.206, 434.977, 2.104
[epoch:86, iter:67211] Loss: 1.409, 10.403, 66.228, 435.069, 1.505
[epoch:86, iter:67231] Loss: 1.409, 10.407, 66.251, 435.136, 1.278
[epoch:86, iter:67251] Loss: 1.409, 10.409, 66.274, 435.191, 1.303
 * Acc@1 62.384 Acc@5 89.440
epoch 85, total time 61.19
Test: [0/313]	Time 0.287 (0.287)	Loss 1.7786 (1.7786)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.0401 (1.7962)	Acc@1 56.250 (57.859)	Acc@5 87.500 (85.458)
Test: [200/313]	Time 0.011 (0.008)	Loss 1.2326 (1.7759)	Acc@1 65.625 (57.400)	Acc@5 87.500 (85.339)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.9314 (1.7731)	Acc@1 43.750 (57.787)	Acc@5 87.500 (85.403)
 * Acc@1 57.820 Acc@5 85.460
saving the best model!
==> training...
Epoch: [86][0/782]	Time 0.574 (0.574)	Data 0.487 (0.487)	Loss 13.8211 (13.8211)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
[epoch:87, iter:67253] Loss: 1.367, 10.126, 69.360, 435.277, 1.236
[epoch:87, iter:67273] Loss: 1.413, 10.484, 67.040, 433.346, 0.961
[epoch:87, iter:67293] Loss: 1.394, 10.457, 66.496, 433.953, 1.224
[epoch:87, iter:67313] Loss: 1.393, 10.449, 66.115, 434.211, 1.433
[epoch:87, iter:67333] Loss: 1.388, 10.374, 66.075, 433.684, 1.399
Epoch: [86][100/782]	Time 0.064 (0.079)	Data 0.002 (0.007)	Loss 13.4532 (13.4491)	Acc@1 60.938 (63.258)	Acc@5 92.188 (90.625)
[epoch:87, iter:67353] Loss: 1.388, 10.339, 66.055, 433.801, 1.306
[epoch:87, iter:67373] Loss: 1.391, 10.343, 65.928, 433.455, 1.382
[epoch:87, iter:67393] Loss: 1.389, 10.327, 65.779, 432.712, 1.247
[epoch:87, iter:67413] Loss: 1.393, 10.322, 65.867, 432.790, 1.394
[epoch:87, iter:67433] Loss: 1.394, 10.345, 65.900, 432.919, 1.228
Epoch: [86][200/782]	Time 0.069 (0.076)	Data 0.002 (0.005)	Loss 13.5896 (13.4869)	Acc@1 70.312 (63.347)	Acc@5 89.062 (90.213)
[epoch:87, iter:67453] Loss: 1.398, 10.358, 66.024, 433.241, 1.279
[epoch:87, iter:67473] Loss: 1.399, 10.366, 65.994, 433.028, 1.446
[epoch:87, iter:67493] Loss: 1.399, 10.367, 65.991, 432.979, 1.160
[epoch:87, iter:67513] Loss: 1.401, 10.372, 66.040, 433.209, 1.386
[epoch:87, iter:67533] Loss: 1.403, 10.380, 66.060, 433.418, 1.289
Epoch: [86][300/782]	Time 0.067 (0.076)	Data 0.002 (0.004)	Loss 13.2763 (13.5265)	Acc@1 67.188 (63.071)	Acc@5 96.875 (89.914)
[epoch:87, iter:67553] Loss: 1.404, 10.384, 66.039, 433.644, 1.001
[epoch:87, iter:67573] Loss: 1.404, 10.387, 66.037, 433.827, 1.278
[epoch:87, iter:67593] Loss: 1.404, 10.393, 66.038, 434.004, 1.038
[epoch:87, iter:67613] Loss: 1.404, 10.396, 66.052, 434.239, 1.021
[epoch:87, iter:67633] Loss: 1.404, 10.394, 65.993, 434.166, 1.255
Epoch: [86][400/782]	Time 0.082 (0.077)	Data 0.003 (0.003)	Loss 13.4369 (13.5575)	Acc@1 60.938 (62.749)	Acc@5 93.750 (89.737)
[epoch:87, iter:67653] Loss: 1.404, 10.396, 65.971, 434.124, 1.365
[epoch:87, iter:67673] Loss: 1.404, 10.400, 66.031, 434.311, 1.241
[epoch:87, iter:67693] Loss: 1.403, 10.398, 66.046, 434.314, 0.982
[epoch:87, iter:67713] Loss: 1.404, 10.400, 66.056, 434.455, 1.143
[epoch:87, iter:67733] Loss: 1.404, 10.400, 66.074, 434.502, 1.218
Epoch: [86][500/782]	Time 0.089 (0.077)	Data 0.003 (0.003)	Loss 13.9843 (13.5996)	Acc@1 70.312 (62.603)	Acc@5 90.625 (89.549)
[epoch:87, iter:67753] Loss: 1.404, 10.402, 66.092, 434.553, 1.212
[epoch:87, iter:67773] Loss: 1.405, 10.403, 66.130, 434.646, 1.420
[epoch:87, iter:67793] Loss: 1.405, 10.411, 66.171, 434.775, 1.659
[epoch:87, iter:67813] Loss: 1.406, 10.411, 66.179, 434.832, 1.523
[epoch:87, iter:67833] Loss: 1.407, 10.414, 66.192, 434.901, 1.270
Epoch: [86][600/782]	Time 0.083 (0.078)	Data 0.003 (0.003)	Loss 14.4981 (13.6384)	Acc@1 57.812 (62.542)	Acc@5 89.062 (89.582)
[epoch:87, iter:67853] Loss: 1.407, 10.414, 66.216, 434.912, 1.537
[epoch:87, iter:67873] Loss: 1.408, 10.416, 66.268, 435.017, 1.123
[epoch:87, iter:67893] Loss: 1.408, 10.417, 66.241, 434.965, 1.131
[epoch:87, iter:67913] Loss: 1.408, 10.415, 66.211, 434.975, 1.346
[epoch:87, iter:67933] Loss: 1.408, 10.411, 66.199, 434.888, 1.229
Epoch: [86][700/782]	Time 0.087 (0.078)	Data 0.003 (0.003)	Loss 14.6470 (13.6394)	Acc@1 60.938 (62.502)	Acc@5 89.062 (89.495)
[epoch:87, iter:67953] Loss: 1.407, 10.412, 66.200, 434.937, 1.486
[epoch:87, iter:67973] Loss: 1.407, 10.411, 66.214, 434.965, 2.176
[epoch:87, iter:67993] Loss: 1.408, 10.411, 66.222, 434.993, 1.545
[epoch:87, iter:68013] Loss: 1.407, 10.406, 66.203, 434.873, 0.970
[epoch:87, iter:68033] Loss: 1.407, 10.403, 66.195, 434.778, 1.129
 * Acc@1 62.528 Acc@5 89.516
epoch 86, total time 60.83
Test: [0/313]	Time 0.277 (0.277)	Loss 2.2678 (2.2678)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.9956 (1.9023)	Acc@1 50.000 (56.436)	Acc@5 81.250 (84.715)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5210 (1.8995)	Acc@1 65.625 (56.063)	Acc@5 87.500 (84.499)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.4353 (1.8970)	Acc@1 43.750 (56.219)	Acc@5 84.375 (84.302)
 * Acc@1 56.340 Acc@5 84.390
==> training...
Epoch: [87][0/782]	Time 0.500 (0.500)	Data 0.434 (0.434)	Loss 13.8789 (13.8789)	Acc@1 62.500 (62.500)	Acc@5 93.750 (93.750)
[epoch:88, iter:68035] Loss: 1.417, 10.385, 67.790, 445.563, 1.218
[epoch:88, iter:68055] Loss: 1.387, 10.375, 66.427, 435.315, 1.237
[epoch:88, iter:68075] Loss: 1.392, 10.347, 66.344, 434.845, 1.511
[epoch:88, iter:68095] Loss: 1.405, 10.391, 66.843, 436.842, 1.287
[epoch:88, iter:68115] Loss: 1.403, 10.394, 66.512, 435.765, 1.098
Epoch: [87][100/782]	Time 0.083 (0.083)	Data 0.002 (0.006)	Loss 13.3261 (13.6016)	Acc@1 60.938 (63.830)	Acc@5 87.500 (88.830)
[epoch:88, iter:68135] Loss: 1.397, 10.393, 66.296, 435.223, 1.483
[epoch:88, iter:68155] Loss: 1.395, 10.402, 66.353, 435.215, 1.418
[epoch:88, iter:68175] Loss: 1.395, 10.387, 66.292, 434.873, 1.262
[epoch:88, iter:68195] Loss: 1.394, 10.379, 66.243, 434.529, 1.658
[epoch:88, iter:68215] Loss: 1.395, 10.373, 66.297, 434.481, 1.192
Epoch: [87][200/782]	Time 0.077 (0.082)	Data 0.002 (0.004)	Loss 13.3489 (13.5350)	Acc@1 68.750 (63.619)	Acc@5 93.750 (89.513)
[epoch:88, iter:68235] Loss: 1.394, 10.372, 66.294, 434.507, 1.012
[epoch:88, iter:68255] Loss: 1.394, 10.369, 66.155, 433.975, 1.181
[epoch:88, iter:68275] Loss: 1.395, 10.365, 66.135, 434.041, 1.560
[epoch:88, iter:68295] Loss: 1.397, 10.367, 66.129, 433.958, 1.251
[epoch:88, iter:68315] Loss: 1.397, 10.373, 66.151, 434.149, 1.364
Epoch: [87][300/782]	Time 0.069 (0.081)	Data 0.002 (0.004)	Loss 14.5380 (13.5192)	Acc@1 53.125 (63.346)	Acc@5 84.375 (89.649)
[epoch:88, iter:68335] Loss: 1.397, 10.377, 66.123, 434.120, 1.775
[epoch:88, iter:68355] Loss: 1.399, 10.386, 66.186, 434.400, 1.535
[epoch:88, iter:68375] Loss: 1.400, 10.392, 66.185, 434.383, 1.204
[epoch:88, iter:68395] Loss: 1.400, 10.395, 66.160, 434.365, 1.196
[epoch:88, iter:68415] Loss: 1.399, 10.387, 66.184, 434.570, 1.529
Epoch: [87][400/782]	Time 0.081 (0.080)	Data 0.002 (0.003)	Loss 14.2867 (13.5724)	Acc@1 62.500 (63.014)	Acc@5 87.500 (89.464)
[epoch:88, iter:68435] Loss: 1.401, 10.388, 66.216, 434.954, 1.622
[epoch:88, iter:68455] Loss: 1.401, 10.396, 66.244, 435.096, 1.751
[epoch:88, iter:68475] Loss: 1.401, 10.402, 66.256, 435.145, 1.601
[epoch:88, iter:68495] Loss: 1.402, 10.402, 66.305, 435.209, 1.822
[epoch:88, iter:68515] Loss: 1.402, 10.411, 66.281, 435.229, 1.795
Epoch: [87][500/782]	Time 0.092 (0.078)	Data 0.003 (0.003)	Loss 12.7141 (13.6051)	Acc@1 64.062 (62.650)	Acc@5 90.625 (89.406)
[epoch:88, iter:68535] Loss: 1.402, 10.413, 66.289, 435.222, 1.358
[epoch:88, iter:68555] Loss: 1.402, 10.411, 66.271, 435.195, 1.107
[epoch:88, iter:68575] Loss: 1.401, 10.409, 66.236, 435.076, 1.168
[epoch:88, iter:68595] Loss: 1.401, 10.409, 66.228, 435.051, 1.597
[epoch:88, iter:68615] Loss: 1.402, 10.406, 66.219, 435.055, 1.595
Epoch: [87][600/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 12.4306 (13.5794)	Acc@1 76.562 (62.950)	Acc@5 96.875 (89.452)
[epoch:88, iter:68635] Loss: 1.402, 10.402, 66.183, 434.877, 0.879
[epoch:88, iter:68655] Loss: 1.402, 10.405, 66.166, 434.848, 1.382
[epoch:88, iter:68675] Loss: 1.401, 10.404, 66.140, 434.798, 1.674
[epoch:88, iter:68695] Loss: 1.401, 10.404, 66.159, 434.870, 1.311
[epoch:88, iter:68715] Loss: 1.401, 10.404, 66.169, 434.809, 1.293
Epoch: [87][700/782]	Time 0.079 (0.078)	Data 0.002 (0.003)	Loss 13.1101 (13.5775)	Acc@1 59.375 (62.952)	Acc@5 95.312 (89.560)
[epoch:88, iter:68735] Loss: 1.401, 10.408, 66.161, 434.794, 1.249
[epoch:88, iter:68755] Loss: 1.402, 10.411, 66.183, 434.901, 1.319
[epoch:88, iter:68775] Loss: 1.402, 10.408, 66.188, 434.895, 1.298
[epoch:88, iter:68795] Loss: 1.402, 10.408, 66.187, 434.947, 1.694
[epoch:88, iter:68815] Loss: 1.402, 10.408, 66.182, 434.978, 0.995
 * Acc@1 62.852 Acc@5 89.508
epoch 87, total time 60.56
Test: [0/313]	Time 0.250 (0.250)	Loss 2.0504 (2.0504)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.010)	Loss 2.1356 (1.8635)	Acc@1 53.125 (56.281)	Acc@5 87.500 (85.179)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5076 (1.8683)	Acc@1 65.625 (56.234)	Acc@5 90.625 (85.012)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.8294 (1.8667)	Acc@1 59.375 (56.115)	Acc@5 90.625 (85.019)
 * Acc@1 56.230 Acc@5 85.090
==> training...
Epoch: [88][0/782]	Time 0.552 (0.552)	Data 0.470 (0.470)	Loss 13.5612 (13.5612)	Acc@1 73.438 (73.438)	Acc@5 90.625 (90.625)
[epoch:89, iter:68817] Loss: 1.363, 10.641, 68.703, 440.916, 1.133
[epoch:89, iter:68837] Loss: 1.399, 10.307, 67.166, 433.609, 0.943
[epoch:89, iter:68857] Loss: 1.394, 10.322, 66.484, 433.793, 1.178
[epoch:89, iter:68877] Loss: 1.399, 10.355, 66.485, 434.511, 1.618
[epoch:89, iter:68897] Loss: 1.400, 10.398, 66.520, 434.308, 1.681
Epoch: [88][100/782]	Time 0.066 (0.080)	Data 0.002 (0.007)	Loss 13.6721 (13.4732)	Acc@1 70.312 (63.691)	Acc@5 90.625 (90.269)
[epoch:89, iter:68917] Loss: 1.402, 10.404, 66.400, 434.430, 1.165
[epoch:89, iter:68937] Loss: 1.401, 10.407, 66.411, 435.005, 1.099
[epoch:89, iter:68957] Loss: 1.402, 10.390, 66.316, 434.663, 0.935
[epoch:89, iter:68977] Loss: 1.400, 10.393, 66.226, 434.514, 1.057
[epoch:89, iter:68997] Loss: 1.400, 10.391, 66.206, 434.759, 1.215
Epoch: [88][200/782]	Time 0.090 (0.076)	Data 0.003 (0.005)	Loss 12.8364 (13.5323)	Acc@1 64.062 (63.332)	Acc@5 95.312 (90.081)
[epoch:89, iter:69017] Loss: 1.401, 10.389, 66.169, 434.635, 0.984
[epoch:89, iter:69037] Loss: 1.405, 10.398, 66.223, 434.884, 1.712
[epoch:89, iter:69057] Loss: 1.405, 10.396, 66.251, 434.892, 1.184
[epoch:89, iter:69077] Loss: 1.404, 10.391, 66.203, 434.896, 1.113
[epoch:89, iter:69097] Loss: 1.405, 10.389, 66.236, 435.098, 1.033
Epoch: [88][300/782]	Time 0.091 (0.077)	Data 0.003 (0.004)	Loss 13.7984 (13.5754)	Acc@1 57.812 (63.024)	Acc@5 90.625 (89.815)
[epoch:89, iter:69117] Loss: 1.405, 10.388, 66.226, 435.082, 1.176
[epoch:89, iter:69137] Loss: 1.403, 10.394, 66.224, 435.299, 0.945
[epoch:89, iter:69157] Loss: 1.403, 10.382, 66.190, 435.204, 1.533
[epoch:89, iter:69177] Loss: 1.402, 10.382, 66.143, 435.119, 1.586
[epoch:89, iter:69197] Loss: 1.403, 10.379, 66.174, 435.192, 1.033
Epoch: [88][400/782]	Time 0.084 (0.078)	Data 0.003 (0.003)	Loss 14.6956 (13.6081)	Acc@1 59.375 (62.858)	Acc@5 84.375 (89.589)
[epoch:89, iter:69217] Loss: 1.403, 10.384, 66.221, 435.404, 1.830
[epoch:89, iter:69237] Loss: 1.403, 10.390, 66.226, 435.471, 1.364
[epoch:89, iter:69257] Loss: 1.405, 10.388, 66.251, 435.590, 1.101
[epoch:89, iter:69277] Loss: 1.405, 10.390, 66.274, 435.548, 1.390
[epoch:89, iter:69297] Loss: 1.406, 10.392, 66.305, 435.597, 1.860
Epoch: [88][500/782]	Time 0.084 (0.079)	Data 0.003 (0.003)	Loss 13.7299 (13.6335)	Acc@1 57.812 (62.778)	Acc@5 93.750 (89.434)
[epoch:89, iter:69317] Loss: 1.406, 10.394, 66.353, 435.638, 1.434
[epoch:89, iter:69337] Loss: 1.406, 10.393, 66.361, 435.673, 1.585
[epoch:89, iter:69357] Loss: 1.406, 10.391, 66.343, 435.580, 1.409
[epoch:89, iter:69377] Loss: 1.408, 10.393, 66.334, 435.609, 1.307
[epoch:89, iter:69397] Loss: 1.409, 10.394, 66.370, 435.642, 1.408
Epoch: [88][600/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.5860 (13.6458)	Acc@1 78.125 (62.742)	Acc@5 89.062 (89.421)
[epoch:89, iter:69417] Loss: 1.409, 10.397, 66.407, 435.689, 0.914
[epoch:89, iter:69437] Loss: 1.408, 10.401, 66.414, 435.628, 1.025
[epoch:89, iter:69457] Loss: 1.408, 10.398, 66.400, 435.494, 1.200
[epoch:89, iter:69477] Loss: 1.408, 10.395, 66.370, 435.385, 1.278
[epoch:89, iter:69497] Loss: 1.408, 10.396, 66.375, 435.455, 1.593
Epoch: [88][700/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.8526 (13.6466)	Acc@1 64.062 (62.620)	Acc@5 90.625 (89.412)
[epoch:89, iter:69517] Loss: 1.409, 10.396, 66.409, 435.527, 1.264
[epoch:89, iter:69537] Loss: 1.409, 10.397, 66.395, 435.443, 1.465
[epoch:89, iter:69557] Loss: 1.409, 10.398, 66.371, 435.381, 1.460
[epoch:89, iter:69577] Loss: 1.409, 10.397, 66.363, 435.364, 1.269
[epoch:89, iter:69597] Loss: 1.409, 10.402, 66.355, 435.333, 1.268
 * Acc@1 62.532 Acc@5 89.396
epoch 88, total time 60.93
Test: [0/313]	Time 0.262 (0.262)	Loss 2.2299 (2.2299)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9967 (2.5177)	Acc@1 37.500 (49.969)	Acc@5 78.125 (80.136)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7394 (2.5160)	Acc@1 56.250 (49.984)	Acc@5 84.375 (80.068)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.2872 (2.5273)	Acc@1 50.000 (50.488)	Acc@5 78.125 (80.004)
 * Acc@1 50.560 Acc@5 80.020
==> training...
Epoch: [89][0/782]	Time 0.569 (0.569)	Data 0.481 (0.481)	Loss 12.9432 (12.9432)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
[epoch:90, iter:69599] Loss: 1.472, 10.292, 67.943, 428.274, 0.875
[epoch:90, iter:69619] Loss: 1.402, 10.494, 66.265, 433.322, 1.348
[epoch:90, iter:69639] Loss: 1.396, 10.439, 66.112, 433.715, 0.836
[epoch:90, iter:69659] Loss: 1.399, 10.404, 66.216, 433.953, 1.333
[epoch:90, iter:69679] Loss: 1.398, 10.406, 66.180, 434.136, 1.572
Epoch: [89][100/782]	Time 0.088 (0.079)	Data 0.003 (0.007)	Loss 13.8064 (13.5084)	Acc@1 64.062 (63.738)	Acc@5 92.188 (89.728)
[epoch:90, iter:69699] Loss: 1.397, 10.394, 66.204, 434.083, 1.456
[epoch:90, iter:69719] Loss: 1.396, 10.432, 66.341, 434.537, 1.080
[epoch:90, iter:69739] Loss: 1.398, 10.425, 66.306, 434.477, 1.607
[epoch:90, iter:69759] Loss: 1.398, 10.427, 66.268, 434.611, 1.174
[epoch:90, iter:69779] Loss: 1.399, 10.419, 66.265, 434.628, 1.766
Epoch: [89][200/782]	Time 0.077 (0.079)	Data 0.003 (0.005)	Loss 12.9617 (13.5683)	Acc@1 62.500 (63.371)	Acc@5 89.062 (89.723)
[epoch:90, iter:69799] Loss: 1.400, 10.426, 66.321, 434.621, 1.334
[epoch:90, iter:69819] Loss: 1.404, 10.430, 66.358, 434.871, 1.451
[epoch:90, iter:69839] Loss: 1.404, 10.417, 66.316, 434.727, 1.364
[epoch:90, iter:69859] Loss: 1.405, 10.423, 66.324, 434.867, 1.067
[epoch:90, iter:69879] Loss: 1.405, 10.411, 66.332, 434.860, 0.985
Epoch: [89][300/782]	Time 0.089 (0.079)	Data 0.003 (0.004)	Loss 13.0883 (13.5951)	Acc@1 65.625 (62.967)	Acc@5 93.750 (89.763)
[epoch:90, iter:69899] Loss: 1.404, 10.410, 66.313, 434.899, 1.128
[epoch:90, iter:69919] Loss: 1.404, 10.403, 66.265, 434.600, 1.428
[epoch:90, iter:69939] Loss: 1.402, 10.398, 66.205, 434.505, 1.723
[epoch:90, iter:69959] Loss: 1.400, 10.403, 66.189, 434.478, 1.524
[epoch:90, iter:69979] Loss: 1.400, 10.396, 66.225, 434.645, 1.396
Epoch: [89][400/782]	Time 0.073 (0.079)	Data 0.002 (0.004)	Loss 13.4631 (13.5874)	Acc@1 56.250 (62.831)	Acc@5 85.938 (89.740)
[epoch:90, iter:69999] Loss: 1.401, 10.395, 66.243, 434.615, 1.592
[epoch:90, iter:70019] Loss: 1.402, 10.393, 66.277, 434.714, 1.630
[epoch:90, iter:70039] Loss: 1.401, 10.391, 66.268, 434.628, 1.239
[epoch:90, iter:70059] Loss: 1.402, 10.389, 66.257, 434.592, 1.269
[epoch:90, iter:70079] Loss: 1.402, 10.386, 66.236, 434.566, 1.276
Epoch: [89][500/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 13.6930 (13.5755)	Acc@1 56.250 (62.999)	Acc@5 84.375 (89.876)
[epoch:90, iter:70099] Loss: 1.401, 10.382, 66.217, 434.474, 1.407
[epoch:90, iter:70119] Loss: 1.401, 10.379, 66.218, 434.457, 1.527
[epoch:90, iter:70139] Loss: 1.401, 10.378, 66.214, 434.573, 2.152
[epoch:90, iter:70159] Loss: 1.401, 10.374, 66.254, 434.631, 1.537
[epoch:90, iter:70179] Loss: 1.401, 10.374, 66.297, 434.761, 1.459
Epoch: [89][600/782]	Time 0.076 (0.077)	Data 0.002 (0.003)	Loss 13.5502 (13.6048)	Acc@1 65.625 (62.877)	Acc@5 93.750 (89.741)
[epoch:90, iter:70199] Loss: 1.402, 10.377, 66.345, 434.867, 1.168
[epoch:90, iter:70219] Loss: 1.403, 10.381, 66.359, 434.893, 1.717
[epoch:90, iter:70239] Loss: 1.403, 10.382, 66.385, 434.909, 1.723
[epoch:90, iter:70259] Loss: 1.403, 10.387, 66.407, 434.990, 1.528
[epoch:90, iter:70279] Loss: 1.403, 10.388, 66.410, 434.962, 1.761
Epoch: [89][700/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 14.1305 (13.6262)	Acc@1 60.938 (62.672)	Acc@5 84.375 (89.586)
[epoch:90, iter:70299] Loss: 1.404, 10.394, 66.420, 435.022, 1.567
[epoch:90, iter:70319] Loss: 1.404, 10.395, 66.411, 435.033, 1.232
[epoch:90, iter:70339] Loss: 1.405, 10.400, 66.431, 435.197, 2.501
[epoch:90, iter:70359] Loss: 1.405, 10.401, 66.423, 435.295, 1.878
[epoch:90, iter:70379] Loss: 1.405, 10.401, 66.419, 435.355, 1.337
 * Acc@1 62.494 Acc@5 89.470
epoch 89, total time 59.53
Test: [0/313]	Time 0.238 (0.238)	Loss 2.1219 (2.1219)	Acc@1 53.125 (53.125)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.8651 (2.7399)	Acc@1 53.125 (46.875)	Acc@5 71.875 (77.135)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8573 (2.6812)	Acc@1 50.000 (46.828)	Acc@5 87.500 (77.379)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.0117 (2.6788)	Acc@1 43.750 (47.249)	Acc@5 75.000 (77.326)
 * Acc@1 47.210 Acc@5 77.530
==> training...
Epoch: [90][0/782]	Time 0.519 (0.519)	Data 0.432 (0.432)	Loss 14.0121 (14.0121)	Acc@1 57.812 (57.812)	Acc@5 89.062 (89.062)
[epoch:91, iter:70381] Loss: 1.451, 10.410, 67.153, 432.196, 1.561
[epoch:91, iter:70401] Loss: 1.434, 10.563, 66.806, 432.541, 1.163
[epoch:91, iter:70421] Loss: 1.413, 10.409, 66.185, 432.016, 1.132
[epoch:91, iter:70441] Loss: 1.406, 10.407, 66.020, 432.518, 1.515
[epoch:91, iter:70461] Loss: 1.399, 10.357, 65.932, 432.317, 1.411
Epoch: [90][100/782]	Time 0.075 (0.081)	Data 0.002 (0.007)	Loss 13.9076 (13.3819)	Acc@1 57.812 (63.645)	Acc@5 84.375 (89.790)
[epoch:91, iter:70481] Loss: 1.396, 10.356, 65.979, 432.394, 1.580
[epoch:91, iter:70501] Loss: 1.399, 10.374, 66.133, 432.787, 1.398
[epoch:91, iter:70521] Loss: 1.394, 10.370, 66.003, 432.417, 1.777
[epoch:91, iter:70541] Loss: 1.394, 10.381, 65.962, 432.593, 1.278
[epoch:91, iter:70561] Loss: 1.396, 10.394, 65.973, 432.718, 1.083
Epoch: [90][200/782]	Time 0.070 (0.080)	Data 0.002 (0.005)	Loss 14.3711 (13.4694)	Acc@1 68.750 (63.067)	Acc@5 87.500 (89.817)
[epoch:91, iter:70581] Loss: 1.398, 10.399, 66.097, 433.217, 1.434
[epoch:91, iter:70601] Loss: 1.400, 10.400, 66.066, 433.213, 1.100
[epoch:91, iter:70621] Loss: 1.400, 10.406, 66.066, 433.385, 1.017
[epoch:91, iter:70641] Loss: 1.400, 10.402, 66.051, 433.503, 1.286
[epoch:91, iter:70661] Loss: 1.400, 10.397, 65.994, 433.333, 1.264
Epoch: [90][300/782]	Time 0.070 (0.079)	Data 0.002 (0.004)	Loss 12.3665 (13.4945)	Acc@1 70.312 (62.946)	Acc@5 95.312 (89.753)
[epoch:91, iter:70681] Loss: 1.398, 10.400, 66.033, 433.582, 0.895
[epoch:91, iter:70701] Loss: 1.400, 10.407, 66.016, 433.599, 1.351
[epoch:91, iter:70721] Loss: 1.400, 10.406, 66.013, 433.619, 1.318
[epoch:91, iter:70741] Loss: 1.399, 10.397, 65.920, 433.473, 0.805
[epoch:91, iter:70761] Loss: 1.399, 10.394, 65.936, 433.542, 1.230
Epoch: [90][400/782]	Time 0.071 (0.076)	Data 0.002 (0.003)	Loss 13.6021 (13.5136)	Acc@1 64.062 (62.855)	Acc@5 93.750 (89.725)
[epoch:91, iter:70781] Loss: 1.398, 10.394, 65.915, 433.583, 1.442
[epoch:91, iter:70801] Loss: 1.400, 10.391, 65.932, 433.562, 1.891
[epoch:91, iter:70821] Loss: 1.400, 10.390, 65.922, 433.595, 1.150
[epoch:91, iter:70841] Loss: 1.400, 10.390, 65.921, 433.730, 1.581
[epoch:91, iter:70861] Loss: 1.401, 10.397, 65.953, 433.782, 1.225
Epoch: [90][500/782]	Time 0.076 (0.076)	Data 0.002 (0.003)	Loss 13.5783 (13.5329)	Acc@1 71.875 (62.987)	Acc@5 92.188 (89.680)
[epoch:91, iter:70881] Loss: 1.402, 10.399, 65.963, 433.763, 1.215
[epoch:91, iter:70901] Loss: 1.404, 10.400, 65.973, 433.823, 1.167
[epoch:91, iter:70921] Loss: 1.404, 10.403, 66.004, 433.934, 1.366
[epoch:91, iter:70941] Loss: 1.405, 10.408, 66.069, 434.135, 0.980
[epoch:91, iter:70961] Loss: 1.406, 10.409, 66.056, 434.127, 1.066
Epoch: [90][600/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 14.2492 (13.5573)	Acc@1 54.688 (62.947)	Acc@5 85.938 (89.621)
[epoch:91, iter:70981] Loss: 1.406, 10.412, 66.049, 434.216, 1.718
[epoch:91, iter:71001] Loss: 1.406, 10.411, 66.064, 434.292, 1.270
[epoch:91, iter:71021] Loss: 1.406, 10.414, 66.081, 434.446, 1.412
[epoch:91, iter:71041] Loss: 1.407, 10.420, 66.118, 434.535, 1.039
[epoch:91, iter:71061] Loss: 1.408, 10.419, 66.155, 434.661, 1.756
Epoch: [90][700/782]	Time 0.090 (0.077)	Data 0.003 (0.003)	Loss 12.9983 (13.5863)	Acc@1 68.750 (62.763)	Acc@5 89.062 (89.515)
[epoch:91, iter:71081] Loss: 1.408, 10.418, 66.157, 434.614, 1.238
[epoch:91, iter:71101] Loss: 1.408, 10.418, 66.169, 434.621, 1.199
[epoch:91, iter:71121] Loss: 1.407, 10.419, 66.170, 434.724, 1.194
[epoch:91, iter:71141] Loss: 1.408, 10.419, 66.169, 434.708, 1.258
[epoch:91, iter:71161] Loss: 1.408, 10.418, 66.156, 434.684, 1.768
 * Acc@1 62.790 Acc@5 89.476
epoch 90, total time 60.18
Test: [0/313]	Time 0.248 (0.248)	Loss 2.7464 (2.7464)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.1408 (2.2729)	Acc@1 46.875 (50.990)	Acc@5 81.250 (81.312)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.8437 (2.3078)	Acc@1 56.250 (51.166)	Acc@5 87.500 (80.286)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.7952 (2.3108)	Acc@1 53.125 (51.391)	Acc@5 87.500 (80.025)
 * Acc@1 51.350 Acc@5 80.040
==> training...
Epoch: [91][0/782]	Time 0.561 (0.561)	Data 0.491 (0.491)	Loss 13.7961 (13.7961)	Acc@1 68.750 (68.750)	Acc@5 89.062 (89.062)
[epoch:92, iter:71163] Loss: 1.377, 10.457, 68.106, 445.795, 1.258
[epoch:92, iter:71183] Loss: 1.434, 10.730, 67.568, 443.030, 1.614
[epoch:92, iter:71203] Loss: 1.413, 10.601, 66.908, 438.622, 1.320
[epoch:92, iter:71223] Loss: 1.405, 10.491, 66.388, 436.145, 1.966
[epoch:92, iter:71243] Loss: 1.400, 10.440, 66.152, 435.366, 1.357
Epoch: [91][100/782]	Time 0.088 (0.084)	Data 0.003 (0.007)	Loss 13.0473 (13.6048)	Acc@1 62.500 (62.809)	Acc@5 87.500 (89.480)
[epoch:92, iter:71263] Loss: 1.402, 10.415, 65.966, 434.794, 1.250
[epoch:92, iter:71283] Loss: 1.406, 10.420, 65.921, 434.559, 1.419
[epoch:92, iter:71303] Loss: 1.403, 10.417, 65.899, 434.142, 1.098
[epoch:92, iter:71323] Loss: 1.401, 10.389, 65.845, 433.555, 1.406
[epoch:92, iter:71343] Loss: 1.401, 10.372, 65.867, 433.115, 1.160
Epoch: [91][200/782]	Time 0.081 (0.083)	Data 0.003 (0.005)	Loss 13.9513 (13.5235)	Acc@1 64.062 (62.586)	Acc@5 89.062 (89.653)
[epoch:92, iter:71363] Loss: 1.400, 10.383, 66.044, 433.397, 1.374
[epoch:92, iter:71383] Loss: 1.398, 10.387, 66.030, 433.370, 1.491
[epoch:92, iter:71403] Loss: 1.397, 10.390, 66.009, 433.397, 1.384
[epoch:92, iter:71423] Loss: 1.394, 10.388, 65.959, 433.389, 1.394
[epoch:92, iter:71443] Loss: 1.394, 10.392, 65.992, 433.515, 1.072
Epoch: [91][300/782]	Time 0.083 (0.081)	Data 0.003 (0.004)	Loss 15.5932 (13.5186)	Acc@1 39.062 (62.811)	Acc@5 87.500 (89.768)
[epoch:92, iter:71463] Loss: 1.393, 10.384, 66.024, 433.493, 2.065
[epoch:92, iter:71483] Loss: 1.394, 10.382, 66.051, 433.688, 1.163
[epoch:92, iter:71503] Loss: 1.396, 10.382, 66.045, 433.807, 1.473
[epoch:92, iter:71523] Loss: 1.396, 10.381, 66.025, 433.747, 1.273
[epoch:92, iter:71543] Loss: 1.399, 10.387, 66.090, 433.970, 1.194
Epoch: [91][400/782]	Time 0.073 (0.080)	Data 0.002 (0.004)	Loss 12.8944 (13.5631)	Acc@1 76.562 (62.714)	Acc@5 90.625 (89.600)
[epoch:92, iter:71563] Loss: 1.400, 10.395, 66.089, 434.048, 1.028
[epoch:92, iter:71583] Loss: 1.401, 10.402, 66.146, 434.266, 1.265
[epoch:92, iter:71603] Loss: 1.402, 10.407, 66.175, 434.444, 1.356
[epoch:92, iter:71623] Loss: 1.404, 10.415, 66.247, 434.727, 1.828
[epoch:92, iter:71643] Loss: 1.404, 10.416, 66.285, 434.758, 1.408
Epoch: [91][500/782]	Time 0.063 (0.079)	Data 0.002 (0.003)	Loss 12.7177 (13.6076)	Acc@1 71.875 (62.718)	Acc@5 93.750 (89.530)
[epoch:92, iter:71663] Loss: 1.403, 10.411, 66.278, 434.723, 1.036
[epoch:92, iter:71683] Loss: 1.404, 10.413, 66.248, 434.732, 1.292
[epoch:92, iter:71703] Loss: 1.404, 10.414, 66.267, 434.761, 1.217
[epoch:92, iter:71723] Loss: 1.404, 10.413, 66.278, 434.713, 1.440
[epoch:92, iter:71743] Loss: 1.404, 10.415, 66.303, 434.690, 1.201
Epoch: [91][600/782]	Time 0.075 (0.078)	Data 0.002 (0.003)	Loss 13.4063 (13.6226)	Acc@1 65.625 (62.638)	Acc@5 87.500 (89.450)
[epoch:92, iter:71763] Loss: 1.404, 10.412, 66.352, 434.719, 1.389
[epoch:92, iter:71783] Loss: 1.405, 10.415, 66.360, 434.767, 1.276
[epoch:92, iter:71803] Loss: 1.406, 10.421, 66.404, 434.882, 1.146
[epoch:92, iter:71823] Loss: 1.407, 10.422, 66.417, 434.880, 1.060
[epoch:92, iter:71843] Loss: 1.407, 10.422, 66.408, 434.860, 1.275
Epoch: [91][700/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.7055 (13.6270)	Acc@1 64.062 (62.652)	Acc@5 90.625 (89.448)
[epoch:92, iter:71863] Loss: 1.406, 10.424, 66.405, 434.852, 1.355
[epoch:92, iter:71883] Loss: 1.407, 10.424, 66.408, 434.873, 1.740
[epoch:92, iter:71903] Loss: 1.407, 10.423, 66.432, 434.925, 1.182
[epoch:92, iter:71923] Loss: 1.407, 10.421, 66.398, 434.848, 1.285
[epoch:92, iter:71943] Loss: 1.407, 10.421, 66.392, 434.794, 1.188
 * Acc@1 62.758 Acc@5 89.474
epoch 91, total time 60.91
Test: [0/313]	Time 0.249 (0.249)	Loss 2.2755 (2.2755)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.7406 (2.1059)	Acc@1 46.875 (53.094)	Acc@5 96.875 (84.004)
Test: [200/313]	Time 0.005 (0.007)	Loss 1.3747 (2.1465)	Acc@1 62.500 (52.799)	Acc@5 90.625 (83.660)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3973 (2.1476)	Acc@1 43.750 (52.814)	Acc@5 78.125 (83.420)
 * Acc@1 52.790 Acc@5 83.390
==> training...
Epoch: [92][0/782]	Time 0.594 (0.594)	Data 0.515 (0.515)	Loss 13.2609 (13.2609)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
[epoch:93, iter:71945] Loss: 1.400, 10.472, 66.082, 432.395, 1.284
[epoch:93, iter:71965] Loss: 1.394, 10.349, 65.546, 434.381, 1.259
[epoch:93, iter:71985] Loss: 1.401, 10.372, 65.451, 434.049, 1.392
[epoch:93, iter:72005] Loss: 1.402, 10.386, 65.422, 433.850, 1.228
[epoch:93, iter:72025] Loss: 1.396, 10.383, 65.394, 433.585, 1.289
Epoch: [92][100/782]	Time 0.074 (0.083)	Data 0.002 (0.007)	Loss 13.4190 (13.4561)	Acc@1 59.375 (62.902)	Acc@5 90.625 (89.728)
[epoch:93, iter:72045] Loss: 1.396, 10.394, 65.560, 433.391, 1.301
[epoch:93, iter:72065] Loss: 1.395, 10.392, 65.443, 432.769, 1.256
[epoch:93, iter:72085] Loss: 1.398, 10.401, 65.448, 433.028, 1.421
[epoch:93, iter:72105] Loss: 1.397, 10.375, 65.613, 433.360, 1.179
[epoch:93, iter:72125] Loss: 1.394, 10.358, 65.606, 433.090, 1.198
Epoch: [92][200/782]	Time 0.084 (0.080)	Data 0.003 (0.005)	Loss 13.8534 (13.4313)	Acc@1 62.500 (63.060)	Acc@5 89.062 (89.785)
[epoch:93, iter:72145] Loss: 1.394, 10.356, 65.620, 433.115, 1.374
[epoch:93, iter:72165] Loss: 1.392, 10.350, 65.558, 433.075, 1.430
[epoch:93, iter:72185] Loss: 1.394, 10.350, 65.564, 433.081, 1.865
[epoch:93, iter:72205] Loss: 1.397, 10.349, 65.594, 433.051, 1.173
[epoch:93, iter:72225] Loss: 1.400, 10.358, 65.653, 433.370, 0.988
Epoch: [92][300/782]	Time 0.079 (0.080)	Data 0.003 (0.004)	Loss 14.5120 (13.4774)	Acc@1 50.000 (63.294)	Acc@5 76.562 (89.722)
[epoch:93, iter:72245] Loss: 1.401, 10.364, 65.784, 433.710, 2.173
[epoch:93, iter:72265] Loss: 1.401, 10.364, 65.785, 433.715, 1.654
[epoch:93, iter:72285] Loss: 1.402, 10.370, 65.793, 433.913, 1.127
[epoch:93, iter:72305] Loss: 1.405, 10.383, 65.872, 434.156, 1.371
[epoch:93, iter:72325] Loss: 1.406, 10.386, 66.000, 434.259, 1.042
Epoch: [92][400/782]	Time 0.074 (0.077)	Data 0.002 (0.004)	Loss 14.9957 (13.5245)	Acc@1 59.375 (63.131)	Acc@5 78.125 (89.631)
[epoch:93, iter:72345] Loss: 1.405, 10.382, 65.988, 434.126, 2.012
[epoch:93, iter:72365] Loss: 1.406, 10.381, 66.049, 434.140, 1.717
[epoch:93, iter:72385] Loss: 1.406, 10.383, 66.044, 434.170, 1.166
[epoch:93, iter:72405] Loss: 1.406, 10.387, 66.032, 434.046, 1.221
[epoch:93, iter:72425] Loss: 1.406, 10.390, 66.043, 434.123, 1.428
Epoch: [92][500/782]	Time 0.077 (0.077)	Data 0.002 (0.003)	Loss 13.4036 (13.5463)	Acc@1 67.188 (63.121)	Acc@5 92.188 (89.593)
[epoch:93, iter:72445] Loss: 1.407, 10.387, 66.064, 434.161, 1.360
[epoch:93, iter:72465] Loss: 1.406, 10.389, 66.062, 434.231, 1.192
[epoch:93, iter:72485] Loss: 1.405, 10.390, 66.068, 434.263, 0.936
[epoch:93, iter:72505] Loss: 1.405, 10.390, 66.125, 434.321, 1.104
[epoch:93, iter:72525] Loss: 1.405, 10.392, 66.138, 434.304, 1.405
Epoch: [92][600/782]	Time 0.080 (0.077)	Data 0.003 (0.003)	Loss 13.2645 (13.5706)	Acc@1 56.250 (62.952)	Acc@5 89.062 (89.416)
[epoch:93, iter:72545] Loss: 1.405, 10.393, 66.122, 434.279, 1.480
[epoch:93, iter:72565] Loss: 1.405, 10.401, 66.138, 434.352, 1.416
[epoch:93, iter:72585] Loss: 1.404, 10.398, 66.153, 434.479, 1.249
[epoch:93, iter:72605] Loss: 1.404, 10.397, 66.148, 434.456, 0.895
[epoch:93, iter:72625] Loss: 1.405, 10.396, 66.135, 434.467, 1.660
Epoch: [92][700/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 14.0655 (13.5893)	Acc@1 62.500 (62.803)	Acc@5 87.500 (89.323)
[epoch:93, iter:72645] Loss: 1.405, 10.393, 66.152, 434.509, 1.375
[epoch:93, iter:72665] Loss: 1.405, 10.391, 66.176, 434.530, 1.652
[epoch:93, iter:72685] Loss: 1.405, 10.390, 66.165, 434.456, 1.513
[epoch:93, iter:72705] Loss: 1.405, 10.389, 66.135, 434.378, 1.395
[epoch:93, iter:72725] Loss: 1.405, 10.385, 66.117, 434.332, 1.286
 * Acc@1 62.820 Acc@5 89.364
epoch 92, total time 60.77
Test: [0/313]	Time 0.271 (0.271)	Loss 2.1397 (2.1397)	Acc@1 43.750 (43.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.010)	Loss 2.2537 (2.1156)	Acc@1 53.125 (53.744)	Acc@5 87.500 (83.137)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.2622 (2.1034)	Acc@1 68.750 (53.420)	Acc@5 90.625 (82.976)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.1936 (2.1230)	Acc@1 59.375 (53.364)	Acc@5 81.250 (82.714)
 * Acc@1 53.380 Acc@5 82.760
==> training...
Epoch: [93][0/782]	Time 0.487 (0.487)	Data 0.419 (0.419)	Loss 14.1948 (14.1948)	Acc@1 60.938 (60.938)	Acc@5 82.812 (82.812)
[epoch:94, iter:72727] Loss: 1.416, 11.045, 69.513, 434.749, 1.573
[epoch:94, iter:72747] Loss: 1.427, 10.459, 68.462, 437.581, 1.910
[epoch:94, iter:72767] Loss: 1.420, 10.436, 67.527, 436.003, 1.505
[epoch:94, iter:72787] Loss: 1.417, 10.449, 67.257, 435.379, 1.323
[epoch:94, iter:72807] Loss: 1.414, 10.442, 66.794, 434.411, 1.323
Epoch: [93][100/782]	Time 0.064 (0.077)	Data 0.002 (0.006)	Loss 13.5570 (13.5974)	Acc@1 59.375 (62.608)	Acc@5 90.625 (90.192)
[epoch:94, iter:72827] Loss: 1.411, 10.439, 66.745, 434.532, 1.423
[epoch:94, iter:72847] Loss: 1.409, 10.449, 66.675, 434.407, 1.285
[epoch:94, iter:72867] Loss: 1.409, 10.429, 66.691, 434.624, 1.561
[epoch:94, iter:72887] Loss: 1.408, 10.431, 66.644, 434.486, 1.816
[epoch:94, iter:72907] Loss: 1.406, 10.434, 66.555, 434.494, 1.168
Epoch: [93][200/782]	Time 0.077 (0.076)	Data 0.002 (0.004)	Loss 12.5798 (13.5739)	Acc@1 78.125 (63.231)	Acc@5 96.875 (89.949)
[epoch:94, iter:72927] Loss: 1.405, 10.436, 66.531, 434.649, 0.767
[epoch:94, iter:72947] Loss: 1.406, 10.439, 66.460, 434.594, 0.997
[epoch:94, iter:72967] Loss: 1.408, 10.436, 66.406, 434.470, 1.001
[epoch:94, iter:72987] Loss: 1.407, 10.432, 66.368, 434.381, 1.642
[epoch:94, iter:73007] Loss: 1.406, 10.427, 66.339, 434.371, 1.238
Epoch: [93][300/782]	Time 0.073 (0.078)	Data 0.002 (0.004)	Loss 13.9058 (13.5567)	Acc@1 65.625 (62.874)	Acc@5 87.500 (89.961)
[epoch:94, iter:73027] Loss: 1.406, 10.419, 66.331, 434.400, 1.396
[epoch:94, iter:73047] Loss: 1.406, 10.417, 66.278, 434.287, 1.438
[epoch:94, iter:73067] Loss: 1.404, 10.415, 66.251, 434.290, 1.961
[epoch:94, iter:73087] Loss: 1.405, 10.412, 66.227, 434.354, 1.378
[epoch:94, iter:73107] Loss: 1.405, 10.410, 66.184, 434.271, 1.079
Epoch: [93][400/782]	Time 0.083 (0.079)	Data 0.003 (0.003)	Loss 13.2287 (13.5494)	Acc@1 56.250 (62.878)	Acc@5 89.062 (89.772)
[epoch:94, iter:73127] Loss: 1.406, 10.412, 66.154, 434.312, 1.485
[epoch:94, iter:73147] Loss: 1.405, 10.407, 66.129, 434.243, 1.673
[epoch:94, iter:73167] Loss: 1.404, 10.402, 66.070, 434.013, 1.342
[epoch:94, iter:73187] Loss: 1.405, 10.400, 66.084, 434.131, 1.658
[epoch:94, iter:73207] Loss: 1.405, 10.395, 66.099, 434.130, 1.446
Epoch: [93][500/782]	Time 0.090 (0.079)	Data 0.003 (0.003)	Loss 13.6367 (13.5367)	Acc@1 70.312 (63.027)	Acc@5 96.875 (89.802)
[epoch:94, iter:73227] Loss: 1.405, 10.393, 66.117, 434.102, 1.099
[epoch:94, iter:73247] Loss: 1.405, 10.392, 66.128, 434.131, 1.081
[epoch:94, iter:73267] Loss: 1.404, 10.389, 66.090, 434.004, 1.205
[epoch:94, iter:73287] Loss: 1.404, 10.384, 66.098, 434.053, 1.614
[epoch:94, iter:73307] Loss: 1.403, 10.385, 66.076, 434.057, 1.641
Epoch: [93][600/782]	Time 0.091 (0.080)	Data 0.003 (0.003)	Loss 13.9101 (13.5395)	Acc@1 64.062 (62.973)	Acc@5 89.062 (89.738)
[epoch:94, iter:73327] Loss: 1.404, 10.382, 66.076, 434.038, 1.294
[epoch:94, iter:73347] Loss: 1.404, 10.384, 66.115, 434.144, 1.295
[epoch:94, iter:73367] Loss: 1.403, 10.379, 66.121, 434.142, 1.405
[epoch:94, iter:73387] Loss: 1.403, 10.383, 66.131, 434.211, 1.616
[epoch:94, iter:73407] Loss: 1.404, 10.381, 66.125, 434.174, 1.444
Epoch: [93][700/782]	Time 0.059 (0.079)	Data 0.002 (0.003)	Loss 13.4592 (13.5613)	Acc@1 46.875 (62.899)	Acc@5 85.938 (89.660)
[epoch:94, iter:73427] Loss: 1.405, 10.381, 66.145, 434.139, 1.758
[epoch:94, iter:73447] Loss: 1.405, 10.382, 66.152, 434.192, 1.605
[epoch:94, iter:73467] Loss: 1.405, 10.385, 66.143, 434.175, 1.602
[epoch:94, iter:73487] Loss: 1.405, 10.383, 66.137, 434.193, 1.545
[epoch:94, iter:73507] Loss: 1.405, 10.385, 66.136, 434.238, 1.437
 * Acc@1 62.834 Acc@5 89.590
epoch 93, total time 61.40
Test: [0/313]	Time 0.268 (0.268)	Loss 1.8881 (1.8881)	Acc@1 43.750 (43.750)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.5238 (2.1409)	Acc@1 46.875 (52.661)	Acc@5 81.250 (82.890)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.0991 (2.0782)	Acc@1 59.375 (53.778)	Acc@5 93.750 (83.333)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3565 (2.0843)	Acc@1 40.625 (53.883)	Acc@5 81.250 (83.451)
 * Acc@1 54.020 Acc@5 83.500
==> training...
Epoch: [94][0/782]	Time 0.546 (0.546)	Data 0.468 (0.468)	Loss 13.4635 (13.4635)	Acc@1 67.188 (67.188)	Acc@5 85.938 (85.938)
[epoch:95, iter:73509] Loss: 1.387, 10.385, 66.976, 438.749, 1.260
[epoch:95, iter:73529] Loss: 1.406, 10.413, 66.712, 437.923, 1.599
[epoch:95, iter:73549] Loss: 1.412, 10.418, 66.593, 436.510, 1.145
[epoch:95, iter:73569] Loss: 1.417, 10.430, 66.319, 435.747, 1.011
[epoch:95, iter:73589] Loss: 1.417, 10.406, 66.030, 434.980, 1.440
Epoch: [94][100/782]	Time 0.072 (0.082)	Data 0.002 (0.007)	Loss 14.0605 (13.6624)	Acc@1 57.812 (62.206)	Acc@5 90.625 (89.372)
[epoch:95, iter:73609] Loss: 1.413, 10.399, 66.093, 434.533, 1.294
[epoch:95, iter:73629] Loss: 1.411, 10.389, 66.051, 434.179, 1.123
[epoch:95, iter:73649] Loss: 1.409, 10.387, 66.004, 433.516, 1.404
[epoch:95, iter:73669] Loss: 1.410, 10.371, 65.941, 433.476, 1.467
[epoch:95, iter:73689] Loss: 1.411, 10.358, 65.910, 433.246, 1.593
Epoch: [94][200/782]	Time 0.074 (0.080)	Data 0.002 (0.005)	Loss 13.0474 (13.5472)	Acc@1 56.250 (62.990)	Acc@5 89.062 (89.529)
[epoch:95, iter:73709] Loss: 1.410, 10.366, 65.914, 433.046, 1.460
[epoch:95, iter:73729] Loss: 1.408, 10.360, 65.998, 432.977, 1.274
[epoch:95, iter:73749] Loss: 1.409, 10.355, 66.055, 433.212, 1.286
[epoch:95, iter:73769] Loss: 1.411, 10.367, 66.105, 433.281, 1.037
[epoch:95, iter:73789] Loss: 1.411, 10.366, 66.076, 433.217, 1.419
Epoch: [94][300/782]	Time 0.063 (0.079)	Data 0.003 (0.004)	Loss 13.0508 (13.5748)	Acc@1 71.875 (63.024)	Acc@5 93.750 (89.628)
[epoch:95, iter:73809] Loss: 1.413, 10.378, 66.176, 433.504, 1.107
[epoch:95, iter:73829] Loss: 1.413, 10.388, 66.226, 433.567, 1.176
[epoch:95, iter:73849] Loss: 1.413, 10.391, 66.290, 433.622, 1.822
[epoch:95, iter:73869] Loss: 1.413, 10.392, 66.290, 433.714, 1.313
[epoch:95, iter:73889] Loss: 1.413, 10.390, 66.255, 433.748, 1.705
Epoch: [94][400/782]	Time 0.085 (0.078)	Data 0.003 (0.003)	Loss 13.5385 (13.5802)	Acc@1 57.812 (63.053)	Acc@5 89.062 (89.550)
[epoch:95, iter:73909] Loss: 1.411, 10.392, 66.224, 433.666, 1.477
[epoch:95, iter:73929] Loss: 1.410, 10.388, 66.195, 433.666, 1.191
[epoch:95, iter:73949] Loss: 1.410, 10.388, 66.192, 433.665, 1.619
[epoch:95, iter:73969] Loss: 1.409, 10.385, 66.172, 433.648, 1.607
[epoch:95, iter:73989] Loss: 1.408, 10.386, 66.219, 433.833, 1.413
Epoch: [94][500/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 13.1079 (13.6001)	Acc@1 68.750 (62.824)	Acc@5 95.312 (89.455)
[epoch:95, iter:74009] Loss: 1.408, 10.390, 66.246, 433.891, 0.992
[epoch:95, iter:74029] Loss: 1.407, 10.387, 66.237, 433.827, 1.428
[epoch:95, iter:74049] Loss: 1.406, 10.393, 66.250, 433.892, 1.167
[epoch:95, iter:74069] Loss: 1.406, 10.398, 66.258, 433.978, 1.319
[epoch:95, iter:74089] Loss: 1.406, 10.399, 66.258, 434.112, 1.612
Epoch: [94][600/782]	Time 0.058 (0.077)	Data 0.002 (0.003)	Loss 13.2102 (13.6131)	Acc@1 56.250 (62.744)	Acc@5 87.500 (89.411)
[epoch:95, iter:74109] Loss: 1.407, 10.400, 66.292, 434.238, 1.409
[epoch:95, iter:74129] Loss: 1.407, 10.400, 66.297, 434.316, 1.610
[epoch:95, iter:74149] Loss: 1.407, 10.405, 66.304, 434.350, 1.487
[epoch:95, iter:74169] Loss: 1.408, 10.408, 66.299, 434.434, 1.494
[epoch:95, iter:74189] Loss: 1.408, 10.413, 66.287, 434.440, 1.327
Epoch: [94][700/782]	Time 0.077 (0.077)	Data 0.002 (0.003)	Loss 13.0075 (13.6292)	Acc@1 65.625 (62.614)	Acc@5 85.938 (89.419)
[epoch:95, iter:74209] Loss: 1.408, 10.415, 66.313, 434.499, 1.344
[epoch:95, iter:74229] Loss: 1.407, 10.413, 66.298, 434.462, 1.110
[epoch:95, iter:74249] Loss: 1.407, 10.415, 66.284, 434.455, 1.688
[epoch:95, iter:74269] Loss: 1.408, 10.415, 66.275, 434.439, 1.176
[epoch:95, iter:74289] Loss: 1.408, 10.417, 66.294, 434.467, 1.479
 * Acc@1 62.532 Acc@5 89.426
epoch 94, total time 59.98
Test: [0/313]	Time 0.245 (0.245)	Loss 2.1765 (2.1765)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9023 (2.5620)	Acc@1 56.250 (49.103)	Acc@5 78.125 (79.177)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7215 (2.5203)	Acc@1 50.000 (49.238)	Acc@5 90.625 (79.229)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6868 (2.5129)	Acc@1 43.750 (49.564)	Acc@5 81.250 (79.101)
 * Acc@1 49.700 Acc@5 79.190
==> training...
Epoch: [95][0/782]	Time 0.583 (0.583)	Data 0.521 (0.521)	Loss 13.8390 (13.8390)	Acc@1 60.938 (60.938)	Acc@5 93.750 (93.750)
[epoch:96, iter:74291] Loss: 1.499, 10.325, 68.659, 438.152, 1.211
[epoch:96, iter:74311] Loss: 1.424, 10.379, 66.976, 434.846, 1.208
[epoch:96, iter:74331] Loss: 1.418, 10.385, 66.200, 434.375, 1.199
[epoch:96, iter:74351] Loss: 1.416, 10.393, 65.891, 433.064, 1.238
[epoch:96, iter:74371] Loss: 1.409, 10.384, 65.873, 433.136, 1.052
Epoch: [95][100/782]	Time 0.067 (0.079)	Data 0.002 (0.008)	Loss 14.8517 (13.4222)	Acc@1 60.938 (64.140)	Acc@5 89.062 (90.501)
[epoch:96, iter:74391] Loss: 1.404, 10.378, 65.790, 432.890, 1.677
[epoch:96, iter:74411] Loss: 1.405, 10.373, 65.784, 433.044, 1.404
[epoch:96, iter:74431] Loss: 1.405, 10.365, 65.768, 432.846, 1.346
[epoch:96, iter:74451] Loss: 1.404, 10.379, 65.752, 433.114, 1.218
[epoch:96, iter:74471] Loss: 1.403, 10.377, 65.744, 433.187, 1.678
Epoch: [95][200/782]	Time 0.068 (0.078)	Data 0.002 (0.005)	Loss 14.2189 (13.4606)	Acc@1 65.625 (63.961)	Acc@5 84.375 (90.065)
[epoch:96, iter:74491] Loss: 1.402, 10.379, 65.731, 433.218, 1.472
[epoch:96, iter:74511] Loss: 1.401, 10.375, 65.659, 432.898, 1.250
[epoch:96, iter:74531] Loss: 1.400, 10.381, 65.658, 433.034, 1.816
[epoch:96, iter:74551] Loss: 1.401, 10.381, 65.780, 433.371, 0.904
[epoch:96, iter:74571] Loss: 1.402, 10.389, 65.838, 433.472, 1.194
Epoch: [95][300/782]	Time 0.080 (0.076)	Data 0.002 (0.004)	Loss 14.5611 (13.4820)	Acc@1 48.438 (64.042)	Acc@5 81.250 (89.841)
[epoch:96, iter:74591] Loss: 1.403, 10.386, 65.878, 433.429, 1.777
[epoch:96, iter:74611] Loss: 1.403, 10.383, 65.882, 433.452, 1.432
[epoch:96, iter:74631] Loss: 1.404, 10.392, 65.968, 433.629, 1.269
[epoch:96, iter:74651] Loss: 1.404, 10.397, 66.003, 433.916, 1.381
[epoch:96, iter:74671] Loss: 1.403, 10.397, 66.013, 433.837, 1.138
Epoch: [95][400/782]	Time 0.084 (0.076)	Data 0.003 (0.004)	Loss 12.7566 (13.5090)	Acc@1 64.062 (63.825)	Acc@5 90.625 (89.752)
[epoch:96, iter:74691] Loss: 1.402, 10.392, 65.981, 433.638, 1.271
[epoch:96, iter:74711] Loss: 1.402, 10.390, 65.949, 433.510, 1.525
[epoch:96, iter:74731] Loss: 1.401, 10.388, 65.936, 433.470, 1.526
[epoch:96, iter:74751] Loss: 1.401, 10.383, 65.935, 433.460, 1.836
[epoch:96, iter:74771] Loss: 1.402, 10.381, 65.950, 433.648, 1.451
Epoch: [95][500/782]	Time 0.086 (0.076)	Data 0.002 (0.003)	Loss 13.2355 (13.5069)	Acc@1 57.812 (63.492)	Acc@5 96.875 (89.692)
[epoch:96, iter:74791] Loss: 1.402, 10.382, 65.904, 433.531, 1.332
[epoch:96, iter:74811] Loss: 1.402, 10.382, 65.946, 433.697, 1.511
[epoch:96, iter:74831] Loss: 1.403, 10.384, 65.936, 433.645, 1.432
[epoch:96, iter:74851] Loss: 1.403, 10.383, 65.938, 433.696, 1.199
[epoch:96, iter:74871] Loss: 1.404, 10.384, 65.973, 433.792, 1.781
Epoch: [95][600/782]	Time 0.070 (0.076)	Data 0.002 (0.003)	Loss 13.0581 (13.5394)	Acc@1 70.312 (63.160)	Acc@5 92.188 (89.642)
[epoch:96, iter:74891] Loss: 1.405, 10.381, 66.003, 433.776, 1.052
[epoch:96, iter:74911] Loss: 1.405, 10.379, 65.993, 433.790, 1.859
[epoch:96, iter:74931] Loss: 1.406, 10.378, 66.007, 433.882, 1.283
[epoch:96, iter:74951] Loss: 1.406, 10.380, 66.012, 433.863, 1.167
[epoch:96, iter:74971] Loss: 1.407, 10.382, 66.023, 433.905, 1.378
Epoch: [95][700/782]	Time 0.074 (0.075)	Data 0.002 (0.003)	Loss 14.3828 (13.5647)	Acc@1 62.500 (63.033)	Acc@5 82.812 (89.499)
[epoch:96, iter:74991] Loss: 1.407, 10.386, 66.040, 434.026, 1.614
[epoch:96, iter:75011] Loss: 1.407, 10.386, 66.047, 434.089, 1.482
[epoch:96, iter:75031] Loss: 1.407, 10.387, 66.067, 434.211, 1.320
[epoch:96, iter:75051] Loss: 1.407, 10.390, 66.096, 434.346, 1.623
[epoch:96, iter:75071] Loss: 1.407, 10.393, 66.097, 434.341, 1.398
 * Acc@1 62.922 Acc@5 89.438
epoch 95, total time 59.45
Test: [0/313]	Time 0.247 (0.247)	Loss 2.0191 (2.0191)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.8916 (1.9944)	Acc@1 59.375 (55.507)	Acc@5 84.375 (85.551)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4184 (2.0091)	Acc@1 65.625 (55.146)	Acc@5 93.750 (85.137)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.6440 (1.9948)	Acc@1 59.375 (55.990)	Acc@5 87.500 (85.008)
 * Acc@1 56.010 Acc@5 85.050
==> training...
Epoch: [96][0/782]	Time 0.488 (0.488)	Data 0.416 (0.416)	Loss 13.8247 (13.8247)	Acc@1 51.562 (51.562)	Acc@5 87.500 (87.500)
[epoch:97, iter:75073] Loss: 1.275, 9.988, 68.238, 438.472, 1.718
[epoch:97, iter:75093] Loss: 1.407, 10.308, 67.289, 435.328, 1.652
[epoch:97, iter:75113] Loss: 1.409, 10.361, 66.844, 434.485, 1.533
[epoch:97, iter:75133] Loss: 1.408, 10.427, 66.721, 434.542, 0.837
[epoch:97, iter:75153] Loss: 1.411, 10.404, 66.670, 434.263, 1.479
Epoch: [96][100/782]	Time 0.073 (0.080)	Data 0.002 (0.006)	Loss 13.2097 (13.5567)	Acc@1 71.875 (63.413)	Acc@5 90.625 (90.006)
[epoch:97, iter:75173] Loss: 1.408, 10.408, 66.379, 433.900, 1.136
[epoch:97, iter:75193] Loss: 1.406, 10.380, 66.400, 434.384, 1.858
[epoch:97, iter:75213] Loss: 1.407, 10.400, 66.376, 434.516, 1.235
[epoch:97, iter:75233] Loss: 1.408, 10.399, 66.325, 434.657, 1.247
[epoch:97, iter:75253] Loss: 1.409, 10.407, 66.381, 434.750, 1.224
Epoch: [96][200/782]	Time 0.074 (0.079)	Data 0.002 (0.004)	Loss 13.1581 (13.5831)	Acc@1 62.500 (63.433)	Acc@5 90.625 (90.011)
[epoch:97, iter:75273] Loss: 1.407, 10.412, 66.453, 434.818, 1.282
[epoch:97, iter:75293] Loss: 1.407, 10.408, 66.424, 434.687, 1.290
[epoch:97, iter:75313] Loss: 1.408, 10.413, 66.406, 434.898, 0.993
[epoch:97, iter:75333] Loss: 1.407, 10.403, 66.355, 434.966, 1.255
[epoch:97, iter:75353] Loss: 1.406, 10.399, 66.303, 434.699, 1.219
Epoch: [96][300/782]	Time 0.086 (0.077)	Data 0.003 (0.004)	Loss 13.0615 (13.5685)	Acc@1 64.062 (62.874)	Acc@5 90.625 (89.836)
[epoch:97, iter:75373] Loss: 1.404, 10.404, 66.260, 434.622, 1.072
[epoch:97, iter:75393] Loss: 1.407, 10.410, 66.254, 434.733, 1.467
[epoch:97, iter:75413] Loss: 1.405, 10.402, 66.256, 434.674, 1.417
[epoch:97, iter:75433] Loss: 1.404, 10.393, 66.207, 434.525, 1.310
[epoch:97, iter:75453] Loss: 1.404, 10.393, 66.191, 434.515, 1.171
Epoch: [96][400/782]	Time 0.062 (0.077)	Data 0.002 (0.003)	Loss 15.1191 (13.5614)	Acc@1 43.750 (63.061)	Acc@5 79.688 (89.616)
[epoch:97, iter:75473] Loss: 1.403, 10.384, 66.181, 434.407, 2.108
[epoch:97, iter:75493] Loss: 1.403, 10.393, 66.219, 434.543, 1.238
[epoch:97, iter:75513] Loss: 1.402, 10.388, 66.250, 434.542, 1.555
[epoch:97, iter:75533] Loss: 1.401, 10.389, 66.234, 434.591, 1.382
[epoch:97, iter:75553] Loss: 1.402, 10.391, 66.274, 434.719, 1.649
Epoch: [96][500/782]	Time 0.069 (0.076)	Data 0.002 (0.003)	Loss 12.4613 (13.5909)	Acc@1 68.750 (63.077)	Acc@5 90.625 (89.633)
[epoch:97, iter:75573] Loss: 1.403, 10.392, 66.299, 434.764, 1.129
[epoch:97, iter:75593] Loss: 1.404, 10.396, 66.300, 434.814, 1.157
[epoch:97, iter:75613] Loss: 1.405, 10.398, 66.313, 434.850, 1.081
[epoch:97, iter:75633] Loss: 1.405, 10.401, 66.311, 434.848, 1.479
[epoch:97, iter:75653] Loss: 1.404, 10.397, 66.275, 434.862, 1.610
Epoch: [96][600/782]	Time 0.070 (0.076)	Data 0.002 (0.003)	Loss 13.9676 (13.6123)	Acc@1 56.250 (62.968)	Acc@5 87.500 (89.554)
[epoch:97, iter:75673] Loss: 1.404, 10.398, 66.279, 434.833, 1.823
[epoch:97, iter:75693] Loss: 1.405, 10.400, 66.295, 434.789, 1.272
[epoch:97, iter:75713] Loss: 1.405, 10.401, 66.305, 434.809, 1.872
[epoch:97, iter:75733] Loss: 1.406, 10.405, 66.265, 434.715, 0.922
[epoch:97, iter:75753] Loss: 1.405, 10.402, 66.236, 434.720, 1.121
Epoch: [96][700/782]	Time 0.071 (0.077)	Data 0.002 (0.003)	Loss 13.6266 (13.6024)	Acc@1 68.750 (62.892)	Acc@5 92.188 (89.542)
[epoch:97, iter:75773] Loss: 1.405, 10.404, 66.214, 434.644, 1.148
[epoch:97, iter:75793] Loss: 1.405, 10.402, 66.210, 434.678, 1.326
[epoch:97, iter:75813] Loss: 1.404, 10.402, 66.205, 434.654, 1.391
[epoch:97, iter:75833] Loss: 1.405, 10.402, 66.234, 434.685, 1.162
[epoch:97, iter:75853] Loss: 1.405, 10.404, 66.246, 434.750, 1.515
 * Acc@1 62.746 Acc@5 89.520
epoch 96, total time 60.44
Test: [0/313]	Time 0.247 (0.247)	Loss 2.1510 (2.1510)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.008 (0.010)	Loss 3.0599 (2.0223)	Acc@1 37.500 (54.734)	Acc@5 71.875 (84.375)
Test: [200/313]	Time 0.009 (0.008)	Loss 1.2332 (2.0283)	Acc@1 68.750 (54.664)	Acc@5 93.750 (84.313)
Test: [300/313]	Time 0.009 (0.008)	Loss 2.5279 (2.0476)	Acc@1 50.000 (54.350)	Acc@5 87.500 (84.250)
 * Acc@1 54.320 Acc@5 84.260
==> training...
Epoch: [97][0/782]	Time 0.589 (0.589)	Data 0.507 (0.507)	Loss 14.5800 (14.5800)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
[epoch:98, iter:75855] Loss: 1.410, 10.867, 69.688, 453.750, 1.505
[epoch:98, iter:75875] Loss: 1.425, 10.390, 67.085, 436.893, 1.006
[epoch:98, iter:75895] Loss: 1.417, 10.455, 66.792, 436.380, 1.236
[epoch:98, iter:75915] Loss: 1.416, 10.458, 66.708, 435.753, 1.632
[epoch:98, iter:75935] Loss: 1.417, 10.436, 66.390, 435.027, 1.568
Epoch: [97][100/782]	Time 0.081 (0.080)	Data 0.002 (0.007)	Loss 13.5983 (13.6024)	Acc@1 64.062 (63.552)	Acc@5 85.938 (90.099)
[epoch:98, iter:75955] Loss: 1.412, 10.429, 66.198, 434.594, 1.342
[epoch:98, iter:75975] Loss: 1.408, 10.420, 66.154, 434.314, 1.181
[epoch:98, iter:75995] Loss: 1.407, 10.429, 66.180, 434.374, 1.464
[epoch:98, iter:76015] Loss: 1.405, 10.430, 66.193, 434.183, 1.573
[epoch:98, iter:76035] Loss: 1.404, 10.432, 66.220, 434.097, 1.179
Epoch: [97][200/782]	Time 0.090 (0.080)	Data 0.005 (0.005)	Loss 13.6561 (13.5453)	Acc@1 56.250 (63.705)	Acc@5 92.188 (90.306)
[epoch:98, iter:76055] Loss: 1.405, 10.429, 66.084, 433.837, 1.511
[epoch:98, iter:76075] Loss: 1.404, 10.430, 66.110, 433.926, 1.203
[epoch:98, iter:76095] Loss: 1.405, 10.437, 66.034, 433.876, 1.326
[epoch:98, iter:76115] Loss: 1.403, 10.445, 66.026, 433.855, 1.672
[epoch:98, iter:76135] Loss: 1.404, 10.446, 66.019, 433.781, 2.030
Epoch: [97][300/782]	Time 0.077 (0.077)	Data 0.002 (0.004)	Loss 13.8544 (13.5470)	Acc@1 68.750 (63.471)	Acc@5 92.188 (90.158)
[epoch:98, iter:76155] Loss: 1.403, 10.455, 66.070, 433.887, 1.179
[epoch:98, iter:76175] Loss: 1.404, 10.452, 66.149, 434.084, 1.234
[epoch:98, iter:76195] Loss: 1.402, 10.441, 66.120, 434.045, 1.329
[epoch:98, iter:76215] Loss: 1.402, 10.437, 66.073, 434.004, 1.298
[epoch:98, iter:76235] Loss: 1.403, 10.434, 66.072, 433.963, 1.463
Epoch: [97][400/782]	Time 0.073 (0.077)	Data 0.002 (0.004)	Loss 13.5571 (13.5597)	Acc@1 64.062 (63.229)	Acc@5 84.375 (89.931)
[epoch:98, iter:76255] Loss: 1.402, 10.438, 66.039, 433.917, 1.419
[epoch:98, iter:76275] Loss: 1.403, 10.434, 66.041, 433.887, 1.863
[epoch:98, iter:76295] Loss: 1.403, 10.424, 66.005, 433.744, 1.751
[epoch:98, iter:76315] Loss: 1.404, 10.423, 66.015, 433.751, 1.654
[epoch:98, iter:76335] Loss: 1.404, 10.418, 66.000, 433.741, 1.673
Epoch: [97][500/782]	Time 0.083 (0.077)	Data 0.003 (0.003)	Loss 13.2807 (13.5647)	Acc@1 62.500 (62.962)	Acc@5 85.938 (89.867)
[epoch:98, iter:76355] Loss: 1.403, 10.418, 66.054, 433.846, 1.529
[epoch:98, iter:76375] Loss: 1.403, 10.424, 66.077, 433.989, 1.724
[epoch:98, iter:76395] Loss: 1.403, 10.427, 66.074, 434.104, 1.019
[epoch:98, iter:76415] Loss: 1.403, 10.425, 66.052, 434.115, 1.519
[epoch:98, iter:76435] Loss: 1.404, 10.422, 66.047, 434.088, 1.998
Epoch: [97][600/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 13.9921 (13.5810)	Acc@1 62.500 (63.028)	Acc@5 85.938 (89.777)
[epoch:98, iter:76455] Loss: 1.404, 10.417, 66.080, 434.173, 1.600
[epoch:98, iter:76475] Loss: 1.403, 10.414, 66.049, 434.059, 1.539
[epoch:98, iter:76495] Loss: 1.403, 10.412, 66.056, 434.028, 1.575
[epoch:98, iter:76515] Loss: 1.402, 10.414, 66.053, 434.054, 1.964
[epoch:98, iter:76535] Loss: 1.403, 10.412, 66.050, 434.043, 1.110
Epoch: [97][700/782]	Time 0.097 (0.077)	Data 0.003 (0.003)	Loss 13.8439 (13.5879)	Acc@1 62.500 (62.799)	Acc@5 87.500 (89.649)
[epoch:98, iter:76555] Loss: 1.403, 10.414, 66.047, 434.124, 1.473
[epoch:98, iter:76575] Loss: 1.403, 10.412, 66.049, 434.194, 1.823
[epoch:98, iter:76595] Loss: 1.403, 10.410, 66.061, 434.214, 1.932
[epoch:98, iter:76615] Loss: 1.403, 10.412, 66.061, 434.221, 1.092
[epoch:98, iter:76635] Loss: 1.404, 10.413, 66.089, 434.288, 1.593
 * Acc@1 62.846 Acc@5 89.630
epoch 97, total time 60.49
Test: [0/313]	Time 0.299 (0.299)	Loss 1.4601 (1.4601)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.7245 (1.8803)	Acc@1 53.125 (56.528)	Acc@5 90.625 (85.922)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.1840 (1.8394)	Acc@1 56.250 (57.121)	Acc@5 90.625 (86.039)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5082 (1.8450)	Acc@1 40.625 (56.925)	Acc@5 90.625 (86.088)
 * Acc@1 56.990 Acc@5 86.050
==> training...
Epoch: [98][0/782]	Time 0.492 (0.492)	Data 0.421 (0.421)	Loss 12.9937 (12.9937)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
[epoch:99, iter:76637] Loss: 1.389, 10.031, 64.502, 426.103, 1.157
[epoch:99, iter:76657] Loss: 1.391, 10.258, 65.437, 433.644, 0.920
[epoch:99, iter:76677] Loss: 1.378, 10.246, 64.978, 430.330, 1.074
[epoch:99, iter:76697] Loss: 1.392, 10.278, 65.138, 431.063, 1.150
[epoch:99, iter:76717] Loss: 1.393, 10.280, 65.328, 431.452, 1.403
Epoch: [98][100/782]	Time 0.080 (0.079)	Data 0.002 (0.006)	Loss 12.9001 (13.3694)	Acc@1 70.312 (63.800)	Acc@5 84.375 (90.114)
[epoch:99, iter:76737] Loss: 1.392, 10.295, 65.507, 432.077, 1.297
[epoch:99, iter:76757] Loss: 1.389, 10.284, 65.518, 431.741, 1.739
[epoch:99, iter:76777] Loss: 1.389, 10.293, 65.708, 432.003, 1.235
[epoch:99, iter:76797] Loss: 1.391, 10.301, 65.853, 432.519, 1.333
[epoch:99, iter:76817] Loss: 1.391, 10.314, 65.788, 432.374, 1.464
Epoch: [98][200/782]	Time 0.076 (0.075)	Data 0.002 (0.004)	Loss 12.7735 (13.3795)	Acc@1 71.875 (64.101)	Acc@5 95.312 (90.260)
[epoch:99, iter:76837] Loss: 1.392, 10.315, 65.707, 432.291, 0.984
[epoch:99, iter:76857] Loss: 1.391, 10.313, 65.723, 432.203, 1.329
[epoch:99, iter:76877] Loss: 1.391, 10.307, 65.712, 432.154, 1.779
[epoch:99, iter:76897] Loss: 1.393, 10.313, 65.723, 432.305, 1.109
[epoch:99, iter:76917] Loss: 1.391, 10.312, 65.722, 432.314, 1.202
Epoch: [98][300/782]	Time 0.076 (0.076)	Data 0.002 (0.004)	Loss 13.1763 (13.4272)	Acc@1 60.938 (63.689)	Acc@5 93.750 (89.888)
[epoch:99, iter:76937] Loss: 1.392, 10.307, 65.831, 432.444, 1.300
[epoch:99, iter:76957] Loss: 1.393, 10.317, 65.944, 432.573, 1.531
[epoch:99, iter:76977] Loss: 1.393, 10.326, 65.955, 432.739, 1.289
[epoch:99, iter:76997] Loss: 1.394, 10.329, 65.977, 432.811, 1.118
[epoch:99, iter:77017] Loss: 1.395, 10.338, 66.040, 432.932, 1.193
Epoch: [98][400/782]	Time 0.070 (0.076)	Data 0.002 (0.003)	Loss 14.3313 (13.4675)	Acc@1 56.250 (63.599)	Acc@5 85.938 (89.865)
[epoch:99, iter:77037] Loss: 1.394, 10.342, 65.984, 432.919, 1.612
[epoch:99, iter:77057] Loss: 1.395, 10.351, 65.955, 432.915, 1.482
[epoch:99, iter:77077] Loss: 1.394, 10.348, 65.914, 432.893, 1.251
[epoch:99, iter:77097] Loss: 1.394, 10.351, 65.898, 432.941, 1.203
[epoch:99, iter:77117] Loss: 1.394, 10.346, 65.951, 433.050, 1.583
Epoch: [98][500/782]	Time 0.086 (0.077)	Data 0.003 (0.003)	Loss 14.5548 (13.4867)	Acc@1 53.125 (63.433)	Acc@5 84.375 (89.802)
[epoch:99, iter:77137] Loss: 1.395, 10.350, 65.958, 433.093, 1.877
[epoch:99, iter:77157] Loss: 1.397, 10.354, 66.028, 433.320, 1.483
[epoch:99, iter:77177] Loss: 1.396, 10.364, 66.080, 433.444, 1.440
[epoch:99, iter:77197] Loss: 1.397, 10.366, 66.081, 433.404, 1.428
[epoch:99, iter:77217] Loss: 1.397, 10.369, 66.085, 433.448, 1.525
Epoch: [98][600/782]	Time 0.077 (0.077)	Data 0.003 (0.003)	Loss 14.0706 (13.5300)	Acc@1 68.750 (63.150)	Acc@5 89.062 (89.673)
[epoch:99, iter:77237] Loss: 1.397, 10.371, 66.091, 433.547, 1.271
[epoch:99, iter:77257] Loss: 1.397, 10.373, 66.106, 433.556, 1.332
[epoch:99, iter:77277] Loss: 1.398, 10.373, 66.100, 433.494, 1.352
[epoch:99, iter:77297] Loss: 1.398, 10.375, 66.079, 433.463, 1.326
[epoch:99, iter:77317] Loss: 1.398, 10.376, 66.066, 433.553, 1.449
Epoch: [98][700/782]	Time 0.067 (0.076)	Data 0.002 (0.003)	Loss 12.4748 (13.5346)	Acc@1 62.500 (63.124)	Acc@5 89.062 (89.646)
[epoch:99, iter:77337] Loss: 1.398, 10.374, 66.061, 433.576, 1.380
[epoch:99, iter:77357] Loss: 1.398, 10.371, 66.052, 433.619, 1.026
[epoch:99, iter:77377] Loss: 1.398, 10.372, 66.053, 433.602, 1.321
[epoch:99, iter:77397] Loss: 1.398, 10.370, 66.057, 433.602, 1.566
[epoch:99, iter:77417] Loss: 1.398, 10.370, 66.048, 433.599, 1.320
 * Acc@1 63.128 Acc@5 89.608
epoch 98, total time 59.43
Test: [0/313]	Time 0.285 (0.285)	Loss 1.9992 (1.9992)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.4449 (2.0693)	Acc@1 43.750 (54.981)	Acc@5 78.125 (82.859)
Test: [200/313]	Time 0.008 (0.008)	Loss 1.8809 (2.0454)	Acc@1 59.375 (55.395)	Acc@5 84.375 (83.162)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5266 (2.0635)	Acc@1 31.250 (55.368)	Acc@5 75.000 (83.098)
 * Acc@1 55.520 Acc@5 83.240
==> training...
Epoch: [99][0/782]	Time 0.511 (0.511)	Data 0.443 (0.443)	Loss 13.6667 (13.6667)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
[epoch:100, iter:77419] Loss: 1.359, 10.651, 67.861, 433.713, 1.251
[epoch:100, iter:77439] Loss: 1.399, 10.369, 65.556, 434.372, 1.050
[epoch:100, iter:77459] Loss: 1.390, 10.370, 65.356, 433.511, 1.315
[epoch:100, iter:77479] Loss: 1.406, 10.378, 65.454, 433.381, 1.605
[epoch:100, iter:77499] Loss: 1.408, 10.368, 65.506, 433.459, 1.160
Epoch: [99][100/782]	Time 0.080 (0.083)	Data 0.002 (0.007)	Loss 13.3839 (13.4496)	Acc@1 57.812 (63.614)	Acc@5 93.750 (90.099)
[epoch:100, iter:77519] Loss: 1.402, 10.333, 65.559, 432.736, 1.445
[epoch:100, iter:77539] Loss: 1.402, 10.325, 65.734, 432.827, 1.691
[epoch:100, iter:77559] Loss: 1.403, 10.327, 65.828, 432.771, 1.439
[epoch:100, iter:77579] Loss: 1.402, 10.339, 65.911, 432.862, 1.332
[epoch:100, iter:77599] Loss: 1.405, 10.356, 65.933, 433.465, 1.200
Epoch: [99][200/782]	Time 0.093 (0.082)	Data 0.003 (0.005)	Loss 13.3981 (13.5447)	Acc@1 65.625 (63.200)	Acc@5 93.750 (89.708)
[epoch:100, iter:77619] Loss: 1.403, 10.352, 65.896, 433.759, 1.300
[epoch:100, iter:77639] Loss: 1.404, 10.345, 65.873, 433.672, 1.732
[epoch:100, iter:77659] Loss: 1.405, 10.352, 65.982, 433.728, 1.621
[epoch:100, iter:77679] Loss: 1.406, 10.360, 66.008, 433.712, 1.347
[epoch:100, iter:77699] Loss: 1.407, 10.363, 66.025, 433.648, 1.467
Epoch: [99][300/782]	Time 0.084 (0.081)	Data 0.002 (0.004)	Loss 13.0931 (13.5729)	Acc@1 65.625 (62.739)	Acc@5 92.188 (89.488)
[epoch:100, iter:77719] Loss: 1.405, 10.367, 66.008, 433.544, 1.164
[epoch:100, iter:77739] Loss: 1.405, 10.374, 66.081, 433.685, 1.724
[epoch:100, iter:77759] Loss: 1.407, 10.384, 66.062, 433.735, 1.185
[epoch:100, iter:77779] Loss: 1.407, 10.381, 66.006, 433.630, 1.786
[epoch:100, iter:77799] Loss: 1.405, 10.379, 66.002, 433.672, 1.226
Epoch: [99][400/782]	Time 0.070 (0.080)	Data 0.002 (0.004)	Loss 13.1869 (13.5809)	Acc@1 62.500 (62.730)	Acc@5 89.062 (89.374)
[epoch:100, iter:77819] Loss: 1.404, 10.375, 65.975, 433.683, 1.404
[epoch:100, iter:77839] Loss: 1.402, 10.374, 65.926, 433.591, 1.723
[epoch:100, iter:77859] Loss: 1.403, 10.374, 65.953, 433.760, 1.265
[epoch:100, iter:77879] Loss: 1.402, 10.374, 65.909, 433.619, 1.574
[epoch:100, iter:77899] Loss: 1.402, 10.378, 65.862, 433.520, 1.477
Epoch: [99][500/782]	Time 0.067 (0.079)	Data 0.002 (0.003)	Loss 13.5122 (13.5692)	Acc@1 62.500 (62.706)	Acc@5 95.312 (89.393)
[epoch:100, iter:77919] Loss: 1.403, 10.380, 65.875, 433.527, 1.051
[epoch:100, iter:77939] Loss: 1.403, 10.377, 65.894, 433.563, 1.604
[epoch:100, iter:77959] Loss: 1.402, 10.380, 65.906, 433.527, 1.374
[epoch:100, iter:77979] Loss: 1.402, 10.380, 65.886, 433.456, 1.222
[epoch:100, iter:77999] Loss: 1.402, 10.381, 65.902, 433.500, 1.116
Epoch: [99][600/782]	Time 0.086 (0.079)	Data 0.003 (0.003)	Loss 13.5777 (13.5734)	Acc@1 60.938 (62.770)	Acc@5 81.250 (89.481)
[epoch:100, iter:78019] Loss: 1.401, 10.383, 65.944, 433.569, 1.500
[epoch:100, iter:78039] Loss: 1.401, 10.381, 65.933, 433.582, 1.862
[epoch:100, iter:78059] Loss: 1.401, 10.385, 65.920, 433.640, 0.958
[epoch:100, iter:78079] Loss: 1.400, 10.389, 65.907, 433.589, 1.431
[epoch:100, iter:78099] Loss: 1.401, 10.388, 65.922, 433.625, 2.012
Epoch: [99][700/782]	Time 0.062 (0.079)	Data 0.002 (0.003)	Loss 13.7934 (13.5665)	Acc@1 54.688 (62.723)	Acc@5 89.062 (89.430)
[epoch:100, iter:78119] Loss: 1.401, 10.393, 65.923, 433.572, 1.532
[epoch:100, iter:78139] Loss: 1.401, 10.392, 65.928, 433.666, 1.266
[epoch:100, iter:78159] Loss: 1.400, 10.390, 65.918, 433.677, 1.467
[epoch:100, iter:78179] Loss: 1.400, 10.388, 65.921, 433.724, 1.312
[epoch:100, iter:78199] Loss: 1.400, 10.389, 65.913, 433.668, 1.095
 * Acc@1 62.784 Acc@5 89.518
epoch 99, total time 61.48
Test: [0/313]	Time 0.258 (0.258)	Loss 2.1543 (2.1543)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.1745 (2.1875)	Acc@1 37.500 (53.094)	Acc@5 87.500 (83.292)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5638 (2.2326)	Acc@1 68.750 (52.052)	Acc@5 84.375 (83.022)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4618 (2.2379)	Acc@1 40.625 (52.481)	Acc@5 75.000 (82.620)
 * Acc@1 52.530 Acc@5 82.700
==> training...
Epoch: [100][0/782]	Time 0.597 (0.597)	Data 0.523 (0.523)	Loss 14.3699 (14.3699)	Acc@1 67.188 (67.188)	Acc@5 89.062 (89.062)
[epoch:101, iter:78201] Loss: 1.471, 10.719, 69.093, 444.106, 1.344
[epoch:101, iter:78221] Loss: 1.412, 10.574, 65.444, 433.299, 1.456
[epoch:101, iter:78241] Loss: 1.422, 10.503, 65.867, 434.490, 1.677
[epoch:101, iter:78261] Loss: 1.407, 10.446, 65.979, 434.245, 1.301
[epoch:101, iter:78281] Loss: 1.405, 10.405, 66.134, 434.346, 1.082
Epoch: [100][100/782]	Time 0.080 (0.087)	Data 0.002 (0.007)	Loss 13.3131 (13.5018)	Acc@1 62.500 (64.155)	Acc@5 89.062 (89.650)
[epoch:101, iter:78301] Loss: 1.406, 10.425, 65.899, 433.636, 1.345
[epoch:101, iter:78321] Loss: 1.410, 10.434, 65.919, 433.199, 1.584
[epoch:101, iter:78341] Loss: 1.410, 10.439, 66.049, 433.867, 1.293
[epoch:101, iter:78361] Loss: 1.407, 10.456, 65.988, 433.952, 1.468
[epoch:101, iter:78381] Loss: 1.408, 10.447, 66.018, 433.945, 1.413
Epoch: [100][200/782]	Time 0.088 (0.080)	Data 0.003 (0.005)	Loss 14.1799 (13.5528)	Acc@1 56.250 (63.099)	Acc@5 84.375 (89.459)
[epoch:101, iter:78401] Loss: 1.408, 10.456, 65.990, 433.917, 1.786
[epoch:101, iter:78421] Loss: 1.406, 10.452, 65.919, 433.746, 1.108
[epoch:101, iter:78441] Loss: 1.405, 10.446, 65.896, 433.690, 1.203
[epoch:101, iter:78461] Loss: 1.402, 10.433, 65.873, 433.579, 1.461
[epoch:101, iter:78481] Loss: 1.401, 10.429, 65.901, 433.632, 1.186
Epoch: [100][300/782]	Time 0.085 (0.080)	Data 0.003 (0.004)	Loss 13.2997 (13.5235)	Acc@1 64.062 (63.159)	Acc@5 89.062 (89.493)
[epoch:101, iter:78501] Loss: 1.400, 10.426, 65.817, 433.379, 1.511
[epoch:101, iter:78521] Loss: 1.400, 10.415, 65.849, 433.350, 1.635
[epoch:101, iter:78541] Loss: 1.399, 10.412, 65.849, 433.348, 1.923
[epoch:101, iter:78561] Loss: 1.399, 10.413, 65.883, 433.368, 1.399
[epoch:101, iter:78581] Loss: 1.399, 10.404, 65.864, 433.339, 1.380
Epoch: [100][400/782]	Time 0.091 (0.081)	Data 0.003 (0.004)	Loss 13.2977 (13.5172)	Acc@1 70.312 (63.221)	Acc@5 93.750 (89.596)
[epoch:101, iter:78601] Loss: 1.400, 10.401, 65.881, 433.328, 1.155
[epoch:101, iter:78621] Loss: 1.399, 10.395, 65.911, 433.395, 1.133
[epoch:101, iter:78641] Loss: 1.399, 10.402, 65.976, 433.396, 0.915
[epoch:101, iter:78661] Loss: 1.401, 10.403, 66.050, 433.487, 1.287
[epoch:101, iter:78681] Loss: 1.400, 10.403, 66.054, 433.463, 1.242
Epoch: [100][500/782]	Time 0.083 (0.080)	Data 0.002 (0.003)	Loss 13.9441 (13.5455)	Acc@1 60.938 (63.158)	Acc@5 90.625 (89.465)
[epoch:101, iter:78701] Loss: 1.398, 10.402, 66.063, 433.498, 1.326
[epoch:101, iter:78721] Loss: 1.399, 10.402, 66.048, 433.492, 1.673
[epoch:101, iter:78741] Loss: 1.398, 10.398, 66.017, 433.441, 1.229
[epoch:101, iter:78761] Loss: 1.399, 10.396, 66.012, 433.435, 1.537
[epoch:101, iter:78781] Loss: 1.399, 10.398, 65.999, 433.445, 1.581
Epoch: [100][600/782]	Time 0.076 (0.080)	Data 0.002 (0.003)	Loss 12.9690 (13.5541)	Acc@1 68.750 (62.978)	Acc@5 90.625 (89.395)
[epoch:101, iter:78801] Loss: 1.399, 10.400, 65.968, 433.497, 1.099
[epoch:101, iter:78821] Loss: 1.399, 10.397, 65.969, 433.517, 0.849
[epoch:101, iter:78841] Loss: 1.398, 10.394, 65.950, 433.446, 1.515
[epoch:101, iter:78861] Loss: 1.398, 10.393, 65.952, 433.517, 1.736
[epoch:101, iter:78881] Loss: 1.398, 10.390, 65.971, 433.519, 1.905
Epoch: [100][700/782]	Time 0.066 (0.079)	Data 0.002 (0.003)	Loss 14.2758 (13.5542)	Acc@1 60.938 (62.986)	Acc@5 82.812 (89.484)
[epoch:101, iter:78901] Loss: 1.400, 10.393, 65.995, 433.548, 1.610
[epoch:101, iter:78921] Loss: 1.400, 10.394, 65.985, 433.626, 1.447
[epoch:101, iter:78941] Loss: 1.400, 10.395, 65.999, 433.673, 1.743
[epoch:101, iter:78961] Loss: 1.401, 10.396, 65.994, 433.713, 1.397
[epoch:101, iter:78981] Loss: 1.401, 10.394, 65.997, 433.764, 1.801
 * Acc@1 62.964 Acc@5 89.398
epoch 100, total time 61.69
Test: [0/313]	Time 0.242 (0.242)	Loss 1.9213 (1.9213)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.8174 (1.8638)	Acc@1 53.125 (56.157)	Acc@5 87.500 (86.108)
Test: [200/313]	Time 0.009 (0.008)	Loss 1.4271 (1.8714)	Acc@1 53.125 (55.908)	Acc@5 87.500 (85.634)
Test: [300/313]	Time 0.010 (0.008)	Loss 2.4730 (1.8650)	Acc@1 43.750 (56.385)	Acc@5 78.125 (85.486)
 * Acc@1 56.400 Acc@5 85.530
==> training...
Epoch: [101][0/782]	Time 0.568 (0.568)	Data 0.497 (0.497)	Loss 13.9906 (13.9906)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
[epoch:102, iter:78983] Loss: 1.430, 10.497, 69.629, 447.817, 1.250
[epoch:102, iter:79003] Loss: 1.410, 10.423, 65.894, 433.477, 1.590
[epoch:102, iter:79023] Loss: 1.419, 10.444, 65.742, 432.692, 1.618
[epoch:102, iter:79043] Loss: 1.423, 10.465, 65.913, 433.063, 1.577
[epoch:102, iter:79063] Loss: 1.422, 10.481, 66.385, 433.915, 1.212
Epoch: [101][100/782]	Time 0.100 (0.086)	Data 0.003 (0.007)	Loss 13.3642 (13.6116)	Acc@1 57.812 (62.794)	Acc@5 85.938 (89.217)
[epoch:102, iter:79083] Loss: 1.417, 10.473, 66.238, 434.129, 1.379
[epoch:102, iter:79103] Loss: 1.415, 10.451, 66.124, 433.900, 1.468
[epoch:102, iter:79123] Loss: 1.414, 10.456, 65.977, 433.792, 1.441
[epoch:102, iter:79143] Loss: 1.413, 10.453, 65.940, 433.557, 1.201
[epoch:102, iter:79163] Loss: 1.409, 10.444, 65.928, 433.442, 1.462
Epoch: [101][200/782]	Time 0.074 (0.079)	Data 0.002 (0.005)	Loss 13.8849 (13.5095)	Acc@1 68.750 (63.526)	Acc@5 84.375 (89.677)
[epoch:102, iter:79183] Loss: 1.407, 10.448, 65.881, 433.230, 1.533
[epoch:102, iter:79203] Loss: 1.410, 10.444, 65.910, 433.174, 1.523
[epoch:102, iter:79223] Loss: 1.408, 10.442, 65.988, 433.145, 0.998
[epoch:102, iter:79243] Loss: 1.409, 10.447, 66.010, 433.244, 1.984
[epoch:102, iter:79263] Loss: 1.410, 10.446, 66.016, 433.450, 0.931
Epoch: [101][300/782]	Time 0.085 (0.079)	Data 0.003 (0.004)	Loss 13.1066 (13.5331)	Acc@1 65.625 (63.403)	Acc@5 87.500 (89.748)
[epoch:102, iter:79283] Loss: 1.410, 10.445, 66.016, 433.628, 1.425
[epoch:102, iter:79303] Loss: 1.408, 10.445, 66.065, 433.709, 1.732
[epoch:102, iter:79323] Loss: 1.408, 10.435, 66.058, 433.717, 1.632
[epoch:102, iter:79343] Loss: 1.408, 10.434, 66.006, 433.653, 1.108
[epoch:102, iter:79363] Loss: 1.408, 10.433, 66.025, 433.568, 1.097
Epoch: [101][400/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 14.0730 (13.5581)	Acc@1 48.438 (62.913)	Acc@5 89.062 (89.639)
[epoch:102, iter:79383] Loss: 1.407, 10.430, 66.046, 433.696, 1.514
[epoch:102, iter:79403] Loss: 1.408, 10.422, 66.063, 433.838, 1.345
[epoch:102, iter:79423] Loss: 1.408, 10.416, 66.027, 433.739, 1.031
[epoch:102, iter:79443] Loss: 1.407, 10.411, 66.070, 433.729, 1.294
[epoch:102, iter:79463] Loss: 1.408, 10.409, 66.047, 433.629, 0.852
Epoch: [101][500/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 14.7906 (13.5451)	Acc@1 59.375 (63.124)	Acc@5 90.625 (89.752)
[epoch:102, iter:79483] Loss: 1.408, 10.408, 66.040, 433.605, 1.506
[epoch:102, iter:79503] Loss: 1.408, 10.407, 66.030, 433.622, 0.927
[epoch:102, iter:79523] Loss: 1.408, 10.415, 66.040, 433.705, 1.628
[epoch:102, iter:79543] Loss: 1.410, 10.419, 66.071, 433.753, 1.114
[epoch:102, iter:79563] Loss: 1.410, 10.420, 66.076, 433.781, 1.826
Epoch: [101][600/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.3097 (13.5694)	Acc@1 64.062 (63.098)	Acc@5 84.375 (89.588)
[epoch:102, iter:79583] Loss: 1.410, 10.422, 66.116, 433.933, 1.396
[epoch:102, iter:79603] Loss: 1.409, 10.420, 66.097, 433.882, 1.234
[epoch:102, iter:79623] Loss: 1.409, 10.416, 66.087, 433.854, 1.500
[epoch:102, iter:79643] Loss: 1.409, 10.412, 66.112, 433.918, 1.880
[epoch:102, iter:79663] Loss: 1.409, 10.414, 66.101, 433.930, 1.587
Epoch: [101][700/782]	Time 0.064 (0.077)	Data 0.002 (0.003)	Loss 13.3693 (13.5647)	Acc@1 60.938 (62.988)	Acc@5 84.375 (89.560)
[epoch:102, iter:79683] Loss: 1.409, 10.418, 66.077, 433.871, 1.617
[epoch:102, iter:79703] Loss: 1.409, 10.418, 66.054, 433.820, 1.635
[epoch:102, iter:79723] Loss: 1.409, 10.416, 66.042, 433.822, 1.499
[epoch:102, iter:79743] Loss: 1.409, 10.412, 66.034, 433.809, 0.803
[epoch:102, iter:79763] Loss: 1.408, 10.409, 66.038, 433.819, 1.266
 * Acc@1 62.922 Acc@5 89.574
epoch 101, total time 60.76
Test: [0/313]	Time 0.273 (0.273)	Loss 3.0721 (3.0721)	Acc@1 53.125 (53.125)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.5175 (2.0794)	Acc@1 46.875 (54.177)	Acc@5 84.375 (83.509)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.1653 (2.0962)	Acc@1 71.875 (53.762)	Acc@5 93.750 (83.504)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4652 (2.1079)	Acc@1 46.875 (54.059)	Acc@5 81.250 (83.347)
 * Acc@1 54.040 Acc@5 83.350
==> training...
Epoch: [102][0/782]	Time 0.475 (0.475)	Data 0.389 (0.389)	Loss 12.6526 (12.6526)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
[epoch:103, iter:79765] Loss: 1.402, 10.299, 65.864, 422.419, 0.946
[epoch:103, iter:79785] Loss: 1.425, 10.553, 66.963, 437.782, 1.419
[epoch:103, iter:79805] Loss: 1.433, 10.595, 66.767, 436.359, 1.564
[epoch:103, iter:79825] Loss: 1.412, 10.547, 66.538, 435.835, 1.183
[epoch:103, iter:79845] Loss: 1.405, 10.507, 66.286, 434.818, 1.072
Epoch: [102][100/782]	Time 0.094 (0.086)	Data 0.003 (0.006)	Loss 14.5823 (13.5254)	Acc@1 54.688 (63.985)	Acc@5 85.938 (89.743)
[epoch:103, iter:79865] Loss: 1.396, 10.469, 65.988, 433.927, 1.770
[epoch:103, iter:79885] Loss: 1.392, 10.431, 66.081, 434.219, 1.411
[epoch:103, iter:79905] Loss: 1.394, 10.423, 66.038, 434.245, 1.472
[epoch:103, iter:79925] Loss: 1.396, 10.400, 66.023, 433.934, 1.231
[epoch:103, iter:79945] Loss: 1.396, 10.388, 65.936, 433.776, 1.133
Epoch: [102][200/782]	Time 0.091 (0.083)	Data 0.003 (0.004)	Loss 13.0329 (13.5301)	Acc@1 60.938 (63.402)	Acc@5 93.750 (89.661)
[epoch:103, iter:79965] Loss: 1.396, 10.384, 65.866, 433.706, 1.264
[epoch:103, iter:79985] Loss: 1.396, 10.379, 65.885, 433.670, 1.105
[epoch:103, iter:80005] Loss: 1.395, 10.370, 65.943, 433.683, 1.440
[epoch:103, iter:80025] Loss: 1.395, 10.372, 65.909, 433.844, 1.289
[epoch:103, iter:80045] Loss: 1.396, 10.370, 65.920, 433.946, 1.133
Epoch: [102][300/782]	Time 0.095 (0.082)	Data 0.003 (0.004)	Loss 12.9689 (13.5570)	Acc@1 60.938 (63.185)	Acc@5 90.625 (89.519)
[epoch:103, iter:80065] Loss: 1.397, 10.375, 65.903, 433.932, 1.110
[epoch:103, iter:80085] Loss: 1.397, 10.379, 65.923, 433.900, 0.913
[epoch:103, iter:80105] Loss: 1.399, 10.381, 65.916, 433.824, 1.536
[epoch:103, iter:80125] Loss: 1.399, 10.381, 65.935, 433.881, 1.517
[epoch:103, iter:80145] Loss: 1.400, 10.379, 65.988, 433.846, 1.288
Epoch: [102][400/782]	Time 0.063 (0.080)	Data 0.002 (0.003)	Loss 13.7434 (13.5449)	Acc@1 62.500 (63.182)	Acc@5 85.938 (89.553)
[epoch:103, iter:80165] Loss: 1.400, 10.389, 65.957, 433.846, 1.554
[epoch:103, iter:80185] Loss: 1.401, 10.389, 65.959, 433.856, 1.275
[epoch:103, iter:80205] Loss: 1.403, 10.386, 65.978, 434.035, 1.520
[epoch:103, iter:80225] Loss: 1.404, 10.389, 65.977, 434.125, 1.162
[epoch:103, iter:80245] Loss: 1.404, 10.386, 65.972, 434.158, 1.245
Epoch: [102][500/782]	Time 0.065 (0.079)	Data 0.002 (0.003)	Loss 13.2115 (13.5519)	Acc@1 70.312 (63.314)	Acc@5 92.188 (89.565)
[epoch:103, iter:80265] Loss: 1.404, 10.380, 65.947, 434.088, 1.149
[epoch:103, iter:80285] Loss: 1.403, 10.379, 65.929, 433.968, 1.550
[epoch:103, iter:80305] Loss: 1.402, 10.373, 65.911, 433.891, 1.181
[epoch:103, iter:80325] Loss: 1.402, 10.375, 65.911, 433.818, 1.368
[epoch:103, iter:80345] Loss: 1.402, 10.376, 65.911, 433.852, 1.535
Epoch: [102][600/782]	Time 0.068 (0.078)	Data 0.002 (0.003)	Loss 12.0783 (13.5350)	Acc@1 73.438 (63.309)	Acc@5 95.312 (89.624)
[epoch:103, iter:80365] Loss: 1.402, 10.373, 65.898, 433.825, 0.898
[epoch:103, iter:80385] Loss: 1.402, 10.373, 65.905, 433.815, 1.296
[epoch:103, iter:80405] Loss: 1.401, 10.372, 65.877, 433.755, 1.190
[epoch:103, iter:80425] Loss: 1.401, 10.365, 65.884, 433.731, 1.539
[epoch:103, iter:80445] Loss: 1.401, 10.366, 65.871, 433.728, 1.348
Epoch: [102][700/782]	Time 0.077 (0.078)	Data 0.002 (0.003)	Loss 13.2236 (13.5336)	Acc@1 60.938 (63.260)	Acc@5 92.188 (89.604)
[epoch:103, iter:80465] Loss: 1.402, 10.371, 65.906, 433.856, 1.095
[epoch:103, iter:80485] Loss: 1.403, 10.374, 65.925, 433.830, 1.283
[epoch:103, iter:80505] Loss: 1.403, 10.376, 65.934, 433.838, 1.959
[epoch:103, iter:80525] Loss: 1.404, 10.380, 65.957, 433.945, 1.553
[epoch:103, iter:80545] Loss: 1.404, 10.377, 65.956, 433.878, 1.300
 * Acc@1 63.260 Acc@5 89.594
epoch 102, total time 61.20
Test: [0/313]	Time 0.243 (0.243)	Loss 1.4746 (1.4746)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.009)	Loss 2.1375 (1.8349)	Acc@1 46.875 (58.014)	Acc@5 87.500 (85.489)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.2147 (1.8207)	Acc@1 62.500 (58.116)	Acc@5 93.750 (85.246)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.9697 (1.8199)	Acc@1 53.125 (58.015)	Acc@5 87.500 (85.486)
 * Acc@1 58.040 Acc@5 85.480
saving the best model!
==> training...
Epoch: [103][0/782]	Time 0.461 (0.461)	Data 0.394 (0.394)	Loss 13.3477 (13.3477)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
[epoch:104, iter:80547] Loss: 1.355, 10.690, 67.421, 433.969, 0.952
[epoch:104, iter:80567] Loss: 1.396, 10.449, 66.822, 434.552, 1.122
[epoch:104, iter:80587] Loss: 1.410, 10.453, 66.164, 433.162, 1.084
[epoch:104, iter:80607] Loss: 1.406, 10.399, 65.769, 431.903, 1.170
[epoch:104, iter:80627] Loss: 1.411, 10.420, 65.850, 432.662, 1.038
Epoch: [103][100/782]	Time 0.062 (0.079)	Data 0.002 (0.006)	Loss 13.7457 (13.4539)	Acc@1 57.812 (63.784)	Acc@5 89.062 (89.991)
[epoch:104, iter:80647] Loss: 1.407, 10.416, 65.795, 432.456, 1.492
[epoch:104, iter:80667] Loss: 1.405, 10.421, 65.713, 431.927, 1.259
[epoch:104, iter:80687] Loss: 1.402, 10.410, 65.708, 432.370, 1.020
[epoch:104, iter:80707] Loss: 1.402, 10.409, 65.733, 432.721, 1.231
[epoch:104, iter:80727] Loss: 1.404, 10.415, 65.827, 433.122, 1.399
Epoch: [103][200/782]	Time 0.071 (0.078)	Data 0.002 (0.004)	Loss 12.7899 (13.5002)	Acc@1 64.062 (63.604)	Acc@5 95.312 (90.096)
[epoch:104, iter:80747] Loss: 1.403, 10.422, 65.916, 433.266, 1.142
[epoch:104, iter:80767] Loss: 1.404, 10.429, 65.883, 433.410, 1.412
[epoch:104, iter:80787] Loss: 1.403, 10.425, 65.874, 433.476, 1.533
[epoch:104, iter:80807] Loss: 1.402, 10.430, 65.884, 433.393, 1.370
[epoch:104, iter:80827] Loss: 1.403, 10.422, 65.942, 433.393, 1.607
Epoch: [103][300/782]	Time 0.088 (0.077)	Data 0.003 (0.004)	Loss 14.0681 (13.5280)	Acc@1 57.812 (63.419)	Acc@5 87.500 (89.846)
[epoch:104, iter:80847] Loss: 1.402, 10.412, 65.947, 433.370, 1.627
[epoch:104, iter:80867] Loss: 1.402, 10.415, 65.979, 433.417, 1.240
[epoch:104, iter:80887] Loss: 1.401, 10.410, 65.962, 433.498, 1.047
[epoch:104, iter:80907] Loss: 1.402, 10.416, 65.977, 433.580, 1.507
[epoch:104, iter:80927] Loss: 1.401, 10.410, 65.978, 433.621, 1.345
Epoch: [103][400/782]	Time 0.078 (0.078)	Data 0.003 (0.003)	Loss 12.5866 (13.5538)	Acc@1 70.312 (63.186)	Acc@5 98.438 (89.713)
[epoch:104, iter:80947] Loss: 1.401, 10.407, 66.021, 433.704, 1.052
[epoch:104, iter:80967] Loss: 1.400, 10.409, 65.986, 433.612, 1.514
[epoch:104, iter:80987] Loss: 1.399, 10.402, 65.991, 433.674, 1.184
[epoch:104, iter:81007] Loss: 1.400, 10.406, 65.982, 433.733, 1.502
[epoch:104, iter:81027] Loss: 1.401, 10.406, 65.979, 433.773, 1.216
Epoch: [103][500/782]	Time 0.088 (0.079)	Data 0.003 (0.003)	Loss 13.7259 (13.5523)	Acc@1 60.938 (63.214)	Acc@5 79.688 (89.692)
[epoch:104, iter:81047] Loss: 1.402, 10.403, 65.970, 433.739, 1.538
[epoch:104, iter:81067] Loss: 1.403, 10.410, 65.998, 433.827, 1.629
[epoch:104, iter:81087] Loss: 1.403, 10.409, 65.984, 433.765, 1.748
[epoch:104, iter:81107] Loss: 1.402, 10.405, 65.983, 433.632, 0.936
[epoch:104, iter:81127] Loss: 1.402, 10.402, 65.982, 433.661, 1.734
Epoch: [103][600/782]	Time 0.059 (0.078)	Data 0.002 (0.003)	Loss 13.7742 (13.5554)	Acc@1 65.625 (63.134)	Acc@5 85.938 (89.653)
[epoch:104, iter:81147] Loss: 1.402, 10.398, 65.985, 433.663, 1.482
[epoch:104, iter:81167] Loss: 1.403, 10.398, 66.002, 433.614, 1.494
[epoch:104, iter:81187] Loss: 1.403, 10.400, 66.035, 433.635, 1.100
[epoch:104, iter:81207] Loss: 1.403, 10.398, 66.041, 433.675, 1.068
[epoch:104, iter:81227] Loss: 1.404, 10.399, 66.045, 433.668, 1.416
Epoch: [103][700/782]	Time 0.090 (0.078)	Data 0.003 (0.003)	Loss 13.4726 (13.5528)	Acc@1 60.938 (63.088)	Acc@5 87.500 (89.651)
[epoch:104, iter:81247] Loss: 1.403, 10.397, 66.017, 433.601, 1.338
[epoch:104, iter:81267] Loss: 1.402, 10.399, 66.011, 433.542, 1.293
[epoch:104, iter:81287] Loss: 1.402, 10.397, 66.013, 433.591, 1.272
[epoch:104, iter:81307] Loss: 1.402, 10.395, 66.019, 433.638, 1.185
[epoch:104, iter:81327] Loss: 1.402, 10.394, 66.006, 433.573, 1.372
 * Acc@1 62.992 Acc@5 89.580
epoch 103, total time 60.03
Test: [0/313]	Time 0.211 (0.211)	Loss 2.7694 (2.7694)	Acc@1 56.250 (56.250)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.1480 (1.9709)	Acc@1 46.875 (55.941)	Acc@5 90.625 (84.189)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.3915 (1.9486)	Acc@1 62.500 (55.690)	Acc@5 93.750 (84.266)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.0844 (1.9596)	Acc@1 40.625 (55.264)	Acc@5 75.000 (84.167)
 * Acc@1 55.320 Acc@5 84.200
==> training...
Epoch: [104][0/782]	Time 0.512 (0.512)	Data 0.438 (0.438)	Loss 13.2747 (13.2747)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
[epoch:105, iter:81329] Loss: 1.405, 10.527, 67.311, 438.284, 1.100
[epoch:105, iter:81349] Loss: 1.397, 10.359, 65.645, 434.525, 1.217
[epoch:105, iter:81369] Loss: 1.389, 10.342, 66.077, 434.768, 1.169
[epoch:105, iter:81389] Loss: 1.380, 10.335, 66.001, 433.181, 1.137
[epoch:105, iter:81409] Loss: 1.375, 10.308, 65.761, 432.740, 1.014
Epoch: [104][100/782]	Time 0.080 (0.083)	Data 0.002 (0.007)	Loss 14.2052 (13.4007)	Acc@1 53.125 (64.310)	Acc@5 82.812 (89.635)
[epoch:105, iter:81429] Loss: 1.373, 10.303, 65.679, 432.582, 1.681
[epoch:105, iter:81449] Loss: 1.378, 10.300, 65.638, 432.967, 1.037
[epoch:105, iter:81469] Loss: 1.377, 10.296, 65.639, 432.626, 1.512
[epoch:105, iter:81489] Loss: 1.383, 10.297, 65.657, 432.518, 1.205
[epoch:105, iter:81509] Loss: 1.384, 10.296, 65.656, 432.362, 1.390
Epoch: [104][200/782]	Time 0.074 (0.080)	Data 0.002 (0.004)	Loss 13.9872 (13.4261)	Acc@1 65.625 (63.557)	Acc@5 85.938 (89.832)
[epoch:105, iter:81529] Loss: 1.387, 10.296, 65.793, 432.401, 1.449
[epoch:105, iter:81549] Loss: 1.389, 10.313, 65.771, 432.242, 1.398
[epoch:105, iter:81569] Loss: 1.392, 10.333, 65.794, 432.552, 1.464
[epoch:105, iter:81589] Loss: 1.392, 10.331, 65.818, 432.775, 2.192
[epoch:105, iter:81609] Loss: 1.393, 10.338, 65.850, 433.063, 1.145
Epoch: [104][300/782]	Time 0.088 (0.080)	Data 0.003 (0.004)	Loss 13.0676 (13.4720)	Acc@1 64.062 (63.201)	Acc@5 89.062 (89.768)
[epoch:105, iter:81629] Loss: 1.393, 10.342, 65.798, 432.946, 1.225
[epoch:105, iter:81649] Loss: 1.394, 10.345, 65.860, 433.061, 1.189
[epoch:105, iter:81669] Loss: 1.394, 10.350, 65.874, 433.049, 0.820
[epoch:105, iter:81689] Loss: 1.395, 10.345, 65.827, 433.067, 1.552
[epoch:105, iter:81709] Loss: 1.395, 10.350, 65.827, 433.134, 0.808
Epoch: [104][400/782]	Time 0.091 (0.080)	Data 0.003 (0.003)	Loss 13.8195 (13.4804)	Acc@1 53.125 (63.482)	Acc@5 90.625 (89.690)
[epoch:105, iter:81729] Loss: 1.396, 10.352, 65.860, 433.121, 1.498
[epoch:105, iter:81749] Loss: 1.397, 10.361, 65.895, 433.271, 1.065
[epoch:105, iter:81769] Loss: 1.397, 10.366, 65.903, 433.324, 1.494
[epoch:105, iter:81789] Loss: 1.397, 10.368, 65.893, 433.403, 1.247
[epoch:105, iter:81809] Loss: 1.396, 10.368, 65.881, 433.433, 1.350
Epoch: [104][500/782]	Time 0.090 (0.080)	Data 0.003 (0.003)	Loss 13.4583 (13.5123)	Acc@1 71.875 (63.199)	Acc@5 92.188 (89.630)
[epoch:105, iter:81829] Loss: 1.397, 10.369, 65.916, 433.539, 1.133
[epoch:105, iter:81849] Loss: 1.398, 10.366, 65.956, 433.663, 1.379
[epoch:105, iter:81869] Loss: 1.398, 10.365, 65.983, 433.813, 1.387
[epoch:105, iter:81889] Loss: 1.397, 10.362, 65.981, 433.780, 1.332
[epoch:105, iter:81909] Loss: 1.396, 10.360, 65.956, 433.676, 1.332
Epoch: [104][600/782]	Time 0.089 (0.080)	Data 0.003 (0.003)	Loss 13.7852 (13.5154)	Acc@1 64.062 (63.275)	Acc@5 93.750 (89.673)
[epoch:105, iter:81929] Loss: 1.395, 10.358, 65.973, 433.709, 1.207
[epoch:105, iter:81949] Loss: 1.396, 10.356, 65.986, 433.712, 1.753
[epoch:105, iter:81969] Loss: 1.397, 10.357, 66.002, 433.672, 1.171
[epoch:105, iter:81989] Loss: 1.396, 10.358, 65.991, 433.630, 1.206
[epoch:105, iter:82009] Loss: 1.395, 10.355, 65.952, 433.544, 1.400
Epoch: [104][700/782]	Time 0.090 (0.080)	Data 0.003 (0.003)	Loss 13.7817 (13.5170)	Acc@1 57.812 (63.028)	Acc@5 95.312 (89.720)
[epoch:105, iter:82029] Loss: 1.395, 10.352, 65.937, 433.480, 1.011
[epoch:105, iter:82049] Loss: 1.394, 10.350, 65.934, 433.421, 1.068
[epoch:105, iter:82069] Loss: 1.394, 10.349, 65.947, 433.487, 1.282
[epoch:105, iter:82089] Loss: 1.395, 10.349, 65.956, 433.504, 1.916
[epoch:105, iter:82109] Loss: 1.394, 10.347, 65.951, 433.508, 1.404
 * Acc@1 63.068 Acc@5 89.720
epoch 104, total time 62.70
Test: [0/313]	Time 0.255 (0.255)	Loss 2.0359 (2.0359)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.6210 (2.0364)	Acc@1 43.750 (54.765)	Acc@5 84.375 (83.261)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.3030 (1.9957)	Acc@1 65.625 (55.224)	Acc@5 90.625 (83.489)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.3917 (1.9893)	Acc@1 53.125 (55.409)	Acc@5 78.125 (83.503)
 * Acc@1 55.440 Acc@5 83.530
==> training...
Epoch: [105][0/782]	Time 0.576 (0.576)	Data 0.488 (0.488)	Loss 13.5800 (13.5800)	Acc@1 64.062 (64.062)	Acc@5 84.375 (84.375)
[epoch:106, iter:82111] Loss: 1.373, 10.606, 66.897, 433.913, 1.538
[epoch:106, iter:82131] Loss: 1.406, 10.373, 66.475, 435.121, 1.165
[epoch:106, iter:82151] Loss: 1.392, 10.421, 66.162, 434.106, 1.339
[epoch:106, iter:82171] Loss: 1.391, 10.381, 65.935, 432.928, 1.395
[epoch:106, iter:82191] Loss: 1.394, 10.341, 65.744, 432.068, 1.851
Epoch: [105][100/782]	Time 0.088 (0.080)	Data 0.003 (0.007)	Loss 13.3880 (13.4296)	Acc@1 68.750 (62.856)	Acc@5 87.500 (89.264)
[epoch:106, iter:82211] Loss: 1.400, 10.346, 65.973, 432.512, 1.383
[epoch:106, iter:82231] Loss: 1.398, 10.342, 66.051, 432.502, 0.830
[epoch:106, iter:82251] Loss: 1.397, 10.345, 65.861, 431.928, 0.926
[epoch:106, iter:82271] Loss: 1.396, 10.328, 65.725, 432.019, 1.425
[epoch:106, iter:82291] Loss: 1.397, 10.326, 65.647, 431.977, 1.396
Epoch: [105][200/782]	Time 0.073 (0.079)	Data 0.002 (0.005)	Loss 13.9484 (13.4129)	Acc@1 62.500 (63.161)	Acc@5 89.062 (89.653)
[epoch:106, iter:82311] Loss: 1.395, 10.330, 65.613, 432.106, 1.478
[epoch:106, iter:82331] Loss: 1.394, 10.332, 65.585, 432.077, 1.267
[epoch:106, iter:82351] Loss: 1.392, 10.328, 65.713, 432.297, 1.163
[epoch:106, iter:82371] Loss: 1.392, 10.326, 65.745, 432.320, 1.124
[epoch:106, iter:82391] Loss: 1.397, 10.338, 65.744, 432.355, 0.881
Epoch: [105][300/782]	Time 0.084 (0.078)	Data 0.002 (0.004)	Loss 13.9984 (13.4375)	Acc@1 62.500 (63.232)	Acc@5 85.938 (89.774)
[epoch:106, iter:82411] Loss: 1.396, 10.336, 65.705, 432.402, 1.507
[epoch:106, iter:82431] Loss: 1.395, 10.339, 65.675, 432.337, 1.173
[epoch:106, iter:82451] Loss: 1.396, 10.343, 65.728, 432.272, 1.633
[epoch:106, iter:82471] Loss: 1.395, 10.339, 65.691, 431.985, 1.170
[epoch:106, iter:82491] Loss: 1.394, 10.340, 65.674, 432.030, 1.587
Epoch: [105][400/782]	Time 0.071 (0.078)	Data 0.002 (0.004)	Loss 14.1001 (13.4499)	Acc@1 64.062 (63.077)	Acc@5 89.062 (89.740)
[epoch:106, iter:82511] Loss: 1.394, 10.338, 65.672, 432.207, 1.341
[epoch:106, iter:82531] Loss: 1.393, 10.342, 65.662, 432.211, 1.046
[epoch:106, iter:82551] Loss: 1.392, 10.339, 65.687, 432.330, 1.306
[epoch:106, iter:82571] Loss: 1.393, 10.336, 65.729, 432.444, 0.906
[epoch:106, iter:82591] Loss: 1.394, 10.337, 65.784, 432.580, 1.974
Epoch: [105][500/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 14.4446 (13.4847)	Acc@1 54.688 (62.958)	Acc@5 84.375 (89.668)
[epoch:106, iter:82611] Loss: 1.395, 10.341, 65.828, 432.717, 1.580
[epoch:106, iter:82631] Loss: 1.396, 10.346, 65.863, 432.786, 1.356
[epoch:106, iter:82651] Loss: 1.396, 10.351, 65.842, 432.726, 1.489
[epoch:106, iter:82671] Loss: 1.395, 10.349, 65.839, 432.662, 1.834
[epoch:106, iter:82691] Loss: 1.394, 10.348, 65.828, 432.677, 1.417
Epoch: [105][600/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 14.8699 (13.4787)	Acc@1 56.250 (63.051)	Acc@5 82.812 (89.770)
[epoch:106, iter:82711] Loss: 1.394, 10.346, 65.852, 432.786, 1.648
[epoch:106, iter:82731] Loss: 1.394, 10.346, 65.866, 432.870, 1.561
[epoch:106, iter:82751] Loss: 1.394, 10.347, 65.877, 432.984, 1.495
[epoch:106, iter:82771] Loss: 1.394, 10.346, 65.885, 432.997, 1.545
[epoch:106, iter:82791] Loss: 1.395, 10.346, 65.881, 432.933, 1.575
Epoch: [105][700/782]	Time 0.077 (0.076)	Data 0.002 (0.003)	Loss 13.4507 (13.5010)	Acc@1 59.375 (63.068)	Acc@5 87.500 (89.756)
[epoch:106, iter:82811] Loss: 1.395, 10.346, 65.880, 432.985, 1.589
[epoch:106, iter:82831] Loss: 1.395, 10.343, 65.885, 433.050, 1.480
[epoch:106, iter:82851] Loss: 1.394, 10.345, 65.885, 433.142, 0.860
[epoch:106, iter:82871] Loss: 1.395, 10.347, 65.904, 433.242, 1.408
[epoch:106, iter:82891] Loss: 1.395, 10.348, 65.895, 433.305, 1.687
 * Acc@1 62.942 Acc@5 89.678
epoch 105, total time 60.09
Test: [0/313]	Time 0.264 (0.264)	Loss 2.0796 (2.0796)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.2216 (2.1032)	Acc@1 53.125 (54.053)	Acc@5 84.375 (83.014)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.8206 (2.0967)	Acc@1 65.625 (54.415)	Acc@5 81.250 (83.225)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.7229 (2.1019)	Acc@1 43.750 (54.662)	Acc@5 71.875 (83.254)
 * Acc@1 54.790 Acc@5 83.290
==> training...
Epoch: [106][0/782]	Time 0.593 (0.593)	Data 0.516 (0.516)	Loss 13.6782 (13.6782)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
[epoch:107, iter:82893] Loss: 1.367, 10.699, 66.585, 443.264, 1.528
[epoch:107, iter:82913] Loss: 1.420, 10.541, 66.107, 435.579, 1.468
[epoch:107, iter:82933] Loss: 1.418, 10.538, 65.952, 434.094, 1.105
[epoch:107, iter:82953] Loss: 1.412, 10.477, 65.785, 433.056, 1.099
[epoch:107, iter:82973] Loss: 1.404, 10.443, 65.766, 432.330, 1.559
Epoch: [106][100/782]	Time 0.063 (0.083)	Data 0.002 (0.007)	Loss 12.2801 (13.4448)	Acc@1 59.375 (62.794)	Acc@5 90.625 (90.377)
[epoch:107, iter:82993] Loss: 1.402, 10.417, 65.715, 431.766, 1.088
[epoch:107, iter:83013] Loss: 1.405, 10.410, 65.686, 431.564, 1.793
[epoch:107, iter:83033] Loss: 1.404, 10.415, 65.694, 431.563, 1.563
[epoch:107, iter:83053] Loss: 1.405, 10.406, 65.881, 431.851, 1.008
[epoch:107, iter:83073] Loss: 1.404, 10.402, 65.911, 431.763, 1.251
Epoch: [106][200/782]	Time 0.078 (0.080)	Data 0.003 (0.005)	Loss 14.0288 (13.5049)	Acc@1 57.812 (62.811)	Acc@5 82.812 (90.166)
[epoch:107, iter:83093] Loss: 1.409, 10.412, 66.052, 432.100, 1.564
[epoch:107, iter:83113] Loss: 1.409, 10.405, 66.060, 432.404, 1.230
[epoch:107, iter:83133] Loss: 1.408, 10.411, 66.094, 432.605, 2.053
[epoch:107, iter:83153] Loss: 1.407, 10.410, 66.116, 432.679, 1.360
[epoch:107, iter:83173] Loss: 1.404, 10.412, 66.051, 432.610, 1.551
Epoch: [106][300/782]	Time 0.095 (0.078)	Data 0.003 (0.004)	Loss 13.4906 (13.5384)	Acc@1 65.625 (62.915)	Acc@5 90.625 (89.826)
[epoch:107, iter:83193] Loss: 1.405, 10.416, 66.094, 432.827, 1.223
[epoch:107, iter:83213] Loss: 1.406, 10.414, 66.140, 432.803, 1.240
[epoch:107, iter:83233] Loss: 1.405, 10.412, 66.110, 432.772, 1.250
[epoch:107, iter:83253] Loss: 1.406, 10.415, 66.194, 432.943, 1.055
[epoch:107, iter:83273] Loss: 1.407, 10.410, 66.161, 432.772, 1.684
Epoch: [106][400/782]	Time 0.058 (0.078)	Data 0.002 (0.004)	Loss 13.1135 (13.5329)	Acc@1 68.750 (63.061)	Acc@5 93.750 (89.873)
[epoch:107, iter:83293] Loss: 1.407, 10.408, 66.193, 432.840, 1.146
[epoch:107, iter:83313] Loss: 1.407, 10.408, 66.169, 432.987, 1.444
[epoch:107, iter:83333] Loss: 1.408, 10.411, 66.195, 433.176, 1.649
[epoch:107, iter:83353] Loss: 1.409, 10.414, 66.159, 433.228, 0.882
[epoch:107, iter:83373] Loss: 1.408, 10.415, 66.128, 433.249, 1.319
Epoch: [106][500/782]	Time 0.095 (0.076)	Data 0.002 (0.003)	Loss 13.9676 (13.5331)	Acc@1 56.250 (63.021)	Acc@5 84.375 (89.839)
[epoch:107, iter:83393] Loss: 1.406, 10.413, 66.143, 433.255, 1.533
[epoch:107, iter:83413] Loss: 1.408, 10.420, 66.184, 433.476, 1.449
[epoch:107, iter:83433] Loss: 1.409, 10.429, 66.212, 433.718, 0.992
[epoch:107, iter:83453] Loss: 1.408, 10.430, 66.201, 433.680, 1.152
[epoch:107, iter:83473] Loss: 1.408, 10.427, 66.200, 433.641, 1.326
Epoch: [106][600/782]	Time 0.092 (0.076)	Data 0.003 (0.003)	Loss 13.0684 (13.5499)	Acc@1 59.375 (62.882)	Acc@5 95.312 (89.741)
[epoch:107, iter:83493] Loss: 1.408, 10.425, 66.168, 433.586, 1.345
[epoch:107, iter:83513] Loss: 1.407, 10.423, 66.146, 433.567, 0.960
[epoch:107, iter:83533] Loss: 1.407, 10.422, 66.156, 433.494, 1.309
[epoch:107, iter:83553] Loss: 1.406, 10.420, 66.149, 433.535, 1.487
[epoch:107, iter:83573] Loss: 1.406, 10.415, 66.128, 433.569, 1.096
Epoch: [106][700/782]	Time 0.073 (0.076)	Data 0.002 (0.003)	Loss 13.3606 (13.5548)	Acc@1 59.375 (62.866)	Acc@5 90.625 (89.651)
[epoch:107, iter:83593] Loss: 1.405, 10.414, 66.135, 433.602, 1.500
[epoch:107, iter:83613] Loss: 1.405, 10.411, 66.119, 433.592, 1.186
[epoch:107, iter:83633] Loss: 1.406, 10.417, 66.132, 433.693, 1.537
[epoch:107, iter:83653] Loss: 1.406, 10.416, 66.114, 433.720, 1.238
[epoch:107, iter:83673] Loss: 1.406, 10.416, 66.128, 433.776, 1.123
 * Acc@1 62.770 Acc@5 89.640
epoch 106, total time 59.61
Test: [0/313]	Time 0.225 (0.225)	Loss 1.8194 (1.8194)	Acc@1 65.625 (65.625)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.8383 (1.8249)	Acc@1 50.000 (57.024)	Acc@5 87.500 (86.386)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.2470 (1.8270)	Acc@1 62.500 (56.779)	Acc@5 93.750 (86.210)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.6979 (1.8267)	Acc@1 56.250 (56.831)	Acc@5 87.500 (86.015)
 * Acc@1 56.860 Acc@5 86.090
==> training...
Epoch: [107][0/782]	Time 0.486 (0.486)	Data 0.397 (0.397)	Loss 14.0009 (14.0009)	Acc@1 54.688 (54.688)	Acc@5 82.812 (82.812)
[epoch:108, iter:83675] Loss: 1.320, 10.099, 69.173, 439.458, 1.745
[epoch:108, iter:83695] Loss: 1.412, 10.372, 66.889, 434.277, 1.260
[epoch:108, iter:83715] Loss: 1.409, 10.441, 66.208, 432.571, 1.093
[epoch:108, iter:83735] Loss: 1.403, 10.410, 65.822, 431.201, 1.493
[epoch:108, iter:83755] Loss: 1.404, 10.371, 65.927, 431.637, 1.278
Epoch: [107][100/782]	Time 0.083 (0.082)	Data 0.002 (0.006)	Loss 13.5344 (13.4257)	Acc@1 67.188 (63.196)	Acc@5 92.188 (90.439)
[epoch:108, iter:83775] Loss: 1.396, 10.372, 65.967, 432.382, 1.190
[epoch:108, iter:83795] Loss: 1.397, 10.366, 65.885, 432.346, 1.407
[epoch:108, iter:83815] Loss: 1.395, 10.373, 65.870, 432.731, 1.339
[epoch:108, iter:83835] Loss: 1.398, 10.378, 65.954, 432.975, 1.489
[epoch:108, iter:83855] Loss: 1.400, 10.390, 66.044, 433.210, 1.305
Epoch: [107][200/782]	Time 0.070 (0.080)	Data 0.002 (0.004)	Loss 13.7318 (13.4377)	Acc@1 68.750 (63.650)	Acc@5 95.312 (90.376)
[epoch:108, iter:83875] Loss: 1.399, 10.401, 65.963, 433.154, 1.151
[epoch:108, iter:83895] Loss: 1.399, 10.393, 65.962, 433.212, 1.463
[epoch:108, iter:83915] Loss: 1.399, 10.392, 66.055, 433.496, 1.438
[epoch:108, iter:83935] Loss: 1.398, 10.383, 66.068, 433.235, 0.948
[epoch:108, iter:83955] Loss: 1.398, 10.382, 65.965, 432.996, 1.257
Epoch: [107][300/782]	Time 0.074 (0.080)	Data 0.002 (0.004)	Loss 13.8377 (13.4237)	Acc@1 57.812 (64.026)	Acc@5 82.812 (90.236)
[epoch:108, iter:83975] Loss: 1.397, 10.376, 65.908, 432.864, 1.504
[epoch:108, iter:83995] Loss: 1.397, 10.374, 65.831, 432.629, 1.327
[epoch:108, iter:84015] Loss: 1.399, 10.379, 65.844, 432.726, 1.377
[epoch:108, iter:84035] Loss: 1.399, 10.381, 65.813, 432.734, 1.364
[epoch:108, iter:84055] Loss: 1.398, 10.384, 65.818, 432.907, 1.162
Epoch: [107][400/782]	Time 0.092 (0.079)	Data 0.003 (0.003)	Loss 14.5490 (13.4551)	Acc@1 59.375 (63.579)	Acc@5 87.500 (90.111)
[epoch:108, iter:84075] Loss: 1.400, 10.388, 65.849, 433.117, 1.815
[epoch:108, iter:84095] Loss: 1.402, 10.389, 65.865, 433.220, 0.938
[epoch:108, iter:84115] Loss: 1.401, 10.390, 65.889, 433.215, 0.942
[epoch:108, iter:84135] Loss: 1.401, 10.386, 65.923, 433.271, 1.444
[epoch:108, iter:84155] Loss: 1.401, 10.386, 65.941, 433.253, 1.088
Epoch: [107][500/782]	Time 0.086 (0.080)	Data 0.003 (0.003)	Loss 14.0380 (13.4740)	Acc@1 53.125 (63.373)	Acc@5 93.750 (89.951)
[epoch:108, iter:84175] Loss: 1.400, 10.382, 65.900, 433.077, 1.538
[epoch:108, iter:84195] Loss: 1.400, 10.382, 65.903, 433.082, 0.969
[epoch:108, iter:84215] Loss: 1.399, 10.378, 65.913, 432.967, 1.721
[epoch:108, iter:84235] Loss: 1.401, 10.377, 65.944, 433.000, 1.310
[epoch:108, iter:84255] Loss: 1.401, 10.377, 65.945, 432.995, 1.117
Epoch: [107][600/782]	Time 0.076 (0.080)	Data 0.002 (0.003)	Loss 12.9527 (13.4757)	Acc@1 67.188 (63.316)	Acc@5 96.875 (90.019)
[epoch:108, iter:84275] Loss: 1.401, 10.374, 65.920, 432.973, 0.995
[epoch:108, iter:84295] Loss: 1.401, 10.376, 65.923, 433.016, 1.573
[epoch:108, iter:84315] Loss: 1.400, 10.378, 65.934, 433.077, 1.366
[epoch:108, iter:84335] Loss: 1.401, 10.383, 65.947, 433.116, 1.365
[epoch:108, iter:84355] Loss: 1.401, 10.386, 65.964, 433.190, 1.194
Epoch: [107][700/782]	Time 0.092 (0.079)	Data 0.002 (0.003)	Loss 13.2046 (13.5136)	Acc@1 64.062 (63.082)	Acc@5 93.750 (89.843)
[epoch:108, iter:84375] Loss: 1.401, 10.390, 65.966, 433.315, 1.253
[epoch:108, iter:84395] Loss: 1.401, 10.391, 65.957, 433.340, 1.386
[epoch:108, iter:84415] Loss: 1.403, 10.392, 65.997, 433.461, 1.748
[epoch:108, iter:84435] Loss: 1.403, 10.392, 66.001, 433.399, 1.300
[epoch:108, iter:84455] Loss: 1.403, 10.393, 66.002, 433.392, 1.713
 * Acc@1 62.964 Acc@5 89.706
epoch 107, total time 61.76
Test: [0/313]	Time 0.255 (0.255)	Loss 1.4562 (1.4562)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.8587 (2.1892)	Acc@1 50.000 (53.837)	Acc@5 93.750 (83.694)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8088 (2.0971)	Acc@1 68.750 (54.415)	Acc@5 93.750 (83.940)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.2973 (2.1200)	Acc@1 31.250 (54.194)	Acc@5 87.500 (83.814)
 * Acc@1 54.150 Acc@5 83.890
==> training...
Epoch: [108][0/782]	Time 0.520 (0.520)	Data 0.428 (0.428)	Loss 12.9453 (12.9453)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
[epoch:109, iter:84457] Loss: 1.436, 10.088, 65.512, 419.911, 1.155
[epoch:109, iter:84477] Loss: 1.385, 10.496, 65.983, 433.028, 1.060
[epoch:109, iter:84497] Loss: 1.385, 10.407, 65.828, 432.390, 1.273
[epoch:109, iter:84517] Loss: 1.400, 10.458, 66.430, 434.164, 1.362
[epoch:109, iter:84537] Loss: 1.398, 10.480, 66.684, 434.653, 1.540
Epoch: [108][100/782]	Time 0.060 (0.082)	Data 0.002 (0.007)	Loss 13.2011 (13.5830)	Acc@1 62.500 (63.567)	Acc@5 89.062 (90.114)
[epoch:109, iter:84557] Loss: 1.400, 10.465, 66.672, 434.713, 1.254
[epoch:109, iter:84577] Loss: 1.401, 10.489, 66.687, 434.681, 1.125
[epoch:109, iter:84597] Loss: 1.402, 10.479, 66.616, 434.614, 1.335
[epoch:109, iter:84617] Loss: 1.398, 10.436, 66.404, 434.018, 1.319
[epoch:109, iter:84637] Loss: 1.397, 10.419, 66.339, 434.192, 1.303
Epoch: [108][200/782]	Time 0.061 (0.080)	Data 0.002 (0.004)	Loss 14.0872 (13.5460)	Acc@1 64.062 (62.819)	Acc@5 84.375 (89.863)
[epoch:109, iter:84657] Loss: 1.398, 10.411, 66.289, 433.951, 1.685
[epoch:109, iter:84677] Loss: 1.399, 10.413, 66.217, 433.628, 1.425
[epoch:109, iter:84697] Loss: 1.399, 10.411, 66.212, 433.730, 1.395
[epoch:109, iter:84717] Loss: 1.400, 10.409, 66.221, 433.624, 1.387
[epoch:109, iter:84737] Loss: 1.401, 10.403, 66.269, 433.607, 1.000
Epoch: [108][300/782]	Time 0.091 (0.079)	Data 0.003 (0.004)	Loss 13.2449 (13.5530)	Acc@1 64.062 (63.004)	Acc@5 95.312 (89.628)
[epoch:109, iter:84757] Loss: 1.402, 10.405, 66.274, 433.608, 1.206
[epoch:109, iter:84777] Loss: 1.402, 10.407, 66.289, 433.708, 1.126
[epoch:109, iter:84797] Loss: 1.403, 10.401, 66.345, 433.677, 1.495
[epoch:109, iter:84817] Loss: 1.403, 10.397, 66.367, 433.785, 1.403
[epoch:109, iter:84837] Loss: 1.403, 10.403, 66.388, 433.857, 1.805
Epoch: [108][400/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 13.1794 (13.5822)	Acc@1 59.375 (62.882)	Acc@5 85.938 (89.573)
[epoch:109, iter:84857] Loss: 1.405, 10.404, 66.417, 433.964, 1.592
[epoch:109, iter:84877] Loss: 1.405, 10.403, 66.400, 433.995, 1.477
[epoch:109, iter:84897] Loss: 1.406, 10.408, 66.376, 433.919, 1.730
[epoch:109, iter:84917] Loss: 1.405, 10.407, 66.370, 433.983, 1.148
[epoch:109, iter:84937] Loss: 1.404, 10.408, 66.359, 434.024, 1.488
Epoch: [108][500/782]	Time 0.059 (0.077)	Data 0.002 (0.003)	Loss 13.2481 (13.5850)	Acc@1 57.812 (62.968)	Acc@5 84.375 (89.705)
[epoch:109, iter:84957] Loss: 1.405, 10.409, 66.342, 433.990, 1.509
[epoch:109, iter:84977] Loss: 1.404, 10.403, 66.268, 433.791, 1.619
[epoch:109, iter:84997] Loss: 1.404, 10.400, 66.263, 433.792, 1.179
[epoch:109, iter:85017] Loss: 1.403, 10.401, 66.251, 433.688, 0.932
[epoch:109, iter:85037] Loss: 1.403, 10.396, 66.233, 433.584, 0.910
Epoch: [108][600/782]	Time 0.086 (0.077)	Data 0.003 (0.003)	Loss 13.7117 (13.5710)	Acc@1 60.938 (62.965)	Acc@5 90.625 (89.684)
[epoch:109, iter:85057] Loss: 1.403, 10.395, 66.219, 433.585, 1.551
[epoch:109, iter:85077] Loss: 1.404, 10.396, 66.204, 433.587, 1.420
[epoch:109, iter:85097] Loss: 1.404, 10.392, 66.185, 433.550, 1.271
[epoch:109, iter:85117] Loss: 1.405, 10.394, 66.186, 433.592, 1.226
[epoch:109, iter:85137] Loss: 1.405, 10.393, 66.198, 433.672, 1.215
Epoch: [108][700/782]	Time 0.086 (0.077)	Data 0.002 (0.003)	Loss 14.0527 (13.5762)	Acc@1 50.000 (62.870)	Acc@5 84.375 (89.698)
[epoch:109, iter:85157] Loss: 1.405, 10.391, 66.202, 433.661, 1.612
[epoch:109, iter:85177] Loss: 1.405, 10.392, 66.223, 433.732, 1.755
[epoch:109, iter:85197] Loss: 1.405, 10.398, 66.246, 433.840, 1.707
[epoch:109, iter:85217] Loss: 1.405, 10.402, 66.253, 433.902, 1.145
[epoch:109, iter:85237] Loss: 1.406, 10.404, 66.280, 434.036, 0.940
 * Acc@1 62.774 Acc@5 89.592
epoch 108, total time 60.33
Test: [0/313]	Time 0.242 (0.242)	Loss 1.9716 (1.9716)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.0098 (1.9892)	Acc@1 62.500 (56.559)	Acc@5 87.500 (84.499)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7916 (1.9380)	Acc@1 65.625 (56.374)	Acc@5 87.500 (84.779)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8256 (1.9478)	Acc@1 43.750 (56.198)	Acc@5 78.125 (84.697)
 * Acc@1 56.280 Acc@5 84.700
==> training...
Epoch: [109][0/782]	Time 0.547 (0.547)	Data 0.459 (0.459)	Loss 14.0361 (14.0361)	Acc@1 54.688 (54.688)	Acc@5 85.938 (85.938)
[epoch:110, iter:85239] Loss: 1.378, 10.496, 69.023, 432.228, 1.601
[epoch:110, iter:85259] Loss: 1.441, 10.454, 66.796, 433.907, 1.471
[epoch:110, iter:85279] Loss: 1.439, 10.423, 65.972, 432.564, 1.032
[epoch:110, iter:85299] Loss: 1.418, 10.394, 65.847, 432.331, 1.163
[epoch:110, iter:85319] Loss: 1.411, 10.372, 65.972, 432.218, 1.140
Epoch: [109][100/782]	Time 0.070 (0.079)	Data 0.002 (0.007)	Loss 13.6345 (13.4993)	Acc@1 62.500 (63.150)	Acc@5 92.188 (89.635)
[epoch:110, iter:85339] Loss: 1.410, 10.386, 66.134, 432.656, 1.250
[epoch:110, iter:85359] Loss: 1.407, 10.387, 66.197, 432.649, 1.334
[epoch:110, iter:85379] Loss: 1.409, 10.399, 66.195, 432.606, 1.690
[epoch:110, iter:85399] Loss: 1.408, 10.391, 66.186, 432.667, 0.740
[epoch:110, iter:85419] Loss: 1.407, 10.400, 66.149, 432.640, 1.282
Epoch: [109][200/782]	Time 0.104 (0.079)	Data 0.003 (0.005)	Loss 13.2748 (13.4807)	Acc@1 67.188 (63.923)	Acc@5 92.188 (89.972)
[epoch:110, iter:85439] Loss: 1.408, 10.392, 66.099, 432.783, 1.178
[epoch:110, iter:85459] Loss: 1.407, 10.396, 66.086, 432.874, 1.059
[epoch:110, iter:85479] Loss: 1.409, 10.397, 66.126, 432.935, 1.078
[epoch:110, iter:85499] Loss: 1.411, 10.412, 66.121, 432.930, 1.313
[epoch:110, iter:85519] Loss: 1.411, 10.412, 66.153, 433.121, 1.541
Epoch: [109][300/782]	Time 0.091 (0.077)	Data 0.003 (0.004)	Loss 14.7278 (13.5338)	Acc@1 54.688 (63.367)	Acc@5 82.812 (89.654)
[epoch:110, iter:85539] Loss: 1.412, 10.415, 66.176, 433.352, 1.531
[epoch:110, iter:85559] Loss: 1.412, 10.417, 66.127, 433.326, 1.400
[epoch:110, iter:85579] Loss: 1.410, 10.410, 66.064, 433.173, 1.002
[epoch:110, iter:85599] Loss: 1.409, 10.404, 66.039, 433.221, 1.533
[epoch:110, iter:85619] Loss: 1.408, 10.393, 65.987, 433.130, 1.274
Epoch: [109][400/782]	Time 0.077 (0.078)	Data 0.002 (0.003)	Loss 13.5405 (13.5194)	Acc@1 64.062 (63.353)	Acc@5 98.438 (89.659)
[epoch:110, iter:85639] Loss: 1.406, 10.386, 65.962, 433.299, 1.168
[epoch:110, iter:85659] Loss: 1.406, 10.384, 65.957, 433.324, 1.940
[epoch:110, iter:85679] Loss: 1.407, 10.377, 65.939, 433.254, 1.652
[epoch:110, iter:85699] Loss: 1.407, 10.373, 65.937, 433.269, 1.353
[epoch:110, iter:85719] Loss: 1.407, 10.373, 65.925, 433.268, 1.506
Epoch: [109][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 14.1671 (13.5273)	Acc@1 60.938 (63.127)	Acc@5 90.625 (89.668)
[epoch:110, iter:85739] Loss: 1.409, 10.379, 65.947, 433.376, 1.219
[epoch:110, iter:85759] Loss: 1.409, 10.377, 65.951, 433.325, 1.228
[epoch:110, iter:85779] Loss: 1.408, 10.375, 65.990, 433.451, 1.528
[epoch:110, iter:85799] Loss: 1.408, 10.375, 66.047, 433.637, 1.453
[epoch:110, iter:85819] Loss: 1.409, 10.377, 66.051, 433.628, 1.211
Epoch: [109][600/782]	Time 0.076 (0.078)	Data 0.002 (0.003)	Loss 14.3902 (13.5412)	Acc@1 50.000 (63.077)	Acc@5 82.812 (89.673)
[epoch:110, iter:85839] Loss: 1.409, 10.377, 66.024, 433.636, 2.056
[epoch:110, iter:85859] Loss: 1.409, 10.380, 66.042, 433.643, 1.833
[epoch:110, iter:85879] Loss: 1.409, 10.380, 66.024, 433.527, 1.016
[epoch:110, iter:85899] Loss: 1.408, 10.382, 66.044, 433.579, 1.405
[epoch:110, iter:85919] Loss: 1.409, 10.384, 66.062, 433.680, 1.652
Epoch: [109][700/782]	Time 0.073 (0.078)	Data 0.003 (0.003)	Loss 13.3072 (13.5504)	Acc@1 62.500 (63.030)	Acc@5 85.938 (89.589)
[epoch:110, iter:85939] Loss: 1.409, 10.385, 66.057, 433.629, 1.373
[epoch:110, iter:85959] Loss: 1.408, 10.385, 66.035, 433.594, 1.381
[epoch:110, iter:85979] Loss: 1.407, 10.382, 65.992, 433.471, 0.927
[epoch:110, iter:85999] Loss: 1.407, 10.376, 65.952, 433.377, 1.434
[epoch:110, iter:86019] Loss: 1.406, 10.374, 65.924, 433.274, 1.167
 * Acc@1 63.032 Acc@5 89.620
epoch 109, total time 61.59
Test: [0/313]	Time 0.237 (0.237)	Loss 1.5564 (1.5564)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.5795 (1.9259)	Acc@1 56.250 (54.486)	Acc@5 96.875 (84.530)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.6316 (1.8857)	Acc@1 46.875 (55.177)	Acc@5 87.500 (84.624)
Test: [300/313]	Time 0.010 (0.008)	Loss 2.4050 (1.8734)	Acc@1 53.125 (55.554)	Acc@5 81.250 (84.780)
 * Acc@1 55.660 Acc@5 84.860
==> training...
Epoch: [110][0/782]	Time 0.609 (0.609)	Data 0.533 (0.533)	Loss 14.6640 (14.6640)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
[epoch:111, iter:86021] Loss: 1.360, 10.185, 71.361, 452.046, 1.426
[epoch:111, iter:86041] Loss: 1.374, 10.287, 65.573, 432.439, 1.317
[epoch:111, iter:86061] Loss: 1.378, 10.273, 65.260, 431.248, 2.276
[epoch:111, iter:86081] Loss: 1.375, 10.215, 65.222, 430.878, 1.181
[epoch:111, iter:86101] Loss: 1.387, 10.270, 65.244, 431.239, 1.145
Epoch: [110][100/782]	Time 0.071 (0.081)	Data 0.002 (0.007)	Loss 12.4922 (13.3090)	Acc@1 68.750 (64.836)	Acc@5 90.625 (91.136)
[epoch:111, iter:86121] Loss: 1.389, 10.297, 65.388, 431.688, 0.943
[epoch:111, iter:86141] Loss: 1.396, 10.329, 65.664, 432.579, 1.207
[epoch:111, iter:86161] Loss: 1.394, 10.333, 65.624, 432.445, 1.109
[epoch:111, iter:86181] Loss: 1.395, 10.345, 65.754, 432.586, 1.530
[epoch:111, iter:86201] Loss: 1.393, 10.350, 65.746, 432.678, 1.022
Epoch: [110][200/782]	Time 0.065 (0.079)	Data 0.002 (0.005)	Loss 14.4566 (13.3772)	Acc@1 62.500 (64.436)	Acc@5 84.375 (90.687)
[epoch:111, iter:86221] Loss: 1.394, 10.347, 65.739, 432.510, 1.734
[epoch:111, iter:86241] Loss: 1.390, 10.352, 65.740, 432.604, 1.269
[epoch:111, iter:86261] Loss: 1.392, 10.349, 65.755, 432.441, 1.632
[epoch:111, iter:86281] Loss: 1.391, 10.349, 65.810, 432.586, 1.413
[epoch:111, iter:86301] Loss: 1.391, 10.349, 65.788, 432.676, 1.321
Epoch: [110][300/782]	Time 0.087 (0.077)	Data 0.003 (0.004)	Loss 14.4273 (13.4253)	Acc@1 53.125 (63.876)	Acc@5 84.375 (90.241)
[epoch:111, iter:86321] Loss: 1.391, 10.344, 65.742, 432.713, 2.048
[epoch:111, iter:86341] Loss: 1.392, 10.340, 65.758, 432.672, 1.296
[epoch:111, iter:86361] Loss: 1.393, 10.342, 65.736, 432.726, 0.749
[epoch:111, iter:86381] Loss: 1.395, 10.351, 65.766, 432.918, 1.652
[epoch:111, iter:86401] Loss: 1.395, 10.353, 65.742, 432.861, 1.289
Epoch: [110][400/782]	Time 0.074 (0.077)	Data 0.002 (0.004)	Loss 13.2510 (13.4452)	Acc@1 67.188 (63.724)	Acc@5 92.188 (90.177)
[epoch:111, iter:86421] Loss: 1.395, 10.350, 65.723, 432.686, 1.179
[epoch:111, iter:86441] Loss: 1.394, 10.347, 65.730, 432.708, 1.431
[epoch:111, iter:86461] Loss: 1.395, 10.349, 65.725, 432.865, 1.867
[epoch:111, iter:86481] Loss: 1.394, 10.346, 65.759, 432.895, 1.491
[epoch:111, iter:86501] Loss: 1.395, 10.348, 65.795, 432.993, 1.277
Epoch: [110][500/782]	Time 0.086 (0.077)	Data 0.003 (0.003)	Loss 13.3692 (13.4784)	Acc@1 62.500 (63.467)	Acc@5 90.625 (90.011)
[epoch:111, iter:86521] Loss: 1.395, 10.350, 65.789, 432.993, 1.305
[epoch:111, iter:86541] Loss: 1.396, 10.349, 65.805, 433.024, 1.449
[epoch:111, iter:86561] Loss: 1.396, 10.353, 65.839, 433.161, 1.410
[epoch:111, iter:86581] Loss: 1.396, 10.355, 65.830, 433.166, 0.571
[epoch:111, iter:86601] Loss: 1.396, 10.356, 65.825, 433.142, 1.405
Epoch: [110][600/782]	Time 0.071 (0.077)	Data 0.002 (0.003)	Loss 13.6692 (13.4985)	Acc@1 59.375 (63.415)	Acc@5 85.938 (89.835)
[epoch:111, iter:86621] Loss: 1.397, 10.356, 65.830, 433.257, 1.409
[epoch:111, iter:86641] Loss: 1.397, 10.356, 65.831, 433.329, 1.180
[epoch:111, iter:86661] Loss: 1.397, 10.358, 65.841, 433.447, 1.614
[epoch:111, iter:86681] Loss: 1.397, 10.359, 65.869, 433.468, 1.728
[epoch:111, iter:86701] Loss: 1.397, 10.363, 65.881, 433.532, 1.616
Epoch: [110][700/782]	Time 0.063 (0.077)	Data 0.002 (0.003)	Loss 13.8658 (13.5231)	Acc@1 43.750 (63.238)	Acc@5 92.188 (89.740)
[epoch:111, iter:86721] Loss: 1.399, 10.365, 65.880, 433.484, 1.568
[epoch:111, iter:86741] Loss: 1.399, 10.361, 65.876, 433.389, 1.542
[epoch:111, iter:86761] Loss: 1.399, 10.363, 65.890, 433.356, 1.540
[epoch:111, iter:86781] Loss: 1.399, 10.364, 65.897, 433.432, 1.387
[epoch:111, iter:86801] Loss: 1.399, 10.366, 65.913, 433.539, 1.293
 * Acc@1 63.108 Acc@5 89.700
epoch 110, total time 60.16
Test: [0/313]	Time 0.308 (0.308)	Loss 1.9497 (1.9497)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.8426 (1.8584)	Acc@1 46.875 (59.035)	Acc@5 90.625 (85.427)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.1335 (1.8493)	Acc@1 68.750 (58.893)	Acc@5 96.875 (85.152)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.1476 (1.8547)	Acc@1 53.125 (58.223)	Acc@5 78.125 (85.112)
 * Acc@1 58.140 Acc@5 85.160
saving the best model!
==> training...
Epoch: [111][0/782]	Time 0.541 (0.541)	Data 0.466 (0.466)	Loss 13.9706 (13.9706)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:112, iter:86803] Loss: 1.264, 10.434, 70.041, 447.119, 1.372
[epoch:112, iter:86823] Loss: 1.368, 10.460, 65.302, 432.214, 1.049
[epoch:112, iter:86843] Loss: 1.376, 10.439, 65.276, 432.226, 1.114
[epoch:112, iter:86863] Loss: 1.375, 10.396, 65.340, 431.908, 1.155
[epoch:112, iter:86883] Loss: 1.374, 10.377, 65.072, 430.504, 1.514
Epoch: [111][100/782]	Time 0.080 (0.084)	Data 0.003 (0.007)	Loss 13.2789 (13.3119)	Acc@1 64.062 (64.124)	Acc@5 90.625 (90.145)
[epoch:112, iter:86903] Loss: 1.378, 10.372, 65.134, 431.206, 1.141
[epoch:112, iter:86923] Loss: 1.383, 10.345, 65.204, 431.157, 1.472
[epoch:112, iter:86943] Loss: 1.386, 10.346, 65.381, 431.443, 1.376
[epoch:112, iter:86963] Loss: 1.386, 10.347, 65.422, 431.928, 1.558
[epoch:112, iter:86983] Loss: 1.387, 10.342, 65.501, 432.150, 0.987
Epoch: [111][200/782]	Time 0.071 (0.080)	Data 0.002 (0.005)	Loss 13.1865 (13.3777)	Acc@1 67.188 (63.822)	Acc@5 95.312 (90.244)
[epoch:112, iter:87003] Loss: 1.387, 10.350, 65.514, 431.974, 1.218
[epoch:112, iter:87023] Loss: 1.389, 10.355, 65.531, 432.037, 1.119
[epoch:112, iter:87043] Loss: 1.391, 10.353, 65.554, 432.007, 1.804
[epoch:112, iter:87063] Loss: 1.392, 10.358, 65.612, 432.028, 1.090
[epoch:112, iter:87083] Loss: 1.391, 10.349, 65.671, 432.084, 1.581
Epoch: [111][300/782]	Time 0.072 (0.080)	Data 0.002 (0.004)	Loss 13.6890 (13.4177)	Acc@1 57.812 (63.652)	Acc@5 90.625 (90.303)
[epoch:112, iter:87103] Loss: 1.392, 10.349, 65.701, 432.092, 1.541
[epoch:112, iter:87123] Loss: 1.393, 10.357, 65.717, 432.203, 1.433
[epoch:112, iter:87143] Loss: 1.395, 10.365, 65.796, 432.486, 1.539
[epoch:112, iter:87163] Loss: 1.398, 10.376, 65.894, 432.726, 1.298
[epoch:112, iter:87183] Loss: 1.398, 10.382, 65.940, 432.852, 1.066
Epoch: [111][400/782]	Time 0.085 (0.079)	Data 0.002 (0.003)	Loss 13.6375 (13.4805)	Acc@1 64.062 (63.634)	Acc@5 92.188 (90.267)
[epoch:112, iter:87203] Loss: 1.399, 10.386, 65.941, 432.870, 1.370
[epoch:112, iter:87223] Loss: 1.400, 10.394, 65.993, 433.067, 1.160
[epoch:112, iter:87243] Loss: 1.401, 10.397, 65.982, 433.008, 1.202
[epoch:112, iter:87263] Loss: 1.401, 10.389, 65.970, 432.908, 1.279
[epoch:112, iter:87283] Loss: 1.400, 10.383, 65.988, 432.938, 1.753
Epoch: [111][500/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 13.8166 (13.4955)	Acc@1 60.938 (63.523)	Acc@5 90.625 (90.182)
[epoch:112, iter:87303] Loss: 1.399, 10.387, 66.010, 433.050, 1.390
[epoch:112, iter:87323] Loss: 1.399, 10.384, 66.055, 433.090, 1.264
[epoch:112, iter:87343] Loss: 1.399, 10.382, 66.077, 433.219, 1.747
[epoch:112, iter:87363] Loss: 1.399, 10.384, 66.083, 433.290, 1.731
[epoch:112, iter:87383] Loss: 1.399, 10.386, 66.059, 433.258, 1.209
Epoch: [111][600/782]	Time 0.075 (0.077)	Data 0.002 (0.003)	Loss 13.8277 (13.5313)	Acc@1 43.750 (63.173)	Acc@5 82.812 (89.962)
[epoch:112, iter:87403] Loss: 1.399, 10.385, 66.076, 433.305, 1.874
[epoch:112, iter:87423] Loss: 1.400, 10.386, 66.022, 433.179, 1.340
[epoch:112, iter:87443] Loss: 1.400, 10.385, 66.040, 433.235, 1.265
[epoch:112, iter:87463] Loss: 1.400, 10.382, 66.030, 433.181, 1.471
[epoch:112, iter:87483] Loss: 1.399, 10.380, 66.050, 433.200, 1.098
Epoch: [111][700/782]	Time 0.083 (0.078)	Data 0.002 (0.003)	Loss 13.3596 (13.5269)	Acc@1 64.062 (63.231)	Acc@5 93.750 (89.921)
[epoch:112, iter:87503] Loss: 1.399, 10.377, 66.068, 433.178, 1.191
[epoch:112, iter:87523] Loss: 1.399, 10.375, 66.041, 433.090, 1.630
[epoch:112, iter:87543] Loss: 1.400, 10.377, 66.042, 433.091, 1.578
[epoch:112, iter:87563] Loss: 1.399, 10.379, 66.059, 433.149, 1.816
[epoch:112, iter:87583] Loss: 1.399, 10.382, 66.049, 433.093, 1.890
 * Acc@1 63.164 Acc@5 89.802
epoch 111, total time 61.12
Test: [0/313]	Time 0.282 (0.282)	Loss 2.2414 (2.2414)	Acc@1 56.250 (56.250)	Acc@5 71.875 (71.875)
Test: [100/313]	Time 0.008 (0.010)	Loss 2.2657 (2.0033)	Acc@1 53.125 (54.796)	Acc@5 87.500 (84.035)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.0788 (1.9555)	Acc@1 59.375 (55.177)	Acc@5 90.625 (84.220)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.6936 (1.9650)	Acc@1 59.375 (54.786)	Acc@5 93.750 (84.043)
 * Acc@1 54.820 Acc@5 84.020
==> training...
Epoch: [112][0/782]	Time 0.533 (0.533)	Data 0.455 (0.455)	Loss 13.6142 (13.6142)	Acc@1 64.062 (64.062)	Acc@5 92.188 (92.188)
[epoch:113, iter:87585] Loss: 1.379, 10.314, 68.645, 428.247, 1.195
[epoch:113, iter:87605] Loss: 1.420, 10.457, 67.461, 436.251, 1.805
[epoch:113, iter:87625] Loss: 1.407, 10.435, 66.696, 435.014, 1.540
[epoch:113, iter:87645] Loss: 1.400, 10.433, 66.090, 433.100, 1.228
[epoch:113, iter:87665] Loss: 1.396, 10.419, 66.028, 433.122, 1.155
Epoch: [112][100/782]	Time 0.088 (0.076)	Data 0.003 (0.007)	Loss 12.9461 (13.4641)	Acc@1 60.938 (64.155)	Acc@5 93.750 (89.527)
[epoch:113, iter:87685] Loss: 1.392, 10.377, 65.812, 432.256, 1.142
[epoch:113, iter:87705] Loss: 1.395, 10.381, 65.840, 432.470, 1.216
[epoch:113, iter:87725] Loss: 1.392, 10.375, 65.768, 432.356, 0.838
[epoch:113, iter:87745] Loss: 1.389, 10.371, 65.651, 432.278, 1.025
[epoch:113, iter:87765] Loss: 1.390, 10.372, 65.603, 432.207, 1.467
Epoch: [112][200/782]	Time 0.089 (0.076)	Data 0.003 (0.004)	Loss 13.2436 (13.4350)	Acc@1 64.062 (64.234)	Acc@5 92.188 (89.358)
[epoch:113, iter:87785] Loss: 1.391, 10.367, 65.627, 432.104, 1.243
[epoch:113, iter:87805] Loss: 1.391, 10.361, 65.616, 432.203, 1.300
[epoch:113, iter:87825] Loss: 1.391, 10.361, 65.553, 431.952, 0.988
[epoch:113, iter:87845] Loss: 1.388, 10.350, 65.596, 432.112, 1.340
[epoch:113, iter:87865] Loss: 1.390, 10.352, 65.697, 432.505, 1.424
Epoch: [112][300/782]	Time 0.078 (0.078)	Data 0.002 (0.004)	Loss 13.4470 (13.4944)	Acc@1 64.062 (63.710)	Acc@5 95.312 (89.452)
[epoch:113, iter:87885] Loss: 1.393, 10.362, 65.815, 432.810, 1.167
[epoch:113, iter:87905] Loss: 1.395, 10.364, 65.838, 433.020, 1.122
[epoch:113, iter:87925] Loss: 1.394, 10.365, 65.790, 432.914, 1.346
[epoch:113, iter:87945] Loss: 1.393, 10.364, 65.731, 432.705, 1.211
[epoch:113, iter:87965] Loss: 1.393, 10.360, 65.736, 432.814, 1.399
Epoch: [112][400/782]	Time 0.091 (0.078)	Data 0.003 (0.003)	Loss 13.5069 (13.5027)	Acc@1 62.500 (63.661)	Acc@5 92.188 (89.464)
[epoch:113, iter:87985] Loss: 1.394, 10.356, 65.767, 432.869, 1.125
[epoch:113, iter:88005] Loss: 1.393, 10.359, 65.768, 432.848, 1.631
[epoch:113, iter:88025] Loss: 1.393, 10.361, 65.774, 432.848, 1.307
[epoch:113, iter:88045] Loss: 1.393, 10.354, 65.736, 432.710, 1.147
[epoch:113, iter:88065] Loss: 1.393, 10.349, 65.746, 432.757, 1.035
Epoch: [112][500/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 13.5482 (13.5009)	Acc@1 64.062 (63.542)	Acc@5 84.375 (89.512)
[epoch:113, iter:88085] Loss: 1.393, 10.346, 65.728, 432.773, 1.489
[epoch:113, iter:88105] Loss: 1.394, 10.346, 65.770, 432.888, 1.810
[epoch:113, iter:88125] Loss: 1.394, 10.348, 65.769, 432.977, 1.733
[epoch:113, iter:88145] Loss: 1.394, 10.351, 65.778, 433.108, 1.324
[epoch:113, iter:88165] Loss: 1.395, 10.351, 65.802, 433.199, 1.454
Epoch: [112][600/782]	Time 0.077 (0.077)	Data 0.002 (0.003)	Loss 12.9505 (13.5217)	Acc@1 60.938 (63.277)	Acc@5 95.312 (89.507)
[epoch:113, iter:88185] Loss: 1.395, 10.353, 65.801, 433.133, 1.237
[epoch:113, iter:88205] Loss: 1.395, 10.351, 65.808, 433.076, 1.239
[epoch:113, iter:88225] Loss: 1.395, 10.352, 65.809, 433.056, 1.035
[epoch:113, iter:88245] Loss: 1.395, 10.353, 65.841, 433.065, 0.915
[epoch:113, iter:88265] Loss: 1.396, 10.354, 65.844, 433.077, 1.165
Epoch: [112][700/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 14.1661 (13.5253)	Acc@1 65.625 (63.240)	Acc@5 90.625 (89.573)
[epoch:113, iter:88285] Loss: 1.395, 10.353, 65.873, 433.141, 1.409
[epoch:113, iter:88305] Loss: 1.396, 10.357, 65.906, 433.151, 1.151
[epoch:113, iter:88325] Loss: 1.396, 10.360, 65.920, 433.168, 1.586
[epoch:113, iter:88345] Loss: 1.396, 10.363, 65.929, 433.180, 1.421
[epoch:113, iter:88365] Loss: 1.396, 10.364, 65.922, 433.190, 1.612
 * Acc@1 63.174 Acc@5 89.538
epoch 112, total time 59.87
Test: [0/313]	Time 0.304 (0.304)	Loss 1.3933 (1.3933)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.7079 (1.8447)	Acc@1 40.625 (57.457)	Acc@5 75.000 (85.241)
Test: [200/313]	Time 0.009 (0.009)	Loss 0.9919 (1.8325)	Acc@1 71.875 (57.432)	Acc@5 93.750 (85.370)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.1966 (1.8570)	Acc@1 43.750 (57.174)	Acc@5 90.625 (85.112)
 * Acc@1 57.110 Acc@5 85.120
==> training...
Epoch: [113][0/782]	Time 0.616 (0.616)	Data 0.551 (0.551)	Loss 14.5763 (14.5763)	Acc@1 51.562 (51.562)	Acc@5 76.562 (76.562)
[epoch:114, iter:88367] Loss: 1.391, 10.421, 70.352, 453.226, 1.838
[epoch:114, iter:88387] Loss: 1.379, 10.446, 65.922, 433.534, 1.739
[epoch:114, iter:88407] Loss: 1.393, 10.429, 66.168, 432.695, 1.356
[epoch:114, iter:88427] Loss: 1.393, 10.383, 65.946, 431.925, 1.264
[epoch:114, iter:88447] Loss: 1.386, 10.348, 65.804, 431.314, 1.499
Epoch: [113][100/782]	Time 0.086 (0.085)	Data 0.003 (0.008)	Loss 12.8865 (13.3273)	Acc@1 73.438 (64.356)	Acc@5 93.750 (90.285)
[epoch:114, iter:88467] Loss: 1.391, 10.321, 65.567, 430.902, 0.898
[epoch:114, iter:88487] Loss: 1.394, 10.340, 65.627, 431.394, 1.148
[epoch:114, iter:88507] Loss: 1.395, 10.349, 65.704, 431.527, 1.197
[epoch:114, iter:88527] Loss: 1.396, 10.340, 65.648, 431.561, 1.072
[epoch:114, iter:88547] Loss: 1.397, 10.334, 65.677, 431.571, 1.494
Epoch: [113][200/782]	Time 0.072 (0.081)	Data 0.002 (0.005)	Loss 14.9894 (13.4079)	Acc@1 56.250 (64.086)	Acc@5 82.812 (90.190)
[epoch:114, iter:88567] Loss: 1.397, 10.333, 65.764, 431.898, 1.789
[epoch:114, iter:88587] Loss: 1.396, 10.339, 65.702, 431.776, 1.102
[epoch:114, iter:88607] Loss: 1.398, 10.345, 65.697, 431.797, 1.078
[epoch:114, iter:88627] Loss: 1.397, 10.339, 65.737, 431.760, 1.097
[epoch:114, iter:88647] Loss: 1.397, 10.343, 65.743, 431.770, 0.797
Epoch: [113][300/782]	Time 0.063 (0.079)	Data 0.002 (0.004)	Loss 13.4004 (13.4156)	Acc@1 56.250 (63.793)	Acc@5 87.500 (90.070)
[epoch:114, iter:88667] Loss: 1.396, 10.340, 65.709, 431.763, 1.526
[epoch:114, iter:88687] Loss: 1.397, 10.346, 65.695, 431.802, 1.002
[epoch:114, iter:88707] Loss: 1.398, 10.355, 65.706, 431.740, 1.173
[epoch:114, iter:88727] Loss: 1.398, 10.355, 65.701, 431.766, 1.648
[epoch:114, iter:88747] Loss: 1.398, 10.359, 65.700, 431.912, 1.321
Epoch: [113][400/782]	Time 0.082 (0.077)	Data 0.003 (0.004)	Loss 13.2534 (13.4470)	Acc@1 62.500 (63.529)	Acc@5 92.188 (90.021)
[epoch:114, iter:88767] Loss: 1.399, 10.363, 65.716, 432.204, 1.261
[epoch:114, iter:88787] Loss: 1.400, 10.362, 65.752, 432.376, 1.156
[epoch:114, iter:88807] Loss: 1.400, 10.362, 65.712, 432.301, 1.240
[epoch:114, iter:88827] Loss: 1.401, 10.363, 65.722, 432.402, 1.774
[epoch:114, iter:88847] Loss: 1.402, 10.364, 65.781, 432.470, 1.311
Epoch: [113][500/782]	Time 0.087 (0.077)	Data 0.003 (0.003)	Loss 12.8708 (13.4851)	Acc@1 67.188 (63.320)	Acc@5 93.750 (89.858)
[epoch:114, iter:88867] Loss: 1.402, 10.362, 65.803, 432.562, 1.176
[epoch:114, iter:88887] Loss: 1.402, 10.368, 65.832, 432.774, 1.707
[epoch:114, iter:88907] Loss: 1.403, 10.376, 65.883, 433.019, 1.458
[epoch:114, iter:88927] Loss: 1.403, 10.377, 65.888, 433.021, 1.063
[epoch:114, iter:88947] Loss: 1.402, 10.376, 65.876, 432.953, 1.305
Epoch: [113][600/782]	Time 0.085 (0.077)	Data 0.003 (0.003)	Loss 13.1283 (13.5148)	Acc@1 68.750 (62.989)	Acc@5 93.750 (89.798)
[epoch:114, iter:88967] Loss: 1.401, 10.372, 65.883, 432.901, 1.065
[epoch:114, iter:88987] Loss: 1.402, 10.371, 65.890, 432.895, 1.243
[epoch:114, iter:89007] Loss: 1.402, 10.375, 65.901, 432.942, 1.180
[epoch:114, iter:89027] Loss: 1.404, 10.377, 65.935, 433.088, 1.369
[epoch:114, iter:89047] Loss: 1.403, 10.378, 65.927, 433.094, 1.502
Epoch: [113][700/782]	Time 0.079 (0.078)	Data 0.003 (0.003)	Loss 12.5696 (13.5338)	Acc@1 62.500 (62.917)	Acc@5 89.062 (89.731)
[epoch:114, iter:89067] Loss: 1.404, 10.377, 65.909, 433.033, 1.337
[epoch:114, iter:89087] Loss: 1.404, 10.376, 65.888, 432.955, 1.088
[epoch:114, iter:89107] Loss: 1.403, 10.374, 65.883, 432.952, 1.077
[epoch:114, iter:89127] Loss: 1.403, 10.375, 65.903, 432.990, 1.184
[epoch:114, iter:89147] Loss: 1.402, 10.375, 65.898, 432.982, 1.281
 * Acc@1 62.934 Acc@5 89.680
epoch 113, total time 61.00
Test: [0/313]	Time 0.279 (0.279)	Loss 2.3944 (2.3944)	Acc@1 53.125 (53.125)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.7122 (2.2349)	Acc@1 46.875 (52.135)	Acc@5 71.875 (81.931)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.3304 (2.2364)	Acc@1 53.125 (52.223)	Acc@5 84.375 (81.561)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.6521 (2.2311)	Acc@1 37.500 (52.668)	Acc@5 87.500 (81.759)
 * Acc@1 52.770 Acc@5 81.820
==> training...
Epoch: [114][0/782]	Time 0.490 (0.490)	Data 0.425 (0.425)	Loss 13.8404 (13.8404)	Acc@1 68.750 (68.750)	Acc@5 95.312 (95.312)
[epoch:115, iter:89149] Loss: 1.538, 10.018, 69.779, 433.200, 1.244
[epoch:115, iter:89169] Loss: 1.402, 10.256, 66.245, 431.834, 1.354
[epoch:115, iter:89189] Loss: 1.410, 10.278, 65.864, 431.150, 0.930
[epoch:115, iter:89209] Loss: 1.404, 10.296, 65.714, 431.407, 1.521
[epoch:115, iter:89229] Loss: 1.412, 10.306, 65.789, 432.151, 1.054
Epoch: [114][100/782]	Time 0.075 (0.082)	Data 0.002 (0.006)	Loss 12.9482 (13.4251)	Acc@1 81.250 (63.567)	Acc@5 92.188 (90.563)
[epoch:115, iter:89249] Loss: 1.411, 10.300, 65.793, 432.258, 0.843
[epoch:115, iter:89269] Loss: 1.413, 10.318, 65.707, 431.906, 1.103
[epoch:115, iter:89289] Loss: 1.410, 10.323, 65.773, 431.941, 1.649
[epoch:115, iter:89309] Loss: 1.409, 10.326, 65.782, 431.993, 0.939
[epoch:115, iter:89329] Loss: 1.406, 10.336, 65.735, 432.024, 1.836
Epoch: [114][200/782]	Time 0.074 (0.079)	Data 0.002 (0.004)	Loss 11.7266 (13.4203)	Acc@1 71.875 (63.511)	Acc@5 98.438 (90.213)
[epoch:115, iter:89349] Loss: 1.404, 10.332, 65.790, 431.905, 0.855
[epoch:115, iter:89369] Loss: 1.405, 10.335, 65.813, 431.938, 1.116
[epoch:115, iter:89389] Loss: 1.404, 10.332, 65.733, 431.799, 1.229
[epoch:115, iter:89409] Loss: 1.403, 10.337, 65.693, 431.784, 1.824
[epoch:115, iter:89429] Loss: 1.401, 10.328, 65.610, 431.712, 1.550
Epoch: [114][300/782]	Time 0.063 (0.077)	Data 0.002 (0.004)	Loss 13.6262 (13.4100)	Acc@1 68.750 (63.429)	Acc@5 87.500 (90.147)
[epoch:115, iter:89449] Loss: 1.402, 10.333, 65.655, 431.701, 1.291
[epoch:115, iter:89469] Loss: 1.402, 10.336, 65.649, 431.655, 1.286
[epoch:115, iter:89489] Loss: 1.400, 10.333, 65.581, 431.405, 1.004
[epoch:115, iter:89509] Loss: 1.400, 10.329, 65.607, 431.431, 1.461
[epoch:115, iter:89529] Loss: 1.400, 10.327, 65.644, 431.465, 1.348
Epoch: [114][400/782]	Time 0.083 (0.076)	Data 0.002 (0.003)	Loss 13.5435 (13.4085)	Acc@1 57.812 (63.536)	Acc@5 82.812 (89.947)
[epoch:115, iter:89549] Loss: 1.400, 10.328, 65.664, 431.637, 1.810
[epoch:115, iter:89569] Loss: 1.399, 10.322, 65.711, 431.696, 1.681
[epoch:115, iter:89589] Loss: 1.398, 10.323, 65.747, 431.817, 1.466
[epoch:115, iter:89609] Loss: 1.398, 10.327, 65.757, 431.732, 1.549
[epoch:115, iter:89629] Loss: 1.398, 10.325, 65.766, 431.759, 1.219
Epoch: [114][500/782]	Time 0.088 (0.077)	Data 0.003 (0.003)	Loss 14.0569 (13.4319)	Acc@1 59.375 (63.454)	Acc@5 87.500 (90.011)
[epoch:115, iter:89649] Loss: 1.397, 10.324, 65.771, 431.834, 1.546
[epoch:115, iter:89669] Loss: 1.398, 10.323, 65.807, 431.850, 1.097
[epoch:115, iter:89689] Loss: 1.398, 10.323, 65.801, 431.850, 1.437
[epoch:115, iter:89709] Loss: 1.398, 10.328, 65.820, 431.971, 1.551
[epoch:115, iter:89729] Loss: 1.397, 10.332, 65.799, 431.980, 1.283
Epoch: [114][600/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 13.1001 (13.4417)	Acc@1 64.062 (63.285)	Acc@5 95.312 (89.941)
[epoch:115, iter:89749] Loss: 1.397, 10.329, 65.762, 431.875, 1.138
[epoch:115, iter:89769] Loss: 1.398, 10.331, 65.796, 431.948, 1.269
[epoch:115, iter:89789] Loss: 1.397, 10.328, 65.795, 431.862, 1.555
[epoch:115, iter:89809] Loss: 1.398, 10.332, 65.850, 431.993, 1.260
[epoch:115, iter:89829] Loss: 1.398, 10.335, 65.847, 432.010, 1.270
Epoch: [114][700/782]	Time 0.087 (0.077)	Data 0.002 (0.003)	Loss 13.2736 (13.4682)	Acc@1 60.938 (62.995)	Acc@5 96.875 (89.803)
[epoch:115, iter:89849] Loss: 1.398, 10.341, 65.846, 432.038, 1.240
[epoch:115, iter:89869] Loss: 1.398, 10.339, 65.852, 432.149, 1.450
[epoch:115, iter:89889] Loss: 1.399, 10.342, 65.867, 432.297, 1.326
[epoch:115, iter:89909] Loss: 1.400, 10.343, 65.918, 432.423, 1.875
[epoch:115, iter:89929] Loss: 1.400, 10.349, 65.943, 432.549, 1.002
 * Acc@1 62.918 Acc@5 89.756
epoch 114, total time 60.22
Test: [0/313]	Time 0.248 (0.248)	Loss 2.2425 (2.2425)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.009)	Loss 2.3864 (2.1011)	Acc@1 43.750 (55.198)	Acc@5 81.250 (83.168)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8647 (2.0570)	Acc@1 62.500 (54.820)	Acc@5 87.500 (83.396)
Test: [300/313]	Time 0.008 (0.007)	Loss 3.0447 (2.0561)	Acc@1 31.250 (54.994)	Acc@5 81.250 (83.607)
 * Acc@1 54.970 Acc@5 83.610
==> training...
Epoch: [115][0/782]	Time 0.486 (0.486)	Data 0.421 (0.421)	Loss 12.9693 (12.9693)	Acc@1 67.188 (67.188)	Acc@5 87.500 (87.500)
[epoch:116, iter:89931] Loss: 1.343, 10.660, 64.044, 427.877, 1.396
[epoch:116, iter:89951] Loss: 1.423, 10.558, 65.620, 434.080, 0.831
[epoch:116, iter:89971] Loss: 1.410, 10.497, 65.380, 433.590, 1.593
[epoch:116, iter:89991] Loss: 1.401, 10.425, 65.449, 432.676, 0.981
[epoch:116, iter:90011] Loss: 1.400, 10.392, 65.554, 432.275, 1.464
Epoch: [115][100/782]	Time 0.075 (0.082)	Data 0.002 (0.006)	Loss 13.6904 (13.4340)	Acc@1 60.938 (63.598)	Acc@5 87.500 (89.991)
[epoch:116, iter:90031] Loss: 1.402, 10.405, 65.560, 432.058, 1.495
[epoch:116, iter:90051] Loss: 1.399, 10.416, 65.665, 432.516, 1.176
[epoch:116, iter:90071] Loss: 1.401, 10.430, 65.672, 432.766, 1.431
[epoch:116, iter:90091] Loss: 1.401, 10.415, 65.770, 432.929, 1.339
[epoch:116, iter:90111] Loss: 1.401, 10.416, 65.756, 432.809, 1.340
Epoch: [115][200/782]	Time 0.077 (0.082)	Data 0.002 (0.004)	Loss 12.8736 (13.4809)	Acc@1 68.750 (63.371)	Acc@5 89.062 (89.910)
[epoch:116, iter:90131] Loss: 1.400, 10.416, 65.781, 432.756, 1.081
[epoch:116, iter:90151] Loss: 1.398, 10.414, 65.786, 432.739, 1.061
[epoch:116, iter:90171] Loss: 1.396, 10.410, 65.790, 432.744, 1.553
[epoch:116, iter:90191] Loss: 1.397, 10.404, 65.813, 432.719, 1.743
[epoch:116, iter:90211] Loss: 1.394, 10.399, 65.770, 432.597, 1.575
Epoch: [115][300/782]	Time 0.086 (0.082)	Data 0.002 (0.004)	Loss 14.1669 (13.4735)	Acc@1 60.938 (63.621)	Acc@5 85.938 (89.862)
[epoch:116, iter:90231] Loss: 1.393, 10.392, 65.818, 432.752, 1.488
[epoch:116, iter:90251] Loss: 1.393, 10.388, 65.795, 432.489, 1.860
[epoch:116, iter:90271] Loss: 1.391, 10.382, 65.746, 432.381, 1.598
[epoch:116, iter:90291] Loss: 1.392, 10.373, 65.731, 432.370, 1.331
[epoch:116, iter:90311] Loss: 1.394, 10.374, 65.739, 432.487, 1.387
Epoch: [115][400/782]	Time 0.062 (0.079)	Data 0.002 (0.003)	Loss 14.5991 (13.4766)	Acc@1 67.188 (63.673)	Acc@5 87.500 (89.916)
[epoch:116, iter:90331] Loss: 1.397, 10.374, 65.772, 432.580, 1.522
[epoch:116, iter:90351] Loss: 1.396, 10.369, 65.768, 432.487, 1.285
[epoch:116, iter:90371] Loss: 1.397, 10.370, 65.740, 432.435, 1.680
[epoch:116, iter:90391] Loss: 1.398, 10.368, 65.766, 432.530, 0.980
[epoch:116, iter:90411] Loss: 1.398, 10.367, 65.746, 432.532, 1.811
Epoch: [115][500/782]	Time 0.068 (0.079)	Data 0.002 (0.003)	Loss 12.9152 (13.4746)	Acc@1 65.625 (63.467)	Acc@5 93.750 (89.914)
[epoch:116, iter:90431] Loss: 1.398, 10.365, 65.720, 432.434, 1.335
[epoch:116, iter:90451] Loss: 1.398, 10.362, 65.730, 432.462, 1.491
[epoch:116, iter:90471] Loss: 1.398, 10.369, 65.722, 432.499, 1.529
[epoch:116, iter:90491] Loss: 1.399, 10.371, 65.749, 432.585, 1.225
[epoch:116, iter:90511] Loss: 1.399, 10.374, 65.795, 432.729, 1.139
Epoch: [115][600/782]	Time 0.089 (0.079)	Data 0.002 (0.003)	Loss 13.8872 (13.5061)	Acc@1 59.375 (63.236)	Acc@5 87.500 (89.762)
[epoch:116, iter:90531] Loss: 1.400, 10.378, 65.791, 432.769, 1.534
[epoch:116, iter:90551] Loss: 1.401, 10.380, 65.822, 432.893, 1.386
[epoch:116, iter:90571] Loss: 1.401, 10.381, 65.814, 432.885, 0.853
[epoch:116, iter:90591] Loss: 1.402, 10.382, 65.807, 432.870, 1.658
[epoch:116, iter:90611] Loss: 1.402, 10.385, 65.815, 432.931, 1.466
Epoch: [115][700/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 13.3889 (13.5191)	Acc@1 65.625 (63.146)	Acc@5 95.312 (89.653)
[epoch:116, iter:90631] Loss: 1.402, 10.384, 65.809, 432.900, 1.044
[epoch:116, iter:90651] Loss: 1.402, 10.384, 65.835, 432.958, 1.427
[epoch:116, iter:90671] Loss: 1.402, 10.386, 65.804, 432.951, 1.150
[epoch:116, iter:90691] Loss: 1.401, 10.384, 65.774, 432.882, 1.419
[epoch:116, iter:90711] Loss: 1.401, 10.382, 65.784, 432.911, 1.550
 * Acc@1 63.040 Acc@5 89.652
epoch 115, total time 62.15
Test: [0/313]	Time 0.269 (0.269)	Loss 1.9546 (1.9546)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.2012 (1.8965)	Acc@1 53.125 (56.281)	Acc@5 84.375 (85.056)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.3459 (1.8738)	Acc@1 62.500 (56.079)	Acc@5 84.375 (84.950)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.3920 (1.8869)	Acc@1 53.125 (56.260)	Acc@5 78.125 (84.718)
 * Acc@1 56.410 Acc@5 84.780
==> training...
Epoch: [116][0/782]	Time 0.566 (0.566)	Data 0.481 (0.481)	Loss 13.4443 (13.4443)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:117, iter:90713] Loss: 1.428, 10.643, 66.690, 428.216, 1.316
[epoch:117, iter:90733] Loss: 1.435, 10.566, 67.063, 436.404, 1.278
[epoch:117, iter:90753] Loss: 1.440, 10.561, 67.018, 435.833, 1.054
[epoch:117, iter:90773] Loss: 1.426, 10.524, 66.401, 433.942, 1.573
[epoch:117, iter:90793] Loss: 1.423, 10.483, 66.229, 433.511, 1.212
Epoch: [116][100/782]	Time 0.065 (0.076)	Data 0.002 (0.007)	Loss 12.9560 (13.5074)	Acc@1 65.625 (63.784)	Acc@5 90.625 (90.130)
[epoch:117, iter:90813] Loss: 1.416, 10.455, 66.100, 433.423, 1.231
[epoch:117, iter:90833] Loss: 1.411, 10.404, 66.059, 432.944, 1.545
[epoch:117, iter:90853] Loss: 1.410, 10.391, 66.053, 433.133, 1.419
[epoch:117, iter:90873] Loss: 1.411, 10.383, 66.085, 433.013, 0.910
[epoch:117, iter:90893] Loss: 1.412, 10.376, 66.116, 433.043, 1.089
Epoch: [116][200/782]	Time 0.073 (0.078)	Data 0.002 (0.005)	Loss 13.3866 (13.4777)	Acc@1 60.938 (63.518)	Acc@5 90.625 (90.120)
[epoch:117, iter:90913] Loss: 1.408, 10.368, 65.994, 432.871, 1.496
[epoch:117, iter:90933] Loss: 1.406, 10.377, 65.905, 432.536, 1.523
[epoch:117, iter:90953] Loss: 1.407, 10.372, 65.871, 432.412, 1.406
[epoch:117, iter:90973] Loss: 1.407, 10.378, 65.901, 432.649, 1.019
[epoch:117, iter:90993] Loss: 1.405, 10.373, 65.885, 432.657, 1.272
Epoch: [116][300/782]	Time 0.060 (0.078)	Data 0.002 (0.004)	Loss 12.7599 (13.4576)	Acc@1 60.938 (63.528)	Acc@5 89.062 (89.914)
[epoch:117, iter:91013] Loss: 1.406, 10.361, 65.814, 432.430, 1.192
[epoch:117, iter:91033] Loss: 1.406, 10.368, 65.800, 432.508, 1.111
[epoch:117, iter:91053] Loss: 1.405, 10.366, 65.767, 432.301, 1.486
[epoch:117, iter:91073] Loss: 1.404, 10.367, 65.746, 432.286, 0.839
[epoch:117, iter:91093] Loss: 1.403, 10.365, 65.706, 432.131, 1.413
Epoch: [116][400/782]	Time 0.064 (0.078)	Data 0.002 (0.004)	Loss 14.4352 (13.4523)	Acc@1 57.812 (63.396)	Acc@5 90.625 (89.896)
[epoch:117, iter:91113] Loss: 1.402, 10.368, 65.741, 432.101, 1.321
[epoch:117, iter:91133] Loss: 1.402, 10.370, 65.763, 432.172, 0.995
[epoch:117, iter:91153] Loss: 1.403, 10.364, 65.815, 432.163, 1.061
[epoch:117, iter:91173] Loss: 1.402, 10.364, 65.820, 432.091, 1.444
[epoch:117, iter:91193] Loss: 1.401, 10.365, 65.825, 432.066, 1.361
Epoch: [116][500/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 12.8257 (13.4608)	Acc@1 62.500 (63.292)	Acc@5 93.750 (89.861)
[epoch:117, iter:91213] Loss: 1.401, 10.366, 65.820, 432.084, 1.309
[epoch:117, iter:91233] Loss: 1.400, 10.363, 65.825, 432.051, 1.297
[epoch:117, iter:91253] Loss: 1.400, 10.364, 65.837, 432.119, 1.272
[epoch:117, iter:91273] Loss: 1.401, 10.365, 65.833, 432.088, 1.322
[epoch:117, iter:91293] Loss: 1.401, 10.366, 65.826, 432.193, 1.574
Epoch: [116][600/782]	Time 0.101 (0.078)	Data 0.003 (0.003)	Loss 13.8676 (13.4919)	Acc@1 68.750 (63.212)	Acc@5 85.938 (89.746)
[epoch:117, iter:91313] Loss: 1.401, 10.368, 65.838, 432.390, 1.324
[epoch:117, iter:91333] Loss: 1.401, 10.370, 65.859, 432.471, 1.417
[epoch:117, iter:91353] Loss: 1.402, 10.376, 65.877, 432.548, 1.136
[epoch:117, iter:91373] Loss: 1.403, 10.375, 65.874, 432.610, 1.329
[epoch:117, iter:91393] Loss: 1.403, 10.376, 65.858, 432.635, 1.052
Epoch: [116][700/782]	Time 0.076 (0.078)	Data 0.002 (0.003)	Loss 13.5087 (13.5139)	Acc@1 67.188 (63.095)	Acc@5 93.750 (89.649)
[epoch:117, iter:91413] Loss: 1.403, 10.376, 65.853, 432.594, 1.102
[epoch:117, iter:91433] Loss: 1.404, 10.379, 65.826, 432.572, 1.345
[epoch:117, iter:91453] Loss: 1.404, 10.376, 65.821, 432.577, 1.321
[epoch:117, iter:91473] Loss: 1.403, 10.376, 65.815, 432.569, 1.246
[epoch:117, iter:91493] Loss: 1.404, 10.378, 65.844, 432.737, 1.558
 * Acc@1 63.048 Acc@5 89.588
epoch 116, total time 60.89
Test: [0/313]	Time 0.248 (0.248)	Loss 1.4699 (1.4699)	Acc@1 59.375 (59.375)	Acc@5 93.750 (93.750)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.1800 (2.1971)	Acc@1 53.125 (51.300)	Acc@5 90.625 (81.467)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7949 (2.1369)	Acc@1 53.125 (52.177)	Acc@5 84.375 (82.152)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.2757 (2.1171)	Acc@1 46.875 (52.544)	Acc@5 84.375 (82.039)
 * Acc@1 52.580 Acc@5 82.100
==> training...
Epoch: [117][0/782]	Time 0.589 (0.589)	Data 0.510 (0.510)	Loss 14.0155 (14.0155)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
[epoch:118, iter:91495] Loss: 1.457, 10.298, 70.279, 441.698, 1.334
[epoch:118, iter:91515] Loss: 1.430, 10.520, 67.685, 438.233, 1.363
[epoch:118, iter:91535] Loss: 1.417, 10.464, 67.016, 436.196, 1.181
[epoch:118, iter:91555] Loss: 1.407, 10.449, 66.822, 436.116, 1.234
[epoch:118, iter:91575] Loss: 1.412, 10.456, 66.523, 435.838, 1.536
Epoch: [117][100/782]	Time 0.085 (0.083)	Data 0.003 (0.007)	Loss 14.1479 (13.6341)	Acc@1 57.812 (62.314)	Acc@5 82.812 (89.279)
[epoch:118, iter:91595] Loss: 1.410, 10.427, 66.295, 435.323, 1.706
[epoch:118, iter:91615] Loss: 1.407, 10.403, 66.235, 434.868, 1.517
[epoch:118, iter:91635] Loss: 1.404, 10.391, 66.123, 434.361, 1.191
[epoch:118, iter:91655] Loss: 1.398, 10.393, 65.903, 433.747, 1.301
[epoch:118, iter:91675] Loss: 1.393, 10.382, 65.734, 433.100, 1.449
Epoch: [117][200/782]	Time 0.085 (0.080)	Data 0.003 (0.005)	Loss 15.0553 (13.4648)	Acc@1 48.438 (63.215)	Acc@5 81.250 (89.684)
[epoch:118, iter:91695] Loss: 1.390, 10.372, 65.622, 432.776, 2.182
[epoch:118, iter:91715] Loss: 1.389, 10.372, 65.686, 432.609, 1.120
[epoch:118, iter:91735] Loss: 1.390, 10.377, 65.742, 432.819, 1.852
[epoch:118, iter:91755] Loss: 1.391, 10.380, 65.794, 432.959, 1.116
[epoch:118, iter:91775] Loss: 1.392, 10.382, 65.836, 433.084, 1.400
Epoch: [117][300/782]	Time 0.091 (0.081)	Data 0.003 (0.004)	Loss 15.4156 (13.4783)	Acc@1 53.125 (63.543)	Acc@5 87.500 (89.722)
[epoch:118, iter:91795] Loss: 1.393, 10.375, 65.838, 432.936, 1.841
[epoch:118, iter:91815] Loss: 1.394, 10.373, 65.813, 432.959, 1.140
[epoch:118, iter:91835] Loss: 1.393, 10.382, 65.816, 433.103, 1.846
[epoch:118, iter:91855] Loss: 1.393, 10.379, 65.801, 433.064, 1.042
[epoch:118, iter:91875] Loss: 1.393, 10.375, 65.756, 432.783, 1.450
Epoch: [117][400/782]	Time 0.083 (0.080)	Data 0.002 (0.004)	Loss 13.6549 (13.4666)	Acc@1 56.250 (63.396)	Acc@5 87.500 (89.748)
[epoch:118, iter:91895] Loss: 1.393, 10.373, 65.765, 432.750, 1.630
[epoch:118, iter:91915] Loss: 1.394, 10.371, 65.782, 432.843, 1.242
[epoch:118, iter:91935] Loss: 1.394, 10.372, 65.743, 432.746, 1.401
[epoch:118, iter:91955] Loss: 1.395, 10.373, 65.792, 432.941, 1.286
[epoch:118, iter:91975] Loss: 1.395, 10.373, 65.790, 432.882, 1.105
Epoch: [117][500/782]	Time 0.080 (0.080)	Data 0.003 (0.003)	Loss 13.4167 (13.4820)	Acc@1 67.188 (63.298)	Acc@5 93.750 (89.764)
[epoch:118, iter:91995] Loss: 1.394, 10.380, 65.763, 432.899, 1.033
[epoch:118, iter:92015] Loss: 1.394, 10.380, 65.747, 432.925, 1.301
[epoch:118, iter:92035] Loss: 1.394, 10.375, 65.717, 432.880, 1.044
[epoch:118, iter:92055] Loss: 1.393, 10.372, 65.703, 432.784, 1.545
[epoch:118, iter:92075] Loss: 1.394, 10.373, 65.720, 432.782, 1.484
Epoch: [117][600/782]	Time 0.057 (0.079)	Data 0.002 (0.003)	Loss 13.6330 (13.4829)	Acc@1 60.938 (63.332)	Acc@5 92.188 (89.720)
[epoch:118, iter:92095] Loss: 1.394, 10.377, 65.775, 432.813, 1.286
[epoch:118, iter:92115] Loss: 1.394, 10.378, 65.799, 432.880, 0.991
[epoch:118, iter:92135] Loss: 1.394, 10.376, 65.810, 432.857, 1.328
[epoch:118, iter:92155] Loss: 1.394, 10.374, 65.806, 432.864, 1.464
[epoch:118, iter:92175] Loss: 1.394, 10.372, 65.790, 432.825, 1.424
Epoch: [117][700/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 13.3130 (13.4944)	Acc@1 67.188 (63.215)	Acc@5 87.500 (89.638)
[epoch:118, iter:92195] Loss: 1.394, 10.370, 65.807, 432.781, 1.242
[epoch:118, iter:92215] Loss: 1.394, 10.368, 65.810, 432.757, 1.229
[epoch:118, iter:92235] Loss: 1.394, 10.368, 65.824, 432.823, 1.271
[epoch:118, iter:92255] Loss: 1.395, 10.369, 65.835, 432.822, 1.398
[epoch:118, iter:92275] Loss: 1.395, 10.372, 65.856, 432.827, 2.003
 * Acc@1 63.164 Acc@5 89.728
epoch 117, total time 60.41
Test: [0/313]	Time 0.253 (0.253)	Loss 1.8395 (1.8395)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.3462 (1.9639)	Acc@1 40.625 (54.548)	Acc@5 87.500 (84.313)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.4191 (1.9700)	Acc@1 65.625 (54.602)	Acc@5 93.750 (84.173)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8222 (1.9791)	Acc@1 43.750 (54.547)	Acc@5 71.875 (84.250)
 * Acc@1 54.630 Acc@5 84.320
==> training...
Epoch: [118][0/782]	Time 0.489 (0.489)	Data 0.423 (0.423)	Loss 13.4349 (13.4349)	Acc@1 67.188 (67.188)	Acc@5 90.625 (90.625)
[epoch:119, iter:92277] Loss: 1.410, 10.278, 66.714, 439.221, 1.276
[epoch:119, iter:92297] Loss: 1.425, 10.564, 65.626, 434.614, 1.346
[epoch:119, iter:92317] Loss: 1.412, 10.470, 65.102, 431.914, 0.811
[epoch:119, iter:92337] Loss: 1.407, 10.454, 65.085, 431.983, 0.932
[epoch:119, iter:92357] Loss: 1.405, 10.375, 65.116, 431.269, 1.119
Epoch: [118][100/782]	Time 0.083 (0.080)	Data 0.003 (0.006)	Loss 13.1539 (13.2854)	Acc@1 59.375 (64.202)	Acc@5 92.188 (90.579)
[epoch:119, iter:92377] Loss: 1.399, 10.353, 65.127, 431.331, 1.300
[epoch:119, iter:92397] Loss: 1.399, 10.367, 65.044, 431.093, 1.322
[epoch:119, iter:92417] Loss: 1.396, 10.355, 65.018, 430.906, 1.004
[epoch:119, iter:92437] Loss: 1.395, 10.351, 65.124, 430.816, 0.910
[epoch:119, iter:92457] Loss: 1.390, 10.341, 65.114, 430.492, 1.743
Epoch: [118][200/782]	Time 0.075 (0.079)	Data 0.002 (0.004)	Loss 13.4922 (13.2770)	Acc@1 60.938 (64.125)	Acc@5 90.625 (90.361)
[epoch:119, iter:92477] Loss: 1.390, 10.335, 65.071, 430.234, 1.214
[epoch:119, iter:92497] Loss: 1.392, 10.334, 65.166, 430.600, 1.407
[epoch:119, iter:92517] Loss: 1.390, 10.323, 65.151, 430.600, 1.614
[epoch:119, iter:92537] Loss: 1.391, 10.314, 65.174, 430.728, 1.428
[epoch:119, iter:92557] Loss: 1.390, 10.325, 65.226, 431.022, 1.780
Epoch: [118][300/782]	Time 0.086 (0.078)	Data 0.003 (0.004)	Loss 13.1603 (13.3565)	Acc@1 65.625 (63.564)	Acc@5 84.375 (90.059)
[epoch:119, iter:92577] Loss: 1.390, 10.328, 65.286, 431.206, 1.323
[epoch:119, iter:92597] Loss: 1.390, 10.320, 65.275, 431.045, 1.311
[epoch:119, iter:92617] Loss: 1.392, 10.329, 65.376, 431.235, 1.286
[epoch:119, iter:92637] Loss: 1.393, 10.340, 65.444, 431.405, 1.131
[epoch:119, iter:92657] Loss: 1.394, 10.340, 65.455, 431.465, 1.373
Epoch: [118][400/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 12.6889 (13.3954)	Acc@1 67.188 (63.509)	Acc@5 93.750 (90.041)
[epoch:119, iter:92677] Loss: 1.394, 10.336, 65.510, 431.620, 1.046
[epoch:119, iter:92697] Loss: 1.394, 10.340, 65.499, 431.649, 1.383
[epoch:119, iter:92717] Loss: 1.394, 10.340, 65.519, 431.688, 1.653
[epoch:119, iter:92737] Loss: 1.395, 10.343, 65.530, 431.776, 1.828
[epoch:119, iter:92757] Loss: 1.395, 10.344, 65.545, 431.893, 1.581
Epoch: [118][500/782]	Time 0.067 (0.076)	Data 0.002 (0.003)	Loss 13.5545 (13.4328)	Acc@1 53.125 (63.292)	Acc@5 89.062 (89.836)
[epoch:119, iter:92777] Loss: 1.395, 10.340, 65.559, 431.924, 1.423
[epoch:119, iter:92797] Loss: 1.395, 10.336, 65.592, 431.991, 1.291
[epoch:119, iter:92817] Loss: 1.396, 10.340, 65.629, 432.005, 1.312
[epoch:119, iter:92837] Loss: 1.396, 10.341, 65.661, 432.130, 1.004
[epoch:119, iter:92857] Loss: 1.396, 10.344, 65.683, 432.227, 1.349
Epoch: [118][600/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 14.7523 (13.4590)	Acc@1 51.562 (63.168)	Acc@5 85.938 (89.928)
[epoch:119, iter:92877] Loss: 1.397, 10.346, 65.694, 432.273, 1.905
[epoch:119, iter:92897] Loss: 1.398, 10.348, 65.707, 432.336, 1.415
[epoch:119, iter:92917] Loss: 1.398, 10.349, 65.723, 432.359, 0.954
[epoch:119, iter:92937] Loss: 1.398, 10.350, 65.736, 432.396, 1.367
[epoch:119, iter:92957] Loss: 1.397, 10.348, 65.730, 432.420, 1.417
Epoch: [118][700/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 14.4598 (13.4808)	Acc@1 57.812 (63.064)	Acc@5 89.062 (89.814)
[epoch:119, iter:92977] Loss: 1.397, 10.343, 65.721, 432.441, 1.533
[epoch:119, iter:92997] Loss: 1.397, 10.348, 65.736, 432.563, 1.394
[epoch:119, iter:93017] Loss: 1.397, 10.348, 65.742, 432.601, 1.386
[epoch:119, iter:93037] Loss: 1.398, 10.349, 65.759, 432.624, 1.835
[epoch:119, iter:93057] Loss: 1.398, 10.351, 65.770, 432.607, 1.703
 * Acc@1 63.066 Acc@5 89.798
epoch 118, total time 60.04
Test: [0/313]	Time 0.238 (0.238)	Loss 2.2776 (2.2776)	Acc@1 59.375 (59.375)	Acc@5 68.750 (68.750)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.7802 (2.3716)	Acc@1 46.875 (52.104)	Acc@5 87.500 (80.631)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7402 (2.3303)	Acc@1 65.625 (52.177)	Acc@5 93.750 (81.188)
Test: [300/313]	Time 0.011 (0.008)	Loss 2.8342 (2.3334)	Acc@1 37.500 (51.910)	Acc@5 84.375 (81.105)
 * Acc@1 51.940 Acc@5 81.200
==> training...
Epoch: [119][0/782]	Time 0.566 (0.566)	Data 0.496 (0.496)	Loss 13.1025 (13.1025)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
[epoch:120, iter:93059] Loss: 1.368, 10.594, 66.391, 432.127, 1.281
[epoch:120, iter:93079] Loss: 1.452, 10.784, 67.391, 441.924, 1.357
[epoch:120, iter:93099] Loss: 1.429, 10.651, 66.981, 439.687, 1.710
[epoch:120, iter:93119] Loss: 1.431, 10.619, 66.400, 436.661, 1.034
[epoch:120, iter:93139] Loss: 1.422, 10.555, 66.267, 435.131, 1.033
Epoch: [119][100/782]	Time 0.072 (0.085)	Data 0.002 (0.007)	Loss 12.8999 (13.5323)	Acc@1 73.438 (63.459)	Acc@5 90.625 (89.882)
[epoch:120, iter:93159] Loss: 1.412, 10.500, 66.051, 433.474, 0.935
[epoch:120, iter:93179] Loss: 1.410, 10.472, 65.930, 433.156, 1.071
[epoch:120, iter:93199] Loss: 1.409, 10.449, 65.853, 433.066, 1.514
[epoch:120, iter:93219] Loss: 1.409, 10.440, 65.889, 433.077, 1.731
[epoch:120, iter:93239] Loss: 1.411, 10.434, 66.019, 433.474, 1.107
Epoch: [119][200/782]	Time 0.060 (0.081)	Data 0.002 (0.005)	Loss 13.5940 (13.5318)	Acc@1 56.250 (62.889)	Acc@5 85.938 (89.739)
[epoch:120, iter:93259] Loss: 1.409, 10.421, 65.999, 433.092, 1.471
[epoch:120, iter:93279] Loss: 1.408, 10.415, 65.974, 432.945, 1.103
[epoch:120, iter:93299] Loss: 1.404, 10.399, 65.948, 432.833, 1.157
[epoch:120, iter:93319] Loss: 1.404, 10.399, 65.981, 432.927, 1.497
[epoch:120, iter:93339] Loss: 1.403, 10.396, 65.992, 432.761, 1.293
Epoch: [119][300/782]	Time 0.071 (0.078)	Data 0.002 (0.004)	Loss 12.8469 (13.5181)	Acc@1 56.250 (63.149)	Acc@5 93.750 (89.763)
[epoch:120, iter:93359] Loss: 1.404, 10.403, 66.025, 432.780, 1.237
[epoch:120, iter:93379] Loss: 1.404, 10.393, 66.049, 432.786, 1.248
[epoch:120, iter:93399] Loss: 1.404, 10.400, 66.015, 432.760, 1.309
[epoch:120, iter:93419] Loss: 1.404, 10.394, 65.985, 432.668, 1.081
[epoch:120, iter:93439] Loss: 1.404, 10.390, 65.974, 432.628, 1.393
Epoch: [119][400/782]	Time 0.076 (0.078)	Data 0.002 (0.004)	Loss 14.0756 (13.5198)	Acc@1 56.250 (63.084)	Acc@5 79.688 (89.713)
[epoch:120, iter:93459] Loss: 1.403, 10.382, 66.003, 432.684, 1.716
[epoch:120, iter:93479] Loss: 1.403, 10.383, 66.006, 432.685, 1.264
[epoch:120, iter:93499] Loss: 1.403, 10.384, 65.944, 432.546, 1.634
[epoch:120, iter:93519] Loss: 1.403, 10.382, 65.918, 432.481, 1.296
[epoch:120, iter:93539] Loss: 1.404, 10.385, 65.924, 432.588, 1.137
Epoch: [119][500/782]	Time 0.095 (0.078)	Data 0.003 (0.003)	Loss 14.0087 (13.5292)	Acc@1 57.812 (63.030)	Acc@5 84.375 (89.512)
[epoch:120, iter:93559] Loss: 1.405, 10.382, 65.935, 432.795, 1.636
[epoch:120, iter:93579] Loss: 1.404, 10.380, 65.912, 432.758, 1.377
[epoch:120, iter:93599] Loss: 1.405, 10.380, 65.881, 432.698, 1.378
[epoch:120, iter:93619] Loss: 1.405, 10.379, 65.832, 432.579, 1.325
[epoch:120, iter:93639] Loss: 1.405, 10.379, 65.816, 432.571, 1.087
Epoch: [119][600/782]	Time 0.083 (0.079)	Data 0.003 (0.003)	Loss 14.1344 (13.5150)	Acc@1 56.250 (63.025)	Acc@5 81.250 (89.489)
[epoch:120, iter:93659] Loss: 1.405, 10.380, 65.803, 432.609, 1.681
[epoch:120, iter:93679] Loss: 1.405, 10.377, 65.800, 432.605, 1.310
[epoch:120, iter:93699] Loss: 1.405, 10.379, 65.805, 432.644, 1.328
[epoch:120, iter:93719] Loss: 1.406, 10.383, 65.823, 432.701, 1.303
[epoch:120, iter:93739] Loss: 1.405, 10.383, 65.819, 432.638, 1.357
Epoch: [119][700/782]	Time 0.065 (0.079)	Data 0.002 (0.003)	Loss 13.0607 (13.5222)	Acc@1 59.375 (62.986)	Acc@5 89.062 (89.504)
[epoch:120, iter:93759] Loss: 1.405, 10.385, 65.829, 432.707, 1.510
[epoch:120, iter:93779] Loss: 1.405, 10.386, 65.811, 432.690, 1.596
[epoch:120, iter:93799] Loss: 1.405, 10.384, 65.802, 432.701, 1.061
[epoch:120, iter:93819] Loss: 1.405, 10.385, 65.793, 432.743, 1.570
[epoch:120, iter:93839] Loss: 1.405, 10.383, 65.808, 432.729, 1.735
 * Acc@1 62.958 Acc@5 89.472
epoch 119, total time 61.64
Test: [0/313]	Time 0.260 (0.260)	Loss 1.8318 (1.8318)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.6872 (2.0406)	Acc@1 50.000 (54.765)	Acc@5 81.250 (84.282)
Test: [200/313]	Time 0.009 (0.009)	Loss 1.5515 (1.9803)	Acc@1 62.500 (55.675)	Acc@5 90.625 (84.453)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.0261 (1.9860)	Acc@1 59.375 (55.700)	Acc@5 84.375 (84.219)
 * Acc@1 55.710 Acc@5 84.320
==> training...
Epoch: [120][0/782]	Time 0.544 (0.544)	Data 0.465 (0.465)	Loss 13.7753 (13.7753)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
[epoch:121, iter:93841] Loss: 1.365, 10.707, 67.599, 438.231, 1.238
[epoch:121, iter:93861] Loss: 1.414, 10.479, 65.997, 433.751, 1.026
[epoch:121, iter:93881] Loss: 1.406, 10.403, 65.323, 431.495, 0.884
[epoch:121, iter:93901] Loss: 1.393, 10.375, 65.098, 430.324, 1.324
[epoch:121, iter:93921] Loss: 1.386, 10.375, 65.163, 430.216, 1.477
Epoch: [120][100/782]	Time 0.073 (0.081)	Data 0.004 (0.007)	Loss 13.1773 (13.2432)	Acc@1 62.500 (64.527)	Acc@5 89.062 (90.656)
[epoch:121, iter:93941] Loss: 1.387, 10.358, 65.301, 430.243, 1.331
[epoch:121, iter:93961] Loss: 1.389, 10.371, 65.355, 430.142, 1.206
[epoch:121, iter:93981] Loss: 1.398, 10.370, 65.360, 430.489, 1.171
[epoch:121, iter:94001] Loss: 1.397, 10.359, 65.398, 430.662, 1.334
[epoch:121, iter:94021] Loss: 1.396, 10.350, 65.413, 430.817, 1.053
Epoch: [120][200/782]	Time 0.085 (0.076)	Data 0.003 (0.004)	Loss 12.2824 (13.3066)	Acc@1 67.188 (64.482)	Acc@5 93.750 (90.477)
[epoch:121, iter:94041] Loss: 1.394, 10.348, 65.373, 430.550, 1.083
[epoch:121, iter:94061] Loss: 1.395, 10.344, 65.382, 430.607, 1.158
[epoch:121, iter:94081] Loss: 1.393, 10.341, 65.340, 430.660, 1.816
[epoch:121, iter:94101] Loss: 1.392, 10.341, 65.362, 430.869, 1.519
[epoch:121, iter:94121] Loss: 1.393, 10.337, 65.432, 431.224, 1.289
Epoch: [120][300/782]	Time 0.071 (0.077)	Data 0.002 (0.004)	Loss 14.0706 (13.3693)	Acc@1 60.938 (64.275)	Acc@5 87.500 (90.184)
[epoch:121, iter:94141] Loss: 1.393, 10.333, 65.450, 431.263, 1.519
[epoch:121, iter:94161] Loss: 1.397, 10.338, 65.517, 431.440, 1.498
[epoch:121, iter:94181] Loss: 1.399, 10.342, 65.626, 431.836, 1.378
[epoch:121, iter:94201] Loss: 1.399, 10.348, 65.675, 431.834, 1.823
[epoch:121, iter:94221] Loss: 1.399, 10.356, 65.709, 431.847, 1.422
Epoch: [120][400/782]	Time 0.087 (0.077)	Data 0.003 (0.003)	Loss 13.1190 (13.4256)	Acc@1 73.438 (63.922)	Acc@5 92.188 (89.935)
[epoch:121, iter:94241] Loss: 1.400, 10.356, 65.709, 431.850, 1.018
[epoch:121, iter:94261] Loss: 1.399, 10.351, 65.693, 431.668, 1.632
[epoch:121, iter:94281] Loss: 1.398, 10.353, 65.655, 431.614, 1.327
[epoch:121, iter:94301] Loss: 1.397, 10.357, 65.653, 431.680, 1.318
[epoch:121, iter:94321] Loss: 1.396, 10.356, 65.630, 431.520, 1.502
Epoch: [120][500/782]	Time 0.080 (0.076)	Data 0.002 (0.003)	Loss 12.6784 (13.4136)	Acc@1 75.000 (63.832)	Acc@5 92.188 (89.898)
[epoch:121, iter:94341] Loss: 1.396, 10.349, 65.609, 431.505, 1.020
[epoch:121, iter:94361] Loss: 1.395, 10.342, 65.606, 431.498, 1.361
[epoch:121, iter:94381] Loss: 1.396, 10.342, 65.616, 431.487, 1.327
[epoch:121, iter:94401] Loss: 1.395, 10.340, 65.609, 431.498, 1.470
[epoch:121, iter:94421] Loss: 1.395, 10.342, 65.610, 431.615, 1.330
Epoch: [120][600/782]	Time 0.074 (0.076)	Data 0.002 (0.003)	Loss 14.2270 (13.4294)	Acc@1 50.000 (63.706)	Acc@5 89.062 (89.853)
[epoch:121, iter:94441] Loss: 1.395, 10.343, 65.676, 431.740, 1.750
[epoch:121, iter:94461] Loss: 1.394, 10.339, 65.678, 431.688, 1.227
[epoch:121, iter:94481] Loss: 1.394, 10.341, 65.693, 431.730, 0.985
[epoch:121, iter:94501] Loss: 1.395, 10.343, 65.680, 431.762, 1.172
[epoch:121, iter:94521] Loss: 1.395, 10.342, 65.677, 431.749, 1.299
Epoch: [120][700/782]	Time 0.071 (0.076)	Data 0.002 (0.003)	Loss 13.7816 (13.4401)	Acc@1 64.062 (63.499)	Acc@5 92.188 (89.809)
[epoch:121, iter:94541] Loss: 1.396, 10.340, 65.698, 431.824, 1.331
[epoch:121, iter:94561] Loss: 1.396, 10.342, 65.703, 431.849, 1.297
[epoch:121, iter:94581] Loss: 1.396, 10.348, 65.691, 431.845, 1.559
[epoch:121, iter:94601] Loss: 1.396, 10.344, 65.669, 431.848, 1.552
[epoch:121, iter:94621] Loss: 1.396, 10.344, 65.699, 431.896, 1.538
 * Acc@1 63.354 Acc@5 89.752
epoch 120, total time 59.58
Test: [0/313]	Time 0.234 (0.234)	Loss 1.7841 (1.7841)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.1116 (2.1967)	Acc@1 53.125 (53.682)	Acc@5 84.375 (83.571)
Test: [200/313]	Time 0.006 (0.009)	Loss 1.2950 (2.2241)	Acc@1 65.625 (53.234)	Acc@5 93.750 (83.364)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.5386 (2.2049)	Acc@1 43.750 (53.457)	Acc@5 78.125 (83.129)
 * Acc@1 53.400 Acc@5 83.160
==> Saving...
==> training...
Epoch: [121][0/782]	Time 0.566 (0.566)	Data 0.491 (0.491)	Loss 14.2764 (14.2764)	Acc@1 51.562 (51.562)	Acc@5 90.625 (90.625)
[epoch:122, iter:94623] Loss: 1.512, 10.493, 72.829, 445.982, 1.521
[epoch:122, iter:94643] Loss: 1.416, 10.374, 67.211, 435.703, 1.192
[epoch:122, iter:94663] Loss: 1.406, 10.397, 66.347, 433.140, 1.026
[epoch:122, iter:94683] Loss: 1.406, 10.355, 65.831, 431.683, 1.006
[epoch:122, iter:94703] Loss: 1.394, 10.323, 65.810, 431.546, 0.935
Epoch: [121][100/782]	Time 0.076 (0.080)	Data 0.002 (0.007)	Loss 13.8896 (13.3509)	Acc@1 56.250 (63.119)	Acc@5 89.062 (90.362)
[epoch:122, iter:94723] Loss: 1.392, 10.315, 65.912, 431.667, 1.593
[epoch:122, iter:94743] Loss: 1.392, 10.318, 65.885, 431.714, 1.467
[epoch:122, iter:94763] Loss: 1.393, 10.324, 65.910, 431.901, 1.383
[epoch:122, iter:94783] Loss: 1.396, 10.325, 65.911, 431.763, 1.140
[epoch:122, iter:94803] Loss: 1.396, 10.335, 65.922, 431.906, 1.148
Epoch: [121][200/782]	Time 0.073 (0.078)	Data 0.002 (0.005)	Loss 14.4713 (13.4217)	Acc@1 53.125 (63.013)	Acc@5 81.250 (90.104)
[epoch:122, iter:94823] Loss: 1.399, 10.354, 66.011, 432.016, 1.872
[epoch:122, iter:94843] Loss: 1.400, 10.370, 66.057, 432.127, 1.470
[epoch:122, iter:94863] Loss: 1.402, 10.372, 66.156, 432.600, 1.461
[epoch:122, iter:94883] Loss: 1.401, 10.377, 66.163, 432.634, 1.601
[epoch:122, iter:94903] Loss: 1.403, 10.373, 66.142, 432.574, 1.649
Epoch: [121][300/782]	Time 0.066 (0.077)	Data 0.002 (0.004)	Loss 12.9580 (13.4668)	Acc@1 60.938 (63.040)	Acc@5 92.188 (89.961)
[epoch:122, iter:94923] Loss: 1.402, 10.374, 66.138, 432.468, 1.033
[epoch:122, iter:94943] Loss: 1.402, 10.375, 66.179, 432.598, 1.561
[epoch:122, iter:94963] Loss: 1.400, 10.375, 66.115, 432.576, 1.527
[epoch:122, iter:94983] Loss: 1.400, 10.378, 66.042, 432.458, 1.952
[epoch:122, iter:95003] Loss: 1.400, 10.383, 66.006, 432.525, 1.300
Epoch: [121][400/782]	Time 0.061 (0.075)	Data 0.002 (0.003)	Loss 14.3250 (13.4831)	Acc@1 56.250 (63.178)	Acc@5 92.188 (89.892)
[epoch:122, iter:95023] Loss: 1.400, 10.381, 65.996, 432.575, 1.232
[epoch:122, iter:95043] Loss: 1.402, 10.384, 66.000, 432.643, 1.130
[epoch:122, iter:95063] Loss: 1.402, 10.384, 65.987, 432.637, 1.361
[epoch:122, iter:95083] Loss: 1.401, 10.378, 65.982, 432.710, 1.010
[epoch:122, iter:95103] Loss: 1.401, 10.376, 65.971, 432.685, 1.818
Epoch: [121][500/782]	Time 0.077 (0.075)	Data 0.002 (0.003)	Loss 13.7671 (13.4829)	Acc@1 68.750 (63.270)	Acc@5 92.188 (89.886)
[epoch:122, iter:95123] Loss: 1.400, 10.374, 65.955, 432.626, 1.120
[epoch:122, iter:95143] Loss: 1.399, 10.372, 65.964, 432.682, 1.762
[epoch:122, iter:95163] Loss: 1.399, 10.375, 65.989, 432.761, 1.265
[epoch:122, iter:95183] Loss: 1.399, 10.375, 66.028, 432.739, 1.309
[epoch:122, iter:95203] Loss: 1.400, 10.380, 66.039, 432.778, 1.973
Epoch: [121][600/782]	Time 0.088 (0.075)	Data 0.002 (0.003)	Loss 12.8826 (13.5079)	Acc@1 68.750 (63.145)	Acc@5 90.625 (89.837)
[epoch:122, iter:95223] Loss: 1.399, 10.383, 66.058, 432.880, 1.015
[epoch:122, iter:95243] Loss: 1.399, 10.384, 66.069, 432.954, 1.208
[epoch:122, iter:95263] Loss: 1.399, 10.387, 66.044, 432.889, 1.179
[epoch:122, iter:95283] Loss: 1.399, 10.385, 66.013, 432.804, 1.453
[epoch:122, iter:95303] Loss: 1.399, 10.385, 65.993, 432.772, 1.425
Epoch: [121][700/782]	Time 0.073 (0.075)	Data 0.002 (0.003)	Loss 13.3786 (13.5115)	Acc@1 64.062 (63.117)	Acc@5 92.188 (89.852)
[epoch:122, iter:95323] Loss: 1.400, 10.386, 65.984, 432.770, 1.073
[epoch:122, iter:95343] Loss: 1.400, 10.388, 65.986, 432.801, 1.357
[epoch:122, iter:95363] Loss: 1.400, 10.389, 65.981, 432.803, 1.792
[epoch:122, iter:95383] Loss: 1.400, 10.387, 65.959, 432.715, 1.215
[epoch:122, iter:95403] Loss: 1.399, 10.385, 65.965, 432.763, 1.479
 * Acc@1 63.030 Acc@5 89.800
epoch 121, total time 58.90
Test: [0/313]	Time 0.278 (0.278)	Loss 1.6925 (1.6925)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.7538 (1.9378)	Acc@1 56.250 (55.198)	Acc@5 87.500 (84.715)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.1134 (1.9478)	Acc@1 68.750 (55.799)	Acc@5 87.500 (84.188)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.4312 (1.9590)	Acc@1 37.500 (55.835)	Acc@5 78.125 (84.022)
 * Acc@1 55.920 Acc@5 84.020
==> training...
Epoch: [122][0/782]	Time 0.501 (0.501)	Data 0.437 (0.437)	Loss 13.2588 (13.2588)	Acc@1 54.688 (54.688)	Acc@5 93.750 (93.750)
[epoch:123, iter:95405] Loss: 1.308, 10.326, 65.144, 428.414, 1.459
[epoch:123, iter:95425] Loss: 1.417, 10.356, 65.330, 430.635, 1.475
[epoch:123, iter:95445] Loss: 1.407, 10.338, 65.341, 431.421, 1.279
[epoch:123, iter:95465] Loss: 1.413, 10.345, 65.516, 431.924, 0.684
[epoch:123, iter:95485] Loss: 1.409, 10.342, 65.565, 431.814, 1.268
Epoch: [122][100/782]	Time 0.090 (0.082)	Data 0.002 (0.007)	Loss 12.8061 (13.3887)	Acc@1 67.188 (63.861)	Acc@5 85.938 (90.501)
[epoch:123, iter:95505] Loss: 1.404, 10.328, 65.583, 431.670, 1.267
[epoch:123, iter:95525] Loss: 1.403, 10.350, 65.610, 431.782, 1.189
[epoch:123, iter:95545] Loss: 1.403, 10.356, 65.711, 431.883, 1.083
[epoch:123, iter:95565] Loss: 1.400, 10.358, 65.644, 431.559, 1.167
[epoch:123, iter:95585] Loss: 1.400, 10.366, 65.635, 431.534, 1.433
Epoch: [122][200/782]	Time 0.091 (0.080)	Data 0.003 (0.004)	Loss 13.5435 (13.3970)	Acc@1 68.750 (63.643)	Acc@5 85.938 (90.127)
[epoch:123, iter:95605] Loss: 1.400, 10.364, 65.621, 431.642, 1.279
[epoch:123, iter:95625] Loss: 1.399, 10.358, 65.665, 431.865, 1.316
[epoch:123, iter:95645] Loss: 1.397, 10.353, 65.615, 431.686, 1.129
[epoch:123, iter:95665] Loss: 1.396, 10.348, 65.557, 431.680, 1.635
[epoch:123, iter:95685] Loss: 1.396, 10.349, 65.579, 431.704, 1.460
Epoch: [122][300/782]	Time 0.074 (0.080)	Data 0.003 (0.004)	Loss 12.9752 (13.3669)	Acc@1 67.188 (63.580)	Acc@5 95.312 (90.085)
[epoch:123, iter:95705] Loss: 1.395, 10.339, 65.445, 431.340, 1.070
[epoch:123, iter:95725] Loss: 1.396, 10.335, 65.484, 431.429, 1.223
[epoch:123, iter:95745] Loss: 1.395, 10.336, 65.465, 431.403, 1.299
[epoch:123, iter:95765] Loss: 1.394, 10.326, 65.426, 431.339, 1.553
[epoch:123, iter:95785] Loss: 1.393, 10.323, 65.408, 431.309, 1.578
Epoch: [122][400/782]	Time 0.085 (0.080)	Data 0.003 (0.003)	Loss 13.4492 (13.3862)	Acc@1 65.625 (63.521)	Acc@5 87.500 (90.025)
[epoch:123, iter:95805] Loss: 1.394, 10.328, 65.421, 431.478, 1.480
[epoch:123, iter:95825] Loss: 1.393, 10.331, 65.454, 431.673, 1.165
[epoch:123, iter:95845] Loss: 1.394, 10.338, 65.472, 431.604, 1.397
[epoch:123, iter:95865] Loss: 1.394, 10.339, 65.523, 431.728, 1.818
[epoch:123, iter:95885] Loss: 1.393, 10.338, 65.509, 431.647, 0.816
Epoch: [122][500/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 13.6408 (13.3964)	Acc@1 53.125 (63.507)	Acc@5 87.500 (89.976)
[epoch:123, iter:95905] Loss: 1.394, 10.342, 65.495, 431.724, 1.492
[epoch:123, iter:95925] Loss: 1.394, 10.343, 65.469, 431.695, 1.000
[epoch:123, iter:95945] Loss: 1.393, 10.342, 65.462, 431.682, 1.318
[epoch:123, iter:95965] Loss: 1.393, 10.343, 65.481, 431.742, 1.621
[epoch:123, iter:95985] Loss: 1.394, 10.348, 65.501, 431.822, 1.336
Epoch: [122][600/782]	Time 0.071 (0.079)	Data 0.002 (0.003)	Loss 13.3009 (13.4134)	Acc@1 60.938 (63.324)	Acc@5 90.625 (89.959)
[epoch:123, iter:96005] Loss: 1.395, 10.349, 65.513, 431.845, 1.310
[epoch:123, iter:96025] Loss: 1.395, 10.348, 65.545, 431.831, 1.380
[epoch:123, iter:96045] Loss: 1.395, 10.350, 65.565, 431.899, 1.215
[epoch:123, iter:96065] Loss: 1.395, 10.354, 65.609, 431.892, 1.888
[epoch:123, iter:96085] Loss: 1.395, 10.357, 65.640, 432.009, 1.400
Epoch: [122][700/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 13.6489 (13.4483)	Acc@1 65.625 (63.184)	Acc@5 93.750 (89.869)
[epoch:123, iter:96105] Loss: 1.396, 10.359, 65.681, 432.089, 1.284
[epoch:123, iter:96125] Loss: 1.396, 10.362, 65.669, 432.117, 1.504
[epoch:123, iter:96145] Loss: 1.397, 10.364, 65.667, 432.179, 1.594
[epoch:123, iter:96165] Loss: 1.397, 10.363, 65.665, 432.238, 1.613
[epoch:123, iter:96185] Loss: 1.397, 10.365, 65.681, 432.288, 1.195
 * Acc@1 63.186 Acc@5 89.802
epoch 122, total time 60.97
Test: [0/313]	Time 0.225 (0.225)	Loss 2.6106 (2.6106)	Acc@1 53.125 (53.125)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.3615 (2.1960)	Acc@1 53.125 (51.918)	Acc@5 84.375 (81.652)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7537 (2.2320)	Acc@1 53.125 (51.897)	Acc@5 84.375 (80.955)
Test: [300/313]	Time 0.009 (0.008)	Loss 2.3776 (2.2359)	Acc@1 40.625 (52.108)	Acc@5 78.125 (80.721)
 * Acc@1 51.990 Acc@5 80.840
==> training...
Epoch: [123][0/782]	Time 0.559 (0.559)	Data 0.465 (0.465)	Loss 13.2106 (13.2106)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
[epoch:124, iter:96187] Loss: 1.367, 10.582, 67.890, 429.285, 1.059
[epoch:124, iter:96207] Loss: 1.399, 10.563, 66.032, 432.358, 1.340
[epoch:124, iter:96227] Loss: 1.406, 10.562, 66.053, 433.200, 1.119
[epoch:124, iter:96247] Loss: 1.403, 10.508, 65.608, 432.433, 1.440
[epoch:124, iter:96267] Loss: 1.403, 10.447, 65.418, 431.767, 1.845
Epoch: [123][100/782]	Time 0.071 (0.082)	Data 0.002 (0.007)	Loss 12.8042 (13.4234)	Acc@1 68.750 (63.397)	Acc@5 95.312 (89.867)
[epoch:124, iter:96287] Loss: 1.403, 10.421, 65.454, 431.366, 0.987
[epoch:124, iter:96307] Loss: 1.400, 10.405, 65.505, 431.613, 0.792
[epoch:124, iter:96327] Loss: 1.399, 10.387, 65.488, 431.971, 0.876
[epoch:124, iter:96347] Loss: 1.398, 10.397, 65.391, 431.695, 1.454
[epoch:124, iter:96367] Loss: 1.398, 10.383, 65.403, 431.871, 1.286
Epoch: [123][200/782]	Time 0.071 (0.081)	Data 0.002 (0.005)	Loss 13.9816 (13.4237)	Acc@1 54.688 (63.417)	Acc@5 87.500 (89.809)
[epoch:124, iter:96387] Loss: 1.395, 10.379, 65.346, 431.744, 1.431
[epoch:124, iter:96407] Loss: 1.396, 10.366, 65.372, 431.435, 1.497
[epoch:124, iter:96427] Loss: 1.396, 10.374, 65.526, 431.508, 0.692
[epoch:124, iter:96447] Loss: 1.396, 10.378, 65.577, 431.698, 1.314
[epoch:124, iter:96467] Loss: 1.399, 10.382, 65.542, 431.542, 1.535
Epoch: [123][300/782]	Time 0.069 (0.080)	Data 0.002 (0.004)	Loss 13.6308 (13.4167)	Acc@1 57.812 (63.559)	Acc@5 87.500 (89.820)
[epoch:124, iter:96487] Loss: 1.398, 10.380, 65.491, 431.313, 1.502
[epoch:124, iter:96507] Loss: 1.398, 10.384, 65.511, 431.270, 1.342
[epoch:124, iter:96527] Loss: 1.398, 10.376, 65.549, 431.353, 1.760
[epoch:124, iter:96547] Loss: 1.399, 10.369, 65.518, 431.285, 1.418
[epoch:124, iter:96567] Loss: 1.399, 10.371, 65.555, 431.405, 1.275
Epoch: [123][400/782]	Time 0.077 (0.080)	Data 0.002 (0.004)	Loss 13.7407 (13.4358)	Acc@1 59.375 (63.287)	Acc@5 85.938 (89.811)
[epoch:124, iter:96587] Loss: 1.399, 10.371, 65.555, 431.392, 1.555
[epoch:124, iter:96607] Loss: 1.399, 10.373, 65.534, 431.195, 1.218
[epoch:124, iter:96627] Loss: 1.401, 10.379, 65.598, 431.313, 1.113
[epoch:124, iter:96647] Loss: 1.402, 10.381, 65.623, 431.423, 1.414
[epoch:124, iter:96667] Loss: 1.401, 10.375, 65.619, 431.353, 1.495
Epoch: [123][500/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 12.5017 (13.4355)	Acc@1 76.562 (63.517)	Acc@5 87.500 (89.926)
[epoch:124, iter:96687] Loss: 1.401, 10.372, 65.642, 431.289, 1.007
[epoch:124, iter:96707] Loss: 1.401, 10.369, 65.658, 431.350, 1.317
[epoch:124, iter:96727] Loss: 1.401, 10.368, 65.691, 431.496, 1.386
[epoch:124, iter:96747] Loss: 1.402, 10.372, 65.709, 431.657, 1.278
[epoch:124, iter:96767] Loss: 1.403, 10.379, 65.719, 431.780, 1.645
Epoch: [123][600/782]	Time 0.090 (0.080)	Data 0.003 (0.003)	Loss 13.6047 (13.4859)	Acc@1 67.188 (63.327)	Acc@5 96.875 (89.741)
[epoch:124, iter:96787] Loss: 1.403, 10.384, 65.746, 431.901, 0.987
[epoch:124, iter:96807] Loss: 1.402, 10.384, 65.759, 431.945, 1.346
[epoch:124, iter:96827] Loss: 1.402, 10.386, 65.796, 432.092, 1.159
[epoch:124, iter:96847] Loss: 1.402, 10.386, 65.800, 432.090, 1.667
[epoch:124, iter:96867] Loss: 1.403, 10.387, 65.810, 432.140, 1.534
Epoch: [123][700/782]	Time 0.061 (0.080)	Data 0.002 (0.003)	Loss 13.8015 (13.5022)	Acc@1 62.500 (63.166)	Acc@5 82.812 (89.660)
[epoch:124, iter:96887] Loss: 1.403, 10.385, 65.806, 432.071, 1.627
[epoch:124, iter:96907] Loss: 1.402, 10.384, 65.788, 431.985, 1.315
[epoch:124, iter:96927] Loss: 1.402, 10.383, 65.796, 431.997, 1.688
[epoch:124, iter:96947] Loss: 1.402, 10.383, 65.787, 431.974, 1.350
[epoch:124, iter:96967] Loss: 1.401, 10.382, 65.796, 432.010, 1.139
 * Acc@1 63.186 Acc@5 89.672
epoch 123, total time 63.48
Test: [0/313]	Time 0.262 (0.262)	Loss 1.6281 (1.6281)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.1784 (1.8992)	Acc@1 43.750 (55.229)	Acc@5 78.125 (84.777)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5459 (1.9006)	Acc@1 59.375 (55.519)	Acc@5 87.500 (84.468)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.9149 (1.9181)	Acc@1 50.000 (55.305)	Acc@5 87.500 (84.084)
 * Acc@1 55.390 Acc@5 84.130
==> training...
Epoch: [124][0/782]	Time 0.555 (0.555)	Data 0.460 (0.460)	Loss 12.9684 (12.9684)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
[epoch:125, iter:96969] Loss: 1.343, 10.289, 64.641, 417.643, 1.388
[epoch:125, iter:96989] Loss: 1.406, 10.424, 65.697, 431.560, 1.254
[epoch:125, iter:97009] Loss: 1.393, 10.369, 65.229, 429.729, 1.101
[epoch:125, iter:97029] Loss: 1.388, 10.327, 65.253, 429.326, 1.361
[epoch:125, iter:97049] Loss: 1.390, 10.327, 65.270, 429.337, 1.485
Epoch: [124][100/782]	Time 0.068 (0.085)	Data 0.002 (0.007)	Loss 13.7592 (13.3284)	Acc@1 65.625 (63.923)	Acc@5 87.500 (90.130)
[epoch:125, iter:97069] Loss: 1.391, 10.338, 65.533, 430.391, 1.255
[epoch:125, iter:97089] Loss: 1.393, 10.329, 65.515, 430.141, 1.555
[epoch:125, iter:97109] Loss: 1.389, 10.322, 65.426, 430.475, 1.627
[epoch:125, iter:97129] Loss: 1.390, 10.344, 65.347, 430.760, 1.198
[epoch:125, iter:97149] Loss: 1.391, 10.330, 65.202, 430.704, 1.040
Epoch: [124][200/782]	Time 0.088 (0.077)	Data 0.003 (0.004)	Loss 13.4306 (13.3308)	Acc@1 75.000 (63.402)	Acc@5 87.500 (89.894)
[epoch:125, iter:97169] Loss: 1.389, 10.326, 65.166, 430.296, 1.271
[epoch:125, iter:97189] Loss: 1.392, 10.323, 65.230, 430.487, 1.084
[epoch:125, iter:97209] Loss: 1.390, 10.321, 65.204, 430.342, 1.244
[epoch:125, iter:97229] Loss: 1.389, 10.326, 65.194, 430.389, 1.270
[epoch:125, iter:97249] Loss: 1.389, 10.319, 65.220, 430.364, 1.507
Epoch: [124][300/782]	Time 0.081 (0.075)	Data 0.002 (0.004)	Loss 12.8867 (13.3641)	Acc@1 68.750 (63.336)	Acc@5 93.750 (89.914)
[epoch:125, iter:97269] Loss: 1.390, 10.321, 65.312, 430.734, 0.908
[epoch:125, iter:97289] Loss: 1.391, 10.317, 65.390, 431.077, 1.498
[epoch:125, iter:97309] Loss: 1.391, 10.316, 65.470, 431.358, 1.320
[epoch:125, iter:97329] Loss: 1.391, 10.322, 65.528, 431.536, 1.280
[epoch:125, iter:97349] Loss: 1.393, 10.324, 65.513, 431.490, 1.242
Epoch: [124][400/782]	Time 0.086 (0.075)	Data 0.003 (0.003)	Loss 13.1836 (13.4264)	Acc@1 62.500 (63.186)	Acc@5 89.062 (89.717)
[epoch:125, iter:97369] Loss: 1.393, 10.325, 65.502, 431.592, 1.471
[epoch:125, iter:97389] Loss: 1.393, 10.328, 65.479, 431.549, 1.314
[epoch:125, iter:97409] Loss: 1.394, 10.330, 65.512, 431.679, 1.220
[epoch:125, iter:97429] Loss: 1.395, 10.334, 65.536, 431.762, 1.456
[epoch:125, iter:97449] Loss: 1.395, 10.334, 65.565, 431.783, 1.614
Epoch: [124][500/782]	Time 0.079 (0.076)	Data 0.003 (0.003)	Loss 13.4564 (13.4582)	Acc@1 64.062 (62.971)	Acc@5 85.938 (89.633)
[epoch:125, iter:97469] Loss: 1.394, 10.331, 65.590, 431.720, 1.501
[epoch:125, iter:97489] Loss: 1.394, 10.331, 65.644, 431.794, 1.122
[epoch:125, iter:97509] Loss: 1.395, 10.335, 65.649, 431.713, 1.459
[epoch:125, iter:97529] Loss: 1.395, 10.330, 65.639, 431.639, 1.114
[epoch:125, iter:97549] Loss: 1.394, 10.330, 65.642, 431.817, 1.885
Epoch: [124][600/782]	Time 0.064 (0.075)	Data 0.002 (0.003)	Loss 15.2289 (13.4691)	Acc@1 50.000 (63.004)	Acc@5 76.562 (89.608)
[epoch:125, iter:97569] Loss: 1.394, 10.333, 65.670, 431.929, 2.024
[epoch:125, iter:97589] Loss: 1.395, 10.339, 65.688, 432.004, 1.555
[epoch:125, iter:97609] Loss: 1.396, 10.341, 65.727, 432.055, 1.378
[epoch:125, iter:97629] Loss: 1.396, 10.344, 65.725, 432.037, 0.964
[epoch:125, iter:97649] Loss: 1.396, 10.345, 65.730, 432.110, 1.770
Epoch: [124][700/782]	Time 0.064 (0.075)	Data 0.002 (0.003)	Loss 14.2215 (13.4984)	Acc@1 57.812 (62.899)	Acc@5 87.500 (89.602)
[epoch:125, iter:97669] Loss: 1.397, 10.352, 65.785, 432.295, 1.517
[epoch:125, iter:97689] Loss: 1.397, 10.357, 65.822, 432.402, 1.522
[epoch:125, iter:97709] Loss: 1.398, 10.361, 65.830, 432.444, 1.457
[epoch:125, iter:97729] Loss: 1.399, 10.367, 65.843, 432.413, 1.749
[epoch:125, iter:97749] Loss: 1.400, 10.368, 65.854, 432.463, 1.421
 * Acc@1 62.878 Acc@5 89.594
epoch 124, total time 58.31
Test: [0/313]	Time 0.223 (0.223)	Loss 2.2928 (2.2928)	Acc@1 56.250 (56.250)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.008)	Loss 2.4051 (1.9836)	Acc@1 43.750 (55.972)	Acc@5 78.125 (85.334)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.7004 (1.9803)	Acc@1 59.375 (55.846)	Acc@5 90.625 (84.997)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.0897 (1.9833)	Acc@1 59.375 (55.648)	Acc@5 84.375 (85.123)
 * Acc@1 55.750 Acc@5 85.180
==> training...
Epoch: [125][0/782]	Time 0.488 (0.488)	Data 0.390 (0.390)	Loss 13.8226 (13.8226)	Acc@1 57.812 (57.812)	Acc@5 87.500 (87.500)
[epoch:126, iter:97751] Loss: 1.550, 10.449, 67.374, 423.069, 1.656
[epoch:126, iter:97771] Loss: 1.417, 10.519, 66.407, 428.518, 1.221
[epoch:126, iter:97791] Loss: 1.399, 10.513, 66.303, 429.047, 1.273
[epoch:126, iter:97811] Loss: 1.398, 10.423, 66.391, 430.663, 0.742
[epoch:126, iter:97831] Loss: 1.390, 10.409, 65.888, 430.022, 0.917
Epoch: [125][100/782]	Time 0.073 (0.081)	Data 0.002 (0.006)	Loss 13.6844 (13.3908)	Acc@1 60.938 (63.567)	Acc@5 90.625 (90.254)
[epoch:126, iter:97851] Loss: 1.394, 10.400, 65.921, 430.643, 1.354
[epoch:126, iter:97871] Loss: 1.393, 10.394, 65.887, 431.047, 1.116
[epoch:126, iter:97891] Loss: 1.397, 10.398, 65.857, 430.857, 1.026
[epoch:126, iter:97911] Loss: 1.394, 10.397, 65.771, 430.674, 1.470
[epoch:126, iter:97931] Loss: 1.395, 10.385, 65.755, 430.471, 0.947
Epoch: [125][200/782]	Time 0.063 (0.079)	Data 0.002 (0.004)	Loss 13.0347 (13.3615)	Acc@1 64.062 (63.961)	Acc@5 95.312 (90.454)
[epoch:126, iter:97951] Loss: 1.396, 10.364, 65.815, 430.636, 1.021
[epoch:126, iter:97971] Loss: 1.395, 10.375, 65.788, 430.791, 1.104
[epoch:126, iter:97991] Loss: 1.395, 10.376, 65.693, 430.669, 1.365
[epoch:126, iter:98011] Loss: 1.397, 10.373, 65.674, 430.815, 1.130
[epoch:126, iter:98031] Loss: 1.396, 10.378, 65.637, 430.840, 1.178
Epoch: [125][300/782]	Time 0.092 (0.077)	Data 0.001 (0.004)	Loss 13.4069 (13.3922)	Acc@1 57.812 (63.808)	Acc@5 85.938 (90.308)
[epoch:126, iter:98051] Loss: 1.396, 10.376, 65.663, 430.931, 1.635
[epoch:126, iter:98071] Loss: 1.395, 10.368, 65.657, 430.800, 1.134
[epoch:126, iter:98091] Loss: 1.394, 10.364, 65.585, 430.715, 1.729
[epoch:126, iter:98111] Loss: 1.394, 10.365, 65.541, 430.623, 1.632
[epoch:126, iter:98131] Loss: 1.395, 10.357, 65.500, 430.582, 1.502
Epoch: [125][400/782]	Time 0.111 (0.077)	Data 0.003 (0.003)	Loss 13.0336 (13.3878)	Acc@1 71.875 (63.665)	Acc@5 92.188 (90.270)
[epoch:126, iter:98151] Loss: 1.397, 10.358, 65.574, 430.826, 1.071
[epoch:126, iter:98171] Loss: 1.397, 10.355, 65.661, 431.105, 1.682
[epoch:126, iter:98191] Loss: 1.398, 10.355, 65.716, 431.345, 1.597
[epoch:126, iter:98211] Loss: 1.397, 10.353, 65.684, 431.358, 1.060
[epoch:126, iter:98231] Loss: 1.396, 10.351, 65.708, 431.382, 1.392
Epoch: [125][500/782]	Time 0.068 (0.075)	Data 0.002 (0.003)	Loss 14.2819 (13.4424)	Acc@1 56.250 (63.195)	Acc@5 89.062 (89.964)
[epoch:126, iter:98251] Loss: 1.398, 10.356, 65.750, 431.478, 1.453
[epoch:126, iter:98271] Loss: 1.399, 10.365, 65.785, 431.600, 1.148
[epoch:126, iter:98291] Loss: 1.399, 10.371, 65.830, 431.714, 1.015
[epoch:126, iter:98311] Loss: 1.400, 10.373, 65.858, 431.859, 1.554
[epoch:126, iter:98331] Loss: 1.400, 10.373, 65.861, 431.941, 1.439
Epoch: [125][600/782]	Time 0.076 (0.075)	Data 0.002 (0.003)	Loss 13.4727 (13.4682)	Acc@1 65.625 (63.202)	Acc@5 92.188 (89.959)
[epoch:126, iter:98351] Loss: 1.399, 10.371, 65.839, 431.913, 1.302
[epoch:126, iter:98371] Loss: 1.399, 10.371, 65.853, 432.032, 1.069
[epoch:126, iter:98391] Loss: 1.399, 10.370, 65.850, 432.034, 1.209
[epoch:126, iter:98411] Loss: 1.398, 10.369, 65.843, 432.057, 1.053
[epoch:126, iter:98431] Loss: 1.398, 10.370, 65.832, 432.044, 1.447
Epoch: [125][700/782]	Time 0.075 (0.075)	Data 0.002 (0.003)	Loss 13.4802 (13.4904)	Acc@1 64.062 (62.952)	Acc@5 89.062 (89.823)
[epoch:126, iter:98451] Loss: 1.398, 10.369, 65.851, 432.133, 1.294
[epoch:126, iter:98471] Loss: 1.400, 10.371, 65.858, 432.189, 1.515
[epoch:126, iter:98491] Loss: 1.400, 10.370, 65.866, 432.268, 1.646
[epoch:126, iter:98511] Loss: 1.401, 10.378, 65.893, 432.380, 1.332
[epoch:126, iter:98531] Loss: 1.401, 10.379, 65.918, 432.419, 1.480
 * Acc@1 62.942 Acc@5 89.804
epoch 125, total time 58.98
Test: [0/313]	Time 0.272 (0.272)	Loss 1.8906 (1.8906)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.010 (0.009)	Loss 1.6064 (1.9260)	Acc@1 56.250 (56.250)	Acc@5 90.625 (85.056)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4132 (1.9384)	Acc@1 68.750 (55.442)	Acc@5 90.625 (84.562)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6784 (1.9306)	Acc@1 46.875 (55.378)	Acc@5 71.875 (84.541)
 * Acc@1 55.470 Acc@5 84.590
==> training...
Epoch: [126][0/782]	Time 0.520 (0.520)	Data 0.438 (0.438)	Loss 13.8539 (13.8539)	Acc@1 57.812 (57.812)	Acc@5 85.938 (85.938)
[epoch:127, iter:98533] Loss: 1.469, 10.795, 69.112, 434.787, 1.656
[epoch:127, iter:98553] Loss: 1.425, 10.462, 66.987, 435.072, 1.135
[epoch:127, iter:98573] Loss: 1.415, 10.419, 65.846, 434.056, 1.528
[epoch:127, iter:98593] Loss: 1.409, 10.410, 65.543, 433.039, 1.310
[epoch:127, iter:98613] Loss: 1.395, 10.419, 65.598, 432.785, 1.187
Epoch: [126][100/782]	Time 0.066 (0.083)	Data 0.002 (0.007)	Loss 13.7561 (13.4767)	Acc@1 71.875 (63.428)	Acc@5 93.750 (89.836)
[epoch:127, iter:98633] Loss: 1.397, 10.387, 65.786, 432.772, 0.966
[epoch:127, iter:98653] Loss: 1.397, 10.390, 65.671, 432.523, 1.164
[epoch:127, iter:98673] Loss: 1.395, 10.387, 65.659, 432.684, 1.189
[epoch:127, iter:98693] Loss: 1.394, 10.396, 65.579, 432.523, 1.570
[epoch:127, iter:98713] Loss: 1.395, 10.394, 65.565, 432.368, 1.385
Epoch: [126][200/782]	Time 0.063 (0.080)	Data 0.002 (0.005)	Loss 12.7119 (13.4725)	Acc@1 71.875 (63.448)	Acc@5 92.188 (89.459)
[epoch:127, iter:98733] Loss: 1.395, 10.378, 65.494, 432.011, 1.124
[epoch:127, iter:98753] Loss: 1.395, 10.364, 65.468, 431.998, 1.151
[epoch:127, iter:98773] Loss: 1.394, 10.364, 65.506, 431.920, 1.337
[epoch:127, iter:98793] Loss: 1.392, 10.360, 65.609, 431.968, 1.818
[epoch:127, iter:98813] Loss: 1.392, 10.355, 65.630, 431.962, 1.273
Epoch: [126][300/782]	Time 0.091 (0.078)	Data 0.003 (0.004)	Loss 12.1114 (13.4618)	Acc@1 62.500 (63.367)	Acc@5 95.312 (89.665)
[epoch:127, iter:98833] Loss: 1.392, 10.356, 65.640, 431.851, 0.990
[epoch:127, iter:98853] Loss: 1.391, 10.363, 65.625, 431.670, 1.299
[epoch:127, iter:98873] Loss: 1.389, 10.350, 65.646, 431.699, 1.260
[epoch:127, iter:98893] Loss: 1.388, 10.351, 65.741, 431.988, 1.335
[epoch:127, iter:98913] Loss: 1.389, 10.352, 65.764, 432.029, 1.250
Epoch: [126][400/782]	Time 0.093 (0.078)	Data 0.003 (0.003)	Loss 13.5079 (13.4790)	Acc@1 65.625 (63.147)	Acc@5 92.188 (89.573)
[epoch:127, iter:98933] Loss: 1.390, 10.360, 65.795, 432.112, 1.398
[epoch:127, iter:98953] Loss: 1.391, 10.367, 65.758, 432.093, 1.417
[epoch:127, iter:98973] Loss: 1.392, 10.366, 65.741, 432.024, 1.614
[epoch:127, iter:98993] Loss: 1.392, 10.365, 65.768, 432.056, 1.215
[epoch:127, iter:99013] Loss: 1.394, 10.373, 65.788, 432.184, 1.616
Epoch: [126][500/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 14.0853 (13.4809)	Acc@1 60.938 (63.348)	Acc@5 85.938 (89.671)
[epoch:127, iter:99033] Loss: 1.394, 10.375, 65.819, 432.250, 1.498
[epoch:127, iter:99053] Loss: 1.394, 10.374, 65.792, 432.221, 1.504
[epoch:127, iter:99073] Loss: 1.395, 10.370, 65.791, 432.286, 1.650
[epoch:127, iter:99093] Loss: 1.395, 10.373, 65.787, 432.265, 1.354
[epoch:127, iter:99113] Loss: 1.395, 10.372, 65.776, 432.172, 1.381
Epoch: [126][600/782]	Time 0.092 (0.078)	Data 0.003 (0.003)	Loss 13.2602 (13.4833)	Acc@1 64.062 (63.316)	Acc@5 90.625 (89.686)
[epoch:127, iter:99133] Loss: 1.395, 10.371, 65.765, 432.156, 1.315
[epoch:127, iter:99153] Loss: 1.394, 10.368, 65.761, 432.140, 1.313
[epoch:127, iter:99173] Loss: 1.394, 10.363, 65.778, 432.106, 1.385
[epoch:127, iter:99193] Loss: 1.394, 10.363, 65.794, 432.037, 1.393
[epoch:127, iter:99213] Loss: 1.395, 10.363, 65.806, 432.040, 1.381
Epoch: [126][700/782]	Time 0.083 (0.078)	Data 0.003 (0.003)	Loss 12.7704 (13.4921)	Acc@1 65.625 (63.124)	Acc@5 90.625 (89.595)
[epoch:127, iter:99233] Loss: 1.395, 10.364, 65.848, 432.104, 1.141
[epoch:127, iter:99253] Loss: 1.395, 10.363, 65.850, 432.064, 1.615
[epoch:127, iter:99273] Loss: 1.395, 10.361, 65.815, 432.025, 1.118
[epoch:127, iter:99293] Loss: 1.396, 10.366, 65.792, 432.020, 1.423
[epoch:127, iter:99313] Loss: 1.396, 10.366, 65.793, 432.052, 1.313
 * Acc@1 63.158 Acc@5 89.614
epoch 126, total time 60.98
Test: [0/313]	Time 0.207 (0.207)	Loss 1.9368 (1.9368)	Acc@1 71.875 (71.875)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.008 (0.010)	Loss 2.7179 (1.9380)	Acc@1 40.625 (54.610)	Acc@5 87.500 (84.623)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.6259 (1.9208)	Acc@1 62.500 (55.053)	Acc@5 90.625 (84.795)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.9836 (1.9398)	Acc@1 28.125 (55.087)	Acc@5 84.375 (84.583)
 * Acc@1 55.160 Acc@5 84.610
==> training...
Epoch: [127][0/782]	Time 0.546 (0.546)	Data 0.463 (0.463)	Loss 13.4831 (13.4831)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
[epoch:128, iter:99315] Loss: 1.403, 10.454, 70.510, 435.462, 1.127
[epoch:128, iter:99335] Loss: 1.411, 10.569, 67.248, 436.413, 0.868
[epoch:128, iter:99355] Loss: 1.417, 10.444, 66.796, 435.212, 1.299
[epoch:128, iter:99375] Loss: 1.401, 10.396, 66.055, 431.805, 1.305
[epoch:128, iter:99395] Loss: 1.402, 10.378, 65.781, 431.520, 1.306
Epoch: [127][100/782]	Time 0.055 (0.081)	Data 0.002 (0.007)	Loss 13.5846 (13.5155)	Acc@1 67.188 (62.887)	Acc@5 87.500 (89.496)
[epoch:128, iter:99415] Loss: 1.402, 10.376, 65.801, 431.753, 1.224
[epoch:128, iter:99435] Loss: 1.402, 10.372, 65.662, 431.567, 1.066
[epoch:128, iter:99455] Loss: 1.400, 10.354, 65.677, 431.674, 1.292
[epoch:128, iter:99475] Loss: 1.395, 10.332, 65.593, 431.539, 1.276
[epoch:128, iter:99495] Loss: 1.395, 10.327, 65.585, 431.513, 1.010
Epoch: [127][200/782]	Time 0.075 (0.081)	Data 0.002 (0.005)	Loss 12.4506 (13.4207)	Acc@1 71.875 (63.456)	Acc@5 92.188 (89.560)
[epoch:128, iter:99515] Loss: 1.395, 10.322, 65.596, 431.356, 1.153
[epoch:128, iter:99535] Loss: 1.392, 10.309, 65.585, 431.153, 1.561
[epoch:128, iter:99555] Loss: 1.391, 10.307, 65.555, 431.087, 1.098
[epoch:128, iter:99575] Loss: 1.393, 10.306, 65.525, 430.933, 1.299
[epoch:128, iter:99595] Loss: 1.391, 10.299, 65.462, 430.849, 1.097
Epoch: [127][300/782]	Time 0.078 (0.081)	Data 0.002 (0.004)	Loss 14.2639 (13.3793)	Acc@1 59.375 (63.497)	Acc@5 93.750 (89.768)
[epoch:128, iter:99615] Loss: 1.392, 10.303, 65.448, 430.873, 1.544
[epoch:128, iter:99635] Loss: 1.391, 10.304, 65.389, 430.687, 1.070
[epoch:128, iter:99655] Loss: 1.390, 10.309, 65.418, 430.826, 1.509
[epoch:128, iter:99675] Loss: 1.391, 10.316, 65.509, 431.009, 1.187
[epoch:128, iter:99695] Loss: 1.394, 10.324, 65.566, 431.257, 1.691
Epoch: [127][400/782]	Time 0.060 (0.080)	Data 0.002 (0.004)	Loss 13.5752 (13.4353)	Acc@1 59.375 (63.346)	Acc@5 95.312 (89.811)
[epoch:128, iter:99715] Loss: 1.393, 10.325, 65.563, 431.276, 1.390
[epoch:128, iter:99735] Loss: 1.392, 10.323, 65.610, 431.291, 1.325
[epoch:128, iter:99755] Loss: 1.393, 10.329, 65.666, 431.495, 1.282
[epoch:128, iter:99775] Loss: 1.393, 10.328, 65.621, 431.343, 1.222
[epoch:128, iter:99795] Loss: 1.392, 10.324, 65.633, 431.345, 1.543
Epoch: [127][500/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 13.6535 (13.4563)	Acc@1 70.312 (63.205)	Acc@5 87.500 (89.730)
[epoch:128, iter:99815] Loss: 1.392, 10.330, 65.645, 431.433, 1.190
[epoch:128, iter:99835] Loss: 1.392, 10.332, 65.654, 431.480, 1.084
[epoch:128, iter:99855] Loss: 1.392, 10.331, 65.687, 431.540, 1.080
[epoch:128, iter:99875] Loss: 1.392, 10.332, 65.678, 431.418, 1.430
[epoch:128, iter:99895] Loss: 1.392, 10.330, 65.674, 431.404, 1.148
Epoch: [127][600/782]	Time 0.059 (0.078)	Data 0.002 (0.003)	Loss 14.7316 (13.4700)	Acc@1 62.500 (63.098)	Acc@5 85.938 (89.723)
[epoch:128, iter:99915] Loss: 1.394, 10.333, 65.714, 431.532, 1.654
[epoch:128, iter:99935] Loss: 1.395, 10.335, 65.744, 431.638, 1.530
[epoch:128, iter:99955] Loss: 1.395, 10.337, 65.738, 431.747, 1.036
[epoch:128, iter:99975] Loss: 1.395, 10.343, 65.750, 431.780, 1.884
[epoch:128, iter:99995] Loss: 1.394, 10.345, 65.776, 431.850, 1.146
Epoch: [127][700/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 13.8008 (13.4845)	Acc@1 62.500 (63.064)	Acc@5 92.188 (89.716)
[epoch:128, iter:100015] Loss: 1.394, 10.348, 65.778, 431.801, 1.310
[epoch:128, iter:100035] Loss: 1.396, 10.352, 65.784, 431.863, 1.513
[epoch:128, iter:100055] Loss: 1.396, 10.351, 65.779, 431.940, 1.415
[epoch:128, iter:100075] Loss: 1.396, 10.350, 65.762, 431.876, 1.368
[epoch:128, iter:100095] Loss: 1.395, 10.349, 65.744, 431.830, 1.787
 * Acc@1 63.050 Acc@5 89.712
epoch 127, total time 61.73
Test: [0/313]	Time 0.219 (0.219)	Loss 2.8738 (2.8738)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.8898 (2.2132)	Acc@1 56.250 (53.311)	Acc@5 81.250 (83.632)
Test: [200/313]	Time 0.006 (0.007)	Loss 1.5676 (2.2707)	Acc@1 71.875 (52.254)	Acc@5 84.375 (82.991)
Test: [300/313]	Time 0.007 (0.007)	Loss 3.3037 (2.3065)	Acc@1 34.375 (52.263)	Acc@5 75.000 (82.288)
 * Acc@1 52.180 Acc@5 82.370
==> training...
Epoch: [128][0/782]	Time 0.525 (0.525)	Data 0.459 (0.459)	Loss 13.8856 (13.8856)	Acc@1 64.062 (64.062)	Acc@5 90.625 (90.625)
[epoch:129, iter:100097] Loss: 1.445, 10.284, 70.579, 449.058, 1.148
[epoch:129, iter:100117] Loss: 1.429, 10.406, 66.526, 434.546, 0.871
[epoch:129, iter:100137] Loss: 1.427, 10.372, 65.965, 432.354, 1.324
[epoch:129, iter:100157] Loss: 1.413, 10.367, 65.772, 433.173, 1.237
[epoch:129, iter:100177] Loss: 1.412, 10.376, 65.625, 432.565, 1.287
Epoch: [128][100/782]	Time 0.081 (0.084)	Data 0.002 (0.007)	Loss 13.9466 (13.5131)	Acc@1 64.062 (63.397)	Acc@5 89.062 (89.310)
[epoch:129, iter:100197] Loss: 1.413, 10.362, 65.676, 432.358, 1.637
[epoch:129, iter:100217] Loss: 1.413, 10.365, 65.740, 432.359, 1.384
[epoch:129, iter:100237] Loss: 1.415, 10.385, 65.831, 432.371, 1.146
[epoch:129, iter:100257] Loss: 1.415, 10.397, 65.876, 432.680, 1.125
[epoch:129, iter:100277] Loss: 1.416, 10.409, 65.841, 432.823, 1.240
Epoch: [128][200/782]	Time 0.083 (0.078)	Data 0.004 (0.005)	Loss 14.3045 (13.5586)	Acc@1 57.812 (63.099)	Acc@5 85.938 (89.677)
[epoch:129, iter:100297] Loss: 1.418, 10.413, 65.890, 433.090, 1.619
[epoch:129, iter:100317] Loss: 1.417, 10.412, 65.905, 432.898, 1.303
[epoch:129, iter:100337] Loss: 1.417, 10.408, 65.931, 432.812, 1.186
[epoch:129, iter:100357] Loss: 1.413, 10.406, 65.815, 432.590, 0.939
[epoch:129, iter:100377] Loss: 1.412, 10.404, 65.843, 432.607, 1.614
Epoch: [128][300/782]	Time 0.062 (0.077)	Data 0.002 (0.004)	Loss 13.0475 (13.4969)	Acc@1 50.000 (63.196)	Acc@5 93.750 (89.639)
[epoch:129, iter:100397] Loss: 1.409, 10.396, 65.757, 432.374, 1.408
[epoch:129, iter:100417] Loss: 1.411, 10.395, 65.846, 432.612, 1.687
[epoch:129, iter:100437] Loss: 1.410, 10.385, 65.820, 432.505, 1.060
[epoch:129, iter:100457] Loss: 1.410, 10.386, 65.822, 432.550, 1.402
[epoch:129, iter:100477] Loss: 1.410, 10.386, 65.865, 432.553, 0.744
Epoch: [128][400/782]	Time 0.090 (0.076)	Data 0.003 (0.003)	Loss 13.2759 (13.5191)	Acc@1 60.938 (63.174)	Acc@5 87.500 (89.682)
[epoch:129, iter:100497] Loss: 1.410, 10.384, 65.869, 432.518, 1.419
[epoch:129, iter:100517] Loss: 1.409, 10.385, 65.848, 432.518, 1.506
[epoch:129, iter:100537] Loss: 1.409, 10.383, 65.832, 432.444, 0.870
[epoch:129, iter:100557] Loss: 1.410, 10.385, 65.872, 432.557, 1.188
[epoch:129, iter:100577] Loss: 1.409, 10.382, 65.851, 432.580, 1.207
Epoch: [128][500/782]	Time 0.074 (0.077)	Data 0.002 (0.003)	Loss 14.4885 (13.5166)	Acc@1 54.688 (63.018)	Acc@5 90.625 (89.683)
[epoch:129, iter:100597] Loss: 1.409, 10.383, 65.874, 432.662, 1.476
[epoch:129, iter:100617] Loss: 1.410, 10.382, 65.871, 432.718, 1.232
[epoch:129, iter:100637] Loss: 1.408, 10.381, 65.835, 432.532, 0.930
[epoch:129, iter:100657] Loss: 1.408, 10.385, 65.852, 432.516, 0.923
[epoch:129, iter:100677] Loss: 1.408, 10.387, 65.883, 432.553, 1.398
Epoch: [128][600/782]	Time 0.080 (0.077)	Data 0.003 (0.003)	Loss 14.3500 (13.5328)	Acc@1 67.188 (62.778)	Acc@5 92.188 (89.632)
[epoch:129, iter:100697] Loss: 1.410, 10.391, 65.911, 432.661, 1.211
[epoch:129, iter:100717] Loss: 1.409, 10.395, 65.920, 432.735, 1.188
[epoch:129, iter:100737] Loss: 1.409, 10.393, 65.894, 432.672, 1.066
[epoch:129, iter:100757] Loss: 1.409, 10.395, 65.871, 432.718, 1.172
[epoch:129, iter:100777] Loss: 1.408, 10.390, 65.852, 432.668, 1.397
Epoch: [128][700/782]	Time 0.093 (0.078)	Data 0.003 (0.003)	Loss 13.7959 (13.5331)	Acc@1 62.500 (62.814)	Acc@5 85.938 (89.557)
[epoch:129, iter:100797] Loss: 1.408, 10.391, 65.857, 432.715, 1.490
[epoch:129, iter:100817] Loss: 1.408, 10.388, 65.851, 432.680, 1.448
[epoch:129, iter:100837] Loss: 1.407, 10.383, 65.820, 432.619, 1.552
[epoch:129, iter:100857] Loss: 1.408, 10.385, 65.822, 432.595, 1.132
[epoch:129, iter:100877] Loss: 1.407, 10.383, 65.813, 432.543, 1.220
 * Acc@1 62.892 Acc@5 89.656
epoch 128, total time 61.41
Test: [0/313]	Time 0.225 (0.225)	Loss 2.3169 (2.3169)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.3440 (2.0572)	Acc@1 43.750 (54.115)	Acc@5 81.250 (84.592)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4927 (2.0237)	Acc@1 62.500 (54.260)	Acc@5 84.375 (84.748)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.3843 (2.0306)	Acc@1 43.750 (54.340)	Acc@5 81.250 (84.583)
 * Acc@1 54.460 Acc@5 84.560
==> training...
Epoch: [129][0/782]	Time 0.559 (0.559)	Data 0.495 (0.495)	Loss 14.2318 (14.2318)	Acc@1 54.688 (54.688)	Acc@5 90.625 (90.625)
[epoch:130, iter:100879] Loss: 1.423, 10.584, 65.835, 442.018, 1.569
[epoch:130, iter:100899] Loss: 1.388, 10.386, 64.904, 432.630, 1.966
[epoch:130, iter:100919] Loss: 1.402, 10.400, 65.294, 432.999, 0.994
[epoch:130, iter:100939] Loss: 1.398, 10.414, 65.549, 432.935, 1.289
[epoch:130, iter:100959] Loss: 1.394, 10.394, 65.703, 432.889, 1.770
Epoch: [129][100/782]	Time 0.071 (0.081)	Data 0.003 (0.007)	Loss 13.0683 (13.5184)	Acc@1 65.625 (62.515)	Acc@5 93.750 (90.176)
[epoch:130, iter:100979] Loss: 1.393, 10.389, 65.591, 432.129, 1.356
[epoch:130, iter:100999] Loss: 1.396, 10.392, 65.576, 431.737, 1.749
[epoch:130, iter:101019] Loss: 1.396, 10.400, 65.575, 431.455, 1.261
[epoch:130, iter:101039] Loss: 1.394, 10.385, 65.531, 431.433, 1.404
[epoch:130, iter:101059] Loss: 1.394, 10.378, 65.518, 431.317, 1.617
Epoch: [129][200/782]	Time 0.078 (0.079)	Data 0.002 (0.005)	Loss 13.5488 (13.4429)	Acc@1 68.750 (62.928)	Acc@5 90.625 (90.190)
[epoch:130, iter:101079] Loss: 1.393, 10.375, 65.501, 431.194, 1.103
[epoch:130, iter:101099] Loss: 1.394, 10.358, 65.468, 430.813, 1.285
[epoch:130, iter:101119] Loss: 1.394, 10.356, 65.373, 430.519, 1.229
[epoch:130, iter:101139] Loss: 1.393, 10.351, 65.411, 430.680, 1.230
[epoch:130, iter:101159] Loss: 1.394, 10.352, 65.474, 430.836, 1.201
Epoch: [129][300/782]	Time 0.081 (0.078)	Data 0.002 (0.004)	Loss 13.9162 (13.4083)	Acc@1 64.062 (63.569)	Acc@5 82.812 (90.251)
[epoch:130, iter:101179] Loss: 1.394, 10.359, 65.560, 430.955, 1.455
[epoch:130, iter:101199] Loss: 1.396, 10.370, 65.562, 430.925, 1.364
[epoch:130, iter:101219] Loss: 1.396, 10.363, 65.517, 430.704, 1.013
[epoch:130, iter:101239] Loss: 1.396, 10.363, 65.562, 430.842, 1.324
[epoch:130, iter:101259] Loss: 1.396, 10.363, 65.582, 430.818, 1.499
Epoch: [129][400/782]	Time 0.057 (0.076)	Data 0.002 (0.003)	Loss 13.2743 (13.4024)	Acc@1 64.062 (63.677)	Acc@5 93.750 (90.048)
[epoch:130, iter:101279] Loss: 1.395, 10.364, 65.597, 430.909, 1.329
[epoch:130, iter:101299] Loss: 1.396, 10.369, 65.596, 430.971, 1.375
[epoch:130, iter:101319] Loss: 1.396, 10.369, 65.571, 430.964, 1.578
[epoch:130, iter:101339] Loss: 1.397, 10.369, 65.627, 431.229, 1.300
[epoch:130, iter:101359] Loss: 1.397, 10.372, 65.604, 431.234, 1.428
Epoch: [129][500/782]	Time 0.064 (0.076)	Data 0.002 (0.003)	Loss 13.8549 (13.4344)	Acc@1 60.938 (63.464)	Acc@5 89.062 (89.970)
[epoch:130, iter:101379] Loss: 1.397, 10.370, 65.610, 431.298, 1.605
[epoch:130, iter:101399] Loss: 1.397, 10.373, 65.606, 431.360, 1.500
[epoch:130, iter:101419] Loss: 1.397, 10.369, 65.599, 431.349, 1.795
[epoch:130, iter:101439] Loss: 1.397, 10.369, 65.580, 431.298, 1.471
[epoch:130, iter:101459] Loss: 1.396, 10.370, 65.609, 431.426, 1.691
Epoch: [129][600/782]	Time 0.089 (0.076)	Data 0.003 (0.003)	Loss 12.8081 (13.4481)	Acc@1 60.938 (63.246)	Acc@5 90.625 (89.858)
[epoch:130, iter:101479] Loss: 1.396, 10.371, 65.593, 431.291, 1.342
[epoch:130, iter:101499] Loss: 1.395, 10.365, 65.568, 431.231, 1.476
[epoch:130, iter:101519] Loss: 1.395, 10.363, 65.562, 431.298, 1.178
[epoch:130, iter:101539] Loss: 1.395, 10.359, 65.552, 431.264, 1.044
[epoch:130, iter:101559] Loss: 1.395, 10.359, 65.563, 431.340, 1.190
Epoch: [129][700/782]	Time 0.076 (0.076)	Data 0.002 (0.003)	Loss 13.3777 (13.4507)	Acc@1 59.375 (63.294)	Acc@5 89.062 (89.814)
[epoch:130, iter:101579] Loss: 1.395, 10.361, 65.575, 431.437, 1.376
[epoch:130, iter:101599] Loss: 1.395, 10.362, 65.584, 431.491, 1.318
[epoch:130, iter:101619] Loss: 1.395, 10.362, 65.580, 431.499, 1.459
[epoch:130, iter:101639] Loss: 1.395, 10.361, 65.556, 431.492, 1.542
[epoch:130, iter:101659] Loss: 1.395, 10.359, 65.528, 431.464, 1.155
 * Acc@1 63.182 Acc@5 89.804
epoch 129, total time 59.26
Test: [0/313]	Time 0.260 (0.260)	Loss 2.3066 (2.3066)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.6831 (2.0880)	Acc@1 50.000 (55.693)	Acc@5 84.375 (82.859)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3642 (2.0383)	Acc@1 46.875 (55.426)	Acc@5 96.875 (83.396)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.9266 (2.0396)	Acc@1 46.875 (55.523)	Acc@5 84.375 (83.306)
 * Acc@1 55.450 Acc@5 83.360
==> training...
Epoch: [130][0/782]	Time 0.553 (0.553)	Data 0.473 (0.473)	Loss 13.6299 (13.6299)	Acc@1 57.812 (57.812)	Acc@5 93.750 (93.750)
[epoch:131, iter:101661] Loss: 1.382, 10.365, 66.980, 440.070, 1.501
[epoch:131, iter:101681] Loss: 1.401, 10.429, 65.745, 433.600, 0.992
[epoch:131, iter:101701] Loss: 1.396, 10.348, 65.616, 432.828, 1.614
[epoch:131, iter:101721] Loss: 1.385, 10.338, 65.556, 432.187, 0.928
[epoch:131, iter:101741] Loss: 1.399, 10.380, 65.807, 432.692, 1.275
Epoch: [130][100/782]	Time 0.082 (0.082)	Data 0.003 (0.007)	Loss 13.1461 (13.4246)	Acc@1 67.188 (63.769)	Acc@5 90.625 (89.991)
[epoch:131, iter:101761] Loss: 1.399, 10.381, 65.591, 431.936, 1.120
[epoch:131, iter:101781] Loss: 1.395, 10.388, 65.563, 431.552, 1.305
[epoch:131, iter:101801] Loss: 1.398, 10.379, 65.686, 432.155, 1.232
[epoch:131, iter:101821] Loss: 1.397, 10.378, 65.616, 432.070, 1.237
[epoch:131, iter:101841] Loss: 1.396, 10.377, 65.649, 432.045, 1.405
Epoch: [130][200/782]	Time 0.072 (0.078)	Data 0.002 (0.005)	Loss 13.6154 (13.4300)	Acc@1 71.875 (63.790)	Acc@5 92.188 (90.275)
[epoch:131, iter:101861] Loss: 1.398, 10.376, 65.624, 432.162, 1.286
[epoch:131, iter:101881] Loss: 1.396, 10.372, 65.666, 432.135, 1.340
[epoch:131, iter:101901] Loss: 1.397, 10.372, 65.660, 432.005, 1.275
[epoch:131, iter:101921] Loss: 1.398, 10.379, 65.736, 432.133, 1.509
[epoch:131, iter:101941] Loss: 1.397, 10.377, 65.672, 431.958, 1.340
Epoch: [130][300/782]	Time 0.095 (0.077)	Data 0.003 (0.004)	Loss 13.2809 (13.4407)	Acc@1 70.312 (63.497)	Acc@5 89.062 (90.153)
[epoch:131, iter:101961] Loss: 1.396, 10.378, 65.716, 431.960, 1.115
[epoch:131, iter:101981] Loss: 1.395, 10.376, 65.749, 432.127, 1.775
[epoch:131, iter:102001] Loss: 1.396, 10.382, 65.794, 432.355, 1.242
[epoch:131, iter:102021] Loss: 1.395, 10.381, 65.812, 432.448, 1.757
[epoch:131, iter:102041] Loss: 1.396, 10.386, 65.825, 432.613, 1.091
Epoch: [130][400/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 13.1826 (13.4729)	Acc@1 68.750 (63.529)	Acc@5 87.500 (90.041)
[epoch:131, iter:102061] Loss: 1.395, 10.384, 65.838, 432.551, 1.449
[epoch:131, iter:102081] Loss: 1.394, 10.381, 65.825, 432.573, 1.816
[epoch:131, iter:102101] Loss: 1.393, 10.376, 65.797, 432.567, 1.448
[epoch:131, iter:102121] Loss: 1.395, 10.375, 65.788, 432.580, 1.198
[epoch:131, iter:102141] Loss: 1.393, 10.372, 65.772, 432.555, 1.588
Epoch: [130][500/782]	Time 0.072 (0.076)	Data 0.002 (0.003)	Loss 14.7375 (13.4803)	Acc@1 67.188 (63.233)	Acc@5 90.625 (89.979)
[epoch:131, iter:102161] Loss: 1.393, 10.373, 65.790, 432.663, 1.293
[epoch:131, iter:102181] Loss: 1.393, 10.370, 65.771, 432.576, 1.145
[epoch:131, iter:102201] Loss: 1.395, 10.374, 65.795, 432.659, 1.577
[epoch:131, iter:102221] Loss: 1.396, 10.377, 65.779, 432.643, 1.258
[epoch:131, iter:102241] Loss: 1.396, 10.378, 65.777, 432.653, 1.219
Epoch: [130][600/782]	Time 0.079 (0.075)	Data 0.002 (0.003)	Loss 13.0328 (13.4850)	Acc@1 71.875 (63.179)	Acc@5 89.062 (89.868)
[epoch:131, iter:102261] Loss: 1.395, 10.372, 65.773, 432.597, 1.214
[epoch:131, iter:102281] Loss: 1.394, 10.369, 65.775, 432.521, 1.092
[epoch:131, iter:102301] Loss: 1.394, 10.366, 65.767, 432.407, 1.190
[epoch:131, iter:102321] Loss: 1.393, 10.364, 65.753, 432.262, 1.571
[epoch:131, iter:102341] Loss: 1.393, 10.365, 65.772, 432.288, 1.499
Epoch: [130][700/782]	Time 0.067 (0.075)	Data 0.002 (0.003)	Loss 13.8574 (13.4813)	Acc@1 62.500 (63.091)	Acc@5 92.188 (89.896)
[epoch:131, iter:102361] Loss: 1.393, 10.363, 65.790, 432.286, 1.383
[epoch:131, iter:102381] Loss: 1.392, 10.356, 65.762, 432.138, 1.328
[epoch:131, iter:102401] Loss: 1.392, 10.355, 65.762, 432.163, 1.278
[epoch:131, iter:102421] Loss: 1.393, 10.357, 65.772, 432.226, 1.080
[epoch:131, iter:102441] Loss: 1.393, 10.356, 65.751, 432.188, 1.307
 * Acc@1 63.120 Acc@5 89.920
epoch 130, total time 58.63
Test: [0/313]	Time 0.274 (0.274)	Loss 1.7957 (1.7957)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.7930 (1.8504)	Acc@1 50.000 (56.219)	Acc@5 90.625 (85.458)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3820 (1.8668)	Acc@1 62.500 (56.343)	Acc@5 93.750 (85.401)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.4902 (1.8597)	Acc@1 43.750 (56.468)	Acc@5 75.000 (85.320)
 * Acc@1 56.650 Acc@5 85.370
==> training...
Epoch: [131][0/782]	Time 0.497 (0.497)	Data 0.420 (0.420)	Loss 15.2029 (15.2029)	Acc@1 45.312 (45.312)	Acc@5 79.688 (79.688)
[epoch:132, iter:102443] Loss: 1.403, 10.545, 68.446, 437.124, 2.235
[epoch:132, iter:102463] Loss: 1.399, 10.452, 65.787, 430.661, 1.199
[epoch:132, iter:102483] Loss: 1.401, 10.470, 65.506, 431.361, 1.559
[epoch:132, iter:102503] Loss: 1.394, 10.438, 65.534, 430.952, 1.050
[epoch:132, iter:102523] Loss: 1.392, 10.377, 65.294, 429.602, 0.886
Epoch: [131][100/782]	Time 0.092 (0.083)	Data 0.003 (0.006)	Loss 13.7346 (13.2972)	Acc@1 62.500 (64.449)	Acc@5 89.062 (90.671)
[epoch:132, iter:102543] Loss: 1.386, 10.360, 65.105, 429.256, 1.621
[epoch:132, iter:102563] Loss: 1.384, 10.365, 65.102, 429.781, 1.239
[epoch:132, iter:102583] Loss: 1.383, 10.360, 65.138, 429.616, 1.179
[epoch:132, iter:102603] Loss: 1.385, 10.366, 65.190, 430.086, 1.143
[epoch:132, iter:102623] Loss: 1.388, 10.353, 65.311, 430.131, 1.354
Epoch: [131][200/782]	Time 0.067 (0.080)	Data 0.002 (0.004)	Loss 12.6400 (13.3492)	Acc@1 62.500 (64.171)	Acc@5 90.625 (90.485)
[epoch:132, iter:102643] Loss: 1.389, 10.349, 65.473, 430.426, 1.351
[epoch:132, iter:102663] Loss: 1.388, 10.354, 65.430, 430.366, 0.969
[epoch:132, iter:102683] Loss: 1.385, 10.346, 65.367, 430.264, 1.215
[epoch:132, iter:102703] Loss: 1.383, 10.330, 65.319, 429.958, 1.079
[epoch:132, iter:102723] Loss: 1.382, 10.316, 65.358, 430.015, 1.255
Epoch: [131][300/782]	Time 0.084 (0.078)	Data 0.002 (0.004)	Loss 13.1360 (13.3159)	Acc@1 70.312 (64.000)	Acc@5 93.750 (90.438)
[epoch:132, iter:102743] Loss: 1.380, 10.316, 65.371, 429.995, 1.072
[epoch:132, iter:102763] Loss: 1.382, 10.312, 65.441, 430.099, 1.560
[epoch:132, iter:102783] Loss: 1.383, 10.321, 65.468, 430.291, 1.013
[epoch:132, iter:102803] Loss: 1.385, 10.327, 65.503, 430.556, 1.230
[epoch:132, iter:102823] Loss: 1.388, 10.336, 65.562, 430.870, 1.466
Epoch: [131][400/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 12.8834 (13.4074)	Acc@1 68.750 (63.692)	Acc@5 90.625 (90.150)
[epoch:132, iter:102843] Loss: 1.389, 10.345, 65.580, 430.960, 1.109
[epoch:132, iter:102863] Loss: 1.390, 10.350, 65.599, 431.068, 1.689
[epoch:132, iter:102883] Loss: 1.389, 10.354, 65.657, 431.200, 1.501
[epoch:132, iter:102903] Loss: 1.392, 10.358, 65.748, 431.341, 1.148
[epoch:132, iter:102923] Loss: 1.392, 10.357, 65.762, 431.345, 1.438
Epoch: [131][500/782]	Time 0.074 (0.076)	Data 0.002 (0.003)	Loss 13.7356 (13.4389)	Acc@1 56.250 (63.417)	Acc@5 90.625 (90.026)
[epoch:132, iter:102943] Loss: 1.393, 10.356, 65.754, 431.406, 1.590
[epoch:132, iter:102963] Loss: 1.394, 10.352, 65.748, 431.454, 1.218
[epoch:132, iter:102983] Loss: 1.394, 10.354, 65.741, 431.609, 1.390
[epoch:132, iter:103003] Loss: 1.393, 10.351, 65.766, 431.545, 1.323
[epoch:132, iter:103023] Loss: 1.393, 10.356, 65.784, 431.596, 1.516
Epoch: [131][600/782]	Time 0.073 (0.076)	Data 0.002 (0.003)	Loss 13.2052 (13.4397)	Acc@1 68.750 (63.491)	Acc@5 98.438 (89.972)
[epoch:132, iter:103043] Loss: 1.393, 10.354, 65.743, 431.488, 1.028
[epoch:132, iter:103063] Loss: 1.392, 10.354, 65.726, 431.424, 1.433
[epoch:132, iter:103083] Loss: 1.392, 10.353, 65.723, 431.451, 0.701
[epoch:132, iter:103103] Loss: 1.393, 10.353, 65.737, 431.524, 1.361
[epoch:132, iter:103123] Loss: 1.393, 10.355, 65.753, 431.682, 1.557
Epoch: [131][700/782]	Time 0.087 (0.077)	Data 0.003 (0.003)	Loss 13.0704 (13.4563)	Acc@1 51.562 (63.340)	Acc@5 84.375 (89.867)
[epoch:132, iter:103143] Loss: 1.393, 10.354, 65.730, 431.652, 1.491
[epoch:132, iter:103163] Loss: 1.393, 10.355, 65.719, 431.613, 1.104
[epoch:132, iter:103183] Loss: 1.394, 10.358, 65.735, 431.660, 1.464
[epoch:132, iter:103203] Loss: 1.395, 10.362, 65.728, 431.684, 1.145
[epoch:132, iter:103223] Loss: 1.395, 10.361, 65.720, 431.688, 1.687
 * Acc@1 63.230 Acc@5 89.746
epoch 131, total time 60.50
Test: [0/313]	Time 0.270 (0.270)	Loss 1.9760 (1.9760)	Acc@1 68.750 (68.750)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.4338 (1.9216)	Acc@1 50.000 (55.074)	Acc@5 87.500 (85.179)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8225 (1.8802)	Acc@1 43.750 (56.032)	Acc@5 93.750 (85.494)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.8433 (1.8832)	Acc@1 40.625 (56.094)	Acc@5 81.250 (85.403)
 * Acc@1 56.260 Acc@5 85.480
==> training...
Epoch: [132][0/782]	Time 0.533 (0.533)	Data 0.459 (0.459)	Loss 13.0970 (13.0970)	Acc@1 64.062 (64.062)	Acc@5 93.750 (93.750)
[epoch:133, iter:103225] Loss: 1.409, 10.348, 66.262, 433.477, 1.289
[epoch:133, iter:103245] Loss: 1.407, 10.507, 64.796, 430.475, 1.111
[epoch:133, iter:103265] Loss: 1.405, 10.562, 65.111, 431.609, 1.461
[epoch:133, iter:103285] Loss: 1.402, 10.517, 65.037, 432.000, 1.330
[epoch:133, iter:103305] Loss: 1.400, 10.473, 65.147, 431.465, 1.171
Epoch: [132][100/782]	Time 0.091 (0.082)	Data 0.003 (0.007)	Loss 12.5775 (13.4069)	Acc@1 70.312 (63.583)	Acc@5 96.875 (90.300)
[epoch:133, iter:103325] Loss: 1.400, 10.441, 65.151, 431.089, 0.875
[epoch:133, iter:103345] Loss: 1.399, 10.437, 65.335, 431.590, 1.542
[epoch:133, iter:103365] Loss: 1.406, 10.441, 65.390, 431.503, 0.932
[epoch:133, iter:103385] Loss: 1.407, 10.438, 65.423, 431.843, 1.304
[epoch:133, iter:103405] Loss: 1.405, 10.418, 65.415, 431.781, 1.608
Epoch: [132][200/782]	Time 0.092 (0.082)	Data 0.002 (0.005)	Loss 13.0166 (13.4403)	Acc@1 57.812 (63.503)	Acc@5 90.625 (90.073)
[epoch:133, iter:103425] Loss: 1.403, 10.407, 65.421, 431.542, 1.339
[epoch:133, iter:103445] Loss: 1.403, 10.407, 65.394, 431.528, 1.519
[epoch:133, iter:103465] Loss: 1.404, 10.415, 65.413, 431.562, 1.348
[epoch:133, iter:103485] Loss: 1.403, 10.410, 65.435, 431.545, 1.292
[epoch:133, iter:103505] Loss: 1.405, 10.403, 65.445, 431.532, 1.368
Epoch: [132][300/782]	Time 0.069 (0.080)	Data 0.002 (0.004)	Loss 13.2903 (13.4313)	Acc@1 65.625 (63.445)	Acc@5 90.625 (90.080)
[epoch:133, iter:103525] Loss: 1.405, 10.393, 65.431, 431.627, 1.262
[epoch:133, iter:103545] Loss: 1.405, 10.385, 65.455, 431.528, 1.098
[epoch:133, iter:103565] Loss: 1.404, 10.374, 65.524, 431.678, 1.116
[epoch:133, iter:103585] Loss: 1.405, 10.371, 65.587, 431.787, 1.338
[epoch:133, iter:103605] Loss: 1.405, 10.369, 65.603, 431.670, 1.415
Epoch: [132][400/782]	Time 0.061 (0.079)	Data 0.002 (0.004)	Loss 13.1144 (13.4542)	Acc@1 67.188 (63.221)	Acc@5 93.750 (89.881)
[epoch:133, iter:103625] Loss: 1.404, 10.367, 65.600, 431.598, 1.184
[epoch:133, iter:103645] Loss: 1.403, 10.361, 65.621, 431.630, 1.292
[epoch:133, iter:103665] Loss: 1.403, 10.365, 65.608, 431.427, 1.249
[epoch:133, iter:103685] Loss: 1.402, 10.366, 65.641, 431.569, 1.364
[epoch:133, iter:103705] Loss: 1.402, 10.368, 65.617, 431.638, 1.650
Epoch: [132][500/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 14.0802 (13.4526)	Acc@1 48.438 (63.133)	Acc@5 89.062 (89.823)
[epoch:133, iter:103725] Loss: 1.402, 10.368, 65.618, 431.731, 1.598
[epoch:133, iter:103745] Loss: 1.402, 10.370, 65.600, 431.744, 1.604
[epoch:133, iter:103765] Loss: 1.402, 10.376, 65.626, 431.828, 0.834
[epoch:133, iter:103785] Loss: 1.402, 10.378, 65.612, 431.802, 0.989
[epoch:133, iter:103805] Loss: 1.402, 10.376, 65.611, 431.817, 1.154
Epoch: [132][600/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 13.2760 (13.4739)	Acc@1 65.625 (63.017)	Acc@5 90.625 (89.744)
[epoch:133, iter:103825] Loss: 1.401, 10.374, 65.619, 431.817, 1.339
[epoch:133, iter:103845] Loss: 1.402, 10.377, 65.626, 431.882, 1.338
[epoch:133, iter:103865] Loss: 1.402, 10.377, 65.636, 431.877, 1.251
[epoch:133, iter:103885] Loss: 1.402, 10.375, 65.633, 431.891, 1.116
[epoch:133, iter:103905] Loss: 1.402, 10.375, 65.631, 431.909, 1.344
Epoch: [132][700/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 12.8640 (13.4919)	Acc@1 65.625 (62.944)	Acc@5 92.188 (89.691)
[epoch:133, iter:103925] Loss: 1.402, 10.374, 65.658, 432.016, 1.172
[epoch:133, iter:103945] Loss: 1.403, 10.374, 65.680, 432.093, 1.303
[epoch:133, iter:103965] Loss: 1.402, 10.373, 65.717, 432.159, 1.158
[epoch:133, iter:103985] Loss: 1.402, 10.376, 65.723, 432.143, 1.586
[epoch:133, iter:104005] Loss: 1.401, 10.375, 65.719, 432.089, 0.907
 * Acc@1 62.820 Acc@5 89.600
epoch 132, total time 61.21
Test: [0/313]	Time 0.230 (0.230)	Loss 2.2418 (2.2418)	Acc@1 62.500 (62.500)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.9449 (1.9103)	Acc@1 43.750 (56.064)	Acc@5 87.500 (84.870)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5334 (1.9096)	Acc@1 62.500 (56.343)	Acc@5 87.500 (84.686)
Test: [300/313]	Time 0.008 (0.008)	Loss 2.5379 (1.9149)	Acc@1 43.750 (56.312)	Acc@5 75.000 (84.583)
 * Acc@1 56.440 Acc@5 84.690
==> training...
Epoch: [133][0/782]	Time 0.514 (0.514)	Data 0.446 (0.446)	Loss 13.0064 (13.0064)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
[epoch:134, iter:104007] Loss: 1.383, 10.303, 65.818, 427.312, 1.097
[epoch:134, iter:104027] Loss: 1.416, 10.429, 66.087, 432.960, 1.287
[epoch:134, iter:104047] Loss: 1.410, 10.366, 65.835, 432.435, 1.152
[epoch:134, iter:104067] Loss: 1.402, 10.350, 65.698, 431.369, 1.338
[epoch:134, iter:104087] Loss: 1.397, 10.354, 65.545, 430.938, 1.499
Epoch: [133][100/782]	Time 0.066 (0.084)	Data 0.002 (0.007)	Loss 15.0883 (13.3628)	Acc@1 51.562 (64.480)	Acc@5 85.938 (90.176)
[epoch:134, iter:104107] Loss: 1.397, 10.358, 65.582, 431.188, 1.758
[epoch:134, iter:104127] Loss: 1.398, 10.350, 65.482, 431.058, 1.208
[epoch:134, iter:104147] Loss: 1.398, 10.343, 65.413, 430.962, 1.248
[epoch:134, iter:104167] Loss: 1.401, 10.355, 65.522, 431.187, 1.700
[epoch:134, iter:104187] Loss: 1.400, 10.365, 65.468, 431.226, 1.362
Epoch: [133][200/782]	Time 0.062 (0.080)	Data 0.002 (0.005)	Loss 13.5008 (13.3967)	Acc@1 56.250 (63.822)	Acc@5 90.625 (90.267)
[epoch:134, iter:104207] Loss: 1.399, 10.364, 65.545, 431.125, 1.284
[epoch:134, iter:104227] Loss: 1.401, 10.374, 65.573, 431.295, 1.505
[epoch:134, iter:104247] Loss: 1.399, 10.369, 65.583, 431.269, 1.569
[epoch:134, iter:104267] Loss: 1.399, 10.351, 65.590, 431.285, 1.345
[epoch:134, iter:104287] Loss: 1.400, 10.344, 65.566, 431.208, 1.360
Epoch: [133][300/782]	Time 0.097 (0.078)	Data 0.002 (0.004)	Loss 13.8697 (13.4191)	Acc@1 62.500 (63.585)	Acc@5 85.938 (89.981)
[epoch:134, iter:104307] Loss: 1.399, 10.339, 65.577, 431.228, 1.652
[epoch:134, iter:104327] Loss: 1.401, 10.343, 65.656, 431.431, 1.710
[epoch:134, iter:104347] Loss: 1.404, 10.352, 65.701, 431.653, 1.184
[epoch:134, iter:104367] Loss: 1.404, 10.355, 65.698, 431.609, 1.496
[epoch:134, iter:104387] Loss: 1.404, 10.357, 65.724, 431.702, 1.144
Epoch: [133][400/782]	Time 0.092 (0.078)	Data 0.003 (0.003)	Loss 12.8080 (13.4535)	Acc@1 64.062 (63.322)	Acc@5 95.312 (89.986)
[epoch:134, iter:104407] Loss: 1.404, 10.359, 65.707, 431.624, 1.100
[epoch:134, iter:104427] Loss: 1.404, 10.362, 65.711, 431.609, 1.354
[epoch:134, iter:104447] Loss: 1.402, 10.355, 65.673, 431.495, 1.118
[epoch:134, iter:104467] Loss: 1.400, 10.347, 65.652, 431.402, 1.344
[epoch:134, iter:104487] Loss: 1.401, 10.342, 65.637, 431.330, 1.287
Epoch: [133][500/782]	Time 0.071 (0.077)	Data 0.002 (0.003)	Loss 14.2524 (13.4482)	Acc@1 62.500 (63.308)	Acc@5 89.062 (89.889)
[epoch:134, iter:104507] Loss: 1.401, 10.344, 65.659, 431.397, 1.363
[epoch:134, iter:104527] Loss: 1.401, 10.343, 65.643, 431.352, 1.214
[epoch:134, iter:104547] Loss: 1.400, 10.343, 65.622, 431.273, 1.123
[epoch:134, iter:104567] Loss: 1.399, 10.343, 65.620, 431.206, 1.386
[epoch:134, iter:104587] Loss: 1.398, 10.338, 65.595, 431.075, 1.633
Epoch: [133][600/782]	Time 0.060 (0.077)	Data 0.002 (0.003)	Loss 13.1766 (13.4490)	Acc@1 65.625 (63.184)	Acc@5 90.625 (89.767)
[epoch:134, iter:104607] Loss: 1.398, 10.339, 65.642, 431.222, 1.243
[epoch:134, iter:104627] Loss: 1.398, 10.342, 65.657, 431.239, 1.851
[epoch:134, iter:104647] Loss: 1.398, 10.345, 65.635, 431.281, 1.395
[epoch:134, iter:104667] Loss: 1.397, 10.348, 65.630, 431.374, 1.309
[epoch:134, iter:104687] Loss: 1.397, 10.347, 65.621, 431.296, 1.226
Epoch: [133][700/782]	Time 0.081 (0.076)	Data 0.003 (0.003)	Loss 14.2592 (13.4521)	Acc@1 64.062 (63.182)	Acc@5 85.938 (89.758)
[epoch:134, iter:104707] Loss: 1.397, 10.348, 65.608, 431.241, 1.618
[epoch:134, iter:104727] Loss: 1.397, 10.349, 65.615, 431.371, 1.425
[epoch:134, iter:104747] Loss: 1.398, 10.352, 65.630, 431.427, 1.558
[epoch:134, iter:104767] Loss: 1.399, 10.356, 65.635, 431.477, 1.254
[epoch:134, iter:104787] Loss: 1.399, 10.359, 65.641, 431.530, 1.588
 * Acc@1 63.216 Acc@5 89.698
epoch 133, total time 60.31
Test: [0/313]	Time 0.221 (0.221)	Loss 2.0340 (2.0340)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.009)	Loss 2.6254 (2.0465)	Acc@1 56.250 (55.446)	Acc@5 78.125 (84.251)
Test: [200/313]	Time 0.005 (0.008)	Loss 1.6969 (2.0485)	Acc@1 62.500 (55.022)	Acc@5 87.500 (84.282)
Test: [300/313]	Time 0.008 (0.007)	Loss 2.5547 (2.0375)	Acc@1 50.000 (55.669)	Acc@5 78.125 (84.375)
 * Acc@1 55.720 Acc@5 84.410
==> training...
Epoch: [134][0/782]	Time 0.503 (0.503)	Data 0.420 (0.420)	Loss 12.9079 (12.9079)	Acc@1 67.188 (67.188)	Acc@5 93.750 (93.750)
[epoch:135, iter:104789] Loss: 1.432, 10.221, 64.107, 424.983, 1.280
[epoch:135, iter:104809] Loss: 1.408, 10.565, 64.946, 433.322, 1.174
[epoch:135, iter:104829] Loss: 1.405, 10.412, 64.668, 429.862, 1.120
[epoch:135, iter:104849] Loss: 1.407, 10.371, 64.956, 430.282, 1.314
[epoch:135, iter:104869] Loss: 1.403, 10.340, 65.010, 430.037, 1.466
Epoch: [134][100/782]	Time 0.087 (0.079)	Data 0.004 (0.006)	Loss 12.6440 (13.3314)	Acc@1 64.062 (63.196)	Acc@5 92.188 (90.223)
[epoch:135, iter:104889] Loss: 1.405, 10.331, 65.105, 430.085, 1.391
[epoch:135, iter:104909] Loss: 1.411, 10.341, 65.238, 430.218, 1.146
[epoch:135, iter:104929] Loss: 1.412, 10.347, 65.267, 430.483, 1.276
[epoch:135, iter:104949] Loss: 1.407, 10.352, 65.275, 430.739, 1.211
[epoch:135, iter:104969] Loss: 1.403, 10.356, 65.399, 430.792, 1.224
Epoch: [134][200/782]	Time 0.079 (0.078)	Data 0.002 (0.004)	Loss 13.2505 (13.3547)	Acc@1 62.500 (63.565)	Acc@5 92.188 (90.205)
[epoch:135, iter:104989] Loss: 1.398, 10.355, 65.366, 430.616, 1.323
[epoch:135, iter:105009] Loss: 1.396, 10.350, 65.274, 430.351, 1.363
[epoch:135, iter:105029] Loss: 1.393, 10.334, 65.197, 430.086, 1.212
[epoch:135, iter:105049] Loss: 1.395, 10.330, 65.263, 430.134, 1.456
[epoch:135, iter:105069] Loss: 1.394, 10.329, 65.279, 430.177, 1.308
Epoch: [134][300/782]	Time 0.076 (0.078)	Data 0.002 (0.004)	Loss 13.0943 (13.3108)	Acc@1 70.312 (63.974)	Acc@5 92.188 (90.241)
[epoch:135, iter:105089] Loss: 1.390, 10.324, 65.265, 430.145, 1.192
[epoch:135, iter:105109] Loss: 1.390, 10.317, 65.322, 430.245, 1.254
[epoch:135, iter:105129] Loss: 1.389, 10.323, 65.345, 430.389, 1.470
[epoch:135, iter:105149] Loss: 1.389, 10.316, 65.382, 430.431, 1.543
[epoch:135, iter:105169] Loss: 1.389, 10.313, 65.351, 430.317, 1.098
Epoch: [134][400/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 13.8113 (13.3253)	Acc@1 62.500 (63.618)	Acc@5 85.938 (90.060)
[epoch:135, iter:105189] Loss: 1.389, 10.309, 65.314, 430.097, 1.333
[epoch:135, iter:105209] Loss: 1.389, 10.309, 65.367, 430.332, 1.259
[epoch:135, iter:105229] Loss: 1.389, 10.304, 65.417, 430.333, 1.096
[epoch:135, iter:105249] Loss: 1.389, 10.303, 65.421, 430.248, 1.322
[epoch:135, iter:105269] Loss: 1.390, 10.310, 65.430, 430.309, 1.206
Epoch: [134][500/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 14.0590 (13.3747)	Acc@1 57.812 (63.370)	Acc@5 84.375 (89.979)
[epoch:135, iter:105289] Loss: 1.392, 10.317, 65.468, 430.461, 1.639
[epoch:135, iter:105309] Loss: 1.392, 10.320, 65.458, 430.533, 1.542
[epoch:135, iter:105329] Loss: 1.392, 10.322, 65.482, 430.687, 1.485
[epoch:135, iter:105349] Loss: 1.392, 10.322, 65.472, 430.720, 1.303
[epoch:135, iter:105369] Loss: 1.391, 10.322, 65.458, 430.762, 1.033
Epoch: [134][600/782]	Time 0.078 (0.079)	Data 0.003 (0.003)	Loss 12.7356 (13.4157)	Acc@1 64.062 (63.171)	Acc@5 93.750 (89.848)
[epoch:135, iter:105389] Loss: 1.392, 10.327, 65.510, 430.900, 1.141
[epoch:135, iter:105409] Loss: 1.393, 10.328, 65.515, 430.916, 0.969
[epoch:135, iter:105429] Loss: 1.392, 10.327, 65.488, 430.869, 1.332
[epoch:135, iter:105449] Loss: 1.392, 10.326, 65.487, 430.866, 1.239
[epoch:135, iter:105469] Loss: 1.393, 10.325, 65.500, 430.911, 1.672
Epoch: [134][700/782]	Time 0.078 (0.078)	Data 0.002 (0.003)	Loss 13.0154 (13.4215)	Acc@1 59.375 (63.191)	Acc@5 85.938 (89.823)
[epoch:135, iter:105489] Loss: 1.393, 10.326, 65.485, 430.883, 1.471
[epoch:135, iter:105509] Loss: 1.393, 10.330, 65.489, 430.968, 1.255
[epoch:135, iter:105529] Loss: 1.393, 10.331, 65.483, 431.019, 0.973
[epoch:135, iter:105549] Loss: 1.393, 10.332, 65.494, 431.070, 1.221
[epoch:135, iter:105569] Loss: 1.392, 10.331, 65.512, 431.053, 1.360
 * Acc@1 63.034 Acc@5 89.778
epoch 134, total time 61.19
Test: [0/313]	Time 0.223 (0.223)	Loss 1.8843 (1.8843)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.009)	Loss 2.0829 (1.9100)	Acc@1 59.375 (55.538)	Acc@5 84.375 (84.839)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.2120 (1.8943)	Acc@1 59.375 (55.162)	Acc@5 96.875 (85.199)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.1566 (1.9019)	Acc@1 50.000 (55.191)	Acc@5 84.375 (84.956)
 * Acc@1 55.300 Acc@5 84.960
==> training...
Epoch: [135][0/782]	Time 0.583 (0.583)	Data 0.520 (0.520)	Loss 13.2934 (13.2934)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:136, iter:105571] Loss: 1.399, 10.728, 65.746, 433.286, 1.227
[epoch:136, iter:105591] Loss: 1.384, 10.537, 65.491, 433.218, 1.559
[epoch:136, iter:105611] Loss: 1.402, 10.542, 65.410, 433.004, 1.429
[epoch:136, iter:105631] Loss: 1.402, 10.426, 65.287, 432.372, 0.770
[epoch:136, iter:105651] Loss: 1.398, 10.359, 65.275, 431.338, 1.332
Epoch: [135][100/782]	Time 0.091 (0.078)	Data 0.002 (0.007)	Loss 12.9229 (13.3517)	Acc@1 67.188 (64.341)	Acc@5 89.062 (90.362)
[epoch:136, iter:105671] Loss: 1.394, 10.340, 65.202, 430.819, 1.189
[epoch:136, iter:105691] Loss: 1.389, 10.327, 65.227, 431.167, 1.822
[epoch:136, iter:105711] Loss: 1.396, 10.340, 65.412, 431.816, 1.538
[epoch:136, iter:105731] Loss: 1.394, 10.336, 65.416, 431.488, 1.243
[epoch:136, iter:105751] Loss: 1.398, 10.341, 65.458, 431.464, 1.389
Epoch: [135][200/782]	Time 0.075 (0.078)	Data 0.002 (0.005)	Loss 13.3218 (13.4154)	Acc@1 75.000 (64.195)	Acc@5 90.625 (90.400)
[epoch:136, iter:105771] Loss: 1.401, 10.361, 65.525, 431.627, 0.988
[epoch:136, iter:105791] Loss: 1.402, 10.366, 65.573, 431.695, 0.965
[epoch:136, iter:105811] Loss: 1.402, 10.368, 65.583, 431.556, 1.523
[epoch:136, iter:105831] Loss: 1.400, 10.358, 65.541, 431.398, 1.565
[epoch:136, iter:105851] Loss: 1.401, 10.362, 65.524, 431.374, 1.324
Epoch: [135][300/782]	Time 0.063 (0.077)	Data 0.002 (0.004)	Loss 13.5574 (13.3855)	Acc@1 65.625 (64.322)	Acc@5 92.188 (90.438)
[epoch:136, iter:105871] Loss: 1.400, 10.356, 65.457, 431.246, 1.254
[epoch:136, iter:105891] Loss: 1.400, 10.353, 65.534, 431.424, 1.877
[epoch:136, iter:105911] Loss: 1.402, 10.359, 65.530, 431.639, 1.332
[epoch:136, iter:105931] Loss: 1.402, 10.359, 65.528, 431.616, 1.998
[epoch:136, iter:105951] Loss: 1.402, 10.363, 65.583, 431.604, 1.403
Epoch: [135][400/782]	Time 0.072 (0.078)	Data 0.002 (0.004)	Loss 14.4093 (13.4485)	Acc@1 45.312 (63.840)	Acc@5 84.375 (90.095)
[epoch:136, iter:105971] Loss: 1.402, 10.364, 65.628, 431.772, 1.712
[epoch:136, iter:105991] Loss: 1.402, 10.363, 65.654, 431.847, 1.488
[epoch:136, iter:106011] Loss: 1.401, 10.365, 65.677, 431.964, 0.985
[epoch:136, iter:106031] Loss: 1.401, 10.360, 65.648, 431.868, 1.434
[epoch:136, iter:106051] Loss: 1.400, 10.359, 65.644, 431.825, 1.417
Epoch: [135][500/782]	Time 0.092 (0.078)	Data 0.002 (0.003)	Loss 12.9779 (13.4430)	Acc@1 64.062 (63.844)	Acc@5 89.062 (90.117)
[epoch:136, iter:106071] Loss: 1.399, 10.358, 65.648, 431.642, 1.274
[epoch:136, iter:106091] Loss: 1.399, 10.352, 65.645, 431.460, 0.865
[epoch:136, iter:106111] Loss: 1.398, 10.353, 65.623, 431.368, 1.204
[epoch:136, iter:106131] Loss: 1.399, 10.353, 65.643, 431.417, 1.284
[epoch:136, iter:106151] Loss: 1.399, 10.351, 65.639, 431.379, 1.541
Epoch: [135][600/782]	Time 0.084 (0.078)	Data 0.003 (0.003)	Loss 13.7033 (13.4352)	Acc@1 60.938 (63.693)	Acc@5 89.062 (90.040)
[epoch:136, iter:106171] Loss: 1.398, 10.350, 65.634, 431.326, 1.347
[epoch:136, iter:106191] Loss: 1.398, 10.351, 65.618, 431.294, 1.626
[epoch:136, iter:106211] Loss: 1.399, 10.351, 65.637, 431.278, 1.330
[epoch:136, iter:106231] Loss: 1.398, 10.347, 65.633, 431.229, 0.900
[epoch:136, iter:106251] Loss: 1.398, 10.349, 65.667, 431.306, 1.402
Epoch: [135][700/782]	Time 0.081 (0.077)	Data 0.003 (0.003)	Loss 13.8696 (13.4563)	Acc@1 60.938 (63.403)	Acc@5 89.062 (89.905)
[epoch:136, iter:106271] Loss: 1.399, 10.354, 65.693, 431.355, 1.401
[epoch:136, iter:106291] Loss: 1.399, 10.359, 65.710, 431.392, 1.297
[epoch:136, iter:106311] Loss: 1.399, 10.360, 65.747, 431.459, 1.649
[epoch:136, iter:106331] Loss: 1.399, 10.361, 65.779, 431.554, 1.376
[epoch:136, iter:106351] Loss: 1.399, 10.359, 65.778, 431.633, 1.940
 * Acc@1 63.242 Acc@5 89.758
epoch 135, total time 60.87
Test: [0/313]	Time 0.254 (0.254)	Loss 1.8918 (1.8918)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.0823 (1.8654)	Acc@1 46.875 (58.106)	Acc@5 87.500 (86.077)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.4134 (1.8680)	Acc@1 56.250 (57.540)	Acc@5 93.750 (85.634)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.2934 (1.8656)	Acc@1 37.500 (57.361)	Acc@5 87.500 (85.590)
 * Acc@1 57.500 Acc@5 85.650
==> training...
Epoch: [136][0/782]	Time 0.538 (0.538)	Data 0.457 (0.457)	Loss 13.9006 (13.9006)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
[epoch:137, iter:106353] Loss: 1.454, 10.594, 69.396, 441.026, 1.349
[epoch:137, iter:106373] Loss: 1.454, 10.578, 66.518, 435.053, 0.717
[epoch:137, iter:106393] Loss: 1.425, 10.458, 66.121, 432.636, 1.023
[epoch:137, iter:106413] Loss: 1.410, 10.409, 66.212, 432.495, 1.423
[epoch:137, iter:106433] Loss: 1.399, 10.410, 66.209, 432.100, 1.422
Epoch: [136][100/782]	Time 0.074 (0.087)	Data 0.002 (0.007)	Loss 14.2326 (13.4249)	Acc@1 59.375 (63.908)	Acc@5 87.500 (90.254)
[epoch:137, iter:106453] Loss: 1.404, 10.386, 66.157, 431.830, 1.446
[epoch:137, iter:106473] Loss: 1.403, 10.366, 66.162, 431.800, 1.243
[epoch:137, iter:106493] Loss: 1.399, 10.369, 65.989, 430.947, 1.477
[epoch:137, iter:106513] Loss: 1.400, 10.363, 65.976, 431.098, 1.384
[epoch:137, iter:106533] Loss: 1.397, 10.344, 65.852, 430.724, 1.497
Epoch: [136][200/782]	Time 0.067 (0.081)	Data 0.002 (0.005)	Loss 13.4567 (13.3314)	Acc@1 70.312 (63.915)	Acc@5 89.062 (90.291)
[epoch:137, iter:106553] Loss: 1.396, 10.333, 65.642, 430.250, 1.385
[epoch:137, iter:106573] Loss: 1.393, 10.325, 65.615, 430.194, 1.313
[epoch:137, iter:106593] Loss: 1.392, 10.323, 65.642, 430.403, 1.585
[epoch:137, iter:106613] Loss: 1.393, 10.330, 65.675, 430.410, 1.287
[epoch:137, iter:106633] Loss: 1.394, 10.332, 65.664, 430.475, 1.071
Epoch: [136][300/782]	Time 0.087 (0.079)	Data 0.002 (0.004)	Loss 13.6954 (13.3686)	Acc@1 62.500 (63.938)	Acc@5 87.500 (90.199)
[epoch:137, iter:106653] Loss: 1.395, 10.332, 65.690, 430.713, 1.680
[epoch:137, iter:106673] Loss: 1.396, 10.333, 65.724, 430.837, 1.089
[epoch:137, iter:106693] Loss: 1.396, 10.333, 65.670, 430.698, 1.623
[epoch:137, iter:106713] Loss: 1.398, 10.341, 65.693, 430.788, 1.455
[epoch:137, iter:106733] Loss: 1.398, 10.342, 65.725, 430.910, 1.139
Epoch: [136][400/782]	Time 0.072 (0.079)	Data 0.002 (0.003)	Loss 12.7393 (13.4027)	Acc@1 64.062 (63.985)	Acc@5 89.062 (90.126)
[epoch:137, iter:106753] Loss: 1.398, 10.344, 65.724, 430.956, 1.296
[epoch:137, iter:106773] Loss: 1.399, 10.347, 65.705, 431.040, 1.429
[epoch:137, iter:106793] Loss: 1.399, 10.348, 65.704, 431.254, 1.442
[epoch:137, iter:106813] Loss: 1.397, 10.346, 65.679, 431.229, 1.283
[epoch:137, iter:106833] Loss: 1.396, 10.343, 65.641, 431.103, 1.037
Epoch: [136][500/782]	Time 0.057 (0.078)	Data 0.002 (0.003)	Loss 12.5822 (13.4001)	Acc@1 60.938 (63.679)	Acc@5 93.750 (89.992)
[epoch:137, iter:106853] Loss: 1.395, 10.340, 65.616, 430.858, 1.190
[epoch:137, iter:106873] Loss: 1.396, 10.340, 65.597, 430.870, 1.291
[epoch:137, iter:106893] Loss: 1.395, 10.342, 65.590, 430.874, 1.019
[epoch:137, iter:106913] Loss: 1.395, 10.340, 65.591, 430.944, 1.607
[epoch:137, iter:106933] Loss: 1.395, 10.336, 65.575, 430.913, 1.266
Epoch: [136][600/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 14.4221 (13.4228)	Acc@1 60.938 (63.491)	Acc@5 87.500 (89.900)
[epoch:137, iter:106953] Loss: 1.395, 10.342, 65.595, 431.106, 1.523
[epoch:137, iter:106973] Loss: 1.397, 10.345, 65.630, 431.176, 1.331
[epoch:137, iter:106993] Loss: 1.398, 10.348, 65.642, 431.204, 2.042
[epoch:137, iter:107013] Loss: 1.398, 10.347, 65.629, 431.243, 0.804
[epoch:137, iter:107033] Loss: 1.398, 10.350, 65.642, 431.286, 1.431
Epoch: [136][700/782]	Time 0.058 (0.078)	Data 0.002 (0.003)	Loss 13.9097 (13.4410)	Acc@1 53.125 (63.367)	Acc@5 85.938 (89.863)
[epoch:137, iter:107053] Loss: 1.398, 10.346, 65.645, 431.324, 1.592
[epoch:137, iter:107073] Loss: 1.398, 10.343, 65.654, 431.436, 1.165
[epoch:137, iter:107093] Loss: 1.398, 10.345, 65.645, 431.395, 1.758
[epoch:137, iter:107113] Loss: 1.398, 10.342, 65.633, 431.394, 1.196
[epoch:137, iter:107133] Loss: 1.398, 10.342, 65.636, 431.460, 1.316
 * Acc@1 63.216 Acc@5 89.808
epoch 136, total time 60.88
Test: [0/313]	Time 0.257 (0.257)	Loss 1.7969 (1.7969)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.009 (0.010)	Loss 2.4158 (2.2232)	Acc@1 46.875 (53.218)	Acc@5 78.125 (81.776)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.7380 (2.1535)	Acc@1 59.375 (53.436)	Acc@5 90.625 (82.292)
Test: [300/313]	Time 0.005 (0.008)	Loss 3.2328 (2.1456)	Acc@1 34.375 (53.717)	Acc@5 81.250 (82.496)
 * Acc@1 53.820 Acc@5 82.550
==> training...
Epoch: [137][0/782]	Time 0.559 (0.559)	Data 0.472 (0.472)	Loss 14.5236 (14.5236)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
[epoch:138, iter:107135] Loss: 1.452, 10.197, 68.151, 439.532, 1.973
[epoch:138, iter:107155] Loss: 1.420, 10.336, 65.988, 433.763, 1.423
[epoch:138, iter:107175] Loss: 1.393, 10.266, 65.777, 432.464, 1.349
[epoch:138, iter:107195] Loss: 1.391, 10.285, 65.801, 432.769, 1.137
[epoch:138, iter:107215] Loss: 1.390, 10.295, 65.802, 433.195, 1.287
Epoch: [137][100/782]	Time 0.090 (0.082)	Data 0.003 (0.007)	Loss 12.9686 (13.4658)	Acc@1 54.688 (63.892)	Acc@5 95.312 (90.269)
[epoch:138, iter:107235] Loss: 1.388, 10.298, 65.766, 432.648, 1.189
[epoch:138, iter:107255] Loss: 1.387, 10.288, 65.826, 432.418, 1.529
[epoch:138, iter:107275] Loss: 1.388, 10.285, 65.811, 431.980, 1.578
[epoch:138, iter:107295] Loss: 1.384, 10.278, 65.602, 431.160, 0.965
[epoch:138, iter:107315] Loss: 1.384, 10.275, 65.512, 430.703, 1.367
Epoch: [137][200/782]	Time 0.089 (0.081)	Data 0.003 (0.005)	Loss 12.8890 (13.3286)	Acc@1 65.625 (64.062)	Acc@5 92.188 (90.306)
[epoch:138, iter:107335] Loss: 1.382, 10.269, 65.447, 430.373, 1.035
[epoch:138, iter:107355] Loss: 1.384, 10.267, 65.478, 430.653, 1.727
[epoch:138, iter:107375] Loss: 1.383, 10.263, 65.525, 430.919, 1.216
[epoch:138, iter:107395] Loss: 1.383, 10.276, 65.522, 430.794, 1.283
[epoch:138, iter:107415] Loss: 1.384, 10.280, 65.557, 430.955, 1.254
Epoch: [137][300/782]	Time 0.088 (0.080)	Data 0.003 (0.004)	Loss 14.3348 (13.3625)	Acc@1 59.375 (63.876)	Acc@5 92.188 (90.173)
[epoch:138, iter:107435] Loss: 1.383, 10.273, 65.516, 430.611, 1.479
[epoch:138, iter:107455] Loss: 1.384, 10.274, 65.512, 430.534, 0.987
[epoch:138, iter:107475] Loss: 1.385, 10.277, 65.505, 430.559, 1.726
[epoch:138, iter:107495] Loss: 1.386, 10.283, 65.477, 430.387, 1.045
[epoch:138, iter:107515] Loss: 1.388, 10.294, 65.429, 430.339, 1.388
Epoch: [137][400/782]	Time 0.088 (0.078)	Data 0.002 (0.004)	Loss 14.1590 (13.3636)	Acc@1 57.812 (63.934)	Acc@5 92.188 (90.056)
[epoch:138, iter:107535] Loss: 1.389, 10.304, 65.470, 430.473, 1.461
[epoch:138, iter:107555] Loss: 1.392, 10.308, 65.499, 430.541, 1.315
[epoch:138, iter:107575] Loss: 1.391, 10.318, 65.540, 430.653, 1.500
[epoch:138, iter:107595] Loss: 1.393, 10.325, 65.591, 430.930, 1.375
[epoch:138, iter:107615] Loss: 1.394, 10.327, 65.582, 431.016, 1.552
Epoch: [137][500/782]	Time 0.080 (0.078)	Data 0.003 (0.003)	Loss 13.0461 (13.4085)	Acc@1 60.938 (63.676)	Acc@5 89.062 (90.067)
[epoch:138, iter:107635] Loss: 1.395, 10.329, 65.558, 430.930, 1.434
[epoch:138, iter:107655] Loss: 1.395, 10.329, 65.566, 431.027, 1.418
[epoch:138, iter:107675] Loss: 1.395, 10.328, 65.584, 430.977, 1.878
[epoch:138, iter:107695] Loss: 1.394, 10.327, 65.567, 430.894, 1.058
[epoch:138, iter:107715] Loss: 1.394, 10.323, 65.567, 430.765, 1.241
Epoch: [137][600/782]	Time 0.062 (0.077)	Data 0.002 (0.003)	Loss 13.0136 (13.4216)	Acc@1 71.875 (63.644)	Acc@5 95.312 (89.965)
[epoch:138, iter:107735] Loss: 1.394, 10.327, 65.620, 430.883, 0.974
[epoch:138, iter:107755] Loss: 1.395, 10.329, 65.673, 431.076, 1.128
[epoch:138, iter:107775] Loss: 1.396, 10.330, 65.687, 431.167, 1.458
[epoch:138, iter:107795] Loss: 1.396, 10.336, 65.691, 431.280, 1.342
[epoch:138, iter:107815] Loss: 1.397, 10.340, 65.728, 431.331, 1.761
Epoch: [137][700/782]	Time 0.065 (0.076)	Data 0.002 (0.003)	Loss 12.5333 (13.4682)	Acc@1 60.938 (63.360)	Acc@5 90.625 (89.898)
[epoch:138, iter:107835] Loss: 1.398, 10.342, 65.773, 431.453, 1.268
[epoch:138, iter:107855] Loss: 1.398, 10.344, 65.805, 431.474, 1.841
[epoch:138, iter:107875] Loss: 1.398, 10.342, 65.794, 431.488, 1.693
[epoch:138, iter:107895] Loss: 1.398, 10.342, 65.772, 431.455, 1.267
[epoch:138, iter:107915] Loss: 1.399, 10.348, 65.805, 431.549, 1.073
 * Acc@1 63.310 Acc@5 89.794
epoch 137, total time 59.97
Test: [0/313]	Time 0.224 (0.224)	Loss 2.0498 (2.0498)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.0674 (2.0105)	Acc@1 56.250 (55.136)	Acc@5 84.375 (83.385)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.0237 (1.9684)	Acc@1 68.750 (54.820)	Acc@5 93.750 (84.328)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5727 (1.9653)	Acc@1 37.500 (54.994)	Acc@5 75.000 (84.219)
 * Acc@1 54.970 Acc@5 84.330
==> training...
Epoch: [138][0/782]	Time 0.610 (0.610)	Data 0.529 (0.529)	Loss 13.9183 (13.9183)	Acc@1 54.688 (54.688)	Acc@5 84.375 (84.375)
[epoch:139, iter:107917] Loss: 1.370, 10.630, 67.717, 437.592, 1.658
[epoch:139, iter:107937] Loss: 1.414, 10.436, 67.094, 434.387, 1.238
[epoch:139, iter:107957] Loss: 1.404, 10.342, 66.161, 432.441, 1.280
[epoch:139, iter:107977] Loss: 1.401, 10.387, 66.035, 431.998, 1.005
[epoch:139, iter:107997] Loss: 1.399, 10.384, 65.714, 430.800, 1.058
Epoch: [138][100/782]	Time 0.094 (0.086)	Data 0.003 (0.008)	Loss 13.8018 (13.4227)	Acc@1 71.875 (63.413)	Acc@5 90.625 (90.532)
[epoch:139, iter:108017] Loss: 1.397, 10.344, 65.687, 430.915, 1.061
[epoch:139, iter:108037] Loss: 1.402, 10.344, 65.640, 430.944, 1.148
[epoch:139, iter:108057] Loss: 1.401, 10.339, 65.706, 430.902, 0.814
[epoch:139, iter:108077] Loss: 1.395, 10.339, 65.550, 430.301, 1.164
[epoch:139, iter:108097] Loss: 1.395, 10.337, 65.417, 429.844, 0.990
Epoch: [138][200/782]	Time 0.080 (0.083)	Data 0.002 (0.005)	Loss 14.1229 (13.3581)	Acc@1 59.375 (63.612)	Acc@5 81.250 (89.995)
[epoch:139, iter:108117] Loss: 1.391, 10.324, 65.349, 429.812, 1.683
[epoch:139, iter:108137] Loss: 1.389, 10.317, 65.332, 429.909, 1.822
[epoch:139, iter:108157] Loss: 1.391, 10.317, 65.405, 429.969, 1.642
[epoch:139, iter:108177] Loss: 1.391, 10.324, 65.408, 429.900, 1.480
[epoch:139, iter:108197] Loss: 1.390, 10.323, 65.386, 429.705, 1.290
Epoch: [138][300/782]	Time 0.083 (0.079)	Data 0.003 (0.004)	Loss 14.5675 (13.3435)	Acc@1 59.375 (63.580)	Acc@5 89.062 (90.033)
[epoch:139, iter:108217] Loss: 1.389, 10.320, 65.495, 429.789, 1.601
[epoch:139, iter:108237] Loss: 1.389, 10.332, 65.595, 430.097, 1.315
[epoch:139, iter:108257] Loss: 1.389, 10.328, 65.551, 430.127, 1.331
[epoch:139, iter:108277] Loss: 1.389, 10.330, 65.514, 430.190, 1.451
[epoch:139, iter:108297] Loss: 1.390, 10.331, 65.546, 430.270, 1.597
Epoch: [138][400/782]	Time 0.076 (0.078)	Data 0.002 (0.004)	Loss 13.6628 (13.3947)	Acc@1 65.625 (63.447)	Acc@5 89.062 (89.924)
[epoch:139, iter:108317] Loss: 1.392, 10.338, 65.609, 430.425, 1.363
[epoch:139, iter:108337] Loss: 1.393, 10.346, 65.693, 430.814, 1.490
[epoch:139, iter:108357] Loss: 1.394, 10.352, 65.700, 430.802, 0.995
[epoch:139, iter:108377] Loss: 1.395, 10.356, 65.693, 430.846, 1.238
[epoch:139, iter:108397] Loss: 1.395, 10.354, 65.683, 430.900, 1.362
Epoch: [138][500/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 13.6305 (13.4335)	Acc@1 57.812 (63.351)	Acc@5 92.188 (89.864)
[epoch:139, iter:108417] Loss: 1.395, 10.356, 65.652, 430.880, 1.303
[epoch:139, iter:108437] Loss: 1.395, 10.355, 65.678, 430.935, 1.424
[epoch:139, iter:108457] Loss: 1.395, 10.361, 65.699, 431.014, 0.939
[epoch:139, iter:108477] Loss: 1.394, 10.362, 65.673, 430.986, 1.199
[epoch:139, iter:108497] Loss: 1.395, 10.364, 65.640, 430.928, 1.788
Epoch: [138][600/782]	Time 0.090 (0.078)	Data 0.002 (0.003)	Loss 15.1386 (13.4384)	Acc@1 60.938 (63.277)	Acc@5 84.375 (90.032)
[epoch:139, iter:108517] Loss: 1.395, 10.363, 65.648, 430.947, 1.982
[epoch:139, iter:108537] Loss: 1.395, 10.364, 65.653, 430.969, 1.070
[epoch:139, iter:108557] Loss: 1.396, 10.366, 65.667, 431.003, 0.991
[epoch:139, iter:108577] Loss: 1.396, 10.369, 65.645, 431.043, 1.173
[epoch:139, iter:108597] Loss: 1.397, 10.374, 65.658, 431.112, 1.357
Epoch: [138][700/782]	Time 0.085 (0.078)	Data 0.003 (0.003)	Loss 13.3700 (13.4524)	Acc@1 62.500 (63.129)	Acc@5 92.188 (89.930)
[epoch:139, iter:108617] Loss: 1.396, 10.375, 65.661, 431.204, 1.291
[epoch:139, iter:108637] Loss: 1.397, 10.374, 65.639, 431.199, 1.321
[epoch:139, iter:108657] Loss: 1.397, 10.371, 65.643, 431.256, 1.273
[epoch:139, iter:108677] Loss: 1.397, 10.369, 65.661, 431.387, 1.632
[epoch:139, iter:108697] Loss: 1.398, 10.369, 65.649, 431.385, 1.178
 * Acc@1 63.082 Acc@5 89.918
epoch 138, total time 60.96
Test: [0/313]	Time 0.264 (0.264)	Loss 1.9230 (1.9230)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.007 (0.010)	Loss 2.4245 (1.9864)	Acc@1 50.000 (55.167)	Acc@5 84.375 (84.963)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.4557 (1.9725)	Acc@1 65.625 (54.897)	Acc@5 90.625 (84.950)
Test: [300/313]	Time 0.005 (0.008)	Loss 2.1154 (1.9911)	Acc@1 56.250 (54.983)	Acc@5 87.500 (84.821)
 * Acc@1 55.100 Acc@5 84.910
==> training...
Epoch: [139][0/782]	Time 0.529 (0.529)	Data 0.438 (0.438)	Loss 13.5311 (13.5311)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
[epoch:140, iter:108699] Loss: 1.413, 10.561, 67.477, 439.588, 1.094
[epoch:140, iter:108719] Loss: 1.417, 10.496, 65.336, 434.537, 0.952
[epoch:140, iter:108739] Loss: 1.416, 10.501, 65.942, 434.840, 1.524
[epoch:140, iter:108759] Loss: 1.414, 10.437, 65.844, 434.782, 0.980
[epoch:140, iter:108779] Loss: 1.415, 10.419, 65.680, 433.643, 1.331
Epoch: [139][100/782]	Time 0.064 (0.080)	Data 0.002 (0.007)	Loss 13.7499 (13.4526)	Acc@1 54.688 (63.320)	Acc@5 87.500 (90.811)
[epoch:140, iter:108799] Loss: 1.414, 10.390, 65.457, 433.244, 1.574
[epoch:140, iter:108819] Loss: 1.409, 10.373, 65.537, 433.091, 1.336
[epoch:140, iter:108839] Loss: 1.408, 10.365, 65.564, 432.409, 1.418
[epoch:140, iter:108859] Loss: 1.404, 10.364, 65.659, 432.372, 0.985
[epoch:140, iter:108879] Loss: 1.404, 10.369, 65.667, 432.374, 1.176
Epoch: [139][200/782]	Time 0.084 (0.077)	Data 0.003 (0.004)	Loss 12.6508 (13.4226)	Acc@1 64.062 (63.285)	Acc@5 87.500 (90.400)
[epoch:140, iter:108899] Loss: 1.402, 10.365, 65.665, 432.260, 1.310
[epoch:140, iter:108919] Loss: 1.402, 10.364, 65.588, 432.123, 1.377
[epoch:140, iter:108939] Loss: 1.402, 10.367, 65.602, 432.467, 1.476
[epoch:140, iter:108959] Loss: 1.402, 10.365, 65.592, 432.210, 1.366
[epoch:140, iter:108979] Loss: 1.400, 10.371, 65.542, 431.850, 1.206
Epoch: [139][300/782]	Time 0.077 (0.077)	Data 0.002 (0.004)	Loss 12.8480 (13.4263)	Acc@1 65.625 (63.408)	Acc@5 93.750 (90.173)
[epoch:140, iter:108999] Loss: 1.400, 10.364, 65.550, 431.718, 1.022
[epoch:140, iter:109019] Loss: 1.400, 10.364, 65.538, 431.757, 1.447
[epoch:140, iter:109039] Loss: 1.399, 10.361, 65.479, 431.486, 1.042
[epoch:140, iter:109059] Loss: 1.399, 10.353, 65.492, 431.519, 1.138
[epoch:140, iter:109079] Loss: 1.396, 10.350, 65.431, 431.447, 1.679
Epoch: [139][400/782]	Time 0.076 (0.078)	Data 0.002 (0.003)	Loss 13.4042 (13.4151)	Acc@1 60.938 (63.462)	Acc@5 87.500 (90.033)
[epoch:140, iter:109099] Loss: 1.395, 10.345, 65.421, 431.465, 1.281
[epoch:140, iter:109119] Loss: 1.394, 10.342, 65.440, 431.342, 1.691
[epoch:140, iter:109139] Loss: 1.395, 10.342, 65.454, 431.303, 1.024
[epoch:140, iter:109159] Loss: 1.395, 10.337, 65.405, 431.047, 1.307
[epoch:140, iter:109179] Loss: 1.395, 10.340, 65.398, 431.072, 1.614
Epoch: [139][500/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 14.3648 (13.4014)	Acc@1 57.812 (63.579)	Acc@5 84.375 (89.933)
[epoch:140, iter:109199] Loss: 1.394, 10.339, 65.379, 430.961, 1.708
[epoch:140, iter:109219] Loss: 1.395, 10.335, 65.418, 431.036, 1.562
[epoch:140, iter:109239] Loss: 1.395, 10.335, 65.453, 431.008, 1.258
[epoch:140, iter:109259] Loss: 1.395, 10.337, 65.482, 431.044, 1.462
[epoch:140, iter:109279] Loss: 1.396, 10.335, 65.466, 430.964, 1.359
Epoch: [139][600/782]	Time 0.071 (0.077)	Data 0.002 (0.003)	Loss 13.2828 (13.3988)	Acc@1 53.125 (63.615)	Acc@5 95.312 (89.988)
[epoch:140, iter:109299] Loss: 1.396, 10.336, 65.444, 430.890, 1.242
[epoch:140, iter:109319] Loss: 1.396, 10.338, 65.457, 430.958, 1.455
[epoch:140, iter:109339] Loss: 1.398, 10.343, 65.470, 431.023, 1.573
[epoch:140, iter:109359] Loss: 1.399, 10.344, 65.473, 431.092, 1.241
[epoch:140, iter:109379] Loss: 1.398, 10.345, 65.491, 431.200, 1.212
Epoch: [139][700/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 13.3246 (13.4231)	Acc@1 68.750 (63.514)	Acc@5 90.625 (89.885)
[epoch:140, iter:109399] Loss: 1.398, 10.349, 65.486, 431.147, 1.114
[epoch:140, iter:109419] Loss: 1.399, 10.351, 65.489, 431.151, 1.421
[epoch:140, iter:109439] Loss: 1.399, 10.351, 65.492, 431.146, 1.283
[epoch:140, iter:109459] Loss: 1.400, 10.351, 65.472, 431.085, 0.969
[epoch:140, iter:109479] Loss: 1.400, 10.353, 65.481, 431.188, 1.145
 * Acc@1 63.384 Acc@5 89.884
epoch 139, total time 60.12
Test: [0/313]	Time 0.255 (0.255)	Loss 2.1011 (2.1011)	Acc@1 56.250 (56.250)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9958 (1.8437)	Acc@1 37.500 (56.374)	Acc@5 75.000 (85.582)
Test: [200/313]	Time 0.008 (0.008)	Loss 1.3618 (1.8486)	Acc@1 56.250 (56.157)	Acc@5 90.625 (86.039)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.5799 (1.8593)	Acc@1 43.750 (56.364)	Acc@5 78.125 (85.818)
 * Acc@1 56.390 Acc@5 85.840
==> training...
Epoch: [140][0/782]	Time 0.533 (0.533)	Data 0.458 (0.458)	Loss 13.2578 (13.2578)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
[epoch:141, iter:109481] Loss: 1.398, 10.629, 67.109, 441.957, 1.111
[epoch:141, iter:109501] Loss: 1.411, 10.525, 65.920, 434.356, 1.640
[epoch:141, iter:109521] Loss: 1.422, 10.446, 65.612, 433.259, 1.459
[epoch:141, iter:109541] Loss: 1.409, 10.415, 65.659, 432.163, 0.939
[epoch:141, iter:109561] Loss: 1.406, 10.372, 65.420, 431.207, 1.481
Epoch: [140][100/782]	Time 0.094 (0.083)	Data 0.003 (0.007)	Loss 14.0810 (13.3801)	Acc@1 56.250 (63.304)	Acc@5 84.375 (89.155)
[epoch:141, iter:109581] Loss: 1.403, 10.351, 65.387, 431.317, 1.647
[epoch:141, iter:109601] Loss: 1.401, 10.351, 65.397, 431.192, 1.374
[epoch:141, iter:109621] Loss: 1.400, 10.347, 65.317, 430.742, 1.301
[epoch:141, iter:109641] Loss: 1.402, 10.358, 65.255, 430.607, 1.238
[epoch:141, iter:109661] Loss: 1.399, 10.345, 65.274, 430.677, 1.413
Epoch: [140][200/782]	Time 0.090 (0.082)	Data 0.003 (0.005)	Loss 13.5015 (13.3755)	Acc@1 60.938 (63.122)	Acc@5 90.625 (89.303)
[epoch:141, iter:109681] Loss: 1.399, 10.350, 65.310, 430.951, 1.194
[epoch:141, iter:109701] Loss: 1.399, 10.355, 65.354, 430.858, 1.344
[epoch:141, iter:109721] Loss: 1.398, 10.353, 65.329, 430.703, 1.498
[epoch:141, iter:109741] Loss: 1.393, 10.338, 65.282, 430.352, 1.187
[epoch:141, iter:109761] Loss: 1.391, 10.340, 65.327, 430.207, 1.337
Epoch: [140][300/782]	Time 0.079 (0.082)	Data 0.002 (0.004)	Loss 14.3611 (13.3442)	Acc@1 60.938 (63.305)	Acc@5 79.688 (89.499)
[epoch:141, iter:109781] Loss: 1.391, 10.339, 65.287, 429.952, 2.037
[epoch:141, iter:109801] Loss: 1.392, 10.335, 65.278, 430.093, 1.414
[epoch:141, iter:109821] Loss: 1.392, 10.334, 65.286, 430.210, 1.930
[epoch:141, iter:109841] Loss: 1.392, 10.340, 65.289, 430.170, 1.553
[epoch:141, iter:109861] Loss: 1.393, 10.348, 65.350, 430.447, 1.034
Epoch: [140][400/782]	Time 0.080 (0.080)	Data 0.002 (0.004)	Loss 13.2968 (13.3695)	Acc@1 70.312 (63.314)	Acc@5 90.625 (89.600)
[epoch:141, iter:109881] Loss: 1.393, 10.346, 65.304, 430.243, 1.214
[epoch:141, iter:109901] Loss: 1.393, 10.348, 65.338, 430.331, 1.351
[epoch:141, iter:109921] Loss: 1.393, 10.342, 65.380, 430.330, 1.226
[epoch:141, iter:109941] Loss: 1.394, 10.349, 65.402, 430.335, 1.495
[epoch:141, iter:109961] Loss: 1.394, 10.349, 65.412, 430.316, 0.781
Epoch: [140][500/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 13.5818 (13.3908)	Acc@1 65.625 (63.345)	Acc@5 81.250 (89.586)
[epoch:141, iter:109981] Loss: 1.393, 10.346, 65.418, 430.391, 1.547
[epoch:141, iter:110001] Loss: 1.393, 10.344, 65.441, 430.572, 1.175
[epoch:141, iter:110021] Loss: 1.393, 10.346, 65.447, 430.640, 1.486
[epoch:141, iter:110041] Loss: 1.393, 10.343, 65.418, 430.599, 1.509
[epoch:141, iter:110061] Loss: 1.393, 10.341, 65.425, 430.574, 1.731
Epoch: [140][600/782]	Time 0.087 (0.079)	Data 0.003 (0.003)	Loss 13.6111 (13.4027)	Acc@1 70.312 (63.280)	Acc@5 96.875 (89.660)
[epoch:141, iter:110081] Loss: 1.393, 10.331, 65.442, 430.479, 1.134
[epoch:141, iter:110101] Loss: 1.393, 10.330, 65.406, 430.341, 1.176
[epoch:141, iter:110121] Loss: 1.393, 10.326, 65.410, 430.317, 1.236
[epoch:141, iter:110141] Loss: 1.393, 10.325, 65.398, 430.324, 1.624
[epoch:141, iter:110161] Loss: 1.393, 10.320, 65.427, 430.368, 1.370
Epoch: [140][700/782]	Time 0.057 (0.079)	Data 0.002 (0.003)	Loss 13.8195 (13.4015)	Acc@1 68.750 (63.229)	Acc@5 90.625 (89.689)
[epoch:141, iter:110181] Loss: 1.394, 10.322, 65.440, 430.448, 1.253
[epoch:141, iter:110201] Loss: 1.394, 10.327, 65.466, 430.529, 1.833
[epoch:141, iter:110221] Loss: 1.394, 10.333, 65.485, 430.617, 1.439
[epoch:141, iter:110241] Loss: 1.394, 10.332, 65.471, 430.635, 1.204
[epoch:141, iter:110261] Loss: 1.395, 10.332, 65.481, 430.720, 1.374
 * Acc@1 63.254 Acc@5 89.676
epoch 140, total time 61.76
Test: [0/313]	Time 0.267 (0.267)	Loss 2.0662 (2.0662)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.010 (0.010)	Loss 2.4664 (2.0026)	Acc@1 53.125 (55.043)	Acc@5 78.125 (84.561)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.8197 (1.9637)	Acc@1 59.375 (55.752)	Acc@5 87.500 (85.152)
Test: [300/313]	Time 0.007 (0.008)	Loss 2.7105 (1.9798)	Acc@1 31.250 (55.679)	Acc@5 87.500 (85.050)
 * Acc@1 55.660 Acc@5 85.120
==> training...
Epoch: [141][0/782]	Time 0.561 (0.561)	Data 0.492 (0.492)	Loss 13.7666 (13.7666)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
[epoch:142, iter:110263] Loss: 1.485, 9.837, 67.985, 431.595, 1.283
[epoch:142, iter:110283] Loss: 1.419, 10.407, 66.077, 430.470, 1.536
[epoch:142, iter:110303] Loss: 1.428, 10.423, 66.202, 432.152, 1.236
[epoch:142, iter:110323] Loss: 1.421, 10.416, 66.158, 432.219, 1.518
[epoch:142, iter:110343] Loss: 1.411, 10.396, 66.058, 431.620, 0.982
Epoch: [141][100/782]	Time 0.072 (0.083)	Data 0.002 (0.007)	Loss 13.2337 (13.5194)	Acc@1 68.750 (62.686)	Acc@5 93.750 (89.604)
[epoch:142, iter:110363] Loss: 1.407, 10.385, 66.033, 431.655, 1.155
[epoch:142, iter:110383] Loss: 1.407, 10.375, 65.959, 431.246, 1.267
[epoch:142, iter:110403] Loss: 1.406, 10.377, 65.814, 431.255, 1.441
[epoch:142, iter:110423] Loss: 1.406, 10.380, 65.870, 431.494, 1.237
[epoch:142, iter:110443] Loss: 1.402, 10.379, 65.758, 431.213, 1.425
Epoch: [141][200/782]	Time 0.092 (0.082)	Data 0.003 (0.005)	Loss 14.5639 (13.3989)	Acc@1 57.812 (63.759)	Acc@5 90.625 (90.042)
[epoch:142, iter:110463] Loss: 1.398, 10.365, 65.598, 430.735, 1.607
[epoch:142, iter:110483] Loss: 1.398, 10.360, 65.643, 430.703, 1.577
[epoch:142, iter:110503] Loss: 1.395, 10.347, 65.573, 430.621, 1.459
[epoch:142, iter:110523] Loss: 1.394, 10.346, 65.561, 430.739, 1.355
[epoch:142, iter:110543] Loss: 1.394, 10.344, 65.602, 431.057, 1.140
Epoch: [141][300/782]	Time 0.079 (0.081)	Data 0.002 (0.004)	Loss 12.9925 (13.4165)	Acc@1 62.500 (63.626)	Acc@5 96.875 (90.147)
[epoch:142, iter:110563] Loss: 1.393, 10.344, 65.645, 431.088, 1.164
[epoch:142, iter:110583] Loss: 1.393, 10.350, 65.684, 431.026, 1.358
[epoch:142, iter:110603] Loss: 1.394, 10.358, 65.684, 431.053, 0.969
[epoch:142, iter:110623] Loss: 1.394, 10.364, 65.698, 431.273, 1.084
[epoch:142, iter:110643] Loss: 1.393, 10.367, 65.763, 431.490, 1.322
Epoch: [141][400/782]	Time 0.064 (0.080)	Data 0.002 (0.004)	Loss 13.6169 (13.4344)	Acc@1 68.750 (63.431)	Acc@5 93.750 (90.083)
[epoch:142, iter:110663] Loss: 1.395, 10.370, 65.769, 431.497, 1.230
[epoch:142, iter:110683] Loss: 1.396, 10.378, 65.787, 431.615, 1.785
[epoch:142, iter:110703] Loss: 1.397, 10.381, 65.847, 431.803, 1.546
[epoch:142, iter:110723] Loss: 1.397, 10.383, 65.838, 431.768, 1.589
[epoch:142, iter:110743] Loss: 1.400, 10.384, 65.865, 431.938, 1.342
Epoch: [141][500/782]	Time 0.078 (0.079)	Data 0.002 (0.003)	Loss 13.8427 (13.4936)	Acc@1 59.375 (63.064)	Acc@5 82.812 (89.774)
[epoch:142, iter:110763] Loss: 1.401, 10.387, 65.886, 432.010, 1.520
[epoch:142, iter:110783] Loss: 1.403, 10.389, 65.916, 432.062, 1.237
[epoch:142, iter:110803] Loss: 1.403, 10.389, 65.910, 432.129, 1.405
[epoch:142, iter:110823] Loss: 1.404, 10.397, 65.909, 432.164, 1.496
[epoch:142, iter:110843] Loss: 1.403, 10.394, 65.894, 432.160, 1.766
Epoch: [141][600/782]	Time 0.065 (0.079)	Data 0.002 (0.003)	Loss 13.6880 (13.5065)	Acc@1 60.938 (63.020)	Acc@5 90.625 (89.705)
[epoch:142, iter:110863] Loss: 1.403, 10.392, 65.869, 432.096, 1.342
[epoch:142, iter:110883] Loss: 1.402, 10.394, 65.862, 432.056, 1.743
[epoch:142, iter:110903] Loss: 1.401, 10.393, 65.850, 431.987, 1.466
[epoch:142, iter:110923] Loss: 1.401, 10.394, 65.861, 432.011, 1.404
[epoch:142, iter:110943] Loss: 1.401, 10.393, 65.829, 431.914, 1.442
Epoch: [141][700/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 12.4379 (13.4982)	Acc@1 78.125 (62.968)	Acc@5 95.312 (89.664)
[epoch:142, iter:110963] Loss: 1.400, 10.392, 65.802, 431.874, 0.807
[epoch:142, iter:110983] Loss: 1.400, 10.391, 65.804, 431.877, 1.491
[epoch:142, iter:111003] Loss: 1.399, 10.386, 65.791, 431.843, 1.236
[epoch:142, iter:111023] Loss: 1.400, 10.384, 65.812, 431.867, 1.420
[epoch:142, iter:111043] Loss: 1.400, 10.383, 65.832, 431.961, 1.312
 * Acc@1 62.874 Acc@5 89.614
epoch 141, total time 61.27
Test: [0/313]	Time 0.246 (0.246)	Loss 2.3584 (2.3584)	Acc@1 53.125 (53.125)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.6371 (2.2559)	Acc@1 50.000 (51.392)	Acc@5 71.875 (80.260)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7086 (2.2539)	Acc@1 56.250 (51.228)	Acc@5 84.375 (80.100)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5126 (2.2424)	Acc@1 50.000 (51.433)	Acc@5 81.250 (80.149)
 * Acc@1 51.440 Acc@5 80.150
==> training...
Epoch: [142][0/782]	Time 0.499 (0.499)	Data 0.415 (0.415)	Loss 13.4004 (13.4004)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
[epoch:143, iter:111045] Loss: 1.295, 10.221, 67.105, 430.643, 1.171
[epoch:143, iter:111065] Loss: 1.376, 10.365, 64.783, 429.655, 1.471
[epoch:143, iter:111085] Loss: 1.379, 10.391, 64.725, 429.627, 1.139
[epoch:143, iter:111105] Loss: 1.382, 10.364, 64.914, 429.359, 1.418
[epoch:143, iter:111125] Loss: 1.385, 10.338, 65.069, 428.740, 1.483
Epoch: [142][100/782]	Time 0.076 (0.078)	Data 0.002 (0.006)	Loss 12.7745 (13.2455)	Acc@1 56.250 (64.186)	Acc@5 92.188 (90.022)
[epoch:143, iter:111145] Loss: 1.380, 10.343, 65.285, 429.102, 1.311
[epoch:143, iter:111165] Loss: 1.376, 10.332, 65.088, 428.767, 1.046
[epoch:143, iter:111185] Loss: 1.381, 10.343, 65.170, 428.991, 1.468
[epoch:143, iter:111205] Loss: 1.382, 10.341, 65.307, 429.321, 1.209
[epoch:143, iter:111225] Loss: 1.384, 10.346, 65.322, 429.323, 1.576
Epoch: [142][200/782]	Time 0.083 (0.078)	Data 0.003 (0.004)	Loss 12.9769 (13.2566)	Acc@1 59.375 (63.845)	Acc@5 96.875 (90.586)
[epoch:143, iter:111245] Loss: 1.385, 10.349, 65.323, 429.168, 1.280
[epoch:143, iter:111265] Loss: 1.381, 10.337, 65.272, 429.069, 1.074
[epoch:143, iter:111285] Loss: 1.380, 10.332, 65.169, 428.944, 1.407
[epoch:143, iter:111305] Loss: 1.381, 10.333, 65.297, 429.193, 1.235
[epoch:143, iter:111325] Loss: 1.383, 10.336, 65.338, 429.335, 1.082
Epoch: [142][300/782]	Time 0.088 (0.077)	Data 0.003 (0.004)	Loss 13.3793 (13.2566)	Acc@1 68.750 (63.881)	Acc@5 87.500 (90.391)
[epoch:143, iter:111345] Loss: 1.384, 10.329, 65.292, 429.109, 1.274
[epoch:143, iter:111365] Loss: 1.386, 10.327, 65.295, 429.162, 0.984
[epoch:143, iter:111385] Loss: 1.387, 10.332, 65.278, 429.267, 1.495
[epoch:143, iter:111405] Loss: 1.387, 10.327, 65.324, 429.495, 1.474
[epoch:143, iter:111425] Loss: 1.386, 10.327, 65.324, 429.463, 1.110
Epoch: [142][400/782]	Time 0.088 (0.078)	Data 0.003 (0.003)	Loss 14.3166 (13.2876)	Acc@1 56.250 (63.681)	Acc@5 90.625 (90.259)
[epoch:143, iter:111445] Loss: 1.386, 10.326, 65.312, 429.540, 1.491
[epoch:143, iter:111465] Loss: 1.388, 10.333, 65.349, 429.594, 1.618
[epoch:143, iter:111485] Loss: 1.388, 10.338, 65.349, 429.644, 1.101
[epoch:143, iter:111505] Loss: 1.389, 10.341, 65.365, 429.666, 1.473
[epoch:143, iter:111525] Loss: 1.390, 10.345, 65.379, 429.822, 1.383
Epoch: [142][500/782]	Time 0.061 (0.077)	Data 0.002 (0.003)	Loss 14.7853 (13.3234)	Acc@1 53.125 (63.944)	Acc@5 85.938 (90.245)
[epoch:143, iter:111545] Loss: 1.391, 10.346, 65.396, 429.895, 1.845
[epoch:143, iter:111565] Loss: 1.392, 10.345, 65.472, 430.219, 1.217
[epoch:143, iter:111585] Loss: 1.392, 10.351, 65.517, 430.366, 1.172
[epoch:143, iter:111605] Loss: 1.392, 10.355, 65.526, 430.432, 1.360
[epoch:143, iter:111625] Loss: 1.393, 10.354, 65.585, 430.563, 1.047
Epoch: [142][600/782]	Time 0.086 (0.078)	Data 0.003 (0.003)	Loss 13.3836 (13.3767)	Acc@1 59.375 (63.699)	Acc@5 87.500 (90.204)
[epoch:143, iter:111645] Loss: 1.393, 10.354, 65.613, 430.636, 1.422
[epoch:143, iter:111665] Loss: 1.393, 10.355, 65.632, 430.695, 1.418
[epoch:143, iter:111685] Loss: 1.394, 10.358, 65.643, 430.768, 1.738
[epoch:143, iter:111705] Loss: 1.394, 10.362, 65.671, 430.905, 1.384
[epoch:143, iter:111725] Loss: 1.393, 10.361, 65.686, 430.898, 1.513
Epoch: [142][700/782]	Time 0.089 (0.077)	Data 0.003 (0.003)	Loss 13.4620 (13.4121)	Acc@1 51.562 (63.434)	Acc@5 85.938 (90.041)
[epoch:143, iter:111745] Loss: 1.394, 10.363, 65.712, 430.918, 1.564
[epoch:143, iter:111765] Loss: 1.395, 10.362, 65.691, 430.905, 1.239
[epoch:143, iter:111785] Loss: 1.394, 10.362, 65.697, 431.027, 1.734
[epoch:143, iter:111805] Loss: 1.394, 10.362, 65.677, 430.970, 1.332
[epoch:143, iter:111825] Loss: 1.394, 10.365, 65.692, 431.024, 1.716
 * Acc@1 63.372 Acc@5 90.014
epoch 142, total time 60.69
Test: [0/313]	Time 0.236 (0.236)	Loss 2.1166 (2.1166)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.1996 (1.8620)	Acc@1 50.000 (56.931)	Acc@5 90.625 (85.365)
Test: [200/313]	Time 0.005 (0.008)	Loss 1.6360 (1.8919)	Acc@1 62.500 (56.250)	Acc@5 84.375 (85.401)
Test: [300/313]	Time 0.008 (0.007)	Loss 1.9112 (1.8863)	Acc@1 46.875 (56.593)	Acc@5 87.500 (85.507)
 * Acc@1 56.530 Acc@5 85.580
==> training...
Epoch: [143][0/782]	Time 0.522 (0.522)	Data 0.444 (0.444)	Loss 12.8764 (12.8764)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
[epoch:144, iter:111827] Loss: 1.364, 10.748, 65.892, 426.784, 1.025
[epoch:144, iter:111847] Loss: 1.392, 10.479, 65.971, 430.369, 0.964
[epoch:144, iter:111867] Loss: 1.398, 10.476, 65.799, 430.319, 1.457
[epoch:144, iter:111887] Loss: 1.396, 10.424, 65.558, 430.004, 1.609
[epoch:144, iter:111907] Loss: 1.397, 10.437, 65.224, 429.302, 1.259
Epoch: [143][100/782]	Time 0.076 (0.081)	Data 0.002 (0.007)	Loss 13.9421 (13.3761)	Acc@1 60.938 (63.707)	Acc@5 81.250 (89.527)
[epoch:144, iter:111927] Loss: 1.394, 10.396, 65.115, 429.295, 1.769
[epoch:144, iter:111947] Loss: 1.392, 10.360, 65.030, 429.140, 1.773
[epoch:144, iter:111967] Loss: 1.391, 10.364, 65.199, 430.016, 1.540
[epoch:144, iter:111987] Loss: 1.390, 10.366, 65.291, 430.456, 0.847
[epoch:144, iter:112007] Loss: 1.387, 10.357, 65.072, 429.738, 1.179
Epoch: [143][200/782]	Time 0.071 (0.076)	Data 0.002 (0.004)	Loss 13.9910 (13.3490)	Acc@1 54.688 (64.000)	Acc@5 92.188 (89.863)
[epoch:144, iter:112027] Loss: 1.386, 10.344, 65.007, 429.517, 1.383
[epoch:144, iter:112047] Loss: 1.384, 10.336, 64.969, 429.221, 1.451
[epoch:144, iter:112067] Loss: 1.384, 10.334, 65.084, 429.420, 1.546
[epoch:144, iter:112087] Loss: 1.384, 10.339, 65.086, 429.372, 1.585
[epoch:144, iter:112107] Loss: 1.386, 10.337, 65.122, 429.384, 1.561
Epoch: [143][300/782]	Time 0.075 (0.076)	Data 0.002 (0.004)	Loss 13.6522 (13.3489)	Acc@1 62.500 (63.979)	Acc@5 87.500 (89.929)
[epoch:144, iter:112127] Loss: 1.387, 10.336, 65.200, 429.669, 1.286
[epoch:144, iter:112147] Loss: 1.389, 10.337, 65.262, 429.728, 1.059
[epoch:144, iter:112167] Loss: 1.389, 10.336, 65.270, 429.830, 1.075
[epoch:144, iter:112187] Loss: 1.390, 10.335, 65.261, 429.806, 1.518
[epoch:144, iter:112207] Loss: 1.390, 10.335, 65.273, 429.839, 1.674
Epoch: [143][400/782]	Time 0.060 (0.076)	Data 0.002 (0.003)	Loss 13.0513 (13.3716)	Acc@1 67.188 (63.860)	Acc@5 100.000 (89.834)
[epoch:144, iter:112227] Loss: 1.388, 10.331, 65.333, 430.041, 0.929
[epoch:144, iter:112247] Loss: 1.388, 10.326, 65.299, 430.033, 0.975
[epoch:144, iter:112267] Loss: 1.388, 10.328, 65.262, 430.004, 1.526
[epoch:144, iter:112287] Loss: 1.389, 10.332, 65.295, 430.105, 1.167
[epoch:144, iter:112307] Loss: 1.390, 10.332, 65.349, 430.237, 1.472
Epoch: [143][500/782]	Time 0.080 (0.076)	Data 0.002 (0.003)	Loss 13.6428 (13.3947)	Acc@1 53.125 (63.607)	Acc@5 89.062 (89.795)
[epoch:144, iter:112327] Loss: 1.390, 10.329, 65.383, 430.298, 1.409
[epoch:144, iter:112347] Loss: 1.390, 10.325, 65.380, 430.266, 1.298
[epoch:144, iter:112367] Loss: 1.390, 10.327, 65.427, 430.324, 1.626
[epoch:144, iter:112387] Loss: 1.389, 10.329, 65.423, 430.333, 1.357
[epoch:144, iter:112407] Loss: 1.390, 10.333, 65.452, 430.468, 1.590
Epoch: [143][600/782]	Time 0.088 (0.077)	Data 0.003 (0.003)	Loss 14.2190 (13.4098)	Acc@1 59.375 (63.509)	Acc@5 79.688 (89.793)
[epoch:144, iter:112427] Loss: 1.391, 10.332, 65.464, 430.513, 1.777
[epoch:144, iter:112447] Loss: 1.392, 10.332, 65.511, 430.608, 1.320
[epoch:144, iter:112467] Loss: 1.391, 10.331, 65.542, 430.576, 1.093
[epoch:144, iter:112487] Loss: 1.391, 10.332, 65.581, 430.613, 1.435
[epoch:144, iter:112507] Loss: 1.392, 10.333, 65.599, 430.738, 1.398
Epoch: [143][700/782]	Time 0.085 (0.078)	Data 0.002 (0.003)	Loss 13.5793 (13.4384)	Acc@1 70.312 (63.338)	Acc@5 89.062 (89.767)
[epoch:144, iter:112527] Loss: 1.392, 10.336, 65.632, 430.827, 1.330
[epoch:144, iter:112547] Loss: 1.393, 10.338, 65.658, 430.936, 1.363
[epoch:144, iter:112567] Loss: 1.393, 10.343, 65.659, 430.971, 0.811
[epoch:144, iter:112587] Loss: 1.392, 10.339, 65.658, 430.902, 1.229
[epoch:144, iter:112607] Loss: 1.392, 10.343, 65.644, 430.935, 1.543
 * Acc@1 63.268 Acc@5 89.762
epoch 143, total time 60.62
Test: [0/313]	Time 0.206 (0.206)	Loss 1.4263 (1.4263)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.9152 (1.9168)	Acc@1 56.250 (55.600)	Acc@5 87.500 (84.499)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.1371 (1.8975)	Acc@1 71.875 (56.032)	Acc@5 90.625 (84.499)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.2800 (1.8940)	Acc@1 37.500 (56.084)	Acc@5 78.125 (84.541)
 * Acc@1 56.190 Acc@5 84.630
==> training...
Epoch: [144][0/782]	Time 0.511 (0.511)	Data 0.447 (0.447)	Loss 13.3565 (13.3565)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
[epoch:145, iter:112609] Loss: 1.350, 10.392, 63.656, 430.226, 1.427
[epoch:145, iter:112629] Loss: 1.407, 10.374, 66.130, 434.901, 1.585
[epoch:145, iter:112649] Loss: 1.403, 10.343, 65.766, 433.036, 0.932
[epoch:145, iter:112669] Loss: 1.406, 10.322, 65.652, 431.558, 1.382
[epoch:145, iter:112689] Loss: 1.398, 10.315, 65.532, 430.846, 0.981
Epoch: [144][100/782]	Time 0.077 (0.084)	Data 0.002 (0.007)	Loss 13.7869 (13.3591)	Acc@1 60.938 (63.800)	Acc@5 89.062 (89.619)
[epoch:145, iter:112709] Loss: 1.391, 10.302, 65.236, 430.061, 1.444
[epoch:145, iter:112729] Loss: 1.389, 10.297, 65.120, 429.619, 1.113
[epoch:145, iter:112749] Loss: 1.390, 10.300, 65.224, 429.915, 0.934
[epoch:145, iter:112769] Loss: 1.396, 10.302, 65.348, 430.293, 1.590
[epoch:145, iter:112789] Loss: 1.398, 10.327, 65.454, 430.494, 0.833
Epoch: [144][200/782]	Time 0.083 (0.083)	Data 0.003 (0.005)	Loss 12.2190 (13.3927)	Acc@1 65.625 (63.658)	Acc@5 95.312 (89.607)
[epoch:145, iter:112809] Loss: 1.397, 10.338, 65.413, 430.588, 1.059
[epoch:145, iter:112829] Loss: 1.398, 10.335, 65.426, 430.455, 0.819
[epoch:145, iter:112849] Loss: 1.398, 10.343, 65.484, 430.614, 1.534
[epoch:145, iter:112869] Loss: 1.399, 10.339, 65.507, 430.813, 1.296
[epoch:145, iter:112889] Loss: 1.399, 10.346, 65.510, 430.898, 0.902
Epoch: [144][300/782]	Time 0.072 (0.081)	Data 0.002 (0.004)	Loss 13.5430 (13.4165)	Acc@1 53.125 (63.471)	Acc@5 87.500 (89.670)
[epoch:145, iter:112909] Loss: 1.399, 10.350, 65.519, 430.948, 1.626
[epoch:145, iter:112929] Loss: 1.400, 10.342, 65.521, 431.018, 1.238
[epoch:145, iter:112949] Loss: 1.401, 10.343, 65.510, 430.958, 1.342
[epoch:145, iter:112969] Loss: 1.401, 10.340, 65.503, 431.003, 1.695
[epoch:145, iter:112989] Loss: 1.401, 10.333, 65.501, 431.046, 1.537
Epoch: [144][400/782]	Time 0.090 (0.080)	Data 0.003 (0.004)	Loss 13.3938 (13.4042)	Acc@1 64.062 (63.583)	Acc@5 89.062 (89.779)
[epoch:145, iter:113009] Loss: 1.399, 10.324, 65.479, 430.933, 1.398
[epoch:145, iter:113029] Loss: 1.399, 10.320, 65.461, 430.898, 1.299
[epoch:145, iter:113049] Loss: 1.399, 10.324, 65.484, 430.884, 1.152
[epoch:145, iter:113069] Loss: 1.398, 10.322, 65.483, 430.792, 1.328
[epoch:145, iter:113089] Loss: 1.397, 10.323, 65.464, 430.680, 1.732
Epoch: [144][500/782]	Time 0.090 (0.079)	Data 0.003 (0.003)	Loss 13.5383 (13.3935)	Acc@1 65.625 (63.632)	Acc@5 92.188 (89.880)
[epoch:145, iter:113109] Loss: 1.398, 10.328, 65.482, 430.790, 1.117
[epoch:145, iter:113129] Loss: 1.399, 10.332, 65.526, 430.975, 1.591
[epoch:145, iter:113149] Loss: 1.399, 10.338, 65.538, 430.986, 1.024
[epoch:145, iter:113169] Loss: 1.399, 10.337, 65.546, 430.964, 1.227
[epoch:145, iter:113189] Loss: 1.399, 10.338, 65.545, 430.956, 1.406
Epoch: [144][600/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 13.6552 (13.4092)	Acc@1 56.250 (63.465)	Acc@5 93.750 (89.861)
[epoch:145, iter:113209] Loss: 1.399, 10.337, 65.543, 430.954, 1.363
[epoch:145, iter:113229] Loss: 1.399, 10.339, 65.566, 431.081, 1.575
[epoch:145, iter:113249] Loss: 1.400, 10.346, 65.577, 431.164, 1.366
[epoch:145, iter:113269] Loss: 1.401, 10.347, 65.607, 431.325, 1.334
[epoch:145, iter:113289] Loss: 1.401, 10.349, 65.641, 431.396, 1.266
Epoch: [144][700/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 14.2876 (13.4509)	Acc@1 64.062 (63.305)	Acc@5 92.188 (89.852)
[epoch:145, iter:113309] Loss: 1.401, 10.350, 65.674, 431.384, 1.241
[epoch:145, iter:113329] Loss: 1.401, 10.354, 65.694, 431.426, 0.873
[epoch:145, iter:113349] Loss: 1.400, 10.356, 65.675, 431.514, 1.572
[epoch:145, iter:113369] Loss: 1.400, 10.355, 65.651, 431.445, 1.166
[epoch:145, iter:113389] Loss: 1.400, 10.351, 65.638, 431.351, 1.766
 * Acc@1 63.198 Acc@5 89.804
epoch 144, total time 61.05
Test: [0/313]	Time 0.247 (0.247)	Loss 1.7857 (1.7857)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.8037 (1.8597)	Acc@1 59.375 (57.735)	Acc@5 87.500 (84.870)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.3192 (1.8291)	Acc@1 75.000 (57.416)	Acc@5 90.625 (85.090)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.5196 (1.8539)	Acc@1 56.250 (57.143)	Acc@5 78.125 (85.143)
 * Acc@1 57.220 Acc@5 85.190
==> training...
Epoch: [145][0/782]	Time 0.544 (0.544)	Data 0.476 (0.476)	Loss 13.0687 (13.0687)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
[epoch:146, iter:113391] Loss: 1.388, 10.886, 66.358, 432.657, 1.070
[epoch:146, iter:113411] Loss: 1.382, 10.374, 65.657, 432.224, 1.303
[epoch:146, iter:113431] Loss: 1.383, 10.356, 65.503, 432.022, 1.066
[epoch:146, iter:113451] Loss: 1.389, 10.353, 65.549, 432.018, 1.531
[epoch:146, iter:113471] Loss: 1.389, 10.346, 65.319, 430.796, 1.105
Epoch: [145][100/782]	Time 0.092 (0.084)	Data 0.002 (0.007)	Loss 13.9014 (13.4443)	Acc@1 59.375 (63.521)	Acc@5 85.938 (89.913)
[epoch:146, iter:113491] Loss: 1.389, 10.360, 65.338, 430.822, 1.629
[epoch:146, iter:113511] Loss: 1.390, 10.347, 65.292, 430.200, 1.113
[epoch:146, iter:113531] Loss: 1.388, 10.341, 65.234, 430.101, 1.270
[epoch:146, iter:113551] Loss: 1.393, 10.338, 65.218, 429.844, 1.260
[epoch:146, iter:113571] Loss: 1.393, 10.347, 65.298, 430.229, 0.963
Epoch: [145][200/782]	Time 0.063 (0.081)	Data 0.002 (0.005)	Loss 13.1874 (13.3760)	Acc@1 54.688 (63.845)	Acc@5 89.062 (90.283)
[epoch:146, iter:113591] Loss: 1.394, 10.352, 65.270, 430.261, 1.677
[epoch:146, iter:113611] Loss: 1.394, 10.344, 65.325, 430.392, 1.584
[epoch:146, iter:113631] Loss: 1.394, 10.341, 65.287, 430.216, 1.170
[epoch:146, iter:113651] Loss: 1.394, 10.338, 65.321, 430.320, 1.362
[epoch:146, iter:113671] Loss: 1.394, 10.339, 65.362, 430.409, 1.136
Epoch: [145][300/782]	Time 0.086 (0.080)	Data 0.002 (0.004)	Loss 12.9265 (13.4020)	Acc@1 68.750 (63.559)	Acc@5 92.188 (90.033)
[epoch:146, iter:113691] Loss: 1.394, 10.338, 65.356, 430.598, 1.219
[epoch:146, iter:113711] Loss: 1.393, 10.332, 65.340, 430.563, 1.498
[epoch:146, iter:113731] Loss: 1.393, 10.331, 65.321, 430.424, 1.327
[epoch:146, iter:113751] Loss: 1.393, 10.338, 65.354, 430.508, 1.672
[epoch:146, iter:113771] Loss: 1.395, 10.340, 65.344, 430.488, 0.837
Epoch: [145][400/782]	Time 0.089 (0.079)	Data 0.003 (0.003)	Loss 14.5915 (13.3980)	Acc@1 62.500 (63.661)	Acc@5 89.062 (89.830)
[epoch:146, iter:113791] Loss: 1.394, 10.344, 65.341, 430.557, 1.524
[epoch:146, iter:113811] Loss: 1.392, 10.350, 65.335, 430.672, 1.404
[epoch:146, iter:113831] Loss: 1.393, 10.355, 65.382, 430.770, 1.315
[epoch:146, iter:113851] Loss: 1.393, 10.350, 65.396, 430.863, 1.468
[epoch:146, iter:113871] Loss: 1.392, 10.344, 65.404, 430.824, 0.939
Epoch: [145][500/782]	Time 0.072 (0.078)	Data 0.002 (0.003)	Loss 13.0921 (13.3987)	Acc@1 64.062 (63.638)	Acc@5 85.938 (89.805)
[epoch:146, iter:113891] Loss: 1.392, 10.344, 65.397, 430.812, 1.486
[epoch:146, iter:113911] Loss: 1.392, 10.345, 65.408, 430.840, 1.169
[epoch:146, iter:113931] Loss: 1.392, 10.346, 65.442, 430.960, 1.786
[epoch:146, iter:113951] Loss: 1.391, 10.346, 65.410, 430.870, 1.526
[epoch:146, iter:113971] Loss: 1.390, 10.340, 65.414, 430.819, 1.538
Epoch: [145][600/782]	Time 0.075 (0.079)	Data 0.002 (0.003)	Loss 14.0238 (13.4048)	Acc@1 59.375 (63.478)	Acc@5 89.062 (89.715)
[epoch:146, iter:113991] Loss: 1.391, 10.340, 65.425, 430.827, 1.256
[epoch:146, iter:114011] Loss: 1.392, 10.338, 65.412, 430.799, 1.592
[epoch:146, iter:114031] Loss: 1.391, 10.334, 65.419, 430.793, 1.449
[epoch:146, iter:114051] Loss: 1.391, 10.334, 65.418, 430.820, 1.286
[epoch:146, iter:114071] Loss: 1.391, 10.333, 65.398, 430.819, 1.310
Epoch: [145][700/782]	Time 0.094 (0.079)	Data 0.002 (0.003)	Loss 14.2784 (13.3946)	Acc@1 65.625 (63.539)	Acc@5 85.938 (89.818)
[epoch:146, iter:114091] Loss: 1.392, 10.334, 65.407, 430.859, 1.372
[epoch:146, iter:114111] Loss: 1.393, 10.336, 65.438, 430.941, 1.186
[epoch:146, iter:114131] Loss: 1.393, 10.337, 65.431, 430.865, 1.717
[epoch:146, iter:114151] Loss: 1.393, 10.338, 65.428, 430.861, 1.443
[epoch:146, iter:114171] Loss: 1.394, 10.340, 65.449, 430.946, 0.953
 * Acc@1 63.418 Acc@5 89.814
epoch 145, total time 61.47
Test: [0/313]	Time 0.229 (0.229)	Loss 2.0046 (2.0046)	Acc@1 68.750 (68.750)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.4926 (2.2967)	Acc@1 37.500 (51.485)	Acc@5 81.250 (81.281)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.7302 (2.2895)	Acc@1 59.375 (51.788)	Acc@5 90.625 (81.328)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.1198 (2.2910)	Acc@1 50.000 (51.941)	Acc@5 71.875 (81.343)
 * Acc@1 51.920 Acc@5 81.250
==> training...
Epoch: [146][0/782]	Time 0.562 (0.562)	Data 0.467 (0.467)	Loss 13.3019 (13.3019)	Acc@1 67.188 (67.188)	Acc@5 89.062 (89.062)
[epoch:147, iter:114173] Loss: 1.397, 10.193, 65.920, 429.502, 1.396
[epoch:147, iter:114193] Loss: 1.405, 10.389, 66.043, 432.614, 0.877
[epoch:147, iter:114213] Loss: 1.403, 10.422, 65.733, 432.195, 0.989
[epoch:147, iter:114233] Loss: 1.404, 10.400, 65.361, 430.766, 1.384
[epoch:147, iter:114253] Loss: 1.404, 10.411, 65.425, 431.336, 1.383
Epoch: [146][100/782]	Time 0.088 (0.079)	Data 0.003 (0.007)	Loss 13.1993 (13.4061)	Acc@1 68.750 (64.109)	Acc@5 93.750 (90.424)
[epoch:147, iter:114273] Loss: 1.404, 10.399, 65.362, 431.365, 1.187
[epoch:147, iter:114293] Loss: 1.400, 10.373, 65.306, 431.164, 1.237
[epoch:147, iter:114313] Loss: 1.399, 10.378, 65.363, 431.628, 1.546
[epoch:147, iter:114333] Loss: 1.405, 10.394, 65.392, 431.898, 1.431
[epoch:147, iter:114353] Loss: 1.405, 10.388, 65.451, 431.844, 1.486
Epoch: [146][200/782]	Time 0.076 (0.080)	Data 0.002 (0.005)	Loss 14.0932 (13.4754)	Acc@1 56.250 (63.184)	Acc@5 82.812 (89.848)
[epoch:147, iter:114373] Loss: 1.406, 10.389, 65.553, 432.248, 1.890
[epoch:147, iter:114393] Loss: 1.405, 10.392, 65.561, 432.196, 1.516
[epoch:147, iter:114413] Loss: 1.404, 10.386, 65.528, 431.883, 0.933
[epoch:147, iter:114433] Loss: 1.401, 10.377, 65.441, 431.364, 1.978
[epoch:147, iter:114453] Loss: 1.399, 10.371, 65.377, 431.184, 1.004
Epoch: [146][300/782]	Time 0.067 (0.079)	Data 0.002 (0.004)	Loss 13.1039 (13.4262)	Acc@1 65.625 (63.559)	Acc@5 93.750 (90.205)
[epoch:147, iter:114473] Loss: 1.401, 10.366, 65.477, 431.424, 1.074
[epoch:147, iter:114493] Loss: 1.400, 10.367, 65.530, 431.521, 1.543
[epoch:147, iter:114513] Loss: 1.401, 10.369, 65.580, 431.518, 1.435
[epoch:147, iter:114533] Loss: 1.403, 10.366, 65.617, 431.516, 1.405
[epoch:147, iter:114553] Loss: 1.403, 10.376, 65.636, 431.617, 1.487
Epoch: [146][400/782]	Time 0.081 (0.079)	Data 0.003 (0.003)	Loss 13.5556 (13.4746)	Acc@1 65.625 (63.275)	Acc@5 85.938 (90.021)
[epoch:147, iter:114573] Loss: 1.403, 10.375, 65.649, 431.780, 1.402
[epoch:147, iter:114593] Loss: 1.403, 10.377, 65.639, 431.715, 1.192
[epoch:147, iter:114613] Loss: 1.402, 10.368, 65.586, 431.489, 1.639
[epoch:147, iter:114633] Loss: 1.401, 10.365, 65.576, 431.424, 1.259
[epoch:147, iter:114653] Loss: 1.401, 10.360, 65.531, 431.347, 1.564
Epoch: [146][500/782]	Time 0.064 (0.079)	Data 0.002 (0.003)	Loss 13.1214 (13.4378)	Acc@1 60.938 (63.342)	Acc@5 90.625 (89.995)
[epoch:147, iter:114673] Loss: 1.401, 10.354, 65.487, 431.220, 1.499
[epoch:147, iter:114693] Loss: 1.401, 10.359, 65.501, 431.279, 1.207
[epoch:147, iter:114713] Loss: 1.401, 10.360, 65.520, 431.305, 1.484
[epoch:147, iter:114733] Loss: 1.400, 10.361, 65.557, 431.351, 1.327
[epoch:147, iter:114753] Loss: 1.400, 10.361, 65.571, 431.372, 1.319
Epoch: [146][600/782]	Time 0.077 (0.078)	Data 0.003 (0.003)	Loss 13.0792 (13.4625)	Acc@1 65.625 (63.277)	Acc@5 95.312 (90.001)
[epoch:147, iter:114773] Loss: 1.400, 10.365, 65.593, 431.537, 1.287
[epoch:147, iter:114793] Loss: 1.401, 10.372, 65.636, 431.670, 1.718
[epoch:147, iter:114813] Loss: 1.401, 10.374, 65.643, 431.730, 1.068
[epoch:147, iter:114833] Loss: 1.402, 10.375, 65.655, 431.782, 1.157
[epoch:147, iter:114853] Loss: 1.403, 10.371, 65.628, 431.720, 0.989
Epoch: [146][700/782]	Time 0.083 (0.078)	Data 0.002 (0.003)	Loss 13.6952 (13.4837)	Acc@1 64.062 (63.160)	Acc@5 85.938 (89.923)
[epoch:147, iter:114873] Loss: 1.402, 10.369, 65.625, 431.735, 1.306
[epoch:147, iter:114893] Loss: 1.402, 10.367, 65.624, 431.772, 1.420
[epoch:147, iter:114913] Loss: 1.402, 10.365, 65.615, 431.708, 1.353
[epoch:147, iter:114933] Loss: 1.402, 10.363, 65.616, 431.657, 1.393
[epoch:147, iter:114953] Loss: 1.402, 10.365, 65.623, 431.644, 1.201
 * Acc@1 63.108 Acc@5 89.826
epoch 146, total time 61.28
Test: [0/313]	Time 0.268 (0.268)	Loss 1.9639 (1.9639)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 2.3337 (2.0933)	Acc@1 46.875 (54.765)	Acc@5 90.625 (85.056)
Test: [200/313]	Time 0.007 (0.009)	Loss 1.6314 (2.0449)	Acc@1 62.500 (55.006)	Acc@5 87.500 (85.246)
Test: [300/313]	Time 0.006 (0.008)	Loss 2.5983 (2.0581)	Acc@1 46.875 (54.942)	Acc@5 78.125 (85.039)
 * Acc@1 54.990 Acc@5 85.160
==> training...
Epoch: [147][0/782]	Time 0.594 (0.594)	Data 0.507 (0.507)	Loss 14.1190 (14.1190)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
[epoch:148, iter:114955] Loss: 1.466, 10.664, 69.206, 437.841, 1.421
[epoch:148, iter:114975] Loss: 1.393, 10.258, 66.126, 429.385, 1.131
[epoch:148, iter:114995] Loss: 1.380, 10.206, 65.635, 427.210, 0.907
[epoch:148, iter:115015] Loss: 1.376, 10.195, 65.588, 427.667, 1.520
[epoch:148, iter:115035] Loss: 1.377, 10.201, 65.700, 427.947, 1.381
Epoch: [147][100/782]	Time 0.093 (0.081)	Data 0.003 (0.007)	Loss 13.0094 (13.2457)	Acc@1 68.750 (64.465)	Acc@5 89.062 (90.594)
[epoch:148, iter:115055] Loss: 1.385, 10.245, 65.599, 428.121, 1.326
[epoch:148, iter:115075] Loss: 1.387, 10.253, 65.490, 428.589, 1.412
[epoch:148, iter:115095] Loss: 1.387, 10.254, 65.528, 428.750, 1.662
[epoch:148, iter:115115] Loss: 1.390, 10.257, 65.641, 429.201, 1.132
[epoch:148, iter:115135] Loss: 1.390, 10.263, 65.855, 429.446, 1.258
Epoch: [147][200/782]	Time 0.074 (0.076)	Data 0.002 (0.005)	Loss 15.0341 (13.3660)	Acc@1 51.562 (63.806)	Acc@5 87.500 (90.190)
[epoch:148, iter:115155] Loss: 1.393, 10.285, 65.921, 429.948, 1.622
[epoch:148, iter:115175] Loss: 1.395, 10.292, 65.943, 430.282, 1.312
[epoch:148, iter:115195] Loss: 1.397, 10.298, 65.873, 430.414, 1.395
[epoch:148, iter:115215] Loss: 1.395, 10.291, 65.743, 430.279, 1.546
[epoch:148, iter:115235] Loss: 1.394, 10.292, 65.757, 430.209, 1.206
Epoch: [147][300/782]	Time 0.071 (0.074)	Data 0.002 (0.004)	Loss 14.1460 (13.3443)	Acc@1 59.375 (63.590)	Acc@5 93.750 (90.298)
[epoch:148, iter:115255] Loss: 1.393, 10.292, 65.645, 429.992, 1.376
[epoch:148, iter:115275] Loss: 1.393, 10.293, 65.607, 429.883, 1.183
[epoch:148, iter:115295] Loss: 1.392, 10.298, 65.578, 429.795, 1.390
[epoch:148, iter:115315] Loss: 1.393, 10.298, 65.653, 430.123, 1.336
[epoch:148, iter:115335] Loss: 1.392, 10.304, 65.667, 430.290, 1.034
Epoch: [147][400/782]	Time 0.074 (0.075)	Data 0.002 (0.003)	Loss 13.9113 (13.3753)	Acc@1 56.250 (63.474)	Acc@5 82.812 (90.282)
[epoch:148, iter:115355] Loss: 1.393, 10.301, 65.655, 430.269, 1.619
[epoch:148, iter:115375] Loss: 1.392, 10.298, 65.608, 430.202, 1.490
[epoch:148, iter:115395] Loss: 1.392, 10.296, 65.577, 430.104, 0.793
[epoch:148, iter:115415] Loss: 1.391, 10.294, 65.577, 430.157, 1.489
[epoch:148, iter:115435] Loss: 1.390, 10.292, 65.535, 430.057, 1.092
Epoch: [147][500/782]	Time 0.085 (0.075)	Data 0.002 (0.003)	Loss 13.4998 (13.3612)	Acc@1 68.750 (63.539)	Acc@5 92.188 (90.170)
[epoch:148, iter:115455] Loss: 1.389, 10.286, 65.510, 430.031, 1.213
[epoch:148, iter:115475] Loss: 1.390, 10.288, 65.491, 430.032, 1.707
[epoch:148, iter:115495] Loss: 1.390, 10.290, 65.493, 430.144, 1.323
[epoch:148, iter:115515] Loss: 1.391, 10.289, 65.499, 430.130, 0.924
[epoch:148, iter:115535] Loss: 1.390, 10.293, 65.490, 430.119, 1.435
Epoch: [147][600/782]	Time 0.085 (0.075)	Data 0.002 (0.003)	Loss 13.2502 (13.3715)	Acc@1 68.750 (63.472)	Acc@5 95.312 (90.118)
[epoch:148, iter:115555] Loss: 1.391, 10.298, 65.480, 430.148, 1.221
[epoch:148, iter:115575] Loss: 1.392, 10.300, 65.486, 430.198, 1.155
[epoch:148, iter:115595] Loss: 1.391, 10.300, 65.488, 430.287, 1.823
[epoch:148, iter:115615] Loss: 1.392, 10.302, 65.502, 430.387, 1.029
[epoch:148, iter:115635] Loss: 1.393, 10.301, 65.496, 430.363, 1.017
Epoch: [147][700/782]	Time 0.079 (0.075)	Data 0.002 (0.003)	Loss 13.0455 (13.3907)	Acc@1 67.188 (63.467)	Acc@5 93.750 (90.005)
[epoch:148, iter:115655] Loss: 1.393, 10.299, 65.484, 430.356, 1.328
[epoch:148, iter:115675] Loss: 1.393, 10.298, 65.492, 430.440, 1.136
[epoch:148, iter:115695] Loss: 1.394, 10.303, 65.487, 430.455, 1.542
[epoch:148, iter:115715] Loss: 1.393, 10.307, 65.481, 430.504, 1.565
[epoch:148, iter:115735] Loss: 1.394, 10.311, 65.465, 430.441, 1.381
 * Acc@1 63.374 Acc@5 89.882
epoch 147, total time 58.92
Test: [0/313]	Time 0.243 (0.243)	Loss 2.6927 (2.6927)	Acc@1 43.750 (43.750)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.007 (0.009)	Loss 3.0461 (2.6065)	Acc@1 46.875 (48.175)	Acc@5 68.750 (78.403)
Test: [200/313]	Time 0.006 (0.008)	Loss 2.2005 (2.6178)	Acc@1 50.000 (47.295)	Acc@5 87.500 (78.234)
Test: [300/313]	Time 0.006 (0.007)	Loss 2.6795 (2.6348)	Acc@1 53.125 (47.280)	Acc@5 71.875 (78.021)
 * Acc@1 47.240 Acc@5 78.070
==> training...
Epoch: [148][0/782]	Time 0.474 (0.474)	Data 0.407 (0.407)	Loss 13.8249 (13.8249)	Acc@1 64.062 (64.062)	Acc@5 90.625 (90.625)
[epoch:149, iter:115737] Loss: 1.451, 10.645, 67.942, 443.645, 1.193
[epoch:149, iter:115757] Loss: 1.429, 10.464, 65.978, 433.482, 0.927
[epoch:149, iter:115777] Loss: 1.404, 10.354, 65.629, 432.049, 1.419
[epoch:149, iter:115797] Loss: 1.397, 10.309, 65.462, 430.882, 1.674
[epoch:149, iter:115817] Loss: 1.394, 10.304, 65.483, 430.751, 1.247
Epoch: [148][100/782]	Time 0.065 (0.083)	Data 0.002 (0.006)	Loss 13.0417 (13.3912)	Acc@1 68.750 (64.124)	Acc@5 90.625 (90.099)
[epoch:149, iter:115837] Loss: 1.393, 10.303, 65.450, 430.641, 1.397
[epoch:149, iter:115857] Loss: 1.396, 10.287, 65.393, 430.627, 1.221
[epoch:149, iter:115877] Loss: 1.395, 10.294, 65.274, 430.347, 1.485
[epoch:149, iter:115897] Loss: 1.397, 10.303, 65.312, 430.224, 1.009
[epoch:149, iter:115917] Loss: 1.396, 10.313, 65.367, 430.190, 1.441
Epoch: [148][200/782]	Time 0.094 (0.080)	Data 0.003 (0.004)	Loss 13.0513 (13.3771)	Acc@1 65.625 (64.016)	Acc@5 92.188 (90.127)
[epoch:149, iter:115937] Loss: 1.395, 10.321, 65.432, 430.358, 1.303
[epoch:149, iter:115957] Loss: 1.395, 10.323, 65.446, 430.391, 0.633
[epoch:149, iter:115977] Loss: 1.394, 10.327, 65.459, 430.652, 1.363
[epoch:149, iter:115997] Loss: 1.394, 10.336, 65.486, 430.617, 1.411
[epoch:149, iter:116017] Loss: 1.395, 10.344, 65.502, 430.650, 1.220
Epoch: [148][300/782]	Time 0.088 (0.080)	Data 0.004 (0.004)	Loss 12.9767 (13.3935)	Acc@1 75.000 (63.777)	Acc@5 87.500 (90.064)
[epoch:149, iter:116037] Loss: 1.395, 10.343, 65.441, 430.619, 1.079
[epoch:149, iter:116057] Loss: 1.397, 10.345, 65.544, 431.012, 0.996
[epoch:149, iter:116077] Loss: 1.395, 10.346, 65.578, 431.009, 0.986
[epoch:149, iter:116097] Loss: 1.395, 10.339, 65.583, 430.827, 1.361
[epoch:149, iter:116117] Loss: 1.395, 10.336, 65.594, 430.725, 1.361
Epoch: [148][400/782]	Time 0.066 (0.080)	Data 0.002 (0.003)	Loss 13.7681 (13.4122)	Acc@1 57.812 (63.529)	Acc@5 90.625 (89.951)
[epoch:149, iter:116137] Loss: 1.394, 10.335, 65.610, 430.619, 1.583
[epoch:149, iter:116157] Loss: 1.393, 10.333, 65.602, 430.611, 1.186
[epoch:149, iter:116177] Loss: 1.393, 10.335, 65.598, 430.703, 1.616
[epoch:149, iter:116197] Loss: 1.393, 10.331, 65.580, 430.682, 1.353
[epoch:149, iter:116217] Loss: 1.392, 10.324, 65.572, 430.620, 1.274
Epoch: [148][500/782]	Time 0.095 (0.080)	Data 0.003 (0.003)	Loss 14.0082 (13.4290)	Acc@1 60.938 (63.404)	Acc@5 93.750 (89.823)
[epoch:149, iter:116237] Loss: 1.392, 10.328, 65.583, 430.689, 1.238
[epoch:149, iter:116257] Loss: 1.394, 10.337, 65.636, 430.837, 1.339
[epoch:149, iter:116277] Loss: 1.394, 10.342, 65.636, 430.833, 1.303
[epoch:149, iter:116297] Loss: 1.395, 10.347, 65.650, 430.894, 1.515
[epoch:149, iter:116317] Loss: 1.395, 10.352, 65.669, 430.919, 1.414
Epoch: [148][600/782]	Time 0.083 (0.079)	Data 0.003 (0.003)	Loss 13.3797 (13.4435)	Acc@1 65.625 (63.410)	Acc@5 92.188 (89.910)
[epoch:149, iter:116337] Loss: 1.395, 10.351, 65.638, 430.951, 1.349
[epoch:149, iter:116357] Loss: 1.395, 10.353, 65.625, 430.957, 1.538
[epoch:149, iter:116377] Loss: 1.395, 10.356, 65.633, 431.021, 1.351
[epoch:149, iter:116397] Loss: 1.395, 10.355, 65.621, 431.017, 1.089
[epoch:149, iter:116417] Loss: 1.396, 10.355, 65.619, 431.069, 1.339
Epoch: [148][700/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 14.2003 (13.4552)	Acc@1 57.812 (63.409)	Acc@5 87.500 (89.898)
[epoch:149, iter:116437] Loss: 1.396, 10.355, 65.669, 431.190, 1.564
[epoch:149, iter:116457] Loss: 1.397, 10.355, 65.679, 431.160, 1.347
[epoch:149, iter:116477] Loss: 1.397, 10.354, 65.650, 431.039, 1.268
[epoch:149, iter:116497] Loss: 1.397, 10.351, 65.663, 431.037, 1.857
[epoch:149, iter:116517] Loss: 1.398, 10.352, 65.638, 430.971, 1.267
 * Acc@1 63.372 Acc@5 89.822
epoch 148, total time 61.25
Test: [0/313]	Time 0.250 (0.250)	Loss 2.3909 (2.3909)	Acc@1 59.375 (59.375)	Acc@5 75.000 (75.000)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.9719 (2.1414)	Acc@1 46.875 (53.156)	Acc@5 78.125 (82.054)
Test: [200/313]	Time 0.007 (0.008)	Loss 1.4257 (2.1554)	Acc@1 59.375 (52.985)	Acc@5 90.625 (81.530)
Test: [300/313]	Time 0.009 (0.007)	Loss 2.7072 (2.1575)	Acc@1 43.750 (53.426)	Acc@5 71.875 (81.260)
 * Acc@1 53.500 Acc@5 81.260
==> training...
Epoch: [149][0/782]	Time 0.529 (0.529)	Data 0.441 (0.441)	Loss 14.5232 (14.5232)	Acc@1 50.000 (50.000)	Acc@5 81.250 (81.250)
[epoch:150, iter:116519] Loss: 1.427, 10.477, 68.008, 437.665, 1.961
[epoch:150, iter:116539] Loss: 1.415, 10.555, 65.783, 432.962, 1.572
[epoch:150, iter:116559] Loss: 1.416, 10.452, 65.940, 432.990, 1.293
[epoch:150, iter:116579] Loss: 1.404, 10.367, 65.679, 431.027, 0.983
[epoch:150, iter:116599] Loss: 1.396, 10.305, 65.363, 430.108, 1.278
Epoch: [149][100/782]	Time 0.079 (0.085)	Data 0.002 (0.007)	Loss 13.2655 (13.3903)	Acc@1 71.875 (63.335)	Acc@5 92.188 (90.548)
[epoch:150, iter:116619] Loss: 1.397, 10.311, 65.412, 430.610, 1.064
[epoch:150, iter:116639] Loss: 1.395, 10.320, 65.419, 430.705, 1.489
[epoch:150, iter:116659] Loss: 1.394, 10.322, 65.489, 430.627, 1.453
[epoch:150, iter:116679] Loss: 1.393, 10.333, 65.407, 430.492, 1.506
[epoch:150, iter:116699] Loss: 1.393, 10.347, 65.427, 430.400, 1.283
Epoch: [149][200/782]	Time 0.092 (0.084)	Data 0.003 (0.005)	Loss 13.7968 (13.3564)	Acc@1 48.438 (63.923)	Acc@5 84.375 (90.353)
[epoch:150, iter:116719] Loss: 1.392, 10.345, 65.387, 429.827, 1.694
[epoch:150, iter:116739] Loss: 1.392, 10.342, 65.321, 429.808, 1.024
[epoch:150, iter:116759] Loss: 1.393, 10.339, 65.358, 429.797, 1.281
[epoch:150, iter:116779] Loss: 1.391, 10.328, 65.359, 429.825, 1.157
[epoch:150, iter:116799] Loss: 1.389, 10.326, 65.351, 429.977, 1.625
Epoch: [149][300/782]	Time 0.074 (0.083)	Data 0.002 (0.004)	Loss 14.6998 (13.3711)	Acc@1 56.250 (63.590)	Acc@5 84.375 (90.303)
[epoch:150, iter:116819] Loss: 1.388, 10.329, 65.354, 429.958, 1.698
[epoch:150, iter:116839] Loss: 1.389, 10.333, 65.342, 429.972, 1.120
[epoch:150, iter:116859] Loss: 1.389, 10.331, 65.339, 430.089, 1.208
[epoch:150, iter:116879] Loss: 1.391, 10.336, 65.360, 430.182, 1.318
[epoch:150, iter:116899] Loss: 1.391, 10.336, 65.424, 430.314, 1.232
Epoch: [149][400/782]	Time 0.089 (0.082)	Data 0.003 (0.004)	Loss 13.2520 (13.3856)	Acc@1 46.875 (63.408)	Acc@5 87.500 (90.087)
[epoch:150, iter:116919] Loss: 1.391, 10.332, 65.400, 430.155, 1.682
[epoch:150, iter:116939] Loss: 1.390, 10.327, 65.371, 430.007, 1.223
[epoch:150, iter:116959] Loss: 1.391, 10.326, 65.383, 430.016, 1.602
[epoch:150, iter:116979] Loss: 1.392, 10.326, 65.392, 430.060, 1.424
[epoch:150, iter:116999] Loss: 1.391, 10.328, 65.385, 430.057, 1.407
Epoch: [149][500/782]	Time 0.069 (0.080)	Data 0.002 (0.003)	Loss 12.8598 (13.3698)	Acc@1 57.812 (63.629)	Acc@5 89.062 (90.085)
[epoch:150, iter:117019] Loss: 1.391, 10.330, 65.364, 429.958, 1.328
[epoch:150, iter:117039] Loss: 1.392, 10.333, 65.367, 430.017, 1.207
[epoch:150, iter:117059] Loss: 1.391, 10.333, 65.419, 430.155, 1.454
[epoch:150, iter:117079] Loss: 1.391, 10.330, 65.433, 430.180, 1.280
[epoch:150, iter:117099] Loss: 1.392, 10.328, 65.453, 430.252, 1.800
Epoch: [149][600/782]	Time 0.069 (0.079)	Data 0.002 (0.003)	Loss 13.0399 (13.3950)	Acc@1 65.625 (63.498)	Acc@5 89.062 (89.944)
[epoch:150, iter:117119] Loss: 1.391, 10.329, 65.447, 430.303, 1.163
[epoch:150, iter:117139] Loss: 1.391, 10.329, 65.435, 430.323, 1.327
[epoch:150, iter:117159] Loss: 1.391, 10.331, 65.424, 430.297, 1.204
[epoch:150, iter:117179] Loss: 1.391, 10.329, 65.408, 430.209, 1.418
[epoch:150, iter:117199] Loss: 1.392, 10.330, 65.441, 430.306, 1.964
Epoch: [149][700/782]	Time 0.067 (0.078)	Data 0.002 (0.003)	Loss 13.6002 (13.4071)	Acc@1 64.062 (63.338)	Acc@5 90.625 (89.938)
[epoch:150, iter:117219] Loss: 1.393, 10.333, 65.446, 430.368, 1.487
[epoch:150, iter:117239] Loss: 1.393, 10.332, 65.460, 430.419, 1.283
[epoch:150, iter:117259] Loss: 1.393, 10.332, 65.467, 430.464, 1.837
[epoch:150, iter:117279] Loss: 1.394, 10.330, 65.469, 430.477, 1.182
[epoch:150, iter:117299] Loss: 1.394, 10.330, 65.500, 430.569, 1.463
 * Acc@1 63.204 Acc@5 89.870
epoch 149, total time 61.35
Test: [0/313]	Time 0.221 (0.221)	Loss 2.3044 (2.3044)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.7904 (2.1861)	Acc@1 50.000 (53.527)	Acc@5 90.625 (82.859)
Test: [200/313]	Time 0.010 (0.008)	Loss 1.7611 (2.1871)	Acc@1 68.750 (53.731)	Acc@5 81.250 (82.556)
Test: [300/313]	Time 0.006 (0.008)	Loss 3.1070 (2.1694)	Acc@1 46.875 (54.080)	Acc@5 75.000 (82.579)
 * Acc@1 54.190 Acc@5 82.700
==> training...
Epoch: [150][0/782]	Time 0.472 (0.472)	Data 0.404 (0.404)	Loss 13.2795 (13.2795)	Acc@1 65.625 (65.625)	Acc@5 85.938 (85.938)
[epoch:151, iter:117301] Loss: 1.412, 10.363, 68.557, 432.966, 1.231
[epoch:151, iter:117321] Loss: 1.387, 10.317, 65.695, 431.065, 0.982
[epoch:151, iter:117341] Loss: 1.380, 10.325, 65.349, 430.241, 1.547
[epoch:151, iter:117361] Loss: 1.374, 10.270, 65.057, 428.799, 1.249
[epoch:151, iter:117381] Loss: 1.376, 10.291, 65.123, 429.542, 1.212
Epoch: [150][100/782]	Time 0.067 (0.076)	Data 0.002 (0.006)	Loss 12.5254 (13.2061)	Acc@1 65.625 (64.372)	Acc@5 89.062 (90.594)
[epoch:151, iter:117401] Loss: 1.375, 10.291, 64.900, 428.761, 1.138
[epoch:151, iter:117421] Loss: 1.377, 10.277, 64.873, 428.848, 1.439
[epoch:151, iter:117441] Loss: 1.383, 10.279, 64.930, 429.388, 1.268
[epoch:151, iter:117461] Loss: 1.384, 10.268, 64.995, 429.445, 1.562
[epoch:151, iter:117481] Loss: 1.385, 10.286, 65.102, 429.694, 0.991
Epoch: [150][200/782]	Time 0.078 (0.075)	Data 0.002 (0.004)	Loss 12.8268 (13.2976)	Acc@1 54.688 (63.503)	Acc@5 87.500 (90.470)
[epoch:151, iter:117501] Loss: 1.383, 10.298, 65.144, 429.690, 1.505
[epoch:151, iter:117521] Loss: 1.384, 10.297, 65.140, 429.694, 1.115
[epoch:151, iter:117541] Loss: 1.385, 10.294, 65.200, 429.954, 1.471
[epoch:151, iter:117561] Loss: 1.383, 10.292, 65.167, 429.837, 0.980
[epoch:151, iter:117581] Loss: 1.384, 10.305, 65.176, 429.959, 1.743
Epoch: [150][300/782]	Time 0.066 (0.074)	Data 0.002 (0.004)	Loss 13.3131 (13.3133)	Acc@1 65.625 (63.767)	Acc@5 89.062 (90.412)
[epoch:151, iter:117601] Loss: 1.385, 10.297, 65.162, 429.688, 1.255
[epoch:151, iter:117621] Loss: 1.386, 10.300, 65.241, 429.663, 1.274
[epoch:151, iter:117641] Loss: 1.386, 10.302, 65.218, 429.563, 1.186
[epoch:151, iter:117661] Loss: 1.388, 10.300, 65.200, 429.565, 1.483
[epoch:151, iter:117681] Loss: 1.388, 10.303, 65.159, 429.619, 1.140
Epoch: [150][400/782]	Time 0.073 (0.073)	Data 0.003 (0.003)	Loss 12.4413 (13.3214)	Acc@1 70.312 (63.634)	Acc@5 92.188 (90.321)
[epoch:151, iter:117701] Loss: 1.389, 10.305, 65.210, 429.771, 1.009
[epoch:151, iter:117721] Loss: 1.390, 10.305, 65.217, 429.903, 1.519
[epoch:151, iter:117741] Loss: 1.390, 10.306, 65.236, 429.904, 1.124
[epoch:151, iter:117761] Loss: 1.389, 10.304, 65.231, 429.790, 1.070
[epoch:151, iter:117781] Loss: 1.388, 10.311, 65.262, 429.890, 1.548
Epoch: [150][500/782]	Time 0.082 (0.074)	Data 0.003 (0.003)	Loss 12.5557 (13.3292)	Acc@1 68.750 (63.857)	Acc@5 85.938 (90.260)
[epoch:151, iter:117801] Loss: 1.390, 10.311, 65.240, 429.726, 1.280
[epoch:151, iter:117821] Loss: 1.389, 10.312, 65.237, 429.722, 1.262
[epoch:151, iter:117841] Loss: 1.390, 10.318, 65.252, 429.825, 1.212
[epoch:151, iter:117861] Loss: 1.390, 10.319, 65.242, 429.839, 0.989
[epoch:151, iter:117881] Loss: 1.390, 10.317, 65.261, 429.951, 0.972
Epoch: [150][600/782]	Time 0.074 (0.074)	Data 0.002 (0.003)	Loss 14.4618 (13.3527)	Acc@1 48.438 (63.561)	Acc@5 82.812 (90.160)
[epoch:151, iter:117901] Loss: 1.390, 10.318, 65.271, 429.930, 2.087
[epoch:151, iter:117921] Loss: 1.391, 10.318, 65.306, 430.009, 1.280
[epoch:151, iter:117941] Loss: 1.391, 10.322, 65.318, 430.140, 1.106
[epoch:151, iter:117961] Loss: 1.391, 10.322, 65.319, 430.172, 1.772
[epoch:151, iter:117981] Loss: 1.392, 10.324, 65.332, 430.230, 1.420
Epoch: [150][700/782]	Time 0.079 (0.075)	Data 0.003 (0.003)	Loss 14.3200 (13.3974)	Acc@1 65.625 (63.380)	Acc@5 85.938 (90.037)
[epoch:151, iter:118001] Loss: 1.392, 10.328, 65.396, 430.418, 1.521
[epoch:151, iter:118021] Loss: 1.393, 10.336, 65.425, 430.517, 1.620
[epoch:151, iter:118041] Loss: 1.393, 10.338, 65.428, 430.500, 0.894
[epoch:151, iter:118061] Loss: 1.392, 10.339, 65.437, 430.479, 1.259
[epoch:151, iter:118081] Loss: 1.392, 10.338, 65.420, 430.405, 0.824
 * Acc@1 63.392 Acc@5 90.012
epoch 150, total time 59.04
Test: [0/313]	Time 0.205 (0.205)	Loss 1.8795 (1.8795)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 2.6969 (2.2256)	Acc@1 56.250 (53.094)	Acc@5 93.750 (82.890)
Test: [200/313]	Time 0.006 (0.008)	Loss 1.5983 (2.1824)	Acc@1 56.250 (52.938)	Acc@5 96.875 (83.287)
Test: [300/313]	Time 0.007 (0.007)	Loss 2.7892 (2.2004)	Acc@1 53.125 (52.834)	Acc@5 78.125 (82.870)
 * Acc@1 52.840 Acc@5 82.830
==> training...
Epoch: [151][0/782]	Time 0.619 (0.619)	Data 0.535 (0.535)	Loss 12.7079 (12.7079)	Acc@1 75.000 (75.000)	Acc@5 89.062 (89.062)
[epoch:152, iter:118083] Loss: 1.289, 10.245, 62.898, 423.520, 1.155
[epoch:152, iter:118103] Loss: 1.332, 10.071, 61.589, 421.048, 1.285
[epoch:152, iter:118123] Loss: 1.317, 9.921, 60.313, 415.751, 0.993
[epoch:152, iter:118143] Loss: 1.303, 9.849, 59.502, 412.625, 0.823
[epoch:152, iter:118163] Loss: 1.293, 9.769, 58.939, 410.212, 1.098
Epoch: [151][100/782]	Time 0.108 (0.080)	Data 0.003 (0.008)	Loss 11.7355 (11.9103)	Acc@1 73.438 (69.230)	Acc@5 93.750 (92.961)
[epoch:152, iter:118183] Loss: 1.290, 9.704, 58.744, 409.130, 0.971
[epoch:152, iter:118203] Loss: 1.284, 9.654, 58.507, 408.232, 0.623
[epoch:152, iter:118223] Loss: 1.277, 9.616, 58.298, 407.264, 1.078
[epoch:152, iter:118243] Loss: 1.273, 9.578, 58.201, 406.786, 1.566
[epoch:152, iter:118263] Loss: 1.267, 9.540, 58.025, 406.003, 0.852
Epoch: [151][200/782]	Time 0.089 (0.079)	Data 0.003 (0.005)	Loss 11.0090 (11.6819)	Acc@1 62.500 (69.916)	Acc@5 90.625 (93.097)
[epoch:152, iter:118283] Loss: 1.263, 9.509, 57.826, 405.125, 1.222
[epoch:152, iter:118303] Loss: 1.260, 9.485, 57.692, 404.465, 1.299
[epoch:152, iter:118323] Loss: 1.254, 9.460, 57.512, 403.698, 0.939
[epoch:152, iter:118343] Loss: 1.250, 9.438, 57.391, 403.121, 0.932
[epoch:152, iter:118363] Loss: 1.248, 9.423, 57.319, 402.742, 0.759
Epoch: [151][300/782]	Time 0.080 (0.076)	Data 0.003 (0.004)	Loss 10.2600 (11.4989)	Acc@1 81.250 (70.640)	Acc@5 98.438 (93.480)
[epoch:152, iter:118383] Loss: 1.245, 9.402, 57.242, 402.311, 0.555
[epoch:152, iter:118403] Loss: 1.243, 9.392, 57.175, 402.023, 0.782
[epoch:152, iter:118423] Loss: 1.240, 9.371, 57.048, 401.433, 0.741
[epoch:152, iter:118443] Loss: 1.238, 9.358, 56.976, 401.079, 0.993
[epoch:152, iter:118463] Loss: 1.236, 9.350, 56.924, 400.894, 0.881
Epoch: [151][400/782]	Time 0.081 (0.077)	Data 0.002 (0.004)	Loss 11.4315 (11.3883)	Acc@1 70.312 (71.255)	Acc@5 93.750 (93.610)
[epoch:152, iter:118483] Loss: 1.235, 9.337, 56.869, 400.559, 1.157
[epoch:152, iter:118503] Loss: 1.233, 9.318, 56.819, 400.254, 1.071
[epoch:152, iter:118523] Loss: 1.231, 9.310, 56.760, 400.015, 1.086
[epoch:152, iter:118543] Loss: 1.230, 9.299, 56.699, 399.677, 1.147
[epoch:152, iter:118563] Loss: 1.228, 9.290, 56.641, 399.357, 0.883
Epoch: [151][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 10.7469 (11.3019)	Acc@1 79.688 (71.491)	Acc@5 100.000 (93.631)
[epoch:152, iter:118583] Loss: 1.226, 9.283, 56.578, 398.987, 0.659
[epoch:152, iter:118603] Loss: 1.225, 9.274, 56.552, 398.860, 0.826
[epoch:152, iter:118623] Loss: 1.224, 9.265, 56.509, 398.656, 0.781
[epoch:152, iter:118643] Loss: 1.223, 9.256, 56.484, 398.507, 0.887
[epoch:152, iter:118663] Loss: 1.221, 9.246, 56.415, 398.176, 1.163
Epoch: [151][600/782]	Time 0.081 (0.078)	Data 0.003 (0.003)	Loss 10.4690 (11.2445)	Acc@1 73.438 (71.701)	Acc@5 96.875 (93.714)
[epoch:152, iter:118683] Loss: 1.220, 9.240, 56.383, 397.969, 0.738
[epoch:152, iter:118703] Loss: 1.219, 9.230, 56.357, 397.749, 1.281
[epoch:152, iter:118723] Loss: 1.218, 9.221, 56.317, 397.535, 1.176
[epoch:152, iter:118743] Loss: 1.217, 9.212, 56.287, 397.367, 1.134
[epoch:152, iter:118763] Loss: 1.216, 9.206, 56.274, 397.291, 0.586
Epoch: [151][700/782]	Time 0.088 (0.079)	Data 0.003 (0.003)	Loss 10.7594 (11.2032)	Acc@1 75.000 (71.835)	Acc@5 96.875 (93.730)
[epoch:152, iter:118783] Loss: 1.215, 9.198, 56.238, 397.113, 0.907
[epoch:152, iter:118803] Loss: 1.215, 9.193, 56.213, 396.986, 0.968
[epoch:152, iter:118823] Loss: 1.213, 9.187, 56.187, 396.848, 0.638
[epoch:152, iter:118843] Loss: 1.212, 9.178, 56.158, 396.695, 1.081
[epoch:152, iter:118863] Loss: 1.211, 9.171, 56.128, 396.526, 0.961
 * Acc@1 71.980 Acc@5 93.782
epoch 151, total time 61.96
Test: [0/313]	Time 0.260 (0.260)	Loss 1.4584 (1.4584)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.6253 (1.2650)	Acc@1 56.250 (68.317)	Acc@5 96.875 (91.399)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.9167 (1.2481)	Acc@1 71.875 (68.159)	Acc@5 96.875 (91.713)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.8466 (1.2624)	Acc@1 56.250 (67.940)	Acc@5 84.375 (91.507)
 * Acc@1 68.090 Acc@5 91.540
saving the best model!
==> training...
Epoch: [152][0/782]	Time 0.540 (0.540)	Data 0.458 (0.458)	Loss 10.7034 (10.7034)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
[epoch:153, iter:118865] Loss: 1.113, 8.917, 55.030, 394.036, 0.756
[epoch:153, iter:118885] Loss: 1.191, 8.916, 55.730, 393.981, 0.915
[epoch:153, iter:118905] Loss: 1.195, 8.900, 55.623, 392.133, 0.927
[epoch:153, iter:118925] Loss: 1.196, 8.905, 55.410, 391.353, 0.707
[epoch:153, iter:118945] Loss: 1.192, 8.884, 55.229, 390.602, 0.865
Epoch: [152][100/782]	Time 0.088 (0.079)	Data 0.003 (0.007)	Loss 10.5218 (10.8145)	Acc@1 78.125 (73.902)	Acc@5 95.312 (95.204)
[epoch:153, iter:118965] Loss: 1.190, 8.884, 55.273, 390.865, 0.614
[epoch:153, iter:118985] Loss: 1.187, 8.878, 55.255, 390.722, 0.706
[epoch:153, iter:119005] Loss: 1.185, 8.870, 55.232, 390.437, 0.997
[epoch:153, iter:119025] Loss: 1.184, 8.881, 55.248, 390.640, 0.840
[epoch:153, iter:119045] Loss: 1.182, 8.872, 55.192, 390.388, 0.657
Epoch: [152][200/782]	Time 0.089 (0.081)	Data 0.003 (0.005)	Loss 11.1239 (10.8124)	Acc@1 64.062 (73.912)	Acc@5 96.875 (94.807)
[epoch:153, iter:119065] Loss: 1.182, 8.870, 55.253, 390.748, 1.089
[epoch:153, iter:119085] Loss: 1.182, 8.875, 55.242, 390.564, 0.850
[epoch:153, iter:119105] Loss: 1.181, 8.872, 55.219, 390.533, 0.784
[epoch:153, iter:119125] Loss: 1.180, 8.871, 55.215, 390.512, 0.887
[epoch:153, iter:119145] Loss: 1.179, 8.870, 55.212, 390.546, 0.962
Epoch: [152][300/782]	Time 0.065 (0.078)	Data 0.002 (0.004)	Loss 10.4079 (10.8142)	Acc@1 71.875 (73.562)	Acc@5 95.312 (94.690)
[epoch:153, iter:119165] Loss: 1.180, 8.868, 55.209, 390.541, 0.822
[epoch:153, iter:119185] Loss: 1.179, 8.866, 55.175, 390.382, 0.678
[epoch:153, iter:119205] Loss: 1.178, 8.860, 55.193, 390.416, 0.768
[epoch:153, iter:119225] Loss: 1.177, 8.860, 55.158, 390.222, 0.806
[epoch:153, iter:119245] Loss: 1.176, 8.860, 55.135, 390.121, 0.771
Epoch: [152][400/782]	Time 0.067 (0.078)	Data 0.002 (0.003)	Loss 10.9552 (10.7879)	Acc@1 76.562 (73.691)	Acc@5 96.875 (94.596)
[epoch:153, iter:119265] Loss: 1.176, 8.858, 55.117, 390.051, 0.835
[epoch:153, iter:119285] Loss: 1.176, 8.857, 55.122, 390.058, 0.952
[epoch:153, iter:119305] Loss: 1.176, 8.854, 55.102, 389.975, 0.918
[epoch:153, iter:119325] Loss: 1.176, 8.851, 55.087, 389.919, 0.964
[epoch:153, iter:119345] Loss: 1.175, 8.848, 55.075, 389.859, 0.997
Epoch: [152][500/782]	Time 0.069 (0.077)	Data 0.002 (0.003)	Loss 10.6670 (10.7788)	Acc@1 75.000 (73.509)	Acc@5 93.750 (94.542)
[epoch:153, iter:119365] Loss: 1.175, 8.848, 55.063, 389.838, 0.819
[epoch:153, iter:119385] Loss: 1.176, 8.844, 55.031, 389.687, 0.851
[epoch:153, iter:119405] Loss: 1.175, 8.841, 55.005, 389.523, 1.076
[epoch:153, iter:119425] Loss: 1.175, 8.840, 54.989, 389.420, 0.855
[epoch:153, iter:119445] Loss: 1.176, 8.837, 54.986, 389.405, 1.013
Epoch: [152][600/782]	Time 0.058 (0.077)	Data 0.002 (0.003)	Loss 10.3515 (10.7640)	Acc@1 78.125 (73.479)	Acc@5 92.188 (94.496)
[epoch:153, iter:119465] Loss: 1.176, 8.836, 54.972, 389.362, 0.793
[epoch:153, iter:119485] Loss: 1.176, 8.834, 54.953, 389.228, 0.760
[epoch:153, iter:119505] Loss: 1.176, 8.831, 54.938, 389.137, 1.020
[epoch:153, iter:119525] Loss: 1.176, 8.831, 54.945, 389.169, 0.746
[epoch:153, iter:119545] Loss: 1.176, 8.828, 54.936, 389.149, 1.038
Epoch: [152][700/782]	Time 0.069 (0.078)	Data 0.003 (0.003)	Loss 10.0868 (10.7517)	Acc@1 70.312 (73.500)	Acc@5 90.625 (94.416)
[epoch:153, iter:119565] Loss: 1.176, 8.826, 54.917, 389.052, 0.924
[epoch:153, iter:119585] Loss: 1.175, 8.822, 54.888, 388.921, 0.849
[epoch:153, iter:119605] Loss: 1.175, 8.823, 54.896, 388.924, 0.752
[epoch:153, iter:119625] Loss: 1.176, 8.820, 54.891, 388.885, 0.677
[epoch:153, iter:119645] Loss: 1.176, 8.821, 54.882, 388.860, 1.032
 * Acc@1 73.644 Acc@5 94.400
epoch 152, total time 60.55
Test: [0/313]	Time 0.247 (0.247)	Loss 1.5157 (1.5157)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.7637 (1.2548)	Acc@1 50.000 (68.410)	Acc@5 93.750 (91.429)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.8499 (1.2220)	Acc@1 75.000 (68.610)	Acc@5 100.000 (91.915)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.7708 (1.2363)	Acc@1 62.500 (68.553)	Acc@5 84.375 (91.705)
 * Acc@1 68.670 Acc@5 91.780
saving the best model!
==> training...
Epoch: [153][0/782]	Time 0.508 (0.508)	Data 0.439 (0.439)	Loss 10.9251 (10.9251)	Acc@1 68.750 (68.750)	Acc@5 89.062 (89.062)
[epoch:154, iter:119647] Loss: 1.201, 8.788, 55.297, 391.496, 1.043
[epoch:154, iter:119667] Loss: 1.165, 8.725, 54.298, 386.605, 0.571
[epoch:154, iter:119687] Loss: 1.177, 8.726, 54.632, 387.589, 0.507
[epoch:154, iter:119707] Loss: 1.174, 8.718, 54.629, 387.423, 0.600
[epoch:154, iter:119727] Loss: 1.175, 8.721, 54.777, 387.945, 1.103
Epoch: [153][100/782]	Time 0.086 (0.083)	Data 0.003 (0.007)	Loss 9.8678 (10.6425)	Acc@1 75.000 (74.103)	Acc@5 96.875 (94.647)
[epoch:154, iter:119747] Loss: 1.172, 8.717, 54.637, 387.104, 0.695
[epoch:154, iter:119767] Loss: 1.170, 8.706, 54.589, 386.787, 0.888
[epoch:154, iter:119787] Loss: 1.169, 8.707, 54.573, 386.759, 1.042
[epoch:154, iter:119807] Loss: 1.172, 8.704, 54.649, 386.880, 0.739
[epoch:154, iter:119827] Loss: 1.173, 8.702, 54.626, 386.758, 0.592
Epoch: [153][200/782]	Time 0.072 (0.081)	Data 0.002 (0.004)	Loss 10.9256 (10.6242)	Acc@1 75.000 (74.557)	Acc@5 90.625 (94.831)
[epoch:154, iter:119847] Loss: 1.172, 8.707, 54.608, 386.729, 1.059
[epoch:154, iter:119867] Loss: 1.171, 8.710, 54.549, 386.632, 1.187
[epoch:154, iter:119887] Loss: 1.172, 8.711, 54.539, 386.510, 0.741
[epoch:154, iter:119907] Loss: 1.171, 8.717, 54.557, 386.625, 1.133
[epoch:154, iter:119927] Loss: 1.170, 8.720, 54.531, 386.594, 0.899
Epoch: [153][300/782]	Time 0.082 (0.080)	Data 0.003 (0.004)	Loss 10.7893 (10.6257)	Acc@1 73.438 (74.320)	Acc@5 92.188 (94.856)
[epoch:154, iter:119947] Loss: 1.172, 8.724, 54.573, 386.729, 0.970
[epoch:154, iter:119967] Loss: 1.172, 8.723, 54.572, 386.621, 0.750
[epoch:154, iter:119987] Loss: 1.173, 8.716, 54.579, 386.552, 0.657
[epoch:154, iter:120007] Loss: 1.172, 8.715, 54.576, 386.535, 0.851
[epoch:154, iter:120027] Loss: 1.172, 8.708, 54.560, 386.431, 0.713
Epoch: [153][400/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 10.6948 (10.6061)	Acc@1 75.000 (74.458)	Acc@5 93.750 (94.853)
[epoch:154, iter:120047] Loss: 1.171, 8.705, 54.535, 386.343, 0.854
[epoch:154, iter:120067] Loss: 1.171, 8.703, 54.536, 386.340, 0.749
[epoch:154, iter:120087] Loss: 1.171, 8.701, 54.536, 386.382, 0.685
[epoch:154, iter:120107] Loss: 1.170, 8.697, 54.522, 386.314, 0.981
[epoch:154, iter:120127] Loss: 1.171, 8.695, 54.523, 386.264, 0.954
Epoch: [153][500/782]	Time 0.077 (0.078)	Data 0.002 (0.003)	Loss 10.8374 (10.6054)	Acc@1 68.750 (74.398)	Acc@5 93.750 (94.848)
[epoch:154, iter:120147] Loss: 1.171, 8.698, 54.526, 386.264, 1.068
[epoch:154, iter:120167] Loss: 1.170, 8.698, 54.529, 386.288, 0.932
[epoch:154, iter:120187] Loss: 1.170, 8.696, 54.521, 386.233, 0.999
[epoch:154, iter:120207] Loss: 1.169, 8.693, 54.506, 386.180, 0.700
[epoch:154, iter:120227] Loss: 1.169, 8.694, 54.515, 386.227, 0.919
Epoch: [153][600/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 10.7131 (10.6015)	Acc@1 82.812 (74.405)	Acc@5 95.312 (94.884)
[epoch:154, iter:120247] Loss: 1.169, 8.691, 54.508, 386.197, 0.699
[epoch:154, iter:120267] Loss: 1.168, 8.692, 54.516, 386.223, 1.321
[epoch:154, iter:120287] Loss: 1.168, 8.691, 54.523, 386.300, 0.968
[epoch:154, iter:120307] Loss: 1.168, 8.692, 54.511, 386.313, 0.723
[epoch:154, iter:120327] Loss: 1.168, 8.691, 54.509, 386.313, 0.698
Epoch: [153][700/782]	Time 0.072 (0.077)	Data 0.002 (0.003)	Loss 10.7528 (10.6079)	Acc@1 68.750 (74.278)	Acc@5 95.312 (94.749)
[epoch:154, iter:120347] Loss: 1.168, 8.690, 54.504, 386.264, 0.987
[epoch:154, iter:120367] Loss: 1.168, 8.688, 54.490, 386.220, 0.796
[epoch:154, iter:120387] Loss: 1.168, 8.686, 54.487, 386.155, 1.083
[epoch:154, iter:120407] Loss: 1.168, 8.685, 54.474, 386.034, 0.621
[epoch:154, iter:120427] Loss: 1.168, 8.684, 54.482, 386.050, 0.644
 * Acc@1 74.198 Acc@5 94.776
epoch 153, total time 59.91
Test: [0/313]	Time 0.219 (0.219)	Loss 1.2655 (1.2655)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.8515 (1.2816)	Acc@1 53.125 (68.193)	Acc@5 90.625 (91.739)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.8366 (1.2476)	Acc@1 68.750 (68.688)	Acc@5 96.875 (91.651)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.8452 (1.2516)	Acc@1 62.500 (68.355)	Acc@5 87.500 (91.663)
 * Acc@1 68.500 Acc@5 91.720
==> training...
Epoch: [154][0/782]	Time 0.518 (0.518)	Data 0.451 (0.451)	Loss 10.1051 (10.1051)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
[epoch:155, iter:120429] Loss: 1.144, 8.297, 55.899, 391.745, 0.454
[epoch:155, iter:120449] Loss: 1.158, 8.562, 54.151, 384.088, 0.575
[epoch:155, iter:120469] Loss: 1.158, 8.599, 54.062, 384.060, 1.045
[epoch:155, iter:120489] Loss: 1.161, 8.637, 54.120, 384.397, 0.779
[epoch:155, iter:120509] Loss: 1.159, 8.625, 54.091, 384.276, 0.629
Epoch: [154][100/782]	Time 0.062 (0.083)	Data 0.002 (0.007)	Loss 9.6736 (10.4496)	Acc@1 82.812 (75.278)	Acc@5 98.438 (94.957)
[epoch:155, iter:120529] Loss: 1.158, 8.616, 54.048, 384.064, 0.561
[epoch:155, iter:120549] Loss: 1.158, 8.621, 53.993, 383.790, 0.722
[epoch:155, iter:120569] Loss: 1.158, 8.626, 54.039, 384.017, 0.929
[epoch:155, iter:120589] Loss: 1.159, 8.641, 54.056, 384.255, 0.994
[epoch:155, iter:120609] Loss: 1.160, 8.641, 54.074, 384.387, 0.831
Epoch: [154][200/782]	Time 0.068 (0.080)	Data 0.002 (0.005)	Loss 10.8136 (10.4966)	Acc@1 70.312 (74.969)	Acc@5 92.188 (94.869)
[epoch:155, iter:120629] Loss: 1.161, 8.631, 54.117, 384.603, 1.043
[epoch:155, iter:120649] Loss: 1.162, 8.631, 54.151, 384.756, 1.104
[epoch:155, iter:120669] Loss: 1.161, 8.632, 54.124, 384.690, 1.302
[epoch:155, iter:120689] Loss: 1.161, 8.627, 54.141, 384.801, 0.660
[epoch:155, iter:120709] Loss: 1.162, 8.624, 54.155, 384.699, 0.975
Epoch: [154][300/782]	Time 0.074 (0.080)	Data 0.002 (0.004)	Loss 11.5701 (10.5114)	Acc@1 60.938 (74.642)	Acc@5 89.062 (94.830)
[epoch:155, iter:120729] Loss: 1.162, 8.631, 54.177, 384.741, 1.326
[epoch:155, iter:120749] Loss: 1.162, 8.631, 54.166, 384.668, 0.732
[epoch:155, iter:120769] Loss: 1.162, 8.632, 54.140, 384.526, 0.799
[epoch:155, iter:120789] Loss: 1.162, 8.635, 54.149, 384.564, 0.806
[epoch:155, iter:120809] Loss: 1.162, 8.631, 54.142, 384.561, 1.132
Epoch: [154][400/782]	Time 0.092 (0.078)	Data 0.003 (0.003)	Loss 10.2312 (10.5065)	Acc@1 76.562 (74.599)	Acc@5 96.875 (94.837)
[epoch:155, iter:120829] Loss: 1.161, 8.626, 54.131, 384.463, 0.667
[epoch:155, iter:120849] Loss: 1.161, 8.622, 54.154, 384.513, 0.676
[epoch:155, iter:120869] Loss: 1.162, 8.624, 54.157, 384.531, 1.146
[epoch:155, iter:120889] Loss: 1.162, 8.623, 54.169, 384.546, 0.706
[epoch:155, iter:120909] Loss: 1.163, 8.624, 54.162, 384.499, 0.753
Epoch: [154][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 10.6075 (10.5113)	Acc@1 73.438 (74.676)	Acc@5 93.750 (94.798)
[epoch:155, iter:120929] Loss: 1.163, 8.624, 54.162, 384.553, 0.854
[epoch:155, iter:120949] Loss: 1.163, 8.624, 54.143, 384.449, 0.775
[epoch:155, iter:120969] Loss: 1.164, 8.626, 54.164, 384.525, 0.911
[epoch:155, iter:120989] Loss: 1.164, 8.622, 54.149, 384.405, 1.101
[epoch:155, iter:121009] Loss: 1.164, 8.620, 54.148, 384.336, 0.650
Epoch: [154][600/782]	Time 0.080 (0.077)	Data 0.003 (0.003)	Loss 10.1930 (10.5058)	Acc@1 78.125 (74.657)	Acc@5 93.750 (94.889)
[epoch:155, iter:121029] Loss: 1.164, 8.621, 54.159, 384.341, 0.660
[epoch:155, iter:121049] Loss: 1.165, 8.621, 54.165, 384.345, 1.014
[epoch:155, iter:121069] Loss: 1.165, 8.618, 54.166, 384.329, 1.055
[epoch:155, iter:121089] Loss: 1.165, 8.619, 54.175, 384.389, 1.297
[epoch:155, iter:121109] Loss: 1.165, 8.617, 54.175, 384.379, 0.707
Epoch: [154][700/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 9.9224 (10.5004)	Acc@1 73.438 (74.753)	Acc@5 96.875 (94.918)
[epoch:155, iter:121129] Loss: 1.165, 8.615, 54.161, 384.285, 0.699
[epoch:155, iter:121149] Loss: 1.165, 8.615, 54.159, 384.275, 0.763
[epoch:155, iter:121169] Loss: 1.165, 8.615, 54.147, 384.226, 0.951
[epoch:155, iter:121189] Loss: 1.164, 8.613, 54.131, 384.141, 0.717
[epoch:155, iter:121209] Loss: 1.164, 8.613, 54.126, 384.099, 1.128
 * Acc@1 74.734 Acc@5 94.892
epoch 154, total time 60.40
Test: [0/313]	Time 0.294 (0.294)	Loss 1.4673 (1.4673)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.7564 (1.2517)	Acc@1 50.000 (68.936)	Acc@5 96.875 (91.863)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.9150 (1.2345)	Acc@1 68.750 (68.812)	Acc@5 93.750 (91.978)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.7714 (1.2399)	Acc@1 59.375 (68.584)	Acc@5 90.625 (92.027)
 * Acc@1 68.830 Acc@5 92.090
saving the best model!
==> training...
Epoch: [155][0/782]	Time 0.558 (0.558)	Data 0.483 (0.483)	Loss 10.1470 (10.1470)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
[epoch:156, iter:121211] Loss: 1.163, 8.284, 54.052, 382.646, 0.588
[epoch:156, iter:121231] Loss: 1.158, 8.633, 54.442, 384.652, 0.869
[epoch:156, iter:121251] Loss: 1.158, 8.593, 54.153, 383.812, 0.917
[epoch:156, iter:121271] Loss: 1.156, 8.598, 54.138, 383.573, 0.811
[epoch:156, iter:121291] Loss: 1.159, 8.579, 54.074, 383.156, 0.482
Epoch: [155][100/782]	Time 0.065 (0.090)	Data 0.002 (0.007)	Loss 10.8047 (10.4218)	Acc@1 73.438 (75.897)	Acc@5 93.750 (95.142)
[epoch:156, iter:121311] Loss: 1.160, 8.572, 54.061, 383.241, 1.048
[epoch:156, iter:121331] Loss: 1.157, 8.564, 54.085, 383.189, 0.910
[epoch:156, iter:121351] Loss: 1.156, 8.561, 53.956, 382.926, 0.569
[epoch:156, iter:121371] Loss: 1.159, 8.549, 53.953, 382.817, 0.882
[epoch:156, iter:121391] Loss: 1.160, 8.560, 54.059, 383.242, 0.680
Epoch: [155][200/782]	Time 0.061 (0.084)	Data 0.002 (0.005)	Loss 10.9960 (10.4119)	Acc@1 67.188 (75.816)	Acc@5 89.062 (95.219)
[epoch:156, iter:121411] Loss: 1.160, 8.560, 54.042, 383.146, 1.085
[epoch:156, iter:121431] Loss: 1.161, 8.559, 54.078, 383.285, 1.221
[epoch:156, iter:121451] Loss: 1.160, 8.559, 54.048, 383.153, 0.801
[epoch:156, iter:121471] Loss: 1.159, 8.564, 54.031, 383.168, 0.779
[epoch:156, iter:121491] Loss: 1.159, 8.569, 54.000, 383.041, 0.646
Epoch: [155][300/782]	Time 0.076 (0.081)	Data 0.002 (0.004)	Loss 9.8582 (10.4165)	Acc@1 79.688 (75.529)	Acc@5 92.188 (94.934)
[epoch:156, iter:121511] Loss: 1.159, 8.567, 53.977, 382.975, 0.676
[epoch:156, iter:121531] Loss: 1.159, 8.568, 53.955, 382.877, 0.693
[epoch:156, iter:121551] Loss: 1.160, 8.566, 53.981, 383.049, 1.170
[epoch:156, iter:121571] Loss: 1.159, 8.563, 53.999, 383.107, 0.949
[epoch:156, iter:121591] Loss: 1.159, 8.563, 53.987, 383.080, 0.933
Epoch: [155][400/782]	Time 0.069 (0.079)	Data 0.002 (0.003)	Loss 10.9364 (10.4142)	Acc@1 64.062 (75.312)	Acc@5 93.750 (94.950)
[epoch:156, iter:121611] Loss: 1.158, 8.564, 53.961, 382.869, 1.325
[epoch:156, iter:121631] Loss: 1.158, 8.569, 53.962, 382.868, 0.649
[epoch:156, iter:121651] Loss: 1.158, 8.568, 53.955, 382.780, 1.011
[epoch:156, iter:121671] Loss: 1.159, 8.566, 53.973, 382.776, 0.794
[epoch:156, iter:121691] Loss: 1.160, 8.567, 53.991, 382.835, 1.105
Epoch: [155][500/782]	Time 0.098 (0.079)	Data 0.003 (0.003)	Loss 10.6753 (10.4237)	Acc@1 70.312 (75.193)	Acc@5 98.438 (94.948)
[epoch:156, iter:121711] Loss: 1.160, 8.564, 53.987, 382.800, 0.886
[epoch:156, iter:121731] Loss: 1.160, 8.564, 54.011, 382.841, 0.760
[epoch:156, iter:121751] Loss: 1.160, 8.565, 54.014, 382.863, 0.772
[epoch:156, iter:121771] Loss: 1.161, 8.565, 54.024, 382.963, 0.627
[epoch:156, iter:121791] Loss: 1.161, 8.564, 54.005, 382.893, 1.050
Epoch: [155][600/782]	Time 0.088 (0.079)	Data 0.003 (0.003)	Loss 10.6784 (10.4301)	Acc@1 73.438 (75.237)	Acc@5 92.188 (94.956)
[epoch:156, iter:121811] Loss: 1.160, 8.564, 54.003, 382.852, 0.902
[epoch:156, iter:121831] Loss: 1.160, 8.564, 54.008, 382.889, 1.155
[epoch:156, iter:121851] Loss: 1.160, 8.563, 54.012, 382.887, 0.908
[epoch:156, iter:121871] Loss: 1.160, 8.562, 54.010, 382.911, 0.901
[epoch:156, iter:121891] Loss: 1.160, 8.561, 54.013, 382.907, 1.066
Epoch: [155][700/782]	Time 0.060 (0.078)	Data 0.002 (0.003)	Loss 10.8119 (10.4417)	Acc@1 68.750 (75.134)	Acc@5 90.625 (94.951)
[epoch:156, iter:121911] Loss: 1.160, 8.564, 54.017, 382.920, 1.022
[epoch:156, iter:121931] Loss: 1.160, 8.564, 54.032, 382.990, 1.096
[epoch:156, iter:121951] Loss: 1.160, 8.563, 54.037, 382.993, 0.761
[epoch:156, iter:121971] Loss: 1.160, 8.562, 54.044, 383.016, 0.754
[epoch:156, iter:121991] Loss: 1.160, 8.560, 54.053, 383.005, 0.822
 * Acc@1 75.174 Acc@5 94.972
epoch 155, total time 61.20
Test: [0/313]	Time 0.263 (0.263)	Loss 1.4119 (1.4119)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.5103 (1.2481)	Acc@1 53.125 (68.410)	Acc@5 96.875 (91.955)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.6883 (1.2056)	Acc@1 81.250 (68.890)	Acc@5 93.750 (92.164)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.8438 (1.2136)	Acc@1 59.375 (68.875)	Acc@5 84.375 (92.047)
 * Acc@1 69.080 Acc@5 92.090
saving the best model!
==> training...
Epoch: [156][0/782]	Time 0.626 (0.626)	Data 0.534 (0.534)	Loss 10.1722 (10.1722)	Acc@1 73.438 (73.438)	Acc@5 96.875 (96.875)
[epoch:157, iter:121993] Loss: 1.140, 8.818, 55.171, 375.872, 0.754
[epoch:157, iter:122013] Loss: 1.160, 8.521, 54.455, 381.573, 0.824
[epoch:157, iter:122033] Loss: 1.157, 8.534, 53.978, 380.429, 0.529
[epoch:157, iter:122053] Loss: 1.153, 8.485, 53.735, 380.054, 0.778
[epoch:157, iter:122073] Loss: 1.152, 8.494, 53.788, 380.505, 0.754
Epoch: [156][100/782]	Time 0.071 (0.081)	Data 0.002 (0.007)	Loss 10.5726 (10.3335)	Acc@1 71.875 (75.634)	Acc@5 95.312 (94.926)
[epoch:157, iter:122093] Loss: 1.151, 8.485, 53.755, 380.299, 0.858
[epoch:157, iter:122113] Loss: 1.150, 8.494, 53.755, 380.506, 0.839
[epoch:157, iter:122133] Loss: 1.153, 8.498, 53.800, 380.851, 0.695
[epoch:157, iter:122153] Loss: 1.154, 8.493, 53.811, 380.876, 0.899
[epoch:157, iter:122173] Loss: 1.155, 8.496, 53.812, 380.857, 0.613
Epoch: [156][200/782]	Time 0.071 (0.076)	Data 0.002 (0.005)	Loss 10.0019 (10.3451)	Acc@1 84.375 (75.863)	Acc@5 95.312 (94.963)
[epoch:157, iter:122193] Loss: 1.155, 8.511, 53.809, 381.024, 0.605
[epoch:157, iter:122213] Loss: 1.155, 8.508, 53.765, 380.762, 0.799
[epoch:157, iter:122233] Loss: 1.155, 8.512, 53.745, 380.740, 0.942
[epoch:157, iter:122253] Loss: 1.156, 8.514, 53.742, 380.718, 1.162
[epoch:157, iter:122273] Loss: 1.156, 8.517, 53.806, 380.937, 0.863
Epoch: [156][300/782]	Time 0.064 (0.074)	Data 0.002 (0.004)	Loss 10.9148 (10.3493)	Acc@1 70.312 (75.753)	Acc@5 93.750 (95.100)
[epoch:157, iter:122293] Loss: 1.156, 8.514, 53.825, 381.055, 0.977
[epoch:157, iter:122313] Loss: 1.156, 8.515, 53.829, 381.077, 1.057
[epoch:157, iter:122333] Loss: 1.156, 8.514, 53.849, 381.166, 1.026
[epoch:157, iter:122353] Loss: 1.156, 8.516, 53.833, 381.112, 0.689
[epoch:157, iter:122373] Loss: 1.157, 8.516, 53.874, 381.367, 0.755
Epoch: [156][400/782]	Time 0.073 (0.074)	Data 0.002 (0.003)	Loss 10.4361 (10.3758)	Acc@1 76.562 (75.588)	Acc@5 93.750 (95.044)
[epoch:157, iter:122393] Loss: 1.157, 8.519, 53.896, 381.399, 0.879
[epoch:157, iter:122413] Loss: 1.158, 8.521, 53.919, 381.405, 0.653
[epoch:157, iter:122433] Loss: 1.158, 8.526, 53.916, 381.472, 1.017
[epoch:157, iter:122453] Loss: 1.158, 8.527, 53.946, 381.664, 0.865
[epoch:157, iter:122473] Loss: 1.158, 8.528, 53.947, 381.694, 0.709
Epoch: [156][500/782]	Time 0.081 (0.074)	Data 0.002 (0.003)	Loss 10.2551 (10.3876)	Acc@1 76.562 (75.527)	Acc@5 95.312 (95.051)
[epoch:157, iter:122493] Loss: 1.158, 8.527, 53.952, 381.677, 0.799
[epoch:157, iter:122513] Loss: 1.158, 8.528, 53.940, 381.654, 1.009
[epoch:157, iter:122533] Loss: 1.158, 8.530, 53.932, 381.614, 0.777
[epoch:157, iter:122553] Loss: 1.158, 8.532, 53.932, 381.666, 0.711
[epoch:157, iter:122573] Loss: 1.158, 8.531, 53.942, 381.768, 0.731
Epoch: [156][600/782]	Time 0.072 (0.074)	Data 0.002 (0.003)	Loss 10.3523 (10.3910)	Acc@1 75.000 (75.463)	Acc@5 93.750 (95.006)
[epoch:157, iter:122593] Loss: 1.158, 8.530, 53.941, 381.802, 0.829
[epoch:157, iter:122613] Loss: 1.158, 8.532, 53.962, 381.890, 0.778
[epoch:157, iter:122633] Loss: 1.158, 8.530, 53.956, 381.880, 0.890
[epoch:157, iter:122653] Loss: 1.158, 8.528, 53.952, 381.859, 0.491
[epoch:157, iter:122673] Loss: 1.158, 8.527, 53.958, 381.922, 1.197
Epoch: [156][700/782]	Time 0.076 (0.074)	Data 0.002 (0.003)	Loss 10.4769 (10.4004)	Acc@1 75.000 (75.441)	Acc@5 96.875 (94.980)
[epoch:157, iter:122693] Loss: 1.158, 8.529, 53.969, 381.992, 0.722
[epoch:157, iter:122713] Loss: 1.158, 8.528, 53.960, 381.988, 0.840
[epoch:157, iter:122733] Loss: 1.158, 8.528, 53.945, 381.929, 1.118
[epoch:157, iter:122753] Loss: 1.158, 8.527, 53.936, 381.872, 0.959
[epoch:157, iter:122773] Loss: 1.157, 8.525, 53.918, 381.795, 0.682
 * Acc@1 75.432 Acc@5 94.998
epoch 156, total time 58.59
Test: [0/313]	Time 0.242 (0.242)	Loss 1.2993 (1.2993)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.7801 (1.2382)	Acc@1 53.125 (69.307)	Acc@5 93.750 (91.399)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.6466 (1.2018)	Acc@1 75.000 (69.372)	Acc@5 100.000 (92.009)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.6704 (1.2060)	Acc@1 62.500 (69.311)	Acc@5 87.500 (92.047)
 * Acc@1 69.430 Acc@5 92.110
saving the best model!
==> training...
Epoch: [157][0/782]	Time 0.481 (0.481)	Data 0.417 (0.417)	Loss 10.8839 (10.8839)	Acc@1 68.750 (68.750)	Acc@5 89.062 (89.062)
[epoch:158, iter:122775] Loss: 1.181, 8.397, 54.564, 385.869, 1.267
[epoch:158, iter:122795] Loss: 1.153, 8.413, 53.779, 380.636, 0.552
[epoch:158, iter:122815] Loss: 1.155, 8.468, 53.482, 378.766, 0.792
[epoch:158, iter:122835] Loss: 1.155, 8.473, 53.330, 378.579, 0.762
[epoch:158, iter:122855] Loss: 1.155, 8.477, 53.531, 380.077, 0.444
Epoch: [157][100/782]	Time 0.069 (0.081)	Data 0.002 (0.007)	Loss 10.4952 (10.2861)	Acc@1 81.250 (76.222)	Acc@5 95.312 (95.374)
[epoch:158, iter:122875] Loss: 1.160, 8.479, 53.573, 379.965, 0.691
[epoch:158, iter:122895] Loss: 1.160, 8.480, 53.576, 380.007, 0.696
[epoch:158, iter:122915] Loss: 1.156, 8.471, 53.565, 380.176, 0.764
[epoch:158, iter:122935] Loss: 1.157, 8.476, 53.631, 380.356, 0.598
[epoch:158, iter:122955] Loss: 1.156, 8.473, 53.704, 380.779, 0.804
Epoch: [157][200/782]	Time 0.086 (0.078)	Data 0.003 (0.004)	Loss 9.6043 (10.2963)	Acc@1 78.125 (76.454)	Acc@5 100.000 (95.305)
[epoch:158, iter:122975] Loss: 1.156, 8.473, 53.677, 380.685, 0.617
[epoch:158, iter:122995] Loss: 1.155, 8.475, 53.688, 380.803, 0.744
[epoch:158, iter:123015] Loss: 1.156, 8.484, 53.695, 380.831, 0.709
[epoch:158, iter:123035] Loss: 1.157, 8.481, 53.724, 380.939, 0.955
[epoch:158, iter:123055] Loss: 1.157, 8.478, 53.739, 381.004, 1.003
Epoch: [157][300/782]	Time 0.068 (0.078)	Data 0.002 (0.004)	Loss 9.8472 (10.3154)	Acc@1 79.688 (75.955)	Acc@5 98.438 (95.255)
[epoch:158, iter:123075] Loss: 1.157, 8.477, 53.708, 380.915, 0.714
[epoch:158, iter:123095] Loss: 1.157, 8.484, 53.682, 380.890, 1.031
[epoch:158, iter:123115] Loss: 1.156, 8.489, 53.699, 381.046, 1.268
[epoch:158, iter:123135] Loss: 1.156, 8.488, 53.695, 381.016, 1.020
[epoch:158, iter:123155] Loss: 1.156, 8.488, 53.652, 380.732, 0.826
Epoch: [157][400/782]	Time 0.066 (0.077)	Data 0.002 (0.003)	Loss 10.4477 (10.3149)	Acc@1 75.000 (75.927)	Acc@5 92.188 (95.227)
[epoch:158, iter:123175] Loss: 1.155, 8.487, 53.652, 380.743, 0.822
[epoch:158, iter:123195] Loss: 1.156, 8.488, 53.656, 380.768, 0.947
[epoch:158, iter:123215] Loss: 1.156, 8.489, 53.657, 380.756, 0.721
[epoch:158, iter:123235] Loss: 1.157, 8.490, 53.681, 380.813, 1.046
[epoch:158, iter:123255] Loss: 1.158, 8.488, 53.677, 380.782, 0.546
Epoch: [157][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 10.1766 (10.3234)	Acc@1 76.562 (75.908)	Acc@5 95.312 (95.244)
[epoch:158, iter:123275] Loss: 1.158, 8.489, 53.672, 380.758, 0.700
[epoch:158, iter:123295] Loss: 1.158, 8.490, 53.673, 380.804, 1.008
[epoch:158, iter:123315] Loss: 1.158, 8.488, 53.669, 380.857, 0.890
[epoch:158, iter:123335] Loss: 1.158, 8.492, 53.672, 380.874, 0.655
[epoch:158, iter:123355] Loss: 1.158, 8.492, 53.695, 380.931, 0.838
Epoch: [157][600/782]	Time 0.083 (0.078)	Data 0.002 (0.003)	Loss 10.3995 (10.3302)	Acc@1 76.562 (75.809)	Acc@5 96.875 (95.281)
[epoch:158, iter:123375] Loss: 1.158, 8.493, 53.695, 380.950, 0.663
[epoch:158, iter:123395] Loss: 1.158, 8.493, 53.703, 380.969, 0.965
[epoch:158, iter:123415] Loss: 1.158, 8.497, 53.699, 380.943, 0.870
[epoch:158, iter:123435] Loss: 1.157, 8.495, 53.689, 380.930, 0.795
[epoch:158, iter:123455] Loss: 1.157, 8.495, 53.686, 380.938, 0.888
Epoch: [157][700/782]	Time 0.086 (0.078)	Data 0.003 (0.003)	Loss 10.7116 (10.3239)	Acc@1 71.875 (75.843)	Acc@5 96.875 (95.310)
[epoch:158, iter:123475] Loss: 1.157, 8.494, 53.678, 380.885, 0.945
[epoch:158, iter:123495] Loss: 1.157, 8.492, 53.674, 380.870, 0.941
[epoch:158, iter:123515] Loss: 1.157, 8.493, 53.696, 380.983, 1.483
[epoch:158, iter:123535] Loss: 1.157, 8.492, 53.692, 380.961, 0.782
[epoch:158, iter:123555] Loss: 1.157, 8.491, 53.684, 380.936, 0.628
 * Acc@1 75.664 Acc@5 95.284
epoch 157, total time 61.74
Test: [0/313]	Time 0.241 (0.241)	Loss 1.3459 (1.3459)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.6646 (1.2441)	Acc@1 53.125 (68.410)	Acc@5 96.875 (91.925)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.9129 (1.2092)	Acc@1 71.875 (69.123)	Acc@5 96.875 (92.133)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.8836 (1.2169)	Acc@1 62.500 (68.823)	Acc@5 87.500 (92.110)
 * Acc@1 68.980 Acc@5 92.190
==> training...
Epoch: [158][0/782]	Time 0.520 (0.520)	Data 0.438 (0.438)	Loss 10.4527 (10.4527)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
[epoch:159, iter:123557] Loss: 1.161, 8.659, 54.001, 384.317, 0.961
[epoch:159, iter:123577] Loss: 1.153, 8.557, 54.152, 383.116, 0.839
[epoch:159, iter:123597] Loss: 1.155, 8.526, 53.740, 381.422, 0.692
[epoch:159, iter:123617] Loss: 1.155, 8.479, 53.562, 380.096, 0.732
[epoch:159, iter:123637] Loss: 1.151, 8.476, 53.529, 380.234, 0.770
Epoch: [158][100/782]	Time 0.092 (0.078)	Data 0.002 (0.006)	Loss 9.8117 (10.2344)	Acc@1 71.875 (76.609)	Acc@5 98.438 (95.715)
[epoch:159, iter:123657] Loss: 1.151, 8.480, 53.555, 379.924, 0.711
[epoch:159, iter:123677] Loss: 1.155, 8.488, 53.645, 380.280, 0.968
[epoch:159, iter:123697] Loss: 1.155, 8.490, 53.682, 380.358, 1.012
[epoch:159, iter:123717] Loss: 1.156, 8.491, 53.678, 380.287, 0.764
[epoch:159, iter:123737] Loss: 1.157, 8.490, 53.698, 380.373, 0.989
Epoch: [158][200/782]	Time 0.075 (0.078)	Data 0.002 (0.004)	Loss 9.7404 (10.2731)	Acc@1 82.812 (76.493)	Acc@5 96.875 (95.553)
[epoch:159, iter:123757] Loss: 1.157, 8.485, 53.669, 380.264, 0.688
[epoch:159, iter:123777] Loss: 1.157, 8.483, 53.653, 380.296, 0.971
[epoch:159, iter:123797] Loss: 1.156, 8.481, 53.642, 380.271, 0.537
[epoch:159, iter:123817] Loss: 1.155, 8.479, 53.616, 380.169, 0.719
[epoch:159, iter:123837] Loss: 1.156, 8.482, 53.612, 380.242, 0.926
Epoch: [158][300/782]	Time 0.094 (0.079)	Data 0.003 (0.004)	Loss 10.3268 (10.2916)	Acc@1 81.250 (76.246)	Acc@5 96.875 (95.515)
[epoch:159, iter:123857] Loss: 1.156, 8.487, 53.651, 380.458, 0.633
[epoch:159, iter:123877] Loss: 1.156, 8.483, 53.665, 380.557, 0.614
[epoch:159, iter:123897] Loss: 1.157, 8.479, 53.703, 380.673, 0.796
[epoch:159, iter:123917] Loss: 1.157, 8.477, 53.704, 380.632, 0.852
[epoch:159, iter:123937] Loss: 1.157, 8.476, 53.696, 380.511, 1.275
Epoch: [158][400/782]	Time 0.092 (0.080)	Data 0.003 (0.003)	Loss 10.8124 (10.2927)	Acc@1 73.438 (76.220)	Acc@5 92.188 (95.488)
[epoch:159, iter:123957] Loss: 1.157, 8.483, 53.702, 380.535, 1.060
[epoch:159, iter:123977] Loss: 1.157, 8.482, 53.706, 380.557, 0.729
[epoch:159, iter:123997] Loss: 1.157, 8.486, 53.710, 380.600, 0.987
[epoch:159, iter:124017] Loss: 1.157, 8.484, 53.710, 380.604, 0.910
[epoch:159, iter:124037] Loss: 1.157, 8.483, 53.726, 380.617, 0.910
Epoch: [158][500/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 9.7672 (10.3011)	Acc@1 75.000 (76.063)	Acc@5 98.438 (95.456)
[epoch:159, iter:124057] Loss: 1.157, 8.481, 53.701, 380.464, 0.611
[epoch:159, iter:124077] Loss: 1.157, 8.479, 53.686, 380.415, 0.669
[epoch:159, iter:124097] Loss: 1.157, 8.475, 53.667, 380.347, 0.923
[epoch:159, iter:124117] Loss: 1.157, 8.476, 53.646, 380.258, 0.998
[epoch:159, iter:124137] Loss: 1.157, 8.476, 53.658, 380.354, 0.932
Epoch: [158][600/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 9.4362 (10.2988)	Acc@1 84.375 (76.006)	Acc@5 98.438 (95.401)
[epoch:159, iter:124157] Loss: 1.157, 8.474, 53.654, 380.303, 0.457
[epoch:159, iter:124177] Loss: 1.157, 8.472, 53.660, 380.277, 0.925
[epoch:159, iter:124197] Loss: 1.156, 8.473, 53.661, 380.259, 0.793
[epoch:159, iter:124217] Loss: 1.156, 8.470, 53.652, 380.203, 0.663
[epoch:159, iter:124237] Loss: 1.156, 8.469, 53.653, 380.194, 0.694
Epoch: [158][700/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 9.6644 (10.2936)	Acc@1 78.125 (75.943)	Acc@5 100.000 (95.388)
[epoch:159, iter:124257] Loss: 1.156, 8.470, 53.638, 380.110, 0.695
[epoch:159, iter:124277] Loss: 1.156, 8.469, 53.643, 380.105, 0.777
[epoch:159, iter:124297] Loss: 1.156, 8.469, 53.637, 380.100, 0.755
[epoch:159, iter:124317] Loss: 1.156, 8.469, 53.647, 380.145, 0.741
[epoch:159, iter:124337] Loss: 1.156, 8.471, 53.648, 380.139, 0.807
 * Acc@1 75.902 Acc@5 95.396
epoch 158, total time 61.19
Test: [0/313]	Time 0.257 (0.257)	Loss 1.3618 (1.3618)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.4282 (1.2303)	Acc@1 59.375 (68.905)	Acc@5 96.875 (91.615)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7003 (1.2103)	Acc@1 75.000 (68.766)	Acc@5 96.875 (91.729)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.6146 (1.2156)	Acc@1 59.375 (68.792)	Acc@5 87.500 (91.860)
 * Acc@1 68.920 Acc@5 91.900
==> training...
Epoch: [159][0/782]	Time 0.584 (0.584)	Data 0.506 (0.506)	Loss 9.9000 (9.9000)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
[epoch:160, iter:124339] Loss: 1.184, 8.320, 52.721, 371.964, 0.720
[epoch:160, iter:124359] Loss: 1.149, 8.470, 53.413, 381.047, 1.284
[epoch:160, iter:124379] Loss: 1.157, 8.456, 53.455, 380.552, 0.700
[epoch:160, iter:124399] Loss: 1.157, 8.458, 53.529, 380.876, 0.880
[epoch:160, iter:124419] Loss: 1.153, 8.458, 53.450, 380.183, 0.838
Epoch: [159][100/782]	Time 0.072 (0.084)	Data 0.002 (0.007)	Loss 10.1299 (10.2606)	Acc@1 71.875 (75.650)	Acc@5 96.875 (95.312)
[epoch:160, iter:124439] Loss: 1.150, 8.462, 53.434, 379.876, 0.940
[epoch:160, iter:124459] Loss: 1.152, 8.456, 53.436, 379.464, 0.579
[epoch:160, iter:124479] Loss: 1.151, 8.447, 53.421, 379.482, 1.194
[epoch:160, iter:124499] Loss: 1.152, 8.440, 53.424, 379.434, 0.668
[epoch:160, iter:124519] Loss: 1.152, 8.448, 53.457, 379.523, 0.737
Epoch: [159][200/782]	Time 0.088 (0.081)	Data 0.003 (0.005)	Loss 9.9914 (10.2534)	Acc@1 75.000 (75.933)	Acc@5 95.312 (95.491)
[epoch:160, iter:124539] Loss: 1.152, 8.450, 53.501, 379.655, 0.772
[epoch:160, iter:124559] Loss: 1.151, 8.446, 53.479, 379.465, 0.552
[epoch:160, iter:124579] Loss: 1.153, 8.443, 53.486, 379.424, 1.062
[epoch:160, iter:124599] Loss: 1.154, 8.440, 53.491, 379.478, 0.964
[epoch:160, iter:124619] Loss: 1.154, 8.443, 53.499, 379.535, 0.868
Epoch: [159][300/782]	Time 0.077 (0.080)	Data 0.002 (0.004)	Loss 10.0685 (10.2610)	Acc@1 82.812 (76.043)	Acc@5 95.312 (95.380)
[epoch:160, iter:124639] Loss: 1.155, 8.441, 53.501, 379.577, 0.759
[epoch:160, iter:124659] Loss: 1.155, 8.444, 53.469, 379.498, 0.828
[epoch:160, iter:124679] Loss: 1.155, 8.445, 53.520, 379.753, 0.891
[epoch:160, iter:124699] Loss: 1.155, 8.439, 53.503, 379.675, 0.755
[epoch:160, iter:124719] Loss: 1.157, 8.443, 53.546, 379.814, 0.728
Epoch: [159][400/782]	Time 0.068 (0.077)	Data 0.002 (0.004)	Loss 9.8661 (10.2773)	Acc@1 76.562 (76.087)	Acc@5 96.875 (95.398)
[epoch:160, iter:124739] Loss: 1.156, 8.446, 53.580, 379.961, 0.789
[epoch:160, iter:124759] Loss: 1.156, 8.448, 53.565, 379.890, 0.977
[epoch:160, iter:124779] Loss: 1.156, 8.447, 53.530, 379.755, 0.805
[epoch:160, iter:124799] Loss: 1.156, 8.444, 53.538, 379.736, 0.717
[epoch:160, iter:124819] Loss: 1.156, 8.444, 53.529, 379.706, 0.755
Epoch: [159][500/782]	Time 0.074 (0.078)	Data 0.002 (0.003)	Loss 10.1305 (10.2626)	Acc@1 81.250 (76.157)	Acc@5 96.875 (95.372)
[epoch:160, iter:124839] Loss: 1.156, 8.446, 53.532, 379.767, 0.697
[epoch:160, iter:124859] Loss: 1.155, 8.446, 53.515, 379.629, 0.699
[epoch:160, iter:124879] Loss: 1.154, 8.444, 53.503, 379.575, 0.680
[epoch:160, iter:124899] Loss: 1.155, 8.445, 53.512, 379.602, 0.927
[epoch:160, iter:124919] Loss: 1.154, 8.446, 53.516, 379.654, 0.829
Epoch: [159][600/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 9.5471 (10.2665)	Acc@1 76.562 (76.089)	Acc@5 93.750 (95.367)
[epoch:160, iter:124939] Loss: 1.154, 8.445, 53.516, 379.659, 0.779
[epoch:160, iter:124959] Loss: 1.154, 8.443, 53.522, 379.660, 0.681
[epoch:160, iter:124979] Loss: 1.154, 8.443, 53.528, 379.675, 0.946
[epoch:160, iter:124999] Loss: 1.155, 8.444, 53.540, 379.721, 0.580
[epoch:160, iter:125019] Loss: 1.155, 8.443, 53.556, 379.758, 0.825
Epoch: [159][700/782]	Time 0.073 (0.078)	Data 0.002 (0.003)	Loss 10.1714 (10.2793)	Acc@1 73.438 (75.927)	Acc@5 92.188 (95.373)
[epoch:160, iter:125039] Loss: 1.155, 8.444, 53.565, 379.790, 0.876
[epoch:160, iter:125059] Loss: 1.156, 8.442, 53.573, 379.793, 0.772
[epoch:160, iter:125079] Loss: 1.156, 8.444, 53.581, 379.830, 0.611
[epoch:160, iter:125099] Loss: 1.156, 8.445, 53.576, 379.822, 0.795
[epoch:160, iter:125119] Loss: 1.156, 8.446, 53.577, 379.818, 0.512
 * Acc@1 75.950 Acc@5 95.364
epoch 159, total time 60.81
Test: [0/313]	Time 0.238 (0.238)	Loss 1.4925 (1.4925)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.009 (0.010)	Loss 1.6310 (1.2224)	Acc@1 53.125 (69.276)	Acc@5 96.875 (92.296)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7064 (1.1919)	Acc@1 81.250 (69.512)	Acc@5 96.875 (92.460)
Test: [300/313]	Time 0.010 (0.008)	Loss 1.5284 (1.2047)	Acc@1 59.375 (69.279)	Acc@5 93.750 (92.421)
 * Acc@1 69.440 Acc@5 92.480
saving the best model!
==> training...
Epoch: [160][0/782]	Time 0.492 (0.492)	Data 0.414 (0.414)	Loss 10.7334 (10.7334)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
[epoch:161, iter:125121] Loss: 1.163, 8.547, 55.322, 384.747, 1.016
[epoch:161, iter:125141] Loss: 1.157, 8.495, 54.112, 380.218, 0.692
[epoch:161, iter:125161] Loss: 1.162, 8.486, 54.082, 380.411, 0.823
[epoch:161, iter:125181] Loss: 1.155, 8.495, 54.096, 380.582, 0.669
[epoch:161, iter:125201] Loss: 1.152, 8.485, 54.024, 380.199, 1.018
Epoch: [160][100/782]	Time 0.066 (0.082)	Data 0.003 (0.007)	Loss 9.8479 (10.2716)	Acc@1 70.312 (75.155)	Acc@5 96.875 (95.668)
[epoch:161, iter:125221] Loss: 1.153, 8.470, 53.859, 379.652, 0.808
[epoch:161, iter:125241] Loss: 1.152, 8.465, 53.725, 379.273, 0.734
[epoch:161, iter:125261] Loss: 1.153, 8.464, 53.577, 378.728, 0.788
[epoch:161, iter:125281] Loss: 1.152, 8.452, 53.546, 378.767, 0.964
[epoch:161, iter:125301] Loss: 1.152, 8.455, 53.616, 379.260, 0.883
Epoch: [160][200/782]	Time 0.089 (0.080)	Data 0.003 (0.004)	Loss 10.8014 (10.2495)	Acc@1 70.312 (75.661)	Acc@5 93.750 (95.616)
[epoch:161, iter:125321] Loss: 1.153, 8.455, 53.673, 379.566, 0.998
[epoch:161, iter:125341] Loss: 1.152, 8.458, 53.644, 379.582, 0.708
[epoch:161, iter:125361] Loss: 1.152, 8.454, 53.607, 379.420, 0.547
[epoch:161, iter:125381] Loss: 1.153, 8.450, 53.594, 379.307, 1.022
[epoch:161, iter:125401] Loss: 1.152, 8.449, 53.611, 379.420, 0.950
Epoch: [160][300/782]	Time 0.086 (0.080)	Data 0.003 (0.004)	Loss 11.1667 (10.2538)	Acc@1 78.125 (75.680)	Acc@5 93.750 (95.437)
[epoch:161, iter:125421] Loss: 1.152, 8.447, 53.644, 379.565, 0.932
[epoch:161, iter:125441] Loss: 1.152, 8.446, 53.629, 379.524, 0.858
[epoch:161, iter:125461] Loss: 1.152, 8.443, 53.672, 379.653, 0.624
[epoch:161, iter:125481] Loss: 1.152, 8.440, 53.627, 379.420, 0.516
[epoch:161, iter:125501] Loss: 1.152, 8.437, 53.582, 379.203, 0.894
Epoch: [160][400/782]	Time 0.084 (0.080)	Data 0.003 (0.003)	Loss 10.2812 (10.2521)	Acc@1 76.562 (75.904)	Acc@5 92.188 (95.312)
[epoch:161, iter:125521] Loss: 1.152, 8.437, 53.576, 379.128, 0.933
[epoch:161, iter:125541] Loss: 1.152, 8.437, 53.600, 379.255, 0.699
[epoch:161, iter:125561] Loss: 1.153, 8.440, 53.612, 379.283, 0.812
[epoch:161, iter:125581] Loss: 1.153, 8.441, 53.635, 379.429, 0.733
[epoch:161, iter:125601] Loss: 1.154, 8.439, 53.653, 379.504, 0.909
Epoch: [160][500/782]	Time 0.077 (0.079)	Data 0.002 (0.003)	Loss 10.4766 (10.2741)	Acc@1 76.562 (75.770)	Acc@5 95.312 (95.397)
[epoch:161, iter:125621] Loss: 1.154, 8.439, 53.642, 379.495, 0.875
[epoch:161, iter:125641] Loss: 1.154, 8.438, 53.633, 379.551, 0.831
[epoch:161, iter:125661] Loss: 1.154, 8.439, 53.633, 379.534, 0.629
[epoch:161, iter:125681] Loss: 1.154, 8.440, 53.622, 379.423, 0.830
[epoch:161, iter:125701] Loss: 1.155, 8.439, 53.618, 379.434, 0.623
Epoch: [160][600/782]	Time 0.081 (0.079)	Data 0.003 (0.003)	Loss 10.1681 (10.2660)	Acc@1 73.438 (75.910)	Acc@5 95.312 (95.396)
[epoch:161, iter:125721] Loss: 1.155, 8.438, 53.611, 379.361, 0.875
[epoch:161, iter:125741] Loss: 1.154, 8.439, 53.613, 379.391, 0.675
[epoch:161, iter:125761] Loss: 1.154, 8.435, 53.597, 379.326, 0.991
[epoch:161, iter:125781] Loss: 1.154, 8.434, 53.600, 379.331, 0.925
[epoch:161, iter:125801] Loss: 1.154, 8.437, 53.619, 379.447, 0.645
Epoch: [160][700/782]	Time 0.086 (0.078)	Data 0.002 (0.003)	Loss 9.9109 (10.2689)	Acc@1 73.438 (75.894)	Acc@5 98.438 (95.422)
[epoch:161, iter:125821] Loss: 1.154, 8.438, 53.623, 379.460, 0.703
[epoch:161, iter:125841] Loss: 1.154, 8.437, 53.612, 379.429, 0.699
[epoch:161, iter:125861] Loss: 1.153, 8.439, 53.614, 379.493, 0.868
[epoch:161, iter:125881] Loss: 1.153, 8.438, 53.612, 379.499, 0.521
[epoch:161, iter:125901] Loss: 1.153, 8.438, 53.590, 379.406, 0.638
 * Acc@1 75.906 Acc@5 95.384
epoch 160, total time 61.55
Test: [0/313]	Time 0.232 (0.232)	Loss 1.5409 (1.5409)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.4872 (1.2489)	Acc@1 56.250 (68.874)	Acc@5 96.875 (91.955)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7267 (1.2230)	Acc@1 71.875 (68.874)	Acc@5 100.000 (92.071)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.5185 (1.2263)	Acc@1 53.125 (68.906)	Acc@5 96.875 (92.130)
 * Acc@1 69.070 Acc@5 92.200
==> Saving...
==> training...
Epoch: [161][0/782]	Time 0.520 (0.520)	Data 0.446 (0.446)	Loss 9.7527 (9.7527)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
[epoch:162, iter:125903] Loss: 1.142, 8.297, 52.280, 374.152, 0.545
[epoch:162, iter:125923] Loss: 1.146, 8.392, 53.336, 378.295, 0.442
[epoch:162, iter:125943] Loss: 1.140, 8.429, 53.199, 377.843, 0.684
[epoch:162, iter:125963] Loss: 1.146, 8.442, 53.139, 377.867, 0.830
[epoch:162, iter:125983] Loss: 1.146, 8.421, 53.216, 377.890, 0.606
Epoch: [161][100/782]	Time 0.060 (0.083)	Data 0.002 (0.007)	Loss 9.4842 (10.1640)	Acc@1 78.125 (75.897)	Acc@5 95.312 (95.823)
[epoch:162, iter:126003] Loss: 1.147, 8.419, 53.221, 377.902, 0.723
[epoch:162, iter:126023] Loss: 1.146, 8.415, 53.259, 378.178, 1.095
[epoch:162, iter:126043] Loss: 1.149, 8.399, 53.271, 378.214, 0.616
[epoch:162, iter:126063] Loss: 1.148, 8.398, 53.219, 377.771, 1.229
[epoch:162, iter:126083] Loss: 1.149, 8.397, 53.291, 378.000, 0.736
Epoch: [161][200/782]	Time 0.065 (0.078)	Data 0.002 (0.005)	Loss 10.2499 (10.1749)	Acc@1 79.688 (76.384)	Acc@5 95.312 (95.872)
[epoch:162, iter:126103] Loss: 1.149, 8.395, 53.328, 378.107, 0.744
[epoch:162, iter:126123] Loss: 1.150, 8.396, 53.375, 378.369, 1.292
[epoch:162, iter:126143] Loss: 1.150, 8.393, 53.391, 378.485, 0.773
[epoch:162, iter:126163] Loss: 1.148, 8.394, 53.412, 378.583, 0.834
[epoch:162, iter:126183] Loss: 1.149, 8.398, 53.428, 378.649, 0.967
Epoch: [161][300/782]	Time 0.082 (0.078)	Data 0.003 (0.004)	Loss 9.9087 (10.2127)	Acc@1 78.125 (76.147)	Acc@5 96.875 (95.671)
[epoch:162, iter:126203] Loss: 1.149, 8.400, 53.411, 378.655, 0.636
[epoch:162, iter:126223] Loss: 1.149, 8.399, 53.448, 378.646, 1.101
[epoch:162, iter:126243] Loss: 1.149, 8.399, 53.463, 378.740, 0.757
[epoch:162, iter:126263] Loss: 1.149, 8.398, 53.491, 378.752, 0.702
[epoch:162, iter:126283] Loss: 1.150, 8.401, 53.502, 378.764, 0.717
Epoch: [161][400/782]	Time 0.065 (0.078)	Data 0.002 (0.003)	Loss 10.3529 (10.2312)	Acc@1 73.438 (76.153)	Acc@5 95.312 (95.531)
[epoch:162, iter:126303] Loss: 1.149, 8.401, 53.494, 378.773, 0.895
[epoch:162, iter:126323] Loss: 1.149, 8.400, 53.503, 378.831, 0.946
[epoch:162, iter:126343] Loss: 1.151, 8.400, 53.517, 378.853, 0.665
[epoch:162, iter:126363] Loss: 1.151, 8.399, 53.513, 378.726, 0.667
[epoch:162, iter:126383] Loss: 1.152, 8.402, 53.525, 378.767, 0.635
Epoch: [161][500/782]	Time 0.071 (0.078)	Data 0.002 (0.003)	Loss 11.0587 (10.2327)	Acc@1 73.438 (76.232)	Acc@5 90.625 (95.540)
[epoch:162, iter:126403] Loss: 1.152, 8.404, 53.522, 378.827, 1.016
[epoch:162, iter:126423] Loss: 1.151, 8.401, 53.517, 378.839, 0.642
[epoch:162, iter:126443] Loss: 1.151, 8.403, 53.504, 378.781, 0.957
[epoch:162, iter:126463] Loss: 1.151, 8.404, 53.501, 378.791, 0.913
[epoch:162, iter:126483] Loss: 1.151, 8.405, 53.485, 378.757, 0.753
Epoch: [161][600/782]	Time 0.092 (0.077)	Data 0.003 (0.003)	Loss 10.3368 (10.2306)	Acc@1 78.125 (76.331)	Acc@5 95.312 (95.510)
[epoch:162, iter:126503] Loss: 1.151, 8.403, 53.490, 378.745, 0.708
[epoch:162, iter:126523] Loss: 1.152, 8.405, 53.499, 378.801, 0.748
[epoch:162, iter:126543] Loss: 1.152, 8.403, 53.500, 378.778, 0.684
[epoch:162, iter:126563] Loss: 1.152, 8.402, 53.507, 378.816, 0.814
[epoch:162, iter:126583] Loss: 1.151, 8.402, 53.505, 378.823, 0.547
Epoch: [161][700/782]	Time 0.069 (0.078)	Data 0.002 (0.003)	Loss 10.6587 (10.2351)	Acc@1 73.438 (76.328)	Acc@5 96.875 (95.482)
[epoch:162, iter:126603] Loss: 1.152, 8.404, 53.515, 378.877, 0.869
[epoch:162, iter:126623] Loss: 1.151, 8.406, 53.506, 378.860, 0.587
[epoch:162, iter:126643] Loss: 1.151, 8.405, 53.516, 378.909, 0.668
[epoch:162, iter:126663] Loss: 1.152, 8.405, 53.521, 378.927, 0.791
[epoch:162, iter:126683] Loss: 1.152, 8.406, 53.518, 378.935, 0.795
 * Acc@1 76.234 Acc@5 95.430
epoch 161, total time 61.26
Test: [0/313]	Time 0.253 (0.253)	Loss 1.5623 (1.5623)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.010 (0.009)	Loss 1.4146 (1.2494)	Acc@1 50.000 (68.998)	Acc@5 96.875 (91.584)
Test: [200/313]	Time 0.010 (0.008)	Loss 0.7276 (1.2167)	Acc@1 78.125 (69.185)	Acc@5 96.875 (92.024)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.6800 (1.2262)	Acc@1 62.500 (68.906)	Acc@5 87.500 (91.954)
 * Acc@1 69.090 Acc@5 92.040
==> training...
Epoch: [162][0/782]	Time 0.515 (0.515)	Data 0.427 (0.427)	Loss 10.2794 (10.2794)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
[epoch:163, iter:126685] Loss: 1.193, 8.881, 55.224, 381.645, 0.541
[epoch:163, iter:126705] Loss: 1.157, 8.535, 53.248, 377.770, 0.751
[epoch:163, iter:126725] Loss: 1.158, 8.507, 53.364, 378.653, 0.785
[epoch:163, iter:126745] Loss: 1.157, 8.469, 53.465, 379.129, 0.730
[epoch:163, iter:126765] Loss: 1.157, 8.453, 53.482, 379.076, 0.637
Epoch: [162][100/782]	Time 0.062 (0.080)	Data 0.002 (0.006)	Loss 9.4738 (10.1937)	Acc@1 85.938 (77.243)	Acc@5 96.875 (95.808)
[epoch:163, iter:126785] Loss: 1.158, 8.439, 53.515, 378.893, 0.586
[epoch:163, iter:126805] Loss: 1.157, 8.434, 53.555, 378.953, 0.582
[epoch:163, iter:126825] Loss: 1.158, 8.430, 53.497, 378.669, 0.919
[epoch:163, iter:126845] Loss: 1.158, 8.432, 53.490, 378.593, 0.944
[epoch:163, iter:126865] Loss: 1.155, 8.432, 53.424, 378.314, 0.813
Epoch: [162][200/782]	Time 0.075 (0.079)	Data 0.002 (0.004)	Loss 10.3417 (10.1785)	Acc@1 75.000 (77.029)	Acc@5 100.000 (95.794)
[epoch:163, iter:126885] Loss: 1.155, 8.430, 53.482, 378.563, 0.670
[epoch:163, iter:126905] Loss: 1.154, 8.433, 53.525, 378.639, 0.435
[epoch:163, iter:126925] Loss: 1.154, 8.430, 53.478, 378.385, 0.819
[epoch:163, iter:126945] Loss: 1.153, 8.426, 53.458, 378.421, 0.964
[epoch:163, iter:126965] Loss: 1.154, 8.424, 53.434, 378.363, 0.736
Epoch: [162][300/782]	Time 0.083 (0.079)	Data 0.003 (0.004)	Loss 9.7391 (10.1600)	Acc@1 82.812 (76.915)	Acc@5 96.875 (95.759)
[epoch:163, iter:126985] Loss: 1.154, 8.417, 53.401, 378.259, 0.686
[epoch:163, iter:127005] Loss: 1.152, 8.421, 53.387, 378.287, 0.878
[epoch:163, iter:127025] Loss: 1.153, 8.418, 53.366, 378.142, 1.149
[epoch:163, iter:127045] Loss: 1.153, 8.419, 53.389, 378.244, 0.935
[epoch:163, iter:127065] Loss: 1.153, 8.419, 53.363, 378.152, 1.039
Epoch: [162][400/782]	Time 0.058 (0.078)	Data 0.002 (0.003)	Loss 9.9018 (10.1682)	Acc@1 81.250 (76.769)	Acc@5 100.000 (95.671)
[epoch:163, iter:127085] Loss: 1.154, 8.416, 53.370, 378.236, 0.500
[epoch:163, iter:127105] Loss: 1.153, 8.417, 53.361, 378.219, 0.933
[epoch:163, iter:127125] Loss: 1.154, 8.417, 53.366, 378.283, 0.971
[epoch:163, iter:127145] Loss: 1.153, 8.416, 53.360, 378.266, 0.794
[epoch:163, iter:127165] Loss: 1.154, 8.417, 53.371, 378.322, 0.344
Epoch: [162][500/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 10.2072 (10.1834)	Acc@1 79.688 (76.678)	Acc@5 96.875 (95.587)
[epoch:163, iter:127185] Loss: 1.154, 8.421, 53.390, 378.451, 0.759
[epoch:163, iter:127205] Loss: 1.154, 8.417, 53.408, 378.498, 0.821
[epoch:163, iter:127225] Loss: 1.154, 8.416, 53.418, 378.549, 0.751
[epoch:163, iter:127245] Loss: 1.154, 8.417, 53.430, 378.575, 0.838
[epoch:163, iter:127265] Loss: 1.154, 8.417, 53.424, 378.553, 0.867
Epoch: [162][600/782]	Time 0.067 (0.077)	Data 0.002 (0.003)	Loss 10.3213 (10.1919)	Acc@1 81.250 (76.594)	Acc@5 93.750 (95.617)
[epoch:163, iter:127285] Loss: 1.154, 8.417, 53.416, 378.617, 0.710
[epoch:163, iter:127305] Loss: 1.153, 8.420, 53.415, 378.646, 0.789
[epoch:163, iter:127325] Loss: 1.153, 8.418, 53.412, 378.646, 1.007
[epoch:163, iter:127345] Loss: 1.152, 8.418, 53.401, 378.637, 0.852
[epoch:163, iter:127365] Loss: 1.152, 8.416, 53.389, 378.587, 0.543
Epoch: [162][700/782]	Time 0.068 (0.077)	Data 0.002 (0.003)	Loss 10.2600 (10.1962)	Acc@1 75.000 (76.438)	Acc@5 96.875 (95.611)
[epoch:163, iter:127385] Loss: 1.152, 8.416, 53.407, 378.683, 0.876
[epoch:163, iter:127405] Loss: 1.152, 8.418, 53.414, 378.677, 0.942
[epoch:163, iter:127425] Loss: 1.153, 8.416, 53.416, 378.679, 0.609
[epoch:163, iter:127445] Loss: 1.152, 8.417, 53.416, 378.636, 0.807
[epoch:163, iter:127465] Loss: 1.152, 8.415, 53.405, 378.585, 0.669
 * Acc@1 76.446 Acc@5 95.622
epoch 162, total time 60.32
Test: [0/313]	Time 0.227 (0.227)	Loss 1.5352 (1.5352)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.010 (0.009)	Loss 1.5101 (1.2379)	Acc@1 56.250 (68.874)	Acc@5 96.875 (92.420)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7922 (1.2086)	Acc@1 71.875 (68.999)	Acc@5 96.875 (92.226)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.6993 (1.2185)	Acc@1 65.625 (68.978)	Acc@5 87.500 (92.245)
 * Acc@1 69.160 Acc@5 92.320
==> training...
Epoch: [163][0/782]	Time 0.587 (0.587)	Data 0.513 (0.513)	Loss 10.8248 (10.8248)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
[epoch:164, iter:127467] Loss: 1.205, 8.817, 56.707, 396.608, 0.856
[epoch:164, iter:127487] Loss: 1.158, 8.404, 53.241, 376.828, 0.990
[epoch:164, iter:127507] Loss: 1.151, 8.412, 53.084, 376.161, 0.623
[epoch:164, iter:127527] Loss: 1.149, 8.425, 53.091, 376.387, 0.712
[epoch:164, iter:127547] Loss: 1.152, 8.428, 53.289, 377.399, 0.712
Epoch: [163][100/782]	Time 0.071 (0.083)	Data 0.002 (0.007)	Loss 9.7425 (10.1307)	Acc@1 76.562 (76.532)	Acc@5 95.312 (95.978)
[epoch:164, iter:127567] Loss: 1.150, 8.421, 53.194, 377.189, 0.686
[epoch:164, iter:127587] Loss: 1.150, 8.417, 53.267, 377.460, 0.669
[epoch:164, iter:127607] Loss: 1.151, 8.401, 53.229, 377.406, 0.931
[epoch:164, iter:127627] Loss: 1.153, 8.401, 53.239, 377.403, 0.642
[epoch:164, iter:127647] Loss: 1.150, 8.400, 53.264, 377.637, 0.790
Epoch: [163][200/782]	Time 0.091 (0.079)	Data 0.002 (0.005)	Loss 9.7373 (10.1436)	Acc@1 84.375 (76.819)	Acc@5 95.312 (95.896)
[epoch:164, iter:127667] Loss: 1.151, 8.399, 53.250, 377.568, 0.607
[epoch:164, iter:127687] Loss: 1.149, 8.398, 53.190, 377.378, 0.712
[epoch:164, iter:127707] Loss: 1.149, 8.399, 53.202, 377.359, 1.036
[epoch:164, iter:127727] Loss: 1.150, 8.395, 53.168, 377.212, 0.654
[epoch:164, iter:127747] Loss: 1.149, 8.398, 53.154, 377.231, 0.696
Epoch: [163][300/782]	Time 0.086 (0.080)	Data 0.002 (0.004)	Loss 10.8661 (10.1312)	Acc@1 70.312 (76.900)	Acc@5 92.188 (95.811)
[epoch:164, iter:127767] Loss: 1.150, 8.394, 53.191, 377.369, 1.264
[epoch:164, iter:127787] Loss: 1.150, 8.395, 53.224, 377.539, 0.864
[epoch:164, iter:127807] Loss: 1.150, 8.393, 53.243, 377.681, 0.859
[epoch:164, iter:127827] Loss: 1.150, 8.392, 53.257, 377.745, 0.770
[epoch:164, iter:127847] Loss: 1.150, 8.393, 53.275, 377.784, 0.956
Epoch: [163][400/782]	Time 0.096 (0.078)	Data 0.003 (0.004)	Loss 10.3167 (10.1562)	Acc@1 75.000 (76.824)	Acc@5 96.875 (95.714)
[epoch:164, iter:127867] Loss: 1.150, 8.395, 53.268, 377.734, 0.788
[epoch:164, iter:127887] Loss: 1.151, 8.395, 53.289, 377.787, 0.565
[epoch:164, iter:127907] Loss: 1.152, 8.396, 53.323, 377.930, 0.819
[epoch:164, iter:127927] Loss: 1.152, 8.394, 53.312, 377.898, 1.008
[epoch:164, iter:127947] Loss: 1.152, 8.395, 53.314, 377.911, 0.774
Epoch: [163][500/782]	Time 0.082 (0.078)	Data 0.002 (0.003)	Loss 9.9513 (10.1691)	Acc@1 75.000 (76.784)	Acc@5 96.875 (95.627)
[epoch:164, iter:127967] Loss: 1.151, 8.395, 53.307, 377.874, 0.712
[epoch:164, iter:127987] Loss: 1.152, 8.396, 53.329, 377.989, 0.672
[epoch:164, iter:128007] Loss: 1.152, 8.396, 53.327, 377.934, 1.414
[epoch:164, iter:128027] Loss: 1.152, 8.396, 53.342, 378.000, 0.785
[epoch:164, iter:128047] Loss: 1.152, 8.399, 53.356, 378.101, 0.879
Epoch: [163][600/782]	Time 0.077 (0.079)	Data 0.002 (0.003)	Loss 10.3642 (10.1886)	Acc@1 70.312 (76.755)	Acc@5 96.875 (95.604)
[epoch:164, iter:128067] Loss: 1.153, 8.400, 53.379, 378.189, 0.912
[epoch:164, iter:128087] Loss: 1.152, 8.399, 53.395, 378.206, 0.811
[epoch:164, iter:128107] Loss: 1.152, 8.400, 53.400, 378.243, 0.819
[epoch:164, iter:128127] Loss: 1.152, 8.402, 53.397, 378.226, 1.036
[epoch:164, iter:128147] Loss: 1.152, 8.402, 53.412, 378.323, 0.923
Epoch: [163][700/782]	Time 0.070 (0.077)	Data 0.002 (0.003)	Loss 10.2172 (10.2019)	Acc@1 79.688 (76.585)	Acc@5 98.438 (95.529)
[epoch:164, iter:128167] Loss: 1.151, 8.398, 53.416, 378.339, 0.607
[epoch:164, iter:128187] Loss: 1.151, 8.397, 53.399, 378.276, 0.828
[epoch:164, iter:128207] Loss: 1.151, 8.397, 53.401, 378.301, 0.762
[epoch:164, iter:128227] Loss: 1.151, 8.396, 53.408, 378.314, 0.504
[epoch:164, iter:128247] Loss: 1.151, 8.397, 53.416, 378.346, 0.895
 * Acc@1 76.466 Acc@5 95.502
epoch 163, total time 60.45
Test: [0/313]	Time 0.230 (0.230)	Loss 1.3647 (1.3647)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.5223 (1.2465)	Acc@1 53.125 (69.276)	Acc@5 96.875 (91.832)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.6684 (1.2074)	Acc@1 75.000 (69.558)	Acc@5 100.000 (92.086)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.5242 (1.2124)	Acc@1 53.125 (69.487)	Acc@5 96.875 (92.110)
 * Acc@1 69.640 Acc@5 92.150
saving the best model!
==> training...
Epoch: [164][0/782]	Time 0.499 (0.499)	Data 0.433 (0.433)	Loss 9.7755 (9.7755)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
[epoch:165, iter:128249] Loss: 1.068, 8.215, 50.967, 373.099, 0.775
[epoch:165, iter:128269] Loss: 1.150, 8.412, 52.969, 376.780, 0.759
[epoch:165, iter:128289] Loss: 1.149, 8.367, 52.910, 376.036, 0.949
[epoch:165, iter:128309] Loss: 1.141, 8.368, 53.072, 376.420, 0.742
[epoch:165, iter:128329] Loss: 1.141, 8.382, 53.024, 376.536, 0.804
Epoch: [164][100/782]	Time 0.090 (0.084)	Data 0.003 (0.007)	Loss 10.0795 (10.0654)	Acc@1 71.875 (77.645)	Acc@5 100.000 (95.761)
[epoch:165, iter:128349] Loss: 1.139, 8.362, 52.926, 376.262, 0.847
[epoch:165, iter:128369] Loss: 1.141, 8.364, 52.997, 376.648, 0.901
[epoch:165, iter:128389] Loss: 1.142, 8.365, 53.001, 376.459, 0.881
[epoch:165, iter:128409] Loss: 1.145, 8.371, 53.054, 376.606, 0.899
[epoch:165, iter:128429] Loss: 1.144, 8.366, 53.080, 376.763, 0.718
Epoch: [164][200/782]	Time 0.065 (0.083)	Data 0.002 (0.005)	Loss 10.5350 (10.1186)	Acc@1 71.875 (77.208)	Acc@5 95.312 (95.631)
[epoch:165, iter:128449] Loss: 1.146, 8.371, 53.169, 377.093, 0.873
[epoch:165, iter:128469] Loss: 1.147, 8.365, 53.175, 377.141, 0.815
[epoch:165, iter:128489] Loss: 1.147, 8.368, 53.171, 377.127, 0.436
[epoch:165, iter:128509] Loss: 1.147, 8.370, 53.171, 377.141, 0.768
[epoch:165, iter:128529] Loss: 1.147, 8.366, 53.144, 376.990, 0.691
Epoch: [164][300/782]	Time 0.093 (0.079)	Data 0.003 (0.004)	Loss 10.6102 (10.1132)	Acc@1 75.000 (77.310)	Acc@5 92.188 (95.676)
[epoch:165, iter:128549] Loss: 1.148, 8.369, 53.150, 377.044, 0.926
[epoch:165, iter:128569] Loss: 1.147, 8.362, 53.146, 377.039, 0.734
[epoch:165, iter:128589] Loss: 1.147, 8.362, 53.155, 377.141, 0.913
[epoch:165, iter:128609] Loss: 1.148, 8.368, 53.181, 377.238, 0.569
[epoch:165, iter:128629] Loss: 1.149, 8.368, 53.211, 377.366, 0.995
Epoch: [164][400/782]	Time 0.090 (0.080)	Data 0.003 (0.004)	Loss 10.2774 (10.1396)	Acc@1 76.562 (77.163)	Acc@5 96.875 (95.605)
[epoch:165, iter:128649] Loss: 1.149, 8.373, 53.229, 377.480, 0.770
[epoch:165, iter:128669] Loss: 1.148, 8.374, 53.234, 377.527, 0.993
[epoch:165, iter:128689] Loss: 1.148, 8.372, 53.243, 377.612, 0.636
[epoch:165, iter:128709] Loss: 1.148, 8.373, 53.240, 377.611, 0.741
[epoch:165, iter:128729] Loss: 1.148, 8.374, 53.245, 377.606, 0.559
Epoch: [164][500/782]	Time 0.070 (0.081)	Data 0.002 (0.003)	Loss 9.7726 (10.1443)	Acc@1 78.125 (77.102)	Acc@5 96.875 (95.609)
[epoch:165, iter:128749] Loss: 1.147, 8.373, 53.241, 377.599, 0.741
[epoch:165, iter:128769] Loss: 1.148, 8.377, 53.279, 377.777, 0.552
[epoch:165, iter:128789] Loss: 1.147, 8.377, 53.288, 377.817, 1.302
[epoch:165, iter:128809] Loss: 1.147, 8.377, 53.304, 377.914, 0.698
[epoch:165, iter:128829] Loss: 1.148, 8.377, 53.317, 377.920, 0.747
Epoch: [164][600/782]	Time 0.089 (0.081)	Data 0.003 (0.003)	Loss 10.2466 (10.1747)	Acc@1 70.312 (76.763)	Acc@5 100.000 (95.484)
[epoch:165, iter:128849] Loss: 1.148, 8.379, 53.330, 378.028, 0.606
[epoch:165, iter:128869] Loss: 1.148, 8.378, 53.342, 378.085, 1.123
[epoch:165, iter:128889] Loss: 1.149, 8.377, 53.330, 377.986, 0.903
[epoch:165, iter:128909] Loss: 1.149, 8.378, 53.349, 377.988, 1.095
[epoch:165, iter:128929] Loss: 1.150, 8.376, 53.349, 377.959, 0.653
Epoch: [164][700/782]	Time 0.073 (0.080)	Data 0.002 (0.003)	Loss 10.6404 (10.1835)	Acc@1 71.875 (76.638)	Acc@5 93.750 (95.466)
[epoch:165, iter:128949] Loss: 1.150, 8.376, 53.353, 377.979, 0.846
[epoch:165, iter:128969] Loss: 1.150, 8.378, 53.353, 378.003, 0.951
[epoch:165, iter:128989] Loss: 1.150, 8.380, 53.351, 377.982, 0.873
[epoch:165, iter:129009] Loss: 1.150, 8.382, 53.367, 378.071, 0.705
[epoch:165, iter:129029] Loss: 1.150, 8.379, 53.365, 378.007, 0.594
 * Acc@1 76.534 Acc@5 95.490
epoch 164, total time 62.62
Test: [0/313]	Time 0.224 (0.224)	Loss 1.3945 (1.3945)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.5296 (1.2488)	Acc@1 59.375 (68.750)	Acc@5 96.875 (91.801)
Test: [200/313]	Time 0.005 (0.008)	Loss 0.7682 (1.2175)	Acc@1 75.000 (69.356)	Acc@5 100.000 (91.931)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.4901 (1.2199)	Acc@1 59.375 (69.217)	Acc@5 93.750 (91.933)
 * Acc@1 69.370 Acc@5 92.010
==> training...
Epoch: [165][0/782]	Time 0.562 (0.562)	Data 0.491 (0.491)	Loss 9.9307 (9.9307)	Acc@1 78.125 (78.125)	Acc@5 95.312 (95.312)
[epoch:166, iter:129031] Loss: 1.146, 8.024, 52.575, 371.878, 0.744
[epoch:166, iter:129051] Loss: 1.150, 8.317, 52.986, 375.168, 0.548
[epoch:166, iter:129071] Loss: 1.142, 8.365, 53.381, 378.076, 0.635
[epoch:166, iter:129091] Loss: 1.144, 8.378, 53.447, 378.686, 0.914
[epoch:166, iter:129111] Loss: 1.145, 8.384, 53.445, 378.261, 0.889
Epoch: [165][100/782]	Time 0.089 (0.079)	Data 0.003 (0.007)	Loss 10.2146 (10.1434)	Acc@1 84.375 (77.382)	Acc@5 96.875 (96.086)
[epoch:166, iter:129131] Loss: 1.149, 8.382, 53.445, 378.134, 0.704
[epoch:166, iter:129151] Loss: 1.150, 8.373, 53.385, 378.023, 0.437
[epoch:166, iter:129171] Loss: 1.150, 8.365, 53.290, 377.544, 0.661
[epoch:166, iter:129191] Loss: 1.150, 8.365, 53.391, 377.790, 1.075
[epoch:166, iter:129211] Loss: 1.149, 8.372, 53.312, 377.467, 0.895
Epoch: [165][200/782]	Time 0.063 (0.080)	Data 0.002 (0.005)	Loss 9.8796 (10.1450)	Acc@1 79.688 (76.835)	Acc@5 98.438 (95.818)
[epoch:166, iter:129231] Loss: 1.149, 8.376, 53.349, 377.630, 0.603
[epoch:166, iter:129251] Loss: 1.149, 8.377, 53.352, 377.744, 0.676
[epoch:166, iter:129271] Loss: 1.149, 8.382, 53.364, 377.917, 0.686
[epoch:166, iter:129291] Loss: 1.148, 8.381, 53.328, 377.790, 0.521
[epoch:166, iter:129311] Loss: 1.148, 8.378, 53.338, 377.768, 0.741
Epoch: [165][300/782]	Time 0.088 (0.078)	Data 0.002 (0.004)	Loss 10.0739 (10.1572)	Acc@1 78.125 (76.874)	Acc@5 96.875 (95.738)
[epoch:166, iter:129331] Loss: 1.148, 8.377, 53.328, 377.711, 0.739
[epoch:166, iter:129351] Loss: 1.147, 8.377, 53.309, 377.731, 0.675
[epoch:166, iter:129371] Loss: 1.147, 8.375, 53.329, 377.765, 0.834
[epoch:166, iter:129391] Loss: 1.147, 8.377, 53.345, 377.864, 0.876
[epoch:166, iter:129411] Loss: 1.147, 8.378, 53.359, 377.813, 0.814
Epoch: [165][400/782]	Time 0.069 (0.078)	Data 0.002 (0.004)	Loss 10.2678 (10.1611)	Acc@1 73.438 (76.718)	Acc@5 95.312 (95.733)
[epoch:166, iter:129431] Loss: 1.148, 8.374, 53.363, 377.733, 0.732
[epoch:166, iter:129451] Loss: 1.148, 8.373, 53.363, 377.815, 0.971
[epoch:166, iter:129471] Loss: 1.148, 8.374, 53.378, 377.845, 0.977
[epoch:166, iter:129491] Loss: 1.148, 8.378, 53.359, 377.810, 0.994
[epoch:166, iter:129511] Loss: 1.149, 8.378, 53.351, 377.857, 0.621
Epoch: [165][500/782]	Time 0.070 (0.078)	Data 0.002 (0.003)	Loss 10.5536 (10.1722)	Acc@1 75.000 (76.706)	Acc@5 96.875 (95.768)
[epoch:166, iter:129531] Loss: 1.148, 8.382, 53.352, 377.893, 0.750
[epoch:166, iter:129551] Loss: 1.148, 8.384, 53.358, 377.910, 0.784
[epoch:166, iter:129571] Loss: 1.148, 8.385, 53.384, 378.057, 0.808
[epoch:166, iter:129591] Loss: 1.149, 8.385, 53.388, 378.081, 1.086
[epoch:166, iter:129611] Loss: 1.148, 8.385, 53.392, 378.142, 0.645
Epoch: [165][600/782]	Time 0.080 (0.078)	Data 0.002 (0.003)	Loss 10.5597 (10.1904)	Acc@1 70.312 (76.591)	Acc@5 98.438 (95.663)
[epoch:166, iter:129631] Loss: 1.148, 8.384, 53.393, 378.167, 0.745
[epoch:166, iter:129651] Loss: 1.148, 8.385, 53.372, 378.098, 0.527
[epoch:166, iter:129671] Loss: 1.148, 8.384, 53.354, 378.053, 0.781
[epoch:166, iter:129691] Loss: 1.148, 8.384, 53.355, 378.047, 0.688
[epoch:166, iter:129711] Loss: 1.149, 8.382, 53.343, 377.997, 0.602
Epoch: [165][700/782]	Time 0.089 (0.078)	Data 0.003 (0.003)	Loss 10.1628 (10.1811)	Acc@1 71.875 (76.641)	Acc@5 96.875 (95.678)
[epoch:166, iter:129731] Loss: 1.148, 8.382, 53.336, 377.968, 0.867
[epoch:166, iter:129751] Loss: 1.149, 8.381, 53.353, 377.982, 0.606
[epoch:166, iter:129771] Loss: 1.149, 8.378, 53.349, 377.953, 0.944
[epoch:166, iter:129791] Loss: 1.149, 8.379, 53.355, 377.974, 0.974
[epoch:166, iter:129811] Loss: 1.150, 8.379, 53.359, 377.992, 0.685
 * Acc@1 76.576 Acc@5 95.656
epoch 165, total time 61.19
Test: [0/313]	Time 0.271 (0.271)	Loss 1.3070 (1.3070)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.4933 (1.2505)	Acc@1 50.000 (68.812)	Acc@5 93.750 (91.460)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7093 (1.2180)	Acc@1 71.875 (68.781)	Acc@5 96.875 (91.838)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4575 (1.2230)	Acc@1 59.375 (68.574)	Acc@5 93.750 (91.840)
 * Acc@1 68.690 Acc@5 91.880
==> training...
Epoch: [166][0/782]	Time 0.466 (0.466)	Data 0.391 (0.391)	Loss 10.2003 (10.2003)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
[epoch:167, iter:129813] Loss: 1.210, 8.407, 54.793, 374.501, 0.656
[epoch:167, iter:129833] Loss: 1.158, 8.403, 53.703, 379.114, 0.838
[epoch:167, iter:129853] Loss: 1.155, 8.406, 53.779, 379.767, 0.895
[epoch:167, iter:129873] Loss: 1.153, 8.413, 53.576, 379.147, 0.689
[epoch:167, iter:129893] Loss: 1.151, 8.399, 53.594, 379.001, 0.444
Epoch: [166][100/782]	Time 0.071 (0.077)	Data 0.002 (0.006)	Loss 9.4297 (10.1160)	Acc@1 81.250 (77.723)	Acc@5 95.312 (95.823)
[epoch:167, iter:129913] Loss: 1.148, 8.393, 53.471, 377.939, 0.598
[epoch:167, iter:129933] Loss: 1.146, 8.397, 53.394, 377.804, 1.025
[epoch:167, iter:129953] Loss: 1.145, 8.387, 53.304, 377.522, 0.787
[epoch:167, iter:129973] Loss: 1.144, 8.385, 53.281, 377.514, 0.884
[epoch:167, iter:129993] Loss: 1.143, 8.385, 53.273, 377.461, 0.843
Epoch: [166][200/782]	Time 0.061 (0.076)	Data 0.002 (0.004)	Loss 10.0006 (10.1121)	Acc@1 75.000 (77.099)	Acc@5 98.438 (95.701)
[epoch:167, iter:130013] Loss: 1.143, 8.386, 53.243, 377.343, 0.795
[epoch:167, iter:130033] Loss: 1.143, 8.382, 53.217, 377.235, 0.670
[epoch:167, iter:130053] Loss: 1.144, 8.381, 53.250, 377.468, 0.581
[epoch:167, iter:130073] Loss: 1.144, 8.379, 53.252, 377.544, 0.608
[epoch:167, iter:130093] Loss: 1.145, 8.382, 53.253, 377.604, 0.793
Epoch: [166][300/782]	Time 0.080 (0.075)	Data 0.003 (0.003)	Loss 10.5459 (10.1203)	Acc@1 76.562 (77.076)	Acc@5 95.312 (95.754)
[epoch:167, iter:130113] Loss: 1.146, 8.379, 53.223, 377.461, 0.912
[epoch:167, iter:130133] Loss: 1.145, 8.387, 53.223, 377.522, 0.658
[epoch:167, iter:130153] Loss: 1.147, 8.389, 53.241, 377.582, 0.863
[epoch:167, iter:130173] Loss: 1.146, 8.388, 53.236, 377.634, 0.986
[epoch:167, iter:130193] Loss: 1.147, 8.385, 53.232, 377.631, 0.597
Epoch: [166][400/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 10.4781 (10.1408)	Acc@1 70.312 (76.894)	Acc@5 95.312 (95.788)
[epoch:167, iter:130213] Loss: 1.148, 8.383, 53.250, 377.629, 0.857
[epoch:167, iter:130233] Loss: 1.148, 8.382, 53.260, 377.625, 0.786
[epoch:167, iter:130253] Loss: 1.147, 8.377, 53.236, 377.534, 0.741
[epoch:167, iter:130273] Loss: 1.148, 8.372, 53.217, 377.395, 0.956
[epoch:167, iter:130293] Loss: 1.147, 8.370, 53.208, 377.424, 0.673
Epoch: [166][500/782]	Time 0.089 (0.077)	Data 0.003 (0.003)	Loss 10.4442 (10.1259)	Acc@1 73.438 (77.083)	Acc@5 92.188 (95.790)
[epoch:167, iter:130313] Loss: 1.147, 8.366, 53.186, 377.346, 0.965
[epoch:167, iter:130333] Loss: 1.147, 8.368, 53.175, 377.290, 0.718
[epoch:167, iter:130353] Loss: 1.148, 8.368, 53.185, 377.290, 0.616
[epoch:167, iter:130373] Loss: 1.148, 8.369, 53.184, 377.293, 0.849
[epoch:167, iter:130393] Loss: 1.148, 8.367, 53.166, 377.183, 0.930
Epoch: [166][600/782]	Time 0.075 (0.077)	Data 0.002 (0.003)	Loss 10.0406 (10.1282)	Acc@1 76.562 (77.017)	Acc@5 95.312 (95.731)
[epoch:167, iter:130413] Loss: 1.148, 8.370, 53.193, 377.315, 0.655
[epoch:167, iter:130433] Loss: 1.148, 8.371, 53.218, 377.453, 0.556
[epoch:167, iter:130453] Loss: 1.148, 8.372, 53.226, 377.473, 0.644
[epoch:167, iter:130473] Loss: 1.149, 8.374, 53.234, 377.469, 0.894
[epoch:167, iter:130493] Loss: 1.149, 8.374, 53.221, 377.422, 0.906
Epoch: [166][700/782]	Time 0.073 (0.077)	Data 0.002 (0.003)	Loss 10.2583 (10.1402)	Acc@1 79.688 (76.904)	Acc@5 92.188 (95.658)
[epoch:167, iter:130513] Loss: 1.148, 8.374, 53.225, 377.448, 0.742
[epoch:167, iter:130533] Loss: 1.149, 8.373, 53.237, 377.505, 0.699
[epoch:167, iter:130553] Loss: 1.149, 8.373, 53.241, 377.508, 0.697
[epoch:167, iter:130573] Loss: 1.149, 8.375, 53.248, 377.583, 0.855
[epoch:167, iter:130593] Loss: 1.149, 8.375, 53.247, 377.515, 0.615
 * Acc@1 76.886 Acc@5 95.652
epoch 166, total time 60.74
Test: [0/313]	Time 0.243 (0.243)	Loss 1.3374 (1.3374)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.4639 (1.2825)	Acc@1 56.250 (68.007)	Acc@5 96.875 (91.429)
Test: [200/313]	Time 0.008 (0.008)	Loss 0.7294 (1.2402)	Acc@1 75.000 (68.501)	Acc@5 96.875 (91.791)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.3722 (1.2450)	Acc@1 65.625 (68.387)	Acc@5 96.875 (91.860)
 * Acc@1 68.530 Acc@5 91.930
==> training...
Epoch: [167][0/782]	Time 0.589 (0.589)	Data 0.512 (0.512)	Loss 10.4331 (10.4331)	Acc@1 65.625 (65.625)	Acc@5 92.188 (92.188)
[epoch:168, iter:130595] Loss: 1.203, 8.445, 53.089, 381.072, 1.021
[epoch:168, iter:130615] Loss: 1.155, 8.386, 53.195, 377.450, 0.843
[epoch:168, iter:130635] Loss: 1.146, 8.436, 53.438, 378.362, 0.648
[epoch:168, iter:130655] Loss: 1.144, 8.409, 53.374, 378.275, 0.987
[epoch:168, iter:130675] Loss: 1.143, 8.396, 53.289, 377.923, 1.008
Epoch: [167][100/782]	Time 0.090 (0.083)	Data 0.003 (0.007)	Loss 10.5716 (10.1776)	Acc@1 68.750 (76.377)	Acc@5 96.875 (95.715)
[epoch:168, iter:130695] Loss: 1.143, 8.400, 53.345, 378.139, 0.865
[epoch:168, iter:130715] Loss: 1.142, 8.392, 53.249, 377.647, 0.655
[epoch:168, iter:130735] Loss: 1.144, 8.385, 53.272, 377.696, 0.846
[epoch:168, iter:130755] Loss: 1.145, 8.386, 53.244, 377.407, 0.374
[epoch:168, iter:130775] Loss: 1.146, 8.394, 53.297, 377.521, 0.923
Epoch: [167][200/782]	Time 0.060 (0.080)	Data 0.002 (0.005)	Loss 9.5062 (10.1661)	Acc@1 78.125 (76.430)	Acc@5 95.312 (95.507)
[epoch:168, iter:130795] Loss: 1.146, 8.394, 53.289, 377.571, 0.735
[epoch:168, iter:130815] Loss: 1.145, 8.384, 53.298, 377.508, 0.784
[epoch:168, iter:130835] Loss: 1.146, 8.380, 53.305, 377.540, 0.939
[epoch:168, iter:130855] Loss: 1.146, 8.375, 53.315, 377.562, 0.846
[epoch:168, iter:130875] Loss: 1.146, 8.376, 53.302, 377.477, 0.638
Epoch: [167][300/782]	Time 0.081 (0.079)	Data 0.003 (0.004)	Loss 9.3498 (10.1432)	Acc@1 76.562 (76.687)	Acc@5 96.875 (95.608)
[epoch:168, iter:130895] Loss: 1.147, 8.375, 53.283, 377.430, 0.546
[epoch:168, iter:130915] Loss: 1.147, 8.377, 53.297, 377.463, 0.803
[epoch:168, iter:130935] Loss: 1.147, 8.375, 53.286, 377.393, 0.902
[epoch:168, iter:130955] Loss: 1.147, 8.373, 53.255, 377.234, 0.589
[epoch:168, iter:130975] Loss: 1.147, 8.373, 53.248, 377.262, 0.899
Epoch: [167][400/782]	Time 0.065 (0.079)	Data 0.002 (0.004)	Loss 8.9957 (10.1460)	Acc@1 84.375 (76.699)	Acc@5 100.000 (95.722)
[epoch:168, iter:130995] Loss: 1.148, 8.373, 53.262, 377.261, 0.355
[epoch:168, iter:131015] Loss: 1.147, 8.377, 53.270, 377.270, 0.620
[epoch:168, iter:131035] Loss: 1.147, 8.374, 53.244, 377.118, 0.787
[epoch:168, iter:131055] Loss: 1.148, 8.369, 53.257, 377.177, 0.845
[epoch:168, iter:131075] Loss: 1.148, 8.369, 53.253, 377.154, 0.595
Epoch: [167][500/782]	Time 0.066 (0.078)	Data 0.002 (0.003)	Loss 10.8375 (10.1379)	Acc@1 73.438 (76.693)	Acc@5 95.312 (95.712)
[epoch:168, iter:131095] Loss: 1.148, 8.371, 53.248, 377.142, 0.959
[epoch:168, iter:131115] Loss: 1.149, 8.370, 53.253, 377.176, 0.718
[epoch:168, iter:131135] Loss: 1.149, 8.373, 53.253, 377.198, 1.125
[epoch:168, iter:131155] Loss: 1.149, 8.374, 53.235, 377.127, 0.532
[epoch:168, iter:131175] Loss: 1.149, 8.371, 53.226, 377.108, 0.927
Epoch: [167][600/782]	Time 0.064 (0.077)	Data 0.002 (0.003)	Loss 10.5666 (10.1421)	Acc@1 75.000 (76.607)	Acc@5 92.188 (95.684)
[epoch:168, iter:131195] Loss: 1.149, 8.370, 53.217, 377.051, 1.015
[epoch:168, iter:131215] Loss: 1.149, 8.370, 53.225, 377.098, 0.835
[epoch:168, iter:131235] Loss: 1.148, 8.370, 53.211, 377.037, 0.957
[epoch:168, iter:131255] Loss: 1.148, 8.370, 53.213, 377.080, 0.855
[epoch:168, iter:131275] Loss: 1.148, 8.371, 53.227, 377.154, 1.200
Epoch: [167][700/782]	Time 0.087 (0.078)	Data 0.003 (0.003)	Loss 10.3566 (10.1507)	Acc@1 78.125 (76.554)	Acc@5 96.875 (95.667)
[epoch:168, iter:131295] Loss: 1.149, 8.371, 53.244, 377.183, 0.780
[epoch:168, iter:131315] Loss: 1.149, 8.373, 53.242, 377.203, 0.907
[epoch:168, iter:131335] Loss: 1.149, 8.373, 53.229, 377.160, 0.660
[epoch:168, iter:131355] Loss: 1.149, 8.372, 53.233, 377.151, 0.888
[epoch:168, iter:131375] Loss: 1.149, 8.371, 53.236, 377.195, 1.023
 * Acc@1 76.574 Acc@5 95.700
epoch 167, total time 60.97
Test: [0/313]	Time 0.276 (0.276)	Loss 1.4517 (1.4517)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.3730 (1.2307)	Acc@1 59.375 (69.493)	Acc@5 96.875 (91.894)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.8419 (1.2032)	Acc@1 75.000 (69.434)	Acc@5 93.750 (92.226)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.7390 (1.2080)	Acc@1 62.500 (69.352)	Acc@5 87.500 (92.141)
 * Acc@1 69.470 Acc@5 92.150
==> training...
Epoch: [168][0/782]	Time 0.593 (0.593)	Data 0.513 (0.513)	Loss 9.2689 (9.2689)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
[epoch:169, iter:131377] Loss: 1.087, 8.302, 51.329, 369.197, 0.366
[epoch:169, iter:131397] Loss: 1.154, 8.381, 53.299, 375.892, 0.601
[epoch:169, iter:131417] Loss: 1.142, 8.384, 53.353, 376.993, 0.828
[epoch:169, iter:131437] Loss: 1.140, 8.387, 53.222, 376.919, 0.598
[epoch:169, iter:131457] Loss: 1.139, 8.381, 53.212, 376.915, 0.849
Epoch: [168][100/782]	Time 0.089 (0.088)	Data 0.003 (0.007)	Loss 10.8087 (10.0685)	Acc@1 59.375 (78.373)	Acc@5 90.625 (96.071)
[epoch:169, iter:131477] Loss: 1.139, 8.366, 53.118, 376.611, 1.244
[epoch:169, iter:131497] Loss: 1.140, 8.360, 53.156, 376.695, 1.132
[epoch:169, iter:131517] Loss: 1.139, 8.369, 53.196, 376.845, 0.540
[epoch:169, iter:131537] Loss: 1.143, 8.374, 53.269, 377.061, 0.643
[epoch:169, iter:131557] Loss: 1.145, 8.378, 53.283, 376.978, 0.460
Epoch: [168][200/782]	Time 0.068 (0.081)	Data 0.002 (0.005)	Loss 10.6289 (10.1118)	Acc@1 79.688 (77.495)	Acc@5 95.312 (95.763)
[epoch:169, iter:131577] Loss: 1.146, 8.387, 53.351, 377.239, 0.593
[epoch:169, iter:131597] Loss: 1.146, 8.382, 53.389, 377.389, 0.753
[epoch:169, iter:131617] Loss: 1.147, 8.381, 53.384, 377.425, 0.701
[epoch:169, iter:131637] Loss: 1.148, 8.387, 53.428, 377.579, 0.945
[epoch:169, iter:131657] Loss: 1.148, 8.390, 53.474, 377.807, 0.800
Epoch: [168][300/782]	Time 0.059 (0.079)	Data 0.002 (0.004)	Loss 10.1559 (10.1327)	Acc@1 78.125 (77.393)	Acc@5 96.875 (95.806)
[epoch:169, iter:131677] Loss: 1.147, 8.382, 53.458, 377.779, 0.790
[epoch:169, iter:131697] Loss: 1.145, 8.385, 53.418, 377.638, 0.588
[epoch:169, iter:131717] Loss: 1.144, 8.385, 53.405, 377.624, 0.550
[epoch:169, iter:131737] Loss: 1.144, 8.384, 53.404, 377.657, 0.530
[epoch:169, iter:131757] Loss: 1.144, 8.380, 53.369, 377.526, 0.680
Epoch: [168][400/782]	Time 0.062 (0.078)	Data 0.002 (0.004)	Loss 9.9918 (10.1393)	Acc@1 76.562 (77.127)	Acc@5 92.188 (95.628)
[epoch:169, iter:131777] Loss: 1.145, 8.381, 53.368, 377.544, 0.878
[epoch:169, iter:131797] Loss: 1.145, 8.379, 53.358, 377.535, 0.855
[epoch:169, iter:131817] Loss: 1.145, 8.378, 53.364, 377.570, 0.711
[epoch:169, iter:131837] Loss: 1.146, 8.376, 53.350, 377.497, 0.885
[epoch:169, iter:131857] Loss: 1.146, 8.376, 53.349, 377.504, 0.543
Epoch: [168][500/782]	Time 0.086 (0.079)	Data 0.002 (0.003)	Loss 10.4147 (10.1325)	Acc@1 76.562 (77.161)	Acc@5 92.188 (95.637)
[epoch:169, iter:131877] Loss: 1.146, 8.372, 53.327, 377.451, 0.840
[epoch:169, iter:131897] Loss: 1.146, 8.373, 53.343, 377.549, 1.012
[epoch:169, iter:131917] Loss: 1.146, 8.370, 53.354, 377.644, 0.368
[epoch:169, iter:131937] Loss: 1.147, 8.371, 53.369, 377.761, 1.051
[epoch:169, iter:131957] Loss: 1.147, 8.371, 53.391, 377.846, 1.041
Epoch: [168][600/782]	Time 0.101 (0.079)	Data 0.004 (0.003)	Loss 10.5677 (10.1627)	Acc@1 70.312 (76.984)	Acc@5 93.750 (95.624)
[epoch:169, iter:131977] Loss: 1.148, 8.368, 53.404, 377.876, 1.054
[epoch:169, iter:131997] Loss: 1.148, 8.369, 53.391, 377.828, 0.864
[epoch:169, iter:132017] Loss: 1.147, 8.367, 53.385, 377.847, 0.538
[epoch:169, iter:132037] Loss: 1.148, 8.371, 53.387, 377.817, 0.913
[epoch:169, iter:132057] Loss: 1.148, 8.368, 53.371, 377.749, 0.754
Epoch: [168][700/782]	Time 0.062 (0.078)	Data 0.002 (0.003)	Loss 10.6278 (10.1641)	Acc@1 73.438 (76.875)	Acc@5 95.312 (95.642)
[epoch:169, iter:132077] Loss: 1.148, 8.368, 53.380, 377.739, 0.860
[epoch:169, iter:132097] Loss: 1.148, 8.369, 53.378, 377.735, 0.748
[epoch:169, iter:132117] Loss: 1.149, 8.369, 53.374, 377.753, 0.863
[epoch:169, iter:132137] Loss: 1.149, 8.369, 53.382, 377.801, 1.135
[epoch:169, iter:132157] Loss: 1.149, 8.369, 53.384, 377.795, 0.920
 * Acc@1 76.772 Acc@5 95.644
epoch 168, total time 61.03
Test: [0/313]	Time 0.257 (0.257)	Loss 1.3389 (1.3389)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.5173 (1.2589)	Acc@1 56.250 (68.286)	Acc@5 93.750 (91.646)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.8003 (1.2231)	Acc@1 71.875 (68.828)	Acc@5 93.750 (91.993)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.6590 (1.2259)	Acc@1 50.000 (69.061)	Acc@5 96.875 (92.089)
 * Acc@1 69.180 Acc@5 92.120
==> training...
Epoch: [169][0/782]	Time 0.457 (0.457)	Data 0.388 (0.388)	Loss 9.4973 (9.4973)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
[epoch:170, iter:132159] Loss: 1.141, 8.603, 52.600, 372.434, 0.445
[epoch:170, iter:132179] Loss: 1.155, 8.380, 53.573, 378.427, 1.011
[epoch:170, iter:132199] Loss: 1.139, 8.337, 53.016, 376.156, 0.924
[epoch:170, iter:132219] Loss: 1.142, 8.323, 52.901, 375.606, 0.968
[epoch:170, iter:132239] Loss: 1.141, 8.335, 52.997, 376.256, 0.558
Epoch: [169][100/782]	Time 0.080 (0.080)	Data 0.002 (0.006)	Loss 9.1931 (10.0189)	Acc@1 89.062 (78.311)	Acc@5 100.000 (95.978)
[epoch:170, iter:132259] Loss: 1.143, 8.338, 52.949, 375.962, 0.422
[epoch:170, iter:132279] Loss: 1.146, 8.339, 53.023, 376.278, 0.483
[epoch:170, iter:132299] Loss: 1.147, 8.339, 53.080, 376.354, 1.068
[epoch:170, iter:132319] Loss: 1.149, 8.349, 53.096, 376.321, 0.548
[epoch:170, iter:132339] Loss: 1.146, 8.343, 53.052, 376.203, 1.035
Epoch: [169][200/782]	Time 0.071 (0.077)	Data 0.002 (0.004)	Loss 9.8076 (10.0469)	Acc@1 76.562 (77.666)	Acc@5 95.312 (95.934)
[epoch:170, iter:132359] Loss: 1.147, 8.346, 53.059, 376.168, 0.624
[epoch:170, iter:132379] Loss: 1.147, 8.348, 53.057, 376.167, 0.838
[epoch:170, iter:132399] Loss: 1.147, 8.350, 53.059, 376.239, 0.697
[epoch:170, iter:132419] Loss: 1.148, 8.349, 53.096, 376.344, 0.583
[epoch:170, iter:132439] Loss: 1.148, 8.352, 53.149, 376.641, 0.595
Epoch: [169][300/782]	Time 0.061 (0.077)	Data 0.002 (0.004)	Loss 10.0430 (10.0632)	Acc@1 76.562 (77.814)	Acc@5 96.875 (95.925)
[epoch:170, iter:132459] Loss: 1.147, 8.347, 53.124, 376.544, 0.719
[epoch:170, iter:132479] Loss: 1.147, 8.349, 53.181, 376.755, 0.754
[epoch:170, iter:132499] Loss: 1.148, 8.350, 53.190, 376.816, 0.629
[epoch:170, iter:132519] Loss: 1.148, 8.353, 53.209, 376.901, 0.613
[epoch:170, iter:132539] Loss: 1.148, 8.355, 53.202, 376.881, 1.135
Epoch: [169][400/782]	Time 0.056 (0.077)	Data 0.002 (0.003)	Loss 10.0140 (10.0916)	Acc@1 75.000 (77.568)	Acc@5 96.875 (95.815)
[epoch:170, iter:132559] Loss: 1.149, 8.354, 53.192, 376.863, 0.695
[epoch:170, iter:132579] Loss: 1.149, 8.352, 53.178, 376.828, 0.819
[epoch:170, iter:132599] Loss: 1.148, 8.353, 53.154, 376.779, 1.006
[epoch:170, iter:132619] Loss: 1.148, 8.351, 53.163, 376.850, 1.195
[epoch:170, iter:132639] Loss: 1.149, 8.351, 53.171, 376.870, 1.093
Epoch: [169][500/782]	Time 0.072 (0.076)	Data 0.002 (0.003)	Loss 10.7240 (10.1009)	Acc@1 79.688 (77.520)	Acc@5 93.750 (95.765)
[epoch:170, iter:132659] Loss: 1.149, 8.349, 53.178, 376.928, 0.865
[epoch:170, iter:132679] Loss: 1.149, 8.349, 53.193, 376.990, 0.843
[epoch:170, iter:132699] Loss: 1.150, 8.352, 53.201, 377.036, 0.854
[epoch:170, iter:132719] Loss: 1.150, 8.352, 53.203, 377.019, 0.696
[epoch:170, iter:132739] Loss: 1.150, 8.352, 53.212, 377.076, 0.740
Epoch: [169][600/782]	Time 0.093 (0.076)	Data 0.003 (0.003)	Loss 9.8966 (10.1191)	Acc@1 73.438 (77.277)	Acc@5 95.312 (95.718)
[epoch:170, iter:132759] Loss: 1.150, 8.350, 53.215, 377.066, 0.830
[epoch:170, iter:132779] Loss: 1.151, 8.349, 53.229, 377.102, 0.819
[epoch:170, iter:132799] Loss: 1.150, 8.349, 53.233, 377.182, 0.868
[epoch:170, iter:132819] Loss: 1.151, 8.352, 53.229, 377.160, 0.485
[epoch:170, iter:132839] Loss: 1.151, 8.352, 53.229, 377.126, 0.769
Epoch: [169][700/782]	Time 0.083 (0.077)	Data 0.003 (0.003)	Loss 10.0763 (10.1263)	Acc@1 75.000 (77.182)	Acc@5 96.875 (95.696)
[epoch:170, iter:132859] Loss: 1.151, 8.352, 53.226, 377.110, 0.854
[epoch:170, iter:132879] Loss: 1.151, 8.352, 53.231, 377.146, 0.930
[epoch:170, iter:132899] Loss: 1.151, 8.355, 53.246, 377.251, 0.871
[epoch:170, iter:132919] Loss: 1.150, 8.354, 53.255, 377.314, 0.785
[epoch:170, iter:132939] Loss: 1.150, 8.355, 53.270, 377.385, 0.746
 * Acc@1 76.980 Acc@5 95.666
epoch 169, total time 61.24
Test: [0/313]	Time 0.246 (0.246)	Loss 1.3980 (1.3980)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.5928 (1.2419)	Acc@1 53.125 (69.028)	Acc@5 96.875 (91.770)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7138 (1.2167)	Acc@1 68.750 (69.061)	Acc@5 100.000 (92.118)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.5099 (1.2254)	Acc@1 59.375 (69.134)	Acc@5 93.750 (92.099)
 * Acc@1 69.200 Acc@5 92.140
==> training...
Epoch: [170][0/782]	Time 0.498 (0.498)	Data 0.433 (0.433)	Loss 9.7631 (9.7631)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
[epoch:171, iter:132941] Loss: 1.154, 8.366, 53.962, 378.175, 0.450
[epoch:171, iter:132961] Loss: 1.159, 8.359, 53.491, 377.087, 0.949
[epoch:171, iter:132981] Loss: 1.161, 8.376, 53.424, 377.123, 0.814
[epoch:171, iter:133001] Loss: 1.160, 8.386, 53.540, 377.475, 0.816
[epoch:171, iter:133021] Loss: 1.160, 8.368, 53.402, 377.130, 0.685
Epoch: [170][100/782]	Time 0.069 (0.082)	Data 0.004 (0.007)	Loss 10.4031 (10.1589)	Acc@1 73.438 (77.398)	Acc@5 95.312 (95.777)
[epoch:171, iter:133041] Loss: 1.161, 8.374, 53.440, 377.646, 0.791
[epoch:171, iter:133061] Loss: 1.159, 8.382, 53.368, 377.638, 0.723
[epoch:171, iter:133081] Loss: 1.160, 8.380, 53.356, 377.398, 0.760
[epoch:171, iter:133101] Loss: 1.159, 8.372, 53.395, 377.488, 0.661
[epoch:171, iter:133121] Loss: 1.158, 8.367, 53.380, 377.512, 0.887
Epoch: [170][200/782]	Time 0.088 (0.081)	Data 0.002 (0.004)	Loss 10.7746 (10.1415)	Acc@1 76.562 (77.558)	Acc@5 95.312 (95.880)
[epoch:171, iter:133141] Loss: 1.158, 8.371, 53.350, 377.382, 1.028
[epoch:171, iter:133161] Loss: 1.157, 8.373, 53.350, 377.330, 0.800
[epoch:171, iter:133181] Loss: 1.157, 8.372, 53.346, 377.255, 0.620
[epoch:171, iter:133201] Loss: 1.157, 8.374, 53.360, 377.388, 0.512
[epoch:171, iter:133221] Loss: 1.156, 8.365, 53.311, 377.097, 0.604
Epoch: [170][300/782]	Time 0.077 (0.082)	Data 0.002 (0.004)	Loss 9.8534 (10.1344)	Acc@1 75.000 (77.149)	Acc@5 93.750 (95.743)
[epoch:171, iter:133241] Loss: 1.154, 8.363, 53.299, 377.011, 0.945
[epoch:171, iter:133261] Loss: 1.154, 8.359, 53.267, 376.891, 0.719
[epoch:171, iter:133281] Loss: 1.153, 8.357, 53.250, 376.825, 0.768
[epoch:171, iter:133301] Loss: 1.153, 8.354, 53.245, 376.777, 0.680
[epoch:171, iter:133321] Loss: 1.154, 8.356, 53.262, 376.825, 0.710
Epoch: [170][400/782]	Time 0.080 (0.082)	Data 0.002 (0.003)	Loss 10.2116 (10.1282)	Acc@1 76.562 (77.092)	Acc@5 93.750 (95.714)
[epoch:171, iter:133341] Loss: 1.153, 8.354, 53.238, 376.757, 0.945
[epoch:171, iter:133361] Loss: 1.153, 8.356, 53.269, 376.865, 0.630
[epoch:171, iter:133381] Loss: 1.152, 8.356, 53.247, 376.784, 0.905
[epoch:171, iter:133401] Loss: 1.151, 8.356, 53.245, 376.766, 0.597
[epoch:171, iter:133421] Loss: 1.151, 8.357, 53.244, 376.706, 0.783
Epoch: [170][500/782]	Time 0.071 (0.082)	Data 0.002 (0.003)	Loss 9.9848 (10.1356)	Acc@1 81.250 (76.940)	Acc@5 98.438 (95.646)
[epoch:171, iter:133441] Loss: 1.151, 8.355, 53.270, 376.796, 0.579
[epoch:171, iter:133461] Loss: 1.151, 8.354, 53.257, 376.762, 0.761
[epoch:171, iter:133481] Loss: 1.151, 8.352, 53.248, 376.703, 0.769
[epoch:171, iter:133501] Loss: 1.151, 8.352, 53.256, 376.771, 0.640
[epoch:171, iter:133521] Loss: 1.151, 8.352, 53.256, 376.762, 0.805
Epoch: [170][600/782]	Time 0.080 (0.081)	Data 0.002 (0.003)	Loss 10.5758 (10.1313)	Acc@1 70.312 (77.085)	Acc@5 89.062 (95.650)
[epoch:171, iter:133541] Loss: 1.151, 8.351, 53.259, 376.780, 1.038
[epoch:171, iter:133561] Loss: 1.151, 8.352, 53.253, 376.782, 0.655
[epoch:171, iter:133581] Loss: 1.151, 8.356, 53.274, 376.880, 1.010
[epoch:171, iter:133601] Loss: 1.151, 8.358, 53.278, 376.911, 0.793
[epoch:171, iter:133621] Loss: 1.151, 8.358, 53.283, 376.958, 0.866
Epoch: [170][700/782]	Time 0.080 (0.080)	Data 0.003 (0.003)	Loss 10.4101 (10.1463)	Acc@1 76.562 (76.935)	Acc@5 93.750 (95.627)
[epoch:171, iter:133641] Loss: 1.151, 8.359, 53.294, 377.022, 0.783
[epoch:171, iter:133661] Loss: 1.151, 8.358, 53.296, 377.057, 0.725
[epoch:171, iter:133681] Loss: 1.150, 8.358, 53.294, 377.083, 0.854
[epoch:171, iter:133701] Loss: 1.150, 8.357, 53.294, 377.083, 0.879
[epoch:171, iter:133721] Loss: 1.150, 8.356, 53.303, 377.115, 0.798
 * Acc@1 76.822 Acc@5 95.656
epoch 170, total time 62.93
Test: [0/313]	Time 0.238 (0.238)	Loss 1.3155 (1.3155)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.4456 (1.2829)	Acc@1 56.250 (68.626)	Acc@5 96.875 (91.368)
Test: [200/313]	Time 0.009 (0.009)	Loss 0.6647 (1.2477)	Acc@1 81.250 (68.983)	Acc@5 96.875 (91.698)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.9287 (1.2552)	Acc@1 62.500 (68.937)	Acc@5 84.375 (91.694)
 * Acc@1 69.030 Acc@5 91.750
==> training...
Epoch: [171][0/782]	Time 0.587 (0.587)	Data 0.515 (0.515)	Loss 9.7214 (9.7214)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
[epoch:172, iter:133723] Loss: 1.193, 8.123, 51.100, 369.660, 0.688
[epoch:172, iter:133743] Loss: 1.131, 8.339, 52.862, 374.870, 0.739
[epoch:172, iter:133763] Loss: 1.139, 8.321, 52.774, 374.442, 0.865
[epoch:172, iter:133783] Loss: 1.141, 8.322, 52.876, 374.900, 0.451
[epoch:172, iter:133803] Loss: 1.144, 8.323, 52.905, 374.991, 0.739
Epoch: [171][100/782]	Time 0.078 (0.087)	Data 0.002 (0.007)	Loss 9.5428 (10.0176)	Acc@1 78.125 (77.336)	Acc@5 98.438 (96.117)
[epoch:172, iter:133823] Loss: 1.142, 8.321, 52.985, 375.649, 0.659
[epoch:172, iter:133843] Loss: 1.145, 8.329, 53.137, 376.408, 0.595
[epoch:172, iter:133863] Loss: 1.146, 8.338, 53.173, 376.432, 0.925
[epoch:172, iter:133883] Loss: 1.145, 8.345, 53.169, 376.556, 0.952
[epoch:172, iter:133903] Loss: 1.142, 8.347, 53.157, 376.517, 0.638
Epoch: [171][200/782]	Time 0.075 (0.082)	Data 0.002 (0.005)	Loss 9.8837 (10.0714)	Acc@1 71.875 (77.542)	Acc@5 93.750 (95.973)
[epoch:172, iter:133923] Loss: 1.144, 8.350, 53.200, 376.587, 0.836
[epoch:172, iter:133943] Loss: 1.145, 8.358, 53.199, 376.740, 0.953
[epoch:172, iter:133963] Loss: 1.144, 8.361, 53.187, 376.754, 0.686
[epoch:172, iter:133983] Loss: 1.144, 8.367, 53.171, 376.669, 0.754
[epoch:172, iter:134003] Loss: 1.145, 8.369, 53.180, 376.785, 0.610
Epoch: [171][300/782]	Time 0.061 (0.082)	Data 0.002 (0.004)	Loss 10.2526 (10.1061)	Acc@1 76.562 (77.066)	Acc@5 93.750 (95.873)
[epoch:172, iter:134023] Loss: 1.145, 8.368, 53.218, 376.962, 0.874
[epoch:172, iter:134043] Loss: 1.146, 8.367, 53.227, 377.000, 0.814
[epoch:172, iter:134063] Loss: 1.146, 8.375, 53.254, 377.262, 1.013
[epoch:172, iter:134083] Loss: 1.146, 8.375, 53.297, 377.431, 1.043
[epoch:172, iter:134103] Loss: 1.147, 8.375, 53.277, 377.367, 0.732
Epoch: [171][400/782]	Time 0.087 (0.080)	Data 0.002 (0.004)	Loss 10.3612 (10.1275)	Acc@1 78.125 (76.968)	Acc@5 93.750 (95.784)
[epoch:172, iter:134123] Loss: 1.147, 8.370, 53.278, 377.292, 0.714
[epoch:172, iter:134143] Loss: 1.147, 8.373, 53.310, 377.407, 0.840
[epoch:172, iter:134163] Loss: 1.148, 8.375, 53.307, 377.345, 0.790
[epoch:172, iter:134183] Loss: 1.147, 8.375, 53.311, 377.327, 0.703
[epoch:172, iter:134203] Loss: 1.147, 8.373, 53.306, 377.261, 0.614
Epoch: [171][500/782]	Time 0.077 (0.080)	Data 0.002 (0.003)	Loss 10.6563 (10.1224)	Acc@1 73.438 (77.037)	Acc@5 92.188 (95.774)
[epoch:172, iter:134223] Loss: 1.148, 8.371, 53.310, 377.196, 0.941
[epoch:172, iter:134243] Loss: 1.148, 8.368, 53.309, 377.178, 0.735
[epoch:172, iter:134263] Loss: 1.148, 8.368, 53.300, 377.167, 1.100
[epoch:172, iter:134283] Loss: 1.148, 8.368, 53.303, 377.189, 0.854
[epoch:172, iter:134303] Loss: 1.148, 8.371, 53.306, 377.257, 1.105
Epoch: [171][600/782]	Time 0.085 (0.080)	Data 0.003 (0.003)	Loss 10.1798 (10.1287)	Acc@1 71.875 (77.002)	Acc@5 96.875 (95.739)
[epoch:172, iter:134323] Loss: 1.148, 8.370, 53.306, 377.278, 0.791
[epoch:172, iter:134343] Loss: 1.149, 8.368, 53.310, 377.257, 1.011
[epoch:172, iter:134363] Loss: 1.149, 8.367, 53.327, 377.290, 0.698
[epoch:172, iter:134383] Loss: 1.149, 8.367, 53.329, 377.272, 0.597
[epoch:172, iter:134403] Loss: 1.149, 8.367, 53.322, 377.282, 1.000
Epoch: [171][700/782]	Time 0.073 (0.080)	Data 0.002 (0.003)	Loss 10.0095 (10.1346)	Acc@1 81.250 (76.810)	Acc@5 96.875 (95.781)
[epoch:172, iter:134423] Loss: 1.149, 8.364, 53.319, 377.220, 0.598
[epoch:172, iter:134443] Loss: 1.149, 8.368, 53.324, 377.257, 0.774
[epoch:172, iter:134463] Loss: 1.149, 8.367, 53.321, 377.309, 0.559
[epoch:172, iter:134483] Loss: 1.149, 8.366, 53.328, 377.315, 0.966
[epoch:172, iter:134503] Loss: 1.148, 8.365, 53.325, 377.367, 0.828
 * Acc@1 76.782 Acc@5 95.768
epoch 171, total time 63.02
Test: [0/313]	Time 0.239 (0.239)	Loss 1.2458 (1.2458)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/313]	Time 0.010 (0.010)	Loss 1.4198 (1.2327)	Acc@1 56.250 (68.998)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.009 (0.009)	Loss 0.6266 (1.1930)	Acc@1 78.125 (69.387)	Acc@5 96.875 (92.257)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.5068 (1.2105)	Acc@1 50.000 (68.802)	Acc@5 96.875 (92.255)
 * Acc@1 68.870 Acc@5 92.310
==> training...
Epoch: [172][0/782]	Time 0.582 (0.582)	Data 0.502 (0.502)	Loss 10.4585 (10.4585)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
[epoch:173, iter:134505] Loss: 1.100, 8.504, 54.966, 391.925, 0.706
[epoch:173, iter:134525] Loss: 1.149, 8.409, 53.532, 378.508, 0.611
[epoch:173, iter:134545] Loss: 1.149, 8.350, 53.292, 377.461, 0.999
[epoch:173, iter:134565] Loss: 1.148, 8.311, 53.207, 377.096, 0.797
[epoch:173, iter:134585] Loss: 1.147, 8.321, 53.130, 376.707, 0.893
Epoch: [172][100/782]	Time 0.074 (0.091)	Data 0.002 (0.008)	Loss 9.5029 (10.1074)	Acc@1 84.375 (76.671)	Acc@5 98.438 (95.885)
[epoch:173, iter:134605] Loss: 1.150, 8.326, 53.150, 376.813, 0.502
[epoch:173, iter:134625] Loss: 1.149, 8.324, 53.156, 376.977, 0.715
[epoch:173, iter:134645] Loss: 1.146, 8.323, 53.140, 376.949, 0.794
[epoch:173, iter:134665] Loss: 1.148, 8.331, 53.156, 376.786, 0.564
[epoch:173, iter:134685] Loss: 1.148, 8.345, 53.243, 377.185, 0.792
Epoch: [172][200/782]	Time 0.092 (0.089)	Data 0.003 (0.005)	Loss 10.2270 (10.1162)	Acc@1 71.875 (76.803)	Acc@5 95.312 (95.857)
[epoch:173, iter:134705] Loss: 1.146, 8.340, 53.213, 376.978, 0.940
[epoch:173, iter:134725] Loss: 1.147, 8.338, 53.215, 376.901, 0.606
[epoch:173, iter:134745] Loss: 1.148, 8.333, 53.215, 376.860, 0.746
[epoch:173, iter:134765] Loss: 1.148, 8.333, 53.199, 376.888, 0.853
[epoch:173, iter:134785] Loss: 1.148, 8.339, 53.184, 376.868, 0.557
Epoch: [172][300/782]	Time 0.083 (0.087)	Data 0.003 (0.004)	Loss 10.6050 (10.1000)	Acc@1 71.875 (77.102)	Acc@5 95.312 (95.842)
[epoch:173, iter:134805] Loss: 1.146, 8.337, 53.141, 376.739, 0.858
[epoch:173, iter:134825] Loss: 1.146, 8.335, 53.136, 376.717, 0.539
[epoch:173, iter:134845] Loss: 1.147, 8.339, 53.144, 376.794, 0.898
[epoch:173, iter:134865] Loss: 1.147, 8.337, 53.145, 376.737, 1.055
[epoch:173, iter:134885] Loss: 1.148, 8.339, 53.179, 376.874, 0.591
Epoch: [172][400/782]	Time 0.074 (0.086)	Data 0.002 (0.004)	Loss 10.1945 (10.1184)	Acc@1 78.125 (77.038)	Acc@5 95.312 (95.815)
[epoch:173, iter:134905] Loss: 1.148, 8.337, 53.185, 376.858, 0.887
[epoch:173, iter:134925] Loss: 1.148, 8.337, 53.186, 376.822, 0.572
[epoch:173, iter:134945] Loss: 1.148, 8.340, 53.180, 376.788, 0.658
[epoch:173, iter:134965] Loss: 1.148, 8.342, 53.197, 376.917, 1.018
[epoch:173, iter:134985] Loss: 1.149, 8.342, 53.232, 377.056, 0.654
Epoch: [172][500/782]	Time 0.074 (0.086)	Data 0.002 (0.004)	Loss 9.8622 (10.1304)	Acc@1 76.562 (76.890)	Acc@5 95.312 (95.865)
[epoch:173, iter:135005] Loss: 1.149, 8.345, 53.238, 377.078, 0.748
[epoch:173, iter:135025] Loss: 1.149, 8.350, 53.253, 377.172, 0.715
[epoch:173, iter:135045] Loss: 1.149, 8.352, 53.246, 377.136, 1.009
[epoch:173, iter:135065] Loss: 1.150, 8.356, 53.255, 377.162, 0.647
[epoch:173, iter:135085] Loss: 1.149, 8.355, 53.221, 376.988, 0.873
Epoch: [172][600/782]	Time 0.072 (0.085)	Data 0.002 (0.003)	Loss 9.6032 (10.1308)	Acc@1 79.688 (76.744)	Acc@5 95.312 (95.804)
[epoch:173, iter:135105] Loss: 1.149, 8.357, 53.220, 376.993, 0.638
[epoch:173, iter:135125] Loss: 1.149, 8.358, 53.209, 376.918, 0.578
[epoch:173, iter:135145] Loss: 1.149, 8.359, 53.200, 376.861, 0.791
[epoch:173, iter:135165] Loss: 1.150, 8.359, 53.222, 376.958, 0.500
[epoch:173, iter:135185] Loss: 1.150, 8.359, 53.223, 376.941, 1.000
Epoch: [172][700/782]	Time 0.071 (0.085)	Data 0.002 (0.003)	Loss 10.1221 (10.1408)	Acc@1 75.000 (76.665)	Acc@5 98.438 (95.807)
[epoch:173, iter:135205] Loss: 1.150, 8.359, 53.250, 377.037, 0.690
[epoch:173, iter:135225] Loss: 1.150, 8.361, 53.249, 377.006, 0.938
[epoch:173, iter:135245] Loss: 1.150, 8.360, 53.251, 377.046, 1.034
[epoch:173, iter:135265] Loss: 1.150, 8.358, 53.258, 377.077, 0.711
[epoch:173, iter:135285] Loss: 1.151, 8.359, 53.264, 377.132, 0.590
 * Acc@1 76.614 Acc@5 95.804
epoch 172, total time 65.61
Test: [0/313]	Time 0.259 (0.259)	Loss 1.2606 (1.2606)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.008 (0.009)	Loss 1.3746 (1.2727)	Acc@1 59.375 (68.224)	Acc@5 93.750 (91.275)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.8829 (1.2390)	Acc@1 65.625 (68.734)	Acc@5 100.000 (91.822)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.2426 (1.2468)	Acc@1 56.250 (68.657)	Acc@5 96.875 (91.933)
 * Acc@1 68.860 Acc@5 91.970
==> training...
Epoch: [173][0/782]	Time 0.637 (0.637)	Data 0.552 (0.552)	Loss 10.3754 (10.3754)	Acc@1 68.750 (68.750)	Acc@5 95.312 (95.312)
[epoch:174, iter:135287] Loss: 1.143, 8.623, 53.699, 376.598, 0.895
[epoch:174, iter:135307] Loss: 1.153, 8.459, 53.720, 378.613, 0.704
[epoch:174, iter:135327] Loss: 1.144, 8.413, 53.451, 378.402, 0.543
[epoch:174, iter:135347] Loss: 1.142, 8.370, 53.354, 377.797, 0.784
[epoch:174, iter:135367] Loss: 1.143, 8.368, 53.361, 377.745, 0.610
Epoch: [173][100/782]	Time 0.094 (0.093)	Data 0.002 (0.008)	Loss 9.7862 (10.1322)	Acc@1 76.562 (77.491)	Acc@5 96.875 (95.916)
[epoch:174, iter:135387] Loss: 1.145, 8.366, 53.413, 378.262, 0.740
[epoch:174, iter:135407] Loss: 1.146, 8.371, 53.356, 377.786, 1.006
[epoch:174, iter:135427] Loss: 1.141, 8.365, 53.275, 377.587, 0.728
[epoch:174, iter:135447] Loss: 1.140, 8.363, 53.113, 376.881, 0.644
[epoch:174, iter:135467] Loss: 1.140, 8.368, 53.061, 376.539, 0.644
Epoch: [173][200/782]	Time 0.061 (0.089)	Data 0.002 (0.005)	Loss 10.0677 (10.0773)	Acc@1 79.688 (77.503)	Acc@5 96.875 (95.841)
[epoch:174, iter:135487] Loss: 1.142, 8.377, 53.090, 376.639, 0.619
[epoch:174, iter:135507] Loss: 1.143, 8.368, 53.050, 376.524, 0.683
[epoch:174, iter:135527] Loss: 1.144, 8.370, 53.041, 376.423, 0.877
[epoch:174, iter:135547] Loss: 1.144, 8.375, 53.072, 376.510, 0.772
[epoch:174, iter:135567] Loss: 1.145, 8.377, 53.112, 376.595, 0.987
Epoch: [173][300/782]	Time 0.093 (0.087)	Data 0.003 (0.004)	Loss 10.4512 (10.0871)	Acc@1 73.438 (77.409)	Acc@5 96.875 (95.868)
[epoch:174, iter:135587] Loss: 1.145, 8.374, 53.098, 376.496, 0.799
[epoch:174, iter:135607] Loss: 1.146, 8.374, 53.159, 376.773, 0.929
[epoch:174, iter:135627] Loss: 1.147, 8.377, 53.212, 377.040, 0.647
[epoch:174, iter:135647] Loss: 1.146, 8.373, 53.181, 376.888, 0.846
[epoch:174, iter:135667] Loss: 1.147, 8.374, 53.223, 377.025, 1.080
Epoch: [173][400/782]	Time 0.085 (0.085)	Data 0.003 (0.004)	Loss 10.2143 (10.1378)	Acc@1 81.250 (76.863)	Acc@5 95.312 (95.659)
[epoch:174, iter:135687] Loss: 1.147, 8.370, 53.236, 377.068, 0.791
[epoch:174, iter:135707] Loss: 1.147, 8.369, 53.240, 377.061, 0.507
[epoch:174, iter:135727] Loss: 1.148, 8.366, 53.244, 376.963, 0.516
[epoch:174, iter:135747] Loss: 1.149, 8.367, 53.256, 376.980, 0.701
[epoch:174, iter:135767] Loss: 1.149, 8.368, 53.261, 377.009, 0.535
Epoch: [173][500/782]	Time 0.080 (0.085)	Data 0.002 (0.004)	Loss 10.6450 (10.1349)	Acc@1 62.500 (76.952)	Acc@5 96.875 (95.787)
[epoch:174, iter:135787] Loss: 1.149, 8.369, 53.269, 377.033, 1.028
[epoch:174, iter:135807] Loss: 1.149, 8.367, 53.287, 377.091, 0.630
[epoch:174, iter:135827] Loss: 1.149, 8.364, 53.292, 377.166, 1.032
[epoch:174, iter:135847] Loss: 1.149, 8.360, 53.290, 377.141, 0.934
[epoch:174, iter:135867] Loss: 1.149, 8.360, 53.275, 377.127, 0.934
Epoch: [173][600/782]	Time 0.092 (0.085)	Data 0.002 (0.003)	Loss 10.0968 (10.1323)	Acc@1 76.562 (77.038)	Acc@5 98.438 (95.780)
[epoch:174, iter:135887] Loss: 1.149, 8.356, 53.265, 377.075, 0.856
[epoch:174, iter:135907] Loss: 1.150, 8.357, 53.276, 377.096, 0.934
[epoch:174, iter:135927] Loss: 1.150, 8.357, 53.270, 377.054, 0.610
[epoch:174, iter:135947] Loss: 1.150, 8.359, 53.274, 377.075, 0.728
[epoch:174, iter:135967] Loss: 1.150, 8.358, 53.284, 377.120, 0.674
Epoch: [173][700/782]	Time 0.081 (0.085)	Data 0.002 (0.003)	Loss 10.3142 (10.1424)	Acc@1 75.000 (76.904)	Acc@5 92.188 (95.749)
[epoch:174, iter:135987] Loss: 1.150, 8.359, 53.299, 377.202, 0.858
[epoch:174, iter:136007] Loss: 1.150, 8.359, 53.315, 377.244, 0.809
[epoch:174, iter:136027] Loss: 1.150, 8.358, 53.325, 377.243, 0.713
[epoch:174, iter:136047] Loss: 1.150, 8.358, 53.333, 377.260, 1.092
[epoch:174, iter:136067] Loss: 1.151, 8.360, 53.350, 377.337, 1.048
 * Acc@1 76.760 Acc@5 95.702
epoch 173, total time 66.11
Test: [0/313]	Time 0.265 (0.265)	Loss 1.5122 (1.5122)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.2186 (1.2591)	Acc@1 62.500 (68.502)	Acc@5 96.875 (91.429)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.6260 (1.2380)	Acc@1 90.625 (68.486)	Acc@5 96.875 (91.744)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.4535 (1.2453)	Acc@1 59.375 (68.667)	Acc@5 96.875 (91.788)
 * Acc@1 68.840 Acc@5 91.840
==> training...
Epoch: [174][0/782]	Time 0.586 (0.586)	Data 0.521 (0.521)	Loss 9.7800 (9.7800)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
[epoch:175, iter:136069] Loss: 1.119, 8.108, 51.901, 367.517, 0.662
[epoch:175, iter:136089] Loss: 1.140, 8.370, 53.051, 374.778, 0.327
[epoch:175, iter:136109] Loss: 1.145, 8.360, 53.260, 376.586, 0.752
[epoch:175, iter:136129] Loss: 1.146, 8.335, 53.153, 376.034, 0.958
[epoch:175, iter:136149] Loss: 1.137, 8.323, 52.988, 375.368, 0.602
Epoch: [174][100/782]	Time 0.092 (0.083)	Data 0.003 (0.007)	Loss 10.0652 (10.0112)	Acc@1 76.562 (78.187)	Acc@5 98.438 (95.838)
[epoch:175, iter:136169] Loss: 1.138, 8.321, 53.052, 375.618, 0.699
[epoch:175, iter:136189] Loss: 1.140, 8.331, 53.119, 375.894, 0.690
[epoch:175, iter:136209] Loss: 1.141, 8.330, 53.092, 375.834, 0.935
[epoch:175, iter:136229] Loss: 1.143, 8.341, 53.137, 376.119, 0.646
[epoch:175, iter:136249] Loss: 1.147, 8.341, 53.188, 376.421, 0.700
Epoch: [174][200/782]	Time 0.086 (0.083)	Data 0.003 (0.005)	Loss 9.6944 (10.0697)	Acc@1 81.250 (77.977)	Acc@5 95.312 (96.035)
[epoch:175, iter:136269] Loss: 1.148, 8.345, 53.268, 376.639, 0.546
[epoch:175, iter:136289] Loss: 1.149, 8.348, 53.284, 376.744, 0.806
[epoch:175, iter:136309] Loss: 1.150, 8.352, 53.320, 376.833, 0.797
[epoch:175, iter:136329] Loss: 1.149, 8.353, 53.306, 376.790, 0.481
[epoch:175, iter:136349] Loss: 1.149, 8.353, 53.313, 376.913, 0.630
Epoch: [174][300/782]	Time 0.084 (0.081)	Data 0.003 (0.004)	Loss 10.2529 (10.0937)	Acc@1 73.438 (77.705)	Acc@5 92.188 (95.951)
[epoch:175, iter:136369] Loss: 1.149, 8.354, 53.316, 376.850, 0.999
[epoch:175, iter:136389] Loss: 1.149, 8.354, 53.311, 376.808, 0.893
[epoch:175, iter:136409] Loss: 1.149, 8.350, 53.278, 376.680, 0.671
[epoch:175, iter:136429] Loss: 1.149, 8.347, 53.295, 376.743, 1.208
[epoch:175, iter:136449] Loss: 1.148, 8.351, 53.265, 376.680, 0.691
Epoch: [174][400/782]	Time 0.087 (0.082)	Data 0.003 (0.004)	Loss 9.9234 (10.0933)	Acc@1 76.562 (77.502)	Acc@5 95.312 (95.905)
[epoch:175, iter:136469] Loss: 1.149, 8.351, 53.291, 376.715, 0.804
[epoch:175, iter:136489] Loss: 1.149, 8.352, 53.277, 376.755, 0.957
[epoch:175, iter:136509] Loss: 1.149, 8.353, 53.301, 376.886, 0.695
[epoch:175, iter:136529] Loss: 1.150, 8.352, 53.299, 376.850, 0.733
[epoch:175, iter:136549] Loss: 1.151, 8.353, 53.305, 376.900, 0.652
Epoch: [174][500/782]	Time 0.083 (0.081)	Data 0.002 (0.003)	Loss 10.8008 (10.1190)	Acc@1 71.875 (77.302)	Acc@5 96.875 (95.821)
[epoch:175, iter:136569] Loss: 1.152, 8.356, 53.331, 377.053, 0.924
[epoch:175, iter:136589] Loss: 1.153, 8.358, 53.349, 377.133, 0.662
[epoch:175, iter:136609] Loss: 1.153, 8.359, 53.361, 377.208, 0.712
[epoch:175, iter:136629] Loss: 1.152, 8.360, 53.370, 377.314, 0.923
[epoch:175, iter:136649] Loss: 1.152, 8.362, 53.367, 377.336, 0.488
Epoch: [174][600/782]	Time 0.082 (0.081)	Data 0.002 (0.003)	Loss 10.5440 (10.1366)	Acc@1 76.562 (77.270)	Acc@5 96.875 (95.752)
[epoch:175, iter:136669] Loss: 1.152, 8.361, 53.380, 377.355, 0.773
[epoch:175, iter:136689] Loss: 1.152, 8.361, 53.386, 377.367, 1.365
[epoch:175, iter:136709] Loss: 1.152, 8.360, 53.389, 377.380, 0.555
[epoch:175, iter:136729] Loss: 1.152, 8.363, 53.382, 377.354, 0.776
[epoch:175, iter:136749] Loss: 1.152, 8.361, 53.373, 377.349, 0.732
Epoch: [174][700/782]	Time 0.071 (0.081)	Data 0.002 (0.003)	Loss 9.9536 (10.1450)	Acc@1 82.812 (77.200)	Acc@5 95.312 (95.734)
[epoch:175, iter:136769] Loss: 1.152, 8.361, 53.366, 377.358, 0.773
[epoch:175, iter:136789] Loss: 1.152, 8.364, 53.373, 377.426, 1.013
[epoch:175, iter:136809] Loss: 1.152, 8.364, 53.360, 377.358, 0.891
[epoch:175, iter:136829] Loss: 1.153, 8.362, 53.370, 377.394, 0.511
[epoch:175, iter:136849] Loss: 1.153, 8.360, 53.368, 377.340, 0.769
 * Acc@1 77.046 Acc@5 95.726
epoch 174, total time 63.39
Test: [0/313]	Time 0.255 (0.255)	Loss 1.6284 (1.6284)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/313]	Time 0.010 (0.010)	Loss 1.1843 (1.2796)	Acc@1 68.750 (68.533)	Acc@5 93.750 (91.429)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.9408 (1.2641)	Acc@1 71.875 (68.175)	Acc@5 96.875 (91.542)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.5932 (1.2687)	Acc@1 53.125 (68.023)	Acc@5 96.875 (91.642)
 * Acc@1 68.250 Acc@5 91.690
==> training...
Epoch: [175][0/782]	Time 0.607 (0.607)	Data 0.536 (0.536)	Loss 10.1099 (10.1099)	Acc@1 82.812 (82.812)	Acc@5 96.875 (96.875)
[epoch:176, iter:136851] Loss: 1.158, 8.362, 55.727, 378.013, 0.532
[epoch:176, iter:136871] Loss: 1.161, 8.339, 53.534, 377.335, 0.638
[epoch:176, iter:136891] Loss: 1.153, 8.357, 53.244, 376.824, 0.803
[epoch:176, iter:136911] Loss: 1.153, 8.356, 53.319, 377.393, 0.910
[epoch:176, iter:136931] Loss: 1.151, 8.355, 53.300, 377.064, 0.816
Epoch: [175][100/782]	Time 0.076 (0.089)	Data 0.002 (0.008)	Loss 9.5643 (10.1042)	Acc@1 81.250 (77.460)	Acc@5 96.875 (96.225)
[epoch:176, iter:136951] Loss: 1.152, 8.337, 53.298, 377.011, 0.543
[epoch:176, iter:136971] Loss: 1.150, 8.339, 53.316, 377.076, 0.761
[epoch:176, iter:136991] Loss: 1.149, 8.344, 53.282, 377.026, 0.594
[epoch:176, iter:137011] Loss: 1.147, 8.339, 53.248, 376.959, 0.657
[epoch:176, iter:137031] Loss: 1.147, 8.347, 53.311, 377.283, 0.640
Epoch: [175][200/782]	Time 0.076 (0.082)	Data 0.002 (0.005)	Loss 9.7284 (10.1106)	Acc@1 78.125 (77.550)	Acc@5 98.438 (96.129)
[epoch:176, iter:137051] Loss: 1.146, 8.350, 53.284, 377.165, 0.737
[epoch:176, iter:137071] Loss: 1.146, 8.353, 53.267, 377.063, 0.981
[epoch:176, iter:137091] Loss: 1.146, 8.349, 53.274, 377.221, 0.668
[epoch:176, iter:137111] Loss: 1.148, 8.346, 53.323, 377.319, 0.702
[epoch:176, iter:137131] Loss: 1.147, 8.340, 53.274, 377.189, 0.981
Epoch: [175][300/782]	Time 0.099 (0.082)	Data 0.003 (0.004)	Loss 10.2346 (10.1165)	Acc@1 70.312 (77.331)	Acc@5 95.312 (95.899)
[epoch:176, iter:137151] Loss: 1.146, 8.339, 53.280, 377.182, 0.793
[epoch:176, iter:137171] Loss: 1.146, 8.339, 53.296, 377.229, 0.716
[epoch:176, iter:137191] Loss: 1.147, 8.343, 53.304, 377.306, 0.759
[epoch:176, iter:137211] Loss: 1.149, 8.341, 53.310, 377.222, 0.878
[epoch:176, iter:137231] Loss: 1.149, 8.342, 53.316, 377.225, 0.686
Epoch: [175][400/782]	Time 0.087 (0.082)	Data 0.003 (0.004)	Loss 10.4362 (10.1293)	Acc@1 79.688 (77.065)	Acc@5 93.750 (95.858)
[epoch:176, iter:137251] Loss: 1.149, 8.344, 53.303, 377.171, 0.914
[epoch:176, iter:137271] Loss: 1.148, 8.346, 53.279, 377.046, 1.105
[epoch:176, iter:137291] Loss: 1.148, 8.345, 53.269, 376.989, 0.803
[epoch:176, iter:137311] Loss: 1.148, 8.347, 53.261, 377.016, 0.763
[epoch:176, iter:137331] Loss: 1.149, 8.348, 53.286, 377.068, 0.846
Epoch: [175][500/782]	Time 0.092 (0.081)	Data 0.003 (0.003)	Loss 9.8650 (10.1383)	Acc@1 82.812 (76.893)	Acc@5 98.438 (95.877)
[epoch:176, iter:137351] Loss: 1.150, 8.349, 53.304, 377.115, 0.645
[epoch:176, iter:137371] Loss: 1.150, 8.348, 53.311, 377.121, 0.916
[epoch:176, iter:137391] Loss: 1.151, 8.347, 53.313, 377.071, 0.778
[epoch:176, iter:137411] Loss: 1.150, 8.352, 53.308, 377.118, 0.717
[epoch:176, iter:137431] Loss: 1.150, 8.350, 53.297, 377.072, 0.697
Epoch: [175][600/782]	Time 0.054 (0.079)	Data 0.002 (0.003)	Loss 10.2752 (10.1327)	Acc@1 67.188 (76.978)	Acc@5 93.750 (95.866)
[epoch:176, iter:137451] Loss: 1.150, 8.346, 53.291, 377.022, 1.076
[epoch:176, iter:137471] Loss: 1.150, 8.345, 53.308, 377.093, 0.755
[epoch:176, iter:137491] Loss: 1.150, 8.347, 53.314, 377.130, 1.221
[epoch:176, iter:137511] Loss: 1.151, 8.348, 53.312, 377.105, 0.962
[epoch:176, iter:137531] Loss: 1.151, 8.350, 53.326, 377.137, 0.659
Epoch: [175][700/782]	Time 0.090 (0.078)	Data 0.002 (0.003)	Loss 10.3081 (10.1462)	Acc@1 70.312 (76.935)	Acc@5 95.312 (95.847)
[epoch:176, iter:137551] Loss: 1.150, 8.351, 53.330, 377.138, 0.921
[epoch:176, iter:137571] Loss: 1.151, 8.351, 53.327, 377.089, 0.972
[epoch:176, iter:137591] Loss: 1.150, 8.352, 53.329, 377.091, 0.860
[epoch:176, iter:137611] Loss: 1.150, 8.352, 53.312, 376.997, 0.688
[epoch:176, iter:137631] Loss: 1.150, 8.354, 53.319, 377.070, 0.635
 * Acc@1 76.952 Acc@5 95.802
epoch 175, total time 61.39
Test: [0/313]	Time 0.232 (0.232)	Loss 1.1908 (1.1908)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.5392 (1.2417)	Acc@1 56.250 (68.843)	Acc@5 93.750 (91.708)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7445 (1.2181)	Acc@1 71.875 (68.890)	Acc@5 96.875 (91.667)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.6208 (1.2259)	Acc@1 50.000 (68.792)	Acc@5 93.750 (91.746)
 * Acc@1 68.950 Acc@5 91.830
==> training...
Epoch: [176][0/782]	Time 0.631 (0.631)	Data 0.537 (0.537)	Loss 10.1131 (10.1131)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
[epoch:177, iter:137633] Loss: 1.200, 8.632, 54.071, 380.808, 0.554
[epoch:177, iter:137653] Loss: 1.137, 8.322, 52.746, 374.843, 0.794
[epoch:177, iter:137673] Loss: 1.141, 8.284, 53.063, 376.401, 0.372
[epoch:177, iter:137693] Loss: 1.140, 8.279, 53.073, 376.140, 0.774
[epoch:177, iter:137713] Loss: 1.150, 8.288, 53.199, 376.180, 1.005
Epoch: [176][100/782]	Time 0.089 (0.087)	Data 0.003 (0.008)	Loss 10.1449 (10.0843)	Acc@1 75.000 (78.094)	Acc@5 96.875 (95.823)
[epoch:177, iter:137733] Loss: 1.150, 8.311, 53.282, 376.613, 0.741
[epoch:177, iter:137753] Loss: 1.151, 8.311, 53.292, 376.705, 0.568
[epoch:177, iter:137773] Loss: 1.150, 8.311, 53.183, 376.193, 0.493
[epoch:177, iter:137793] Loss: 1.148, 8.311, 53.189, 376.352, 0.554
[epoch:177, iter:137813] Loss: 1.150, 8.311, 53.186, 376.332, 1.090
Epoch: [176][200/782]	Time 0.096 (0.087)	Data 0.003 (0.005)	Loss 9.9532 (10.0811)	Acc@1 76.562 (77.760)	Acc@5 96.875 (95.701)
[epoch:177, iter:137833] Loss: 1.149, 8.315, 53.181, 376.371, 0.736
[epoch:177, iter:137853] Loss: 1.150, 8.325, 53.239, 376.659, 0.704
[epoch:177, iter:137873] Loss: 1.149, 8.322, 53.208, 376.630, 0.718
[epoch:177, iter:137893] Loss: 1.148, 8.320, 53.209, 376.673, 1.165
[epoch:177, iter:137913] Loss: 1.148, 8.327, 53.208, 376.756, 0.927
Epoch: [176][300/782]	Time 0.073 (0.087)	Data 0.002 (0.004)	Loss 10.3257 (10.1127)	Acc@1 76.562 (77.575)	Acc@5 95.312 (95.562)
[epoch:177, iter:137933] Loss: 1.149, 8.329, 53.200, 376.826, 0.961
[epoch:177, iter:137953] Loss: 1.150, 8.332, 53.226, 376.860, 0.969
[epoch:177, iter:137973] Loss: 1.150, 8.334, 53.257, 376.874, 0.798
[epoch:177, iter:137993] Loss: 1.149, 8.335, 53.229, 376.865, 0.569
[epoch:177, iter:138013] Loss: 1.150, 8.335, 53.228, 376.838, 0.894
Epoch: [176][400/782]	Time 0.079 (0.085)	Data 0.002 (0.004)	Loss 10.5728 (10.1280)	Acc@1 78.125 (77.272)	Acc@5 96.875 (95.566)
[epoch:177, iter:138033] Loss: 1.151, 8.340, 53.247, 376.964, 0.652
[epoch:177, iter:138053] Loss: 1.150, 8.344, 53.252, 377.065, 1.179
[epoch:177, iter:138073] Loss: 1.150, 8.346, 53.247, 377.044, 1.023
[epoch:177, iter:138093] Loss: 1.151, 8.350, 53.285, 377.202, 1.435
[epoch:177, iter:138113] Loss: 1.151, 8.355, 53.302, 377.313, 0.718
Epoch: [176][500/782]	Time 0.076 (0.083)	Data 0.002 (0.003)	Loss 9.9169 (10.1437)	Acc@1 84.375 (77.105)	Acc@5 96.875 (95.574)
[epoch:177, iter:138133] Loss: 1.151, 8.352, 53.294, 377.273, 0.548
[epoch:177, iter:138153] Loss: 1.152, 8.355, 53.305, 377.375, 0.804
[epoch:177, iter:138173] Loss: 1.152, 8.357, 53.320, 377.468, 0.564
[epoch:177, iter:138193] Loss: 1.151, 8.357, 53.306, 377.415, 0.621
[epoch:177, iter:138213] Loss: 1.151, 8.357, 53.319, 377.484, 0.716
Epoch: [176][600/782]	Time 0.091 (0.083)	Data 0.003 (0.003)	Loss 10.1450 (10.1519)	Acc@1 75.000 (77.088)	Acc@5 98.438 (95.650)
[epoch:177, iter:138233] Loss: 1.151, 8.360, 53.323, 377.486, 0.764
[epoch:177, iter:138253] Loss: 1.152, 8.360, 53.323, 377.478, 0.521
[epoch:177, iter:138273] Loss: 1.152, 8.357, 53.318, 377.437, 0.455
[epoch:177, iter:138293] Loss: 1.152, 8.355, 53.322, 377.417, 0.865
[epoch:177, iter:138313] Loss: 1.152, 8.358, 53.340, 377.466, 0.561
Epoch: [176][700/782]	Time 0.095 (0.083)	Data 0.003 (0.003)	Loss 11.0513 (10.1572)	Acc@1 71.875 (77.089)	Acc@5 93.750 (95.613)
[epoch:177, iter:138333] Loss: 1.152, 8.358, 53.353, 377.471, 0.932
[epoch:177, iter:138353] Loss: 1.153, 8.358, 53.362, 377.486, 0.863
[epoch:177, iter:138373] Loss: 1.153, 8.357, 53.361, 377.483, 0.861
[epoch:177, iter:138393] Loss: 1.153, 8.358, 53.374, 377.536, 1.159
[epoch:177, iter:138413] Loss: 1.153, 8.359, 53.380, 377.535, 0.605
 * Acc@1 76.998 Acc@5 95.604
epoch 176, total time 65.08
Test: [0/313]	Time 0.204 (0.204)	Loss 1.3521 (1.3521)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3155 (1.2625)	Acc@1 62.500 (68.472)	Acc@5 96.875 (91.460)
Test: [200/313]	Time 0.010 (0.008)	Loss 0.9452 (1.2241)	Acc@1 71.875 (69.123)	Acc@5 100.000 (91.962)
Test: [300/313]	Time 0.009 (0.008)	Loss 1.6107 (1.2291)	Acc@1 62.500 (69.207)	Acc@5 90.625 (92.016)
 * Acc@1 69.230 Acc@5 92.080
==> training...
Epoch: [177][0/782]	Time 0.555 (0.555)	Data 0.459 (0.459)	Loss 10.5246 (10.5246)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
[epoch:178, iter:138415] Loss: 1.133, 8.301, 54.837, 383.529, 0.801
[epoch:178, iter:138435] Loss: 1.138, 8.365, 53.531, 378.034, 0.907
[epoch:178, iter:138455] Loss: 1.151, 8.379, 53.446, 377.683, 0.756
[epoch:178, iter:138475] Loss: 1.146, 8.358, 53.357, 377.378, 0.852
[epoch:178, iter:138495] Loss: 1.149, 8.371, 53.403, 377.588, 0.273
Epoch: [177][100/782]	Time 0.064 (0.086)	Data 0.002 (0.007)	Loss 10.2601 (10.1286)	Acc@1 79.688 (77.058)	Acc@5 90.625 (96.086)
[epoch:178, iter:138515] Loss: 1.147, 8.365, 53.325, 377.280, 0.908
[epoch:178, iter:138535] Loss: 1.148, 8.363, 53.309, 377.287, 0.932
[epoch:178, iter:138555] Loss: 1.148, 8.364, 53.319, 377.431, 0.619
[epoch:178, iter:138575] Loss: 1.148, 8.352, 53.272, 377.183, 0.782
[epoch:178, iter:138595] Loss: 1.149, 8.348, 53.266, 377.162, 0.846
Epoch: [177][200/782]	Time 0.095 (0.086)	Data 0.003 (0.005)	Loss 10.1431 (10.1273)	Acc@1 79.688 (76.671)	Acc@5 96.875 (95.872)
[epoch:178, iter:138615] Loss: 1.150, 8.352, 53.247, 376.965, 0.647
[epoch:178, iter:138635] Loss: 1.150, 8.355, 53.268, 377.026, 0.779
[epoch:178, iter:138655] Loss: 1.151, 8.355, 53.263, 377.029, 1.025
[epoch:178, iter:138675] Loss: 1.151, 8.358, 53.242, 376.960, 0.759
[epoch:178, iter:138695] Loss: 1.150, 8.360, 53.275, 377.139, 0.900
Epoch: [177][300/782]	Time 0.076 (0.084)	Data 0.002 (0.004)	Loss 9.8555 (10.1424)	Acc@1 81.250 (76.900)	Acc@5 98.438 (95.852)
[epoch:178, iter:138715] Loss: 1.151, 8.362, 53.335, 377.367, 0.535
[epoch:178, iter:138735] Loss: 1.151, 8.364, 53.354, 377.380, 0.868
[epoch:178, iter:138755] Loss: 1.150, 8.364, 53.318, 377.305, 0.548
[epoch:178, iter:138775] Loss: 1.149, 8.362, 53.316, 377.240, 0.654
[epoch:178, iter:138795] Loss: 1.150, 8.358, 53.340, 377.247, 0.685
Epoch: [177][400/782]	Time 0.088 (0.084)	Data 0.003 (0.004)	Loss 9.8016 (10.1406)	Acc@1 70.312 (77.014)	Acc@5 96.875 (95.885)
[epoch:178, iter:138815] Loss: 1.149, 8.359, 53.341, 377.304, 0.746
[epoch:178, iter:138835] Loss: 1.150, 8.358, 53.353, 377.295, 0.832
[epoch:178, iter:138855] Loss: 1.150, 8.357, 53.347, 377.205, 1.089
[epoch:178, iter:138875] Loss: 1.150, 8.361, 53.345, 377.186, 1.137
[epoch:178, iter:138895] Loss: 1.150, 8.361, 53.371, 377.272, 0.983
Epoch: [177][500/782]	Time 0.070 (0.083)	Data 0.002 (0.003)	Loss 9.7312 (10.1492)	Acc@1 82.812 (76.959)	Acc@5 100.000 (95.774)
[epoch:178, iter:138915] Loss: 1.150, 8.363, 53.374, 377.308, 0.431
[epoch:178, iter:138935] Loss: 1.150, 8.365, 53.399, 377.417, 0.788
[epoch:178, iter:138955] Loss: 1.151, 8.363, 53.382, 377.303, 0.679
[epoch:178, iter:138975] Loss: 1.151, 8.363, 53.366, 377.247, 0.551
[epoch:178, iter:138995] Loss: 1.151, 8.362, 53.373, 377.245, 0.777
Epoch: [177][600/782]	Time 0.073 (0.083)	Data 0.002 (0.003)	Loss 10.0408 (10.1593)	Acc@1 76.562 (76.791)	Acc@5 98.438 (95.749)
[epoch:178, iter:139015] Loss: 1.151, 8.365, 53.376, 377.300, 0.711
[epoch:178, iter:139035] Loss: 1.151, 8.365, 53.390, 377.391, 0.884
[epoch:178, iter:139055] Loss: 1.151, 8.365, 53.411, 377.461, 0.878
[epoch:178, iter:139075] Loss: 1.151, 8.367, 53.411, 377.540, 0.655
[epoch:178, iter:139095] Loss: 1.152, 8.367, 53.424, 377.624, 0.544
Epoch: [177][700/782]	Time 0.093 (0.083)	Data 0.003 (0.003)	Loss 9.9685 (10.1786)	Acc@1 76.562 (76.776)	Acc@5 98.438 (95.703)
[epoch:178, iter:139115] Loss: 1.152, 8.369, 53.442, 377.714, 0.697
[epoch:178, iter:139135] Loss: 1.152, 8.371, 53.440, 377.738, 0.845
[epoch:178, iter:139155] Loss: 1.152, 8.372, 53.442, 377.742, 0.751
[epoch:178, iter:139175] Loss: 1.152, 8.373, 53.444, 377.715, 1.037
[epoch:178, iter:139195] Loss: 1.152, 8.372, 53.433, 377.651, 0.666
 * Acc@1 76.702 Acc@5 95.680
epoch 177, total time 64.91
Test: [0/313]	Time 0.293 (0.293)	Loss 1.4818 (1.4818)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2194 (1.2540)	Acc@1 56.250 (69.400)	Acc@5 93.750 (91.399)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.6960 (1.2092)	Acc@1 78.125 (69.496)	Acc@5 96.875 (91.947)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.3578 (1.2283)	Acc@1 59.375 (69.072)	Acc@5 96.875 (91.757)
 * Acc@1 69.210 Acc@5 91.790
==> training...
Epoch: [178][0/782]	Time 0.567 (0.567)	Data 0.477 (0.477)	Loss 10.2571 (10.2571)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
[epoch:179, iter:139197] Loss: 1.166, 8.486, 54.359, 382.114, 0.703
[epoch:179, iter:139217] Loss: 1.140, 8.296, 52.843, 375.371, 0.804
[epoch:179, iter:139237] Loss: 1.139, 8.323, 53.068, 376.552, 0.836
[epoch:179, iter:139257] Loss: 1.147, 8.330, 53.201, 376.543, 0.636
[epoch:179, iter:139277] Loss: 1.149, 8.338, 53.409, 377.513, 0.972
Epoch: [178][100/782]	Time 0.090 (0.087)	Data 0.003 (0.007)	Loss 9.8947 (10.1278)	Acc@1 78.125 (77.135)	Acc@5 98.438 (95.823)
[epoch:179, iter:139297] Loss: 1.152, 8.339, 53.389, 377.175, 0.454
[epoch:179, iter:139317] Loss: 1.152, 8.349, 53.385, 377.083, 0.549
[epoch:179, iter:139337] Loss: 1.151, 8.348, 53.418, 377.070, 0.618
[epoch:179, iter:139357] Loss: 1.148, 8.349, 53.303, 376.696, 0.977
[epoch:179, iter:139377] Loss: 1.150, 8.353, 53.282, 376.791, 0.439
Epoch: [178][200/782]	Time 0.094 (0.085)	Data 0.003 (0.005)	Loss 9.2481 (10.0833)	Acc@1 84.375 (77.581)	Acc@5 98.438 (95.857)
[epoch:179, iter:139397] Loss: 1.148, 8.362, 53.234, 376.711, 0.489
[epoch:179, iter:139417] Loss: 1.148, 8.370, 53.230, 376.701, 0.758
[epoch:179, iter:139437] Loss: 1.149, 8.368, 53.193, 376.495, 0.494
[epoch:179, iter:139457] Loss: 1.149, 8.370, 53.186, 376.478, 0.475
[epoch:179, iter:139477] Loss: 1.149, 8.367, 53.176, 376.441, 0.753
Epoch: [178][300/782]	Time 0.076 (0.084)	Data 0.002 (0.004)	Loss 10.8865 (10.0969)	Acc@1 75.000 (77.585)	Acc@5 95.312 (95.780)
[epoch:179, iter:139497] Loss: 1.150, 8.366, 53.227, 376.661, 0.877
[epoch:179, iter:139517] Loss: 1.150, 8.367, 53.227, 376.670, 0.865
[epoch:179, iter:139537] Loss: 1.150, 8.367, 53.254, 376.762, 0.528
[epoch:179, iter:139557] Loss: 1.150, 8.367, 53.263, 376.804, 0.962
[epoch:179, iter:139577] Loss: 1.151, 8.367, 53.267, 376.805, 0.543
Epoch: [178][400/782]	Time 0.094 (0.084)	Data 0.003 (0.004)	Loss 9.9690 (10.1033)	Acc@1 71.875 (77.657)	Acc@5 96.875 (95.819)
[epoch:179, iter:139597] Loss: 1.150, 8.368, 53.262, 376.834, 0.843
[epoch:179, iter:139617] Loss: 1.151, 8.368, 53.267, 376.956, 0.564
[epoch:179, iter:139637] Loss: 1.150, 8.366, 53.274, 376.958, 0.720
[epoch:179, iter:139657] Loss: 1.150, 8.369, 53.269, 377.007, 0.363
[epoch:179, iter:139677] Loss: 1.150, 8.369, 53.238, 376.936, 0.492
Epoch: [178][500/782]	Time 0.069 (0.084)	Data 0.002 (0.003)	Loss 10.1879 (10.1091)	Acc@1 75.000 (77.557)	Acc@5 96.875 (95.855)
[epoch:179, iter:139697] Loss: 1.151, 8.368, 53.265, 377.038, 0.901
[epoch:179, iter:139717] Loss: 1.150, 8.366, 53.270, 377.052, 0.545
[epoch:179, iter:139737] Loss: 1.151, 8.365, 53.265, 377.016, 0.462
[epoch:179, iter:139757] Loss: 1.151, 8.366, 53.277, 377.107, 0.857
[epoch:179, iter:139777] Loss: 1.151, 8.367, 53.294, 377.175, 0.966
Epoch: [178][600/782]	Time 0.086 (0.083)	Data 0.003 (0.003)	Loss 11.1614 (10.1288)	Acc@1 68.750 (77.361)	Acc@5 89.062 (95.861)
[epoch:179, iter:139797] Loss: 1.152, 8.367, 53.313, 377.237, 1.179
[epoch:179, iter:139817] Loss: 1.152, 8.369, 53.317, 377.267, 0.806
[epoch:179, iter:139837] Loss: 1.152, 8.369, 53.318, 377.306, 0.775
[epoch:179, iter:139857] Loss: 1.152, 8.369, 53.319, 377.290, 0.713
[epoch:179, iter:139877] Loss: 1.152, 8.373, 53.319, 377.250, 0.943
Epoch: [178][700/782]	Time 0.090 (0.082)	Data 0.003 (0.003)	Loss 10.1583 (10.1424)	Acc@1 75.000 (77.216)	Acc@5 93.750 (95.827)
[epoch:179, iter:139897] Loss: 1.152, 8.372, 53.329, 377.305, 0.768
[epoch:179, iter:139917] Loss: 1.151, 8.373, 53.325, 377.308, 0.882
[epoch:179, iter:139937] Loss: 1.152, 8.372, 53.334, 377.323, 0.893
[epoch:179, iter:139957] Loss: 1.152, 8.372, 53.335, 377.318, 0.907
[epoch:179, iter:139977] Loss: 1.152, 8.371, 53.333, 377.292, 0.955
 * Acc@1 77.148 Acc@5 95.798
epoch 178, total time 64.56
Test: [0/313]	Time 0.245 (0.245)	Loss 1.5131 (1.5131)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3544 (1.2614)	Acc@1 62.500 (68.936)	Acc@5 96.875 (91.027)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7372 (1.2318)	Acc@1 71.875 (68.626)	Acc@5 96.875 (91.651)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.6461 (1.2453)	Acc@1 59.375 (68.252)	Acc@5 90.625 (91.559)
 * Acc@1 68.390 Acc@5 91.620
==> training...
Epoch: [179][0/782]	Time 0.493 (0.493)	Data 0.431 (0.431)	Loss 9.8360 (9.8360)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)
[epoch:180, iter:139979] Loss: 1.163, 8.119, 53.948, 377.543, 0.601
[epoch:180, iter:139999] Loss: 1.151, 8.330, 53.649, 377.893, 0.646
[epoch:180, iter:140019] Loss: 1.146, 8.334, 53.338, 376.775, 0.924
[epoch:180, iter:140039] Loss: 1.149, 8.330, 53.251, 375.982, 0.921
[epoch:180, iter:140059] Loss: 1.145, 8.340, 53.236, 375.997, 0.649
Epoch: [179][100/782]	Time 0.092 (0.086)	Data 0.003 (0.007)	Loss 9.4916 (10.0794)	Acc@1 81.250 (77.939)	Acc@5 100.000 (96.287)
[epoch:180, iter:140079] Loss: 1.144, 8.345, 53.303, 376.412, 0.505
[epoch:180, iter:140099] Loss: 1.143, 8.346, 53.290, 376.479, 0.645
[epoch:180, iter:140119] Loss: 1.146, 8.347, 53.276, 376.471, 0.756
[epoch:180, iter:140139] Loss: 1.146, 8.346, 53.248, 376.384, 0.639
[epoch:180, iter:140159] Loss: 1.145, 8.342, 53.255, 376.493, 0.796
Epoch: [179][200/782]	Time 0.066 (0.085)	Data 0.002 (0.005)	Loss 10.5628 (10.0890)	Acc@1 71.875 (77.853)	Acc@5 93.750 (96.051)
[epoch:180, iter:140179] Loss: 1.146, 8.353, 53.299, 376.782, 0.871
[epoch:180, iter:140199] Loss: 1.147, 8.359, 53.339, 376.812, 0.825
[epoch:180, iter:140219] Loss: 1.147, 8.358, 53.287, 376.679, 0.743
[epoch:180, iter:140239] Loss: 1.147, 8.359, 53.263, 376.649, 1.097
[epoch:180, iter:140259] Loss: 1.148, 8.367, 53.246, 376.724, 1.032
Epoch: [179][300/782]	Time 0.092 (0.086)	Data 0.003 (0.004)	Loss 10.0354 (10.1036)	Acc@1 78.125 (77.762)	Acc@5 96.875 (95.894)
[epoch:180, iter:140279] Loss: 1.148, 8.370, 53.266, 376.781, 0.729
[epoch:180, iter:140299] Loss: 1.149, 8.374, 53.298, 376.967, 0.369
[epoch:180, iter:140319] Loss: 1.150, 8.375, 53.322, 376.999, 0.688
[epoch:180, iter:140339] Loss: 1.151, 8.374, 53.336, 377.040, 0.598
[epoch:180, iter:140359] Loss: 1.152, 8.373, 53.336, 377.066, 0.573
Epoch: [179][400/782]	Time 0.086 (0.086)	Data 0.003 (0.004)	Loss 9.9816 (10.1326)	Acc@1 76.562 (77.322)	Acc@5 98.438 (95.913)
[epoch:180, iter:140379] Loss: 1.153, 8.378, 53.354, 377.145, 0.574
[epoch:180, iter:140399] Loss: 1.153, 8.377, 53.371, 377.312, 0.626
[epoch:180, iter:140419] Loss: 1.153, 8.373, 53.355, 377.229, 0.645
[epoch:180, iter:140439] Loss: 1.153, 8.371, 53.370, 377.277, 0.933
[epoch:180, iter:140459] Loss: 1.152, 8.370, 53.367, 377.334, 0.799
Epoch: [179][500/782]	Time 0.070 (0.085)	Data 0.002 (0.003)	Loss 10.5136 (10.1371)	Acc@1 75.000 (77.261)	Acc@5 93.750 (95.861)
[epoch:180, iter:140479] Loss: 1.153, 8.369, 53.361, 377.325, 0.701
[epoch:180, iter:140499] Loss: 1.153, 8.369, 53.375, 377.378, 1.014
[epoch:180, iter:140519] Loss: 1.153, 8.368, 53.383, 377.385, 0.834
[epoch:180, iter:140539] Loss: 1.153, 8.369, 53.383, 377.375, 0.613
[epoch:180, iter:140559] Loss: 1.153, 8.371, 53.399, 377.463, 0.786
Epoch: [179][600/782]	Time 0.095 (0.084)	Data 0.003 (0.003)	Loss 9.9861 (10.1609)	Acc@1 78.125 (77.036)	Acc@5 95.312 (95.765)
[epoch:180, iter:140579] Loss: 1.153, 8.372, 53.425, 377.574, 0.751
[epoch:180, iter:140599] Loss: 1.154, 8.370, 53.431, 377.601, 0.473
[epoch:180, iter:140619] Loss: 1.154, 8.370, 53.425, 377.586, 1.242
[epoch:180, iter:140639] Loss: 1.154, 8.372, 53.430, 377.634, 0.738
[epoch:180, iter:140659] Loss: 1.153, 8.371, 53.430, 377.579, 0.543
Epoch: [179][700/782]	Time 0.093 (0.084)	Data 0.003 (0.003)	Loss 9.8222 (10.1627)	Acc@1 76.562 (77.091)	Acc@5 98.438 (95.756)
[epoch:180, iter:140679] Loss: 1.153, 8.373, 53.426, 377.551, 0.627
[epoch:180, iter:140699] Loss: 1.153, 8.374, 53.416, 377.506, 0.687
[epoch:180, iter:140719] Loss: 1.154, 8.373, 53.423, 377.545, 0.891
[epoch:180, iter:140739] Loss: 1.154, 8.377, 53.438, 377.623, 0.570
[epoch:180, iter:140759] Loss: 1.154, 8.378, 53.455, 377.698, 0.554
 * Acc@1 76.996 Acc@5 95.722
epoch 179, total time 65.69
Test: [0/313]	Time 0.281 (0.281)	Loss 1.2659 (1.2659)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.011)	Loss 1.5156 (1.2981)	Acc@1 56.250 (68.502)	Acc@5 96.875 (91.151)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.5624 (1.2632)	Acc@1 81.250 (68.548)	Acc@5 96.875 (91.604)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.3532 (1.2689)	Acc@1 62.500 (68.200)	Acc@5 90.625 (91.539)
 * Acc@1 68.280 Acc@5 91.580
==> training...
Epoch: [180][0/782]	Time 0.615 (0.615)	Data 0.540 (0.540)	Loss 10.6197 (10.6197)	Acc@1 73.438 (73.438)	Acc@5 93.750 (93.750)
[epoch:181, iter:140761] Loss: 1.123, 8.722, 54.609, 386.825, 0.849
[epoch:181, iter:140781] Loss: 1.157, 8.379, 53.729, 377.973, 0.907
[epoch:181, iter:140801] Loss: 1.156, 8.335, 53.513, 377.162, 0.531
[epoch:181, iter:140821] Loss: 1.159, 8.366, 53.496, 377.546, 0.585
[epoch:181, iter:140841] Loss: 1.157, 8.358, 53.299, 376.650, 0.535
Epoch: [180][100/782]	Time 0.092 (0.091)	Data 0.002 (0.008)	Loss 10.1544 (10.1018)	Acc@1 76.562 (77.413)	Acc@5 95.312 (96.210)
[epoch:181, iter:140861] Loss: 1.156, 8.356, 53.287, 376.587, 0.860
[epoch:181, iter:140881] Loss: 1.157, 8.367, 53.301, 376.689, 0.824
[epoch:181, iter:140901] Loss: 1.155, 8.378, 53.371, 377.094, 0.941
[epoch:181, iter:140921] Loss: 1.156, 8.385, 53.376, 377.266, 0.855
[epoch:181, iter:140941] Loss: 1.155, 8.382, 53.394, 377.326, 0.860
Epoch: [180][200/782]	Time 0.066 (0.087)	Data 0.002 (0.005)	Loss 10.0374 (10.1414)	Acc@1 73.438 (77.099)	Acc@5 96.875 (96.051)
[epoch:181, iter:140961] Loss: 1.156, 8.377, 53.370, 377.023, 0.792
[epoch:181, iter:140981] Loss: 1.155, 8.368, 53.352, 376.929, 0.777
[epoch:181, iter:141001] Loss: 1.157, 8.369, 53.371, 377.033, 1.161
[epoch:181, iter:141021] Loss: 1.155, 8.371, 53.369, 377.024, 0.439
[epoch:181, iter:141041] Loss: 1.157, 8.371, 53.380, 376.977, 0.584
Epoch: [180][300/782]	Time 0.090 (0.085)	Data 0.003 (0.004)	Loss 10.4883 (10.1416)	Acc@1 70.312 (77.092)	Acc@5 95.312 (96.034)
[epoch:181, iter:141061] Loss: 1.157, 8.373, 53.380, 377.045, 1.092
[epoch:181, iter:141081] Loss: 1.157, 8.374, 53.384, 377.068, 0.941
[epoch:181, iter:141101] Loss: 1.156, 8.372, 53.366, 377.061, 0.598
[epoch:181, iter:141121] Loss: 1.156, 8.370, 53.371, 377.210, 0.902
[epoch:181, iter:141141] Loss: 1.157, 8.371, 53.407, 377.362, 0.905
Epoch: [180][400/782]	Time 0.076 (0.084)	Data 0.002 (0.004)	Loss 9.6806 (10.1637)	Acc@1 82.812 (76.827)	Acc@5 98.438 (95.835)
[epoch:181, iter:141161] Loss: 1.157, 8.374, 53.420, 377.322, 0.545
[epoch:181, iter:141181] Loss: 1.157, 8.375, 53.409, 377.316, 0.526
[epoch:181, iter:141201] Loss: 1.156, 8.374, 53.386, 377.281, 0.820
[epoch:181, iter:141221] Loss: 1.156, 8.375, 53.378, 377.309, 1.009
[epoch:181, iter:141241] Loss: 1.156, 8.374, 53.373, 377.312, 0.411
Epoch: [180][500/782]	Time 0.088 (0.083)	Data 0.003 (0.003)	Loss 9.9941 (10.1557)	Acc@1 78.125 (76.906)	Acc@5 93.750 (95.843)
[epoch:181, iter:141261] Loss: 1.156, 8.373, 53.370, 377.355, 0.662
[epoch:181, iter:141281] Loss: 1.156, 8.375, 53.388, 377.422, 0.877
[epoch:181, iter:141301] Loss: 1.156, 8.373, 53.376, 377.360, 0.650
[epoch:181, iter:141321] Loss: 1.156, 8.373, 53.393, 377.444, 0.764
[epoch:181, iter:141341] Loss: 1.156, 8.373, 53.383, 377.433, 0.756
Epoch: [180][600/782]	Time 0.093 (0.082)	Data 0.004 (0.003)	Loss 10.8713 (10.1670)	Acc@1 60.938 (76.739)	Acc@5 96.875 (95.757)
[epoch:181, iter:141361] Loss: 1.156, 8.372, 53.380, 377.412, 1.028
[epoch:181, iter:141381] Loss: 1.156, 8.373, 53.370, 377.387, 0.556
[epoch:181, iter:141401] Loss: 1.156, 8.373, 53.359, 377.358, 0.562
[epoch:181, iter:141421] Loss: 1.156, 8.372, 53.363, 377.378, 0.828
[epoch:181, iter:141441] Loss: 1.156, 8.371, 53.365, 377.378, 0.596
Epoch: [180][700/782]	Time 0.071 (0.082)	Data 0.002 (0.003)	Loss 10.0605 (10.1613)	Acc@1 78.125 (76.812)	Acc@5 96.875 (95.785)
[epoch:181, iter:141461] Loss: 1.156, 8.368, 53.361, 377.336, 0.583
[epoch:181, iter:141481] Loss: 1.156, 8.368, 53.376, 377.382, 0.676
[epoch:181, iter:141501] Loss: 1.156, 8.368, 53.391, 377.465, 0.532
[epoch:181, iter:141521] Loss: 1.156, 8.369, 53.383, 377.438, 0.542
[epoch:181, iter:141541] Loss: 1.156, 8.367, 53.389, 377.481, 1.078
 * Acc@1 76.668 Acc@5 95.726
epoch 180, total time 64.00
Test: [0/313]	Time 0.213 (0.213)	Loss 1.5412 (1.5412)	Acc@1 71.875 (71.875)	Acc@5 78.125 (78.125)
Test: [100/313]	Time 0.007 (0.008)	Loss 1.4246 (1.3141)	Acc@1 56.250 (68.224)	Acc@5 96.875 (91.058)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7645 (1.2667)	Acc@1 78.125 (68.703)	Acc@5 93.750 (91.465)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4947 (1.2740)	Acc@1 56.250 (68.605)	Acc@5 93.750 (91.393)
 * Acc@1 68.710 Acc@5 91.440
==> training...
Epoch: [181][0/782]	Time 0.588 (0.588)	Data 0.496 (0.496)	Loss 9.4498 (9.4498)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
[epoch:182, iter:141543] Loss: 1.156, 8.070, 52.004, 368.629, 0.345
[epoch:182, iter:141563] Loss: 1.158, 8.251, 52.680, 375.280, 0.421
[epoch:182, iter:141583] Loss: 1.142, 8.258, 52.489, 374.860, 0.555
[epoch:182, iter:141603] Loss: 1.141, 8.213, 52.174, 373.487, 0.540
[epoch:182, iter:141623] Loss: 1.133, 8.225, 52.010, 373.296, 0.553
Epoch: [181][100/782]	Time 0.093 (0.093)	Data 0.003 (0.008)	Loss 9.5220 (9.8057)	Acc@1 73.438 (79.254)	Acc@5 95.312 (96.736)
[epoch:182, iter:141643] Loss: 1.133, 8.243, 51.894, 372.687, 0.824
[epoch:182, iter:141663] Loss: 1.133, 8.238, 51.802, 372.232, 0.598
[epoch:182, iter:141683] Loss: 1.132, 8.236, 51.736, 371.952, 0.802
[epoch:182, iter:141703] Loss: 1.131, 8.227, 51.754, 371.953, 0.735
[epoch:182, iter:141723] Loss: 1.131, 8.215, 51.744, 372.081, 0.679
Epoch: [181][200/782]	Time 0.070 (0.089)	Data 0.002 (0.005)	Loss 9.5486 (9.7805)	Acc@1 82.812 (79.260)	Acc@5 98.438 (96.533)
[epoch:182, iter:141743] Loss: 1.130, 8.205, 51.706, 371.891, 0.549
[epoch:182, iter:141763] Loss: 1.130, 8.209, 51.661, 371.665, 0.975
[epoch:182, iter:141783] Loss: 1.130, 8.204, 51.634, 371.623, 0.643
[epoch:182, iter:141803] Loss: 1.130, 8.210, 51.610, 371.578, 0.554
[epoch:182, iter:141823] Loss: 1.129, 8.208, 51.592, 371.588, 1.056
Epoch: [181][300/782]	Time 0.066 (0.087)	Data 0.002 (0.004)	Loss 8.9962 (9.7700)	Acc@1 85.938 (78.997)	Acc@5 98.438 (96.340)
[epoch:182, iter:141843] Loss: 1.127, 8.207, 51.569, 371.471, 0.519
[epoch:182, iter:141863] Loss: 1.128, 8.202, 51.565, 371.452, 0.511
[epoch:182, iter:141883] Loss: 1.129, 8.204, 51.552, 371.490, 0.379
[epoch:182, iter:141903] Loss: 1.129, 8.201, 51.512, 371.256, 0.526
[epoch:182, iter:141923] Loss: 1.129, 8.201, 51.484, 371.116, 0.843
Epoch: [181][400/782]	Time 0.087 (0.085)	Data 0.002 (0.004)	Loss 9.1719 (9.7394)	Acc@1 75.000 (79.123)	Acc@5 98.438 (96.404)
[epoch:182, iter:141943] Loss: 1.128, 8.198, 51.454, 371.014, 0.640
[epoch:182, iter:141963] Loss: 1.128, 8.201, 51.444, 370.911, 0.585
[epoch:182, iter:141983] Loss: 1.127, 8.203, 51.422, 370.845, 0.982
[epoch:182, iter:142003] Loss: 1.127, 8.201, 51.416, 370.828, 0.620
[epoch:182, iter:142023] Loss: 1.127, 8.198, 51.387, 370.659, 0.838
Epoch: [181][500/782]	Time 0.077 (0.084)	Data 0.002 (0.003)	Loss 9.4334 (9.7258)	Acc@1 87.500 (79.101)	Acc@5 98.438 (96.420)
[epoch:182, iter:142043] Loss: 1.127, 8.197, 51.371, 370.569, 0.475
[epoch:182, iter:142063] Loss: 1.127, 8.195, 51.354, 370.486, 0.589
[epoch:182, iter:142083] Loss: 1.126, 8.194, 51.351, 370.471, 0.765
[epoch:182, iter:142103] Loss: 1.126, 8.193, 51.342, 370.444, 0.813
[epoch:182, iter:142123] Loss: 1.125, 8.191, 51.343, 370.422, 0.648
Epoch: [181][600/782]	Time 0.089 (0.083)	Data 0.003 (0.003)	Loss 9.5076 (9.7142)	Acc@1 82.812 (79.188)	Acc@5 98.438 (96.423)
[epoch:182, iter:142143] Loss: 1.125, 8.192, 51.341, 370.444, 0.590
[epoch:182, iter:142163] Loss: 1.125, 8.193, 51.349, 370.495, 0.437
[epoch:182, iter:142183] Loss: 1.126, 8.193, 51.355, 370.485, 0.615
[epoch:182, iter:142203] Loss: 1.125, 8.192, 51.338, 370.412, 0.635
[epoch:182, iter:142223] Loss: 1.125, 8.192, 51.345, 370.450, 0.527
Epoch: [181][700/782]	Time 0.091 (0.083)	Data 0.003 (0.003)	Loss 9.6285 (9.7119)	Acc@1 78.125 (79.186)	Acc@5 98.438 (96.398)
[epoch:182, iter:142243] Loss: 1.125, 8.191, 51.332, 370.369, 0.590
[epoch:182, iter:142263] Loss: 1.125, 8.191, 51.329, 370.356, 0.724
[epoch:182, iter:142283] Loss: 1.124, 8.187, 51.321, 370.320, 0.731
[epoch:182, iter:142303] Loss: 1.124, 8.188, 51.316, 370.287, 0.683
[epoch:182, iter:142323] Loss: 1.124, 8.186, 51.309, 370.240, 0.432
 * Acc@1 79.152 Acc@5 96.412
epoch 181, total time 64.68
Test: [0/313]	Time 0.267 (0.267)	Loss 1.3355 (1.3355)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.009)	Loss 1.3639 (1.1741)	Acc@1 59.375 (70.514)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.008 (0.008)	Loss 0.6663 (1.1378)	Acc@1 81.250 (71.238)	Acc@5 93.750 (92.506)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.4650 (1.1522)	Acc@1 62.500 (70.816)	Acc@5 96.875 (92.587)
 * Acc@1 70.920 Acc@5 92.650
saving the best model!
==> training...
Epoch: [182][0/782]	Time 0.507 (0.507)	Data 0.413 (0.413)	Loss 9.6103 (9.6103)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
[epoch:183, iter:142325] Loss: 1.095, 8.074, 50.375, 366.562, 0.760
[epoch:183, iter:142345] Loss: 1.124, 8.138, 50.803, 367.460, 0.371
[epoch:183, iter:142365] Loss: 1.121, 8.141, 50.979, 368.810, 0.590
[epoch:183, iter:142385] Loss: 1.119, 8.161, 50.985, 368.708, 0.897
[epoch:183, iter:142405] Loss: 1.119, 8.160, 51.039, 369.276, 0.576
Epoch: [182][100/782]	Time 0.068 (0.083)	Data 0.002 (0.006)	Loss 9.9108 (9.6297)	Acc@1 68.750 (79.873)	Acc@5 95.312 (96.581)
[epoch:183, iter:142425] Loss: 1.118, 8.151, 51.003, 368.974, 1.003
[epoch:183, iter:142445] Loss: 1.119, 8.144, 51.009, 368.975, 0.521
[epoch:183, iter:142465] Loss: 1.118, 8.142, 50.992, 368.985, 0.713
[epoch:183, iter:142485] Loss: 1.116, 8.156, 50.999, 369.182, 0.958
[epoch:183, iter:142505] Loss: 1.114, 8.145, 50.966, 369.028, 0.506
Epoch: [182][200/782]	Time 0.089 (0.080)	Data 0.002 (0.004)	Loss 8.9577 (9.5998)	Acc@1 90.625 (80.131)	Acc@5 96.875 (96.650)
[epoch:183, iter:142525] Loss: 1.115, 8.137, 50.957, 368.885, 0.433
[epoch:183, iter:142545] Loss: 1.115, 8.132, 50.941, 368.715, 0.830
[epoch:183, iter:142565] Loss: 1.116, 8.129, 50.926, 368.499, 0.694
[epoch:183, iter:142585] Loss: 1.115, 8.131, 50.884, 368.365, 0.544
[epoch:183, iter:142605] Loss: 1.115, 8.125, 50.875, 368.188, 0.876
Epoch: [182][300/782]	Time 0.091 (0.077)	Data 0.003 (0.004)	Loss 9.8982 (9.5776)	Acc@1 76.562 (80.015)	Acc@5 96.875 (96.730)
[epoch:183, iter:142625] Loss: 1.114, 8.128, 50.871, 368.190, 0.683
[epoch:183, iter:142645] Loss: 1.115, 8.125, 50.851, 368.081, 0.711
[epoch:183, iter:142665] Loss: 1.115, 8.127, 50.840, 368.004, 0.778
[epoch:183, iter:142685] Loss: 1.115, 8.128, 50.848, 367.964, 0.742
[epoch:183, iter:142705] Loss: 1.115, 8.129, 50.849, 367.896, 0.701
Epoch: [182][400/782]	Time 0.079 (0.079)	Data 0.002 (0.003)	Loss 10.0703 (9.5740)	Acc@1 76.562 (79.972)	Acc@5 95.312 (96.672)
[epoch:183, iter:142725] Loss: 1.114, 8.124, 50.846, 367.817, 1.012
[epoch:183, iter:142745] Loss: 1.114, 8.122, 50.859, 367.868, 0.470
[epoch:183, iter:142765] Loss: 1.114, 8.121, 50.852, 367.815, 0.833
[epoch:183, iter:142785] Loss: 1.114, 8.120, 50.866, 367.924, 0.708
[epoch:183, iter:142805] Loss: 1.114, 8.125, 50.875, 367.999, 0.545
Epoch: [182][500/782]	Time 0.089 (0.079)	Data 0.003 (0.003)	Loss 10.0727 (9.5899)	Acc@1 73.438 (79.856)	Acc@5 98.438 (96.551)
[epoch:183, iter:142825] Loss: 1.114, 8.123, 50.875, 367.960, 0.725
[epoch:183, iter:142845] Loss: 1.114, 8.121, 50.863, 367.869, 0.585
[epoch:183, iter:142865] Loss: 1.115, 8.123, 50.876, 367.987, 0.751
[epoch:183, iter:142885] Loss: 1.115, 8.124, 50.869, 367.959, 1.027
[epoch:183, iter:142905] Loss: 1.114, 8.125, 50.851, 367.920, 0.644
Epoch: [182][600/782]	Time 0.070 (0.080)	Data 0.002 (0.003)	Loss 9.1021 (9.5830)	Acc@1 85.938 (79.846)	Acc@5 96.875 (96.516)
[epoch:183, iter:142925] Loss: 1.114, 8.123, 50.847, 367.903, 0.610
[epoch:183, iter:142945] Loss: 1.113, 8.126, 50.846, 367.954, 0.614
[epoch:183, iter:142965] Loss: 1.114, 8.128, 50.844, 367.937, 0.512
[epoch:183, iter:142985] Loss: 1.114, 8.125, 50.831, 367.876, 0.732
[epoch:183, iter:143005] Loss: 1.114, 8.128, 50.831, 367.913, 0.652
Epoch: [182][700/782]	Time 0.091 (0.079)	Data 0.003 (0.003)	Loss 9.6244 (9.5828)	Acc@1 81.250 (79.803)	Acc@5 100.000 (96.509)
[epoch:183, iter:143025] Loss: 1.114, 8.131, 50.831, 367.933, 0.571
[epoch:183, iter:143045] Loss: 1.114, 8.131, 50.846, 367.985, 0.526
[epoch:183, iter:143065] Loss: 1.114, 8.131, 50.850, 368.023, 0.497
[epoch:183, iter:143085] Loss: 1.114, 8.131, 50.850, 367.982, 0.903
[epoch:183, iter:143105] Loss: 1.114, 8.130, 50.849, 367.981, 0.662
 * Acc@1 79.764 Acc@5 96.504
epoch 182, total time 61.84
Test: [0/313]	Time 0.244 (0.244)	Loss 1.2852 (1.2852)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3480 (1.1786)	Acc@1 53.125 (69.988)	Acc@5 96.875 (91.925)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7183 (1.1401)	Acc@1 75.000 (70.818)	Acc@5 96.875 (92.646)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.5003 (1.1529)	Acc@1 65.625 (70.619)	Acc@5 96.875 (92.722)
 * Acc@1 70.710 Acc@5 92.760
==> training...
Epoch: [183][0/782]	Time 0.538 (0.538)	Data 0.461 (0.461)	Loss 10.1507 (10.1507)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
[epoch:184, iter:143107] Loss: 1.198, 8.860, 53.685, 377.100, 0.606
[epoch:184, iter:143127] Loss: 1.120, 8.123, 50.838, 367.784, 0.506
[epoch:184, iter:143147] Loss: 1.117, 8.142, 50.774, 367.237, 0.595
[epoch:184, iter:143167] Loss: 1.117, 8.144, 50.779, 367.362, 0.606
[epoch:184, iter:143187] Loss: 1.118, 8.145, 50.814, 367.351, 0.585
Epoch: [183][100/782]	Time 0.076 (0.086)	Data 0.002 (0.007)	Loss 9.4605 (9.5355)	Acc@1 79.688 (80.213)	Acc@5 95.312 (96.643)
[epoch:184, iter:143207] Loss: 1.118, 8.124, 50.778, 366.883, 0.827
[epoch:184, iter:143227] Loss: 1.119, 8.138, 50.790, 367.100, 0.831
[epoch:184, iter:143247] Loss: 1.119, 8.141, 50.827, 367.426, 0.474
[epoch:184, iter:143267] Loss: 1.117, 8.146, 50.821, 367.577, 0.484
[epoch:184, iter:143287] Loss: 1.116, 8.146, 50.861, 367.806, 0.711
Epoch: [183][200/782]	Time 0.070 (0.083)	Data 0.002 (0.005)	Loss 9.1120 (9.5564)	Acc@1 84.375 (80.201)	Acc@5 96.875 (96.681)
[epoch:184, iter:143307] Loss: 1.114, 8.142, 50.837, 367.673, 0.477
[epoch:184, iter:143327] Loss: 1.114, 8.146, 50.853, 367.730, 0.404
[epoch:184, iter:143347] Loss: 1.116, 8.137, 50.847, 367.523, 0.638
[epoch:184, iter:143367] Loss: 1.115, 8.134, 50.838, 367.509, 0.785
[epoch:184, iter:143387] Loss: 1.115, 8.132, 50.840, 367.487, 0.413
Epoch: [183][300/782]	Time 0.091 (0.082)	Data 0.002 (0.004)	Loss 9.8417 (9.5543)	Acc@1 73.438 (80.124)	Acc@5 92.188 (96.605)
[epoch:184, iter:143407] Loss: 1.114, 8.134, 50.823, 367.422, 0.913
[epoch:184, iter:143427] Loss: 1.114, 8.133, 50.813, 367.392, 0.866
[epoch:184, iter:143447] Loss: 1.113, 8.134, 50.794, 367.373, 0.669
[epoch:184, iter:143467] Loss: 1.112, 8.135, 50.779, 367.362, 0.798
[epoch:184, iter:143487] Loss: 1.113, 8.139, 50.813, 367.542, 0.778
Epoch: [183][400/782]	Time 0.090 (0.082)	Data 0.003 (0.003)	Loss 9.8100 (9.5637)	Acc@1 78.125 (79.730)	Acc@5 96.875 (96.575)
[epoch:184, iter:143507] Loss: 1.113, 8.140, 50.816, 367.589, 0.728
[epoch:184, iter:143527] Loss: 1.113, 8.138, 50.810, 367.482, 0.572
[epoch:184, iter:143547] Loss: 1.113, 8.137, 50.802, 367.465, 0.805
[epoch:184, iter:143567] Loss: 1.113, 8.136, 50.833, 367.624, 0.690
[epoch:184, iter:143587] Loss: 1.113, 8.133, 50.829, 367.621, 0.554
Epoch: [183][500/782]	Time 0.075 (0.082)	Data 0.003 (0.003)	Loss 9.7452 (9.5646)	Acc@1 79.688 (79.759)	Acc@5 95.312 (96.563)
[epoch:184, iter:143607] Loss: 1.112, 8.129, 50.819, 367.593, 0.691
[epoch:184, iter:143627] Loss: 1.112, 8.132, 50.828, 367.699, 0.540
[epoch:184, iter:143647] Loss: 1.113, 8.131, 50.812, 367.619, 0.793
[epoch:184, iter:143667] Loss: 1.112, 8.128, 50.794, 367.538, 1.028
[epoch:184, iter:143687] Loss: 1.112, 8.127, 50.805, 367.574, 0.640
Epoch: [183][600/782]	Time 0.078 (0.082)	Data 0.002 (0.003)	Loss 9.4126 (9.5685)	Acc@1 84.375 (79.752)	Acc@5 95.312 (96.568)
[epoch:184, iter:143707] Loss: 1.112, 8.130, 50.814, 367.626, 0.589
[epoch:184, iter:143727] Loss: 1.112, 8.128, 50.807, 367.574, 0.647
[epoch:184, iter:143747] Loss: 1.112, 8.130, 50.810, 367.591, 0.669
[epoch:184, iter:143767] Loss: 1.113, 8.130, 50.820, 367.622, 0.994
[epoch:184, iter:143787] Loss: 1.114, 8.131, 50.823, 367.606, 0.904
Epoch: [183][700/782]	Time 0.074 (0.081)	Data 0.002 (0.003)	Loss 9.3934 (9.5694)	Acc@1 75.000 (79.770)	Acc@5 98.438 (96.592)
[epoch:184, iter:143807] Loss: 1.113, 8.131, 50.811, 367.572, 0.681
[epoch:184, iter:143827] Loss: 1.113, 8.131, 50.811, 367.577, 0.671
[epoch:184, iter:143847] Loss: 1.113, 8.131, 50.810, 367.556, 0.622
[epoch:184, iter:143867] Loss: 1.114, 8.132, 50.804, 367.534, 0.550
[epoch:184, iter:143887] Loss: 1.114, 8.130, 50.810, 367.566, 0.579
 * Acc@1 79.714 Acc@5 96.550
epoch 183, total time 63.60
Test: [0/313]	Time 0.303 (0.303)	Loss 1.2776 (1.2776)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.010 (0.011)	Loss 1.3408 (1.1814)	Acc@1 56.250 (69.802)	Acc@5 96.875 (92.420)
Test: [200/313]	Time 0.008 (0.009)	Loss 0.6697 (1.1436)	Acc@1 75.000 (70.616)	Acc@5 96.875 (92.942)
Test: [300/313]	Time 0.010 (0.008)	Loss 1.4065 (1.1528)	Acc@1 62.500 (70.515)	Acc@5 96.875 (92.836)
 * Acc@1 70.600 Acc@5 92.880
==> training...
Epoch: [184][0/782]	Time 0.542 (0.542)	Data 0.459 (0.459)	Loss 9.1202 (9.1202)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
[epoch:185, iter:143889] Loss: 1.099, 8.224, 49.769, 361.234, 0.503
[epoch:185, iter:143909] Loss: 1.097, 8.148, 51.234, 370.802, 0.630
[epoch:185, iter:143929] Loss: 1.107, 8.121, 50.800, 367.560, 0.818
[epoch:185, iter:143949] Loss: 1.100, 8.128, 50.692, 367.354, 0.582
[epoch:185, iter:143969] Loss: 1.102, 8.123, 50.783, 367.626, 0.573
Epoch: [184][100/782]	Time 0.079 (0.084)	Data 0.002 (0.007)	Loss 9.3923 (9.5359)	Acc@1 81.250 (80.229)	Acc@5 98.438 (97.107)
[epoch:185, iter:143989] Loss: 1.106, 8.140, 50.851, 367.930, 0.522
[epoch:185, iter:144009] Loss: 1.105, 8.144, 50.802, 367.759, 0.484
[epoch:185, iter:144029] Loss: 1.106, 8.136, 50.812, 367.826, 0.551
[epoch:185, iter:144049] Loss: 1.109, 8.125, 50.819, 367.913, 0.612
[epoch:185, iter:144069] Loss: 1.110, 8.117, 50.808, 367.817, 0.716
Epoch: [184][200/782]	Time 0.092 (0.083)	Data 0.003 (0.005)	Loss 9.8570 (9.5272)	Acc@1 76.562 (80.255)	Acc@5 96.875 (96.961)
[epoch:185, iter:144089] Loss: 1.110, 8.115, 50.796, 367.691, 0.560
[epoch:185, iter:144109] Loss: 1.110, 8.113, 50.782, 367.570, 0.661
[epoch:185, iter:144129] Loss: 1.110, 8.114, 50.784, 367.631, 0.340
[epoch:185, iter:144149] Loss: 1.110, 8.117, 50.796, 367.733, 0.762
[epoch:185, iter:144169] Loss: 1.110, 8.125, 50.809, 367.860, 0.806
Epoch: [184][300/782]	Time 0.069 (0.083)	Data 0.002 (0.004)	Loss 9.6701 (9.5517)	Acc@1 84.375 (79.957)	Acc@5 96.875 (96.844)
[epoch:185, iter:144189] Loss: 1.110, 8.122, 50.799, 367.770, 0.601
[epoch:185, iter:144209] Loss: 1.111, 8.118, 50.784, 367.714, 0.928
[epoch:185, iter:144229] Loss: 1.112, 8.120, 50.808, 367.870, 0.728
[epoch:185, iter:144249] Loss: 1.112, 8.117, 50.830, 367.914, 0.503
[epoch:185, iter:144269] Loss: 1.113, 8.120, 50.836, 367.875, 0.633
Epoch: [184][400/782]	Time 0.084 (0.083)	Data 0.002 (0.004)	Loss 9.6402 (9.5639)	Acc@1 79.688 (79.765)	Acc@5 96.875 (96.797)
[epoch:185, iter:144289] Loss: 1.113, 8.118, 50.823, 367.775, 0.687
[epoch:185, iter:144309] Loss: 1.113, 8.118, 50.827, 367.777, 0.827
[epoch:185, iter:144329] Loss: 1.112, 8.118, 50.808, 367.715, 0.855
[epoch:185, iter:144349] Loss: 1.113, 8.118, 50.813, 367.734, 0.754
[epoch:185, iter:144369] Loss: 1.113, 8.118, 50.832, 367.823, 0.619
Epoch: [184][500/782]	Time 0.072 (0.083)	Data 0.002 (0.003)	Loss 9.7546 (9.5717)	Acc@1 73.438 (79.781)	Acc@5 96.875 (96.750)
[epoch:185, iter:144389] Loss: 1.113, 8.118, 50.824, 367.800, 0.700
[epoch:185, iter:144409] Loss: 1.113, 8.116, 50.811, 367.708, 0.670
[epoch:185, iter:144429] Loss: 1.113, 8.118, 50.820, 367.702, 0.587
[epoch:185, iter:144449] Loss: 1.114, 8.115, 50.816, 367.647, 0.659
[epoch:185, iter:144469] Loss: 1.114, 8.112, 50.798, 367.571, 0.745
Epoch: [184][600/782]	Time 0.091 (0.083)	Data 0.002 (0.003)	Loss 9.3223 (9.5612)	Acc@1 81.250 (79.947)	Acc@5 95.312 (96.794)
[epoch:185, iter:144489] Loss: 1.114, 8.111, 50.801, 367.572, 0.642
[epoch:185, iter:144509] Loss: 1.114, 8.111, 50.783, 367.501, 0.997
[epoch:185, iter:144529] Loss: 1.114, 8.110, 50.795, 367.581, 0.777
[epoch:185, iter:144549] Loss: 1.114, 8.110, 50.781, 367.551, 0.568
[epoch:185, iter:144569] Loss: 1.114, 8.111, 50.768, 367.490, 0.662
Epoch: [184][700/782]	Time 0.067 (0.082)	Data 0.002 (0.003)	Loss 9.0529 (9.5547)	Acc@1 84.375 (79.993)	Acc@5 100.000 (96.826)
[epoch:185, iter:144589] Loss: 1.114, 8.112, 50.772, 367.498, 0.474
[epoch:185, iter:144609] Loss: 1.114, 8.110, 50.763, 367.448, 0.803
[epoch:185, iter:144629] Loss: 1.114, 8.110, 50.746, 367.331, 0.804
[epoch:185, iter:144649] Loss: 1.113, 8.110, 50.748, 367.312, 0.505
[epoch:185, iter:144669] Loss: 1.113, 8.111, 50.744, 367.292, 0.603
 * Acc@1 79.956 Acc@5 96.812
epoch 184, total time 64.09
Test: [0/313]	Time 0.209 (0.209)	Loss 1.3072 (1.3072)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3200 (1.1795)	Acc@1 53.125 (70.390)	Acc@5 96.875 (91.801)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7035 (1.1388)	Acc@1 75.000 (70.973)	Acc@5 96.875 (92.506)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.3999 (1.1505)	Acc@1 65.625 (70.723)	Acc@5 100.000 (92.649)
 * Acc@1 70.860 Acc@5 92.690
==> training...
Epoch: [185][0/782]	Time 0.614 (0.614)	Data 0.543 (0.543)	Loss 9.6140 (9.6140)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
[epoch:186, iter:144671] Loss: 1.064, 8.130, 49.972, 365.235, 0.716
[epoch:186, iter:144691] Loss: 1.106, 8.080, 50.582, 367.188, 0.665
[epoch:186, iter:144711] Loss: 1.106, 8.091, 50.289, 366.043, 0.492
[epoch:186, iter:144731] Loss: 1.110, 8.098, 50.451, 366.436, 0.618
[epoch:186, iter:144751] Loss: 1.108, 8.085, 50.415, 366.091, 0.735
Epoch: [185][100/782]	Time 0.083 (0.088)	Data 0.003 (0.008)	Loss 9.5281 (9.4758)	Acc@1 82.812 (80.322)	Acc@5 96.875 (96.983)
[epoch:186, iter:144771] Loss: 1.105, 8.097, 50.489, 366.782, 0.607
[epoch:186, iter:144791] Loss: 1.105, 8.099, 50.464, 366.615, 0.599
[epoch:186, iter:144811] Loss: 1.104, 8.097, 50.457, 366.664, 0.657
[epoch:186, iter:144831] Loss: 1.105, 8.097, 50.465, 366.514, 1.200
[epoch:186, iter:144851] Loss: 1.106, 8.093, 50.472, 366.504, 0.770
Epoch: [185][200/782]	Time 0.092 (0.086)	Data 0.003 (0.005)	Loss 8.7902 (9.4879)	Acc@1 85.938 (79.897)	Acc@5 100.000 (96.914)
[epoch:186, iter:144871] Loss: 1.106, 8.096, 50.516, 366.645, 0.326
[epoch:186, iter:144891] Loss: 1.107, 8.097, 50.548, 366.750, 0.720
[epoch:186, iter:144911] Loss: 1.109, 8.102, 50.621, 367.002, 0.898
[epoch:186, iter:144931] Loss: 1.109, 8.102, 50.633, 367.060, 0.667
[epoch:186, iter:144951] Loss: 1.109, 8.107, 50.685, 367.239, 0.782
Epoch: [185][300/782]	Time 0.096 (0.082)	Data 0.004 (0.004)	Loss 9.6547 (9.5224)	Acc@1 78.125 (79.952)	Acc@5 95.312 (96.880)
[epoch:186, iter:144971] Loss: 1.109, 8.105, 50.698, 367.339, 0.714
[epoch:186, iter:144991] Loss: 1.109, 8.097, 50.687, 367.311, 0.970
[epoch:186, iter:145011] Loss: 1.109, 8.098, 50.670, 367.226, 0.667
[epoch:186, iter:145031] Loss: 1.110, 8.104, 50.697, 367.289, 0.788
[epoch:186, iter:145051] Loss: 1.111, 8.105, 50.703, 367.300, 0.765
Epoch: [185][400/782]	Time 0.092 (0.081)	Data 0.003 (0.004)	Loss 10.2159 (9.5245)	Acc@1 67.188 (79.941)	Acc@5 93.750 (96.809)
[epoch:186, iter:145071] Loss: 1.110, 8.099, 50.685, 367.219, 1.025
[epoch:186, iter:145091] Loss: 1.109, 8.100, 50.681, 367.259, 0.857
[epoch:186, iter:145111] Loss: 1.109, 8.099, 50.672, 367.199, 0.682
[epoch:186, iter:145131] Loss: 1.109, 8.101, 50.703, 367.314, 0.661
[epoch:186, iter:145151] Loss: 1.108, 8.100, 50.694, 367.300, 0.444
Epoch: [185][500/782]	Time 0.068 (0.080)	Data 0.002 (0.003)	Loss 9.5191 (9.5330)	Acc@1 75.000 (79.800)	Acc@5 98.438 (96.788)
[epoch:186, iter:145171] Loss: 1.109, 8.102, 50.701, 367.316, 0.673
[epoch:186, iter:145191] Loss: 1.109, 8.101, 50.681, 367.197, 0.751
[epoch:186, iter:145211] Loss: 1.109, 8.102, 50.663, 367.117, 0.521
[epoch:186, iter:145231] Loss: 1.109, 8.105, 50.667, 367.184, 0.386
[epoch:186, iter:145251] Loss: 1.109, 8.104, 50.666, 367.136, 0.539
Epoch: [185][600/782]	Time 0.080 (0.081)	Data 0.002 (0.003)	Loss 9.1859 (9.5282)	Acc@1 79.688 (79.739)	Acc@5 100.000 (96.766)
[epoch:186, iter:145271] Loss: 1.110, 8.104, 50.674, 367.116, 0.499
[epoch:186, iter:145291] Loss: 1.110, 8.105, 50.657, 367.001, 0.532
[epoch:186, iter:145311] Loss: 1.110, 8.104, 50.664, 366.992, 0.593
[epoch:186, iter:145331] Loss: 1.110, 8.101, 50.678, 366.995, 0.786
[epoch:186, iter:145351] Loss: 1.110, 8.101, 50.683, 367.025, 0.541
Epoch: [185][700/782]	Time 0.083 (0.082)	Data 0.003 (0.003)	Loss 9.9310 (9.5299)	Acc@1 81.250 (79.790)	Acc@5 95.312 (96.770)
[epoch:186, iter:145371] Loss: 1.110, 8.099, 50.690, 367.063, 0.618
[epoch:186, iter:145391] Loss: 1.110, 8.102, 50.693, 367.058, 0.606
[epoch:186, iter:145411] Loss: 1.110, 8.101, 50.687, 367.025, 0.560
[epoch:186, iter:145431] Loss: 1.110, 8.103, 50.689, 367.031, 0.631
[epoch:186, iter:145451] Loss: 1.111, 8.104, 50.706, 367.116, 0.582
 * Acc@1 79.772 Acc@5 96.738
epoch 185, total time 64.60
Test: [0/313]	Time 0.321 (0.321)	Loss 1.3866 (1.3866)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.3065 (1.1781)	Acc@1 62.500 (70.854)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.6954 (1.1441)	Acc@1 78.125 (71.020)	Acc@5 96.875 (92.584)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.3781 (1.1555)	Acc@1 65.625 (70.930)	Acc@5 93.750 (92.566)
 * Acc@1 71.050 Acc@5 92.620
saving the best model!
==> training...
Epoch: [186][0/782]	Time 0.522 (0.522)	Data 0.451 (0.451)	Loss 10.1759 (10.1759)	Acc@1 71.875 (71.875)	Acc@5 89.062 (89.062)
[epoch:187, iter:145453] Loss: 1.099, 8.336, 51.483, 371.272, 1.100
[epoch:187, iter:145473] Loss: 1.120, 8.049, 50.744, 367.095, 0.305
[epoch:187, iter:145493] Loss: 1.108, 8.074, 50.626, 366.500, 0.641
[epoch:187, iter:145513] Loss: 1.103, 8.075, 50.622, 366.413, 0.760
[epoch:187, iter:145533] Loss: 1.103, 8.088, 50.587, 366.272, 0.555
Epoch: [186][100/782]	Time 0.083 (0.090)	Data 0.002 (0.007)	Loss 9.5307 (9.4889)	Acc@1 76.562 (80.059)	Acc@5 96.875 (96.813)
[epoch:187, iter:145553] Loss: 1.105, 8.101, 50.572, 366.337, 0.688
[epoch:187, iter:145573] Loss: 1.110, 8.093, 50.602, 366.160, 0.394
[epoch:187, iter:145593] Loss: 1.110, 8.095, 50.561, 365.908, 0.572
[epoch:187, iter:145613] Loss: 1.111, 8.102, 50.634, 366.188, 0.802
[epoch:187, iter:145633] Loss: 1.110, 8.105, 50.682, 366.481, 0.726
Epoch: [186][200/782]	Time 0.083 (0.087)	Data 0.002 (0.005)	Loss 9.8792 (9.5127)	Acc@1 75.000 (79.921)	Acc@5 93.750 (96.743)
[epoch:187, iter:145653] Loss: 1.109, 8.109, 50.646, 366.383, 0.834
[epoch:187, iter:145673] Loss: 1.110, 8.110, 50.667, 366.577, 0.785
[epoch:187, iter:145693] Loss: 1.111, 8.101, 50.693, 366.699, 0.811
[epoch:187, iter:145713] Loss: 1.112, 8.103, 50.684, 366.630, 0.576
[epoch:187, iter:145733] Loss: 1.112, 8.105, 50.668, 366.623, 0.467
Epoch: [186][300/782]	Time 0.073 (0.084)	Data 0.003 (0.004)	Loss 9.5429 (9.5307)	Acc@1 81.250 (80.004)	Acc@5 96.875 (96.745)
[epoch:187, iter:145753] Loss: 1.112, 8.109, 50.703, 366.854, 0.677
[epoch:187, iter:145773] Loss: 1.112, 8.109, 50.682, 366.768, 0.857
[epoch:187, iter:145793] Loss: 1.112, 8.108, 50.691, 366.804, 0.499
[epoch:187, iter:145813] Loss: 1.113, 8.109, 50.686, 366.771, 0.660
[epoch:187, iter:145833] Loss: 1.112, 8.108, 50.664, 366.661, 0.824
Epoch: [186][400/782]	Time 0.068 (0.085)	Data 0.002 (0.004)	Loss 9.6308 (9.5267)	Acc@1 73.438 (80.003)	Acc@5 96.875 (96.743)
[epoch:187, iter:145853] Loss: 1.111, 8.107, 50.661, 366.638, 0.926
[epoch:187, iter:145873] Loss: 1.111, 8.106, 50.660, 366.632, 0.736
[epoch:187, iter:145893] Loss: 1.112, 8.108, 50.663, 366.618, 0.571
[epoch:187, iter:145913] Loss: 1.112, 8.108, 50.647, 366.544, 0.722
[epoch:187, iter:145933] Loss: 1.112, 8.108, 50.648, 366.556, 0.855
Epoch: [186][500/782]	Time 0.070 (0.083)	Data 0.002 (0.003)	Loss 9.5525 (9.5234)	Acc@1 82.812 (80.118)	Acc@5 98.438 (96.760)
[epoch:187, iter:145953] Loss: 1.112, 8.109, 50.655, 366.638, 0.584
[epoch:187, iter:145973] Loss: 1.112, 8.106, 50.647, 366.617, 0.660
[epoch:187, iter:145993] Loss: 1.112, 8.104, 50.650, 366.646, 0.645
[epoch:187, iter:146013] Loss: 1.113, 8.105, 50.667, 366.729, 0.889
[epoch:187, iter:146033] Loss: 1.112, 8.101, 50.665, 366.718, 0.783
Epoch: [186][600/782]	Time 0.090 (0.082)	Data 0.003 (0.003)	Loss 9.9836 (9.5308)	Acc@1 79.688 (80.106)	Acc@5 96.875 (96.651)
[epoch:187, iter:146053] Loss: 1.112, 8.102, 50.674, 366.770, 0.710
[epoch:187, iter:146073] Loss: 1.112, 8.101, 50.670, 366.782, 0.482
[epoch:187, iter:146093] Loss: 1.112, 8.103, 50.677, 366.834, 0.536
[epoch:187, iter:146113] Loss: 1.112, 8.103, 50.673, 366.826, 0.718
[epoch:187, iter:146133] Loss: 1.112, 8.103, 50.647, 366.696, 0.557
Epoch: [186][700/782]	Time 0.077 (0.082)	Data 0.003 (0.003)	Loss 9.3125 (9.5231)	Acc@1 82.812 (80.138)	Acc@5 98.438 (96.657)
[epoch:187, iter:146153] Loss: 1.112, 8.103, 50.656, 366.752, 0.430
[epoch:187, iter:146173] Loss: 1.112, 8.103, 50.657, 366.758, 0.765
[epoch:187, iter:146193] Loss: 1.112, 8.104, 50.656, 366.761, 0.948
[epoch:187, iter:146213] Loss: 1.112, 8.104, 50.666, 366.778, 0.590
[epoch:187, iter:146233] Loss: 1.112, 8.102, 50.668, 366.762, 0.733
 * Acc@1 80.092 Acc@5 96.642
epoch 186, total time 63.56
Test: [0/313]	Time 0.276 (0.276)	Loss 1.3438 (1.3438)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2913 (1.1752)	Acc@1 56.250 (70.297)	Acc@5 96.875 (92.017)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.6773 (1.1365)	Acc@1 78.125 (71.004)	Acc@5 96.875 (92.724)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.3963 (1.1490)	Acc@1 62.500 (70.671)	Acc@5 96.875 (92.722)
 * Acc@1 70.830 Acc@5 92.770
==> training...
Epoch: [187][0/782]	Time 0.543 (0.543)	Data 0.465 (0.465)	Loss 9.3299 (9.3299)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
[epoch:188, iter:146235] Loss: 1.118, 8.015, 49.014, 355.317, 0.743
[epoch:188, iter:146255] Loss: 1.107, 8.115, 50.658, 366.699, 0.674
[epoch:188, iter:146275] Loss: 1.106, 8.115, 50.638, 366.894, 0.508
[epoch:188, iter:146295] Loss: 1.116, 8.120, 50.595, 366.369, 0.816
[epoch:188, iter:146315] Loss: 1.115, 8.123, 50.612, 366.617, 0.509
Epoch: [187][100/782]	Time 0.065 (0.085)	Data 0.002 (0.007)	Loss 9.5333 (9.5323)	Acc@1 84.375 (80.337)	Acc@5 100.000 (96.782)
[epoch:188, iter:146335] Loss: 1.113, 8.107, 50.607, 366.604, 0.438
[epoch:188, iter:146355] Loss: 1.111, 8.097, 50.470, 366.127, 0.534
[epoch:188, iter:146375] Loss: 1.113, 8.100, 50.514, 366.322, 0.482
[epoch:188, iter:146395] Loss: 1.113, 8.106, 50.542, 366.285, 0.810
[epoch:188, iter:146415] Loss: 1.112, 8.104, 50.547, 366.470, 0.844
Epoch: [187][200/782]	Time 0.067 (0.082)	Data 0.002 (0.005)	Loss 9.1975 (9.4981)	Acc@1 87.500 (80.449)	Acc@5 95.312 (96.712)
[epoch:188, iter:146435] Loss: 1.112, 8.099, 50.555, 366.411, 0.496
[epoch:188, iter:146455] Loss: 1.112, 8.090, 50.563, 366.346, 0.689
[epoch:188, iter:146475] Loss: 1.113, 8.089, 50.563, 366.450, 0.682
[epoch:188, iter:146495] Loss: 1.112, 8.089, 50.549, 366.413, 0.571
[epoch:188, iter:146515] Loss: 1.112, 8.083, 50.552, 366.505, 0.621
Epoch: [187][300/782]	Time 0.074 (0.082)	Data 0.002 (0.004)	Loss 9.6879 (9.4998)	Acc@1 81.250 (80.534)	Acc@5 95.312 (96.761)
[epoch:188, iter:146535] Loss: 1.112, 8.088, 50.577, 366.549, 0.777
[epoch:188, iter:146555] Loss: 1.112, 8.085, 50.586, 366.686, 0.410
[epoch:188, iter:146575] Loss: 1.113, 8.083, 50.567, 366.540, 0.438
[epoch:188, iter:146595] Loss: 1.112, 8.082, 50.592, 366.652, 0.582
[epoch:188, iter:146615] Loss: 1.112, 8.076, 50.590, 366.619, 0.572
Epoch: [187][400/782]	Time 0.075 (0.080)	Data 0.002 (0.003)	Loss 9.8869 (9.4978)	Acc@1 79.688 (80.591)	Acc@5 98.438 (96.801)
[epoch:188, iter:146635] Loss: 1.113, 8.079, 50.610, 366.672, 0.773
[epoch:188, iter:146655] Loss: 1.113, 8.083, 50.608, 366.646, 0.660
[epoch:188, iter:146675] Loss: 1.113, 8.084, 50.596, 366.552, 0.462
[epoch:188, iter:146695] Loss: 1.113, 8.087, 50.606, 366.640, 0.554
[epoch:188, iter:146715] Loss: 1.113, 8.084, 50.616, 366.703, 0.465
Epoch: [187][500/782]	Time 0.064 (0.079)	Data 0.002 (0.003)	Loss 9.9484 (9.5097)	Acc@1 76.562 (80.367)	Acc@5 93.750 (96.760)
[epoch:188, iter:146735] Loss: 1.112, 8.084, 50.615, 366.702, 0.776
[epoch:188, iter:146755] Loss: 1.112, 8.084, 50.632, 366.772, 0.661
[epoch:188, iter:146775] Loss: 1.112, 8.087, 50.638, 366.802, 0.746
[epoch:188, iter:146795] Loss: 1.112, 8.085, 50.625, 366.767, 0.553
[epoch:188, iter:146815] Loss: 1.112, 8.087, 50.627, 366.814, 0.572
Epoch: [187][600/782]	Time 0.074 (0.079)	Data 0.002 (0.003)	Loss 10.0991 (9.5177)	Acc@1 78.125 (80.244)	Acc@5 96.875 (96.774)
[epoch:188, iter:146835] Loss: 1.112, 8.090, 50.632, 366.818, 0.675
[epoch:188, iter:146855] Loss: 1.112, 8.089, 50.623, 366.781, 0.538
[epoch:188, iter:146875] Loss: 1.112, 8.087, 50.616, 366.745, 0.467
[epoch:188, iter:146895] Loss: 1.112, 8.086, 50.617, 366.744, 0.753
[epoch:188, iter:146915] Loss: 1.112, 8.085, 50.624, 366.772, 0.960
Epoch: [187][700/782]	Time 0.066 (0.079)	Data 0.002 (0.003)	Loss 9.1472 (9.5089)	Acc@1 79.688 (80.225)	Acc@5 95.312 (96.786)
[epoch:188, iter:146935] Loss: 1.112, 8.085, 50.610, 366.672, 0.669
[epoch:188, iter:146955] Loss: 1.113, 8.088, 50.630, 366.781, 0.731
[epoch:188, iter:146975] Loss: 1.113, 8.088, 50.632, 366.799, 0.633
[epoch:188, iter:146995] Loss: 1.113, 8.086, 50.630, 366.767, 0.596
[epoch:188, iter:147015] Loss: 1.113, 8.085, 50.628, 366.730, 0.541
 * Acc@1 80.170 Acc@5 96.742
epoch 187, total time 62.11
Test: [0/313]	Time 0.238 (0.238)	Loss 1.3282 (1.3282)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2702 (1.1827)	Acc@1 59.375 (70.761)	Acc@5 96.875 (91.986)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7096 (1.1481)	Acc@1 78.125 (70.958)	Acc@5 96.875 (92.568)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.3597 (1.1602)	Acc@1 65.625 (70.640)	Acc@5 93.750 (92.629)
 * Acc@1 70.760 Acc@5 92.700
==> training...
Epoch: [188][0/782]	Time 0.605 (0.605)	Data 0.502 (0.502)	Loss 9.4304 (9.4304)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
[epoch:189, iter:147017] Loss: 1.084, 8.144, 50.419, 360.959, 0.595
[epoch:189, iter:147037] Loss: 1.106, 8.127, 50.715, 366.545, 0.422
[epoch:189, iter:147057] Loss: 1.111, 8.094, 50.690, 366.347, 0.879
[epoch:189, iter:147077] Loss: 1.115, 8.127, 50.837, 367.422, 0.641
[epoch:189, iter:147097] Loss: 1.112, 8.104, 50.861, 367.864, 0.770
Epoch: [188][100/782]	Time 0.083 (0.086)	Data 0.002 (0.007)	Loss 9.5729 (9.5979)	Acc@1 76.562 (79.703)	Acc@5 92.188 (96.256)
[epoch:189, iter:147117] Loss: 1.113, 8.096, 50.798, 367.243, 0.665
[epoch:189, iter:147137] Loss: 1.114, 8.094, 50.846, 367.410, 0.820
[epoch:189, iter:147157] Loss: 1.111, 8.091, 50.824, 367.453, 0.594
[epoch:189, iter:147177] Loss: 1.110, 8.093, 50.782, 367.307, 0.811
[epoch:189, iter:147197] Loss: 1.111, 8.096, 50.806, 367.426, 0.510
Epoch: [188][200/782]	Time 0.086 (0.082)	Data 0.003 (0.005)	Loss 9.9765 (9.5653)	Acc@1 71.875 (79.781)	Acc@5 96.875 (96.432)
[epoch:189, iter:147217] Loss: 1.113, 8.092, 50.801, 367.408, 0.788
[epoch:189, iter:147237] Loss: 1.113, 8.088, 50.759, 367.284, 1.100
[epoch:189, iter:147257] Loss: 1.112, 8.089, 50.735, 367.213, 0.461
[epoch:189, iter:147277] Loss: 1.113, 8.089, 50.694, 367.056, 0.576
[epoch:189, iter:147297] Loss: 1.113, 8.089, 50.678, 366.939, 0.714
Epoch: [188][300/782]	Time 0.074 (0.082)	Data 0.002 (0.004)	Loss 9.0516 (9.5270)	Acc@1 82.812 (79.937)	Acc@5 98.438 (96.631)
[epoch:189, iter:147317] Loss: 1.112, 8.090, 50.641, 366.796, 0.667
[epoch:189, iter:147337] Loss: 1.112, 8.085, 50.603, 366.482, 0.684
[epoch:189, iter:147357] Loss: 1.112, 8.083, 50.616, 366.530, 0.492
[epoch:189, iter:147377] Loss: 1.112, 8.087, 50.647, 366.711, 0.536
[epoch:189, iter:147397] Loss: 1.112, 8.084, 50.634, 366.663, 0.831
Epoch: [188][400/782]	Time 0.069 (0.082)	Data 0.002 (0.004)	Loss 9.7592 (9.5132)	Acc@1 67.188 (80.182)	Acc@5 92.188 (96.470)
[epoch:189, iter:147417] Loss: 1.111, 8.088, 50.632, 366.704, 0.977
[epoch:189, iter:147437] Loss: 1.111, 8.090, 50.623, 366.575, 0.590
[epoch:189, iter:147457] Loss: 1.111, 8.088, 50.621, 366.578, 0.698
[epoch:189, iter:147477] Loss: 1.111, 8.088, 50.623, 366.600, 0.632
[epoch:189, iter:147497] Loss: 1.112, 8.089, 50.635, 366.637, 0.749
Epoch: [188][500/782]	Time 0.090 (0.082)	Data 0.002 (0.003)	Loss 8.8045 (9.5127)	Acc@1 82.812 (80.071)	Acc@5 98.438 (96.513)
[epoch:189, iter:147517] Loss: 1.112, 8.090, 50.621, 366.599, 0.484
[epoch:189, iter:147537] Loss: 1.112, 8.085, 50.604, 366.499, 0.739
[epoch:189, iter:147557] Loss: 1.112, 8.087, 50.615, 366.556, 0.535
[epoch:189, iter:147577] Loss: 1.112, 8.088, 50.637, 366.661, 0.595
[epoch:189, iter:147597] Loss: 1.112, 8.086, 50.642, 366.692, 0.464
Epoch: [188][600/782]	Time 0.093 (0.082)	Data 0.003 (0.003)	Loss 10.1611 (9.5253)	Acc@1 84.375 (80.054)	Acc@5 98.438 (96.514)
[epoch:189, iter:147617] Loss: 1.112, 8.087, 50.658, 366.797, 0.580
[epoch:189, iter:147637] Loss: 1.112, 8.088, 50.657, 366.811, 0.594
[epoch:189, iter:147657] Loss: 1.112, 8.089, 50.660, 366.820, 0.695
[epoch:189, iter:147677] Loss: 1.112, 8.088, 50.665, 366.872, 0.587
[epoch:189, iter:147697] Loss: 1.112, 8.089, 50.668, 366.816, 0.690
Epoch: [188][700/782]	Time 0.080 (0.082)	Data 0.002 (0.003)	Loss 9.8912 (9.5304)	Acc@1 70.312 (80.033)	Acc@5 95.312 (96.554)
[epoch:189, iter:147717] Loss: 1.112, 8.090, 50.672, 366.834, 0.915
[epoch:189, iter:147737] Loss: 1.112, 8.089, 50.664, 366.772, 0.579
[epoch:189, iter:147757] Loss: 1.112, 8.090, 50.662, 366.783, 0.722
[epoch:189, iter:147777] Loss: 1.112, 8.092, 50.659, 366.801, 0.657
[epoch:189, iter:147797] Loss: 1.112, 8.091, 50.662, 366.788, 0.870
 * Acc@1 80.026 Acc@5 96.580
epoch 188, total time 64.57
Test: [0/313]	Time 0.226 (0.226)	Loss 1.3013 (1.3013)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2833 (1.1754)	Acc@1 56.250 (70.699)	Acc@5 96.875 (92.234)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.6992 (1.1416)	Acc@1 75.000 (70.989)	Acc@5 96.875 (92.771)
Test: [300/313]	Time 0.007 (0.007)	Loss 1.3855 (1.1538)	Acc@1 65.625 (70.671)	Acc@5 90.625 (92.670)
 * Acc@1 70.810 Acc@5 92.720
==> training...
Epoch: [189][0/782]	Time 0.497 (0.497)	Data 0.430 (0.430)	Loss 10.1197 (10.1197)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
[epoch:190, iter:147799] Loss: 1.066, 7.934, 51.470, 371.620, 0.976
[epoch:190, iter:147819] Loss: 1.091, 8.023, 50.659, 367.246, 0.573
[epoch:190, iter:147839] Loss: 1.099, 8.090, 50.519, 366.538, 0.574
[epoch:190, iter:147859] Loss: 1.105, 8.091, 50.623, 367.060, 0.541
[epoch:190, iter:147879] Loss: 1.103, 8.082, 50.675, 367.390, 0.883
Epoch: [189][100/782]	Time 0.068 (0.077)	Data 0.002 (0.006)	Loss 8.8003 (9.5008)	Acc@1 82.812 (80.090)	Acc@5 100.000 (96.689)
[epoch:190, iter:147899] Loss: 1.103, 8.066, 50.664, 367.308, 0.489
[epoch:190, iter:147919] Loss: 1.104, 8.060, 50.605, 366.990, 0.492
[epoch:190, iter:147939] Loss: 1.105, 8.066, 50.604, 366.817, 0.795
[epoch:190, iter:147959] Loss: 1.105, 8.067, 50.531, 366.458, 0.888
[epoch:190, iter:147979] Loss: 1.105, 8.073, 50.509, 366.275, 0.719
Epoch: [189][200/782]	Time 0.090 (0.080)	Data 0.003 (0.004)	Loss 9.2773 (9.4714)	Acc@1 76.562 (80.107)	Acc@5 96.875 (96.813)
[epoch:190, iter:147999] Loss: 1.105, 8.069, 50.491, 366.189, 0.671
[epoch:190, iter:148019] Loss: 1.105, 8.063, 50.564, 366.396, 0.609
[epoch:190, iter:148039] Loss: 1.106, 8.060, 50.528, 366.300, 0.606
[epoch:190, iter:148059] Loss: 1.106, 8.060, 50.533, 366.274, 0.797
[epoch:190, iter:148079] Loss: 1.107, 8.060, 50.566, 366.359, 0.663
Epoch: [189][300/782]	Time 0.092 (0.082)	Data 0.003 (0.004)	Loss 9.0807 (9.4745)	Acc@1 81.250 (80.103)	Acc@5 95.312 (96.901)
[epoch:190, iter:148099] Loss: 1.108, 8.060, 50.537, 366.177, 0.650
[epoch:190, iter:148119] Loss: 1.108, 8.065, 50.543, 366.225, 0.656
[epoch:190, iter:148139] Loss: 1.108, 8.063, 50.527, 366.169, 0.570
[epoch:190, iter:148159] Loss: 1.108, 8.061, 50.508, 366.092, 0.767
[epoch:190, iter:148179] Loss: 1.109, 8.061, 50.510, 366.058, 0.653
Epoch: [189][400/782]	Time 0.087 (0.083)	Data 0.003 (0.004)	Loss 9.7044 (9.4795)	Acc@1 84.375 (79.882)	Acc@5 100.000 (96.832)
[epoch:190, iter:148199] Loss: 1.109, 8.061, 50.497, 365.958, 0.519
[epoch:190, iter:148219] Loss: 1.109, 8.064, 50.511, 366.017, 0.663
[epoch:190, iter:148239] Loss: 1.109, 8.068, 50.532, 366.131, 0.500
[epoch:190, iter:148259] Loss: 1.110, 8.069, 50.548, 366.166, 0.541
[epoch:190, iter:148279] Loss: 1.109, 8.070, 50.539, 366.202, 0.505
Epoch: [189][500/782]	Time 0.070 (0.082)	Data 0.002 (0.003)	Loss 9.5974 (9.4832)	Acc@1 81.250 (79.996)	Acc@5 96.875 (96.813)
[epoch:190, iter:148299] Loss: 1.109, 8.069, 50.534, 366.172, 0.628
[epoch:190, iter:148319] Loss: 1.110, 8.070, 50.546, 366.215, 0.719
[epoch:190, iter:148339] Loss: 1.110, 8.072, 50.567, 366.318, 0.540
[epoch:190, iter:148359] Loss: 1.111, 8.074, 50.600, 366.424, 0.949
[epoch:190, iter:148379] Loss: 1.111, 8.075, 50.597, 366.426, 0.512
Epoch: [189][600/782]	Time 0.084 (0.082)	Data 0.003 (0.003)	Loss 9.0048 (9.5005)	Acc@1 87.500 (79.979)	Acc@5 96.875 (96.787)
[epoch:190, iter:148399] Loss: 1.110, 8.076, 50.589, 366.346, 0.510
[epoch:190, iter:148419] Loss: 1.110, 8.078, 50.592, 366.388, 0.848
[epoch:190, iter:148439] Loss: 1.111, 8.077, 50.590, 366.361, 0.573
[epoch:190, iter:148459] Loss: 1.111, 8.075, 50.589, 366.323, 0.638
[epoch:190, iter:148479] Loss: 1.111, 8.074, 50.589, 366.313, 0.732
Epoch: [189][700/782]	Time 0.090 (0.082)	Data 0.003 (0.003)	Loss 9.1641 (9.4978)	Acc@1 81.250 (80.029)	Acc@5 98.438 (96.797)
[epoch:190, iter:148499] Loss: 1.111, 8.072, 50.579, 366.270, 0.568
[epoch:190, iter:148519] Loss: 1.111, 8.071, 50.571, 366.262, 0.485
[epoch:190, iter:148539] Loss: 1.111, 8.073, 50.583, 366.297, 0.740
[epoch:190, iter:148559] Loss: 1.112, 8.075, 50.604, 366.360, 0.978
[epoch:190, iter:148579] Loss: 1.112, 8.077, 50.606, 366.391, 0.991
 * Acc@1 79.996 Acc@5 96.762
epoch 189, total time 64.02
Test: [0/313]	Time 0.288 (0.288)	Loss 1.2549 (1.2549)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2623 (1.1799)	Acc@1 59.375 (70.514)	Acc@5 96.875 (92.296)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.7096 (1.1457)	Acc@1 71.875 (71.035)	Acc@5 93.750 (92.677)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.5033 (1.1562)	Acc@1 62.500 (70.702)	Acc@5 96.875 (92.722)
 * Acc@1 70.810 Acc@5 92.770
==> training...
Epoch: [190][0/782]	Time 0.613 (0.613)	Data 0.525 (0.525)	Loss 10.1604 (10.1604)	Acc@1 76.562 (76.562)	Acc@5 92.188 (92.188)
[epoch:191, iter:148581] Loss: 1.097, 7.980, 51.408, 372.458, 0.922
[epoch:191, iter:148601] Loss: 1.104, 8.049, 50.296, 365.330, 0.573
[epoch:191, iter:148621] Loss: 1.100, 8.116, 50.270, 365.216, 0.874
[epoch:191, iter:148641] Loss: 1.105, 8.090, 50.200, 364.671, 0.598
[epoch:191, iter:148661] Loss: 1.107, 8.094, 50.351, 365.538, 0.743
Epoch: [190][100/782]	Time 0.057 (0.085)	Data 0.002 (0.007)	Loss 9.5575 (9.5028)	Acc@1 76.562 (79.718)	Acc@5 98.438 (96.689)
[epoch:191, iter:148681] Loss: 1.104, 8.089, 50.318, 365.393, 0.541
[epoch:191, iter:148701] Loss: 1.108, 8.085, 50.434, 365.751, 0.494
[epoch:191, iter:148721] Loss: 1.110, 8.097, 50.442, 365.878, 0.673
[epoch:191, iter:148741] Loss: 1.108, 8.094, 50.451, 366.002, 0.486
[epoch:191, iter:148761] Loss: 1.110, 8.096, 50.514, 366.246, 0.728
Epoch: [190][200/782]	Time 0.088 (0.084)	Data 0.003 (0.005)	Loss 9.2916 (9.5129)	Acc@1 78.125 (79.703)	Acc@5 96.875 (96.688)
[epoch:191, iter:148781] Loss: 1.110, 8.091, 50.473, 366.100, 0.607
[epoch:191, iter:148801] Loss: 1.108, 8.091, 50.491, 366.215, 0.531
[epoch:191, iter:148821] Loss: 1.108, 8.091, 50.461, 366.058, 0.700
[epoch:191, iter:148841] Loss: 1.108, 8.090, 50.511, 366.219, 0.682
[epoch:191, iter:148861] Loss: 1.108, 8.082, 50.568, 366.423, 0.821
Epoch: [190][300/782]	Time 0.064 (0.081)	Data 0.002 (0.004)	Loss 9.7418 (9.5252)	Acc@1 84.375 (79.926)	Acc@5 95.312 (96.584)
[epoch:191, iter:148881] Loss: 1.109, 8.086, 50.590, 366.412, 0.560
[epoch:191, iter:148901] Loss: 1.109, 8.082, 50.608, 366.416, 0.869
[epoch:191, iter:148921] Loss: 1.110, 8.085, 50.619, 366.462, 0.763
[epoch:191, iter:148941] Loss: 1.111, 8.084, 50.594, 366.338, 0.484
[epoch:191, iter:148961] Loss: 1.112, 8.083, 50.603, 366.382, 0.399
Epoch: [190][400/782]	Time 0.071 (0.079)	Data 0.002 (0.004)	Loss 9.3456 (9.5127)	Acc@1 82.812 (80.143)	Acc@5 98.438 (96.715)
[epoch:191, iter:148981] Loss: 1.112, 8.081, 50.586, 366.318, 0.557
[epoch:191, iter:149001] Loss: 1.112, 8.081, 50.585, 366.321, 0.761
[epoch:191, iter:149021] Loss: 1.112, 8.080, 50.575, 366.248, 0.523
[epoch:191, iter:149041] Loss: 1.112, 8.076, 50.559, 366.144, 0.803
[epoch:191, iter:149061] Loss: 1.112, 8.080, 50.548, 366.081, 0.585
Epoch: [190][500/782]	Time 0.080 (0.078)	Data 0.003 (0.003)	Loss 9.4326 (9.5009)	Acc@1 84.375 (80.130)	Acc@5 96.875 (96.747)
[epoch:191, iter:149081] Loss: 1.112, 8.080, 50.547, 366.076, 0.619
[epoch:191, iter:149101] Loss: 1.112, 8.078, 50.545, 366.061, 0.761
[epoch:191, iter:149121] Loss: 1.113, 8.078, 50.562, 366.115, 0.386
[epoch:191, iter:149141] Loss: 1.113, 8.078, 50.581, 366.201, 0.582
[epoch:191, iter:149161] Loss: 1.113, 8.077, 50.576, 366.181, 0.600
Epoch: [190][600/782]	Time 0.075 (0.077)	Data 0.002 (0.003)	Loss 9.3419 (9.5065)	Acc@1 89.062 (80.080)	Acc@5 100.000 (96.753)
[epoch:191, iter:149181] Loss: 1.112, 8.079, 50.585, 366.221, 0.378
[epoch:191, iter:149201] Loss: 1.112, 8.080, 50.578, 366.184, 0.833
[epoch:191, iter:149221] Loss: 1.112, 8.080, 50.575, 366.186, 0.724
[epoch:191, iter:149241] Loss: 1.112, 8.080, 50.565, 366.157, 0.651
[epoch:191, iter:149261] Loss: 1.112, 8.081, 50.575, 366.200, 0.922
Epoch: [190][700/782]	Time 0.064 (0.078)	Data 0.002 (0.003)	Loss 10.6126 (9.5060)	Acc@1 79.688 (80.151)	Acc@5 95.312 (96.735)
[epoch:191, iter:149281] Loss: 1.112, 8.080, 50.581, 366.234, 0.782
[epoch:191, iter:149301] Loss: 1.112, 8.080, 50.575, 366.206, 0.573
[epoch:191, iter:149321] Loss: 1.111, 8.081, 50.580, 366.234, 0.495
[epoch:191, iter:149341] Loss: 1.111, 8.081, 50.586, 366.270, 0.776
[epoch:191, iter:149361] Loss: 1.111, 8.084, 50.589, 366.300, 0.556
 * Acc@1 80.152 Acc@5 96.750
epoch 190, total time 61.33
Test: [0/313]	Time 0.292 (0.292)	Loss 1.2765 (1.2765)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.010)	Loss 1.3069 (1.1714)	Acc@1 62.500 (70.514)	Acc@5 96.875 (92.141)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.6825 (1.1368)	Acc@1 78.125 (71.144)	Acc@5 96.875 (92.646)
Test: [300/313]	Time 0.009 (0.008)	Loss 1.4189 (1.1501)	Acc@1 62.500 (71.076)	Acc@5 96.875 (92.639)
 * Acc@1 71.170 Acc@5 92.680
saving the best model!
==> training...
Epoch: [191][0/782]	Time 0.603 (0.603)	Data 0.510 (0.510)	Loss 9.3229 (9.3229)	Acc@1 85.938 (85.938)	Acc@5 96.875 (96.875)
[epoch:192, iter:149363] Loss: 1.159, 7.988, 49.738, 361.255, 0.549
[epoch:192, iter:149383] Loss: 1.133, 8.075, 50.266, 364.516, 0.751
[epoch:192, iter:149403] Loss: 1.122, 8.104, 50.329, 364.925, 0.867
[epoch:192, iter:149423] Loss: 1.117, 8.104, 50.515, 366.433, 0.710
[epoch:192, iter:149443] Loss: 1.113, 8.086, 50.551, 366.749, 0.703
Epoch: [191][100/782]	Time 0.073 (0.090)	Data 0.002 (0.008)	Loss 9.1929 (9.5018)	Acc@1 75.000 (80.446)	Acc@5 96.875 (96.782)
[epoch:192, iter:149463] Loss: 1.115, 8.097, 50.642, 367.037, 0.694
[epoch:192, iter:149483] Loss: 1.114, 8.099, 50.586, 366.692, 0.554
[epoch:192, iter:149503] Loss: 1.114, 8.098, 50.632, 366.829, 0.678
[epoch:192, iter:149523] Loss: 1.113, 8.089, 50.502, 366.320, 0.981
[epoch:192, iter:149543] Loss: 1.113, 8.082, 50.553, 366.533, 0.479
Epoch: [191][200/782]	Time 0.077 (0.085)	Data 0.003 (0.005)	Loss 8.9135 (9.4725)	Acc@1 84.375 (80.457)	Acc@5 100.000 (96.712)
[epoch:192, iter:149563] Loss: 1.114, 8.086, 50.533, 366.312, 0.422
[epoch:192, iter:149583] Loss: 1.114, 8.086, 50.561, 366.395, 0.531
[epoch:192, iter:149603] Loss: 1.115, 8.085, 50.559, 366.334, 0.651
[epoch:192, iter:149623] Loss: 1.115, 8.083, 50.534, 366.158, 0.560
[epoch:192, iter:149643] Loss: 1.115, 8.089, 50.560, 366.214, 0.555
Epoch: [191][300/782]	Time 0.085 (0.083)	Data 0.002 (0.004)	Loss 9.4365 (9.4835)	Acc@1 76.562 (80.077)	Acc@5 95.312 (96.667)
[epoch:192, iter:149663] Loss: 1.113, 8.085, 50.519, 366.077, 0.712
[epoch:192, iter:149683] Loss: 1.114, 8.084, 50.529, 366.135, 0.648
[epoch:192, iter:149703] Loss: 1.113, 8.082, 50.521, 366.161, 0.769
[epoch:192, iter:149723] Loss: 1.113, 8.085, 50.547, 366.314, 0.477
[epoch:192, iter:149743] Loss: 1.113, 8.086, 50.548, 366.308, 0.445
Epoch: [191][400/782]	Time 0.091 (0.082)	Data 0.003 (0.004)	Loss 9.4693 (9.4856)	Acc@1 81.250 (80.229)	Acc@5 98.438 (96.719)
[epoch:192, iter:149763] Loss: 1.112, 8.083, 50.530, 366.193, 0.669
[epoch:192, iter:149783] Loss: 1.113, 8.084, 50.520, 366.129, 1.007
[epoch:192, iter:149803] Loss: 1.113, 8.082, 50.543, 366.223, 0.650
[epoch:192, iter:149823] Loss: 1.113, 8.082, 50.549, 366.227, 0.592
[epoch:192, iter:149843] Loss: 1.113, 8.080, 50.546, 366.187, 0.621
Epoch: [191][500/782]	Time 0.088 (0.082)	Data 0.003 (0.003)	Loss 9.9166 (9.4888)	Acc@1 76.562 (80.205)	Acc@5 93.750 (96.722)
[epoch:192, iter:149863] Loss: 1.113, 8.081, 50.547, 366.163, 0.772
[epoch:192, iter:149883] Loss: 1.113, 8.082, 50.568, 366.235, 0.684
[epoch:192, iter:149903] Loss: 1.113, 8.082, 50.558, 366.199, 0.492
[epoch:192, iter:149923] Loss: 1.112, 8.081, 50.546, 366.192, 0.537
[epoch:192, iter:149943] Loss: 1.113, 8.082, 50.556, 366.237, 0.850
Epoch: [191][600/782]	Time 0.095 (0.081)	Data 0.003 (0.003)	Loss 8.8992 (9.4928)	Acc@1 81.250 (80.265)	Acc@5 98.438 (96.680)
[epoch:192, iter:149963] Loss: 1.113, 8.083, 50.547, 366.155, 0.463
[epoch:192, iter:149983] Loss: 1.113, 8.082, 50.554, 366.200, 0.511
[epoch:192, iter:150003] Loss: 1.113, 8.082, 50.563, 366.200, 0.482
[epoch:192, iter:150023] Loss: 1.113, 8.082, 50.562, 366.221, 0.631
[epoch:192, iter:150043] Loss: 1.113, 8.079, 50.546, 366.136, 0.693
Epoch: [191][700/782]	Time 0.093 (0.082)	Data 0.004 (0.003)	Loss 9.2487 (9.4939)	Acc@1 79.688 (80.171)	Acc@5 95.312 (96.681)
[epoch:192, iter:150063] Loss: 1.112, 8.078, 50.544, 366.122, 0.798
[epoch:192, iter:150083] Loss: 1.113, 8.078, 50.557, 366.166, 0.523
[epoch:192, iter:150103] Loss: 1.113, 8.078, 50.568, 366.197, 0.672
[epoch:192, iter:150123] Loss: 1.113, 8.078, 50.569, 366.179, 0.726
[epoch:192, iter:150143] Loss: 1.114, 8.079, 50.581, 366.223, 0.850
 * Acc@1 80.180 Acc@5 96.646
epoch 191, total time 64.41
Test: [0/313]	Time 0.239 (0.239)	Loss 1.3471 (1.3471)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.1965 (1.1734)	Acc@1 59.375 (70.266)	Acc@5 96.875 (92.110)
Test: [200/313]	Time 0.008 (0.008)	Loss 0.7002 (1.1382)	Acc@1 75.000 (70.756)	Acc@5 96.875 (92.568)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.4223 (1.1508)	Acc@1 65.625 (70.598)	Acc@5 96.875 (92.733)
 * Acc@1 70.700 Acc@5 92.790
==> training...
Epoch: [192][0/782]	Time 0.504 (0.504)	Data 0.423 (0.423)	Loss 10.6859 (10.6859)	Acc@1 67.188 (67.188)	Acc@5 93.750 (93.750)
[epoch:193, iter:150145] Loss: 1.204, 8.030, 54.200, 381.800, 1.005
[epoch:193, iter:150165] Loss: 1.107, 8.023, 50.632, 366.062, 0.662
[epoch:193, iter:150185] Loss: 1.112, 8.046, 50.597, 366.082, 0.606
[epoch:193, iter:150205] Loss: 1.110, 8.058, 50.577, 366.132, 0.573
[epoch:193, iter:150225] Loss: 1.112, 8.075, 50.545, 366.250, 0.466
Epoch: [192][100/782]	Time 0.088 (0.088)	Data 0.003 (0.007)	Loss 9.8362 (9.4937)	Acc@1 78.125 (80.152)	Acc@5 93.750 (96.751)
[epoch:193, iter:150245] Loss: 1.112, 8.072, 50.601, 366.544, 0.707
[epoch:193, iter:150265] Loss: 1.111, 8.072, 50.594, 366.679, 0.616
[epoch:193, iter:150285] Loss: 1.110, 8.071, 50.634, 366.838, 0.722
[epoch:193, iter:150305] Loss: 1.111, 8.072, 50.609, 366.529, 0.575
[epoch:193, iter:150325] Loss: 1.114, 8.073, 50.602, 366.486, 0.376
Epoch: [192][200/782]	Time 0.073 (0.084)	Data 0.002 (0.004)	Loss 9.2598 (9.4945)	Acc@1 79.688 (80.426)	Acc@5 98.438 (96.859)
[epoch:193, iter:150345] Loss: 1.113, 8.082, 50.587, 366.444, 0.639
[epoch:193, iter:150365] Loss: 1.114, 8.085, 50.608, 366.536, 0.510
[epoch:193, iter:150385] Loss: 1.113, 8.078, 50.582, 366.424, 0.847
[epoch:193, iter:150405] Loss: 1.112, 8.080, 50.598, 366.569, 0.474
[epoch:193, iter:150425] Loss: 1.112, 8.080, 50.633, 366.804, 0.615
Epoch: [192][300/782]	Time 0.077 (0.083)	Data 0.002 (0.004)	Loss 9.5272 (9.5011)	Acc@1 82.812 (80.342)	Acc@5 98.438 (96.724)
[epoch:193, iter:150445] Loss: 1.113, 8.084, 50.631, 366.786, 0.514
[epoch:193, iter:150465] Loss: 1.113, 8.086, 50.631, 366.730, 0.679
[epoch:193, iter:150485] Loss: 1.114, 8.084, 50.654, 366.813, 0.542
[epoch:193, iter:150505] Loss: 1.114, 8.086, 50.653, 366.885, 0.650
[epoch:193, iter:150525] Loss: 1.114, 8.085, 50.668, 366.910, 0.457
Epoch: [192][400/782]	Time 0.072 (0.082)	Data 0.002 (0.003)	Loss 9.2436 (9.5109)	Acc@1 84.375 (80.319)	Acc@5 95.312 (96.657)
[epoch:193, iter:150545] Loss: 1.113, 8.085, 50.656, 366.873, 0.572
[epoch:193, iter:150565] Loss: 1.113, 8.084, 50.658, 366.877, 0.626
[epoch:193, iter:150585] Loss: 1.113, 8.086, 50.664, 366.927, 0.735
[epoch:193, iter:150605] Loss: 1.113, 8.085, 50.657, 366.894, 0.654
[epoch:193, iter:150625] Loss: 1.113, 8.082, 50.646, 366.872, 0.711
Epoch: [192][500/782]	Time 0.073 (0.081)	Data 0.002 (0.003)	Loss 10.1023 (9.5100)	Acc@1 75.000 (80.261)	Acc@5 93.750 (96.650)
[epoch:193, iter:150645] Loss: 1.113, 8.083, 50.635, 366.848, 0.927
[epoch:193, iter:150665] Loss: 1.113, 8.082, 50.637, 366.835, 0.375
[epoch:193, iter:150685] Loss: 1.112, 8.080, 50.639, 366.827, 0.783
[epoch:193, iter:150705] Loss: 1.112, 8.078, 50.627, 366.772, 0.389
[epoch:193, iter:150725] Loss: 1.112, 8.077, 50.617, 366.690, 0.660
Epoch: [192][600/782]	Time 0.084 (0.081)	Data 0.003 (0.003)	Loss 9.5569 (9.5023)	Acc@1 73.438 (80.166)	Acc@5 95.312 (96.680)
[epoch:193, iter:150745] Loss: 1.112, 8.076, 50.608, 366.649, 0.835
[epoch:193, iter:150765] Loss: 1.112, 8.076, 50.601, 366.608, 0.700
[epoch:193, iter:150785] Loss: 1.112, 8.076, 50.606, 366.616, 0.851
[epoch:193, iter:150805] Loss: 1.112, 8.077, 50.612, 366.676, 0.689
[epoch:193, iter:150825] Loss: 1.112, 8.074, 50.611, 366.643, 0.892
Epoch: [192][700/782]	Time 0.081 (0.081)	Data 0.003 (0.003)	Loss 8.7012 (9.5034)	Acc@1 90.625 (80.202)	Acc@5 100.000 (96.706)
[epoch:193, iter:150845] Loss: 1.112, 8.075, 50.612, 366.617, 0.284
[epoch:193, iter:150865] Loss: 1.112, 8.074, 50.602, 366.539, 0.886
[epoch:193, iter:150885] Loss: 1.112, 8.074, 50.610, 366.539, 0.483
[epoch:193, iter:150905] Loss: 1.112, 8.075, 50.606, 366.514, 0.844
[epoch:193, iter:150925] Loss: 1.111, 8.074, 50.596, 366.458, 0.759
 * Acc@1 80.252 Acc@5 96.730
epoch 192, total time 62.90
Test: [0/313]	Time 0.290 (0.290)	Loss 1.2634 (1.2634)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.011)	Loss 1.2163 (1.1835)	Acc@1 62.500 (70.328)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.7314 (1.1416)	Acc@1 71.875 (70.927)	Acc@5 100.000 (92.522)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.3911 (1.1514)	Acc@1 65.625 (70.826)	Acc@5 93.750 (92.712)
 * Acc@1 70.940 Acc@5 92.740
==> training...
Epoch: [193][0/782]	Time 0.575 (0.575)	Data 0.496 (0.496)	Loss 9.6964 (9.6964)	Acc@1 85.938 (85.938)	Acc@5 96.875 (96.875)
[epoch:194, iter:150927] Loss: 1.142, 8.151, 52.160, 373.607, 0.589
[epoch:194, iter:150947] Loss: 1.124, 8.069, 50.437, 365.173, 0.447
[epoch:194, iter:150967] Loss: 1.117, 8.098, 50.343, 364.721, 0.778
[epoch:194, iter:150987] Loss: 1.112, 8.097, 50.353, 365.190, 0.864
[epoch:194, iter:151007] Loss: 1.110, 8.080, 50.253, 364.675, 0.498
Epoch: [193][100/782]	Time 0.078 (0.089)	Data 0.002 (0.007)	Loss 9.2926 (9.4309)	Acc@1 87.500 (80.941)	Acc@5 96.875 (96.875)
[epoch:194, iter:151027] Loss: 1.109, 8.087, 50.297, 365.078, 0.550
[epoch:194, iter:151047] Loss: 1.108, 8.094, 50.347, 365.489, 0.680
[epoch:194, iter:151067] Loss: 1.107, 8.087, 50.336, 365.396, 0.784
[epoch:194, iter:151087] Loss: 1.106, 8.081, 50.334, 365.349, 0.668
[epoch:194, iter:151107] Loss: 1.106, 8.069, 50.312, 365.193, 0.749
Epoch: [193][200/782]	Time 0.088 (0.089)	Data 0.003 (0.005)	Loss 9.2350 (9.4456)	Acc@1 81.250 (80.597)	Acc@5 95.312 (96.821)
[epoch:194, iter:151127] Loss: 1.107, 8.069, 50.362, 365.371, 0.567
[epoch:194, iter:151147] Loss: 1.108, 8.073, 50.361, 365.355, 0.753
[epoch:194, iter:151167] Loss: 1.107, 8.069, 50.391, 365.561, 0.228
[epoch:194, iter:151187] Loss: 1.107, 8.069, 50.392, 365.484, 0.536
[epoch:194, iter:151207] Loss: 1.108, 8.067, 50.416, 365.546, 0.620
Epoch: [193][300/782]	Time 0.083 (0.087)	Data 0.003 (0.004)	Loss 9.9137 (9.4509)	Acc@1 75.000 (80.596)	Acc@5 95.312 (96.958)
[epoch:194, iter:151227] Loss: 1.109, 8.066, 50.402, 365.439, 0.718
[epoch:194, iter:151247] Loss: 1.108, 8.067, 50.370, 365.335, 0.653
[epoch:194, iter:151267] Loss: 1.110, 8.071, 50.405, 365.501, 0.781
[epoch:194, iter:151287] Loss: 1.110, 8.068, 50.407, 365.460, 0.477
[epoch:194, iter:151307] Loss: 1.109, 8.067, 50.419, 365.551, 0.498
Epoch: [193][400/782]	Time 0.068 (0.087)	Data 0.002 (0.004)	Loss 9.4328 (9.4651)	Acc@1 81.250 (80.412)	Acc@5 90.625 (96.898)
[epoch:194, iter:151327] Loss: 1.110, 8.063, 50.451, 365.717, 0.782
[epoch:194, iter:151347] Loss: 1.111, 8.062, 50.456, 365.700, 0.825
[epoch:194, iter:151367] Loss: 1.110, 8.062, 50.435, 365.644, 0.688
[epoch:194, iter:151387] Loss: 1.111, 8.062, 50.432, 365.595, 0.397
[epoch:194, iter:151407] Loss: 1.111, 8.064, 50.432, 365.558, 0.561
Epoch: [193][500/782]	Time 0.074 (0.086)	Data 0.002 (0.004)	Loss 9.5619 (9.4676)	Acc@1 81.250 (80.374)	Acc@5 93.750 (96.800)
[epoch:194, iter:151427] Loss: 1.111, 8.066, 50.443, 365.571, 0.758
[epoch:194, iter:151447] Loss: 1.111, 8.065, 50.434, 365.569, 0.612
[epoch:194, iter:151467] Loss: 1.112, 8.068, 50.464, 365.710, 0.304
[epoch:194, iter:151487] Loss: 1.111, 8.070, 50.466, 365.721, 0.464
[epoch:194, iter:151507] Loss: 1.112, 8.069, 50.465, 365.724, 0.503
Epoch: [193][600/782]	Time 0.072 (0.085)	Data 0.002 (0.003)	Loss 8.9813 (9.4674)	Acc@1 84.375 (80.540)	Acc@5 98.438 (96.813)
[epoch:194, iter:151527] Loss: 1.112, 8.069, 50.467, 365.751, 0.495
[epoch:194, iter:151547] Loss: 1.112, 8.070, 50.472, 365.766, 0.307
[epoch:194, iter:151567] Loss: 1.112, 8.067, 50.481, 365.811, 0.708
[epoch:194, iter:151587] Loss: 1.113, 8.069, 50.486, 365.831, 0.632
[epoch:194, iter:151607] Loss: 1.112, 8.068, 50.477, 365.818, 0.675
Epoch: [193][700/782]	Time 0.082 (0.085)	Data 0.004 (0.003)	Loss 10.0130 (9.4725)	Acc@1 71.875 (80.452)	Acc@5 93.750 (96.777)
[epoch:194, iter:151627] Loss: 1.112, 8.067, 50.480, 365.828, 0.986
[epoch:194, iter:151647] Loss: 1.112, 8.069, 50.482, 365.856, 0.422
[epoch:194, iter:151667] Loss: 1.112, 8.070, 50.490, 365.900, 0.697
[epoch:194, iter:151687] Loss: 1.112, 8.072, 50.493, 365.919, 0.818
[epoch:194, iter:151707] Loss: 1.111, 8.072, 50.483, 365.912, 0.486
 * Acc@1 80.362 Acc@5 96.802
epoch 193, total time 66.31
Test: [0/313]	Time 0.287 (0.287)	Loss 1.3200 (1.3200)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2514 (1.1769)	Acc@1 59.375 (70.606)	Acc@5 96.875 (91.955)
Test: [200/313]	Time 0.008 (0.008)	Loss 0.6712 (1.1388)	Acc@1 71.875 (71.284)	Acc@5 100.000 (92.693)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.3373 (1.1481)	Acc@1 62.500 (71.055)	Acc@5 100.000 (92.899)
 * Acc@1 71.190 Acc@5 92.920
saving the best model!
==> training...
Epoch: [194][0/782]	Time 0.608 (0.608)	Data 0.520 (0.520)	Loss 9.3474 (9.3474)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
[epoch:195, iter:151709] Loss: 1.102, 8.088, 49.609, 362.990, 0.573
[epoch:195, iter:151729] Loss: 1.108, 8.051, 50.347, 364.751, 0.495
[epoch:195, iter:151749] Loss: 1.104, 8.060, 50.326, 365.245, 0.807
[epoch:195, iter:151769] Loss: 1.100, 8.045, 50.356, 364.910, 0.770
[epoch:195, iter:151789] Loss: 1.103, 8.044, 50.347, 364.807, 0.698
Epoch: [194][100/782]	Time 0.056 (0.085)	Data 0.002 (0.007)	Loss 10.2462 (9.4096)	Acc@1 71.875 (80.415)	Acc@5 96.875 (96.968)
[epoch:195, iter:151809] Loss: 1.105, 8.053, 50.333, 364.910, 0.909
[epoch:195, iter:151829] Loss: 1.105, 8.060, 50.300, 364.947, 0.572
[epoch:195, iter:151849] Loss: 1.105, 8.058, 50.296, 364.966, 0.464
[epoch:195, iter:151869] Loss: 1.105, 8.061, 50.308, 365.097, 0.406
[epoch:195, iter:151889] Loss: 1.105, 8.054, 50.256, 364.751, 0.726
Epoch: [194][200/782]	Time 0.089 (0.082)	Data 0.003 (0.005)	Loss 9.6187 (9.4129)	Acc@1 78.125 (81.001)	Acc@5 93.750 (96.821)
[epoch:195, iter:151909] Loss: 1.107, 8.056, 50.305, 365.066, 0.700
[epoch:195, iter:151929] Loss: 1.107, 8.055, 50.336, 365.224, 0.666
[epoch:195, iter:151949] Loss: 1.107, 8.049, 50.309, 365.084, 0.657
[epoch:195, iter:151969] Loss: 1.107, 8.055, 50.310, 365.076, 0.317
[epoch:195, iter:151989] Loss: 1.107, 8.052, 50.322, 365.062, 0.738
Epoch: [194][300/782]	Time 0.067 (0.081)	Data 0.002 (0.004)	Loss 9.3861 (9.4212)	Acc@1 82.812 (81.011)	Acc@5 100.000 (96.859)
[epoch:195, iter:152009] Loss: 1.108, 8.056, 50.348, 365.109, 0.495
[epoch:195, iter:152029] Loss: 1.108, 8.056, 50.340, 365.030, 0.981
[epoch:195, iter:152049] Loss: 1.108, 8.055, 50.312, 364.933, 0.484
[epoch:195, iter:152069] Loss: 1.108, 8.058, 50.322, 364.972, 0.586
[epoch:195, iter:152089] Loss: 1.108, 8.059, 50.336, 365.017, 0.797
Epoch: [194][400/782]	Time 0.091 (0.081)	Data 0.003 (0.004)	Loss 9.5585 (9.4290)	Acc@1 85.938 (80.732)	Acc@5 95.312 (96.805)
[epoch:195, iter:152109] Loss: 1.108, 8.061, 50.341, 365.057, 0.753
[epoch:195, iter:152129] Loss: 1.108, 8.059, 50.354, 365.111, 0.766
[epoch:195, iter:152149] Loss: 1.108, 8.063, 50.364, 365.207, 0.601
[epoch:195, iter:152169] Loss: 1.108, 8.066, 50.406, 365.411, 0.518
[epoch:195, iter:152189] Loss: 1.108, 8.065, 50.417, 365.445, 0.613
Epoch: [194][500/782]	Time 0.082 (0.082)	Data 0.002 (0.003)	Loss 9.5236 (9.4513)	Acc@1 78.125 (80.673)	Acc@5 96.875 (96.719)
[epoch:195, iter:152209] Loss: 1.108, 8.063, 50.407, 365.396, 0.629
[epoch:195, iter:152229] Loss: 1.109, 8.063, 50.411, 365.415, 0.550
[epoch:195, iter:152249] Loss: 1.108, 8.065, 50.414, 365.440, 0.842
[epoch:195, iter:152269] Loss: 1.108, 8.065, 50.400, 365.409, 0.587
[epoch:195, iter:152289] Loss: 1.108, 8.064, 50.412, 365.442, 0.559
Epoch: [194][600/782]	Time 0.091 (0.081)	Data 0.003 (0.003)	Loss 10.0716 (9.4589)	Acc@1 82.812 (80.527)	Acc@5 98.438 (96.711)
[epoch:195, iter:152309] Loss: 1.109, 8.066, 50.425, 365.461, 0.819
[epoch:195, iter:152329] Loss: 1.109, 8.066, 50.432, 365.489, 0.880
[epoch:195, iter:152349] Loss: 1.109, 8.067, 50.440, 365.548, 0.901
[epoch:195, iter:152369] Loss: 1.109, 8.065, 50.445, 365.549, 0.661
[epoch:195, iter:152389] Loss: 1.109, 8.065, 50.459, 365.614, 0.577
Epoch: [194][700/782]	Time 0.075 (0.081)	Data 0.003 (0.003)	Loss 9.3956 (9.4654)	Acc@1 82.812 (80.499)	Acc@5 95.312 (96.726)
[epoch:195, iter:152409] Loss: 1.109, 8.066, 50.468, 365.686, 0.586
[epoch:195, iter:152429] Loss: 1.109, 8.066, 50.467, 365.682, 0.734
[epoch:195, iter:152449] Loss: 1.109, 8.064, 50.470, 365.684, 0.614
[epoch:195, iter:152469] Loss: 1.109, 8.065, 50.496, 365.819, 0.903
[epoch:195, iter:152489] Loss: 1.109, 8.065, 50.498, 365.852, 0.640
 * Acc@1 80.446 Acc@5 96.712
epoch 194, total time 63.16
Test: [0/313]	Time 0.225 (0.225)	Loss 1.3099 (1.3099)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.012 (0.009)	Loss 1.2851 (1.1746)	Acc@1 59.375 (70.545)	Acc@5 96.875 (91.955)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7335 (1.1360)	Acc@1 78.125 (71.300)	Acc@5 100.000 (92.615)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.4246 (1.1485)	Acc@1 65.625 (71.024)	Acc@5 90.625 (92.733)
 * Acc@1 71.140 Acc@5 92.780
==> training...
Epoch: [195][0/782]	Time 0.570 (0.570)	Data 0.505 (0.505)	Loss 9.5042 (9.5042)	Acc@1 82.812 (82.812)	Acc@5 93.750 (93.750)
[epoch:196, iter:152491] Loss: 1.123, 8.145, 50.372, 363.622, 0.646
[epoch:196, iter:152511] Loss: 1.115, 7.980, 50.389, 365.901, 0.718
[epoch:196, iter:152531] Loss: 1.107, 8.050, 50.358, 366.100, 0.820
[epoch:196, iter:152551] Loss: 1.111, 8.069, 50.656, 367.256, 0.485
[epoch:196, iter:152571] Loss: 1.111, 8.056, 50.606, 366.702, 0.605
Epoch: [195][100/782]	Time 0.080 (0.086)	Data 0.002 (0.008)	Loss 10.0581 (9.4975)	Acc@1 76.562 (80.523)	Acc@5 96.875 (96.751)
[epoch:196, iter:152591] Loss: 1.107, 8.048, 50.646, 366.692, 0.748
[epoch:196, iter:152611] Loss: 1.108, 8.058, 50.555, 366.415, 0.548
[epoch:196, iter:152631] Loss: 1.110, 8.051, 50.540, 366.235, 0.269
[epoch:196, iter:152651] Loss: 1.110, 8.061, 50.509, 366.207, 0.456
[epoch:196, iter:152671] Loss: 1.109, 8.061, 50.486, 366.146, 0.592
Epoch: [195][200/782]	Time 0.065 (0.083)	Data 0.002 (0.005)	Loss 8.8674 (9.4654)	Acc@1 89.062 (80.706)	Acc@5 100.000 (96.859)
[epoch:196, iter:152691] Loss: 1.109, 8.064, 50.496, 366.185, 0.321
[epoch:196, iter:152711] Loss: 1.109, 8.066, 50.494, 366.100, 0.585
[epoch:196, iter:152731] Loss: 1.108, 8.069, 50.477, 366.034, 0.738
[epoch:196, iter:152751] Loss: 1.107, 8.071, 50.461, 365.965, 0.549
[epoch:196, iter:152771] Loss: 1.107, 8.071, 50.460, 366.072, 0.568
Epoch: [195][300/782]	Time 0.083 (0.082)	Data 0.003 (0.004)	Loss 9.4497 (9.4645)	Acc@1 76.562 (80.399)	Acc@5 100.000 (96.896)
[epoch:196, iter:152791] Loss: 1.108, 8.069, 50.449, 365.910, 0.690
[epoch:196, iter:152811] Loss: 1.107, 8.069, 50.447, 365.898, 0.739
[epoch:196, iter:152831] Loss: 1.108, 8.067, 50.469, 365.988, 0.633
[epoch:196, iter:152851] Loss: 1.107, 8.067, 50.454, 366.016, 0.575
[epoch:196, iter:152871] Loss: 1.108, 8.068, 50.495, 366.219, 0.624
Epoch: [195][400/782]	Time 0.077 (0.081)	Data 0.003 (0.004)	Loss 9.1115 (9.4720)	Acc@1 82.812 (80.424)	Acc@5 98.438 (96.988)
[epoch:196, iter:152891] Loss: 1.108, 8.068, 50.514, 366.325, 0.599
[epoch:196, iter:152911] Loss: 1.109, 8.071, 50.516, 366.359, 0.464
[epoch:196, iter:152931] Loss: 1.109, 8.070, 50.497, 366.219, 0.596
[epoch:196, iter:152951] Loss: 1.109, 8.070, 50.491, 366.177, 0.510
[epoch:196, iter:152971] Loss: 1.109, 8.071, 50.502, 366.228, 0.657
Epoch: [195][500/782]	Time 0.096 (0.082)	Data 0.003 (0.003)	Loss 9.1733 (9.4641)	Acc@1 87.500 (80.430)	Acc@5 98.438 (97.034)
[epoch:196, iter:152991] Loss: 1.109, 8.070, 50.493, 366.161, 0.361
[epoch:196, iter:153011] Loss: 1.109, 8.069, 50.496, 366.144, 0.900
[epoch:196, iter:153031] Loss: 1.109, 8.068, 50.479, 366.042, 0.783
[epoch:196, iter:153051] Loss: 1.108, 8.068, 50.483, 366.052, 0.657
[epoch:196, iter:153071] Loss: 1.108, 8.067, 50.462, 365.985, 0.810
Epoch: [195][600/782]	Time 0.091 (0.081)	Data 0.002 (0.003)	Loss 9.6653 (9.4610)	Acc@1 85.938 (80.343)	Acc@5 96.875 (96.987)
[epoch:196, iter:153091] Loss: 1.109, 8.064, 50.464, 365.981, 0.487
[epoch:196, iter:153111] Loss: 1.109, 8.067, 50.469, 365.967, 0.735
[epoch:196, iter:153131] Loss: 1.108, 8.068, 50.467, 365.946, 0.764
[epoch:196, iter:153151] Loss: 1.109, 8.068, 50.474, 365.960, 0.598
[epoch:196, iter:153171] Loss: 1.109, 8.066, 50.469, 365.913, 0.366
Epoch: [195][700/782]	Time 0.096 (0.082)	Data 0.002 (0.003)	Loss 9.4785 (9.4704)	Acc@1 82.812 (80.245)	Acc@5 96.875 (96.913)
[epoch:196, iter:153191] Loss: 1.109, 8.068, 50.481, 365.995, 0.712
[epoch:196, iter:153211] Loss: 1.110, 8.068, 50.489, 366.027, 0.611
[epoch:196, iter:153231] Loss: 1.109, 8.067, 50.487, 366.012, 0.710
[epoch:196, iter:153251] Loss: 1.109, 8.067, 50.490, 366.008, 0.751
[epoch:196, iter:153271] Loss: 1.110, 8.068, 50.500, 366.053, 0.569
 * Acc@1 80.302 Acc@5 96.868
epoch 195, total time 63.57
Test: [0/313]	Time 0.235 (0.235)	Loss 1.2372 (1.2372)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3374 (1.1728)	Acc@1 56.250 (70.730)	Acc@5 96.875 (92.296)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.6844 (1.1377)	Acc@1 78.125 (71.206)	Acc@5 100.000 (92.708)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3993 (1.1496)	Acc@1 62.500 (70.785)	Acc@5 100.000 (92.774)
 * Acc@1 70.900 Acc@5 92.810
==> training...
Epoch: [196][0/782]	Time 0.579 (0.579)	Data 0.512 (0.512)	Loss 9.0083 (9.0083)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
[epoch:197, iter:153273] Loss: 1.019, 7.901, 47.961, 359.862, 0.596
[epoch:197, iter:153293] Loss: 1.113, 7.984, 49.879, 362.549, 0.725
[epoch:197, iter:153313] Loss: 1.114, 8.004, 50.255, 364.398, 0.732
[epoch:197, iter:153333] Loss: 1.113, 8.029, 50.399, 365.258, 0.483
[epoch:197, iter:153353] Loss: 1.113, 8.047, 50.490, 365.687, 0.547
Epoch: [196][100/782]	Time 0.079 (0.080)	Data 0.002 (0.007)	Loss 9.5562 (9.4705)	Acc@1 78.125 (80.291)	Acc@5 92.188 (96.674)
[epoch:197, iter:153373] Loss: 1.115, 8.056, 50.520, 365.722, 0.902
[epoch:197, iter:153393] Loss: 1.117, 8.078, 50.570, 365.985, 0.730
[epoch:197, iter:153413] Loss: 1.116, 8.066, 50.526, 365.703, 0.421
[epoch:197, iter:153433] Loss: 1.117, 8.062, 50.543, 365.890, 0.851
[epoch:197, iter:153453] Loss: 1.117, 8.056, 50.555, 365.938, 0.373
Epoch: [196][200/782]	Time 0.081 (0.080)	Data 0.003 (0.005)	Loss 9.5574 (9.4820)	Acc@1 76.562 (80.589)	Acc@5 92.188 (96.805)
[epoch:197, iter:153473] Loss: 1.116, 8.060, 50.594, 366.177, 0.714
[epoch:197, iter:153493] Loss: 1.115, 8.058, 50.574, 366.024, 0.517
[epoch:197, iter:153513] Loss: 1.115, 8.056, 50.608, 366.273, 1.010
[epoch:197, iter:153533] Loss: 1.114, 8.059, 50.583, 366.172, 0.751
[epoch:197, iter:153553] Loss: 1.113, 8.060, 50.579, 366.149, 0.755
Epoch: [196][300/782]	Time 0.065 (0.081)	Data 0.002 (0.004)	Loss 9.1055 (9.4742)	Acc@1 81.250 (80.570)	Acc@5 98.438 (96.839)
[epoch:197, iter:153573] Loss: 1.112, 8.059, 50.551, 366.079, 0.611
[epoch:197, iter:153593] Loss: 1.111, 8.064, 50.562, 366.153, 0.736
[epoch:197, iter:153613] Loss: 1.111, 8.065, 50.580, 366.240, 0.967
[epoch:197, iter:153633] Loss: 1.111, 8.066, 50.559, 366.137, 0.538
[epoch:197, iter:153653] Loss: 1.111, 8.066, 50.556, 366.127, 0.552
Epoch: [196][400/782]	Time 0.084 (0.080)	Data 0.002 (0.004)	Loss 9.5572 (9.4783)	Acc@1 79.688 (80.334)	Acc@5 96.875 (96.867)
[epoch:197, iter:153673] Loss: 1.110, 8.066, 50.544, 366.071, 0.720
[epoch:197, iter:153693] Loss: 1.110, 8.065, 50.564, 366.183, 0.605
[epoch:197, iter:153713] Loss: 1.110, 8.067, 50.559, 366.202, 0.765
[epoch:197, iter:153733] Loss: 1.110, 8.066, 50.555, 366.137, 0.842
[epoch:197, iter:153753] Loss: 1.110, 8.065, 50.555, 366.144, 0.641
Epoch: [196][500/782]	Time 0.090 (0.080)	Data 0.003 (0.003)	Loss 9.3886 (9.4799)	Acc@1 82.812 (80.336)	Acc@5 96.875 (96.834)
[epoch:197, iter:153773] Loss: 1.110, 8.064, 50.537, 366.078, 0.569
[epoch:197, iter:153793] Loss: 1.110, 8.066, 50.518, 365.998, 0.420
[epoch:197, iter:153813] Loss: 1.111, 8.070, 50.539, 366.045, 0.738
[epoch:197, iter:153833] Loss: 1.111, 8.071, 50.544, 366.058, 0.690
[epoch:197, iter:153853] Loss: 1.111, 8.072, 50.537, 365.984, 0.486
Epoch: [196][600/782]	Time 0.093 (0.080)	Data 0.003 (0.003)	Loss 8.8832 (9.4774)	Acc@1 89.062 (80.366)	Acc@5 98.438 (96.800)
[epoch:197, iter:153873] Loss: 1.111, 8.068, 50.529, 365.962, 0.449
[epoch:197, iter:153893] Loss: 1.110, 8.067, 50.517, 365.918, 0.651
[epoch:197, iter:153913] Loss: 1.111, 8.067, 50.513, 365.883, 0.519
[epoch:197, iter:153933] Loss: 1.111, 8.068, 50.533, 365.955, 0.584
[epoch:197, iter:153953] Loss: 1.111, 8.068, 50.526, 365.944, 0.713
Epoch: [196][700/782]	Time 0.070 (0.080)	Data 0.002 (0.003)	Loss 8.8946 (9.4775)	Acc@1 85.938 (80.325)	Acc@5 98.438 (96.793)
[epoch:197, iter:153973] Loss: 1.111, 8.069, 50.518, 365.899, 0.547
[epoch:197, iter:153993] Loss: 1.111, 8.071, 50.516, 365.896, 0.528
[epoch:197, iter:154013] Loss: 1.111, 8.070, 50.511, 365.840, 0.385
[epoch:197, iter:154033] Loss: 1.111, 8.069, 50.501, 365.792, 0.590
[epoch:197, iter:154053] Loss: 1.111, 8.068, 50.501, 365.819, 0.500
 * Acc@1 80.348 Acc@5 96.810
epoch 196, total time 62.34
Test: [0/313]	Time 0.258 (0.258)	Loss 1.2843 (1.2843)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.1885 (1.1665)	Acc@1 59.375 (71.349)	Acc@5 96.875 (92.203)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.6549 (1.1330)	Acc@1 81.250 (71.533)	Acc@5 100.000 (92.584)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.3377 (1.1467)	Acc@1 65.625 (71.096)	Acc@5 96.875 (92.660)
 * Acc@1 71.210 Acc@5 92.710
saving the best model!
==> training...
Epoch: [197][0/782]	Time 0.555 (0.555)	Data 0.483 (0.483)	Loss 9.6034 (9.6034)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
[epoch:198, iter:154055] Loss: 1.119, 8.034, 50.536, 371.257, 0.663
[epoch:198, iter:154075] Loss: 1.119, 8.027, 50.174, 364.190, 0.678
[epoch:198, iter:154095] Loss: 1.118, 8.024, 50.449, 365.859, 0.508
[epoch:198, iter:154115] Loss: 1.114, 8.009, 50.312, 365.038, 0.628
[epoch:198, iter:154135] Loss: 1.117, 8.031, 50.422, 365.435, 0.726
Epoch: [197][100/782]	Time 0.072 (0.091)	Data 0.003 (0.007)	Loss 9.4856 (9.4787)	Acc@1 81.250 (80.538)	Acc@5 93.750 (96.999)
[epoch:198, iter:154155] Loss: 1.116, 8.039, 50.520, 365.948, 0.674
[epoch:198, iter:154175] Loss: 1.117, 8.037, 50.570, 366.386, 0.567
[epoch:198, iter:154195] Loss: 1.117, 8.034, 50.569, 366.318, 0.507
[epoch:198, iter:154215] Loss: 1.116, 8.040, 50.544, 366.145, 0.849
[epoch:198, iter:154235] Loss: 1.115, 8.041, 50.551, 366.138, 0.691
Epoch: [197][200/782]	Time 0.088 (0.085)	Data 0.002 (0.005)	Loss 9.7978 (9.4746)	Acc@1 73.438 (80.504)	Acc@5 96.875 (96.743)
[epoch:198, iter:154255] Loss: 1.113, 8.045, 50.489, 365.819, 0.785
[epoch:198, iter:154275] Loss: 1.112, 8.039, 50.461, 365.664, 0.747
[epoch:198, iter:154295] Loss: 1.111, 8.037, 50.410, 365.355, 0.591
[epoch:198, iter:154315] Loss: 1.113, 8.040, 50.445, 365.552, 0.842
[epoch:198, iter:154335] Loss: 1.112, 8.041, 50.428, 365.552, 0.688
Epoch: [197][300/782]	Time 0.095 (0.086)	Data 0.003 (0.004)	Loss 9.8690 (9.4639)	Acc@1 76.562 (80.212)	Acc@5 93.750 (96.833)
[epoch:198, iter:154355] Loss: 1.112, 8.038, 50.417, 365.445, 0.830
[epoch:198, iter:154375] Loss: 1.112, 8.039, 50.442, 365.567, 0.574
[epoch:198, iter:154395] Loss: 1.111, 8.043, 50.474, 365.754, 0.794
[epoch:198, iter:154415] Loss: 1.112, 8.049, 50.500, 365.803, 0.478
[epoch:198, iter:154435] Loss: 1.111, 8.052, 50.505, 365.854, 0.635
Epoch: [197][400/782]	Time 0.081 (0.086)	Data 0.003 (0.004)	Loss 9.4598 (9.4777)	Acc@1 82.812 (80.256)	Acc@5 100.000 (96.844)
[epoch:198, iter:154455] Loss: 1.111, 8.057, 50.499, 365.845, 0.545
[epoch:198, iter:154475] Loss: 1.110, 8.057, 50.501, 365.889, 0.580
[epoch:198, iter:154495] Loss: 1.110, 8.054, 50.502, 365.877, 0.629
[epoch:198, iter:154515] Loss: 1.110, 8.054, 50.502, 365.872, 0.447
[epoch:198, iter:154535] Loss: 1.111, 8.058, 50.508, 365.876, 0.588
Epoch: [197][500/782]	Time 0.092 (0.086)	Data 0.002 (0.003)	Loss 9.2154 (9.4710)	Acc@1 82.812 (80.367)	Acc@5 98.438 (96.797)
[epoch:198, iter:154555] Loss: 1.110, 8.059, 50.491, 365.792, 0.466
[epoch:198, iter:154575] Loss: 1.110, 8.058, 50.505, 365.896, 0.679
[epoch:198, iter:154595] Loss: 1.111, 8.057, 50.517, 365.897, 0.427
[epoch:198, iter:154615] Loss: 1.112, 8.060, 50.529, 365.961, 0.494
[epoch:198, iter:154635] Loss: 1.111, 8.063, 50.530, 365.993, 0.765
Epoch: [197][600/782]	Time 0.089 (0.086)	Data 0.003 (0.003)	Loss 9.0229 (9.4745)	Acc@1 82.812 (80.452)	Acc@5 98.438 (96.781)
[epoch:198, iter:154655] Loss: 1.112, 8.063, 50.524, 365.937, 0.468
[epoch:198, iter:154675] Loss: 1.112, 8.063, 50.524, 365.914, 0.569
[epoch:198, iter:154695] Loss: 1.112, 8.062, 50.524, 365.895, 0.595
[epoch:198, iter:154715] Loss: 1.111, 8.059, 50.523, 365.893, 0.547
[epoch:198, iter:154735] Loss: 1.112, 8.060, 50.516, 365.848, 0.761
Epoch: [197][700/782]	Time 0.084 (0.086)	Data 0.003 (0.003)	Loss 9.9231 (9.4717)	Acc@1 71.875 (80.481)	Acc@5 96.875 (96.822)
[epoch:198, iter:154755] Loss: 1.112, 8.060, 50.522, 365.892, 0.945
[epoch:198, iter:154775] Loss: 1.111, 8.057, 50.513, 365.871, 1.012
[epoch:198, iter:154795] Loss: 1.111, 8.059, 50.509, 365.830, 0.484
[epoch:198, iter:154815] Loss: 1.111, 8.060, 50.519, 365.869, 0.591
[epoch:198, iter:154835] Loss: 1.111, 8.060, 50.517, 365.849, 0.387
 * Acc@1 80.488 Acc@5 96.770
epoch 197, total time 67.54
Test: [0/313]	Time 0.267 (0.267)	Loss 1.2662 (1.2662)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.011 (0.011)	Loss 1.3550 (1.1758)	Acc@1 59.375 (70.637)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.010 (0.009)	Loss 0.6711 (1.1371)	Acc@1 75.000 (71.035)	Acc@5 100.000 (92.755)
Test: [300/313]	Time 0.008 (0.009)	Loss 1.4006 (1.1505)	Acc@1 62.500 (70.785)	Acc@5 96.875 (92.743)
 * Acc@1 70.940 Acc@5 92.780
==> training...
Epoch: [198][0/782]	Time 0.661 (0.661)	Data 0.563 (0.563)	Loss 9.3876 (9.3876)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
[epoch:199, iter:154837] Loss: 1.097, 7.923, 50.591, 365.527, 0.599
[epoch:199, iter:154857] Loss: 1.105, 8.086, 50.665, 367.264, 0.559
[epoch:199, iter:154877] Loss: 1.104, 8.145, 50.683, 367.997, 0.606
[epoch:199, iter:154897] Loss: 1.105, 8.133, 50.608, 367.195, 0.585
[epoch:199, iter:154917] Loss: 1.105, 8.133, 50.646, 367.413, 0.569
Epoch: [198][100/782]	Time 0.092 (0.091)	Data 0.003 (0.008)	Loss 9.5519 (9.5313)	Acc@1 76.562 (79.749)	Acc@5 100.000 (96.767)
[epoch:199, iter:154937] Loss: 1.106, 8.121, 50.538, 366.659, 0.655
[epoch:199, iter:154957] Loss: 1.106, 8.107, 50.566, 366.850, 0.369
[epoch:199, iter:154977] Loss: 1.107, 8.104, 50.584, 366.859, 0.489
[epoch:199, iter:154997] Loss: 1.107, 8.098, 50.559, 366.505, 0.683
[epoch:199, iter:155017] Loss: 1.107, 8.089, 50.547, 366.356, 0.539
Epoch: [198][200/782]	Time 0.081 (0.090)	Data 0.003 (0.005)	Loss 9.5816 (9.5167)	Acc@1 78.125 (80.030)	Acc@5 95.312 (96.743)
[epoch:199, iter:155037] Loss: 1.108, 8.087, 50.603, 366.574, 0.715
[epoch:199, iter:155057] Loss: 1.107, 8.085, 50.594, 366.516, 0.705
[epoch:199, iter:155077] Loss: 1.107, 8.083, 50.594, 366.484, 0.561
[epoch:199, iter:155097] Loss: 1.107, 8.081, 50.539, 366.275, 0.617
[epoch:199, iter:155117] Loss: 1.106, 8.078, 50.542, 366.229, 0.598
Epoch: [198][300/782]	Time 0.077 (0.084)	Data 0.002 (0.004)	Loss 9.3477 (9.4729)	Acc@1 84.375 (80.419)	Acc@5 96.875 (96.808)
[epoch:199, iter:155137] Loss: 1.107, 8.071, 50.506, 366.008, 0.563
[epoch:199, iter:155157] Loss: 1.108, 8.071, 50.481, 365.924, 0.354
[epoch:199, iter:155177] Loss: 1.108, 8.070, 50.479, 365.880, 0.445
[epoch:199, iter:155197] Loss: 1.108, 8.067, 50.468, 365.841, 0.764
[epoch:199, iter:155217] Loss: 1.108, 8.068, 50.478, 365.892, 0.746
Epoch: [198][400/782]	Time 0.092 (0.084)	Data 0.003 (0.004)	Loss 9.5079 (9.4537)	Acc@1 82.812 (80.588)	Acc@5 96.875 (96.871)
[epoch:199, iter:155237] Loss: 1.108, 8.067, 50.480, 365.912, 0.697
[epoch:199, iter:155257] Loss: 1.107, 8.066, 50.468, 365.882, 0.684
[epoch:199, iter:155277] Loss: 1.107, 8.066, 50.456, 365.831, 0.564
[epoch:199, iter:155297] Loss: 1.108, 8.069, 50.471, 365.916, 0.633
[epoch:199, iter:155317] Loss: 1.107, 8.068, 50.471, 365.944, 0.754
Epoch: [198][500/782]	Time 0.092 (0.083)	Data 0.003 (0.004)	Loss 9.1780 (9.4508)	Acc@1 87.500 (80.576)	Acc@5 95.312 (96.813)
[epoch:199, iter:155337] Loss: 1.107, 8.066, 50.451, 365.851, 0.548
[epoch:199, iter:155357] Loss: 1.107, 8.066, 50.450, 365.803, 0.739
[epoch:199, iter:155377] Loss: 1.107, 8.067, 50.445, 365.773, 0.790
[epoch:199, iter:155397] Loss: 1.107, 8.064, 50.430, 365.674, 0.678
[epoch:199, iter:155417] Loss: 1.107, 8.064, 50.420, 365.605, 0.548
Epoch: [198][600/782]	Time 0.075 (0.083)	Data 0.002 (0.003)	Loss 9.4834 (9.4497)	Acc@1 76.562 (80.652)	Acc@5 96.875 (96.833)
[epoch:199, iter:155437] Loss: 1.107, 8.066, 50.430, 365.640, 0.710
[epoch:199, iter:155457] Loss: 1.107, 8.065, 50.419, 365.547, 0.389
[epoch:199, iter:155477] Loss: 1.108, 8.065, 50.433, 365.608, 0.745
[epoch:199, iter:155497] Loss: 1.108, 8.065, 50.425, 365.620, 0.947
[epoch:199, iter:155517] Loss: 1.108, 8.063, 50.432, 365.650, 0.520
Epoch: [198][700/782]	Time 0.092 (0.082)	Data 0.003 (0.003)	Loss 9.8001 (9.4546)	Acc@1 79.688 (80.635)	Acc@5 96.875 (96.804)
[epoch:199, iter:155537] Loss: 1.107, 8.065, 50.439, 365.684, 0.642
[epoch:199, iter:155557] Loss: 1.108, 8.064, 50.441, 365.656, 0.674
[epoch:199, iter:155577] Loss: 1.108, 8.063, 50.448, 365.704, 0.572
[epoch:199, iter:155597] Loss: 1.108, 8.064, 50.448, 365.704, 0.638
[epoch:199, iter:155617] Loss: 1.108, 8.063, 50.457, 365.723, 0.343
 * Acc@1 80.552 Acc@5 96.798
epoch 198, total time 64.10
Test: [0/313]	Time 0.263 (0.263)	Loss 1.3035 (1.3035)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.009 (0.011)	Loss 1.3237 (1.1740)	Acc@1 59.375 (70.730)	Acc@5 96.875 (91.925)
Test: [200/313]	Time 0.008 (0.010)	Loss 0.6790 (1.1409)	Acc@1 81.250 (71.362)	Acc@5 100.000 (92.460)
Test: [300/313]	Time 0.008 (0.009)	Loss 1.3398 (1.1519)	Acc@1 62.500 (70.930)	Acc@5 96.875 (92.660)
 * Acc@1 71.050 Acc@5 92.720
==> training...
Epoch: [199][0/782]	Time 0.575 (0.575)	Data 0.482 (0.482)	Loss 10.6024 (10.6024)	Acc@1 76.562 (76.562)	Acc@5 89.062 (89.062)
[epoch:200, iter:155619] Loss: 1.191, 8.612, 54.120, 375.888, 0.956
[epoch:200, iter:155639] Loss: 1.114, 8.148, 51.065, 368.861, 0.613
[epoch:200, iter:155659] Loss: 1.107, 8.066, 50.658, 367.146, 0.488
[epoch:200, iter:155679] Loss: 1.108, 8.072, 50.612, 366.741, 0.720
[epoch:200, iter:155699] Loss: 1.110, 8.053, 50.481, 365.916, 0.635
Epoch: [199][100/782]	Time 0.090 (0.094)	Data 0.002 (0.007)	Loss 9.5033 (9.4302)	Acc@1 82.812 (81.142)	Acc@5 95.312 (97.076)
[epoch:200, iter:155719] Loss: 1.109, 8.039, 50.519, 366.086, 0.562
[epoch:200, iter:155739] Loss: 1.108, 8.048, 50.521, 366.131, 0.523
[epoch:200, iter:155759] Loss: 1.107, 8.044, 50.468, 366.041, 0.734
[epoch:200, iter:155779] Loss: 1.109, 8.046, 50.519, 366.034, 0.596
[epoch:200, iter:155799] Loss: 1.108, 8.054, 50.481, 366.000, 0.534
Epoch: [199][200/782]	Time 0.074 (0.088)	Data 0.002 (0.005)	Loss 9.4178 (9.4524)	Acc@1 85.938 (80.892)	Acc@5 98.438 (96.906)
[epoch:200, iter:155819] Loss: 1.109, 8.057, 50.548, 366.263, 0.433
[epoch:200, iter:155839] Loss: 1.110, 8.064, 50.564, 366.377, 0.571
[epoch:200, iter:155859] Loss: 1.108, 8.068, 50.544, 366.276, 0.718
[epoch:200, iter:155879] Loss: 1.109, 8.067, 50.569, 366.388, 0.513
[epoch:200, iter:155899] Loss: 1.109, 8.065, 50.565, 366.314, 0.518
Epoch: [199][300/782]	Time 0.076 (0.087)	Data 0.002 (0.004)	Loss 9.2779 (9.4543)	Acc@1 82.812 (80.980)	Acc@5 96.875 (96.932)
[epoch:200, iter:155919] Loss: 1.109, 8.061, 50.546, 366.132, 0.586
[epoch:200, iter:155939] Loss: 1.109, 8.063, 50.574, 366.205, 0.794
[epoch:200, iter:155959] Loss: 1.109, 8.060, 50.561, 366.163, 0.739
[epoch:200, iter:155979] Loss: 1.109, 8.061, 50.530, 366.001, 0.488
[epoch:200, iter:155999] Loss: 1.109, 8.061, 50.531, 366.024, 0.559
Epoch: [199][400/782]	Time 0.094 (0.086)	Data 0.003 (0.004)	Loss 9.0421 (9.4621)	Acc@1 82.812 (80.763)	Acc@5 95.312 (96.887)
[epoch:200, iter:156019] Loss: 1.110, 8.065, 50.524, 365.972, 0.655
[epoch:200, iter:156039] Loss: 1.111, 8.061, 50.552, 366.034, 0.808
[epoch:200, iter:156059] Loss: 1.111, 8.062, 50.543, 365.995, 0.685
[epoch:200, iter:156079] Loss: 1.111, 8.060, 50.522, 365.880, 0.553
[epoch:200, iter:156099] Loss: 1.110, 8.059, 50.506, 365.823, 0.294
Epoch: [199][500/782]	Time 0.095 (0.087)	Data 0.003 (0.004)	Loss 9.3774 (9.4597)	Acc@1 79.688 (80.639)	Acc@5 100.000 (96.828)
[epoch:200, iter:156119] Loss: 1.110, 8.060, 50.491, 365.747, 0.583
[epoch:200, iter:156139] Loss: 1.110, 8.060, 50.480, 365.708, 0.580
[epoch:200, iter:156159] Loss: 1.110, 8.060, 50.504, 365.792, 0.399
[epoch:200, iter:156179] Loss: 1.109, 8.058, 50.483, 365.706, 0.648
[epoch:200, iter:156199] Loss: 1.110, 8.059, 50.489, 365.700, 0.644
Epoch: [199][600/782]	Time 0.082 (0.087)	Data 0.002 (0.003)	Loss 9.6333 (9.4670)	Acc@1 81.250 (80.545)	Acc@5 98.438 (96.826)
[epoch:200, iter:156219] Loss: 1.110, 8.060, 50.507, 365.810, 0.622
[epoch:200, iter:156239] Loss: 1.110, 8.058, 50.507, 365.806, 0.615
[epoch:200, iter:156259] Loss: 1.110, 8.058, 50.492, 365.728, 0.507
[epoch:200, iter:156279] Loss: 1.110, 8.060, 50.493, 365.731, 0.541
[epoch:200, iter:156299] Loss: 1.111, 8.058, 50.505, 365.792, 0.364
Epoch: [199][700/782]	Time 0.094 (0.087)	Data 0.003 (0.003)	Loss 10.0206 (9.4671)	Acc@1 71.875 (80.539)	Acc@5 98.438 (96.866)
[epoch:200, iter:156319] Loss: 1.111, 8.057, 50.505, 365.785, 0.922
[epoch:200, iter:156339] Loss: 1.111, 8.059, 50.504, 365.820, 0.776
[epoch:200, iter:156359] Loss: 1.110, 8.061, 50.505, 365.846, 0.551
[epoch:200, iter:156379] Loss: 1.110, 8.063, 50.501, 365.802, 0.755
[epoch:200, iter:156399] Loss: 1.110, 8.062, 50.505, 365.832, 0.344
 * Acc@1 80.514 Acc@5 96.868
epoch 199, total time 68.17
Test: [0/313]	Time 0.216 (0.216)	Loss 1.3534 (1.3534)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.3110 (1.1773)	Acc@1 59.375 (70.854)	Acc@5 96.875 (91.986)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.6973 (1.1381)	Acc@1 78.125 (71.331)	Acc@5 100.000 (92.615)
Test: [300/313]	Time 0.009 (0.008)	Loss 1.3846 (1.1474)	Acc@1 65.625 (71.117)	Acc@5 96.875 (92.701)
 * Acc@1 71.290 Acc@5 92.750
saving the best model!
==> training...
Epoch: [200][0/782]	Time 0.556 (0.556)	Data 0.471 (0.471)	Loss 9.2698 (9.2698)	Acc@1 85.938 (85.938)	Acc@5 96.875 (96.875)
[epoch:201, iter:156401] Loss: 1.036, 7.746, 50.058, 364.913, 0.663
[epoch:201, iter:156421] Loss: 1.108, 7.992, 50.104, 364.503, 0.561
[epoch:201, iter:156441] Loss: 1.109, 8.003, 50.309, 365.209, 0.729
[epoch:201, iter:156461] Loss: 1.108, 8.025, 50.207, 364.556, 0.419
[epoch:201, iter:156481] Loss: 1.108, 8.024, 50.186, 364.678, 0.721
Epoch: [200][100/782]	Time 0.077 (0.094)	Data 0.002 (0.007)	Loss 10.0333 (9.4060)	Acc@1 79.688 (80.569)	Acc@5 96.875 (97.169)
[epoch:201, iter:156501] Loss: 1.108, 8.042, 50.198, 364.968, 0.625
[epoch:201, iter:156521] Loss: 1.109, 8.040, 50.242, 365.093, 0.297
[epoch:201, iter:156541] Loss: 1.107, 8.043, 50.245, 365.231, 0.552
[epoch:201, iter:156561] Loss: 1.108, 8.037, 50.316, 365.367, 0.526
[epoch:201, iter:156581] Loss: 1.108, 8.036, 50.342, 365.400, 0.734
Epoch: [200][200/782]	Time 0.074 (0.090)	Data 0.002 (0.005)	Loss 8.9813 (9.4082)	Acc@1 84.375 (81.056)	Acc@5 98.438 (97.163)
[epoch:201, iter:156601] Loss: 1.109, 8.037, 50.319, 365.259, 0.447
[epoch:201, iter:156621] Loss: 1.108, 8.043, 50.325, 365.356, 0.650
[epoch:201, iter:156641] Loss: 1.108, 8.047, 50.370, 365.573, 0.663
[epoch:201, iter:156661] Loss: 1.109, 8.052, 50.387, 365.546, 0.798
[epoch:201, iter:156681] Loss: 1.110, 8.059, 50.424, 365.690, 0.719
Epoch: [200][300/782]	Time 0.093 (0.089)	Data 0.003 (0.004)	Loss 9.6426 (9.4352)	Acc@1 79.688 (80.887)	Acc@5 96.875 (97.020)
[epoch:201, iter:156701] Loss: 1.110, 8.058, 50.428, 365.707, 0.658
[epoch:201, iter:156721] Loss: 1.111, 8.058, 50.437, 365.697, 0.489
[epoch:201, iter:156741] Loss: 1.111, 8.059, 50.455, 365.750, 0.430
[epoch:201, iter:156761] Loss: 1.111, 8.059, 50.489, 365.871, 0.871
[epoch:201, iter:156781] Loss: 1.111, 8.058, 50.485, 365.810, 0.530
Epoch: [200][400/782]	Time 0.070 (0.085)	Data 0.002 (0.004)	Loss 9.2887 (9.4541)	Acc@1 79.688 (80.712)	Acc@5 98.438 (96.972)
[epoch:201, iter:156801] Loss: 1.111, 8.062, 50.485, 365.814, 0.670
[epoch:201, iter:156821] Loss: 1.110, 8.061, 50.474, 365.744, 0.500
[epoch:201, iter:156841] Loss: 1.111, 8.058, 50.453, 365.616, 0.782
[epoch:201, iter:156861] Loss: 1.111, 8.057, 50.449, 365.555, 0.677
[epoch:201, iter:156881] Loss: 1.110, 8.057, 50.441, 365.533, 0.713
Epoch: [200][500/782]	Time 0.089 (0.086)	Data 0.003 (0.003)	Loss 9.2303 (9.4398)	Acc@1 75.000 (80.695)	Acc@5 95.312 (96.981)
[epoch:201, iter:156901] Loss: 1.110, 8.056, 50.426, 365.505, 0.752
[epoch:201, iter:156921] Loss: 1.111, 8.052, 50.448, 365.615, 0.563
[epoch:201, iter:156941] Loss: 1.110, 8.050, 50.427, 365.496, 0.325
[epoch:201, iter:156961] Loss: 1.110, 8.053, 50.433, 365.523, 0.698
[epoch:201, iter:156981] Loss: 1.111, 8.054, 50.439, 365.549, 0.558
Epoch: [200][600/782]	Time 0.096 (0.086)	Data 0.003 (0.003)	Loss 9.1789 (9.4447)	Acc@1 71.875 (80.629)	Acc@5 96.875 (96.950)
[epoch:201, iter:157001] Loss: 1.110, 8.054, 50.427, 365.485, 0.746
[epoch:201, iter:157021] Loss: 1.110, 8.053, 50.435, 365.550, 0.623
[epoch:201, iter:157041] Loss: 1.110, 8.054, 50.435, 365.534, 0.640
[epoch:201, iter:157061] Loss: 1.111, 8.054, 50.440, 365.557, 0.611
[epoch:201, iter:157081] Loss: 1.110, 8.054, 50.443, 365.580, 0.960
Epoch: [200][700/782]	Time 0.076 (0.086)	Data 0.002 (0.003)	Loss 9.7042 (9.4505)	Acc@1 79.688 (80.572)	Acc@5 96.875 (96.940)
[epoch:201, iter:157101] Loss: 1.111, 8.052, 50.441, 365.580, 0.661
[epoch:201, iter:157121] Loss: 1.110, 8.050, 50.441, 365.568, 0.438
[epoch:201, iter:157141] Loss: 1.111, 8.054, 50.446, 365.582, 0.739
[epoch:201, iter:157161] Loss: 1.111, 8.055, 50.455, 365.630, 0.692
[epoch:201, iter:157181] Loss: 1.111, 8.056, 50.449, 365.629, 0.922
 * Acc@1 80.542 Acc@5 96.914
epoch 200, total time 67.53
Test: [0/313]	Time 0.223 (0.223)	Loss 1.2744 (1.2744)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2261 (1.1751)	Acc@1 59.375 (70.761)	Acc@5 96.875 (91.894)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7324 (1.1384)	Acc@1 75.000 (71.362)	Acc@5 100.000 (92.475)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.4826 (1.1504)	Acc@1 62.500 (71.024)	Acc@5 93.750 (92.670)
 * Acc@1 71.160 Acc@5 92.720
==> Saving...
==> training...
Epoch: [201][0/782]	Time 0.504 (0.504)	Data 0.418 (0.418)	Loss 9.4837 (9.4837)	Acc@1 84.375 (84.375)	Acc@5 95.312 (95.312)
[epoch:202, iter:157183] Loss: 1.098, 8.007, 51.310, 371.037, 0.623
[epoch:202, iter:157203] Loss: 1.105, 8.031, 50.709, 366.509, 0.439
[epoch:202, iter:157223] Loss: 1.108, 8.017, 50.487, 365.614, 0.624
[epoch:202, iter:157243] Loss: 1.110, 8.044, 50.485, 366.045, 0.593
[epoch:202, iter:157263] Loss: 1.109, 8.025, 50.428, 365.588, 0.474
Epoch: [201][100/782]	Time 0.086 (0.085)	Data 0.002 (0.006)	Loss 10.1133 (9.4567)	Acc@1 82.812 (80.863)	Acc@5 92.188 (96.952)
[epoch:202, iter:157283] Loss: 1.110, 8.044, 50.524, 365.904, 0.792
[epoch:202, iter:157303] Loss: 1.110, 8.044, 50.432, 365.557, 0.810
[epoch:202, iter:157323] Loss: 1.108, 8.050, 50.455, 365.680, 0.881
[epoch:202, iter:157343] Loss: 1.108, 8.043, 50.447, 365.609, 0.521
[epoch:202, iter:157363] Loss: 1.109, 8.050, 50.458, 365.693, 0.761
Epoch: [201][200/782]	Time 0.076 (0.085)	Data 0.002 (0.004)	Loss 9.9987 (9.4459)	Acc@1 81.250 (80.418)	Acc@5 95.312 (96.859)
[epoch:202, iter:157383] Loss: 1.109, 8.048, 50.429, 365.549, 0.699
[epoch:202, iter:157403] Loss: 1.107, 8.052, 50.407, 365.512, 0.364
[epoch:202, iter:157423] Loss: 1.107, 8.054, 50.449, 365.706, 0.630
[epoch:202, iter:157443] Loss: 1.107, 8.052, 50.453, 365.724, 0.971
[epoch:202, iter:157463] Loss: 1.108, 8.052, 50.489, 365.898, 0.523
Epoch: [201][300/782]	Time 0.065 (0.084)	Data 0.002 (0.004)	Loss 9.2719 (9.4599)	Acc@1 84.375 (80.305)	Acc@5 93.750 (96.823)
[epoch:202, iter:157483] Loss: 1.109, 8.048, 50.482, 365.804, 0.677
[epoch:202, iter:157503] Loss: 1.109, 8.049, 50.496, 365.868, 0.706
[epoch:202, iter:157523] Loss: 1.109, 8.049, 50.557, 366.146, 0.577
[epoch:202, iter:157543] Loss: 1.109, 8.049, 50.532, 366.057, 0.580
[epoch:202, iter:157563] Loss: 1.109, 8.048, 50.528, 366.099, 0.552
Epoch: [201][400/782]	Time 0.080 (0.085)	Data 0.002 (0.004)	Loss 9.1376 (9.4774)	Acc@1 79.688 (80.186)	Acc@5 96.875 (96.781)
[epoch:202, iter:157583] Loss: 1.110, 8.047, 50.547, 366.182, 0.600
[epoch:202, iter:157603] Loss: 1.110, 8.049, 50.537, 366.118, 0.541
[epoch:202, iter:157623] Loss: 1.111, 8.052, 50.561, 366.166, 0.690
[epoch:202, iter:157643] Loss: 1.111, 8.053, 50.549, 366.074, 0.515
[epoch:202, iter:157663] Loss: 1.111, 8.056, 50.563, 366.127, 0.682
Epoch: [201][500/782]	Time 0.088 (0.084)	Data 0.003 (0.003)	Loss 9.7704 (9.4737)	Acc@1 87.500 (80.243)	Acc@5 96.875 (96.822)
[epoch:202, iter:157683] Loss: 1.111, 8.053, 50.552, 366.055, 0.547
[epoch:202, iter:157703] Loss: 1.111, 8.052, 50.539, 365.972, 0.559
[epoch:202, iter:157723] Loss: 1.110, 8.051, 50.522, 365.931, 0.623
[epoch:202, iter:157743] Loss: 1.110, 8.052, 50.506, 365.868, 0.484
[epoch:202, iter:157763] Loss: 1.110, 8.052, 50.512, 365.886, 0.911
Epoch: [201][600/782]	Time 0.087 (0.083)	Data 0.003 (0.003)	Loss 9.4838 (9.4674)	Acc@1 81.250 (80.174)	Acc@5 100.000 (96.841)
[epoch:202, iter:157783] Loss: 1.110, 8.055, 50.511, 365.908, 0.544
[epoch:202, iter:157803] Loss: 1.110, 8.056, 50.495, 365.868, 0.605
[epoch:202, iter:157823] Loss: 1.110, 8.058, 50.492, 365.910, 0.582
[epoch:202, iter:157843] Loss: 1.109, 8.059, 50.488, 365.922, 0.808
[epoch:202, iter:157863] Loss: 1.109, 8.056, 50.486, 365.918, 0.750
Epoch: [201][700/782]	Time 0.073 (0.084)	Data 0.002 (0.003)	Loss 9.0961 (9.4640)	Acc@1 89.062 (80.209)	Acc@5 98.438 (96.844)
[epoch:202, iter:157883] Loss: 1.109, 8.056, 50.493, 365.945, 0.491
[epoch:202, iter:157903] Loss: 1.109, 8.054, 50.478, 365.873, 0.454
[epoch:202, iter:157923] Loss: 1.109, 8.054, 50.483, 365.883, 0.621
[epoch:202, iter:157943] Loss: 1.110, 8.053, 50.484, 365.848, 0.361
[epoch:202, iter:157963] Loss: 1.110, 8.055, 50.476, 365.784, 0.739
 * Acc@1 80.278 Acc@5 96.830
epoch 201, total time 65.60
Test: [0/313]	Time 0.231 (0.231)	Loss 1.3364 (1.3364)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.009)	Loss 1.3510 (1.1784)	Acc@1 56.250 (71.009)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.6633 (1.1400)	Acc@1 78.125 (71.315)	Acc@5 100.000 (92.693)
Test: [300/313]	Time 0.010 (0.008)	Loss 1.3642 (1.1509)	Acc@1 62.500 (71.127)	Acc@5 90.625 (92.681)
 * Acc@1 71.260 Acc@5 92.730
==> training...
Epoch: [202][0/782]	Time 0.608 (0.608)	Data 0.537 (0.537)	Loss 9.5225 (9.5225)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
[epoch:203, iter:157965] Loss: 1.128, 8.198, 49.544, 363.782, 0.688
[epoch:203, iter:157985] Loss: 1.101, 8.087, 50.458, 366.332, 0.606
[epoch:203, iter:158005] Loss: 1.101, 8.037, 50.157, 364.654, 0.789
[epoch:203, iter:158025] Loss: 1.098, 8.050, 50.167, 364.594, 0.457
[epoch:203, iter:158045] Loss: 1.103, 8.055, 50.287, 365.019, 0.678
Epoch: [202][100/782]	Time 0.089 (0.094)	Data 0.003 (0.008)	Loss 9.6577 (9.4591)	Acc@1 82.812 (80.662)	Acc@5 96.875 (96.519)
[epoch:203, iter:158065] Loss: 1.105, 8.075, 50.358, 365.513, 0.600
[epoch:203, iter:158085] Loss: 1.107, 8.063, 50.303, 365.287, 0.744
[epoch:203, iter:158105] Loss: 1.108, 8.062, 50.339, 365.401, 0.485
[epoch:203, iter:158125] Loss: 1.107, 8.068, 50.331, 365.404, 0.630
[epoch:203, iter:158145] Loss: 1.108, 8.066, 50.356, 365.344, 0.506
Epoch: [202][200/782]	Time 0.093 (0.090)	Data 0.003 (0.005)	Loss 9.3279 (9.4510)	Acc@1 87.500 (80.613)	Acc@5 98.438 (96.782)
[epoch:203, iter:158165] Loss: 1.108, 8.067, 50.372, 365.368, 0.540
[epoch:203, iter:158185] Loss: 1.108, 8.061, 50.375, 365.404, 0.413
[epoch:203, iter:158205] Loss: 1.108, 8.060, 50.402, 365.473, 1.000
[epoch:203, iter:158225] Loss: 1.107, 8.060, 50.371, 365.293, 0.446
[epoch:203, iter:158245] Loss: 1.107, 8.064, 50.375, 365.395, 0.731
Epoch: [202][300/782]	Time 0.095 (0.088)	Data 0.003 (0.004)	Loss 9.7355 (9.4508)	Acc@1 78.125 (80.554)	Acc@5 95.312 (96.844)
[epoch:203, iter:158265] Loss: 1.108, 8.068, 50.432, 365.584, 0.686
[epoch:203, iter:158285] Loss: 1.107, 8.070, 50.411, 365.546, 0.534
[epoch:203, iter:158305] Loss: 1.107, 8.068, 50.406, 365.491, 0.526
[epoch:203, iter:158325] Loss: 1.107, 8.068, 50.406, 365.486, 0.781
[epoch:203, iter:158345] Loss: 1.107, 8.065, 50.429, 365.585, 0.609
Epoch: [202][400/782]	Time 0.107 (0.088)	Data 0.003 (0.004)	Loss 9.0451 (9.4471)	Acc@1 82.812 (80.630)	Acc@5 98.438 (96.828)
[epoch:203, iter:158365] Loss: 1.107, 8.066, 50.427, 365.560, 0.585
[epoch:203, iter:158385] Loss: 1.107, 8.064, 50.441, 365.614, 0.788
[epoch:203, iter:158405] Loss: 1.107, 8.063, 50.450, 365.626, 0.834
[epoch:203, iter:158425] Loss: 1.108, 8.067, 50.466, 365.754, 0.647
[epoch:203, iter:158445] Loss: 1.108, 8.067, 50.463, 365.742, 0.662
Epoch: [202][500/782]	Time 0.067 (0.088)	Data 0.002 (0.004)	Loss 9.4119 (9.4598)	Acc@1 73.438 (80.595)	Acc@5 96.875 (96.822)
[epoch:203, iter:158465] Loss: 1.108, 8.064, 50.476, 365.820, 0.695
[epoch:203, iter:158485] Loss: 1.108, 8.063, 50.481, 365.859, 0.706
[epoch:203, iter:158505] Loss: 1.107, 8.065, 50.492, 365.911, 0.504
[epoch:203, iter:158525] Loss: 1.108, 8.065, 50.479, 365.865, 0.421
[epoch:203, iter:158545] Loss: 1.107, 8.062, 50.470, 365.796, 0.718
Epoch: [202][600/782]	Time 0.090 (0.087)	Data 0.003 (0.003)	Loss 9.0054 (9.4592)	Acc@1 76.562 (80.467)	Acc@5 98.438 (96.826)
[epoch:203, iter:158565] Loss: 1.108, 8.062, 50.458, 365.741, 0.604
[epoch:203, iter:158585] Loss: 1.108, 8.062, 50.458, 365.725, 0.592
[epoch:203, iter:158605] Loss: 1.108, 8.062, 50.455, 365.690, 0.411
[epoch:203, iter:158625] Loss: 1.108, 8.062, 50.450, 365.644, 1.057
[epoch:203, iter:158645] Loss: 1.108, 8.058, 50.436, 365.547, 0.573
Epoch: [202][700/782]	Time 0.068 (0.086)	Data 0.002 (0.003)	Loss 9.3333 (9.4512)	Acc@1 87.500 (80.512)	Acc@5 98.438 (96.857)
[epoch:203, iter:158665] Loss: 1.108, 8.057, 50.445, 365.561, 0.339
[epoch:203, iter:158685] Loss: 1.109, 8.054, 50.435, 365.515, 0.530
[epoch:203, iter:158705] Loss: 1.109, 8.055, 50.432, 365.509, 0.549
[epoch:203, iter:158725] Loss: 1.109, 8.056, 50.425, 365.476, 0.551
[epoch:203, iter:158745] Loss: 1.109, 8.055, 50.436, 365.524, 0.472
 * Acc@1 80.420 Acc@5 96.848
epoch 202, total time 67.24
Test: [0/313]	Time 0.229 (0.229)	Loss 1.2875 (1.2875)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2656 (1.1813)	Acc@1 62.500 (70.575)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.008 (0.009)	Loss 0.6778 (1.1433)	Acc@1 75.000 (71.067)	Acc@5 96.875 (92.631)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.4739 (1.1546)	Acc@1 65.625 (70.878)	Acc@5 93.750 (92.743)
 * Acc@1 70.970 Acc@5 92.800
==> training...
Epoch: [203][0/782]	Time 0.509 (0.509)	Data 0.440 (0.440)	Loss 9.0182 (9.0182)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
[epoch:204, iter:158747] Loss: 1.122, 7.665, 50.437, 362.423, 0.463
[epoch:204, iter:158767] Loss: 1.116, 8.023, 50.395, 365.167, 0.389
[epoch:204, iter:158787] Loss: 1.111, 8.057, 50.445, 365.243, 0.433
[epoch:204, iter:158807] Loss: 1.114, 8.048, 50.473, 365.452, 0.654
[epoch:204, iter:158827] Loss: 1.117, 8.064, 50.548, 365.700, 0.437
Epoch: [203][100/782]	Time 0.087 (0.089)	Data 0.003 (0.007)	Loss 9.9791 (9.4438)	Acc@1 76.562 (81.420)	Acc@5 96.875 (97.045)
[epoch:204, iter:158847] Loss: 1.119, 8.050, 50.579, 365.663, 0.774
[epoch:204, iter:158867] Loss: 1.119, 8.056, 50.602, 365.709, 0.675
[epoch:204, iter:158887] Loss: 1.119, 8.062, 50.616, 365.832, 0.834
[epoch:204, iter:158907] Loss: 1.118, 8.070, 50.572, 365.662, 0.651
[epoch:204, iter:158927] Loss: 1.116, 8.066, 50.536, 365.564, 0.800
Epoch: [203][200/782]	Time 0.090 (0.088)	Data 0.003 (0.005)	Loss 9.4560 (9.4551)	Acc@1 84.375 (80.970)	Acc@5 100.000 (96.859)
[epoch:204, iter:158947] Loss: 1.115, 8.070, 50.505, 365.542, 0.433
[epoch:204, iter:158967] Loss: 1.114, 8.064, 50.518, 365.549, 0.592
[epoch:204, iter:158987] Loss: 1.113, 8.061, 50.473, 365.406, 0.328
[epoch:204, iter:159007] Loss: 1.113, 8.063, 50.477, 365.555, 0.666
[epoch:204, iter:159027] Loss: 1.112, 8.071, 50.503, 365.702, 0.525
Epoch: [203][300/782]	Time 0.088 (0.088)	Data 0.003 (0.004)	Loss 9.1086 (9.4630)	Acc@1 87.500 (80.824)	Acc@5 95.312 (96.974)
[epoch:204, iter:159047] Loss: 1.112, 8.069, 50.481, 365.657, 0.444
[epoch:204, iter:159067] Loss: 1.112, 8.069, 50.459, 365.563, 0.444
[epoch:204, iter:159087] Loss: 1.112, 8.069, 50.474, 365.608, 0.740
[epoch:204, iter:159107] Loss: 1.111, 8.068, 50.471, 365.615, 0.474
[epoch:204, iter:159127] Loss: 1.111, 8.064, 50.453, 365.543, 0.535
Epoch: [203][400/782]	Time 0.090 (0.088)	Data 0.003 (0.004)	Loss 9.7305 (9.4644)	Acc@1 84.375 (80.669)	Acc@5 96.875 (96.910)
[epoch:204, iter:159147] Loss: 1.112, 8.067, 50.472, 365.600, 0.548
[epoch:204, iter:159167] Loss: 1.112, 8.065, 50.478, 365.616, 0.612
[epoch:204, iter:159187] Loss: 1.112, 8.065, 50.492, 365.709, 0.752
[epoch:204, iter:159207] Loss: 1.112, 8.062, 50.484, 365.633, 0.435
[epoch:204, iter:159227] Loss: 1.112, 8.064, 50.495, 365.698, 0.482
Epoch: [203][500/782]	Time 0.065 (0.087)	Data 0.002 (0.003)	Loss 9.5333 (9.4687)	Acc@1 70.312 (80.399)	Acc@5 95.312 (96.897)
[epoch:204, iter:159247] Loss: 1.112, 8.063, 50.491, 365.689, 0.780
[epoch:204, iter:159267] Loss: 1.111, 8.064, 50.484, 365.707, 0.621
[epoch:204, iter:159287] Loss: 1.111, 8.064, 50.472, 365.677, 0.666
[epoch:204, iter:159307] Loss: 1.111, 8.064, 50.489, 365.732, 0.393
[epoch:204, iter:159327] Loss: 1.111, 8.060, 50.501, 365.799, 0.546
Epoch: [203][600/782]	Time 0.092 (0.087)	Data 0.003 (0.003)	Loss 9.7483 (9.4708)	Acc@1 71.875 (80.400)	Acc@5 95.312 (96.927)
[epoch:204, iter:159347] Loss: 1.111, 8.061, 50.506, 365.834, 0.770
[epoch:204, iter:159367] Loss: 1.111, 8.063, 50.511, 365.870, 0.657
[epoch:204, iter:159387] Loss: 1.110, 8.063, 50.509, 365.875, 0.676
[epoch:204, iter:159407] Loss: 1.110, 8.064, 50.510, 365.884, 0.511
[epoch:204, iter:159427] Loss: 1.110, 8.063, 50.495, 365.807, 0.635
Epoch: [203][700/782]	Time 0.089 (0.087)	Data 0.003 (0.003)	Loss 9.7001 (9.4676)	Acc@1 78.125 (80.434)	Acc@5 96.875 (96.915)
[epoch:204, iter:159447] Loss: 1.110, 8.064, 50.490, 365.764, 0.755
[epoch:204, iter:159467] Loss: 1.110, 8.061, 50.478, 365.712, 0.706
[epoch:204, iter:159487] Loss: 1.110, 8.062, 50.480, 365.737, 0.623
[epoch:204, iter:159507] Loss: 1.110, 8.063, 50.484, 365.740, 0.481
[epoch:204, iter:159527] Loss: 1.110, 8.062, 50.476, 365.689, 0.693
 * Acc@1 80.470 Acc@5 96.942
epoch 203, total time 68.39
Test: [0/313]	Time 0.259 (0.259)	Loss 1.2875 (1.2875)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.011)	Loss 1.2987 (1.1838)	Acc@1 56.250 (70.730)	Acc@5 96.875 (92.327)
Test: [200/313]	Time 0.007 (0.009)	Loss 0.6999 (1.1424)	Acc@1 75.000 (71.067)	Acc@5 96.875 (92.708)
Test: [300/313]	Time 0.007 (0.009)	Loss 1.4602 (1.1555)	Acc@1 65.625 (70.847)	Acc@5 100.000 (92.712)
 * Acc@1 70.980 Acc@5 92.760
==> training...
Epoch: [204][0/782]	Time 0.662 (0.662)	Data 0.575 (0.575)	Loss 9.3814 (9.3814)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
[epoch:205, iter:159529] Loss: 1.009, 8.232, 50.803, 375.163, 0.432
[epoch:205, iter:159549] Loss: 1.097, 8.102, 50.107, 364.651, 0.841
[epoch:205, iter:159569] Loss: 1.107, 8.109, 50.261, 365.235, 1.008
[epoch:205, iter:159589] Loss: 1.108, 8.107, 50.489, 366.134, 0.760
[epoch:205, iter:159609] Loss: 1.111, 8.082, 50.500, 366.278, 0.621
Epoch: [204][100/782]	Time 0.092 (0.091)	Data 0.003 (0.008)	Loss 9.2773 (9.4512)	Acc@1 76.562 (80.662)	Acc@5 98.438 (96.844)
[epoch:205, iter:159629] Loss: 1.111, 8.072, 50.500, 366.083, 0.652
[epoch:205, iter:159649] Loss: 1.107, 8.069, 50.401, 365.706, 0.765
[epoch:205, iter:159669] Loss: 1.107, 8.059, 50.440, 365.776, 0.445
[epoch:205, iter:159689] Loss: 1.106, 8.061, 50.471, 365.965, 0.894
[epoch:205, iter:159709] Loss: 1.106, 8.057, 50.388, 365.518, 0.658
Epoch: [204][200/782]	Time 0.094 (0.090)	Data 0.003 (0.005)	Loss 9.6510 (9.4329)	Acc@1 75.000 (80.193)	Acc@5 95.312 (96.867)
[epoch:205, iter:159729] Loss: 1.106, 8.059, 50.384, 365.443, 0.782
[epoch:205, iter:159749] Loss: 1.106, 8.052, 50.438, 365.619, 0.815
[epoch:205, iter:159769] Loss: 1.106, 8.051, 50.442, 365.647, 0.757
[epoch:205, iter:159789] Loss: 1.106, 8.053, 50.435, 365.698, 0.495
[epoch:205, iter:159809] Loss: 1.106, 8.053, 50.417, 365.597, 0.783
Epoch: [204][300/782]	Time 0.092 (0.089)	Data 0.003 (0.004)	Loss 8.8690 (9.4319)	Acc@1 90.625 (80.591)	Acc@5 100.000 (96.911)
[epoch:205, iter:159829] Loss: 1.107, 8.053, 50.419, 365.583, 0.365
[epoch:205, iter:159849] Loss: 1.107, 8.053, 50.425, 365.582, 0.860
[epoch:205, iter:159869] Loss: 1.107, 8.052, 50.400, 365.439, 0.854
[epoch:205, iter:159889] Loss: 1.107, 8.053, 50.424, 365.574, 0.488
[epoch:205, iter:159909] Loss: 1.108, 8.052, 50.457, 365.710, 0.859
Epoch: [204][400/782]	Time 0.071 (0.088)	Data 0.002 (0.004)	Loss 9.0104 (9.4446)	Acc@1 79.688 (80.408)	Acc@5 100.000 (96.871)
[epoch:205, iter:159929] Loss: 1.108, 8.051, 50.428, 365.585, 0.505
[epoch:205, iter:159949] Loss: 1.108, 8.050, 50.423, 365.574, 0.796
[epoch:205, iter:159969] Loss: 1.107, 8.054, 50.415, 365.578, 0.839
[epoch:205, iter:159989] Loss: 1.107, 8.054, 50.423, 365.556, 0.628
[epoch:205, iter:160009] Loss: 1.107, 8.055, 50.421, 365.553, 0.671
Epoch: [204][500/782]	Time 0.093 (0.088)	Data 0.003 (0.004)	Loss 9.2926 (9.4421)	Acc@1 85.938 (80.464)	Acc@5 93.750 (96.831)
[epoch:205, iter:160029] Loss: 1.108, 8.054, 50.418, 365.483, 0.510
[epoch:205, iter:160049] Loss: 1.108, 8.053, 50.420, 365.473, 0.463
[epoch:205, iter:160069] Loss: 1.108, 8.053, 50.421, 365.449, 0.606
[epoch:205, iter:160089] Loss: 1.108, 8.055, 50.439, 365.521, 0.572
[epoch:205, iter:160109] Loss: 1.108, 8.053, 50.460, 365.618, 0.504
Epoch: [204][600/782]	Time 0.084 (0.088)	Data 0.002 (0.004)	Loss 9.5991 (9.4503)	Acc@1 84.375 (80.473)	Acc@5 96.875 (96.870)
[epoch:205, iter:160129] Loss: 1.109, 8.053, 50.466, 365.674, 0.624
[epoch:205, iter:160149] Loss: 1.109, 8.055, 50.461, 365.623, 0.630
[epoch:205, iter:160169] Loss: 1.110, 8.054, 50.457, 365.573, 0.548
[epoch:205, iter:160189] Loss: 1.110, 8.056, 50.447, 365.486, 0.633
[epoch:205, iter:160209] Loss: 1.111, 8.057, 50.461, 365.554, 0.473
Epoch: [204][700/782]	Time 0.091 (0.088)	Data 0.002 (0.003)	Loss 9.7469 (9.4462)	Acc@1 73.438 (80.405)	Acc@5 95.312 (96.839)
[epoch:205, iter:160229] Loss: 1.111, 8.055, 50.451, 365.513, 0.792
[epoch:205, iter:160249] Loss: 1.110, 8.057, 50.436, 365.457, 0.835
[epoch:205, iter:160269] Loss: 1.110, 8.057, 50.434, 365.464, 0.575
[epoch:205, iter:160289] Loss: 1.110, 8.056, 50.429, 365.425, 0.613
[epoch:205, iter:160309] Loss: 1.111, 8.054, 50.433, 365.437, 0.764
 * Acc@1 80.454 Acc@5 96.844
epoch 204, total time 68.52
Test: [0/313]	Time 0.287 (0.287)	Loss 1.2959 (1.2959)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2716 (1.1893)	Acc@1 62.500 (70.575)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7272 (1.1485)	Acc@1 78.125 (71.129)	Acc@5 96.875 (92.584)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4447 (1.1609)	Acc@1 65.625 (70.868)	Acc@5 96.875 (92.681)
 * Acc@1 70.980 Acc@5 92.740
==> training...
Epoch: [205][0/782]	Time 0.622 (0.622)	Data 0.525 (0.525)	Loss 8.9950 (8.9950)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
[epoch:206, iter:160311] Loss: 1.089, 7.561, 49.529, 359.688, 0.461
[epoch:206, iter:160331] Loss: 1.125, 8.104, 50.158, 363.555, 0.540
[epoch:206, iter:160351] Loss: 1.111, 8.069, 50.282, 365.400, 0.444
[epoch:206, iter:160371] Loss: 1.110, 8.063, 50.138, 364.384, 0.482
[epoch:206, iter:160391] Loss: 1.112, 8.053, 50.150, 364.024, 0.795
Epoch: [205][100/782]	Time 0.096 (0.093)	Data 0.003 (0.008)	Loss 9.8696 (9.3912)	Acc@1 75.000 (81.250)	Acc@5 98.438 (97.061)
[epoch:206, iter:160411] Loss: 1.113, 8.062, 50.214, 364.484, 0.745
[epoch:206, iter:160431] Loss: 1.115, 8.051, 50.282, 364.600, 0.557
[epoch:206, iter:160451] Loss: 1.114, 8.054, 50.302, 364.740, 0.581
[epoch:206, iter:160471] Loss: 1.114, 8.046, 50.256, 364.524, 0.602
[epoch:206, iter:160491] Loss: 1.113, 8.047, 50.285, 364.828, 0.482
Epoch: [205][200/782]	Time 0.085 (0.090)	Data 0.003 (0.005)	Loss 9.4354 (9.4069)	Acc@1 79.688 (81.242)	Acc@5 95.312 (96.891)
[epoch:206, iter:160511] Loss: 1.114, 8.042, 50.286, 364.827, 0.760
[epoch:206, iter:160531] Loss: 1.115, 8.044, 50.325, 364.942, 0.724
[epoch:206, iter:160551] Loss: 1.114, 8.042, 50.339, 364.935, 0.593
[epoch:206, iter:160571] Loss: 1.113, 8.042, 50.333, 364.962, 0.896
[epoch:206, iter:160591] Loss: 1.113, 8.041, 50.364, 365.132, 0.963
Epoch: [205][300/782]	Time 0.076 (0.087)	Data 0.002 (0.004)	Loss 8.4956 (9.4168)	Acc@1 84.375 (81.048)	Acc@5 100.000 (96.859)
[epoch:206, iter:160611] Loss: 1.113, 8.040, 50.365, 365.046, 0.381
[epoch:206, iter:160631] Loss: 1.112, 8.039, 50.375, 365.061, 0.706
[epoch:206, iter:160651] Loss: 1.112, 8.038, 50.349, 364.949, 0.559
[epoch:206, iter:160671] Loss: 1.113, 8.039, 50.383, 365.133, 0.399
[epoch:206, iter:160691] Loss: 1.113, 8.038, 50.371, 365.042, 0.553
Epoch: [205][400/782]	Time 0.092 (0.085)	Data 0.003 (0.004)	Loss 9.0906 (9.4133)	Acc@1 78.125 (81.075)	Acc@5 95.312 (96.949)
[epoch:206, iter:160711] Loss: 1.114, 8.039, 50.380, 365.093, 0.675
[epoch:206, iter:160731] Loss: 1.114, 8.039, 50.380, 365.070, 0.647
[epoch:206, iter:160751] Loss: 1.113, 8.041, 50.366, 365.006, 0.460
[epoch:206, iter:160771] Loss: 1.113, 8.039, 50.370, 365.026, 0.786
[epoch:206, iter:160791] Loss: 1.113, 8.040, 50.377, 365.045, 0.581
Epoch: [205][500/782]	Time 0.094 (0.085)	Data 0.003 (0.004)	Loss 9.1742 (9.4164)	Acc@1 82.812 (81.050)	Acc@5 98.438 (96.916)
[epoch:206, iter:160811] Loss: 1.113, 8.041, 50.388, 365.100, 0.416
[epoch:206, iter:160831] Loss: 1.112, 8.040, 50.392, 365.118, 0.887
[epoch:206, iter:160851] Loss: 1.112, 8.041, 50.389, 365.110, 0.668
[epoch:206, iter:160871] Loss: 1.113, 8.039, 50.392, 365.100, 0.824
[epoch:206, iter:160891] Loss: 1.112, 8.039, 50.393, 365.129, 0.732
Epoch: [205][600/782]	Time 0.077 (0.085)	Data 0.002 (0.003)	Loss 9.1817 (9.4191)	Acc@1 82.812 (80.876)	Acc@5 98.438 (96.896)
[epoch:206, iter:160911] Loss: 1.112, 8.039, 50.396, 365.163, 0.434
[epoch:206, iter:160931] Loss: 1.112, 8.040, 50.403, 365.242, 0.630
[epoch:206, iter:160951] Loss: 1.112, 8.040, 50.401, 365.272, 0.898
[epoch:206, iter:160971] Loss: 1.112, 8.042, 50.419, 365.350, 0.580
[epoch:206, iter:160991] Loss: 1.112, 8.041, 50.426, 365.353, 0.490
Epoch: [205][700/782]	Time 0.086 (0.086)	Data 0.003 (0.003)	Loss 9.4288 (9.4371)	Acc@1 84.375 (80.601)	Acc@5 95.312 (96.882)
[epoch:206, iter:161011] Loss: 1.112, 8.041, 50.432, 365.380, 0.668
[epoch:206, iter:161031] Loss: 1.112, 8.043, 50.445, 365.417, 0.416
[epoch:206, iter:161051] Loss: 1.112, 8.044, 50.438, 365.412, 0.548
[epoch:206, iter:161071] Loss: 1.112, 8.045, 50.434, 365.390, 0.338
[epoch:206, iter:161091] Loss: 1.111, 8.044, 50.430, 365.407, 0.497
 * Acc@1 80.492 Acc@5 96.856
epoch 205, total time 66.83
Test: [0/313]	Time 0.269 (0.269)	Loss 1.2668 (1.2668)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2855 (1.1760)	Acc@1 56.250 (71.009)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7324 (1.1392)	Acc@1 71.875 (71.362)	Acc@5 96.875 (92.631)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4472 (1.1498)	Acc@1 59.375 (71.034)	Acc@5 96.875 (92.733)
 * Acc@1 71.170 Acc@5 92.790
==> training...
Epoch: [206][0/782]	Time 0.538 (0.538)	Data 0.453 (0.453)	Loss 9.1319 (9.1319)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
[epoch:207, iter:161093] Loss: 1.136, 7.973, 50.174, 361.969, 0.385
[epoch:207, iter:161113] Loss: 1.094, 8.056, 50.146, 363.029, 0.497
[epoch:207, iter:161133] Loss: 1.102, 8.022, 50.203, 363.747, 0.566
[epoch:207, iter:161153] Loss: 1.108, 8.044, 50.193, 363.840, 0.759
[epoch:207, iter:161173] Loss: 1.109, 8.053, 50.289, 364.518, 0.759
Epoch: [206][100/782]	Time 0.085 (0.092)	Data 0.003 (0.007)	Loss 9.7572 (9.4120)	Acc@1 81.250 (80.832)	Acc@5 96.875 (97.153)
[epoch:207, iter:161193] Loss: 1.111, 8.047, 50.358, 364.839, 0.710
[epoch:207, iter:161213] Loss: 1.112, 8.051, 50.378, 365.040, 0.581
[epoch:207, iter:161233] Loss: 1.109, 8.047, 50.324, 364.755, 0.692
[epoch:207, iter:161253] Loss: 1.110, 8.056, 50.392, 365.138, 0.880
[epoch:207, iter:161273] Loss: 1.110, 8.055, 50.381, 365.189, 0.680
Epoch: [206][200/782]	Time 0.091 (0.087)	Data 0.003 (0.005)	Loss 9.5972 (9.4413)	Acc@1 81.250 (80.169)	Acc@5 95.312 (96.875)
[epoch:207, iter:161293] Loss: 1.111, 8.061, 50.398, 365.274, 0.671
[epoch:207, iter:161313] Loss: 1.112, 8.057, 50.404, 365.207, 0.243
[epoch:207, iter:161333] Loss: 1.112, 8.055, 50.415, 365.229, 0.656
[epoch:207, iter:161353] Loss: 1.113, 8.062, 50.417, 365.208, 0.547
[epoch:207, iter:161373] Loss: 1.113, 8.061, 50.439, 365.283, 0.590
Epoch: [206][300/782]	Time 0.076 (0.089)	Data 0.002 (0.004)	Loss 9.2839 (9.4518)	Acc@1 82.812 (80.352)	Acc@5 96.875 (96.813)
[epoch:207, iter:161393] Loss: 1.113, 8.065, 50.452, 365.429, 0.567
[epoch:207, iter:161413] Loss: 1.113, 8.065, 50.457, 365.433, 0.515
[epoch:207, iter:161433] Loss: 1.112, 8.063, 50.395, 365.162, 0.877
[epoch:207, iter:161453] Loss: 1.113, 8.061, 50.417, 365.254, 0.564
[epoch:207, iter:161473] Loss: 1.112, 8.058, 50.400, 365.240, 0.876
Epoch: [206][400/782]	Time 0.092 (0.089)	Data 0.002 (0.004)	Loss 9.3356 (9.4398)	Acc@1 85.938 (80.447)	Acc@5 100.000 (96.758)
[epoch:207, iter:161493] Loss: 1.113, 8.056, 50.410, 365.224, 0.473
[epoch:207, iter:161513] Loss: 1.112, 8.055, 50.396, 365.141, 0.508
[epoch:207, iter:161533] Loss: 1.113, 8.055, 50.410, 365.170, 0.468
[epoch:207, iter:161553] Loss: 1.113, 8.057, 50.416, 365.216, 0.727
[epoch:207, iter:161573] Loss: 1.113, 8.055, 50.400, 365.158, 0.550
Epoch: [206][500/782]	Time 0.085 (0.089)	Data 0.003 (0.003)	Loss 9.4134 (9.4398)	Acc@1 79.688 (80.539)	Acc@5 98.438 (96.803)
[epoch:207, iter:161593] Loss: 1.114, 8.059, 50.422, 365.250, 0.634
[epoch:207, iter:161613] Loss: 1.113, 8.057, 50.425, 365.281, 0.583
[epoch:207, iter:161633] Loss: 1.113, 8.055, 50.418, 365.247, 0.909
[epoch:207, iter:161653] Loss: 1.112, 8.056, 50.405, 365.175, 0.700
[epoch:207, iter:161673] Loss: 1.112, 8.055, 50.414, 365.209, 0.333
Epoch: [206][600/782]	Time 0.099 (0.090)	Data 0.003 (0.003)	Loss 9.5315 (9.4418)	Acc@1 81.250 (80.519)	Acc@5 98.438 (96.784)
[epoch:207, iter:161693] Loss: 1.112, 8.056, 50.419, 365.195, 0.639
[epoch:207, iter:161713] Loss: 1.112, 8.056, 50.418, 365.207, 0.482
[epoch:207, iter:161733] Loss: 1.112, 8.055, 50.415, 365.210, 0.663
[epoch:207, iter:161753] Loss: 1.111, 8.055, 50.413, 365.207, 0.561
[epoch:207, iter:161773] Loss: 1.111, 8.057, 50.423, 365.260, 0.369
Epoch: [206][700/782]	Time 0.100 (0.091)	Data 0.003 (0.003)	Loss 9.2998 (9.4392)	Acc@1 84.375 (80.568)	Acc@5 98.438 (96.799)
[epoch:207, iter:161793] Loss: 1.112, 8.057, 50.428, 365.296, 0.607
[epoch:207, iter:161813] Loss: 1.112, 8.056, 50.437, 365.347, 0.682
[epoch:207, iter:161833] Loss: 1.112, 8.055, 50.441, 365.386, 0.870
[epoch:207, iter:161853] Loss: 1.112, 8.055, 50.437, 365.387, 0.498
[epoch:207, iter:161873] Loss: 1.111, 8.057, 50.427, 365.322, 0.591
 * Acc@1 80.526 Acc@5 96.768
epoch 206, total time 71.58
Test: [0/313]	Time 0.274 (0.274)	Loss 1.3093 (1.3093)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3901 (1.1790)	Acc@1 59.375 (70.575)	Acc@5 96.875 (92.420)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7227 (1.1419)	Acc@1 75.000 (71.222)	Acc@5 100.000 (92.802)
Test: [300/313]	Time 0.011 (0.008)	Loss 1.4694 (1.1531)	Acc@1 62.500 (71.200)	Acc@5 96.875 (92.909)
 * Acc@1 71.330 Acc@5 92.960
saving the best model!
==> training...
Epoch: [207][0/782]	Time 0.541 (0.541)	Data 0.466 (0.466)	Loss 10.0080 (10.0080)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
[epoch:208, iter:161875] Loss: 1.130, 8.379, 51.101, 370.495, 0.916
[epoch:208, iter:161895] Loss: 1.110, 7.975, 50.198, 364.342, 0.609
[epoch:208, iter:161915] Loss: 1.108, 7.986, 50.274, 364.820, 0.512
[epoch:208, iter:161935] Loss: 1.109, 8.027, 50.344, 365.569, 0.671
[epoch:208, iter:161955] Loss: 1.109, 8.024, 50.324, 365.174, 0.534
Epoch: [207][100/782]	Time 0.095 (0.092)	Data 0.003 (0.007)	Loss 9.2084 (9.3973)	Acc@1 90.625 (80.631)	Acc@5 98.438 (97.324)
[epoch:208, iter:161975] Loss: 1.106, 8.026, 50.321, 365.196, 0.381
[epoch:208, iter:161995] Loss: 1.109, 8.027, 50.368, 365.330, 0.717
[epoch:208, iter:162015] Loss: 1.112, 8.034, 50.384, 365.349, 0.331
[epoch:208, iter:162035] Loss: 1.114, 8.037, 50.387, 365.258, 0.722
[epoch:208, iter:162055] Loss: 1.113, 8.032, 50.359, 365.131, 0.678
Epoch: [207][200/782]	Time 0.085 (0.086)	Data 0.002 (0.005)	Loss 9.3528 (9.4221)	Acc@1 70.312 (80.543)	Acc@5 98.438 (97.038)
[epoch:208, iter:162075] Loss: 1.114, 8.031, 50.351, 365.029, 0.676
[epoch:208, iter:162095] Loss: 1.113, 8.027, 50.309, 364.756, 0.544
[epoch:208, iter:162115] Loss: 1.112, 8.033, 50.297, 364.765, 0.681
[epoch:208, iter:162135] Loss: 1.113, 8.035, 50.342, 365.016, 0.527
[epoch:208, iter:162155] Loss: 1.114, 8.035, 50.376, 365.118, 0.699
Epoch: [207][300/782]	Time 0.091 (0.088)	Data 0.003 (0.004)	Loss 8.7779 (9.4092)	Acc@1 82.812 (80.528)	Acc@5 98.438 (96.974)
[epoch:208, iter:162175] Loss: 1.113, 8.030, 50.315, 364.798, 0.599
[epoch:208, iter:162195] Loss: 1.113, 8.035, 50.301, 364.724, 0.613
[epoch:208, iter:162215] Loss: 1.113, 8.034, 50.304, 364.721, 0.546
[epoch:208, iter:162235] Loss: 1.112, 8.038, 50.311, 364.805, 0.779
[epoch:208, iter:162255] Loss: 1.111, 8.043, 50.304, 364.867, 0.785
Epoch: [207][400/782]	Time 0.071 (0.088)	Data 0.002 (0.004)	Loss 9.3240 (9.4195)	Acc@1 75.000 (80.401)	Acc@5 95.312 (97.023)
[epoch:208, iter:162275] Loss: 1.112, 8.043, 50.335, 364.992, 0.675
[epoch:208, iter:162295] Loss: 1.111, 8.045, 50.369, 365.153, 0.626
[epoch:208, iter:162315] Loss: 1.111, 8.045, 50.379, 365.169, 0.862
[epoch:208, iter:162335] Loss: 1.111, 8.043, 50.396, 365.233, 0.389
[epoch:208, iter:162355] Loss: 1.111, 8.045, 50.386, 365.220, 0.757
Epoch: [207][500/782]	Time 0.096 (0.087)	Data 0.003 (0.003)	Loss 9.0020 (9.4244)	Acc@1 85.938 (80.592)	Acc@5 98.438 (96.975)
[epoch:208, iter:162375] Loss: 1.111, 8.047, 50.374, 365.167, 0.447
[epoch:208, iter:162395] Loss: 1.112, 8.044, 50.359, 365.085, 0.430
[epoch:208, iter:162415] Loss: 1.112, 8.043, 50.351, 365.038, 0.522
[epoch:208, iter:162435] Loss: 1.112, 8.044, 50.349, 365.058, 0.546
[epoch:208, iter:162455] Loss: 1.112, 8.045, 50.355, 365.053, 0.918
Epoch: [207][600/782]	Time 0.089 (0.088)	Data 0.002 (0.003)	Loss 9.4593 (9.4206)	Acc@1 73.438 (80.600)	Acc@5 95.312 (96.956)
[epoch:208, iter:162475] Loss: 1.112, 8.047, 50.342, 365.004, 0.829
[epoch:208, iter:162495] Loss: 1.112, 8.046, 50.353, 365.063, 0.533
[epoch:208, iter:162515] Loss: 1.112, 8.046, 50.367, 365.139, 0.563
[epoch:208, iter:162535] Loss: 1.112, 8.047, 50.366, 365.163, 0.415
[epoch:208, iter:162555] Loss: 1.112, 8.045, 50.375, 365.224, 0.637
Epoch: [207][700/782]	Time 0.093 (0.087)	Data 0.002 (0.003)	Loss 9.0811 (9.4335)	Acc@1 82.812 (80.528)	Acc@5 98.438 (96.900)
[epoch:208, iter:162575] Loss: 1.111, 8.047, 50.389, 365.276, 0.469
[epoch:208, iter:162595] Loss: 1.111, 8.049, 50.388, 365.315, 0.633
[epoch:208, iter:162615] Loss: 1.111, 8.049, 50.383, 365.303, 0.655
[epoch:208, iter:162635] Loss: 1.111, 8.047, 50.370, 365.231, 0.906
[epoch:208, iter:162655] Loss: 1.111, 8.048, 50.382, 365.276, 0.592
 * Acc@1 80.432 Acc@5 96.866
epoch 207, total time 68.30
Test: [0/313]	Time 0.267 (0.267)	Loss 1.3190 (1.3190)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.3332 (1.1763)	Acc@1 56.250 (70.637)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7370 (1.1375)	Acc@1 78.125 (71.098)	Acc@5 96.875 (92.693)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4366 (1.1511)	Acc@1 62.500 (70.961)	Acc@5 93.750 (92.701)
 * Acc@1 71.090 Acc@5 92.750
==> training...
Epoch: [208][0/782]	Time 0.693 (0.693)	Data 0.598 (0.598)	Loss 9.4680 (9.4680)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
[epoch:209, iter:162657] Loss: 1.110, 7.935, 50.093, 362.461, 0.541
[epoch:209, iter:162677] Loss: 1.113, 7.969, 50.217, 363.694, 0.836
[epoch:209, iter:162697] Loss: 1.104, 7.977, 50.057, 363.635, 0.721
[epoch:209, iter:162717] Loss: 1.108, 8.008, 50.028, 363.518, 0.431
[epoch:209, iter:162737] Loss: 1.103, 8.008, 50.098, 363.982, 0.786
Epoch: [208][100/782]	Time 0.100 (0.095)	Data 0.002 (0.008)	Loss 9.3141 (9.4077)	Acc@1 81.250 (80.569)	Acc@5 100.000 (97.107)
[epoch:209, iter:162757] Loss: 1.107, 8.031, 50.207, 364.657, 0.571
[epoch:209, iter:162777] Loss: 1.108, 8.027, 50.308, 364.865, 0.660
[epoch:209, iter:162797] Loss: 1.108, 8.025, 50.319, 364.810, 0.417
[epoch:209, iter:162817] Loss: 1.109, 8.028, 50.316, 364.760, 0.470
[epoch:209, iter:162837] Loss: 1.108, 8.035, 50.280, 364.740, 0.444
Epoch: [208][200/782]	Time 0.114 (0.095)	Data 0.003 (0.005)	Loss 9.3108 (9.4228)	Acc@1 82.812 (80.232)	Acc@5 98.438 (96.984)
[epoch:209, iter:162857] Loss: 1.109, 8.037, 50.325, 364.822, 0.552
[epoch:209, iter:162877] Loss: 1.108, 8.031, 50.265, 364.496, 0.746
[epoch:209, iter:162897] Loss: 1.108, 8.041, 50.271, 364.656, 0.536
[epoch:209, iter:162917] Loss: 1.110, 8.042, 50.319, 364.836, 0.727
[epoch:209, iter:162937] Loss: 1.110, 8.040, 50.297, 364.619, 0.800
Epoch: [208][300/782]	Time 0.093 (0.094)	Data 0.003 (0.004)	Loss 9.3037 (9.4110)	Acc@1 82.812 (80.502)	Acc@5 96.875 (96.901)
[epoch:209, iter:162957] Loss: 1.110, 8.044, 50.285, 364.664, 0.655
[epoch:209, iter:162977] Loss: 1.110, 8.041, 50.279, 364.681, 0.737
[epoch:209, iter:162997] Loss: 1.111, 8.039, 50.288, 364.729, 1.015
[epoch:209, iter:163017] Loss: 1.111, 8.039, 50.306, 364.822, 0.452
[epoch:209, iter:163037] Loss: 1.111, 8.039, 50.328, 364.914, 0.560
Epoch: [208][400/782]	Time 0.099 (0.094)	Data 0.003 (0.004)	Loss 9.6418 (9.4209)	Acc@1 76.562 (80.510)	Acc@5 95.312 (96.902)
[epoch:209, iter:163057] Loss: 1.111, 8.036, 50.331, 364.950, 0.704
[epoch:209, iter:163077] Loss: 1.110, 8.036, 50.337, 364.971, 1.071
[epoch:209, iter:163097] Loss: 1.110, 8.034, 50.331, 364.951, 0.523
[epoch:209, iter:163117] Loss: 1.110, 8.039, 50.349, 365.058, 0.845
[epoch:209, iter:163137] Loss: 1.110, 8.037, 50.333, 365.015, 0.620
Epoch: [208][500/782]	Time 0.093 (0.095)	Data 0.003 (0.004)	Loss 9.1059 (9.4183)	Acc@1 84.375 (80.620)	Acc@5 98.438 (96.950)
[epoch:209, iter:163157] Loss: 1.110, 8.040, 50.317, 364.944, 0.468
[epoch:209, iter:163177] Loss: 1.110, 8.038, 50.304, 364.868, 0.764
[epoch:209, iter:163197] Loss: 1.110, 8.041, 50.313, 364.892, 0.532
[epoch:209, iter:163217] Loss: 1.110, 8.039, 50.312, 364.898, 0.590
[epoch:209, iter:163237] Loss: 1.110, 8.041, 50.312, 364.889, 1.098
Epoch: [208][600/782]	Time 0.093 (0.094)	Data 0.003 (0.003)	Loss 9.2274 (9.4237)	Acc@1 84.375 (80.631)	Acc@5 96.875 (96.911)
[epoch:209, iter:163257] Loss: 1.110, 8.043, 50.313, 364.933, 0.575
[epoch:209, iter:163277] Loss: 1.110, 8.042, 50.320, 364.948, 0.813
[epoch:209, iter:163297] Loss: 1.111, 8.040, 50.328, 364.965, 0.504
[epoch:209, iter:163317] Loss: 1.111, 8.040, 50.342, 365.036, 0.305
[epoch:209, iter:163337] Loss: 1.112, 8.043, 50.350, 365.097, 0.560
Epoch: [208][700/782]	Time 0.097 (0.094)	Data 0.002 (0.003)	Loss 8.9969 (9.4338)	Acc@1 76.562 (80.630)	Acc@5 98.438 (96.946)
[epoch:209, iter:163357] Loss: 1.112, 8.043, 50.353, 365.132, 0.555
[epoch:209, iter:163377] Loss: 1.112, 8.042, 50.351, 365.095, 0.547
[epoch:209, iter:163397] Loss: 1.112, 8.041, 50.344, 365.084, 0.520
[epoch:209, iter:163417] Loss: 1.112, 8.041, 50.342, 365.050, 0.543
[epoch:209, iter:163437] Loss: 1.112, 8.042, 50.340, 365.064, 0.608
 * Acc@1 80.652 Acc@5 96.980
epoch 208, total time 73.49
Test: [0/313]	Time 0.241 (0.241)	Loss 1.2537 (1.2537)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.3304 (1.1801)	Acc@1 59.375 (70.483)	Acc@5 96.875 (91.770)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7229 (1.1413)	Acc@1 81.250 (71.067)	Acc@5 96.875 (92.475)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4565 (1.1531)	Acc@1 62.500 (70.868)	Acc@5 100.000 (92.722)
 * Acc@1 70.970 Acc@5 92.790
==> training...
Epoch: [209][0/782]	Time 0.552 (0.552)	Data 0.458 (0.458)	Loss 9.2987 (9.2987)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
[epoch:210, iter:163439] Loss: 1.111, 7.773, 49.112, 359.031, 0.657
[epoch:210, iter:163459] Loss: 1.101, 8.019, 49.818, 362.680, 0.753
[epoch:210, iter:163479] Loss: 1.105, 8.017, 50.264, 364.437, 0.428
[epoch:210, iter:163499] Loss: 1.107, 8.031, 50.204, 364.530, 0.529
[epoch:210, iter:163519] Loss: 1.110, 8.029, 50.218, 364.336, 0.746
Epoch: [209][100/782]	Time 0.084 (0.094)	Data 0.002 (0.007)	Loss 9.8417 (9.4233)	Acc@1 78.125 (81.374)	Acc@5 92.188 (96.999)
[epoch:210, iter:163539] Loss: 1.110, 8.043, 50.282, 364.730, 0.694
[epoch:210, iter:163559] Loss: 1.111, 8.034, 50.330, 364.716, 0.591
[epoch:210, iter:163579] Loss: 1.112, 8.032, 50.386, 364.984, 0.670
[epoch:210, iter:163599] Loss: 1.109, 8.032, 50.306, 364.752, 0.661
[epoch:210, iter:163619] Loss: 1.108, 8.035, 50.306, 364.887, 0.644
Epoch: [209][200/782]	Time 0.091 (0.095)	Data 0.002 (0.005)	Loss 8.9393 (9.4194)	Acc@1 82.812 (80.986)	Acc@5 98.438 (97.015)
[epoch:210, iter:163639] Loss: 1.107, 8.035, 50.313, 364.851, 0.565
[epoch:210, iter:163659] Loss: 1.108, 8.035, 50.337, 364.960, 0.673
[epoch:210, iter:163679] Loss: 1.108, 8.040, 50.327, 364.805, 0.645
[epoch:210, iter:163699] Loss: 1.109, 8.040, 50.327, 364.807, 0.958
[epoch:210, iter:163719] Loss: 1.110, 8.043, 50.372, 364.962, 0.608
Epoch: [209][300/782]	Time 0.073 (0.088)	Data 0.002 (0.004)	Loss 9.0283 (9.4331)	Acc@1 89.062 (80.970)	Acc@5 96.875 (97.010)
[epoch:210, iter:163739] Loss: 1.111, 8.041, 50.380, 364.990, 0.454
[epoch:210, iter:163759] Loss: 1.110, 8.040, 50.391, 365.092, 0.628
[epoch:210, iter:163779] Loss: 1.111, 8.038, 50.383, 365.027, 0.706
[epoch:210, iter:163799] Loss: 1.110, 8.040, 50.387, 365.030, 0.844
[epoch:210, iter:163819] Loss: 1.111, 8.038, 50.386, 364.967, 0.306
Epoch: [209][400/782]	Time 0.081 (0.087)	Data 0.002 (0.003)	Loss 9.9824 (9.4315)	Acc@1 78.125 (80.927)	Acc@5 93.750 (97.011)
[epoch:210, iter:163839] Loss: 1.111, 8.041, 50.396, 365.062, 0.810
[epoch:210, iter:163859] Loss: 1.112, 8.040, 50.403, 365.129, 0.830
[epoch:210, iter:163879] Loss: 1.112, 8.043, 50.433, 365.286, 0.650
[epoch:210, iter:163899] Loss: 1.113, 8.045, 50.448, 365.324, 0.774
[epoch:210, iter:163919] Loss: 1.113, 8.049, 50.452, 365.403, 0.372
Epoch: [209][500/782]	Time 0.073 (0.086)	Data 0.002 (0.003)	Loss 9.4334 (9.4356)	Acc@1 87.500 (80.966)	Acc@5 98.438 (96.978)
[epoch:210, iter:163939] Loss: 1.112, 8.050, 50.424, 365.315, 0.364
[epoch:210, iter:163959] Loss: 1.112, 8.048, 50.410, 365.285, 0.469
[epoch:210, iter:163979] Loss: 1.112, 8.045, 50.398, 365.201, 0.678
[epoch:210, iter:163999] Loss: 1.113, 8.045, 50.409, 365.246, 0.517
[epoch:210, iter:164019] Loss: 1.112, 8.047, 50.412, 365.231, 0.411
Epoch: [209][600/782]	Time 0.074 (0.086)	Data 0.002 (0.003)	Loss 8.9387 (9.4310)	Acc@1 84.375 (80.933)	Acc@5 100.000 (97.002)
[epoch:210, iter:164039] Loss: 1.113, 8.046, 50.411, 365.209, 0.375
[epoch:210, iter:164059] Loss: 1.113, 8.044, 50.417, 365.233, 0.715
[epoch:210, iter:164079] Loss: 1.113, 8.045, 50.414, 365.210, 0.655
[epoch:210, iter:164099] Loss: 1.113, 8.046, 50.411, 365.186, 0.917
[epoch:210, iter:164119] Loss: 1.113, 8.045, 50.411, 365.166, 0.756
Epoch: [209][700/782]	Time 0.091 (0.086)	Data 0.003 (0.003)	Loss 9.3232 (9.4296)	Acc@1 87.500 (80.831)	Acc@5 96.875 (96.975)
[epoch:210, iter:164139] Loss: 1.113, 8.046, 50.407, 365.137, 0.510
[epoch:210, iter:164159] Loss: 1.113, 8.043, 50.393, 365.090, 0.548
[epoch:210, iter:164179] Loss: 1.113, 8.043, 50.387, 365.053, 0.510
[epoch:210, iter:164199] Loss: 1.112, 8.042, 50.375, 364.997, 0.701
[epoch:210, iter:164219] Loss: 1.112, 8.042, 50.381, 365.051, 0.346
 * Acc@1 80.756 Acc@5 96.946
epoch 209, total time 67.51
Test: [0/313]	Time 0.330 (0.330)	Loss 1.3333 (1.3333)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2276 (1.1842)	Acc@1 59.375 (70.978)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.6782 (1.1418)	Acc@1 75.000 (71.440)	Acc@5 100.000 (92.631)
Test: [300/313]	Time 0.008 (0.007)	Loss 1.3759 (1.1557)	Acc@1 62.500 (71.086)	Acc@5 93.750 (92.660)
 * Acc@1 71.210 Acc@5 92.710
==> training...
Epoch: [210][0/782]	Time 0.579 (0.579)	Data 0.491 (0.491)	Loss 9.0394 (9.0394)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
[epoch:211, iter:164221] Loss: 1.088, 7.792, 49.177, 361.356, 0.476
[epoch:211, iter:164241] Loss: 1.098, 8.022, 50.112, 365.071, 0.825
[epoch:211, iter:164261] Loss: 1.100, 8.030, 50.253, 365.387, 0.643
[epoch:211, iter:164281] Loss: 1.105, 8.035, 50.358, 365.394, 0.690
[epoch:211, iter:164301] Loss: 1.104, 8.015, 50.318, 364.664, 0.831
Epoch: [210][100/782]	Time 0.100 (0.098)	Data 0.002 (0.007)	Loss 9.1211 (9.4495)	Acc@1 84.375 (80.337)	Acc@5 96.875 (96.782)
[epoch:211, iter:164321] Loss: 1.106, 8.025, 50.357, 364.767, 0.551
[epoch:211, iter:164341] Loss: 1.107, 8.035, 50.444, 365.182, 0.633
[epoch:211, iter:164361] Loss: 1.108, 8.049, 50.486, 365.432, 0.711
[epoch:211, iter:164381] Loss: 1.110, 8.048, 50.477, 365.195, 0.939
[epoch:211, iter:164401] Loss: 1.110, 8.051, 50.456, 365.174, 0.502
Epoch: [210][200/782]	Time 0.083 (0.091)	Data 0.003 (0.005)	Loss 9.5025 (9.4626)	Acc@1 76.562 (80.255)	Acc@5 96.875 (96.844)
[epoch:211, iter:164421] Loss: 1.110, 8.049, 50.448, 365.145, 0.667
[epoch:211, iter:164441] Loss: 1.110, 8.058, 50.496, 365.406, 0.355
[epoch:211, iter:164461] Loss: 1.110, 8.055, 50.444, 365.139, 0.793
[epoch:211, iter:164481] Loss: 1.109, 8.056, 50.439, 365.141, 0.614
[epoch:211, iter:164501] Loss: 1.108, 8.054, 50.436, 365.172, 0.516
Epoch: [210][300/782]	Time 0.094 (0.088)	Data 0.003 (0.004)	Loss 9.4965 (9.4576)	Acc@1 87.500 (80.399)	Acc@5 95.312 (96.839)
[epoch:211, iter:164521] Loss: 1.110, 8.052, 50.445, 365.264, 0.582
[epoch:211, iter:164541] Loss: 1.111, 8.051, 50.410, 364.995, 0.463
[epoch:211, iter:164561] Loss: 1.112, 8.045, 50.436, 365.099, 0.655
[epoch:211, iter:164581] Loss: 1.111, 8.043, 50.447, 365.195, 0.795
[epoch:211, iter:164601] Loss: 1.110, 8.042, 50.434, 365.165, 0.573
Epoch: [210][400/782]	Time 0.090 (0.088)	Data 0.003 (0.004)	Loss 9.5147 (9.4376)	Acc@1 79.688 (80.669)	Acc@5 95.312 (96.891)
[epoch:211, iter:164621] Loss: 1.110, 8.037, 50.405, 364.995, 0.650
[epoch:211, iter:164641] Loss: 1.110, 8.040, 50.409, 364.998, 0.612
[epoch:211, iter:164661] Loss: 1.110, 8.038, 50.425, 365.120, 0.568
[epoch:211, iter:164681] Loss: 1.110, 8.041, 50.423, 365.167, 0.517
[epoch:211, iter:164701] Loss: 1.110, 8.041, 50.416, 365.104, 0.801
Epoch: [210][500/782]	Time 0.091 (0.089)	Data 0.003 (0.003)	Loss 10.1687 (9.4432)	Acc@1 75.000 (80.608)	Acc@5 93.750 (96.869)
[epoch:211, iter:164721] Loss: 1.110, 8.040, 50.413, 365.085, 0.857
[epoch:211, iter:164741] Loss: 1.110, 8.042, 50.431, 365.193, 0.773
[epoch:211, iter:164761] Loss: 1.111, 8.045, 50.426, 365.195, 0.530
[epoch:211, iter:164781] Loss: 1.111, 8.045, 50.425, 365.232, 0.671
[epoch:211, iter:164801] Loss: 1.110, 8.044, 50.439, 365.270, 0.471
Epoch: [210][600/782]	Time 0.095 (0.089)	Data 0.003 (0.003)	Loss 9.2294 (9.4454)	Acc@1 84.375 (80.605)	Acc@5 96.875 (96.896)
[epoch:211, iter:164821] Loss: 1.110, 8.044, 50.440, 365.285, 0.618
[epoch:211, iter:164841] Loss: 1.111, 8.042, 50.446, 365.303, 0.634
[epoch:211, iter:164861] Loss: 1.111, 8.041, 50.446, 365.279, 0.651
[epoch:211, iter:164881] Loss: 1.111, 8.041, 50.444, 365.285, 0.530
[epoch:211, iter:164901] Loss: 1.111, 8.041, 50.433, 365.255, 0.664
Epoch: [210][700/782]	Time 0.095 (0.090)	Data 0.003 (0.003)	Loss 9.0615 (9.4432)	Acc@1 85.938 (80.624)	Acc@5 96.875 (96.900)
[epoch:211, iter:164921] Loss: 1.111, 8.042, 50.443, 365.309, 0.571
[epoch:211, iter:164941] Loss: 1.110, 8.044, 50.440, 365.315, 0.927
[epoch:211, iter:164961] Loss: 1.110, 8.042, 50.426, 365.260, 0.628
[epoch:211, iter:164981] Loss: 1.111, 8.044, 50.444, 365.342, 0.514
[epoch:211, iter:165001] Loss: 1.111, 8.043, 50.442, 365.340, 0.823
 * Acc@1 80.678 Acc@5 96.904
epoch 210, total time 70.79
Test: [0/313]	Time 0.326 (0.326)	Loss 1.3011 (1.3011)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2853 (1.1823)	Acc@1 59.375 (70.452)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7173 (1.1444)	Acc@1 78.125 (70.927)	Acc@5 100.000 (92.677)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4161 (1.1562)	Acc@1 62.500 (70.868)	Acc@5 93.750 (92.764)
 * Acc@1 70.990 Acc@5 92.800
==> training...
Epoch: [211][0/782]	Time 0.538 (0.538)	Data 0.472 (0.472)	Loss 10.1469 (10.1469)	Acc@1 68.750 (68.750)	Acc@5 95.312 (95.312)
[epoch:212, iter:165003] Loss: 1.142, 8.297, 52.220, 375.939, 0.827
[epoch:212, iter:165023] Loss: 1.099, 8.111, 50.634, 367.232, 0.484
[epoch:212, iter:165043] Loss: 1.101, 8.099, 50.476, 366.483, 0.565
[epoch:212, iter:165063] Loss: 1.106, 8.088, 50.457, 366.121, 0.771
[epoch:212, iter:165083] Loss: 1.110, 8.064, 50.473, 365.930, 0.621
Epoch: [211][100/782]	Time 0.078 (0.081)	Data 0.002 (0.007)	Loss 9.2556 (9.4456)	Acc@1 76.562 (81.173)	Acc@5 96.875 (96.736)
[epoch:212, iter:165103] Loss: 1.110, 8.052, 50.521, 366.062, 0.609
[epoch:212, iter:165123] Loss: 1.108, 8.042, 50.419, 365.502, 0.665
[epoch:212, iter:165143] Loss: 1.107, 8.046, 50.393, 365.522, 0.349
[epoch:212, iter:165163] Loss: 1.107, 8.039, 50.345, 365.248, 0.473
[epoch:212, iter:165183] Loss: 1.109, 8.042, 50.337, 365.239, 0.670
Epoch: [211][200/782]	Time 0.088 (0.078)	Data 0.003 (0.004)	Loss 9.0969 (9.3907)	Acc@1 89.062 (81.437)	Acc@5 96.875 (96.898)
[epoch:212, iter:165203] Loss: 1.108, 8.036, 50.324, 365.098, 0.409
[epoch:212, iter:165223] Loss: 1.108, 8.036, 50.309, 365.086, 0.676
[epoch:212, iter:165243] Loss: 1.108, 8.037, 50.291, 365.036, 0.695
[epoch:212, iter:165263] Loss: 1.110, 8.034, 50.309, 365.076, 0.490
[epoch:212, iter:165283] Loss: 1.110, 8.035, 50.291, 364.928, 0.864
Epoch: [211][300/782]	Time 0.065 (0.079)	Data 0.002 (0.004)	Loss 8.5970 (9.3918)	Acc@1 89.062 (81.240)	Acc@5 100.000 (96.870)
[epoch:212, iter:165303] Loss: 1.110, 8.031, 50.264, 364.821, 0.333
[epoch:212, iter:165323] Loss: 1.108, 8.027, 50.246, 364.782, 0.779
[epoch:212, iter:165343] Loss: 1.108, 8.026, 50.225, 364.680, 0.440
[epoch:212, iter:165363] Loss: 1.108, 8.029, 50.235, 364.805, 0.840
[epoch:212, iter:165383] Loss: 1.109, 8.027, 50.228, 364.752, 0.604
Epoch: [211][400/782]	Time 0.104 (0.080)	Data 0.003 (0.003)	Loss 10.0215 (9.3904)	Acc@1 79.688 (81.141)	Acc@5 95.312 (96.809)
[epoch:212, iter:165403] Loss: 1.109, 8.029, 50.236, 364.815, 0.809
[epoch:212, iter:165423] Loss: 1.109, 8.032, 50.235, 364.776, 0.476
[epoch:212, iter:165443] Loss: 1.110, 8.031, 50.222, 364.709, 0.653
[epoch:212, iter:165463] Loss: 1.110, 8.031, 50.215, 364.657, 0.645
[epoch:212, iter:165483] Loss: 1.109, 8.032, 50.220, 364.691, 0.604
Epoch: [211][500/782]	Time 0.079 (0.083)	Data 0.002 (0.003)	Loss 9.5003 (9.3854)	Acc@1 84.375 (80.929)	Acc@5 98.438 (96.819)
[epoch:212, iter:165503] Loss: 1.109, 8.029, 50.193, 364.553, 0.543
[epoch:212, iter:165523] Loss: 1.110, 8.028, 50.209, 364.654, 0.733
[epoch:212, iter:165543] Loss: 1.110, 8.025, 50.196, 364.593, 0.806
[epoch:212, iter:165563] Loss: 1.110, 8.024, 50.195, 364.577, 0.617
[epoch:212, iter:165583] Loss: 1.110, 8.026, 50.196, 364.608, 0.635
Epoch: [211][600/782]	Time 0.074 (0.084)	Data 0.002 (0.003)	Loss 9.7916 (9.3880)	Acc@1 78.125 (80.894)	Acc@5 92.188 (96.828)
[epoch:212, iter:165603] Loss: 1.110, 8.024, 50.192, 364.583, 0.690
[epoch:212, iter:165623] Loss: 1.110, 8.024, 50.190, 364.591, 0.529
[epoch:212, iter:165643] Loss: 1.110, 8.022, 50.184, 364.556, 0.591
[epoch:212, iter:165663] Loss: 1.110, 8.023, 50.199, 364.648, 0.619
[epoch:212, iter:165683] Loss: 1.110, 8.024, 50.198, 364.646, 0.761
Epoch: [211][700/782]	Time 0.073 (0.083)	Data 0.002 (0.003)	Loss 9.2853 (9.3889)	Acc@1 76.562 (80.909)	Acc@5 100.000 (96.859)
[epoch:212, iter:165703] Loss: 1.110, 8.024, 50.186, 364.609, 0.639
[epoch:212, iter:165723] Loss: 1.110, 8.022, 50.182, 364.575, 0.764
[epoch:212, iter:165743] Loss: 1.110, 8.022, 50.180, 364.567, 0.461
[epoch:212, iter:165763] Loss: 1.110, 8.023, 50.179, 364.587, 0.811
[epoch:212, iter:165783] Loss: 1.110, 8.024, 50.182, 364.590, 0.521
 * Acc@1 80.988 Acc@5 96.872
epoch 211, total time 63.94
Test: [0/313]	Time 0.232 (0.232)	Loss 1.2952 (1.2952)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2098 (1.1693)	Acc@1 65.625 (70.792)	Acc@5 96.875 (92.327)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.6961 (1.1313)	Acc@1 75.000 (71.346)	Acc@5 96.875 (92.662)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.5199 (1.1437)	Acc@1 62.500 (71.034)	Acc@5 96.875 (92.847)
 * Acc@1 71.190 Acc@5 92.900
==> training...
Epoch: [212][0/782]	Time 0.634 (0.634)	Data 0.535 (0.535)	Loss 9.2438 (9.2438)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
[epoch:213, iter:165785] Loss: 1.059, 8.079, 50.001, 364.448, 0.493
[epoch:213, iter:165805] Loss: 1.106, 7.931, 50.173, 364.217, 0.631
[epoch:213, iter:165825] Loss: 1.102, 7.956, 50.098, 363.992, 0.528
[epoch:213, iter:165845] Loss: 1.105, 7.976, 50.172, 364.657, 0.791
[epoch:213, iter:165865] Loss: 1.104, 7.976, 50.123, 364.560, 0.707
Epoch: [212][100/782]	Time 0.092 (0.096)	Data 0.003 (0.008)	Loss 9.6097 (9.3738)	Acc@1 85.938 (80.538)	Acc@5 100.000 (97.200)
[epoch:213, iter:165885] Loss: 1.104, 7.987, 50.073, 364.289, 0.483
[epoch:213, iter:165905] Loss: 1.104, 7.989, 50.008, 363.893, 0.782
[epoch:213, iter:165925] Loss: 1.105, 7.994, 50.025, 363.980, 0.679
[epoch:213, iter:165945] Loss: 1.104, 7.988, 50.032, 364.113, 0.691
[epoch:213, iter:165965] Loss: 1.105, 7.999, 50.055, 364.149, 0.616
Epoch: [212][200/782]	Time 0.083 (0.093)	Data 0.002 (0.005)	Loss 9.8916 (9.3733)	Acc@1 78.125 (80.737)	Acc@5 95.312 (96.898)
[epoch:213, iter:165985] Loss: 1.105, 7.998, 50.069, 364.103, 0.677
[epoch:213, iter:166005] Loss: 1.105, 7.995, 50.057, 363.996, 0.524
[epoch:213, iter:166025] Loss: 1.106, 8.002, 50.064, 364.087, 0.437
[epoch:213, iter:166045] Loss: 1.105, 7.999, 50.061, 364.129, 0.516
[epoch:213, iter:166065] Loss: 1.104, 7.999, 50.040, 364.072, 0.487
Epoch: [212][300/782]	Time 0.094 (0.093)	Data 0.002 (0.004)	Loss 9.0703 (9.3721)	Acc@1 81.250 (80.752)	Acc@5 100.000 (96.911)
[epoch:213, iter:166085] Loss: 1.106, 8.000, 50.084, 364.227, 0.407
[epoch:213, iter:166105] Loss: 1.106, 8.001, 50.090, 364.223, 0.649
[epoch:213, iter:166125] Loss: 1.105, 8.004, 50.096, 364.200, 0.504
[epoch:213, iter:166145] Loss: 1.105, 8.004, 50.078, 364.164, 0.698
[epoch:213, iter:166165] Loss: 1.105, 8.007, 50.078, 364.242, 0.336
Epoch: [212][400/782]	Time 0.095 (0.093)	Data 0.003 (0.004)	Loss 8.6401 (9.3627)	Acc@1 95.312 (81.086)	Acc@5 100.000 (96.930)
[epoch:213, iter:166185] Loss: 1.103, 8.010, 50.060, 364.236, 0.191
[epoch:213, iter:166205] Loss: 1.104, 8.011, 50.067, 364.232, 0.575
[epoch:213, iter:166225] Loss: 1.105, 8.011, 50.082, 364.272, 0.544
[epoch:213, iter:166245] Loss: 1.105, 8.011, 50.091, 364.303, 0.513
[epoch:213, iter:166265] Loss: 1.105, 8.011, 50.069, 364.191, 0.822
Epoch: [212][500/782]	Time 0.089 (0.093)	Data 0.002 (0.004)	Loss 9.1641 (9.3568)	Acc@1 85.938 (81.088)	Acc@5 95.312 (97.009)
[epoch:213, iter:166285] Loss: 1.105, 8.012, 50.052, 364.114, 0.540
[epoch:213, iter:166305] Loss: 1.105, 8.015, 50.048, 364.117, 0.599
[epoch:213, iter:166325] Loss: 1.105, 8.015, 50.030, 364.067, 0.459
[epoch:213, iter:166345] Loss: 1.105, 8.014, 50.033, 364.051, 0.480
[epoch:213, iter:166365] Loss: 1.105, 8.013, 50.015, 363.975, 0.737
Epoch: [212][600/782]	Time 0.085 (0.091)	Data 0.002 (0.003)	Loss 9.3288 (9.3503)	Acc@1 84.375 (81.115)	Acc@5 95.312 (97.018)
[epoch:213, iter:166385] Loss: 1.104, 8.013, 50.011, 363.996, 0.575
[epoch:213, iter:166405] Loss: 1.104, 8.012, 50.001, 363.946, 0.318
[epoch:213, iter:166425] Loss: 1.104, 8.014, 49.997, 363.941, 0.492
[epoch:213, iter:166445] Loss: 1.104, 8.016, 49.991, 363.928, 0.350
[epoch:213, iter:166465] Loss: 1.104, 8.016, 49.991, 363.910, 0.708
Epoch: [212][700/782]	Time 0.074 (0.089)	Data 0.002 (0.003)	Loss 9.3348 (9.3481)	Acc@1 84.375 (81.078)	Acc@5 98.438 (97.024)
[epoch:213, iter:166485] Loss: 1.104, 8.016, 50.001, 363.951, 0.466
[epoch:213, iter:166505] Loss: 1.104, 8.017, 50.001, 363.931, 0.733
[epoch:213, iter:166525] Loss: 1.104, 8.017, 49.995, 363.873, 0.553
[epoch:213, iter:166545] Loss: 1.105, 8.018, 50.007, 363.912, 0.818
[epoch:213, iter:166565] Loss: 1.104, 8.018, 50.005, 363.911, 0.551
 * Acc@1 81.174 Acc@5 97.038
epoch 212, total time 68.90
Test: [0/313]	Time 0.307 (0.307)	Loss 1.3000 (1.3000)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.011)	Loss 1.3357 (1.1784)	Acc@1 59.375 (70.978)	Acc@5 96.875 (91.925)
Test: [200/313]	Time 0.006 (0.009)	Loss 0.6778 (1.1407)	Acc@1 78.125 (71.284)	Acc@5 96.875 (92.522)
Test: [300/313]	Time 0.006 (0.008)	Loss 1.4200 (1.1516)	Acc@1 62.500 (71.065)	Acc@5 96.875 (92.743)
 * Acc@1 71.220 Acc@5 92.790
==> training...
Epoch: [213][0/782]	Time 0.694 (0.694)	Data 0.601 (0.601)	Loss 9.8983 (9.8983)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
[epoch:214, iter:166567] Loss: 1.129, 8.060, 52.225, 380.546, 0.544
[epoch:214, iter:166587] Loss: 1.114, 8.152, 50.285, 365.619, 0.899
[epoch:214, iter:166607] Loss: 1.116, 8.090, 50.214, 364.526, 0.747
[epoch:214, iter:166627] Loss: 1.110, 8.074, 50.131, 364.438, 0.557
[epoch:214, iter:166647] Loss: 1.109, 8.061, 50.087, 364.413, 0.649
Epoch: [213][100/782]	Time 0.082 (0.096)	Data 0.002 (0.008)	Loss 8.7102 (9.3803)	Acc@1 92.188 (80.709)	Acc@5 96.875 (96.875)
[epoch:214, iter:166667] Loss: 1.104, 8.056, 50.026, 364.166, 0.458
[epoch:214, iter:166687] Loss: 1.108, 8.062, 50.072, 364.403, 0.689
[epoch:214, iter:166707] Loss: 1.107, 8.052, 50.066, 364.367, 0.450
[epoch:214, iter:166727] Loss: 1.106, 8.049, 50.089, 364.446, 0.317
[epoch:214, iter:166747] Loss: 1.106, 8.039, 50.130, 364.493, 0.722
Epoch: [213][200/782]	Time 0.094 (0.091)	Data 0.003 (0.005)	Loss 9.4243 (9.3899)	Acc@1 82.812 (80.714)	Acc@5 98.438 (96.782)
[epoch:214, iter:166767] Loss: 1.105, 8.035, 50.074, 364.300, 0.571
[epoch:214, iter:166787] Loss: 1.108, 8.027, 50.127, 364.383, 0.749
[epoch:214, iter:166807] Loss: 1.108, 8.026, 50.109, 364.296, 0.471
[epoch:214, iter:166827] Loss: 1.107, 8.021, 50.048, 364.008, 0.455
[epoch:214, iter:166847] Loss: 1.106, 8.023, 50.036, 363.940, 0.783
Epoch: [213][300/782]	Time 0.086 (0.091)	Data 0.003 (0.004)	Loss 9.7188 (9.3692)	Acc@1 81.250 (80.845)	Acc@5 96.875 (96.828)
[epoch:214, iter:166867] Loss: 1.106, 8.027, 50.042, 363.941, 0.652
[epoch:214, iter:166887] Loss: 1.106, 8.024, 50.056, 364.007, 0.476
[epoch:214, iter:166907] Loss: 1.106, 8.021, 50.049, 364.045, 0.608
[epoch:214, iter:166927] Loss: 1.106, 8.019, 50.067, 364.124, 0.391
[epoch:214, iter:166947] Loss: 1.106, 8.019, 50.077, 364.221, 0.686
Epoch: [213][400/782]	Time 0.091 (0.091)	Data 0.003 (0.004)	Loss 9.2567 (9.3690)	Acc@1 84.375 (81.129)	Acc@5 93.750 (96.828)
[epoch:214, iter:166967] Loss: 1.106, 8.018, 50.076, 364.202, 0.574
[epoch:214, iter:166987] Loss: 1.105, 8.018, 50.069, 364.140, 0.516
[epoch:214, iter:167007] Loss: 1.106, 8.017, 50.084, 364.189, 0.317
[epoch:214, iter:167027] Loss: 1.106, 8.015, 50.049, 364.045, 0.506
[epoch:214, iter:167047] Loss: 1.106, 8.015, 50.034, 363.988, 0.606
Epoch: [213][500/782]	Time 0.090 (0.091)	Data 0.003 (0.004)	Loss 8.8622 (9.3510)	Acc@1 89.062 (81.219)	Acc@5 98.438 (96.872)
[epoch:214, iter:167067] Loss: 1.106, 8.012, 50.022, 363.935, 0.440
[epoch:214, iter:167087] Loss: 1.106, 8.014, 50.004, 363.838, 0.420
[epoch:214, iter:167107] Loss: 1.106, 8.015, 50.016, 363.923, 0.724
[epoch:214, iter:167127] Loss: 1.106, 8.018, 50.022, 363.984, 0.780
[epoch:214, iter:167147] Loss: 1.106, 8.015, 50.022, 363.980, 0.673
Epoch: [213][600/782]	Time 0.092 (0.092)	Data 0.003 (0.003)	Loss 9.3659 (9.3540)	Acc@1 81.250 (81.182)	Acc@5 92.188 (96.914)
[epoch:214, iter:167167] Loss: 1.106, 8.016, 50.035, 364.028, 0.774
[epoch:214, iter:167187] Loss: 1.106, 8.018, 50.042, 364.058, 0.505
[epoch:214, iter:167207] Loss: 1.106, 8.017, 50.032, 364.036, 0.790
[epoch:214, iter:167227] Loss: 1.107, 8.016, 50.041, 364.061, 0.581
[epoch:214, iter:167247] Loss: 1.107, 8.015, 50.036, 364.030, 0.695
Epoch: [213][700/782]	Time 0.082 (0.092)	Data 0.002 (0.003)	Loss 9.0728 (9.3560)	Acc@1 82.812 (81.141)	Acc@5 96.875 (96.973)
[epoch:214, iter:167267] Loss: 1.107, 8.015, 50.049, 364.114, 0.505
[epoch:214, iter:167287] Loss: 1.107, 8.017, 50.061, 364.185, 0.285
[epoch:214, iter:167307] Loss: 1.106, 8.020, 50.065, 364.197, 0.598
[epoch:214, iter:167327] Loss: 1.107, 8.020, 50.067, 364.202, 1.086
[epoch:214, iter:167347] Loss: 1.107, 8.020, 50.063, 364.190, 0.839
 * Acc@1 81.056 Acc@5 96.984
epoch 213, total time 70.80
Test: [0/313]	Time 0.267 (0.267)	Loss 1.3399 (1.3399)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2840 (1.1774)	Acc@1 65.625 (70.978)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.009 (0.008)	Loss 0.7569 (1.1394)	Acc@1 78.125 (71.424)	Acc@5 100.000 (92.631)
Test: [300/313]	Time 0.008 (0.008)	Loss 1.3627 (1.1517)	Acc@1 59.375 (71.065)	Acc@5 96.875 (92.816)
 * Acc@1 71.180 Acc@5 92.860
==> training...
Epoch: [214][0/782]	Time 0.614 (0.614)	Data 0.531 (0.531)	Loss 9.1456 (9.1456)	Acc@1 85.938 (85.938)	Acc@5 96.875 (96.875)
[epoch:215, iter:167349] Loss: 1.124, 7.896, 49.891, 363.781, 0.463
[epoch:215, iter:167369] Loss: 1.100, 8.001, 49.589, 361.996, 0.639
[epoch:215, iter:167389] Loss: 1.100, 7.961, 49.639, 361.688, 0.806
[epoch:215, iter:167409] Loss: 1.101, 7.964, 49.702, 362.488, 0.842
[epoch:215, iter:167429] Loss: 1.099, 7.987, 49.680, 362.324, 0.718
Epoch: [214][100/782]	Time 0.069 (0.083)	Data 0.002 (0.007)	Loss 10.1295 (9.2597)	Acc@1 70.312 (82.194)	Acc@5 93.750 (97.277)
[epoch:215, iter:167449] Loss: 1.102, 7.998, 49.730, 362.410, 1.021
[epoch:215, iter:167469] Loss: 1.103, 7.996, 49.796, 362.713, 0.520
[epoch:215, iter:167489] Loss: 1.103, 7.993, 49.860, 363.082, 0.547
[epoch:215, iter:167509] Loss: 1.104, 7.995, 49.883, 363.189, 0.636
[epoch:215, iter:167529] Loss: 1.104, 7.999, 49.918, 363.335, 0.868
Epoch: [214][200/782]	Time 0.062 (0.078)	Data 0.002 (0.005)	Loss 9.5340 (9.3214)	Acc@1 78.125 (81.522)	Acc@5 98.438 (97.225)
[epoch:215, iter:167549] Loss: 1.106, 7.997, 49.919, 363.290, 0.748
[epoch:215, iter:167569] Loss: 1.106, 8.003, 49.956, 363.512, 0.633
[epoch:215, iter:167589] Loss: 1.105, 8.006, 49.947, 363.504, 0.567
[epoch:215, iter:167609] Loss: 1.106, 8.008, 49.987, 363.704, 0.553
[epoch:215, iter:167629] Loss: 1.106, 8.009, 49.986, 363.705, 0.647
Epoch: [214][300/782]	Time 0.070 (0.078)	Data 0.002 (0.004)	Loss 9.8758 (9.3474)	Acc@1 76.562 (81.224)	Acc@5 92.188 (96.989)
[epoch:215, iter:167649] Loss: 1.107, 8.014, 49.982, 363.737, 0.646
[epoch:215, iter:167669] Loss: 1.106, 8.011, 49.989, 363.756, 0.555
[epoch:215, iter:167689] Loss: 1.107, 8.009, 49.983, 363.719, 0.543
[epoch:215, iter:167709] Loss: 1.107, 8.010, 49.975, 363.682, 0.946
[epoch:215, iter:167729] Loss: 1.107, 8.014, 49.988, 363.769, 0.454
Epoch: [214][400/782]	Time 0.089 (0.080)	Data 0.002 (0.003)	Loss 9.5110 (9.3491)	Acc@1 75.000 (81.059)	Acc@5 96.875 (97.027)
[epoch:215, iter:167749] Loss: 1.108, 8.012, 50.005, 363.782, 0.752
[epoch:215, iter:167769] Loss: 1.107, 8.015, 49.996, 363.715, 0.355
[epoch:215, iter:167789] Loss: 1.107, 8.016, 49.986, 363.698, 0.793
[epoch:215, iter:167809] Loss: 1.107, 8.015, 49.992, 363.760, 0.785
[epoch:215, iter:167829] Loss: 1.107, 8.013, 49.995, 363.778, 0.698
Epoch: [214][500/782]	Time 0.095 (0.081)	Data 0.002 (0.003)	Loss 9.3026 (9.3477)	Acc@1 85.938 (81.047)	Acc@5 98.438 (96.962)
[epoch:215, iter:167849] Loss: 1.107, 8.013, 49.983, 363.733, 0.518
[epoch:215, iter:167869] Loss: 1.107, 8.013, 49.988, 363.758, 0.693
[epoch:215, iter:167889] Loss: 1.106, 8.013, 49.982, 363.726, 0.527
[epoch:215, iter:167909] Loss: 1.106, 8.013, 49.973, 363.723, 0.594
[epoch:215, iter:167929] Loss: 1.105, 8.014, 49.982, 363.759, 0.608
Epoch: [214][600/782]	Time 0.087 (0.083)	Data 0.003 (0.003)	Loss 9.5491 (9.3536)	Acc@1 82.812 (80.915)	Acc@5 100.000 (96.940)
[epoch:215, iter:167949] Loss: 1.105, 8.015, 49.999, 363.857, 0.532
[epoch:215, iter:167969] Loss: 1.106, 8.015, 50.012, 363.932, 0.539
[epoch:215, iter:167989] Loss: 1.106, 8.017, 50.024, 363.999, 0.675
[epoch:215, iter:168009] Loss: 1.106, 8.017, 50.024, 364.033, 0.769
[epoch:215, iter:168029] Loss: 1.106, 8.016, 50.040, 364.061, 0.691
Epoch: [214][700/782]	Time 0.090 (0.082)	Data 0.003 (0.003)	Loss 9.3992 (9.3599)	Acc@1 82.812 (80.898)	Acc@5 95.312 (96.973)
[epoch:215, iter:168049] Loss: 1.106, 8.016, 50.031, 364.044, 0.512
[epoch:215, iter:168069] Loss: 1.106, 8.016, 50.032, 364.039, 0.626
[epoch:215, iter:168089] Loss: 1.107, 8.017, 50.040, 364.082, 0.543
[epoch:215, iter:168109] Loss: 1.107, 8.018, 50.049, 364.117, 0.887
[epoch:215, iter:168129] Loss: 1.107, 8.019, 50.053, 364.149, 0.400
 * Acc@1 80.856 Acc@5 96.974
epoch 214, total time 64.90
Test: [0/313]	Time 0.333 (0.333)	Loss 1.3036 (1.3036)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2799 (1.1805)	Acc@1 65.625 (70.637)	Acc@5 96.875 (91.986)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7514 (1.1414)	Acc@1 78.125 (71.206)	Acc@5 96.875 (92.522)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4202 (1.1537)	Acc@1 62.500 (71.024)	Acc@5 100.000 (92.629)
 * Acc@1 71.160 Acc@5 92.670
==> training...
Epoch: [215][0/782]	Time 0.550 (0.550)	Data 0.488 (0.488)	Loss 8.8090 (8.8090)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
[epoch:216, iter:168131] Loss: 1.051, 7.668, 48.147, 354.047, 0.535
[epoch:216, iter:168151] Loss: 1.105, 7.947, 49.731, 362.265, 0.401
[epoch:216, iter:168171] Loss: 1.098, 7.983, 49.696, 362.320, 0.486
[epoch:216, iter:168191] Loss: 1.095, 7.981, 49.865, 363.264, 0.746
[epoch:216, iter:168211] Loss: 1.102, 8.003, 50.001, 363.752, 0.562
Epoch: [215][100/782]	Time 0.091 (0.092)	Data 0.002 (0.007)	Loss 8.5498 (9.3092)	Acc@1 90.625 (81.776)	Acc@5 100.000 (97.231)
[epoch:216, iter:168231] Loss: 1.104, 8.005, 49.982, 363.534, 0.344
[epoch:216, iter:168251] Loss: 1.105, 8.007, 49.987, 363.671, 0.884
[epoch:216, iter:168271] Loss: 1.106, 8.011, 49.985, 363.774, 0.350
[epoch:216, iter:168291] Loss: 1.106, 8.012, 50.018, 363.851, 0.949
[epoch:216, iter:168311] Loss: 1.106, 8.016, 50.030, 363.970, 0.566
Epoch: [215][200/782]	Time 0.095 (0.084)	Data 0.002 (0.005)	Loss 9.5186 (9.3528)	Acc@1 81.250 (81.203)	Acc@5 95.312 (96.891)
[epoch:216, iter:168331] Loss: 1.107, 8.019, 50.048, 364.086, 0.678
[epoch:216, iter:168351] Loss: 1.107, 8.020, 50.055, 364.036, 0.493
[epoch:216, iter:168371] Loss: 1.108, 8.015, 50.036, 363.933, 0.715
[epoch:216, iter:168391] Loss: 1.107, 8.010, 50.003, 363.806, 0.589
[epoch:216, iter:168411] Loss: 1.105, 8.012, 49.990, 363.841, 0.621
Epoch: [215][300/782]	Time 0.089 (0.083)	Data 0.002 (0.004)	Loss 9.6148 (9.3505)	Acc@1 90.625 (81.255)	Acc@5 98.438 (96.963)
[epoch:216, iter:168431] Loss: 1.106, 8.015, 50.019, 364.029, 0.440
[epoch:216, iter:168451] Loss: 1.105, 8.012, 50.013, 364.027, 0.435
[epoch:216, iter:168471] Loss: 1.104, 8.011, 49.983, 363.877, 0.540
[epoch:216, iter:168491] Loss: 1.104, 8.014, 50.000, 364.015, 0.440
[epoch:216, iter:168511] Loss: 1.104, 8.017, 50.010, 364.052, 0.511
Epoch: [215][400/782]	Time 0.095 (0.086)	Data 0.003 (0.003)	Loss 9.0111 (9.3513)	Acc@1 87.500 (81.281)	Acc@5 100.000 (96.953)
[epoch:216, iter:168531] Loss: 1.105, 8.017, 50.026, 364.038, 0.428
[epoch:216, iter:168551] Loss: 1.106, 8.019, 50.056, 364.155, 0.618
[epoch:216, iter:168571] Loss: 1.106, 8.019, 50.050, 364.088, 0.561
[epoch:216, iter:168591] Loss: 1.106, 8.016, 50.053, 364.069, 0.455
[epoch:216, iter:168611] Loss: 1.107, 8.016, 50.077, 364.207, 0.732
Epoch: [215][500/782]	Time 0.095 (0.087)	Data 0.002 (0.003)	Loss 9.9049 (9.3611)	Acc@1 78.125 (81.300)	Acc@5 95.312 (96.937)
[epoch:216, iter:168631] Loss: 1.106, 8.016, 50.066, 364.133, 0.745
[epoch:216, iter:168651] Loss: 1.106, 8.017, 50.051, 364.090, 0.598
[epoch:216, iter:168671] Loss: 1.107, 8.018, 50.068, 364.144, 0.482
[epoch:216, iter:168691] Loss: 1.107, 8.019, 50.057, 364.066, 0.588
[epoch:216, iter:168711] Loss: 1.107, 8.021, 50.058, 364.087, 0.752
Epoch: [215][600/782]	Time 0.096 (0.088)	Data 0.003 (0.003)	Loss 8.9102 (9.3625)	Acc@1 89.062 (81.234)	Acc@5 100.000 (96.937)
[epoch:216, iter:168731] Loss: 1.107, 8.021, 50.060, 364.122, 0.318
[epoch:216, iter:168751] Loss: 1.107, 8.022, 50.059, 364.101, 0.489
[epoch:216, iter:168771] Loss: 1.107, 8.025, 50.077, 364.213, 0.616
[epoch:216, iter:168791] Loss: 1.107, 8.025, 50.079, 364.228, 0.583
[epoch:216, iter:168811] Loss: 1.107, 8.025, 50.075, 364.197, 0.610
Epoch: [215][700/782]	Time 0.063 (0.087)	Data 0.002 (0.003)	Loss 10.1436 (9.3671)	Acc@1 78.125 (81.250)	Acc@5 98.438 (96.971)
[epoch:216, iter:168831] Loss: 1.107, 8.026, 50.079, 364.208, 0.648
[epoch:216, iter:168851] Loss: 1.107, 8.026, 50.088, 364.232, 0.529
[epoch:216, iter:168871] Loss: 1.107, 8.025, 50.090, 364.226, 0.476
[epoch:216, iter:168891] Loss: 1.107, 8.024, 50.076, 364.163, 0.974
[epoch:216, iter:168911] Loss: 1.106, 8.024, 50.079, 364.180, 0.482
 * Acc@1 81.150 Acc@5 96.962
epoch 215, total time 67.03
Test: [0/313]	Time 0.267 (0.267)	Loss 1.3000 (1.3000)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2906 (1.1721)	Acc@1 65.625 (71.040)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7209 (1.1343)	Acc@1 78.125 (71.471)	Acc@5 96.875 (92.693)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3965 (1.1464)	Acc@1 62.500 (71.096)	Acc@5 93.750 (92.805)
 * Acc@1 71.210 Acc@5 92.860
==> training...
Epoch: [216][0/782]	Time 0.557 (0.557)	Data 0.480 (0.480)	Loss 9.6471 (9.6471)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
[epoch:217, iter:168913] Loss: 1.084, 8.170, 51.367, 373.706, 0.623
[epoch:217, iter:168933] Loss: 1.094, 8.048, 50.302, 365.927, 0.995
[epoch:217, iter:168953] Loss: 1.097, 8.039, 50.268, 365.679, 0.464
[epoch:217, iter:168973] Loss: 1.099, 8.047, 50.089, 364.579, 0.931
[epoch:217, iter:168993] Loss: 1.101, 8.021, 50.115, 364.775, 0.748
Epoch: [216][100/782]	Time 0.081 (0.101)	Data 0.002 (0.007)	Loss 9.4100 (9.4132)	Acc@1 78.125 (81.250)	Acc@5 100.000 (96.999)
[epoch:217, iter:169013] Loss: 1.100, 8.044, 50.219, 365.384, 0.514
[epoch:217, iter:169033] Loss: 1.101, 8.045, 50.218, 365.402, 0.421
[epoch:217, iter:169053] Loss: 1.102, 8.040, 50.285, 365.463, 0.689
[epoch:217, iter:169073] Loss: 1.102, 8.037, 50.290, 365.443, 0.727
[epoch:217, iter:169093] Loss: 1.102, 8.031, 50.262, 365.234, 0.570
Epoch: [216][200/782]	Time 0.089 (0.097)	Data 0.002 (0.005)	Loss 9.0726 (9.3948)	Acc@1 78.125 (81.413)	Acc@5 100.000 (97.007)
[epoch:217, iter:169113] Loss: 1.102, 8.031, 50.204, 364.922, 0.608
[epoch:217, iter:169133] Loss: 1.102, 8.028, 50.201, 364.843, 0.549
[epoch:217, iter:169153] Loss: 1.103, 8.038, 50.187, 364.850, 0.629
[epoch:217, iter:169173] Loss: 1.103, 8.036, 50.167, 364.775, 0.385
[epoch:217, iter:169193] Loss: 1.103, 8.033, 50.155, 364.622, 0.362
Epoch: [216][300/782]	Time 0.076 (0.092)	Data 0.002 (0.004)	Loss 9.1749 (9.3708)	Acc@1 85.938 (81.593)	Acc@5 95.312 (97.114)
[epoch:217, iter:169213] Loss: 1.105, 8.036, 50.144, 364.577, 0.470
[epoch:217, iter:169233] Loss: 1.105, 8.034, 50.129, 364.532, 0.637
[epoch:217, iter:169253] Loss: 1.107, 8.033, 50.154, 364.484, 0.854
[epoch:217, iter:169273] Loss: 1.107, 8.036, 50.131, 364.428, 0.421
[epoch:217, iter:169293] Loss: 1.106, 8.030, 50.106, 364.342, 0.453
Epoch: [216][400/782]	Time 0.108 (0.093)	Data 0.003 (0.004)	Loss 8.9153 (9.3568)	Acc@1 82.812 (81.492)	Acc@5 98.438 (97.156)
[epoch:217, iter:169313] Loss: 1.106, 8.031, 50.087, 364.237, 0.476
[epoch:217, iter:169333] Loss: 1.105, 8.030, 50.073, 364.207, 0.434
[epoch:217, iter:169353] Loss: 1.106, 8.028, 50.085, 364.188, 0.377
[epoch:217, iter:169373] Loss: 1.107, 8.025, 50.083, 364.149, 0.467
[epoch:217, iter:169393] Loss: 1.106, 8.025, 50.066, 364.090, 0.448
Epoch: [216][500/782]	Time 0.079 (0.090)	Data 0.002 (0.003)	Loss 9.3497 (9.3521)	Acc@1 76.562 (81.437)	Acc@5 96.875 (97.025)
[epoch:217, iter:169413] Loss: 1.106, 8.023, 50.082, 364.135, 0.597
[epoch:217, iter:169433] Loss: 1.107, 8.022, 50.089, 364.148, 1.069
[epoch:217, iter:169453] Loss: 1.107, 8.023, 50.098, 364.179, 0.560
[epoch:217, iter:169473] Loss: 1.107, 8.026, 50.100, 364.200, 0.639
[epoch:217, iter:169493] Loss: 1.107, 8.024, 50.090, 364.146, 0.914
Epoch: [216][600/782]	Time 0.088 (0.090)	Data 0.002 (0.003)	Loss 9.3381 (9.3568)	Acc@1 79.688 (81.351)	Acc@5 96.875 (96.982)
[epoch:217, iter:169513] Loss: 1.108, 8.028, 50.091, 364.182, 0.664
[epoch:217, iter:169533] Loss: 1.108, 8.027, 50.083, 364.149, 0.740
[epoch:217, iter:169553] Loss: 1.107, 8.027, 50.079, 364.127, 0.608
[epoch:217, iter:169573] Loss: 1.107, 8.026, 50.067, 364.095, 0.787
[epoch:217, iter:169593] Loss: 1.107, 8.025, 50.064, 364.082, 0.957
Epoch: [216][700/782]	Time 0.092 (0.090)	Data 0.002 (0.003)	Loss 9.7879 (9.3531)	Acc@1 73.438 (81.270)	Acc@5 96.875 (96.991)
[epoch:217, iter:169613] Loss: 1.107, 8.022, 50.061, 364.069, 0.831
[epoch:217, iter:169633] Loss: 1.107, 8.023, 50.062, 364.070, 0.733
[epoch:217, iter:169653] Loss: 1.107, 8.021, 50.059, 364.035, 0.631
[epoch:217, iter:169673] Loss: 1.107, 8.022, 50.059, 364.058, 0.442
[epoch:217, iter:169693] Loss: 1.107, 8.024, 50.063, 364.074, 0.476
 * Acc@1 81.198 Acc@5 96.968
epoch 216, total time 70.55
Test: [0/313]	Time 0.274 (0.274)	Loss 1.3351 (1.3351)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2247 (1.1710)	Acc@1 65.625 (71.101)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7293 (1.1332)	Acc@1 78.125 (71.517)	Acc@5 96.875 (92.615)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4234 (1.1449)	Acc@1 62.500 (71.252)	Acc@5 93.750 (92.743)
 * Acc@1 71.370 Acc@5 92.800
saving the best model!
==> training...
Epoch: [217][0/782]	Time 0.572 (0.572)	Data 0.502 (0.502)	Loss 9.5696 (9.5696)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
[epoch:218, iter:169695] Loss: 1.155, 8.098, 50.749, 363.394, 0.615
[epoch:218, iter:169715] Loss: 1.105, 8.082, 49.997, 364.692, 1.045
[epoch:218, iter:169735] Loss: 1.102, 8.069, 49.873, 363.727, 0.828
[epoch:218, iter:169755] Loss: 1.104, 8.061, 49.864, 363.849, 0.633
[epoch:218, iter:169775] Loss: 1.102, 8.047, 50.000, 364.408, 0.634
Epoch: [217][100/782]	Time 0.074 (0.081)	Data 0.002 (0.007)	Loss 9.2826 (9.3569)	Acc@1 82.812 (80.616)	Acc@5 98.438 (96.952)
[epoch:218, iter:169795] Loss: 1.104, 8.039, 50.040, 364.733, 0.536
[epoch:218, iter:169815] Loss: 1.104, 8.040, 50.088, 364.630, 0.459
[epoch:218, iter:169835] Loss: 1.104, 8.027, 49.976, 364.019, 0.615
[epoch:218, iter:169855] Loss: 1.104, 8.026, 49.959, 363.898, 0.840
[epoch:218, iter:169875] Loss: 1.103, 8.021, 49.962, 363.915, 0.758
Epoch: [217][200/782]	Time 0.073 (0.081)	Data 0.002 (0.005)	Loss 9.2459 (9.3272)	Acc@1 79.688 (81.180)	Acc@5 93.750 (96.875)
[epoch:218, iter:169895] Loss: 1.104, 8.024, 49.989, 364.074, 0.670
[epoch:218, iter:169915] Loss: 1.104, 8.026, 50.001, 364.108, 0.402
[epoch:218, iter:169935] Loss: 1.104, 8.019, 49.995, 364.092, 0.797
[epoch:218, iter:169955] Loss: 1.104, 8.016, 50.012, 364.186, 0.512
[epoch:218, iter:169975] Loss: 1.105, 8.018, 49.997, 364.061, 0.580
Epoch: [217][300/782]	Time 0.075 (0.081)	Data 0.002 (0.004)	Loss 9.2607 (9.3304)	Acc@1 81.250 (81.146)	Acc@5 98.438 (96.984)
[epoch:218, iter:169995] Loss: 1.105, 8.015, 49.996, 363.974, 0.572
[epoch:218, iter:170015] Loss: 1.105, 8.015, 50.016, 364.085, 0.495
[epoch:218, iter:170035] Loss: 1.104, 8.012, 50.021, 364.089, 0.862
[epoch:218, iter:170055] Loss: 1.105, 8.012, 50.029, 364.150, 0.626
[epoch:218, iter:170075] Loss: 1.105, 8.012, 50.023, 364.147, 0.429
Epoch: [217][400/782]	Time 0.072 (0.080)	Data 0.002 (0.003)	Loss 9.8323 (9.3422)	Acc@1 78.125 (81.121)	Acc@5 96.875 (96.980)
[epoch:218, iter:170095] Loss: 1.105, 8.012, 50.013, 364.109, 0.605
[epoch:218, iter:170115] Loss: 1.106, 8.017, 50.028, 364.139, 0.608
[epoch:218, iter:170135] Loss: 1.105, 8.015, 50.036, 364.163, 0.640
[epoch:218, iter:170155] Loss: 1.105, 8.013, 50.024, 364.072, 0.641
[epoch:218, iter:170175] Loss: 1.105, 8.011, 50.038, 364.115, 0.730
Epoch: [217][500/782]	Time 0.070 (0.079)	Data 0.002 (0.003)	Loss 9.9041 (9.3490)	Acc@1 82.812 (81.203)	Acc@5 95.312 (96.975)
[epoch:218, iter:170195] Loss: 1.106, 8.014, 50.050, 364.167, 0.647
[epoch:218, iter:170215] Loss: 1.106, 8.015, 50.055, 364.160, 0.563
[epoch:218, iter:170235] Loss: 1.106, 8.011, 50.039, 364.094, 0.451
[epoch:218, iter:170255] Loss: 1.106, 8.014, 50.044, 364.116, 0.529
[epoch:218, iter:170275] Loss: 1.105, 8.014, 50.042, 364.086, 0.599
Epoch: [217][600/782]	Time 0.100 (0.079)	Data 0.003 (0.003)	Loss 9.4718 (9.3526)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.919)
[epoch:218, iter:170295] Loss: 1.106, 8.015, 50.053, 364.140, 0.634
[epoch:218, iter:170315] Loss: 1.106, 8.015, 50.058, 364.163, 0.721
[epoch:218, iter:170335] Loss: 1.106, 8.016, 50.061, 364.149, 0.553
[epoch:218, iter:170355] Loss: 1.106, 8.016, 50.052, 364.128, 0.642
[epoch:218, iter:170375] Loss: 1.106, 8.016, 50.054, 364.129, 0.989
Epoch: [217][700/782]	Time 0.089 (0.081)	Data 0.003 (0.003)	Loss 9.3197 (9.3593)	Acc@1 84.375 (81.165)	Acc@5 98.438 (96.953)
[epoch:218, iter:170395] Loss: 1.106, 8.018, 50.058, 364.149, 0.598
[epoch:218, iter:170415] Loss: 1.107, 8.016, 50.053, 364.135, 0.843
[epoch:218, iter:170435] Loss: 1.106, 8.016, 50.055, 364.145, 0.559
[epoch:218, iter:170455] Loss: 1.106, 8.014, 50.053, 364.110, 0.645
[epoch:218, iter:170475] Loss: 1.105, 8.013, 50.052, 364.121, 0.700
 * Acc@1 81.106 Acc@5 96.974
epoch 217, total time 63.16
Test: [0/313]	Time 0.286 (0.286)	Loss 1.3018 (1.3018)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3328 (1.1775)	Acc@1 59.375 (70.792)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7256 (1.1405)	Acc@1 78.125 (71.346)	Acc@5 100.000 (92.662)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3955 (1.1524)	Acc@1 65.625 (71.159)	Acc@5 96.875 (92.764)
 * Acc@1 71.320 Acc@5 92.820
==> training...
Epoch: [218][0/782]	Time 0.547 (0.547)	Data 0.455 (0.455)	Loss 9.3918 (9.3918)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
[epoch:219, iter:170477] Loss: 1.080, 7.870, 50.106, 362.745, 0.661
[epoch:219, iter:170497] Loss: 1.085, 8.061, 49.787, 363.219, 0.789
[epoch:219, iter:170517] Loss: 1.094, 8.023, 49.983, 363.901, 0.687
[epoch:219, iter:170537] Loss: 1.099, 8.064, 50.089, 364.611, 0.801
[epoch:219, iter:170557] Loss: 1.100, 8.056, 50.182, 364.819, 0.499
Epoch: [218][100/782]	Time 0.078 (0.083)	Data 0.002 (0.007)	Loss 9.2441 (9.3412)	Acc@1 82.812 (81.699)	Acc@5 98.438 (97.308)
[epoch:219, iter:170577] Loss: 1.101, 8.050, 50.035, 364.158, 0.486
[epoch:219, iter:170597] Loss: 1.101, 8.051, 49.972, 363.837, 0.691
[epoch:219, iter:170617] Loss: 1.102, 8.050, 49.937, 363.632, 0.537
[epoch:219, iter:170637] Loss: 1.102, 8.034, 49.909, 363.259, 0.979
[epoch:219, iter:170657] Loss: 1.104, 8.023, 49.925, 363.337, 0.747
Epoch: [218][200/782]	Time 0.087 (0.077)	Data 0.003 (0.004)	Loss 8.8885 (9.3322)	Acc@1 82.812 (81.359)	Acc@5 96.875 (96.961)
[epoch:219, iter:170677] Loss: 1.105, 8.021, 49.934, 363.422, 0.561
[epoch:219, iter:170697] Loss: 1.106, 8.024, 49.989, 363.619, 0.605
[epoch:219, iter:170717] Loss: 1.106, 8.021, 49.999, 363.577, 0.539
[epoch:219, iter:170737] Loss: 1.106, 8.026, 49.991, 363.592, 0.481
[epoch:219, iter:170757] Loss: 1.104, 8.031, 50.017, 363.807, 0.652
Epoch: [218][300/782]	Time 0.089 (0.081)	Data 0.003 (0.004)	Loss 10.2678 (9.3491)	Acc@1 78.125 (81.266)	Acc@5 92.188 (96.979)
[epoch:219, iter:170777] Loss: 1.105, 8.030, 50.026, 363.907, 0.980
[epoch:219, iter:170797] Loss: 1.105, 8.024, 50.001, 363.788, 0.514
[epoch:219, iter:170817] Loss: 1.105, 8.021, 50.014, 363.848, 0.924
[epoch:219, iter:170837] Loss: 1.104, 8.017, 49.998, 363.728, 0.633
[epoch:219, iter:170857] Loss: 1.104, 8.017, 50.000, 363.724, 0.733
Epoch: [218][400/782]	Time 0.092 (0.083)	Data 0.003 (0.003)	Loss 9.2041 (9.3514)	Acc@1 79.688 (81.063)	Acc@5 100.000 (96.961)
[epoch:219, iter:170877] Loss: 1.105, 8.020, 50.004, 363.703, 0.536
[epoch:219, iter:170897] Loss: 1.105, 8.018, 50.003, 363.683, 0.599
[epoch:219, iter:170917] Loss: 1.106, 8.016, 50.000, 363.672, 0.521
[epoch:219, iter:170937] Loss: 1.105, 8.015, 49.999, 363.704, 0.566
[epoch:219, iter:170957] Loss: 1.105, 8.016, 50.011, 363.798, 0.604
Epoch: [218][500/782]	Time 0.092 (0.085)	Data 0.002 (0.003)	Loss 9.0081 (9.3524)	Acc@1 81.250 (81.035)	Acc@5 100.000 (96.975)
[epoch:219, iter:170977] Loss: 1.105, 8.014, 50.006, 363.762, 0.689
[epoch:219, iter:170997] Loss: 1.105, 8.013, 49.996, 363.724, 0.736
[epoch:219, iter:171017] Loss: 1.105, 8.014, 50.005, 363.752, 0.638
[epoch:219, iter:171037] Loss: 1.105, 8.016, 50.013, 363.801, 0.439
[epoch:219, iter:171057] Loss: 1.106, 8.018, 50.040, 363.895, 0.426
Epoch: [218][600/782]	Time 0.071 (0.086)	Data 0.002 (0.003)	Loss 9.1113 (9.3634)	Acc@1 90.625 (80.977)	Acc@5 100.000 (96.927)
[epoch:219, iter:171077] Loss: 1.106, 8.017, 50.039, 363.906, 0.383
[epoch:219, iter:171097] Loss: 1.106, 8.018, 50.040, 363.936, 0.659
[epoch:219, iter:171117] Loss: 1.106, 8.017, 50.031, 363.851, 0.794
[epoch:219, iter:171137] Loss: 1.106, 8.018, 50.049, 363.974, 0.600
[epoch:219, iter:171157] Loss: 1.105, 8.020, 50.040, 363.954, 0.577
Epoch: [218][700/782]	Time 0.090 (0.085)	Data 0.002 (0.003)	Loss 9.3401 (9.3610)	Acc@1 85.938 (81.087)	Acc@5 95.312 (96.982)
[epoch:219, iter:171177] Loss: 1.105, 8.020, 50.043, 363.955, 0.568
[epoch:219, iter:171197] Loss: 1.106, 8.022, 50.052, 363.990, 0.418
[epoch:219, iter:171217] Loss: 1.106, 8.021, 50.050, 363.990, 0.636
[epoch:219, iter:171237] Loss: 1.106, 8.020, 50.046, 363.963, 0.560
[epoch:219, iter:171257] Loss: 1.106, 8.018, 50.053, 364.004, 0.561
 * Acc@1 81.120 Acc@5 97.018
epoch 218, total time 66.31
Test: [0/313]	Time 0.260 (0.260)	Loss 1.2742 (1.2742)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2413 (1.1697)	Acc@1 59.375 (70.854)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7158 (1.1347)	Acc@1 78.125 (71.300)	Acc@5 96.875 (92.646)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3930 (1.1458)	Acc@1 65.625 (71.127)	Acc@5 93.750 (92.805)
 * Acc@1 71.240 Acc@5 92.860
==> training...
Epoch: [219][0/782]	Time 0.554 (0.554)	Data 0.460 (0.460)	Loss 9.5456 (9.5456)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
[epoch:220, iter:171259] Loss: 1.151, 7.772, 49.902, 360.930, 0.871
[epoch:220, iter:171279] Loss: 1.099, 8.044, 50.264, 365.831, 0.780
[epoch:220, iter:171299] Loss: 1.103, 8.016, 50.067, 363.970, 0.600
[epoch:220, iter:171319] Loss: 1.106, 7.990, 49.996, 363.580, 0.500
[epoch:220, iter:171339] Loss: 1.112, 8.002, 50.035, 363.827, 0.449
Epoch: [219][100/782]	Time 0.087 (0.094)	Data 0.002 (0.007)	Loss 10.1329 (9.3400)	Acc@1 73.438 (81.173)	Acc@5 93.750 (97.092)
[epoch:220, iter:171359] Loss: 1.110, 8.012, 49.981, 363.674, 0.855
[epoch:220, iter:171379] Loss: 1.111, 8.023, 49.989, 363.666, 0.551
[epoch:220, iter:171399] Loss: 1.110, 8.024, 50.027, 363.857, 0.530
[epoch:220, iter:171419] Loss: 1.112, 8.025, 50.050, 363.938, 0.403
[epoch:220, iter:171439] Loss: 1.111, 8.022, 50.029, 363.829, 0.539
Epoch: [219][200/782]	Time 0.069 (0.090)	Data 0.002 (0.005)	Loss 10.1550 (9.3337)	Acc@1 78.125 (81.514)	Acc@5 96.875 (97.085)
[epoch:220, iter:171459] Loss: 1.110, 8.020, 50.036, 363.852, 0.848
[epoch:220, iter:171479] Loss: 1.110, 8.025, 50.039, 363.939, 0.599
[epoch:220, iter:171499] Loss: 1.108, 8.026, 49.994, 363.760, 0.686
[epoch:220, iter:171519] Loss: 1.108, 8.024, 49.999, 363.876, 0.719
[epoch:220, iter:171539] Loss: 1.107, 8.024, 50.028, 364.039, 0.454
Epoch: [219][300/782]	Time 0.081 (0.088)	Data 0.002 (0.004)	Loss 8.7689 (9.3393)	Acc@1 87.500 (81.266)	Acc@5 96.875 (97.062)
[epoch:220, iter:171559] Loss: 1.107, 8.026, 50.022, 363.985, 0.419
[epoch:220, iter:171579] Loss: 1.106, 8.025, 50.023, 364.020, 0.660
[epoch:220, iter:171599] Loss: 1.106, 8.026, 50.044, 364.121, 0.419
[epoch:220, iter:171619] Loss: 1.107, 8.029, 50.050, 364.126, 0.602
[epoch:220, iter:171639] Loss: 1.107, 8.029, 50.076, 364.236, 0.747
Epoch: [219][400/782]	Time 0.087 (0.088)	Data 0.002 (0.004)	Loss 9.3980 (9.3572)	Acc@1 75.000 (81.043)	Acc@5 95.312 (97.085)
[epoch:220, iter:171659] Loss: 1.107, 8.031, 50.073, 364.273, 0.686
[epoch:220, iter:171679] Loss: 1.107, 8.030, 50.095, 364.316, 0.619
[epoch:220, iter:171699] Loss: 1.107, 8.028, 50.089, 364.347, 0.870
[epoch:220, iter:171719] Loss: 1.107, 8.029, 50.094, 364.384, 0.601
[epoch:220, iter:171739] Loss: 1.107, 8.027, 50.093, 364.374, 1.011
Epoch: [219][500/782]	Time 0.090 (0.088)	Data 0.002 (0.003)	Loss 9.8322 (9.3609)	Acc@1 81.250 (81.044)	Acc@5 95.312 (97.031)
[epoch:220, iter:171759] Loss: 1.107, 8.026, 50.089, 364.321, 0.581
[epoch:220, iter:171779] Loss: 1.107, 8.024, 50.090, 364.319, 0.626
[epoch:220, iter:171799] Loss: 1.107, 8.023, 50.069, 364.223, 0.629
[epoch:220, iter:171819] Loss: 1.108, 8.022, 50.075, 364.228, 0.475
[epoch:220, iter:171839] Loss: 1.107, 8.020, 50.058, 364.181, 0.466
Epoch: [219][600/782]	Time 0.089 (0.088)	Data 0.002 (0.003)	Loss 9.6485 (9.3542)	Acc@1 75.000 (81.063)	Acc@5 98.438 (97.023)
[epoch:220, iter:171859] Loss: 1.107, 8.018, 50.058, 364.169, 0.742
[epoch:220, iter:171879] Loss: 1.107, 8.019, 50.046, 364.097, 0.734
[epoch:220, iter:171899] Loss: 1.106, 8.018, 50.047, 364.105, 0.603
[epoch:220, iter:171919] Loss: 1.106, 8.017, 50.036, 364.044, 0.850
[epoch:220, iter:171939] Loss: 1.106, 8.017, 50.039, 364.033, 0.647
Epoch: [219][700/782]	Time 0.080 (0.086)	Data 0.003 (0.003)	Loss 9.4435 (9.3505)	Acc@1 79.688 (81.143)	Acc@5 95.312 (97.002)
[epoch:220, iter:171959] Loss: 1.106, 8.017, 50.037, 364.026, 0.589
[epoch:220, iter:171979] Loss: 1.106, 8.017, 50.033, 364.022, 0.481
[epoch:220, iter:171999] Loss: 1.106, 8.018, 50.045, 364.060, 0.736
[epoch:220, iter:172019] Loss: 1.106, 8.018, 50.044, 364.063, 0.550
[epoch:220, iter:172039] Loss: 1.106, 8.018, 50.037, 364.022, 0.816
 * Acc@1 81.164 Acc@5 96.998
epoch 219, total time 67.72
Test: [0/313]	Time 0.320 (0.320)	Loss 1.3236 (1.3236)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2166 (1.1704)	Acc@1 62.500 (71.040)	Acc@5 96.875 (92.172)
Test: [200/313]	Time 0.009 (0.008)	Loss 0.7146 (1.1322)	Acc@1 78.125 (71.362)	Acc@5 100.000 (92.755)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4963 (1.1450)	Acc@1 62.500 (71.107)	Acc@5 96.875 (92.878)
 * Acc@1 71.250 Acc@5 92.930
==> training...
Epoch: [220][0/782]	Time 0.583 (0.583)	Data 0.517 (0.517)	Loss 9.6324 (9.6324)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
[epoch:221, iter:172041] Loss: 1.021, 8.169, 50.587, 367.800, 0.808
[epoch:221, iter:172061] Loss: 1.105, 8.040, 50.067, 364.338, 0.789
[epoch:221, iter:172081] Loss: 1.102, 8.022, 50.128, 364.456, 0.523
[epoch:221, iter:172101] Loss: 1.098, 8.012, 50.135, 364.606, 0.737
[epoch:221, iter:172121] Loss: 1.102, 8.001, 50.114, 364.312, 0.318
Epoch: [220][100/782]	Time 0.064 (0.095)	Data 0.002 (0.007)	Loss 9.6549 (9.3591)	Acc@1 78.125 (80.600)	Acc@5 93.750 (96.921)
[epoch:221, iter:172141] Loss: 1.101, 7.999, 50.109, 364.103, 0.787
[epoch:221, iter:172161] Loss: 1.102, 8.015, 50.104, 364.207, 0.757
[epoch:221, iter:172181] Loss: 1.106, 8.007, 50.177, 364.491, 0.621
[epoch:221, iter:172201] Loss: 1.104, 7.997, 50.114, 364.298, 0.385
[epoch:221, iter:172221] Loss: 1.104, 7.996, 50.062, 364.082, 0.766
Epoch: [220][200/782]	Time 0.104 (0.092)	Data 0.003 (0.005)	Loss 10.0338 (9.3391)	Acc@1 75.000 (81.180)	Acc@5 92.188 (96.968)
[epoch:221, iter:172241] Loss: 1.105, 7.998, 50.084, 364.103, 0.772
[epoch:221, iter:172261] Loss: 1.106, 8.001, 50.100, 364.279, 0.705
[epoch:221, iter:172281] Loss: 1.107, 8.008, 50.121, 364.386, 0.579
[epoch:221, iter:172301] Loss: 1.107, 8.003, 50.109, 364.338, 0.814
[epoch:221, iter:172321] Loss: 1.105, 8.002, 50.047, 364.128, 0.597
Epoch: [220][300/782]	Time 0.110 (0.096)	Data 0.003 (0.004)	Loss 9.2778 (9.3367)	Acc@1 71.875 (80.959)	Acc@5 93.750 (97.020)
[epoch:221, iter:172341] Loss: 1.106, 7.998, 50.004, 363.864, 0.879
[epoch:221, iter:172361] Loss: 1.106, 8.005, 50.047, 364.087, 0.865
[epoch:221, iter:172381] Loss: 1.107, 8.008, 50.086, 364.187, 0.546
[epoch:221, iter:172401] Loss: 1.107, 8.010, 50.074, 364.117, 0.394
[epoch:221, iter:172421] Loss: 1.107, 8.007, 50.068, 364.044, 0.602
Epoch: [220][400/782]	Time 0.089 (0.096)	Data 0.002 (0.004)	Loss 9.1923 (9.3484)	Acc@1 79.688 (80.958)	Acc@5 100.000 (96.976)
[epoch:221, iter:172441] Loss: 1.107, 8.010, 50.058, 363.962, 0.467
[epoch:221, iter:172461] Loss: 1.107, 8.011, 50.059, 364.004, 0.504
[epoch:221, iter:172481] Loss: 1.106, 8.009, 50.052, 363.989, 0.486
[epoch:221, iter:172501] Loss: 1.106, 8.009, 50.039, 363.972, 0.495
[epoch:221, iter:172521] Loss: 1.105, 8.010, 50.032, 363.944, 0.897
Epoch: [220][500/782]	Time 0.100 (0.095)	Data 0.002 (0.003)	Loss 8.9545 (9.3458)	Acc@1 81.250 (80.957)	Acc@5 98.438 (96.987)
[epoch:221, iter:172541] Loss: 1.105, 8.010, 50.027, 363.929, 0.577
[epoch:221, iter:172561] Loss: 1.105, 8.010, 50.031, 363.948, 0.689
[epoch:221, iter:172581] Loss: 1.105, 8.008, 50.025, 363.925, 0.715
[epoch:221, iter:172601] Loss: 1.105, 8.007, 50.033, 363.952, 0.593
[epoch:221, iter:172621] Loss: 1.106, 8.007, 50.045, 363.994, 0.745
Epoch: [220][600/782]	Time 0.104 (0.097)	Data 0.003 (0.003)	Loss 9.1518 (9.3475)	Acc@1 85.938 (80.935)	Acc@5 100.000 (97.023)
[epoch:221, iter:172641] Loss: 1.106, 8.008, 50.056, 364.097, 0.414
[epoch:221, iter:172661] Loss: 1.106, 8.008, 50.072, 364.137, 0.717
[epoch:221, iter:172681] Loss: 1.106, 8.006, 50.071, 364.135, 0.705
[epoch:221, iter:172701] Loss: 1.106, 8.008, 50.071, 364.151, 0.858
[epoch:221, iter:172721] Loss: 1.107, 8.009, 50.075, 364.153, 0.541
Epoch: [220][700/782]	Time 0.104 (0.097)	Data 0.002 (0.003)	Loss 10.0051 (9.3603)	Acc@1 78.125 (80.887)	Acc@5 93.750 (96.998)
[epoch:221, iter:172741] Loss: 1.107, 8.010, 50.099, 364.244, 0.767
[epoch:221, iter:172761] Loss: 1.107, 8.009, 50.100, 364.289, 0.775
[epoch:221, iter:172781] Loss: 1.107, 8.012, 50.097, 364.275, 0.422
[epoch:221, iter:172801] Loss: 1.107, 8.011, 50.088, 364.229, 0.513
[epoch:221, iter:172821] Loss: 1.107, 8.012, 50.065, 364.119, 0.543
 * Acc@1 80.986 Acc@5 97.018
epoch 220, total time 75.81
Test: [0/313]	Time 0.256 (0.256)	Loss 1.2930 (1.2930)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2875 (1.1776)	Acc@1 62.500 (70.854)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7048 (1.1387)	Acc@1 81.250 (71.471)	Acc@5 96.875 (92.584)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.4005 (1.1503)	Acc@1 62.500 (71.086)	Acc@5 96.875 (92.691)
 * Acc@1 71.200 Acc@5 92.740
==> training...
Epoch: [221][0/782]	Time 0.560 (0.560)	Data 0.481 (0.481)	Loss 9.1266 (9.1266)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
[epoch:222, iter:172823] Loss: 1.097, 8.239, 49.228, 358.969, 0.609
[epoch:222, iter:172843] Loss: 1.091, 7.918, 49.636, 361.623, 0.612
[epoch:222, iter:172863] Loss: 1.097, 7.966, 49.799, 363.129, 0.615
[epoch:222, iter:172883] Loss: 1.104, 7.970, 49.999, 363.873, 0.739
[epoch:222, iter:172903] Loss: 1.107, 7.980, 50.013, 363.565, 0.512
Epoch: [221][100/782]	Time 0.088 (0.100)	Data 0.002 (0.007)	Loss 9.0665 (9.3277)	Acc@1 81.250 (80.879)	Acc@5 95.312 (97.169)
[epoch:222, iter:172923] Loss: 1.107, 7.990, 49.992, 363.477, 0.703
[epoch:222, iter:172943] Loss: 1.107, 7.987, 49.943, 363.400, 1.048
[epoch:222, iter:172963] Loss: 1.110, 8.004, 50.012, 363.613, 0.733
[epoch:222, iter:172983] Loss: 1.108, 7.998, 49.957, 363.351, 0.598
[epoch:222, iter:173003] Loss: 1.109, 7.996, 49.979, 363.343, 0.457
Epoch: [221][200/782]	Time 0.108 (0.098)	Data 0.003 (0.005)	Loss 9.4619 (9.3189)	Acc@1 73.438 (80.978)	Acc@5 93.750 (97.201)
[epoch:222, iter:173023] Loss: 1.108, 8.001, 49.983, 363.418, 0.970
[epoch:222, iter:173043] Loss: 1.108, 8.006, 49.993, 363.390, 0.630
[epoch:222, iter:173063] Loss: 1.109, 8.004, 50.078, 363.767, 0.867
[epoch:222, iter:173083] Loss: 1.109, 8.007, 50.050, 363.609, 0.478
[epoch:222, iter:173103] Loss: 1.109, 8.008, 50.054, 363.652, 0.455
Epoch: [221][300/782]	Time 0.092 (0.097)	Data 0.003 (0.004)	Loss 9.7795 (9.3424)	Acc@1 75.000 (80.866)	Acc@5 95.312 (97.103)
[epoch:222, iter:173123] Loss: 1.108, 8.010, 50.044, 363.615, 0.758
[epoch:222, iter:173143] Loss: 1.108, 8.009, 50.043, 363.666, 0.665
[epoch:222, iter:173163] Loss: 1.107, 8.012, 50.050, 363.819, 0.518
[epoch:222, iter:173183] Loss: 1.106, 8.013, 50.037, 363.821, 0.546
[epoch:222, iter:173203] Loss: 1.106, 8.014, 50.060, 364.013, 0.707
Epoch: [221][400/782]	Time 0.093 (0.096)	Data 0.002 (0.004)	Loss 8.5699 (9.3554)	Acc@1 89.062 (80.911)	Acc@5 96.875 (96.988)
[epoch:222, iter:173223] Loss: 1.105, 8.011, 50.048, 363.976, 0.450
[epoch:222, iter:173243] Loss: 1.105, 8.006, 50.029, 363.885, 0.366
[epoch:222, iter:173263] Loss: 1.105, 8.012, 50.056, 364.025, 0.575
[epoch:222, iter:173283] Loss: 1.105, 8.010, 50.049, 363.971, 0.716
[epoch:222, iter:173303] Loss: 1.105, 8.007, 50.048, 363.995, 0.858
Epoch: [221][500/782]	Time 0.098 (0.095)	Data 0.003 (0.003)	Loss 9.5610 (9.3592)	Acc@1 75.000 (80.894)	Acc@5 93.750 (96.969)
[epoch:222, iter:173323] Loss: 1.105, 8.009, 50.049, 364.021, 0.687
[epoch:222, iter:173343] Loss: 1.105, 8.011, 50.050, 364.034, 0.392
[epoch:222, iter:173363] Loss: 1.105, 8.010, 50.046, 364.021, 0.721
[epoch:222, iter:173383] Loss: 1.105, 8.008, 50.049, 364.077, 0.665
[epoch:222, iter:173403] Loss: 1.105, 8.006, 50.054, 364.095, 0.579
Epoch: [221][600/782]	Time 0.089 (0.094)	Data 0.002 (0.003)	Loss 9.3690 (9.3600)	Acc@1 85.938 (81.003)	Acc@5 96.875 (96.969)
[epoch:222, iter:173423] Loss: 1.105, 8.007, 50.067, 364.133, 0.640
[epoch:222, iter:173443] Loss: 1.105, 8.011, 50.078, 364.214, 0.828
[epoch:222, iter:173463] Loss: 1.105, 8.012, 50.064, 364.149, 0.678
[epoch:222, iter:173483] Loss: 1.105, 8.013, 50.075, 364.211, 0.834
[epoch:222, iter:173503] Loss: 1.105, 8.012, 50.055, 364.129, 0.745
Epoch: [221][700/782]	Time 0.077 (0.091)	Data 0.002 (0.003)	Loss 9.1841 (9.3601)	Acc@1 79.688 (80.998)	Acc@5 96.875 (96.951)
[epoch:222, iter:173523] Loss: 1.105, 8.013, 50.051, 364.087, 0.494
[epoch:222, iter:173543] Loss: 1.105, 8.014, 50.058, 364.142, 0.595
[epoch:222, iter:173563] Loss: 1.105, 8.016, 50.055, 364.117, 0.571
[epoch:222, iter:173583] Loss: 1.105, 8.015, 50.056, 364.108, 0.447
[epoch:222, iter:173603] Loss: 1.105, 8.015, 50.051, 364.070, 0.719
 * Acc@1 80.974 Acc@5 96.944
epoch 221, total time 70.50
Test: [0/313]	Time 0.251 (0.251)	Loss 1.3415 (1.3415)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2620 (1.1804)	Acc@1 62.500 (70.699)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.010 (0.009)	Loss 0.7261 (1.1445)	Acc@1 78.125 (71.222)	Acc@5 96.875 (92.600)
Test: [300/313]	Time 0.010 (0.009)	Loss 1.4316 (1.1554)	Acc@1 62.500 (70.972)	Acc@5 93.750 (92.660)
 * Acc@1 71.060 Acc@5 92.720
==> training...
Epoch: [222][0/782]	Time 0.591 (0.591)	Data 0.495 (0.495)	Loss 9.5295 (9.5295)	Acc@1 76.562 (76.562)	Acc@5 95.312 (95.312)
[epoch:223, iter:173605] Loss: 1.074, 7.956, 50.762, 370.693, 0.800
[epoch:223, iter:173625] Loss: 1.103, 7.978, 49.559, 361.500, 0.662
[epoch:223, iter:173645] Loss: 1.108, 8.000, 49.856, 362.597, 0.869
[epoch:223, iter:173665] Loss: 1.106, 8.034, 49.981, 363.385, 0.736
[epoch:223, iter:173685] Loss: 1.106, 8.044, 50.025, 363.599, 0.612
Epoch: [222][100/782]	Time 0.091 (0.096)	Data 0.003 (0.007)	Loss 9.5450 (9.3445)	Acc@1 78.125 (80.941)	Acc@5 95.312 (97.030)
[epoch:223, iter:173705] Loss: 1.103, 8.027, 50.022, 363.778, 0.723
[epoch:223, iter:173725] Loss: 1.104, 8.019, 50.008, 363.791, 0.512
[epoch:223, iter:173745] Loss: 1.104, 8.020, 49.990, 363.682, 0.438
[epoch:223, iter:173765] Loss: 1.107, 8.034, 50.093, 364.141, 0.445
[epoch:223, iter:173785] Loss: 1.106, 8.030, 50.053, 363.999, 0.422
Epoch: [222][200/782]	Time 0.094 (0.092)	Data 0.003 (0.005)	Loss 9.9107 (9.3313)	Acc@1 82.812 (81.087)	Acc@5 90.625 (97.194)
[epoch:223, iter:173805] Loss: 1.106, 8.032, 50.049, 364.002, 0.827
[epoch:223, iter:173825] Loss: 1.107, 8.034, 50.085, 364.202, 0.776
[epoch:223, iter:173845] Loss: 1.106, 8.034, 50.076, 364.190, 0.413
[epoch:223, iter:173865] Loss: 1.106, 8.035, 50.055, 364.218, 0.569
[epoch:223, iter:173885] Loss: 1.105, 8.033, 50.059, 364.196, 0.692
Epoch: [222][300/782]	Time 0.091 (0.091)	Data 0.002 (0.004)	Loss 9.5261 (9.3324)	Acc@1 82.812 (81.395)	Acc@5 96.875 (97.264)
[epoch:223, iter:173905] Loss: 1.106, 8.038, 50.050, 364.162, 0.582
[epoch:223, iter:173925] Loss: 1.105, 8.034, 50.039, 364.127, 0.607
[epoch:223, iter:173945] Loss: 1.105, 8.036, 50.023, 364.074, 0.644
[epoch:223, iter:173965] Loss: 1.105, 8.035, 49.998, 363.936, 0.568
[epoch:223, iter:173985] Loss: 1.104, 8.034, 49.987, 363.844, 0.611
Epoch: [222][400/782]	Time 0.091 (0.091)	Data 0.002 (0.004)	Loss 9.4567 (9.3332)	Acc@1 75.000 (81.164)	Acc@5 93.750 (97.128)
[epoch:223, iter:174005] Loss: 1.105, 8.031, 49.995, 363.853, 0.896
[epoch:223, iter:174025] Loss: 1.106, 8.030, 50.008, 363.879, 0.536
[epoch:223, iter:174045] Loss: 1.106, 8.028, 49.991, 363.784, 0.533
[epoch:223, iter:174065] Loss: 1.106, 8.024, 49.991, 363.778, 0.872
[epoch:223, iter:174085] Loss: 1.106, 8.020, 49.978, 363.682, 0.630
Epoch: [222][500/782]	Time 0.075 (0.090)	Data 0.002 (0.003)	Loss 9.2632 (9.3365)	Acc@1 81.250 (81.141)	Acc@5 98.438 (97.078)
[epoch:223, iter:174105] Loss: 1.106, 8.021, 50.000, 363.833, 0.498
[epoch:223, iter:174125] Loss: 1.106, 8.016, 49.990, 363.811, 0.446
[epoch:223, iter:174145] Loss: 1.106, 8.017, 50.003, 363.849, 0.662
[epoch:223, iter:174165] Loss: 1.107, 8.016, 50.014, 363.846, 0.801
[epoch:223, iter:174185] Loss: 1.107, 8.016, 50.014, 363.838, 0.937
Epoch: [222][600/782]	Time 0.074 (0.090)	Data 0.002 (0.003)	Loss 9.9588 (9.3420)	Acc@1 75.000 (81.110)	Acc@5 92.188 (97.080)
[epoch:223, iter:174205] Loss: 1.106, 8.020, 50.011, 363.864, 0.881
[epoch:223, iter:174225] Loss: 1.107, 8.018, 50.019, 363.864, 1.016
[epoch:223, iter:174245] Loss: 1.106, 8.022, 50.031, 363.961, 0.711
[epoch:223, iter:174265] Loss: 1.107, 8.023, 50.039, 364.024, 0.787
[epoch:223, iter:174285] Loss: 1.107, 8.022, 50.048, 364.051, 0.631
Epoch: [222][700/782]	Time 0.084 (0.091)	Data 0.002 (0.003)	Loss 8.8872 (9.3564)	Acc@1 84.375 (80.985)	Acc@5 100.000 (97.071)
[epoch:223, iter:174305] Loss: 1.107, 8.023, 50.051, 364.090, 0.436
[epoch:223, iter:174325] Loss: 1.107, 8.024, 50.039, 364.038, 0.690
[epoch:223, iter:174345] Loss: 1.107, 8.024, 50.029, 363.996, 0.629
[epoch:223, iter:174365] Loss: 1.106, 8.023, 50.026, 363.986, 0.583
[epoch:223, iter:174385] Loss: 1.106, 8.022, 50.021, 363.942, 0.482
 * Acc@1 80.998 Acc@5 97.078
epoch 222, total time 69.97
Test: [0/313]	Time 0.259 (0.259)	Loss 1.3825 (1.3825)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2616 (1.1728)	Acc@1 59.375 (70.823)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7462 (1.1386)	Acc@1 78.125 (71.502)	Acc@5 96.875 (92.631)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3139 (1.1486)	Acc@1 62.500 (71.252)	Acc@5 93.750 (92.712)
 * Acc@1 71.390 Acc@5 92.750
saving the best model!
==> training...
Epoch: [223][0/782]	Time 0.612 (0.612)	Data 0.523 (0.523)	Loss 9.5513 (9.5513)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
[epoch:224, iter:174387] Loss: 1.091, 8.399, 49.413, 360.566, 0.862
[epoch:224, iter:174407] Loss: 1.110, 8.003, 49.851, 361.463, 0.496
[epoch:224, iter:174427] Loss: 1.111, 8.053, 49.990, 362.987, 0.860
[epoch:224, iter:174447] Loss: 1.108, 8.058, 49.935, 362.964, 0.840
[epoch:224, iter:174467] Loss: 1.102, 8.040, 49.851, 362.925, 0.771
Epoch: [223][100/782]	Time 0.094 (0.091)	Data 0.003 (0.008)	Loss 8.9255 (9.3100)	Acc@1 82.812 (81.126)	Acc@5 98.438 (97.231)
[epoch:224, iter:174487] Loss: 1.105, 8.051, 49.890, 363.003, 0.549
[epoch:224, iter:174507] Loss: 1.103, 8.043, 49.870, 363.005, 0.603
[epoch:224, iter:174527] Loss: 1.103, 8.035, 49.891, 363.214, 0.414
[epoch:224, iter:174547] Loss: 1.103, 8.034, 49.906, 363.267, 0.605
[epoch:224, iter:174567] Loss: 1.104, 8.029, 49.946, 363.396, 0.900
Epoch: [223][200/782]	Time 0.090 (0.090)	Data 0.002 (0.005)	Loss 9.0342 (9.3236)	Acc@1 87.500 (81.157)	Acc@5 98.438 (97.233)
[epoch:224, iter:174587] Loss: 1.103, 8.037, 49.929, 363.283, 0.363
[epoch:224, iter:174607] Loss: 1.104, 8.031, 49.896, 363.119, 0.508
[epoch:224, iter:174627] Loss: 1.104, 8.033, 49.909, 363.265, 0.569
[epoch:224, iter:174647] Loss: 1.104, 8.034, 49.905, 363.214, 0.537
[epoch:224, iter:174667] Loss: 1.103, 8.032, 49.891, 363.158, 0.574
Epoch: [223][300/782]	Time 0.083 (0.090)	Data 0.003 (0.004)	Loss 9.7353 (9.3208)	Acc@1 73.438 (81.120)	Acc@5 92.188 (97.150)
[epoch:224, iter:174687] Loss: 1.103, 8.029, 49.907, 363.216, 1.039
[epoch:224, iter:174707] Loss: 1.103, 8.026, 49.889, 363.171, 0.667
[epoch:224, iter:174727] Loss: 1.104, 8.028, 49.898, 363.212, 0.418
[epoch:224, iter:174747] Loss: 1.104, 8.028, 49.903, 363.243, 0.400
[epoch:224, iter:174767] Loss: 1.104, 8.032, 49.934, 363.393, 0.515
Epoch: [223][400/782]	Time 0.094 (0.091)	Data 0.003 (0.004)	Loss 9.5421 (9.3347)	Acc@1 84.375 (80.966)	Acc@5 98.438 (97.132)
[epoch:224, iter:174787] Loss: 1.103, 8.033, 49.929, 363.359, 0.533
[epoch:224, iter:174807] Loss: 1.103, 8.032, 49.934, 363.406, 0.579
[epoch:224, iter:174827] Loss: 1.103, 8.030, 49.942, 363.452, 0.754
[epoch:224, iter:174847] Loss: 1.103, 8.028, 49.938, 363.417, 0.624
[epoch:224, iter:174867] Loss: 1.104, 8.026, 49.951, 363.453, 0.464
Epoch: [223][500/782]	Time 0.094 (0.091)	Data 0.003 (0.004)	Loss 9.8160 (9.3340)	Acc@1 76.562 (81.156)	Acc@5 98.438 (97.146)
[epoch:224, iter:174887] Loss: 1.103, 8.026, 49.950, 363.468, 0.755
[epoch:224, iter:174907] Loss: 1.103, 8.026, 49.963, 363.524, 0.467
[epoch:224, iter:174927] Loss: 1.103, 8.024, 49.957, 363.499, 0.439
[epoch:224, iter:174947] Loss: 1.104, 8.024, 49.945, 363.440, 0.377
[epoch:224, iter:174967] Loss: 1.104, 8.023, 49.957, 363.480, 0.679
Epoch: [223][600/782]	Time 0.087 (0.091)	Data 0.002 (0.003)	Loss 9.2118 (9.3306)	Acc@1 87.500 (81.211)	Acc@5 98.438 (97.171)
[epoch:224, iter:174987] Loss: 1.104, 8.024, 49.954, 363.502, 0.452
[epoch:224, iter:175007] Loss: 1.105, 8.024, 49.966, 363.525, 0.887
[epoch:224, iter:175027] Loss: 1.105, 8.027, 49.969, 363.548, 0.691
[epoch:224, iter:175047] Loss: 1.105, 8.028, 49.976, 363.598, 0.751
[epoch:224, iter:175067] Loss: 1.105, 8.029, 49.981, 363.654, 0.544
Epoch: [223][700/782]	Time 0.093 (0.091)	Data 0.002 (0.003)	Loss 9.2178 (9.3376)	Acc@1 84.375 (81.145)	Acc@5 96.875 (97.118)
[epoch:224, iter:175087] Loss: 1.105, 8.027, 49.970, 363.630, 0.650
[epoch:224, iter:175107] Loss: 1.105, 8.027, 49.978, 363.674, 1.042
[epoch:224, iter:175127] Loss: 1.105, 8.028, 49.985, 363.724, 0.781
[epoch:224, iter:175147] Loss: 1.105, 8.026, 49.992, 363.753, 0.866
[epoch:224, iter:175167] Loss: 1.105, 8.026, 49.990, 363.744, 0.622
 * Acc@1 81.090 Acc@5 97.076
epoch 223, total time 71.16
Test: [0/313]	Time 0.273 (0.273)	Loss 1.3035 (1.3035)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.009)	Loss 1.2622 (1.1758)	Acc@1 59.375 (70.421)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7801 (1.1354)	Acc@1 68.750 (71.035)	Acc@5 100.000 (92.693)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4461 (1.1459)	Acc@1 62.500 (70.993)	Acc@5 93.750 (92.774)
 * Acc@1 71.110 Acc@5 92.830
==> training...
Epoch: [224][0/782]	Time 0.536 (0.536)	Data 0.454 (0.454)	Loss 9.3287 (9.3287)	Acc@1 84.375 (84.375)	Acc@5 95.312 (95.312)
[epoch:225, iter:175169] Loss: 1.067, 8.098, 50.066, 366.225, 0.650
[epoch:225, iter:175189] Loss: 1.107, 7.965, 50.056, 363.308, 0.763
[epoch:225, iter:175209] Loss: 1.110, 7.975, 50.214, 363.929, 0.670
[epoch:225, iter:175229] Loss: 1.108, 8.003, 50.052, 363.794, 0.551
[epoch:225, iter:175249] Loss: 1.108, 8.015, 50.035, 363.554, 0.835
Epoch: [224][100/782]	Time 0.090 (0.092)	Data 0.003 (0.007)	Loss 8.5673 (9.3357)	Acc@1 92.188 (81.080)	Acc@5 100.000 (97.061)
[epoch:225, iter:175269] Loss: 1.109, 8.012, 50.031, 363.473, 0.215
[epoch:225, iter:175289] Loss: 1.111, 8.008, 50.103, 363.577, 0.706
[epoch:225, iter:175309] Loss: 1.111, 8.006, 50.068, 363.552, 0.589
[epoch:225, iter:175329] Loss: 1.109, 8.007, 50.070, 363.681, 0.714
[epoch:225, iter:175349] Loss: 1.108, 8.009, 50.070, 363.742, 0.590
Epoch: [224][200/782]	Time 0.101 (0.095)	Data 0.002 (0.005)	Loss 9.5330 (9.3455)	Acc@1 75.000 (80.854)	Acc@5 95.312 (97.124)
[epoch:225, iter:175369] Loss: 1.109, 8.011, 50.066, 363.535, 0.831
[epoch:225, iter:175389] Loss: 1.108, 8.014, 50.083, 363.785, 0.447
[epoch:225, iter:175409] Loss: 1.110, 8.012, 50.093, 363.754, 0.457
[epoch:225, iter:175429] Loss: 1.108, 8.012, 50.065, 363.737, 0.452
[epoch:225, iter:175449] Loss: 1.107, 8.015, 50.047, 363.710, 0.478
Epoch: [224][300/782]	Time 0.108 (0.094)	Data 0.003 (0.004)	Loss 9.2274 (9.3447)	Acc@1 76.562 (80.897)	Acc@5 100.000 (97.171)
[epoch:225, iter:175469] Loss: 1.107, 8.010, 50.057, 363.814, 0.559
[epoch:225, iter:175489] Loss: 1.107, 8.008, 50.012, 363.549, 0.407
[epoch:225, iter:175509] Loss: 1.107, 8.008, 50.034, 363.680, 0.515
[epoch:225, iter:175529] Loss: 1.107, 8.005, 50.039, 363.709, 0.542
[epoch:225, iter:175549] Loss: 1.107, 8.012, 50.031, 363.718, 0.590
Epoch: [224][400/782]	Time 0.088 (0.096)	Data 0.002 (0.004)	Loss 9.3087 (9.3459)	Acc@1 84.375 (80.895)	Acc@5 93.750 (97.128)
[epoch:225, iter:175569] Loss: 1.106, 8.014, 50.046, 363.848, 0.574
[epoch:225, iter:175589] Loss: 1.106, 8.017, 50.045, 363.913, 0.574
[epoch:225, iter:175609] Loss: 1.107, 8.013, 50.022, 363.786, 0.398
[epoch:225, iter:175629] Loss: 1.107, 8.013, 50.028, 363.842, 0.541
[epoch:225, iter:175649] Loss: 1.106, 8.016, 50.031, 363.905, 0.620
Epoch: [224][500/782]	Time 0.094 (0.094)	Data 0.003 (0.003)	Loss 9.3449 (9.3348)	Acc@1 75.000 (81.091)	Acc@5 96.875 (97.165)
[epoch:225, iter:175669] Loss: 1.106, 8.014, 50.031, 363.878, 0.670
[epoch:225, iter:175689] Loss: 1.105, 8.016, 50.020, 363.895, 0.525
[epoch:225, iter:175709] Loss: 1.106, 8.015, 50.028, 363.897, 0.709
[epoch:225, iter:175729] Loss: 1.106, 8.016, 50.030, 363.883, 0.628
[epoch:225, iter:175749] Loss: 1.105, 8.018, 50.029, 363.917, 0.840
Epoch: [224][600/782]	Time 0.094 (0.094)	Data 0.003 (0.003)	Loss 9.4574 (9.3416)	Acc@1 82.812 (81.000)	Acc@5 93.750 (97.112)
[epoch:225, iter:175769] Loss: 1.106, 8.018, 50.021, 363.868, 0.692
[epoch:225, iter:175789] Loss: 1.105, 8.016, 50.002, 363.769, 0.716
[epoch:225, iter:175809] Loss: 1.106, 8.016, 50.008, 363.792, 0.676
[epoch:225, iter:175829] Loss: 1.105, 8.015, 50.006, 363.793, 0.653
[epoch:225, iter:175849] Loss: 1.105, 8.013, 50.005, 363.786, 0.555
Epoch: [224][700/782]	Time 0.122 (0.094)	Data 0.027 (0.003)	Loss 9.4097 (9.3322)	Acc@1 90.625 (81.143)	Acc@5 98.438 (97.087)
[epoch:225, iter:175869] Loss: 1.104, 8.014, 50.000, 363.782, 0.383
[epoch:225, iter:175889] Loss: 1.105, 8.013, 50.017, 363.835, 0.534
[epoch:225, iter:175909] Loss: 1.105, 8.012, 50.008, 363.803, 0.501
[epoch:225, iter:175929] Loss: 1.105, 8.012, 50.009, 363.827, 0.698
[epoch:225, iter:175949] Loss: 1.105, 8.012, 49.999, 363.811, 0.632
 * Acc@1 81.136 Acc@5 97.040
epoch 224, total time 73.85
Test: [0/313]	Time 0.278 (0.278)	Loss 1.2911 (1.2911)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2224 (1.1763)	Acc@1 62.500 (70.637)	Acc@5 96.875 (92.141)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7308 (1.1357)	Acc@1 78.125 (71.486)	Acc@5 96.875 (92.646)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.5229 (1.1487)	Acc@1 62.500 (71.096)	Acc@5 93.750 (92.774)
 * Acc@1 71.210 Acc@5 92.820
==> training...
Epoch: [225][0/782]	Time 0.573 (0.573)	Data 0.484 (0.484)	Loss 9.4866 (9.4866)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
[epoch:226, iter:175951] Loss: 1.082, 8.158, 51.370, 374.712, 0.560
[epoch:226, iter:175971] Loss: 1.090, 7.987, 49.843, 363.781, 0.505
[epoch:226, iter:175991] Loss: 1.099, 8.024, 50.097, 365.136, 0.420
[epoch:226, iter:176011] Loss: 1.108, 8.021, 50.334, 365.292, 0.658
[epoch:226, iter:176031] Loss: 1.102, 8.010, 50.160, 364.340, 0.820
Epoch: [225][100/782]	Time 0.098 (0.096)	Data 0.002 (0.007)	Loss 9.5856 (9.3721)	Acc@1 78.125 (80.724)	Acc@5 93.750 (96.921)
[epoch:226, iter:176051] Loss: 1.104, 8.002, 50.132, 364.127, 0.743
[epoch:226, iter:176071] Loss: 1.106, 8.000, 50.198, 364.335, 0.588
[epoch:226, iter:176091] Loss: 1.106, 7.988, 50.156, 364.174, 0.503
[epoch:226, iter:176111] Loss: 1.107, 7.993, 50.128, 364.048, 0.541
[epoch:226, iter:176131] Loss: 1.106, 7.991, 50.113, 363.960, 0.801
Epoch: [225][200/782]	Time 0.092 (0.094)	Data 0.003 (0.005)	Loss 8.7630 (9.3533)	Acc@1 87.500 (81.149)	Acc@5 100.000 (97.069)
[epoch:226, iter:176151] Loss: 1.106, 7.994, 50.127, 364.093, 0.342
[epoch:226, iter:176171] Loss: 1.106, 7.996, 50.095, 364.057, 0.662
[epoch:226, iter:176191] Loss: 1.106, 7.996, 50.058, 363.906, 0.324
[epoch:226, iter:176211] Loss: 1.106, 8.001, 50.046, 363.924, 0.334
[epoch:226, iter:176231] Loss: 1.105, 8.006, 50.018, 363.935, 0.598
Epoch: [225][300/782]	Time 0.084 (0.094)	Data 0.002 (0.004)	Loss 9.3933 (9.3258)	Acc@1 87.500 (81.421)	Acc@5 96.875 (97.046)
[epoch:226, iter:176251] Loss: 1.105, 8.007, 50.004, 363.853, 0.489
[epoch:226, iter:176271] Loss: 1.105, 8.008, 49.999, 363.866, 0.747
[epoch:226, iter:176291] Loss: 1.106, 8.010, 50.031, 364.011, 0.535
[epoch:226, iter:176311] Loss: 1.105, 8.011, 50.026, 363.956, 0.721
[epoch:226, iter:176331] Loss: 1.105, 8.012, 50.020, 363.904, 0.589
Epoch: [225][400/782]	Time 0.078 (0.089)	Data 0.002 (0.004)	Loss 9.6555 (9.3384)	Acc@1 78.125 (81.133)	Acc@5 93.750 (96.945)
[epoch:226, iter:176351] Loss: 1.106, 8.011, 50.020, 363.926, 0.821
[epoch:226, iter:176371] Loss: 1.105, 8.010, 50.030, 363.950, 0.756
[epoch:226, iter:176391] Loss: 1.106, 8.007, 50.018, 363.841, 0.773
[epoch:226, iter:176411] Loss: 1.105, 8.008, 50.005, 363.822, 0.604
[epoch:226, iter:176431] Loss: 1.105, 8.007, 49.994, 363.728, 0.454
Epoch: [225][500/782]	Time 0.065 (0.086)	Data 0.002 (0.003)	Loss 9.3753 (9.3306)	Acc@1 78.125 (81.135)	Acc@5 96.875 (97.040)
[epoch:226, iter:176451] Loss: 1.105, 8.006, 49.999, 363.743, 0.758
[epoch:226, iter:176471] Loss: 1.105, 8.005, 50.022, 363.851, 0.463
[epoch:226, iter:176491] Loss: 1.105, 8.006, 50.018, 363.822, 0.745
[epoch:226, iter:176511] Loss: 1.104, 8.006, 50.037, 363.942, 0.585
[epoch:226, iter:176531] Loss: 1.104, 8.004, 50.015, 363.814, 0.528
Epoch: [225][600/782]	Time 0.080 (0.084)	Data 0.003 (0.003)	Loss 9.0672 (9.3407)	Acc@1 87.500 (80.964)	Acc@5 98.438 (97.034)
[epoch:226, iter:176551] Loss: 1.105, 8.003, 50.017, 363.812, 0.526
[epoch:226, iter:176571] Loss: 1.104, 8.004, 50.010, 363.818, 0.614
[epoch:226, iter:176591] Loss: 1.103, 8.006, 50.005, 363.822, 0.596
[epoch:226, iter:176611] Loss: 1.104, 8.008, 50.012, 363.838, 0.926
[epoch:226, iter:176631] Loss: 1.104, 8.007, 50.000, 363.784, 0.657
Epoch: [225][700/782]	Time 0.103 (0.085)	Data 0.002 (0.003)	Loss 10.0146 (9.3454)	Acc@1 75.000 (80.940)	Acc@5 96.875 (97.024)
[epoch:226, iter:176651] Loss: 1.103, 8.007, 50.011, 363.866, 0.704
[epoch:226, iter:176671] Loss: 1.104, 8.009, 50.013, 363.836, 0.637
[epoch:226, iter:176691] Loss: 1.104, 8.009, 50.018, 363.841, 0.883
[epoch:226, iter:176711] Loss: 1.104, 8.008, 50.034, 363.916, 0.355
[epoch:226, iter:176731] Loss: 1.104, 8.008, 50.040, 363.950, 0.664
 * Acc@1 81.024 Acc@5 97.028
epoch 225, total time 68.22
Test: [0/313]	Time 0.313 (0.313)	Loss 1.2444 (1.2444)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2866 (1.1662)	Acc@1 59.375 (70.978)	Acc@5 96.875 (92.234)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7179 (1.1330)	Acc@1 78.125 (71.269)	Acc@5 100.000 (92.615)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4263 (1.1450)	Acc@1 62.500 (71.065)	Acc@5 93.750 (92.733)
 * Acc@1 71.200 Acc@5 92.780
==> training...
Epoch: [226][0/782]	Time 0.574 (0.574)	Data 0.487 (0.487)	Loss 9.2668 (9.2668)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
[epoch:227, iter:176733] Loss: 1.106, 8.398, 49.269, 362.834, 0.594
[epoch:227, iter:176753] Loss: 1.105, 8.030, 50.113, 364.763, 0.643
[epoch:227, iter:176773] Loss: 1.103, 7.983, 50.003, 363.925, 0.715
[epoch:227, iter:176793] Loss: 1.102, 8.005, 49.997, 363.932, 0.864
[epoch:227, iter:176813] Loss: 1.105, 8.019, 50.055, 364.237, 0.795
Epoch: [226][100/782]	Time 0.093 (0.096)	Data 0.003 (0.007)	Loss 8.8469 (9.3861)	Acc@1 82.812 (80.012)	Acc@5 100.000 (96.829)
[epoch:227, iter:176833] Loss: 1.103, 8.001, 50.028, 364.098, 0.395
[epoch:227, iter:176853] Loss: 1.100, 8.007, 49.965, 363.906, 0.573
[epoch:227, iter:176873] Loss: 1.103, 8.010, 50.013, 364.083, 0.767
[epoch:227, iter:176893] Loss: 1.101, 7.994, 49.955, 363.767, 0.397
[epoch:227, iter:176913] Loss: 1.100, 8.000, 49.962, 363.909, 0.747
Epoch: [226][200/782]	Time 0.109 (0.097)	Data 0.003 (0.005)	Loss 9.3135 (9.3314)	Acc@1 84.375 (80.962)	Acc@5 96.875 (97.062)
[epoch:227, iter:176933] Loss: 1.099, 7.999, 49.933, 363.731, 0.503
[epoch:227, iter:176953] Loss: 1.099, 8.010, 49.939, 363.712, 0.505
[epoch:227, iter:176973] Loss: 1.100, 8.006, 49.981, 363.840, 0.546
[epoch:227, iter:176993] Loss: 1.099, 8.006, 49.974, 363.900, 0.598
[epoch:227, iter:177013] Loss: 1.100, 8.009, 50.017, 364.067, 0.374
Epoch: [226][300/782]	Time 0.074 (0.100)	Data 0.002 (0.004)	Loss 9.0505 (9.3465)	Acc@1 81.250 (81.074)	Acc@5 100.000 (96.911)
[epoch:227, iter:177033] Loss: 1.100, 8.008, 49.997, 363.927, 0.550
[epoch:227, iter:177053] Loss: 1.101, 8.002, 49.975, 363.777, 0.783
[epoch:227, iter:177073] Loss: 1.102, 8.005, 49.977, 363.822, 0.885
[epoch:227, iter:177093] Loss: 1.102, 8.012, 49.989, 363.847, 1.095
[epoch:227, iter:177113] Loss: 1.102, 8.014, 50.003, 363.886, 0.753
Epoch: [226][400/782]	Time 0.088 (0.099)	Data 0.003 (0.004)	Loss 9.2887 (9.3470)	Acc@1 82.812 (81.180)	Acc@5 95.312 (96.883)
[epoch:227, iter:177133] Loss: 1.103, 8.013, 50.016, 363.871, 0.640
[epoch:227, iter:177153] Loss: 1.103, 8.013, 50.023, 363.873, 0.616
[epoch:227, iter:177173] Loss: 1.104, 8.017, 50.039, 363.964, 0.815
[epoch:227, iter:177193] Loss: 1.104, 8.017, 50.053, 364.010, 0.552
[epoch:227, iter:177213] Loss: 1.104, 8.015, 50.053, 364.012, 0.488
Epoch: [226][500/782]	Time 0.096 (0.098)	Data 0.003 (0.004)	Loss 9.4041 (9.3559)	Acc@1 81.250 (81.050)	Acc@5 93.750 (96.897)
[epoch:227, iter:177233] Loss: 1.104, 8.013, 50.046, 363.949, 0.737
[epoch:227, iter:177253] Loss: 1.104, 8.009, 50.028, 363.880, 0.422
[epoch:227, iter:177273] Loss: 1.104, 8.008, 50.016, 363.843, 0.454
[epoch:227, iter:177293] Loss: 1.105, 8.006, 50.009, 363.770, 0.623
[epoch:227, iter:177313] Loss: 1.104, 8.007, 50.007, 363.774, 0.514
Epoch: [226][600/782]	Time 0.095 (0.096)	Data 0.003 (0.003)	Loss 9.4511 (9.3397)	Acc@1 79.688 (81.146)	Acc@5 98.438 (96.958)
[epoch:227, iter:177333] Loss: 1.103, 8.007, 49.990, 363.714, 0.601
[epoch:227, iter:177353] Loss: 1.103, 8.006, 50.003, 363.765, 0.581
[epoch:227, iter:177373] Loss: 1.104, 8.008, 50.010, 363.777, 0.655
[epoch:227, iter:177393] Loss: 1.103, 8.010, 49.999, 363.737, 0.568
[epoch:227, iter:177413] Loss: 1.103, 8.009, 50.003, 363.742, 0.605
Epoch: [226][700/782]	Time 0.088 (0.096)	Data 0.002 (0.003)	Loss 9.3077 (9.3424)	Acc@1 82.812 (81.127)	Acc@5 98.438 (96.953)
[epoch:227, iter:177433] Loss: 1.103, 8.007, 50.002, 363.737, 0.493
[epoch:227, iter:177453] Loss: 1.103, 8.006, 49.990, 363.710, 0.857
[epoch:227, iter:177473] Loss: 1.103, 8.007, 49.981, 363.687, 0.395
[epoch:227, iter:177493] Loss: 1.103, 8.008, 49.978, 363.681, 0.388
[epoch:227, iter:177513] Loss: 1.104, 8.009, 49.995, 363.764, 0.571
 * Acc@1 81.100 Acc@5 96.958
epoch 226, total time 73.42
Test: [0/313]	Time 0.263 (0.263)	Loss 1.2884 (1.2884)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2351 (1.1701)	Acc@1 65.625 (71.009)	Acc@5 96.875 (92.234)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7062 (1.1341)	Acc@1 78.125 (71.440)	Acc@5 96.875 (92.584)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3752 (1.1461)	Acc@1 62.500 (71.262)	Acc@5 96.875 (92.743)
 * Acc@1 71.370 Acc@5 92.800
==> training...
Epoch: [227][0/782]	Time 0.545 (0.545)	Data 0.453 (0.453)	Loss 8.7888 (8.7888)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
[epoch:228, iter:177515] Loss: 1.056, 7.774, 48.882, 355.625, 0.386
[epoch:228, iter:177535] Loss: 1.108, 8.014, 50.417, 365.998, 0.756
[epoch:228, iter:177555] Loss: 1.106, 8.059, 50.464, 366.310, 0.493
[epoch:228, iter:177575] Loss: 1.111, 8.020, 50.504, 366.205, 0.899
[epoch:228, iter:177595] Loss: 1.110, 8.025, 50.427, 365.883, 0.567
Epoch: [227][100/782]	Time 0.070 (0.089)	Data 0.002 (0.007)	Loss 9.6022 (9.4137)	Acc@1 82.812 (81.126)	Acc@5 96.875 (97.215)
[epoch:228, iter:177615] Loss: 1.110, 8.027, 50.381, 365.761, 0.635
[epoch:228, iter:177635] Loss: 1.112, 8.023, 50.345, 365.557, 0.660
[epoch:228, iter:177655] Loss: 1.111, 8.028, 50.373, 365.730, 0.777
[epoch:228, iter:177675] Loss: 1.112, 8.021, 50.348, 365.444, 0.531
[epoch:228, iter:177695] Loss: 1.113, 8.018, 50.288, 365.015, 0.647
Epoch: [227][200/782]	Time 0.069 (0.080)	Data 0.001 (0.004)	Loss 9.2606 (9.3952)	Acc@1 84.375 (81.149)	Acc@5 98.438 (96.992)
[epoch:228, iter:177715] Loss: 1.113, 8.020, 50.283, 365.013, 0.534
[epoch:228, iter:177735] Loss: 1.112, 8.018, 50.242, 364.764, 0.525
[epoch:228, iter:177755] Loss: 1.111, 8.017, 50.195, 364.523, 0.638
[epoch:228, iter:177775] Loss: 1.112, 8.019, 50.216, 364.630, 1.038
[epoch:228, iter:177795] Loss: 1.111, 8.019, 50.187, 364.508, 0.957
Epoch: [227][300/782]	Time 0.075 (0.078)	Data 0.002 (0.004)	Loss 8.9605 (9.3797)	Acc@1 84.375 (80.954)	Acc@5 100.000 (96.984)
[epoch:228, iter:177815] Loss: 1.110, 8.019, 50.168, 364.574, 0.401
[epoch:228, iter:177835] Loss: 1.109, 8.018, 50.173, 364.612, 0.621
[epoch:228, iter:177855] Loss: 1.110, 8.018, 50.193, 364.618, 0.858
[epoch:228, iter:177875] Loss: 1.110, 8.019, 50.206, 364.654, 0.620
[epoch:228, iter:177895] Loss: 1.110, 8.013, 50.197, 364.589, 0.360
Epoch: [227][400/782]	Time 0.091 (0.079)	Data 0.002 (0.003)	Loss 8.7460 (9.3785)	Acc@1 85.938 (80.876)	Acc@5 100.000 (97.027)
[epoch:228, iter:177915] Loss: 1.109, 8.011, 50.149, 364.373, 0.319
[epoch:228, iter:177935] Loss: 1.108, 8.013, 50.126, 364.292, 0.601
[epoch:228, iter:177955] Loss: 1.108, 8.014, 50.124, 364.246, 0.741
[epoch:228, iter:177975] Loss: 1.109, 8.016, 50.134, 364.291, 0.382
[epoch:228, iter:177995] Loss: 1.109, 8.017, 50.141, 364.310, 0.688
Epoch: [227][500/782]	Time 0.094 (0.082)	Data 0.003 (0.003)	Loss 9.5363 (9.3757)	Acc@1 78.125 (80.901)	Acc@5 96.875 (97.043)
[epoch:228, iter:178015] Loss: 1.109, 8.020, 50.136, 364.338, 0.659
[epoch:228, iter:178035] Loss: 1.109, 8.020, 50.129, 364.277, 0.911
[epoch:228, iter:178055] Loss: 1.109, 8.018, 50.138, 364.320, 0.422
[epoch:228, iter:178075] Loss: 1.109, 8.015, 50.134, 364.312, 0.436
[epoch:228, iter:178095] Loss: 1.108, 8.014, 50.137, 364.376, 0.868
Epoch: [227][600/782]	Time 0.087 (0.083)	Data 0.003 (0.003)	Loss 9.1863 (9.3679)	Acc@1 87.500 (81.128)	Acc@5 96.875 (97.034)
[epoch:228, iter:178115] Loss: 1.108, 8.012, 50.130, 364.320, 0.515
[epoch:228, iter:178135] Loss: 1.107, 8.014, 50.133, 364.376, 0.486
[epoch:228, iter:178155] Loss: 1.107, 8.014, 50.124, 364.293, 0.290
[epoch:228, iter:178175] Loss: 1.107, 8.015, 50.112, 364.245, 0.869
[epoch:228, iter:178195] Loss: 1.107, 8.015, 50.118, 364.248, 0.662
Epoch: [227][700/782]	Time 0.094 (0.084)	Data 0.002 (0.003)	Loss 9.1529 (9.3616)	Acc@1 78.125 (81.208)	Acc@5 98.438 (97.056)
[epoch:228, iter:178215] Loss: 1.107, 8.015, 50.098, 364.142, 0.690
[epoch:228, iter:178235] Loss: 1.107, 8.016, 50.090, 364.107, 0.570
[epoch:228, iter:178255] Loss: 1.107, 8.017, 50.081, 364.061, 0.884
[epoch:228, iter:178275] Loss: 1.107, 8.014, 50.072, 364.008, 0.598
[epoch:228, iter:178295] Loss: 1.107, 8.016, 50.076, 364.069, 0.697
 * Acc@1 81.218 Acc@5 97.084
epoch 227, total time 66.56
Test: [0/313]	Time 0.325 (0.325)	Loss 1.3241 (1.3241)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2294 (1.1763)	Acc@1 59.375 (71.132)	Acc@5 96.875 (92.017)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7092 (1.1377)	Acc@1 78.125 (71.517)	Acc@5 96.875 (92.584)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4673 (1.1513)	Acc@1 62.500 (71.117)	Acc@5 93.750 (92.701)
 * Acc@1 71.240 Acc@5 92.750
==> training...
Epoch: [228][0/782]	Time 0.561 (0.561)	Data 0.475 (0.475)	Loss 9.6004 (9.6004)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
[epoch:229, iter:178297] Loss: 1.127, 8.402, 52.111, 372.607, 0.501
[epoch:229, iter:178317] Loss: 1.121, 8.027, 50.475, 363.702, 0.445
[epoch:229, iter:178337] Loss: 1.117, 8.065, 50.468, 364.590, 0.780
[epoch:229, iter:178357] Loss: 1.119, 8.038, 50.428, 364.615, 0.599
[epoch:229, iter:178377] Loss: 1.118, 8.022, 50.346, 364.323, 0.471
Epoch: [228][100/782]	Time 0.080 (0.092)	Data 0.003 (0.007)	Loss 9.0879 (9.3874)	Acc@1 79.688 (81.188)	Acc@5 95.312 (96.968)
[epoch:229, iter:178397] Loss: 1.114, 8.021, 50.264, 363.981, 0.628
[epoch:229, iter:178417] Loss: 1.112, 8.018, 50.195, 363.851, 0.559
[epoch:229, iter:178437] Loss: 1.112, 8.023, 50.203, 363.835, 0.785
[epoch:229, iter:178457] Loss: 1.112, 8.021, 50.171, 363.768, 0.608
[epoch:229, iter:178477] Loss: 1.111, 8.028, 50.202, 364.085, 0.842
Epoch: [228][200/782]	Time 0.074 (0.087)	Data 0.002 (0.005)	Loss 9.3013 (9.3776)	Acc@1 75.000 (81.188)	Acc@5 95.312 (96.992)
[epoch:229, iter:178497] Loss: 1.110, 8.031, 50.205, 364.182, 0.664
[epoch:229, iter:178517] Loss: 1.108, 8.028, 50.172, 364.052, 0.844
[epoch:229, iter:178537] Loss: 1.109, 8.027, 50.183, 364.083, 0.754
[epoch:229, iter:178557] Loss: 1.109, 8.029, 50.176, 364.138, 0.641
[epoch:229, iter:178577] Loss: 1.109, 8.031, 50.182, 364.187, 0.771
Epoch: [228][300/782]	Time 0.090 (0.088)	Data 0.002 (0.004)	Loss 9.0985 (9.3788)	Acc@1 81.250 (81.089)	Acc@5 98.438 (96.885)
[epoch:229, iter:178597] Loss: 1.109, 8.033, 50.163, 364.141, 0.473
[epoch:229, iter:178617] Loss: 1.108, 8.037, 50.149, 364.116, 0.608
[epoch:229, iter:178637] Loss: 1.108, 8.036, 50.118, 364.075, 0.544
[epoch:229, iter:178657] Loss: 1.108, 8.037, 50.122, 364.108, 0.737
[epoch:229, iter:178677] Loss: 1.107, 8.034, 50.122, 364.171, 0.469
Epoch: [228][400/782]	Time 0.095 (0.089)	Data 0.003 (0.004)	Loss 9.2849 (9.3715)	Acc@1 78.125 (81.141)	Acc@5 93.750 (96.926)
[epoch:229, iter:178697] Loss: 1.108, 8.032, 50.135, 364.213, 0.727
[epoch:229, iter:178717] Loss: 1.108, 8.028, 50.123, 364.150, 0.640
[epoch:229, iter:178737] Loss: 1.107, 8.023, 50.115, 364.116, 0.482
[epoch:229, iter:178757] Loss: 1.107, 8.026, 50.112, 364.119, 0.615
[epoch:229, iter:178777] Loss: 1.107, 8.026, 50.100, 364.033, 0.482
Epoch: [228][500/782]	Time 0.087 (0.090)	Data 0.003 (0.003)	Loss 8.8854 (9.3587)	Acc@1 89.062 (81.125)	Acc@5 98.438 (96.947)
[epoch:229, iter:178797] Loss: 1.107, 8.025, 50.090, 363.982, 0.394
[epoch:229, iter:178817] Loss: 1.107, 8.023, 50.085, 363.949, 0.437
[epoch:229, iter:178837] Loss: 1.107, 8.021, 50.073, 363.879, 0.523
[epoch:229, iter:178857] Loss: 1.107, 8.021, 50.087, 363.989, 0.626
[epoch:229, iter:178877] Loss: 1.107, 8.019, 50.091, 364.037, 0.540
Epoch: [228][600/782]	Time 0.087 (0.090)	Data 0.002 (0.003)	Loss 9.2251 (9.3570)	Acc@1 81.250 (81.097)	Acc@5 95.312 (96.966)
[epoch:229, iter:178897] Loss: 1.107, 8.017, 50.089, 364.004, 0.593
[epoch:229, iter:178917] Loss: 1.106, 8.016, 50.071, 363.937, 0.404
[epoch:229, iter:178937] Loss: 1.106, 8.017, 50.076, 363.936, 0.822
[epoch:229, iter:178957] Loss: 1.107, 8.015, 50.084, 363.981, 0.594
[epoch:229, iter:178977] Loss: 1.107, 8.015, 50.081, 363.954, 0.629
Epoch: [228][700/782]	Time 0.085 (0.091)	Data 0.002 (0.003)	Loss 8.8718 (9.3557)	Acc@1 78.125 (81.040)	Acc@5 98.438 (96.917)
[epoch:229, iter:178997] Loss: 1.107, 8.012, 50.062, 363.843, 0.626
[epoch:229, iter:179017] Loss: 1.106, 8.010, 50.066, 363.864, 0.774
[epoch:229, iter:179037] Loss: 1.106, 8.011, 50.067, 363.891, 0.533
[epoch:229, iter:179057] Loss: 1.106, 8.010, 50.069, 363.918, 0.471
[epoch:229, iter:179077] Loss: 1.106, 8.010, 50.071, 363.927, 0.663
 * Acc@1 81.002 Acc@5 96.958
epoch 228, total time 70.46
Test: [0/313]	Time 0.264 (0.264)	Loss 1.3528 (1.3528)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.007 (0.010)	Loss 1.2251 (1.1714)	Acc@1 62.500 (70.916)	Acc@5 96.875 (92.234)
Test: [200/313]	Time 0.008 (0.009)	Loss 0.6900 (1.1347)	Acc@1 78.125 (71.440)	Acc@5 100.000 (92.677)
Test: [300/313]	Time 0.010 (0.009)	Loss 1.3706 (1.1472)	Acc@1 62.500 (71.169)	Acc@5 100.000 (92.753)
 * Acc@1 71.280 Acc@5 92.810
==> training...
Epoch: [229][0/782]	Time 0.622 (0.622)	Data 0.550 (0.550)	Loss 9.0589 (9.0589)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
[epoch:230, iter:179079] Loss: 1.053, 7.923, 47.855, 361.018, 0.694
[epoch:230, iter:179099] Loss: 1.095, 7.972, 49.762, 363.011, 0.657
[epoch:230, iter:179119] Loss: 1.100, 8.007, 49.942, 363.821, 0.383
[epoch:230, iter:179139] Loss: 1.099, 8.017, 50.016, 364.081, 0.457
[epoch:230, iter:179159] Loss: 1.102, 8.019, 50.068, 364.253, 0.415
Epoch: [229][100/782]	Time 0.060 (0.091)	Data 0.002 (0.008)	Loss 9.1789 (9.3556)	Acc@1 85.938 (80.724)	Acc@5 96.875 (97.123)
[epoch:230, iter:179179] Loss: 1.102, 8.028, 50.007, 363.898, 0.438
[epoch:230, iter:179199] Loss: 1.104, 8.020, 49.996, 363.751, 0.494
[epoch:230, iter:179219] Loss: 1.100, 8.008, 49.936, 363.629, 0.820
[epoch:230, iter:179239] Loss: 1.101, 8.008, 49.907, 363.455, 0.723
[epoch:230, iter:179259] Loss: 1.100, 8.008, 49.881, 363.342, 0.464
Epoch: [229][200/782]	Time 0.074 (0.082)	Data 0.002 (0.005)	Loss 9.3294 (9.3297)	Acc@1 89.062 (80.721)	Acc@5 96.875 (97.201)
[epoch:230, iter:179279] Loss: 1.100, 8.014, 49.937, 363.578, 0.546
[epoch:230, iter:179299] Loss: 1.100, 8.013, 49.936, 363.485, 0.623
[epoch:230, iter:179319] Loss: 1.101, 8.014, 49.952, 363.525, 0.698
[epoch:230, iter:179339] Loss: 1.102, 8.020, 49.941, 363.417, 0.720
[epoch:230, iter:179359] Loss: 1.102, 8.015, 49.963, 363.447, 0.699
Epoch: [229][300/782]	Time 0.107 (0.083)	Data 0.003 (0.004)	Loss 9.1772 (9.3308)	Acc@1 85.938 (81.011)	Acc@5 100.000 (97.098)
[epoch:230, iter:179379] Loss: 1.102, 8.022, 49.949, 363.501, 0.539
[epoch:230, iter:179399] Loss: 1.102, 8.020, 49.922, 363.419, 1.112
[epoch:230, iter:179419] Loss: 1.102, 8.017, 49.949, 363.509, 0.472
[epoch:230, iter:179439] Loss: 1.104, 8.019, 49.970, 363.584, 0.538
[epoch:230, iter:179459] Loss: 1.104, 8.017, 49.953, 363.487, 0.493
Epoch: [229][400/782]	Time 0.083 (0.085)	Data 0.003 (0.004)	Loss 9.6130 (9.3313)	Acc@1 79.688 (81.114)	Acc@5 95.312 (97.074)
[epoch:230, iter:179479] Loss: 1.104, 8.020, 49.955, 363.489, 0.799
[epoch:230, iter:179499] Loss: 1.104, 8.017, 49.947, 363.428, 0.453
[epoch:230, iter:179519] Loss: 1.105, 8.016, 49.958, 363.386, 0.797
[epoch:230, iter:179539] Loss: 1.105, 8.017, 49.994, 363.558, 0.514
[epoch:230, iter:179559] Loss: 1.105, 8.018, 50.016, 363.704, 0.432
Epoch: [229][500/782]	Time 0.095 (0.083)	Data 0.003 (0.003)	Loss 9.5059 (9.3432)	Acc@1 79.688 (81.163)	Acc@5 98.438 (97.068)
[epoch:230, iter:179579] Loss: 1.105, 8.020, 50.032, 363.767, 0.601
[epoch:230, iter:179599] Loss: 1.105, 8.019, 50.045, 363.809, 0.746
[epoch:230, iter:179619] Loss: 1.105, 8.018, 50.062, 363.922, 0.677
[epoch:230, iter:179639] Loss: 1.105, 8.017, 50.077, 364.001, 0.820
[epoch:230, iter:179659] Loss: 1.105, 8.018, 50.058, 363.950, 0.568
Epoch: [229][600/782]	Time 0.092 (0.083)	Data 0.003 (0.003)	Loss 9.5968 (9.3519)	Acc@1 68.750 (81.097)	Acc@5 98.438 (97.021)
[epoch:230, iter:179679] Loss: 1.105, 8.017, 50.068, 363.972, 0.788
[epoch:230, iter:179699] Loss: 1.105, 8.018, 50.063, 363.967, 0.400
[epoch:230, iter:179719] Loss: 1.105, 8.016, 50.058, 363.956, 0.275
[epoch:230, iter:179739] Loss: 1.105, 8.016, 50.052, 363.925, 0.459
[epoch:230, iter:179759] Loss: 1.105, 8.015, 50.058, 363.942, 0.804
Epoch: [229][700/782]	Time 0.093 (0.082)	Data 0.003 (0.003)	Loss 10.0949 (9.3492)	Acc@1 71.875 (81.190)	Acc@5 96.875 (97.022)
[epoch:230, iter:179779] Loss: 1.105, 8.013, 50.062, 363.984, 0.814
[epoch:230, iter:179799] Loss: 1.105, 8.014, 50.053, 363.910, 0.695
[epoch:230, iter:179819] Loss: 1.105, 8.014, 50.049, 363.932, 0.569
[epoch:230, iter:179839] Loss: 1.105, 8.013, 50.037, 363.869, 0.627
[epoch:230, iter:179859] Loss: 1.105, 8.013, 50.030, 363.829, 0.752
 * Acc@1 81.116 Acc@5 97.018
epoch 229, total time 64.38
Test: [0/313]	Time 0.253 (0.253)	Loss 1.3439 (1.3439)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2037 (1.1753)	Acc@1 59.375 (70.885)	Acc@5 96.875 (92.265)
Test: [200/313]	Time 0.007 (0.008)	Loss 0.7553 (1.1380)	Acc@1 75.000 (71.409)	Acc@5 100.000 (92.786)
Test: [300/313]	Time 0.007 (0.008)	Loss 1.3636 (1.1488)	Acc@1 62.500 (71.179)	Acc@5 93.750 (92.899)
 * Acc@1 71.280 Acc@5 92.940
==> training...
Epoch: [230][0/782]	Time 0.594 (0.594)	Data 0.523 (0.523)	Loss 9.2388 (9.2388)	Acc@1 85.938 (85.938)	Acc@5 95.312 (95.312)
[epoch:231, iter:179861] Loss: 1.130, 8.141, 50.348, 362.991, 0.462
[epoch:231, iter:179881] Loss: 1.106, 8.065, 50.185, 365.397, 0.488
[epoch:231, iter:179901] Loss: 1.106, 8.035, 50.165, 364.376, 0.548
[epoch:231, iter:179921] Loss: 1.103, 8.027, 50.128, 364.413, 0.516
[epoch:231, iter:179941] Loss: 1.102, 8.027, 50.118, 364.534, 0.419
Epoch: [230][100/782]	Time 0.076 (0.087)	Data 0.002 (0.008)	Loss 9.2999 (9.3483)	Acc@1 76.562 (81.993)	Acc@5 96.875 (97.107)
[epoch:231, iter:179961] Loss: 1.102, 8.019, 50.090, 364.551, 0.766
[epoch:231, iter:179981] Loss: 1.101, 8.030, 50.113, 364.874, 1.009
[epoch:231, iter:180001] Loss: 1.100, 8.027, 50.064, 364.575, 0.653
[epoch:231, iter:180021] Loss: 1.102, 8.033, 50.066, 364.627, 0.718
[epoch:231, iter:180041] Loss: 1.103, 8.026, 50.042, 364.390, 0.594
Epoch: [230][200/782]	Time 0.067 (0.084)	Data 0.002 (0.005)	Loss 8.7989 (9.3627)	Acc@1 79.688 (81.149)	Acc@5 100.000 (97.085)
[epoch:231, iter:180061] Loss: 1.103, 8.027, 50.063, 364.494, 0.446
[epoch:231, iter:180081] Loss: 1.104, 8.026, 50.076, 364.414, 0.577
[epoch:231, iter:180101] Loss: 1.104, 8.023, 50.054, 364.289, 0.620
[epoch:231, iter:180121] Loss: 1.103, 8.014, 50.017, 364.109, 0.509
[epoch:231, iter:180141] Loss: 1.103, 8.012, 50.011, 364.066, 0.641
Epoch: [230][300/782]	Time 0.093 (0.081)	Data 0.002 (0.004)	Loss 9.3956 (9.3507)	Acc@1 79.688 (81.333)	Acc@5 98.438 (97.067)
[epoch:231, iter:180161] Loss: 1.104, 8.014, 50.034, 364.126, 0.587
[epoch:231, iter:180181] Loss: 1.104, 8.013, 50.024, 364.009, 0.598
[epoch:231, iter:180201] Loss: 1.104, 8.014, 50.023, 364.042, 0.561
[epoch:231, iter:180221] Loss: 1.102, 8.013, 49.997, 363.945, 0.652
[epoch:231, iter:180241] Loss: 1.103, 8.012, 50.017, 364.062, 0.824
Epoch: [230][400/782]	Time 0.079 (0.084)	Data 0.002 (0.004)	Loss 9.1270 (9.3451)	Acc@1 87.500 (81.308)	Acc@5 98.438 (97.019)
[epoch:231, iter:180261] Loss: 1.103, 8.009, 50.006, 363.995, 0.381
[epoch:231, iter:180281] Loss: 1.103, 8.008, 50.009, 364.045, 0.460
[epoch:231, iter:180301] Loss: 1.103, 8.010, 49.990, 363.950, 0.789
[epoch:231, iter:180321] Loss: 1.103, 8.010, 50.009, 364.023, 0.711
[epoch:231, iter:180341] Loss: 1.103, 8.010, 50.001, 363.981, 0.414
Epoch: [230][500/782]	Time 0.080 (0.084)	Data 0.002 (0.003)	Loss 8.9767 (9.3505)	Acc@1 81.250 (81.113)	Acc@5 100.000 (97.009)
[epoch:231, iter:180361] Loss: 1.103, 8.013, 50.008, 364.015, 0.558
[epoch:231, iter:180381] Loss: 1.103, 8.012, 50.002, 363.973, 0.445
[epoch:231, iter:180401] Loss: 1.103, 8.013, 50.014, 364.031, 0.567
[epoch:231, iter:180421] Loss: 1.103, 8.012, 50.011, 364.018, 0.806
[epoch:231, iter:180441] Loss: 1.104, 8.012, 50.004, 364.014, 0.618
Epoch: [230][600/782]	Time 0.092 (0.086)	Data 0.003 (0.003)	Loss 8.6377 (9.3479)	Acc@1 85.938 (81.045)	Acc@5 98.438 (97.010)
[epoch:231, iter:180461] Loss: 1.104, 8.012, 49.999, 363.994, 0.465
[epoch:231, iter:180481] Loss: 1.104, 8.012, 50.015, 364.062, 0.629
[epoch:231, iter:180501] Loss: 1.104, 8.011, 50.007, 364.011, 0.566
[epoch:231, iter:180521] Loss: 1.104, 8.011, 49.997, 363.953, 0.514
[epoch:231, iter:180541] Loss: 1.104, 8.012, 49.999, 363.980, 0.400
Epoch: [230][700/782]	Time 0.087 (0.086)	Data 0.003 (0.003)	Loss 9.3748 (9.3445)	Acc@1 75.000 (81.183)	Acc@5 93.750 (97.031)
[epoch:231, iter:180561] Loss: 1.104, 8.013, 50.009, 364.005, 0.783
[epoch:231, iter:180581] Loss: 1.104, 8.014, 50.020, 364.030, 0.673
[epoch:231, iter:180601] Loss: 1.104, 8.013, 50.006, 363.955, 0.811
[epoch:231, iter:180621] Loss: 1.104, 8.016, 50.018, 364.011, 0.734
[epoch:231, iter:180641] Loss: 1.105, 8.014, 50.015, 363.949, 0.342
 * Acc@1 81.148 Acc@5 97.030
epoch 230, total time 67.00
Test: [0/313]	Time 0.249 (0.249)	Loss 1.2888 (1.2888)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2588 (1.1711)	Acc@1 59.375 (70.854)	Acc@5 96.875 (92.203)
Test: [200/313]	Time 0.005 (0.008)	Loss 0.7060 (1.1360)	Acc@1 78.125 (71.175)	Acc@5 96.875 (92.708)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4616 (1.1483)	Acc@1 62.500 (70.951)	Acc@5 93.750 (92.743)
 * Acc@1 71.070 Acc@5 92.800
==> training...
Epoch: [231][0/782]	Time 0.530 (0.530)	Data 0.458 (0.458)	Loss 9.3226 (9.3226)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
[epoch:232, iter:180643] Loss: 1.127, 8.132, 50.076, 362.498, 0.619
[epoch:232, iter:180663] Loss: 1.126, 8.035, 50.200, 364.944, 0.626
[epoch:232, iter:180683] Loss: 1.122, 7.994, 50.307, 364.975, 0.597
[epoch:232, iter:180703] Loss: 1.114, 8.019, 50.283, 365.395, 0.671
[epoch:232, iter:180723] Loss: 1.110, 8.029, 50.207, 365.250, 0.744
Epoch: [231][100/782]	Time 0.110 (0.102)	Data 0.003 (0.007)	Loss 8.9785 (9.3517)	Acc@1 89.062 (81.111)	Acc@5 98.438 (96.844)
[epoch:232, iter:180743] Loss: 1.108, 8.029, 50.127, 364.958, 0.418
[epoch:232, iter:180763] Loss: 1.106, 8.025, 50.127, 365.012, 0.651
[epoch:232, iter:180783] Loss: 1.107, 8.028, 50.118, 364.930, 0.738
[epoch:232, iter:180803] Loss: 1.105, 8.020, 50.062, 364.591, 0.618
[epoch:232, iter:180823] Loss: 1.104, 8.017, 50.095, 364.819, 0.780
Epoch: [231][200/782]	Time 0.093 (0.097)	Data 0.003 (0.005)	Loss 9.4525 (9.3484)	Acc@1 84.375 (81.569)	Acc@5 98.438 (96.758)
[epoch:232, iter:180843] Loss: 1.106, 8.016, 50.092, 364.691, 0.497
[epoch:232, iter:180863] Loss: 1.106, 8.020, 50.104, 364.707, 0.489
[epoch:232, iter:180883] Loss: 1.106, 8.017, 50.098, 364.610, 0.581
[epoch:232, iter:180903] Loss: 1.106, 8.012, 50.065, 364.369, 0.600
[epoch:232, iter:180923] Loss: 1.106, 8.010, 50.082, 364.404, 0.512
Epoch: [231][300/782]	Time 0.073 (0.088)	Data 0.002 (0.004)	Loss 9.1948 (9.3498)	Acc@1 82.812 (81.603)	Acc@5 96.875 (96.932)
[epoch:232, iter:180943] Loss: 1.106, 8.011, 50.075, 364.345, 0.598
[epoch:232, iter:180963] Loss: 1.106, 8.010, 50.048, 364.163, 0.611
[epoch:232, iter:180983] Loss: 1.106, 8.013, 50.055, 364.174, 0.728
[epoch:232, iter:181003] Loss: 1.106, 8.012, 50.033, 364.069, 0.394
[epoch:232, iter:181023] Loss: 1.105, 8.012, 50.011, 363.955, 0.676
Epoch: [231][400/782]	Time 0.074 (0.084)	Data 0.002 (0.003)	Loss 9.1409 (9.3320)	Acc@1 81.250 (81.620)	Acc@5 98.438 (97.015)
[epoch:232, iter:181043] Loss: 1.105, 8.010, 50.015, 363.927, 0.644
[epoch:232, iter:181063] Loss: 1.106, 8.011, 50.024, 363.927, 0.474
[epoch:232, iter:181083] Loss: 1.106, 8.007, 50.040, 363.988, 0.590
[epoch:232, iter:181103] Loss: 1.107, 8.008, 50.054, 364.049, 0.719
[epoch:232, iter:181123] Loss: 1.106, 8.006, 50.044, 364.012, 0.798
Epoch: [231][500/782]	Time 0.073 (0.082)	Data 0.002 (0.003)	Loss 9.7582 (9.3405)	Acc@1 84.375 (81.450)	Acc@5 96.875 (96.987)
[epoch:232, iter:181143] Loss: 1.106, 8.009, 50.039, 363.998, 0.631
[epoch:232, iter:181163] Loss: 1.106, 8.010, 50.044, 364.010, 0.776
[epoch:232, iter:181183] Loss: 1.106, 8.012, 50.036, 363.987, 0.829
[epoch:232, iter:181203] Loss: 1.106, 8.010, 50.037, 363.966, 0.377
[epoch:232, iter:181223] Loss: 1.107, 8.012, 50.047, 364.027, 0.691
Epoch: [231][600/782]	Time 0.074 (0.083)	Data 0.002 (0.003)	Loss 9.3825 (9.3443)	Acc@1 84.375 (81.411)	Acc@5 93.750 (96.969)
[epoch:232, iter:181243] Loss: 1.107, 8.009, 50.048, 364.046, 0.667
[epoch:232, iter:181263] Loss: 1.106, 8.007, 50.031, 363.951, 0.469
[epoch:232, iter:181283] Loss: 1.107, 8.008, 50.041, 363.946, 0.466
[epoch:232, iter:181303] Loss: 1.107, 8.006, 50.042, 363.950, 0.598
[epoch:232, iter:181323] Loss: 1.107, 8.007, 50.031, 363.901, 0.454
Epoch: [231][700/782]	Time 0.086 (0.083)	Data 0.002 (0.003)	Loss 8.7812 (9.3382)	Acc@1 85.938 (81.303)	Acc@5 98.438 (97.033)
[epoch:232, iter:181343] Loss: 1.107, 8.004, 50.026, 363.864, 0.414
[epoch:232, iter:181363] Loss: 1.106, 8.003, 50.025, 363.877, 0.703
[epoch:232, iter:181383] Loss: 1.106, 8.005, 50.021, 363.844, 0.751
[epoch:232, iter:181403] Loss: 1.106, 8.004, 50.009, 363.776, 0.659
[epoch:232, iter:181423] Loss: 1.106, 8.005, 50.009, 363.774, 0.624
 * Acc@1 81.234 Acc@5 97.042
epoch 231, total time 64.11
Test: [0/313]	Time 0.281 (0.281)	Loss 1.3038 (1.3038)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2131 (1.1705)	Acc@1 65.625 (70.761)	Acc@5 96.875 (92.141)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7584 (1.1353)	Acc@1 78.125 (71.533)	Acc@5 96.875 (92.522)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4813 (1.1471)	Acc@1 65.625 (71.221)	Acc@5 100.000 (92.712)
 * Acc@1 71.310 Acc@5 92.770
==> training...
Epoch: [232][0/782]	Time 0.675 (0.675)	Data 0.600 (0.600)	Loss 9.1278 (9.1278)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
[epoch:233, iter:181425] Loss: 1.111, 7.787, 50.554, 365.269, 0.443
[epoch:233, iter:181445] Loss: 1.118, 8.008, 50.068, 363.670, 0.883
[epoch:233, iter:181465] Loss: 1.105, 7.979, 49.825, 362.990, 0.711
[epoch:233, iter:181485] Loss: 1.105, 7.997, 49.919, 363.732, 0.647
[epoch:233, iter:181505] Loss: 1.104, 8.006, 49.884, 363.299, 0.992
Epoch: [232][100/782]	Time 0.092 (0.090)	Data 0.003 (0.008)	Loss 9.5964 (9.3586)	Acc@1 78.125 (80.894)	Acc@5 93.750 (96.581)
[epoch:233, iter:181525] Loss: 1.102, 8.002, 49.980, 363.883, 0.796
[epoch:233, iter:181545] Loss: 1.103, 8.014, 50.046, 363.907, 0.619
[epoch:233, iter:181565] Loss: 1.104, 8.018, 49.975, 363.558, 0.668
[epoch:233, iter:181585] Loss: 1.103, 8.023, 49.978, 363.523, 0.867
[epoch:233, iter:181605] Loss: 1.104, 8.021, 50.026, 363.798, 0.571
Epoch: [232][200/782]	Time 0.097 (0.089)	Data 0.003 (0.005)	Loss 9.3939 (9.3667)	Acc@1 75.000 (80.838)	Acc@5 95.312 (96.821)
[epoch:233, iter:181625] Loss: 1.103, 8.024, 50.046, 363.856, 0.766
[epoch:233, iter:181645] Loss: 1.102, 8.021, 49.992, 363.585, 0.391
[epoch:233, iter:181665] Loss: 1.102, 8.023, 50.007, 363.687, 0.709
[epoch:233, iter:181685] Loss: 1.104, 8.020, 50.001, 363.673, 0.571
[epoch:233, iter:181705] Loss: 1.103, 8.015, 50.013, 363.710, 0.603
Epoch: [232][300/782]	Time 0.093 (0.088)	Data 0.003 (0.004)	Loss 8.8769 (9.3482)	Acc@1 84.375 (81.022)	Acc@5 96.875 (96.849)
[epoch:233, iter:181725] Loss: 1.102, 8.015, 49.967, 363.530, 0.482
[epoch:233, iter:181745] Loss: 1.102, 8.017, 49.980, 363.613, 0.555
[epoch:233, iter:181765] Loss: 1.102, 8.022, 49.992, 363.709, 0.747
[epoch:233, iter:181785] Loss: 1.102, 8.026, 49.988, 363.717, 0.640
[epoch:233, iter:181805] Loss: 1.102, 8.024, 49.975, 363.623, 0.622
Epoch: [232][400/782]	Time 0.106 (0.089)	Data 0.003 (0.004)	Loss 10.0834 (9.3484)	Acc@1 84.375 (81.094)	Acc@5 98.438 (96.910)
[epoch:233, iter:181825] Loss: 1.102, 8.027, 49.985, 363.643, 0.550
[epoch:233, iter:181845] Loss: 1.103, 8.028, 49.990, 363.642, 0.346
[epoch:233, iter:181865] Loss: 1.104, 8.025, 49.998, 363.693, 0.590
[epoch:233, iter:181885] Loss: 1.104, 8.021, 49.996, 363.659, 0.736
[epoch:233, iter:181905] Loss: 1.104, 8.021, 49.989, 363.634, 0.396
Epoch: [232][500/782]	Time 0.104 (0.092)	Data 0.003 (0.004)	Loss 10.1551 (9.3445)	Acc@1 79.688 (81.247)	Acc@5 90.625 (96.962)
[epoch:233, iter:181925] Loss: 1.104, 8.022, 49.999, 363.690, 0.899
[epoch:233, iter:181945] Loss: 1.104, 8.018, 49.985, 363.606, 0.846
[epoch:233, iter:181965] Loss: 1.104, 8.017, 49.989, 363.638, 0.523
[epoch:233, iter:181985] Loss: 1.105, 8.019, 49.999, 363.702, 0.729
[epoch:233, iter:182005] Loss: 1.105, 8.018, 50.007, 363.712, 0.305
Epoch: [232][600/782]	Time 0.091 (0.093)	Data 0.002 (0.003)	Loss 9.4244 (9.3464)	Acc@1 81.250 (81.172)	Acc@5 96.875 (97.005)
[epoch:233, iter:182025] Loss: 1.105, 8.019, 50.008, 363.749, 0.504
[epoch:233, iter:182045] Loss: 1.105, 8.017, 49.991, 363.632, 0.587
[epoch:233, iter:182065] Loss: 1.105, 8.018, 49.989, 363.624, 0.625
[epoch:233, iter:182085] Loss: 1.105, 8.019, 50.006, 363.696, 0.488
[epoch:233, iter:182105] Loss: 1.106, 8.019, 50.000, 363.702, 0.489
Epoch: [232][700/782]	Time 0.092 (0.093)	Data 0.002 (0.003)	Loss 9.9147 (9.3465)	Acc@1 78.125 (81.232)	Acc@5 98.438 (96.991)
[epoch:233, iter:182125] Loss: 1.105, 8.018, 50.014, 363.765, 0.669
[epoch:233, iter:182145] Loss: 1.106, 8.019, 50.017, 363.772, 0.573
[epoch:233, iter:182165] Loss: 1.106, 8.019, 50.014, 363.746, 0.382
[epoch:233, iter:182185] Loss: 1.106, 8.016, 50.012, 363.740, 0.584
[epoch:233, iter:182205] Loss: 1.106, 8.013, 50.004, 363.706, 0.570
 * Acc@1 81.210 Acc@5 96.992
epoch 232, total time 72.81
Test: [0/313]	Time 0.275 (0.275)	Loss 1.3053 (1.3053)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2994 (1.1750)	Acc@1 59.375 (70.854)	Acc@5 96.875 (92.327)
Test: [200/313]	Time 0.005 (0.007)	Loss 0.6949 (1.1355)	Acc@1 78.125 (71.331)	Acc@5 96.875 (92.708)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4612 (1.1479)	Acc@1 62.500 (71.065)	Acc@5 96.875 (92.774)
 * Acc@1 71.180 Acc@5 92.830
==> training...
Epoch: [233][0/782]	Time 0.549 (0.549)	Data 0.460 (0.460)	Loss 9.0802 (9.0802)	Acc@1 78.125 (78.125)	Acc@5 95.312 (95.312)
[epoch:234, iter:182207] Loss: 1.122, 7.941, 48.540, 360.415, 0.600
[epoch:234, iter:182227] Loss: 1.119, 8.108, 50.592, 367.908, 0.555
[epoch:234, iter:182247] Loss: 1.114, 8.069, 50.452, 366.413, 0.781
[epoch:234, iter:182267] Loss: 1.116, 8.068, 50.362, 365.822, 0.705
[epoch:234, iter:182287] Loss: 1.117, 8.038, 50.179, 364.788, 0.695
Epoch: [233][100/782]	Time 0.090 (0.089)	Data 0.002 (0.007)	Loss 9.7332 (9.3786)	Acc@1 76.562 (81.126)	Acc@5 95.312 (97.123)
[epoch:234, iter:182307] Loss: 1.117, 8.028, 50.110, 364.527, 0.728
[epoch:234, iter:182327] Loss: 1.115, 8.040, 50.203, 365.092, 0.584
[epoch:234, iter:182347] Loss: 1.112, 8.031, 50.153, 364.837, 0.743
[epoch:234, iter:182367] Loss: 1.111, 8.030, 50.164, 364.852, 0.504
[epoch:234, iter:182387] Loss: 1.111, 8.023, 50.127, 364.583, 0.530
Epoch: [233][200/782]	Time 0.089 (0.085)	Data 0.003 (0.004)	Loss 8.6676 (9.3646)	Acc@1 87.500 (80.799)	Acc@5 96.875 (97.077)
[epoch:234, iter:182407] Loss: 1.110, 8.017, 50.083, 364.297, 0.444
[epoch:234, iter:182427] Loss: 1.110, 8.014, 50.100, 364.349, 0.648
[epoch:234, iter:182447] Loss: 1.110, 8.015, 50.078, 364.219, 0.752
[epoch:234, iter:182467] Loss: 1.109, 8.016, 50.060, 364.178, 0.370
[epoch:234, iter:182487] Loss: 1.109, 8.018, 50.057, 364.209, 0.624
Epoch: [233][300/782]	Time 0.073 (0.081)	Data 0.002 (0.004)	Loss 9.5468 (9.3734)	Acc@1 79.688 (80.814)	Acc@5 96.875 (96.942)
[epoch:234, iter:182507] Loss: 1.109, 8.017, 50.111, 364.444, 0.649
[epoch:234, iter:182527] Loss: 1.109, 8.014, 50.124, 364.496, 0.611
[epoch:234, iter:182547] Loss: 1.109, 8.010, 50.089, 364.305, 0.252
[epoch:234, iter:182567] Loss: 1.108, 8.009, 50.084, 364.267, 0.622
[epoch:234, iter:182587] Loss: 1.108, 8.012, 50.070, 364.184, 0.510
Epoch: [233][400/782]	Time 0.076 (0.081)	Data 0.002 (0.003)	Loss 9.0706 (9.3643)	Acc@1 84.375 (80.849)	Acc@5 100.000 (96.914)
[epoch:234, iter:182607] Loss: 1.108, 8.012, 50.073, 364.141, 0.457
[epoch:234, iter:182627] Loss: 1.108, 8.011, 50.055, 364.082, 0.624
[epoch:234, iter:182647] Loss: 1.108, 8.011, 50.038, 363.971, 0.565
[epoch:234, iter:182667] Loss: 1.108, 8.007, 50.035, 363.910, 0.576
[epoch:234, iter:182687] Loss: 1.109, 8.010, 50.040, 363.938, 0.474
Epoch: [233][500/782]	Time 0.088 (0.081)	Data 0.003 (0.003)	Loss 9.2930 (9.3558)	Acc@1 82.812 (80.910)	Acc@5 96.875 (96.937)
[epoch:234, iter:182707] Loss: 1.109, 8.013, 50.059, 364.025, 0.538
[epoch:234, iter:182727] Loss: 1.109, 8.014, 50.060, 364.045, 0.428
[epoch:234, iter:182747] Loss: 1.109, 8.014, 50.056, 364.072, 0.527
[epoch:234, iter:182767] Loss: 1.108, 8.011, 50.031, 363.982, 0.507
[epoch:234, iter:182787] Loss: 1.108, 8.009, 50.024, 363.942, 0.654
Epoch: [233][600/782]	Time 0.090 (0.081)	Data 0.003 (0.003)	Loss 9.1307 (9.3461)	Acc@1 84.375 (81.097)	Acc@5 98.438 (97.005)
[epoch:234, iter:182807] Loss: 1.108, 8.010, 50.022, 363.911, 0.545
[epoch:234, iter:182827] Loss: 1.108, 8.009, 50.026, 363.879, 0.918
[epoch:234, iter:182847] Loss: 1.108, 8.011, 50.036, 363.932, 0.590
[epoch:234, iter:182867] Loss: 1.108, 8.009, 50.036, 363.860, 0.553
[epoch:234, iter:182887] Loss: 1.108, 8.011, 50.038, 363.843, 0.579
Epoch: [233][700/782]	Time 0.092 (0.082)	Data 0.002 (0.003)	Loss 9.3679 (9.3510)	Acc@1 82.812 (80.987)	Acc@5 96.875 (96.986)
[epoch:234, iter:182907] Loss: 1.108, 8.012, 50.042, 363.861, 0.672
[epoch:234, iter:182927] Loss: 1.108, 8.013, 50.046, 363.901, 0.650
[epoch:234, iter:182947] Loss: 1.108, 8.010, 50.053, 363.942, 0.534
[epoch:234, iter:182967] Loss: 1.108, 8.009, 50.052, 363.956, 0.360
[epoch:234, iter:182987] Loss: 1.109, 8.010, 50.054, 363.938, 0.872
 * Acc@1 80.986 Acc@5 97.022
epoch 233, total time 65.00
Test: [0/313]	Time 0.272 (0.272)	Loss 1.2322 (1.2322)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.3175 (1.1700)	Acc@1 62.500 (71.040)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7268 (1.1321)	Acc@1 75.000 (71.502)	Acc@5 96.875 (92.677)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4556 (1.1439)	Acc@1 65.625 (71.190)	Acc@5 93.750 (92.712)
 * Acc@1 71.320 Acc@5 92.760
==> training...
Epoch: [234][0/782]	Time 0.637 (0.637)	Data 0.550 (0.550)	Loss 9.2025 (9.2025)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
[epoch:235, iter:182989] Loss: 1.118, 7.752, 49.515, 357.254, 0.515
[epoch:235, iter:183009] Loss: 1.108, 7.957, 49.769, 362.273, 0.627
[epoch:235, iter:183029] Loss: 1.105, 7.957, 49.757, 362.447, 0.543
[epoch:235, iter:183049] Loss: 1.104, 7.985, 49.799, 362.748, 0.561
[epoch:235, iter:183069] Loss: 1.106, 7.976, 49.767, 362.505, 0.451
Epoch: [234][100/782]	Time 0.073 (0.094)	Data 0.002 (0.008)	Loss 9.2496 (9.2593)	Acc@1 82.812 (82.317)	Acc@5 96.875 (97.092)
[epoch:235, iter:183089] Loss: 1.103, 7.979, 49.796, 362.715, 0.632
[epoch:235, iter:183109] Loss: 1.103, 7.984, 49.776, 362.754, 0.513
[epoch:235, iter:183129] Loss: 1.102, 7.989, 49.789, 362.893, 0.537
[epoch:235, iter:183149] Loss: 1.105, 7.984, 49.867, 363.230, 0.527
[epoch:235, iter:183169] Loss: 1.105, 7.987, 49.850, 363.170, 0.573
Epoch: [234][200/782]	Time 0.088 (0.094)	Data 0.003 (0.005)	Loss 9.1330 (9.2943)	Acc@1 81.250 (81.794)	Acc@5 93.750 (97.178)
[epoch:235, iter:183189] Loss: 1.107, 7.988, 49.881, 363.271, 0.628
[epoch:235, iter:183209] Loss: 1.107, 7.990, 49.903, 363.412, 0.574
[epoch:235, iter:183229] Loss: 1.108, 7.989, 49.927, 363.476, 0.550
[epoch:235, iter:183249] Loss: 1.108, 7.990, 49.900, 363.332, 0.591
[epoch:235, iter:183269] Loss: 1.108, 7.993, 49.930, 363.503, 0.412
Epoch: [234][300/782]	Time 0.104 (0.096)	Data 0.003 (0.004)	Loss 10.0620 (9.3171)	Acc@1 79.688 (81.598)	Acc@5 95.312 (97.171)
[epoch:235, iter:183289] Loss: 1.107, 7.996, 49.935, 363.482, 0.788
[epoch:235, iter:183309] Loss: 1.108, 7.999, 49.957, 363.602, 0.747
[epoch:235, iter:183329] Loss: 1.108, 8.000, 49.954, 363.569, 0.735
[epoch:235, iter:183349] Loss: 1.108, 8.001, 49.960, 363.602, 0.473
[epoch:235, iter:183369] Loss: 1.108, 8.001, 49.958, 363.571, 0.616
Epoch: [234][400/782]	Time 0.104 (0.096)	Data 0.002 (0.004)	Loss 8.8259 (9.3185)	Acc@1 81.250 (81.495)	Acc@5 100.000 (97.179)
[epoch:235, iter:183389] Loss: 1.107, 7.998, 49.942, 363.521, 0.447
[epoch:235, iter:183409] Loss: 1.106, 7.998, 49.922, 363.473, 0.672
[epoch:235, iter:183429] Loss: 1.107, 7.998, 49.919, 363.422, 0.766
[epoch:235, iter:183449] Loss: 1.106, 7.996, 49.917, 363.369, 0.585
[epoch:235, iter:183469] Loss: 1.107, 7.998, 49.945, 363.474, 0.655
Epoch: [234][500/782]	Time 0.086 (0.095)	Data 0.002 (0.004)	Loss 9.2582 (9.3234)	Acc@1 84.375 (81.468)	Acc@5 98.438 (97.174)
[epoch:235, iter:183489] Loss: 1.107, 8.002, 49.963, 363.595, 0.582
[epoch:235, iter:183509] Loss: 1.107, 8.003, 49.980, 363.678, 0.433
[epoch:235, iter:183529] Loss: 1.107, 8.003, 49.984, 363.712, 0.536
[epoch:235, iter:183549] Loss: 1.106, 8.004, 49.992, 363.766, 0.420
[epoch:235, iter:183569] Loss: 1.106, 8.006, 49.988, 363.770, 0.669
Epoch: [234][600/782]	Time 0.102 (0.094)	Data 0.003 (0.003)	Loss 8.9176 (9.3318)	Acc@1 84.375 (81.416)	Acc@5 98.438 (97.101)
[epoch:235, iter:183589] Loss: 1.106, 8.005, 49.991, 363.808, 0.528
[epoch:235, iter:183609] Loss: 1.105, 8.004, 49.987, 363.819, 0.672
[epoch:235, iter:183629] Loss: 1.105, 8.003, 49.984, 363.811, 0.785
[epoch:235, iter:183649] Loss: 1.105, 8.002, 49.982, 363.821, 0.516
[epoch:235, iter:183669] Loss: 1.105, 8.002, 49.989, 363.831, 0.332
Epoch: [234][700/782]	Time 0.091 (0.094)	Data 0.002 (0.003)	Loss 9.3215 (9.3334)	Acc@1 76.562 (81.246)	Acc@5 95.312 (97.096)
[epoch:235, iter:183689] Loss: 1.105, 8.004, 49.980, 363.784, 0.662
[epoch:235, iter:183709] Loss: 1.105, 8.005, 49.994, 363.830, 0.969
[epoch:235, iter:183729] Loss: 1.106, 8.005, 49.997, 363.852, 0.815
[epoch:235, iter:183749] Loss: 1.106, 8.005, 49.998, 363.860, 0.856
[epoch:235, iter:183769] Loss: 1.105, 8.003, 49.983, 363.808, 0.702
 * Acc@1 81.202 Acc@5 97.076
epoch 234, total time 73.43
Test: [0/313]	Time 0.311 (0.311)	Loss 1.3337 (1.3337)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2721 (1.1694)	Acc@1 62.500 (70.792)	Acc@5 96.875 (92.296)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7010 (1.1339)	Acc@1 78.125 (71.331)	Acc@5 100.000 (92.677)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4142 (1.1450)	Acc@1 65.625 (71.096)	Acc@5 90.625 (92.784)
 * Acc@1 71.220 Acc@5 92.850
==> training...
Epoch: [235][0/782]	Time 0.608 (0.608)	Data 0.512 (0.512)	Loss 9.3230 (9.3230)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
[epoch:236, iter:183771] Loss: 1.099, 7.990, 49.814, 361.009, 0.549
[epoch:236, iter:183791] Loss: 1.119, 7.981, 50.319, 365.554, 0.535
[epoch:236, iter:183811] Loss: 1.115, 7.991, 50.097, 364.709, 0.610
[epoch:236, iter:183831] Loss: 1.106, 8.018, 50.038, 364.738, 0.561
[epoch:236, iter:183851] Loss: 1.103, 8.021, 49.984, 364.423, 0.646
Epoch: [235][100/782]	Time 0.091 (0.095)	Data 0.002 (0.008)	Loss 9.6768 (9.3629)	Acc@1 79.688 (81.204)	Acc@5 93.750 (96.658)
[epoch:236, iter:183871] Loss: 1.105, 8.028, 50.034, 364.555, 0.762
[epoch:236, iter:183891] Loss: 1.104, 8.022, 49.997, 364.359, 0.625
[epoch:236, iter:183911] Loss: 1.105, 8.028, 50.004, 364.258, 0.527
[epoch:236, iter:183931] Loss: 1.105, 8.028, 49.994, 364.190, 0.552
[epoch:236, iter:183951] Loss: 1.103, 8.025, 49.993, 364.192, 0.700
Epoch: [235][200/782]	Time 0.088 (0.093)	Data 0.002 (0.005)	Loss 9.1372 (9.3680)	Acc@1 79.688 (80.924)	Acc@5 93.750 (96.766)
[epoch:236, iter:183971] Loss: 1.103, 8.016, 50.012, 364.121, 0.761
[epoch:236, iter:183991] Loss: 1.104, 8.016, 50.019, 364.045, 0.650
[epoch:236, iter:184011] Loss: 1.106, 8.018, 50.022, 363.987, 0.642
[epoch:236, iter:184031] Loss: 1.105, 8.020, 50.017, 363.949, 0.573
[epoch:236, iter:184051] Loss: 1.105, 8.021, 50.031, 364.030, 0.432
Epoch: [235][300/782]	Time 0.092 (0.093)	Data 0.003 (0.004)	Loss 8.5091 (9.3579)	Acc@1 89.062 (81.074)	Acc@5 98.438 (96.808)
[epoch:236, iter:184071] Loss: 1.106, 8.021, 50.042, 364.043, 0.452
[epoch:236, iter:184091] Loss: 1.106, 8.021, 50.040, 364.076, 0.736
[epoch:236, iter:184111] Loss: 1.106, 8.020, 50.040, 364.089, 0.725
[epoch:236, iter:184131] Loss: 1.106, 8.017, 50.041, 364.072, 0.645
[epoch:236, iter:184151] Loss: 1.106, 8.012, 50.015, 363.934, 0.799
Epoch: [235][400/782]	Time 0.087 (0.092)	Data 0.002 (0.004)	Loss 9.3848 (9.3460)	Acc@1 75.000 (81.102)	Acc@5 96.875 (96.937)
[epoch:236, iter:184171] Loss: 1.106, 8.013, 49.991, 363.820, 0.753
[epoch:236, iter:184191] Loss: 1.106, 8.015, 49.992, 363.864, 0.955
[epoch:236, iter:184211] Loss: 1.106, 8.016, 49.982, 363.860, 0.547
[epoch:236, iter:184231] Loss: 1.106, 8.019, 49.986, 363.842, 0.779
[epoch:236, iter:184251] Loss: 1.106, 8.018, 49.989, 363.852, 0.491
Epoch: [235][500/782]	Time 0.093 (0.091)	Data 0.002 (0.004)	Loss 9.3919 (9.3512)	Acc@1 84.375 (81.050)	Acc@5 96.875 (97.012)
[epoch:236, iter:184271] Loss: 1.106, 8.017, 49.991, 363.800, 0.571
[epoch:236, iter:184291] Loss: 1.106, 8.016, 49.990, 363.816, 0.699
[epoch:236, iter:184311] Loss: 1.106, 8.018, 49.984, 363.776, 0.733
[epoch:236, iter:184331] Loss: 1.106, 8.017, 49.994, 363.803, 0.501
[epoch:236, iter:184351] Loss: 1.106, 8.016, 49.987, 363.750, 0.453
Epoch: [235][600/782]	Time 0.070 (0.091)	Data 0.002 (0.003)	Loss 8.7235 (9.3458)	Acc@1 85.938 (81.133)	Acc@5 100.000 (97.002)
[epoch:236, iter:184371] Loss: 1.105, 8.015, 49.978, 363.725, 0.426
[epoch:236, iter:184391] Loss: 1.105, 8.012, 49.967, 363.684, 0.737
[epoch:236, iter:184411] Loss: 1.105, 8.013, 49.956, 363.597, 0.788
[epoch:236, iter:184431] Loss: 1.105, 8.013, 49.968, 363.691, 0.363
[epoch:236, iter:184451] Loss: 1.105, 8.011, 49.966, 363.693, 0.884
Epoch: [235][700/782]	Time 0.097 (0.090)	Data 0.002 (0.003)	Loss 9.5769 (9.3366)	Acc@1 73.438 (81.228)	Acc@5 93.750 (97.031)
[epoch:236, iter:184471] Loss: 1.104, 8.011, 49.958, 363.650, 0.779
[epoch:236, iter:184491] Loss: 1.105, 8.011, 49.973, 363.684, 0.620
[epoch:236, iter:184511] Loss: 1.105, 8.009, 49.976, 363.676, 0.810
[epoch:236, iter:184531] Loss: 1.105, 8.009, 49.971, 363.654, 0.632
[epoch:236, iter:184551] Loss: 1.105, 8.006, 49.971, 363.652, 0.480
 * Acc@1 81.180 Acc@5 97.050
epoch 235, total time 71.32
Test: [0/313]	Time 0.252 (0.252)	Loss 1.3172 (1.3172)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.1835 (1.1713)	Acc@1 65.625 (71.040)	Acc@5 96.875 (92.079)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.6765 (1.1339)	Acc@1 81.250 (71.486)	Acc@5 100.000 (92.568)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4588 (1.1479)	Acc@1 62.500 (71.159)	Acc@5 96.875 (92.660)
 * Acc@1 71.290 Acc@5 92.700
==> training...
Epoch: [236][0/782]	Time 0.576 (0.576)	Data 0.500 (0.500)	Loss 9.6930 (9.6930)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
[epoch:237, iter:184553] Loss: 1.049, 8.063, 50.118, 371.804, 0.883
[epoch:237, iter:184573] Loss: 1.107, 8.013, 50.367, 365.541, 0.482
[epoch:237, iter:184593] Loss: 1.100, 7.994, 50.158, 364.845, 0.863
[epoch:237, iter:184613] Loss: 1.102, 7.987, 49.928, 363.582, 0.719
[epoch:237, iter:184633] Loss: 1.103, 7.981, 49.824, 363.076, 0.611
Epoch: [236][100/782]	Time 0.075 (0.092)	Data 0.002 (0.007)	Loss 8.9181 (9.3122)	Acc@1 82.812 (80.956)	Acc@5 96.875 (97.045)
[epoch:237, iter:184653] Loss: 1.101, 8.000, 49.876, 363.502, 0.494
[epoch:237, iter:184673] Loss: 1.102, 8.002, 49.877, 363.297, 0.540
[epoch:237, iter:184693] Loss: 1.103, 8.011, 49.876, 363.250, 0.653
[epoch:237, iter:184713] Loss: 1.103, 8.013, 49.891, 363.327, 0.463
[epoch:237, iter:184733] Loss: 1.104, 8.014, 49.924, 363.428, 0.648
Epoch: [236][200/782]	Time 0.085 (0.090)	Data 0.002 (0.005)	Loss 8.8006 (9.3282)	Acc@1 90.625 (80.939)	Acc@5 100.000 (97.100)
[epoch:237, iter:184753] Loss: 1.105, 8.014, 49.933, 363.403, 0.343
[epoch:237, iter:184773] Loss: 1.107, 8.020, 49.963, 363.637, 0.389
[epoch:237, iter:184793] Loss: 1.108, 8.022, 50.006, 363.761, 0.366
[epoch:237, iter:184813] Loss: 1.108, 8.023, 50.042, 363.928, 0.605
[epoch:237, iter:184833] Loss: 1.108, 8.022, 50.052, 363.976, 0.759
Epoch: [236][300/782]	Time 0.088 (0.089)	Data 0.002 (0.004)	Loss 9.2387 (9.3574)	Acc@1 79.688 (80.663)	Acc@5 98.438 (96.994)
[epoch:237, iter:184853] Loss: 1.107, 8.019, 50.049, 363.975, 0.539
[epoch:237, iter:184873] Loss: 1.107, 8.019, 50.050, 363.997, 0.505
[epoch:237, iter:184893] Loss: 1.107, 8.020, 50.040, 363.949, 0.963
[epoch:237, iter:184913] Loss: 1.107, 8.017, 50.027, 363.813, 0.608
[epoch:237, iter:184933] Loss: 1.107, 8.019, 50.016, 363.757, 0.545
Epoch: [236][400/782]	Time 0.089 (0.086)	Data 0.002 (0.004)	Loss 8.9684 (9.3524)	Acc@1 84.375 (80.677)	Acc@5 96.875 (96.941)
[epoch:237, iter:184953] Loss: 1.108, 8.021, 50.039, 363.865, 0.465
[epoch:237, iter:184973] Loss: 1.108, 8.019, 50.020, 363.760, 0.642
[epoch:237, iter:184993] Loss: 1.109, 8.018, 50.036, 363.830, 0.592
[epoch:237, iter:185013] Loss: 1.108, 8.017, 50.031, 363.811, 0.587
[epoch:237, iter:185033] Loss: 1.107, 8.018, 50.036, 363.890, 0.635
Epoch: [236][500/782]	Time 0.075 (0.088)	Data 0.002 (0.003)	Loss 8.6449 (9.3468)	Acc@1 90.625 (80.873)	Acc@5 100.000 (96.984)
[epoch:237, iter:185053] Loss: 1.107, 8.018, 50.030, 363.850, 0.277
[epoch:237, iter:185073] Loss: 1.107, 8.020, 50.037, 363.903, 0.492
[epoch:237, iter:185093] Loss: 1.107, 8.016, 50.012, 363.792, 0.564
[epoch:237, iter:185113] Loss: 1.107, 8.016, 50.016, 363.767, 0.777
[epoch:237, iter:185133] Loss: 1.107, 8.015, 50.007, 363.729, 0.683
Epoch: [236][600/782]	Time 0.105 (0.089)	Data 0.003 (0.003)	Loss 9.8524 (9.3397)	Acc@1 82.812 (81.081)	Acc@5 96.875 (96.995)
[epoch:237, iter:185153] Loss: 1.107, 8.014, 50.008, 363.720, 0.794
[epoch:237, iter:185173] Loss: 1.107, 8.016, 50.000, 363.728, 0.621
[epoch:237, iter:185193] Loss: 1.106, 8.014, 49.974, 363.638, 0.693
[epoch:237, iter:185213] Loss: 1.106, 8.012, 49.973, 363.644, 1.066
[epoch:237, iter:185233] Loss: 1.106, 8.013, 49.976, 363.633, 0.641
Epoch: [236][700/782]	Time 0.079 (0.090)	Data 0.002 (0.003)	Loss 9.2965 (9.3347)	Acc@1 85.938 (81.023)	Acc@5 98.438 (96.993)
[epoch:237, iter:185253] Loss: 1.106, 8.014, 49.965, 363.588, 0.529
[epoch:237, iter:185273] Loss: 1.106, 8.016, 49.961, 363.602, 0.770
[epoch:237, iter:185293] Loss: 1.106, 8.014, 49.971, 363.670, 0.653
[epoch:237, iter:185313] Loss: 1.106, 8.015, 49.970, 363.669, 0.601
[epoch:237, iter:185333] Loss: 1.106, 8.014, 49.971, 363.669, 0.406
 * Acc@1 81.066 Acc@5 96.976
epoch 236, total time 69.88
Test: [0/313]	Time 0.302 (0.302)	Loss 1.3372 (1.3372)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2628 (1.1718)	Acc@1 59.375 (70.545)	Acc@5 96.875 (92.048)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.7150 (1.1343)	Acc@1 75.000 (71.082)	Acc@5 100.000 (92.693)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4066 (1.1469)	Acc@1 65.625 (70.909)	Acc@5 96.875 (92.784)
 * Acc@1 71.080 Acc@5 92.840
==> training...
Epoch: [237][0/782]	Time 0.525 (0.525)	Data 0.434 (0.434)	Loss 8.8198 (8.8198)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
[epoch:238, iter:185335] Loss: 1.149, 7.864, 48.605, 357.190, 0.320
[epoch:238, iter:185355] Loss: 1.126, 7.979, 50.046, 362.983, 0.553
[epoch:238, iter:185375] Loss: 1.115, 7.995, 49.885, 363.112, 0.658
[epoch:238, iter:185395] Loss: 1.114, 8.019, 49.964, 363.456, 0.641
[epoch:238, iter:185415] Loss: 1.114, 8.022, 50.036, 363.709, 0.566
Epoch: [237][100/782]	Time 0.105 (0.105)	Data 0.002 (0.007)	Loss 9.3773 (9.3263)	Acc@1 82.812 (81.250)	Acc@5 95.312 (97.045)
[epoch:238, iter:185435] Loss: 1.114, 8.038, 50.104, 364.070, 0.677
[epoch:238, iter:185455] Loss: 1.113, 8.035, 50.106, 364.008, 0.502
[epoch:238, iter:185475] Loss: 1.111, 8.024, 50.087, 364.096, 0.639
[epoch:238, iter:185495] Loss: 1.111, 8.029, 50.112, 364.203, 0.483
[epoch:238, iter:185515] Loss: 1.112, 8.031, 50.124, 364.205, 0.666
Epoch: [237][200/782]	Time 0.086 (0.103)	Data 0.003 (0.005)	Loss 9.1258 (9.3578)	Acc@1 84.375 (81.172)	Acc@5 96.875 (96.844)
[epoch:238, iter:185535] Loss: 1.113, 8.028, 50.130, 364.165, 0.547
[epoch:238, iter:185555] Loss: 1.114, 8.033, 50.160, 364.214, 0.596
[epoch:238, iter:185575] Loss: 1.114, 8.035, 50.182, 364.431, 0.442
[epoch:238, iter:185595] Loss: 1.113, 8.034, 50.176, 364.405, 0.732
[epoch:238, iter:185615] Loss: 1.114, 8.024, 50.159, 364.251, 0.587
Epoch: [237][300/782]	Time 0.093 (0.100)	Data 0.003 (0.004)	Loss 10.1616 (9.3746)	Acc@1 79.688 (80.996)	Acc@5 98.438 (96.776)
[epoch:238, iter:185635] Loss: 1.114, 8.029, 50.170, 364.345, 0.638
[epoch:238, iter:185655] Loss: 1.114, 8.029, 50.185, 364.456, 0.692
[epoch:238, iter:185675] Loss: 1.113, 8.027, 50.171, 364.395, 0.532
[epoch:238, iter:185695] Loss: 1.112, 8.026, 50.146, 364.294, 0.367
[epoch:238, iter:185715] Loss: 1.112, 8.024, 50.134, 364.237, 0.467
Epoch: [237][400/782]	Time 0.090 (0.098)	Data 0.003 (0.004)	Loss 8.6930 (9.3683)	Acc@1 82.812 (80.853)	Acc@5 98.438 (96.898)
[epoch:238, iter:185735] Loss: 1.110, 8.027, 50.116, 364.156, 0.441
[epoch:238, iter:185755] Loss: 1.110, 8.026, 50.120, 364.135, 0.594
[epoch:238, iter:185775] Loss: 1.111, 8.027, 50.134, 364.160, 0.428
[epoch:238, iter:185795] Loss: 1.111, 8.026, 50.133, 364.117, 0.550
[epoch:238, iter:185815] Loss: 1.111, 8.025, 50.119, 364.058, 0.575
Epoch: [237][500/782]	Time 0.066 (0.094)	Data 0.002 (0.003)	Loss 9.1631 (9.3718)	Acc@1 81.250 (80.807)	Acc@5 98.438 (96.884)
[epoch:238, iter:185835] Loss: 1.110, 8.025, 50.131, 364.160, 0.511
[epoch:238, iter:185855] Loss: 1.110, 8.027, 50.136, 364.167, 0.363
[epoch:238, iter:185875] Loss: 1.110, 8.028, 50.127, 364.079, 0.536
[epoch:238, iter:185895] Loss: 1.109, 8.027, 50.102, 364.005, 0.731
[epoch:238, iter:185915] Loss: 1.109, 8.025, 50.095, 363.965, 0.630
Epoch: [237][600/782]	Time 0.074 (0.091)	Data 0.002 (0.003)	Loss 9.7380 (9.3573)	Acc@1 84.375 (81.011)	Acc@5 95.312 (96.935)
[epoch:238, iter:185935] Loss: 1.109, 8.024, 50.100, 363.982, 0.584
[epoch:238, iter:185955] Loss: 1.109, 8.024, 50.095, 363.990, 0.802
[epoch:238, iter:185975] Loss: 1.109, 8.022, 50.086, 363.988, 0.499
[epoch:238, iter:185995] Loss: 1.109, 8.023, 50.081, 363.995, 0.614
[epoch:238, iter:186015] Loss: 1.109, 8.023, 50.090, 364.079, 0.464
Epoch: [237][700/782]	Time 0.081 (0.089)	Data 0.002 (0.003)	Loss 8.9369 (9.3520)	Acc@1 81.250 (81.012)	Acc@5 98.438 (96.955)
[epoch:238, iter:186035] Loss: 1.108, 8.025, 50.080, 364.069, 0.539
[epoch:238, iter:186055] Loss: 1.108, 8.025, 50.077, 364.067, 0.395
[epoch:238, iter:186075] Loss: 1.107, 8.025, 50.067, 364.055, 0.660
[epoch:238, iter:186095] Loss: 1.107, 8.023, 50.072, 364.063, 0.897
[epoch:238, iter:186115] Loss: 1.107, 8.023, 50.068, 364.053, 0.542
 * Acc@1 80.980 Acc@5 96.958
epoch 237, total time 69.27
Test: [0/313]	Time 0.232 (0.232)	Loss 1.2985 (1.2985)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.008)	Loss 1.3008 (1.1701)	Acc@1 59.375 (70.761)	Acc@5 96.875 (92.389)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.6957 (1.1324)	Acc@1 75.000 (71.346)	Acc@5 100.000 (92.802)
Test: [300/313]	Time 0.006 (0.006)	Loss 1.4381 (1.1444)	Acc@1 65.625 (71.148)	Acc@5 93.750 (92.909)
 * Acc@1 71.250 Acc@5 92.950
==> training...
Epoch: [238][0/782]	Time 0.553 (0.553)	Data 0.482 (0.482)	Loss 8.8740 (8.8740)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
[epoch:239, iter:186117] Loss: 1.116, 7.734, 49.463, 354.273, 0.435
[epoch:239, iter:186137] Loss: 1.093, 8.021, 50.013, 364.696, 0.714
[epoch:239, iter:186157] Loss: 1.103, 8.019, 50.051, 364.122, 0.663
[epoch:239, iter:186177] Loss: 1.106, 8.007, 50.138, 364.447, 0.422
[epoch:239, iter:186197] Loss: 1.106, 8.014, 50.119, 364.274, 0.781
Epoch: [238][100/782]	Time 0.086 (0.089)	Data 0.003 (0.007)	Loss 9.1491 (9.3658)	Acc@1 81.250 (80.554)	Acc@5 95.312 (96.829)
[epoch:239, iter:186217] Loss: 1.107, 8.010, 50.152, 364.483, 0.665
[epoch:239, iter:186237] Loss: 1.107, 8.001, 50.132, 364.446, 0.493
[epoch:239, iter:186257] Loss: 1.106, 7.995, 50.117, 364.386, 0.560
[epoch:239, iter:186277] Loss: 1.105, 7.994, 50.051, 364.122, 0.440
[epoch:239, iter:186297] Loss: 1.103, 7.994, 50.058, 364.191, 0.816
Epoch: [238][200/782]	Time 0.089 (0.089)	Data 0.003 (0.005)	Loss 9.9016 (9.3449)	Acc@1 81.250 (80.986)	Acc@5 96.875 (97.023)
[epoch:239, iter:186317] Loss: 1.105, 7.996, 50.046, 364.093, 0.694
[epoch:239, iter:186337] Loss: 1.104, 8.001, 50.020, 364.039, 0.634
[epoch:239, iter:186357] Loss: 1.103, 8.005, 50.014, 364.066, 0.900
[epoch:239, iter:186377] Loss: 1.103, 8.010, 50.089, 364.414, 0.715
[epoch:239, iter:186397] Loss: 1.102, 8.011, 50.061, 364.359, 0.877
Epoch: [238][300/782]	Time 0.086 (0.089)	Data 0.002 (0.004)	Loss 9.4875 (9.3527)	Acc@1 79.688 (81.042)	Acc@5 96.875 (96.865)
[epoch:239, iter:186417] Loss: 1.101, 8.013, 50.031, 364.215, 0.577
[epoch:239, iter:186437] Loss: 1.102, 8.013, 50.053, 364.316, 0.634
[epoch:239, iter:186457] Loss: 1.102, 8.008, 50.029, 364.208, 0.566
[epoch:239, iter:186477] Loss: 1.102, 8.008, 50.016, 364.074, 0.515
[epoch:239, iter:186497] Loss: 1.102, 8.009, 50.029, 364.115, 0.880
Epoch: [238][400/782]	Time 0.080 (0.089)	Data 0.002 (0.004)	Loss 9.1836 (9.3446)	Acc@1 81.250 (81.125)	Acc@5 98.438 (96.949)
[epoch:239, iter:186517] Loss: 1.103, 8.007, 50.017, 364.033, 0.618
[epoch:239, iter:186537] Loss: 1.103, 8.007, 50.002, 363.953, 0.629
[epoch:239, iter:186557] Loss: 1.103, 8.008, 49.973, 363.835, 0.692
[epoch:239, iter:186577] Loss: 1.103, 8.005, 49.955, 363.726, 0.611
[epoch:239, iter:186597] Loss: 1.103, 8.006, 49.941, 363.669, 0.739
Epoch: [238][500/782]	Time 0.073 (0.090)	Data 0.002 (0.003)	Loss 9.2336 (9.3249)	Acc@1 81.250 (81.194)	Acc@5 96.875 (96.959)
[epoch:239, iter:186617] Loss: 1.103, 8.005, 49.939, 363.681, 0.569
[epoch:239, iter:186637] Loss: 1.102, 8.005, 49.931, 363.659, 0.732
[epoch:239, iter:186657] Loss: 1.102, 8.004, 49.936, 363.644, 0.571
[epoch:239, iter:186677] Loss: 1.103, 8.003, 49.941, 363.635, 0.507
[epoch:239, iter:186697] Loss: 1.103, 8.005, 49.945, 363.648, 0.772
Epoch: [238][600/782]	Time 0.084 (0.089)	Data 0.003 (0.003)	Loss 9.0037 (9.3282)	Acc@1 81.250 (81.136)	Acc@5 98.438 (96.995)
[epoch:239, iter:186717] Loss: 1.103, 8.004, 49.950, 363.628, 0.491
[epoch:239, iter:186737] Loss: 1.103, 8.003, 49.956, 363.614, 0.561
[epoch:239, iter:186757] Loss: 1.103, 8.006, 49.963, 363.690, 0.544
[epoch:239, iter:186777] Loss: 1.103, 8.005, 49.948, 363.610, 0.798
[epoch:239, iter:186797] Loss: 1.103, 8.004, 49.934, 363.551, 0.744
Epoch: [238][700/782]	Time 0.093 (0.089)	Data 0.002 (0.003)	Loss 9.4980 (9.3268)	Acc@1 76.562 (81.087)	Acc@5 96.875 (96.978)
[epoch:239, iter:186817] Loss: 1.103, 8.004, 49.932, 363.511, 0.728
[epoch:239, iter:186837] Loss: 1.103, 8.006, 49.936, 363.521, 0.534
[epoch:239, iter:186857] Loss: 1.104, 8.005, 49.947, 363.572, 0.679
[epoch:239, iter:186877] Loss: 1.104, 8.005, 49.955, 363.618, 0.674
[epoch:239, iter:186897] Loss: 1.104, 8.005, 49.956, 363.608, 0.581
 * Acc@1 81.104 Acc@5 96.976
epoch 238, total time 69.73
Test: [0/313]	Time 0.324 (0.324)	Loss 1.3175 (1.3175)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.006 (0.010)	Loss 1.2529 (1.1649)	Acc@1 56.250 (71.225)	Acc@5 96.875 (91.894)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7151 (1.1278)	Acc@1 75.000 (71.533)	Acc@5 100.000 (92.444)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3739 (1.1392)	Acc@1 65.625 (71.242)	Acc@5 93.750 (92.691)
 * Acc@1 71.330 Acc@5 92.750
==> training...
Epoch: [239][0/782]	Time 0.563 (0.563)	Data 0.481 (0.481)	Loss 9.3389 (9.3389)	Acc@1 90.625 (90.625)	Acc@5 95.312 (95.312)
[epoch:240, iter:186899] Loss: 1.114, 7.953, 50.690, 372.409, 0.510
[epoch:240, iter:186919] Loss: 1.100, 7.958, 50.118, 363.193, 0.566
[epoch:240, iter:186939] Loss: 1.099, 7.994, 50.087, 363.599, 0.554
[epoch:240, iter:186959] Loss: 1.105, 8.003, 50.101, 363.536, 0.358
[epoch:240, iter:186979] Loss: 1.104, 7.996, 50.070, 363.504, 0.504
Epoch: [239][100/782]	Time 0.073 (0.092)	Data 0.002 (0.007)	Loss 9.6616 (9.3329)	Acc@1 79.688 (81.853)	Acc@5 93.750 (96.844)
[epoch:240, iter:186999] Loss: 1.103, 8.003, 50.002, 363.293, 0.757
[epoch:240, iter:187019] Loss: 1.106, 8.022, 50.041, 363.540, 0.558
[epoch:240, iter:187039] Loss: 1.105, 8.024, 50.054, 363.815, 0.260
[epoch:240, iter:187059] Loss: 1.105, 8.017, 50.073, 363.881, 0.345
[epoch:240, iter:187079] Loss: 1.106, 8.018, 50.076, 363.893, 0.448
Epoch: [239][200/782]	Time 0.073 (0.085)	Data 0.002 (0.005)	Loss 9.2542 (9.3472)	Acc@1 85.938 (81.483)	Acc@5 96.875 (96.968)
[epoch:240, iter:187099] Loss: 1.106, 8.013, 50.064, 363.842, 0.530
[epoch:240, iter:187119] Loss: 1.106, 8.019, 50.055, 363.918, 0.648
[epoch:240, iter:187139] Loss: 1.107, 8.019, 50.070, 364.028, 0.572
[epoch:240, iter:187159] Loss: 1.107, 8.019, 50.071, 364.048, 0.578
[epoch:240, iter:187179] Loss: 1.106, 8.017, 50.041, 363.962, 0.482
Epoch: [239][300/782]	Time 0.076 (0.082)	Data 0.002 (0.004)	Loss 9.0250 (9.3373)	Acc@1 79.688 (81.333)	Acc@5 98.438 (97.124)
[epoch:240, iter:187199] Loss: 1.105, 8.014, 50.021, 363.888, 0.619
[epoch:240, iter:187219] Loss: 1.105, 8.013, 50.031, 363.963, 0.533
[epoch:240, iter:187239] Loss: 1.105, 8.011, 50.039, 363.984, 0.459
[epoch:240, iter:187259] Loss: 1.106, 8.008, 50.038, 363.995, 0.666
[epoch:240, iter:187279] Loss: 1.106, 8.006, 50.032, 363.945, 0.444
Epoch: [239][400/782]	Time 0.071 (0.082)	Data 0.002 (0.003)	Loss 9.0093 (9.3370)	Acc@1 87.500 (81.402)	Acc@5 98.438 (97.148)
[epoch:240, iter:187299] Loss: 1.106, 8.004, 50.032, 363.921, 0.509
[epoch:240, iter:187319] Loss: 1.107, 8.009, 50.042, 363.921, 0.517
[epoch:240, iter:187339] Loss: 1.107, 8.007, 50.040, 363.913, 0.601
[epoch:240, iter:187359] Loss: 1.106, 8.008, 50.030, 363.832, 0.595
[epoch:240, iter:187379] Loss: 1.107, 8.006, 50.024, 363.750, 0.625
Epoch: [239][500/782]	Time 0.070 (0.081)	Data 0.002 (0.003)	Loss 9.5385 (9.3377)	Acc@1 73.438 (81.281)	Acc@5 96.875 (97.037)
[epoch:240, iter:187399] Loss: 1.107, 8.007, 50.037, 363.818, 0.720
[epoch:240, iter:187419] Loss: 1.107, 8.008, 50.033, 363.840, 0.632
[epoch:240, iter:187439] Loss: 1.106, 8.007, 50.024, 363.784, 0.512
[epoch:240, iter:187459] Loss: 1.107, 8.009, 50.013, 363.716, 0.607
[epoch:240, iter:187479] Loss: 1.107, 8.011, 50.044, 363.889, 0.804
Epoch: [239][600/782]	Time 0.072 (0.080)	Data 0.002 (0.003)	Loss 9.0115 (9.3428)	Acc@1 84.375 (81.284)	Acc@5 100.000 (97.099)
[epoch:240, iter:187499] Loss: 1.108, 8.013, 50.059, 363.968, 0.568
[epoch:240, iter:187519] Loss: 1.108, 8.015, 50.051, 363.878, 0.667
[epoch:240, iter:187539] Loss: 1.108, 8.016, 50.049, 363.929, 0.569
[epoch:240, iter:187559] Loss: 1.107, 8.015, 50.040, 363.868, 0.922
[epoch:240, iter:187579] Loss: 1.107, 8.017, 50.033, 363.845, 0.642
Epoch: [239][700/782]	Time 0.073 (0.079)	Data 0.002 (0.003)	Loss 9.1186 (9.3390)	Acc@1 87.500 (81.306)	Acc@5 98.438 (97.051)
[epoch:240, iter:187599] Loss: 1.107, 8.017, 50.039, 363.839, 0.443
[epoch:240, iter:187619] Loss: 1.107, 8.018, 50.041, 363.856, 0.814
[epoch:240, iter:187639] Loss: 1.107, 8.018, 50.043, 363.847, 0.651
[epoch:240, iter:187659] Loss: 1.107, 8.017, 50.038, 363.850, 0.399
[epoch:240, iter:187679] Loss: 1.107, 8.018, 50.049, 363.881, 0.567
 * Acc@1 81.300 Acc@5 97.046
epoch 239, total time 62.86
Test: [0/313]	Time 0.265 (0.265)	Loss 1.2528 (1.2528)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/313]	Time 0.006 (0.009)	Loss 1.2741 (1.1751)	Acc@1 62.500 (70.637)	Acc@5 96.875 (92.234)
Test: [200/313]	Time 0.006 (0.007)	Loss 0.6980 (1.1418)	Acc@1 75.000 (71.160)	Acc@5 100.000 (92.631)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.4373 (1.1548)	Acc@1 65.625 (70.920)	Acc@5 96.875 (92.712)
 * Acc@1 71.080 Acc@5 92.770
==> training...
Epoch: [240][0/782]	Time 0.529 (0.529)	Data 0.450 (0.450)	Loss 8.8516 (8.8516)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
[epoch:241, iter:187681] Loss: 1.055, 7.952, 48.026, 350.497, 0.535
[epoch:241, iter:187701] Loss: 1.120, 8.033, 50.223, 364.299, 0.690
[epoch:241, iter:187721] Loss: 1.109, 8.023, 50.116, 364.205, 0.462
[epoch:241, iter:187741] Loss: 1.110, 8.026, 50.113, 364.122, 0.837
[epoch:241, iter:187761] Loss: 1.111, 8.024, 50.074, 363.792, 0.469
Epoch: [240][100/782]	Time 0.092 (0.098)	Data 0.003 (0.007)	Loss 9.6663 (9.3882)	Acc@1 81.250 (80.616)	Acc@5 96.875 (96.890)
[epoch:241, iter:187781] Loss: 1.111, 8.033, 50.089, 364.144, 0.736
[epoch:241, iter:187801] Loss: 1.112, 8.048, 50.141, 364.388, 0.346
[epoch:241, iter:187821] Loss: 1.111, 8.040, 50.106, 364.214, 0.538
[epoch:241, iter:187841] Loss: 1.112, 8.039, 50.125, 364.150, 0.714
[epoch:241, iter:187861] Loss: 1.111, 8.035, 50.075, 363.902, 0.645
Epoch: [240][200/782]	Time 0.090 (0.091)	Data 0.003 (0.005)	Loss 9.9849 (9.3670)	Acc@1 75.000 (80.978)	Acc@5 93.750 (97.007)
[epoch:241, iter:187881] Loss: 1.111, 8.030, 50.102, 364.008, 0.850
[epoch:241, iter:187901] Loss: 1.111, 8.028, 50.083, 363.964, 0.613
[epoch:241, iter:187921] Loss: 1.111, 8.025, 50.063, 363.935, 0.649
[epoch:241, iter:187941] Loss: 1.110, 8.031, 50.054, 363.917, 0.597
[epoch:241, iter:187961] Loss: 1.111, 8.036, 50.087, 364.096, 0.684
Epoch: [240][300/782]	Time 0.107 (0.093)	Data 0.003 (0.004)	Loss 10.0093 (9.3621)	Acc@1 81.250 (80.876)	Acc@5 93.750 (97.015)
[epoch:241, iter:187981] Loss: 1.109, 8.034, 50.055, 364.016, 0.623
[epoch:241, iter:188001] Loss: 1.109, 8.037, 50.089, 364.155, 0.649
[epoch:241, iter:188021] Loss: 1.108, 8.033, 50.076, 364.084, 0.667
[epoch:241, iter:188041] Loss: 1.109, 8.032, 50.078, 364.110, 0.705
[epoch:241, iter:188061] Loss: 1.108, 8.031, 50.055, 364.032, 0.725
Epoch: [240][400/782]	Time 0.103 (0.095)	Data 0.002 (0.004)	Loss 9.4540 (9.3520)	Acc@1 75.000 (81.075)	Acc@5 96.875 (97.004)
[epoch:241, iter:188081] Loss: 1.108, 8.030, 50.038, 363.960, 0.779
[epoch:241, iter:188101] Loss: 1.108, 8.028, 50.050, 363.985, 0.620
[epoch:241, iter:188121] Loss: 1.109, 8.028, 50.062, 363.965, 0.512
[epoch:241, iter:188141] Loss: 1.109, 8.026, 50.066, 363.948, 0.473
[epoch:241, iter:188161] Loss: 1.109, 8.025, 50.074, 363.985, 0.512
Epoch: [240][500/782]	Time 0.102 (0.096)	Data 0.003 (0.003)	Loss 9.2864 (9.3624)	Acc@1 78.125 (80.891)	Acc@5 96.875 (97.025)
[epoch:241, iter:188181] Loss: 1.108, 8.028, 50.076, 364.045, 0.721
[epoch:241, iter:188201] Loss: 1.108, 8.027, 50.053, 363.950, 0.631
[epoch:241, iter:188221] Loss: 1.107, 8.027, 50.040, 363.888, 0.913
[epoch:241, iter:188241] Loss: 1.107, 8.026, 50.026, 363.818, 0.475
[epoch:241, iter:188261] Loss: 1.107, 8.027, 50.020, 363.727, 0.473
Epoch: [240][600/782]	Time 0.109 (0.095)	Data 0.003 (0.003)	Loss 9.5117 (9.3468)	Acc@1 81.250 (80.964)	Acc@5 96.875 (96.984)
[epoch:241, iter:188281] Loss: 1.107, 8.025, 50.013, 363.665, 0.740
[epoch:241, iter:188301] Loss: 1.107, 8.022, 50.017, 363.642, 0.612
[epoch:241, iter:188321] Loss: 1.107, 8.021, 50.022, 363.632, 0.552
[epoch:241, iter:188341] Loss: 1.107, 8.022, 50.019, 363.656, 0.854
[epoch:241, iter:188361] Loss: 1.107, 8.020, 49.999, 363.582, 0.576
Epoch: [240][700/782]	Time 0.093 (0.095)	Data 0.003 (0.003)	Loss 9.9420 (9.3453)	Acc@1 78.125 (80.916)	Acc@5 95.312 (96.966)
[epoch:241, iter:188381] Loss: 1.107, 8.021, 50.005, 363.668, 0.828
[epoch:241, iter:188401] Loss: 1.106, 8.021, 50.010, 363.694, 0.477
[epoch:241, iter:188421] Loss: 1.107, 8.018, 50.017, 363.709, 0.733
[epoch:241, iter:188441] Loss: 1.107, 8.017, 50.033, 363.806, 0.582
[epoch:241, iter:188461] Loss: 1.107, 8.018, 50.043, 363.831, 0.726
 * Acc@1 81.008 Acc@5 97.000
epoch 240, total time 74.12
Test: [0/313]	Time 0.272 (0.272)	Loss 1.3036 (1.3036)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/313]	Time 0.008 (0.009)	Loss 1.3290 (1.1730)	Acc@1 56.250 (70.761)	Acc@5 93.750 (92.079)
Test: [200/313]	Time 0.006 (0.008)	Loss 0.7277 (1.1369)	Acc@1 75.000 (71.222)	Acc@5 100.000 (92.646)
Test: [300/313]	Time 0.006 (0.007)	Loss 1.3562 (1.1476)	Acc@1 62.500 (70.930)	Acc@5 93.750 (92.743)
 * Acc@1 71.060 Acc@5 92.800
==> Saving...
best accuracy: tensor(71.3900, device='cuda:0')
