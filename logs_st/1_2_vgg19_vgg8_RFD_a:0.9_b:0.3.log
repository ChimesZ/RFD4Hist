==> loading teacher model
==> done
Test: [0/750]	Time 26.266 (26.266)	Loss 0.4634 (0.4634)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.063 (0.327)	Loss 0.5072 (0.4629)	Acc@1 84.375 (86.912)	Acc@5 96.875 (94.957)
Test: [200/750]	Time 0.067 (0.197)	Loss 1.2823 (0.4595)	Acc@1 50.000 (85.603)	Acc@5 93.750 (96.175)
Test: [300/750]	Time 0.063 (0.153)	Loss 1.0237 (0.6758)	Acc@1 65.625 (75.872)	Acc@5 93.750 (95.442)
Test: [400/750]	Time 0.058 (0.131)	Loss 0.5271 (0.7502)	Acc@1 84.375 (72.600)	Acc@5 87.500 (94.989)
Test: [500/750]	Time 0.077 (0.118)	Loss 0.5424 (0.7175)	Acc@1 75.000 (74.339)	Acc@5 100.000 (94.885)
Test: [600/750]	Time 0.065 (0.109)	Loss 0.7790 (0.7285)	Acc@1 68.750 (74.189)	Acc@5 93.750 (94.748)
Test: [700/750]	Time 0.039 (0.103)	Loss 0.7082 (0.7212)	Acc@1 68.750 (74.269)	Acc@5 96.875 (94.954)
 * Acc@1 74.571 Acc@5 94.971
teacher accuracy:  tensor(74.5708, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 2.834 (2.834)	Data 1.357 (1.357)	Loss 9.3514 (9.3514)	Loss@kd 13.9762 (13.9762)	Acc@1 14.062 (14.062)	Acc@5 67.188 (67.188)
Epoch: [1][100/875]	Time 0.535 (0.533)	Data 0.007 (0.020)	Loss 4.5213 (5.2892)	Loss@kd 4.6558 (6.5646)	Acc@1 35.938 (37.129)	Acc@5 90.625 (90.145)
Epoch: [1][200/875]	Time 0.505 (0.521)	Data 0.007 (0.014)	Loss 3.9182 (4.6746)	Loss@kd 4.1700 (5.4681)	Acc@1 37.500 (40.368)	Acc@5 90.625 (91.682)
Epoch: [1][300/875]	Time 0.520 (0.517)	Data 0.007 (0.012)	Loss 4.0711 (4.3614)	Loss@kd 3.9358 (4.9793)	Acc@1 39.062 (42.302)	Acc@5 89.062 (92.691)
Epoch: [1][400/875]	Time 0.501 (0.515)	Data 0.008 (0.011)	Loss 2.8288 (4.1577)	Loss@kd 3.5988 (4.6815)	Acc@1 53.125 (43.797)	Acc@5 95.312 (93.243)
Epoch: [1][500/875]	Time 0.515 (0.514)	Data 0.006 (0.010)	Loss 3.5624 (4.0045)	Loss@kd 3.6289 (4.4745)	Acc@1 43.750 (44.969)	Acc@5 90.625 (93.663)
Epoch: [1][600/875]	Time 0.524 (0.513)	Data 0.007 (0.009)	Loss 3.6107 (3.8840)	Loss@kd 3.7299 (4.3252)	Acc@1 53.125 (45.749)	Acc@5 100.000 (93.924)
Epoch: [1][700/875]	Time 0.425 (0.508)	Data 0.007 (0.009)	Loss 3.1399 (3.7874)	Loss@kd 3.4518 (4.2065)	Acc@1 48.438 (46.356)	Acc@5 95.312 (94.129)
Epoch: [1][800/875]	Time 0.509 (0.508)	Data 0.007 (0.009)	Loss 3.1314 (3.7028)	Loss@kd 3.4422 (4.1086)	Acc@1 50.000 (46.996)	Acc@5 95.312 (94.351)
 * Acc@1 47.455 Acc@5 94.493
epoch 1, total time 444.80
Test: [0/750]	Time 0.744 (0.744)	Loss 0.7929 (0.7929)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.028 (0.035)	Loss 1.4421 (0.6734)	Acc@1 37.500 (80.136)	Acc@5 90.625 (88.676)
Test: [200/750]	Time 0.034 (0.032)	Loss 2.1627 (0.9893)	Acc@1 18.750 (63.697)	Acc@5 78.125 (89.241)
Test: [300/750]	Time 0.021 (0.031)	Loss 1.3449 (1.2061)	Acc@1 31.250 (53.000)	Acc@5 93.750 (88.611)
Test: [400/750]	Time 0.020 (0.031)	Loss 0.7554 (1.2213)	Acc@1 84.375 (51.442)	Acc@5 96.875 (89.253)
Test: [500/750]	Time 0.038 (0.031)	Loss 1.4791 (1.1714)	Acc@1 53.125 (54.784)	Acc@5 87.500 (89.452)
Test: [600/750]	Time 0.020 (0.030)	Loss 0.9892 (1.1975)	Acc@1 71.875 (54.623)	Acc@5 87.500 (88.758)
Test: [700/750]	Time 0.019 (0.030)	Loss 1.9336 (1.2153)	Acc@1 31.250 (54.400)	Acc@5 68.750 (87.705)
 * Acc@1 53.858 Acc@5 86.729
saving the best model!
==> training...
Epoch: [2][0/875]	Time 1.922 (1.922)	Data 1.416 (1.416)	Loss 2.7158 (2.7158)	Loss@kd 3.2689 (3.2689)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [2][100/875]	Time 0.494 (0.523)	Data 0.007 (0.021)	Loss 3.0782 (3.0004)	Loss@kd 3.3145 (3.3356)	Acc@1 51.562 (53.218)	Acc@5 95.312 (96.225)
Epoch: [2][200/875]	Time 0.499 (0.516)	Data 0.007 (0.014)	Loss 2.8859 (2.9688)	Loss@kd 3.2287 (3.3106)	Acc@1 46.875 (53.125)	Acc@5 92.188 (96.191)
Epoch: [2][300/875]	Time 0.496 (0.514)	Data 0.005 (0.012)	Loss 2.5799 (2.9341)	Loss@kd 3.1349 (3.2932)	Acc@1 56.250 (53.442)	Acc@5 98.438 (96.294)
Epoch: [2][400/875]	Time 0.495 (0.512)	Data 0.007 (0.010)	Loss 2.5836 (2.9127)	Loss@kd 3.0632 (3.2686)	Acc@1 57.812 (53.702)	Acc@5 95.312 (96.361)
Epoch: [2][500/875]	Time 0.511 (0.506)	Data 0.007 (0.010)	Loss 2.9670 (2.8833)	Loss@kd 3.2000 (3.2512)	Acc@1 51.562 (53.911)	Acc@5 96.875 (96.367)
Epoch: [2][600/875]	Time 0.499 (0.507)	Data 0.007 (0.009)	Loss 2.5804 (2.8714)	Loss@kd 3.1740 (3.2367)	Acc@1 54.688 (54.170)	Acc@5 95.312 (96.389)
Epoch: [2][700/875]	Time 0.505 (0.507)	Data 0.007 (0.009)	Loss 2.6597 (2.8563)	Loss@kd 3.2375 (3.2237)	Acc@1 73.438 (54.317)	Acc@5 98.438 (96.394)
Epoch: [2][800/875]	Time 0.496 (0.508)	Data 0.007 (0.009)	Loss 2.7757 (2.8319)	Loss@kd 3.0954 (3.2059)	Acc@1 59.375 (54.506)	Acc@5 98.438 (96.424)
 * Acc@1 54.677 Acc@5 96.438
epoch 2, total time 444.43
Test: [0/750]	Time 0.618 (0.618)	Loss 0.8922 (0.8922)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.039 (0.033)	Loss 0.8432 (0.6334)	Acc@1 75.000 (82.921)	Acc@5 93.750 (90.811)
Test: [200/750]	Time 0.045 (0.031)	Loss 1.5826 (0.7589)	Acc@1 25.000 (73.741)	Acc@5 87.500 (92.118)
Test: [300/750]	Time 0.024 (0.030)	Loss 1.1542 (0.9272)	Acc@1 53.125 (61.732)	Acc@5 96.875 (92.930)
Test: [400/750]	Time 0.041 (0.030)	Loss 1.6927 (1.0430)	Acc@1 40.625 (58.619)	Acc@5 84.375 (92.207)
Test: [500/750]	Time 0.025 (0.030)	Loss 1.8201 (1.2115)	Acc@1 40.625 (55.795)	Acc@5 75.000 (87.980)
Test: [600/750]	Time 0.042 (0.030)	Loss 1.1242 (1.2688)	Acc@1 56.250 (54.519)	Acc@5 90.625 (86.814)
Test: [700/750]	Time 0.027 (0.029)	Loss 2.1395 (1.2964)	Acc@1 25.000 (53.326)	Acc@5 68.750 (86.301)
 * Acc@1 52.421 Acc@5 85.592
==> training...
Epoch: [3][0/875]	Time 1.800 (1.800)	Data 1.279 (1.279)	Loss 2.3326 (2.3326)	Loss@kd 2.9543 (2.9543)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.498 (0.522)	Data 0.007 (0.020)	Loss 3.2577 (2.6388)	Loss@kd 3.0719 (3.0620)	Acc@1 39.062 (57.580)	Acc@5 95.312 (97.076)
Epoch: [3][200/875]	Time 0.522 (0.515)	Data 0.007 (0.013)	Loss 2.4497 (2.6191)	Loss@kd 3.1043 (3.0436)	Acc@1 60.938 (56.817)	Acc@5 98.438 (96.844)
Epoch: [3][300/875]	Time 0.523 (0.506)	Data 0.008 (0.011)	Loss 2.8729 (2.6211)	Loss@kd 3.0132 (3.0471)	Acc@1 50.000 (56.785)	Acc@5 95.312 (96.776)
Epoch: [3][400/875]	Time 0.500 (0.506)	Data 0.006 (0.010)	Loss 2.8492 (2.6074)	Loss@kd 3.0219 (3.0401)	Acc@1 53.125 (56.694)	Acc@5 96.875 (96.848)
Epoch: [3][500/875]	Time 0.502 (0.507)	Data 0.007 (0.010)	Loss 2.7497 (2.5984)	Loss@kd 3.0107 (3.0322)	Acc@1 53.125 (56.574)	Acc@5 98.438 (96.853)
Epoch: [3][600/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss 2.3139 (2.5795)	Loss@kd 2.8033 (3.0205)	Acc@1 64.062 (56.830)	Acc@5 100.000 (96.898)
Epoch: [3][700/875]	Time 0.521 (0.508)	Data 0.007 (0.009)	Loss 2.3161 (2.5647)	Loss@kd 3.0606 (3.0146)	Acc@1 53.125 (56.925)	Acc@5 96.875 (96.951)
Epoch: [3][800/875]	Time 0.528 (0.508)	Data 0.008 (0.009)	Loss 2.3138 (2.5505)	Loss@kd 2.9600 (3.0056)	Acc@1 62.500 (57.032)	Acc@5 98.438 (96.932)
 * Acc@1 57.259 Acc@5 96.977
epoch 3, total time 444.71
Test: [0/750]	Time 0.720 (0.720)	Loss 0.5600 (0.5600)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.019 (0.033)	Loss 0.8711 (0.5470)	Acc@1 78.125 (82.797)	Acc@5 90.625 (93.286)
Test: [200/750]	Time 0.034 (0.030)	Loss 2.2634 (0.8031)	Acc@1 12.500 (74.254)	Acc@5 75.000 (91.356)
Test: [300/750]	Time 0.021 (0.029)	Loss 1.3120 (1.1849)	Acc@1 40.625 (57.382)	Acc@5 100.000 (89.151)
Test: [400/750]	Time 0.025 (0.029)	Loss 1.9203 (1.3479)	Acc@1 43.750 (52.034)	Acc@5 78.125 (87.718)
Test: [500/750]	Time 0.018 (0.029)	Loss 0.4539 (1.4367)	Acc@1 87.500 (51.609)	Acc@5 100.000 (84.487)
Test: [600/750]	Time 0.022 (0.028)	Loss 1.7247 (1.3836)	Acc@1 46.875 (53.884)	Acc@5 71.875 (84.703)
Test: [700/750]	Time 0.018 (0.027)	Loss 0.8953 (1.3753)	Acc@1 75.000 (54.141)	Acc@5 90.625 (84.522)
 * Acc@1 55.471 Acc@5 84.929
saving the best model!
==> training...
Epoch: [4][0/875]	Time 1.660 (1.660)	Data 1.200 (1.200)	Loss 2.3889 (2.3889)	Loss@kd 3.0007 (3.0007)	Acc@1 50.000 (50.000)	Acc@5 96.875 (96.875)
Epoch: [4][100/875]	Time 0.526 (0.506)	Data 0.010 (0.019)	Loss 2.1865 (2.3648)	Loss@kd 2.9138 (2.8949)	Acc@1 62.500 (59.066)	Acc@5 96.875 (96.906)
Epoch: [4][200/875]	Time 0.493 (0.507)	Data 0.007 (0.013)	Loss 2.6134 (2.4041)	Loss@kd 2.9475 (2.9132)	Acc@1 54.688 (58.520)	Acc@5 96.875 (96.968)
Epoch: [4][300/875]	Time 0.492 (0.508)	Data 0.007 (0.011)	Loss 2.3827 (2.3999)	Loss@kd 2.8170 (2.9124)	Acc@1 62.500 (58.586)	Acc@5 98.438 (97.109)
Epoch: [4][400/875]	Time 0.525 (0.508)	Data 0.009 (0.010)	Loss 2.2092 (2.3894)	Loss@kd 2.8831 (2.9103)	Acc@1 57.812 (58.954)	Acc@5 100.000 (97.210)
Epoch: [4][500/875]	Time 0.494 (0.509)	Data 0.007 (0.010)	Loss 2.2935 (2.3725)	Loss@kd 2.9038 (2.9033)	Acc@1 60.938 (59.072)	Acc@5 100.000 (97.259)
Epoch: [4][600/875]	Time 0.525 (0.509)	Data 0.006 (0.009)	Loss 2.2346 (2.3584)	Loss@kd 2.8531 (2.8986)	Acc@1 54.688 (59.055)	Acc@5 100.000 (97.307)
Epoch: [4][700/875]	Time 0.466 (0.508)	Data 0.005 (0.009)	Loss 2.4263 (2.3460)	Loss@kd 2.8417 (2.8922)	Acc@1 57.812 (59.163)	Acc@5 100.000 (97.287)
Epoch: [4][800/875]	Time 0.504 (0.506)	Data 0.004 (0.009)	Loss 2.1071 (2.3374)	Loss@kd 2.8778 (2.8871)	Acc@1 67.188 (59.244)	Acc@5 98.438 (97.290)
 * Acc@1 59.195 Acc@5 97.307
epoch 4, total time 442.96
Test: [0/750]	Time 0.642 (0.642)	Loss 0.7354 (0.7354)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.036 (0.030)	Loss 1.0822 (0.7190)	Acc@1 56.250 (79.332)	Acc@5 93.750 (90.408)
Test: [200/750]	Time 0.027 (0.027)	Loss 1.8656 (0.9076)	Acc@1 43.750 (68.113)	Acc@5 81.250 (91.713)
Test: [300/750]	Time 0.021 (0.026)	Loss 1.2004 (1.0677)	Acc@1 50.000 (59.988)	Acc@5 90.625 (91.289)
Test: [400/750]	Time 0.023 (0.025)	Loss 0.9540 (1.1061)	Acc@1 68.750 (58.081)	Acc@5 87.500 (91.233)
Test: [500/750]	Time 0.015 (0.025)	Loss 0.6179 (1.0906)	Acc@1 75.000 (60.404)	Acc@5 100.000 (90.263)
Test: [600/750]	Time 0.017 (0.025)	Loss 0.7299 (1.0484)	Acc@1 68.750 (62.339)	Acc@5 90.625 (90.838)
Test: [700/750]	Time 0.018 (0.025)	Loss 3.1038 (1.1091)	Acc@1 6.250 (60.690)	Acc@5 53.125 (89.738)
 * Acc@1 58.346 Acc@5 88.333
saving the best model!
==> training...
Epoch: [5][0/875]	Time 1.880 (1.880)	Data 1.362 (1.362)	Loss 2.1831 (2.1831)	Loss@kd 2.7910 (2.7910)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [5][100/875]	Time 0.523 (0.522)	Data 0.008 (0.020)	Loss 2.3824 (2.2272)	Loss@kd 2.8523 (2.8323)	Acc@1 62.500 (59.947)	Acc@5 96.875 (97.463)
Epoch: [5][200/875]	Time 0.511 (0.516)	Data 0.007 (0.014)	Loss 2.2505 (2.2403)	Loss@kd 2.7590 (2.8386)	Acc@1 64.062 (60.160)	Acc@5 96.875 (97.497)
Epoch: [5][300/875]	Time 0.532 (0.514)	Data 0.007 (0.012)	Loss 2.1309 (2.2367)	Loss@kd 2.7289 (2.8359)	Acc@1 57.812 (59.899)	Acc@5 96.875 (97.415)
Epoch: [5][400/875]	Time 0.496 (0.513)	Data 0.006 (0.010)	Loss 2.2319 (2.2355)	Loss@kd 3.0733 (2.8310)	Acc@1 65.625 (59.897)	Acc@5 98.438 (97.545)
Epoch: [5][500/875]	Time 0.457 (0.508)	Data 0.008 (0.010)	Loss 2.3028 (2.2326)	Loss@kd 2.8140 (2.8292)	Acc@1 54.688 (60.086)	Acc@5 95.312 (97.530)
Epoch: [5][600/875]	Time 0.519 (0.506)	Data 0.007 (0.009)	Loss 2.3006 (2.2278)	Loss@kd 2.7303 (2.8263)	Acc@1 54.688 (60.181)	Acc@5 98.438 (97.496)
Epoch: [5][700/875]	Time 0.497 (0.507)	Data 0.007 (0.009)	Loss 2.4059 (2.2240)	Loss@kd 2.7234 (2.8242)	Acc@1 62.500 (60.200)	Acc@5 100.000 (97.510)
Epoch: [5][800/875]	Time 0.501 (0.507)	Data 0.007 (0.009)	Loss 1.7240 (2.2188)	Loss@kd 2.6643 (2.8196)	Acc@1 71.875 (60.463)	Acc@5 100.000 (97.486)
 * Acc@1 60.495 Acc@5 97.477
epoch 5, total time 444.11
Test: [0/750]	Time 0.745 (0.745)	Loss 0.9361 (0.9361)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.020 (0.038)	Loss 0.8858 (0.7781)	Acc@1 71.875 (82.580)	Acc@5 100.000 (89.728)
Test: [200/750]	Time 0.028 (0.034)	Loss 4.1338 (0.9226)	Acc@1 0.000 (73.570)	Acc@5 43.750 (90.889)
Test: [300/750]	Time 0.042 (0.032)	Loss 2.5128 (1.6597)	Acc@1 12.500 (52.336)	Acc@5 93.750 (82.039)
Test: [400/750]	Time 0.036 (0.031)	Loss 2.0800 (1.8773)	Acc@1 43.750 (45.823)	Acc@5 81.250 (83.588)
Test: [500/750]	Time 0.030 (0.030)	Loss 1.6863 (1.8821)	Acc@1 43.750 (46.538)	Acc@5 81.250 (83.595)
Test: [600/750]	Time 0.021 (0.030)	Loss 0.3753 (1.7955)	Acc@1 93.750 (48.378)	Acc@5 96.875 (84.318)
Test: [700/750]	Time 0.029 (0.030)	Loss 0.7818 (1.6256)	Acc@1 81.250 (52.706)	Acc@5 90.625 (86.194)
 * Acc@1 54.796 Acc@5 86.742
==> training...
Epoch: [6][0/875]	Time 1.740 (1.740)	Data 1.245 (1.245)	Loss 2.0504 (2.0504)	Loss@kd 2.6812 (2.6812)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [6][100/875]	Time 0.509 (0.522)	Data 0.007 (0.019)	Loss 2.0482 (2.1523)	Loss@kd 2.7692 (2.7793)	Acc@1 53.125 (60.381)	Acc@5 98.438 (97.463)
Epoch: [6][200/875]	Time 0.530 (0.516)	Data 0.005 (0.013)	Loss 2.1452 (2.1354)	Loss@kd 2.7166 (2.7745)	Acc@1 60.938 (60.766)	Acc@5 98.438 (97.831)
Epoch: [6][300/875]	Time 0.501 (0.505)	Data 0.007 (0.011)	Loss 2.1252 (2.1289)	Loss@kd 2.7877 (2.7756)	Acc@1 53.125 (60.922)	Acc@5 98.438 (97.757)
Epoch: [6][400/875]	Time 0.531 (0.506)	Data 0.007 (0.010)	Loss 2.1036 (2.1316)	Loss@kd 2.8627 (2.7728)	Acc@1 64.062 (60.887)	Acc@5 98.438 (97.736)
Epoch: [6][500/875]	Time 0.497 (0.507)	Data 0.005 (0.009)	Loss 2.0469 (2.1178)	Loss@kd 2.6099 (2.7685)	Acc@1 65.625 (61.103)	Acc@5 96.875 (97.680)
Epoch: [6][600/875]	Time 0.514 (0.507)	Data 0.008 (0.009)	Loss 2.1030 (2.1111)	Loss@kd 2.7760 (2.7641)	Acc@1 59.375 (61.184)	Acc@5 98.438 (97.663)
Epoch: [6][700/875]	Time 0.512 (0.507)	Data 0.007 (0.009)	Loss 2.2251 (2.1014)	Loss@kd 2.7003 (2.7580)	Acc@1 56.250 (61.370)	Acc@5 96.875 (97.671)
Epoch: [6][800/875]	Time 0.499 (0.508)	Data 0.007 (0.009)	Loss 1.9609 (2.1002)	Loss@kd 2.6912 (2.7565)	Acc@1 64.062 (61.357)	Acc@5 96.875 (97.657)
 * Acc@1 61.468 Acc@5 97.709
epoch 6, total time 444.50
Test: [0/750]	Time 0.638 (0.638)	Loss 0.4566 (0.4566)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.042 (0.035)	Loss 0.6247 (0.4780)	Acc@1 75.000 (84.468)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.038 (0.033)	Loss 1.5183 (0.5820)	Acc@1 43.750 (80.100)	Acc@5 93.750 (94.838)
Test: [300/750]	Time 0.026 (0.031)	Loss 1.2306 (0.8135)	Acc@1 46.875 (70.370)	Acc@5 93.750 (93.574)
Test: [400/750]	Time 0.017 (0.030)	Loss 0.9251 (0.9403)	Acc@1 81.250 (65.150)	Acc@5 87.500 (93.049)
Test: [500/750]	Time 0.023 (0.030)	Loss 1.0231 (0.9637)	Acc@1 71.875 (65.812)	Acc@5 100.000 (91.704)
Test: [600/750]	Time 0.026 (0.030)	Loss 1.1547 (0.9997)	Acc@1 59.375 (64.725)	Acc@5 84.375 (91.296)
Test: [700/750]	Time 0.040 (0.030)	Loss 2.1202 (1.0589)	Acc@1 40.625 (62.968)	Acc@5 75.000 (90.193)
 * Acc@1 62.158 Acc@5 89.433
saving the best model!
==> training...
Epoch: [7][0/875]	Time 1.744 (1.744)	Data 1.274 (1.274)	Loss 1.9732 (1.9732)	Loss@kd 2.6194 (2.6194)	Acc@1 59.375 (59.375)	Acc@5 93.750 (93.750)
Epoch: [7][100/875]	Time 0.509 (0.498)	Data 0.007 (0.019)	Loss 2.2238 (2.0207)	Loss@kd 2.6417 (2.7230)	Acc@1 48.438 (63.057)	Acc@5 95.312 (97.912)
Epoch: [7][200/875]	Time 0.520 (0.504)	Data 0.007 (0.013)	Loss 2.1007 (2.0412)	Loss@kd 2.7685 (2.7287)	Acc@1 56.250 (62.391)	Acc@5 96.875 (97.808)
Epoch: [7][300/875]	Time 0.500 (0.506)	Data 0.007 (0.011)	Loss 2.0608 (2.0405)	Loss@kd 2.6486 (2.7221)	Acc@1 60.938 (62.178)	Acc@5 98.438 (97.726)
Epoch: [7][400/875]	Time 0.529 (0.507)	Data 0.005 (0.010)	Loss 1.7772 (2.0381)	Loss@kd 2.6619 (2.7233)	Acc@1 64.062 (62.274)	Acc@5 98.438 (97.654)
Epoch: [7][500/875]	Time 0.492 (0.507)	Data 0.006 (0.010)	Loss 2.1663 (2.0294)	Loss@kd 2.6356 (2.7181)	Acc@1 68.750 (62.594)	Acc@5 96.875 (97.717)
Epoch: [7][600/875]	Time 0.520 (0.507)	Data 0.007 (0.009)	Loss 2.4918 (2.0251)	Loss@kd 3.2526 (2.7173)	Acc@1 75.000 (62.833)	Acc@5 96.875 (97.751)
Epoch: [7][700/875]	Time 0.496 (0.508)	Data 0.007 (0.009)	Loss 1.7312 (2.0200)	Loss@kd 2.7081 (2.7147)	Acc@1 65.625 (62.718)	Acc@5 98.438 (97.769)
Epoch: [7][800/875]	Time 0.493 (0.503)	Data 0.007 (0.009)	Loss 1.9497 (2.0224)	Loss@kd 2.5676 (2.7147)	Acc@1 60.938 (62.672)	Acc@5 98.438 (97.766)
 * Acc@1 62.632 Acc@5 97.761
epoch 7, total time 441.15
Test: [0/750]	Time 0.703 (0.703)	Loss 0.6858 (0.6858)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.037 (0.032)	Loss 0.5083 (0.7064)	Acc@1 78.125 (82.024)	Acc@5 100.000 (90.285)
Test: [200/750]	Time 0.022 (0.029)	Loss 2.0824 (0.6853)	Acc@1 25.000 (78.576)	Acc@5 78.125 (92.724)
Test: [300/750]	Time 0.016 (0.027)	Loss 2.1081 (1.1091)	Acc@1 21.875 (61.275)	Acc@5 78.125 (88.029)
Test: [400/750]	Time 0.020 (0.027)	Loss 0.6942 (1.2831)	Acc@1 71.875 (54.045)	Acc@5 90.625 (85.965)
Test: [500/750]	Time 0.019 (0.026)	Loss 0.9046 (1.2043)	Acc@1 56.250 (57.136)	Acc@5 100.000 (87.138)
Test: [600/750]	Time 0.028 (0.026)	Loss 0.8397 (1.1787)	Acc@1 75.000 (58.054)	Acc@5 90.625 (88.197)
Test: [700/750]	Time 0.018 (0.026)	Loss 1.2342 (1.1446)	Acc@1 65.625 (59.482)	Acc@5 87.500 (88.837)
 * Acc@1 60.275 Acc@5 88.825
==> training...
Epoch: [8][0/875]	Time 1.736 (1.736)	Data 1.266 (1.266)	Loss 1.9185 (1.9185)	Loss@kd 2.6685 (2.6685)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [8][100/875]	Time 0.517 (0.522)	Data 0.007 (0.020)	Loss 2.0147 (1.9695)	Loss@kd 2.6436 (2.7046)	Acc@1 73.438 (63.985)	Acc@5 96.875 (98.144)
Epoch: [8][200/875]	Time 0.496 (0.516)	Data 0.006 (0.014)	Loss 1.9201 (1.9549)	Loss@kd 2.8103 (2.6969)	Acc@1 65.625 (63.915)	Acc@5 100.000 (97.994)
Epoch: [8][300/875]	Time 0.501 (0.514)	Data 0.007 (0.011)	Loss 1.9947 (1.9632)	Loss@kd 2.8273 (2.6966)	Acc@1 56.250 (63.590)	Acc@5 95.312 (97.975)
Epoch: [8][400/875]	Time 0.520 (0.512)	Data 0.006 (0.010)	Loss 1.8950 (1.9579)	Loss@kd 2.6205 (2.6926)	Acc@1 65.625 (63.513)	Acc@5 98.438 (97.986)
Epoch: [8][500/875]	Time 0.499 (0.512)	Data 0.008 (0.010)	Loss 2.1928 (1.9579)	Loss@kd 2.9379 (2.6916)	Acc@1 65.625 (63.514)	Acc@5 98.438 (97.976)
Epoch: [8][600/875]	Time 0.501 (0.507)	Data 0.007 (0.009)	Loss 2.1165 (1.9571)	Loss@kd 2.7493 (2.6862)	Acc@1 64.062 (63.524)	Acc@5 98.438 (97.951)
Epoch: [8][700/875]	Time 0.507 (0.508)	Data 0.008 (0.009)	Loss 1.7057 (1.9541)	Loss@kd 2.6110 (2.6847)	Acc@1 62.500 (63.481)	Acc@5 100.000 (97.907)
Epoch: [8][800/875]	Time 0.500 (0.508)	Data 0.008 (0.009)	Loss 2.1695 (1.9511)	Loss@kd 2.6467 (2.6812)	Acc@1 65.625 (63.452)	Acc@5 98.438 (97.921)
 * Acc@1 63.425 Acc@5 97.916
epoch 8, total time 444.85
Test: [0/750]	Time 0.691 (0.691)	Loss 0.7620 (0.7620)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.033 (0.035)	Loss 0.4737 (0.6937)	Acc@1 81.250 (80.631)	Acc@5 100.000 (91.739)
Test: [200/750]	Time 0.024 (0.032)	Loss 1.7473 (0.6377)	Acc@1 31.250 (79.820)	Acc@5 90.625 (94.076)
Test: [300/750]	Time 0.040 (0.031)	Loss 1.7365 (0.9200)	Acc@1 34.375 (68.459)	Acc@5 87.500 (92.463)
Test: [400/750]	Time 0.044 (0.030)	Loss 0.4416 (1.0617)	Acc@1 87.500 (62.547)	Acc@5 96.875 (90.773)
Test: [500/750]	Time 0.026 (0.030)	Loss 0.6431 (0.9734)	Acc@1 75.000 (65.993)	Acc@5 100.000 (91.417)
Test: [600/750]	Time 0.032 (0.030)	Loss 0.6424 (0.9668)	Acc@1 84.375 (66.280)	Acc@5 93.750 (91.691)
Test: [700/750]	Time 0.029 (0.030)	Loss 1.6514 (0.9874)	Acc@1 53.125 (65.447)	Acc@5 81.250 (91.463)
 * Acc@1 64.738 Acc@5 91.000
saving the best model!
==> training...
Epoch: [9][0/875]	Time 1.741 (1.741)	Data 1.242 (1.242)	Loss 1.9311 (1.9311)	Loss@kd 2.7403 (2.7403)	Acc@1 54.688 (54.688)	Acc@5 95.312 (95.312)
Epoch: [9][100/875]	Time 0.522 (0.521)	Data 0.008 (0.020)	Loss 2.1054 (1.9105)	Loss@kd 2.8480 (2.6552)	Acc@1 65.625 (63.908)	Acc@5 100.000 (98.082)
Epoch: [9][200/875]	Time 0.504 (0.515)	Data 0.007 (0.013)	Loss 1.8140 (1.9220)	Loss@kd 2.6824 (2.6558)	Acc@1 67.188 (63.573)	Acc@5 98.438 (98.002)
Epoch: [9][300/875]	Time 0.453 (0.510)	Data 0.008 (0.011)	Loss 1.9696 (1.9176)	Loss@kd 2.5985 (2.6551)	Acc@1 71.875 (63.440)	Acc@5 98.438 (97.887)
Epoch: [9][400/875]	Time 0.512 (0.505)	Data 0.007 (0.010)	Loss 1.9204 (1.9181)	Loss@kd 2.6188 (2.6544)	Acc@1 60.938 (63.423)	Acc@5 100.000 (97.865)
Epoch: [9][500/875]	Time 0.496 (0.506)	Data 0.005 (0.010)	Loss 2.0989 (1.9147)	Loss@kd 2.5369 (2.6512)	Acc@1 57.812 (63.302)	Acc@5 96.875 (97.857)
Epoch: [9][600/875]	Time 0.505 (0.507)	Data 0.006 (0.009)	Loss 1.7591 (1.9101)	Loss@kd 2.6069 (2.6505)	Acc@1 68.750 (63.452)	Acc@5 98.438 (97.845)
Epoch: [9][700/875]	Time 0.523 (0.507)	Data 0.008 (0.009)	Loss 1.9683 (1.9115)	Loss@kd 2.7001 (2.6530)	Acc@1 57.812 (63.552)	Acc@5 96.875 (97.894)
Epoch: [9][800/875]	Time 0.511 (0.507)	Data 0.007 (0.009)	Loss 2.0409 (1.9056)	Loss@kd 2.7281 (2.6487)	Acc@1 50.000 (63.553)	Acc@5 100.000 (97.913)
 * Acc@1 63.609 Acc@5 97.959
epoch 9, total time 444.08
Test: [0/750]	Time 0.667 (0.667)	Loss 0.4596 (0.4596)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.040 (0.033)	Loss 0.3739 (0.4415)	Acc@1 84.375 (87.500)	Acc@5 100.000 (95.050)
Test: [200/750]	Time 0.022 (0.029)	Loss 2.1421 (0.4973)	Acc@1 25.000 (85.075)	Acc@5 81.250 (95.647)
Test: [300/750]	Time 0.020 (0.028)	Loss 1.7186 (0.9501)	Acc@1 50.000 (69.061)	Acc@5 90.625 (92.473)
Test: [400/750]	Time 0.035 (0.027)	Loss 1.5125 (1.1681)	Acc@1 56.250 (62.321)	Acc@5 87.500 (90.991)
Test: [500/750]	Time 0.033 (0.027)	Loss 0.8877 (1.2067)	Acc@1 68.750 (62.232)	Acc@5 96.875 (89.883)
Test: [600/750]	Time 0.039 (0.026)	Loss 1.2714 (1.2228)	Acc@1 56.250 (60.753)	Acc@5 87.500 (89.767)
Test: [700/750]	Time 0.035 (0.026)	Loss 1.1660 (1.2213)	Acc@1 71.875 (60.432)	Acc@5 78.125 (89.573)
 * Acc@1 61.275 Acc@5 89.450
==> training...
Epoch: [10][0/875]	Time 1.708 (1.708)	Data 1.236 (1.236)	Loss 1.9950 (1.9950)	Loss@kd 2.8310 (2.8310)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [10][100/875]	Time 0.457 (0.505)	Data 0.008 (0.019)	Loss 1.7555 (1.8651)	Loss@kd 2.5441 (2.6117)	Acc@1 65.625 (64.279)	Acc@5 95.312 (98.144)
Epoch: [10][200/875]	Time 0.496 (0.498)	Data 0.007 (0.013)	Loss 1.9387 (1.8854)	Loss@kd 2.5534 (2.6210)	Acc@1 65.625 (63.526)	Acc@5 98.438 (97.870)
Epoch: [10][300/875]	Time 0.510 (0.502)	Data 0.007 (0.011)	Loss 1.8961 (1.8794)	Loss@kd 2.5491 (2.6237)	Acc@1 62.500 (63.876)	Acc@5 98.438 (97.903)
Epoch: [10][400/875]	Time 0.527 (0.504)	Data 0.007 (0.010)	Loss 1.7427 (1.8784)	Loss@kd 2.5863 (2.6274)	Acc@1 75.000 (64.086)	Acc@5 100.000 (97.869)
Epoch: [10][500/875]	Time 0.493 (0.505)	Data 0.007 (0.009)	Loss 1.9567 (1.8830)	Loss@kd 2.6764 (2.6364)	Acc@1 60.938 (64.247)	Acc@5 98.438 (97.917)
Epoch: [10][600/875]	Time 0.523 (0.506)	Data 0.007 (0.009)	Loss 2.0569 (1.8798)	Loss@kd 2.7229 (2.6361)	Acc@1 53.125 (63.998)	Acc@5 96.875 (97.912)
Epoch: [10][700/875]	Time 0.497 (0.506)	Data 0.007 (0.009)	Loss 1.8749 (1.8788)	Loss@kd 2.7179 (2.6353)	Acc@1 67.188 (64.031)	Acc@5 95.312 (97.923)
Epoch: [10][800/875]	Time 0.454 (0.505)	Data 0.006 (0.008)	Loss 1.7722 (1.8787)	Loss@kd 2.5375 (2.6329)	Acc@1 64.062 (63.965)	Acc@5 96.875 (97.932)
 * Acc@1 64.066 Acc@5 97.961
epoch 10, total time 440.13
Test: [0/750]	Time 0.719 (0.719)	Loss 0.6201 (0.6201)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.032 (0.036)	Loss 0.3868 (0.6694)	Acc@1 84.375 (82.859)	Acc@5 96.875 (93.100)
Test: [200/750]	Time 0.028 (0.032)	Loss 1.7964 (0.6127)	Acc@1 28.125 (81.063)	Acc@5 75.000 (94.558)
Test: [300/750]	Time 0.022 (0.031)	Loss 1.3839 (0.9267)	Acc@1 43.750 (67.255)	Acc@5 93.750 (91.373)
Test: [400/750]	Time 0.026 (0.030)	Loss 0.6639 (1.0164)	Acc@1 78.125 (63.529)	Acc@5 90.625 (90.882)
Test: [500/750]	Time 0.023 (0.030)	Loss 0.8828 (0.9939)	Acc@1 81.250 (64.926)	Acc@5 96.875 (90.457)
Test: [600/750]	Time 0.023 (0.029)	Loss 1.0773 (1.0170)	Acc@1 68.750 (63.920)	Acc@5 90.625 (90.308)
Test: [700/750]	Time 0.037 (0.029)	Loss 1.2768 (1.0148)	Acc@1 53.125 (63.869)	Acc@5 84.375 (90.465)
 * Acc@1 64.037 Acc@5 90.325
==> training...
Epoch: [11][0/875]	Time 1.804 (1.804)	Data 1.302 (1.302)	Loss 1.7406 (1.7406)	Loss@kd 2.6462 (2.6462)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [11][100/875]	Time 0.525 (0.521)	Data 0.007 (0.020)	Loss 1.7057 (1.8742)	Loss@kd 2.6076 (2.6317)	Acc@1 70.312 (63.428)	Acc@5 98.438 (98.175)
Epoch: [11][200/875]	Time 0.512 (0.515)	Data 0.007 (0.014)	Loss 1.6076 (1.8374)	Loss@kd 2.5952 (2.6112)	Acc@1 76.562 (64.381)	Acc@5 96.875 (98.010)
Epoch: [11][300/875]	Time 0.495 (0.513)	Data 0.006 (0.012)	Loss 1.5957 (1.8392)	Loss@kd 2.6040 (2.6073)	Acc@1 64.062 (64.192)	Acc@5 98.438 (97.965)
Epoch: [11][400/875]	Time 0.492 (0.512)	Data 0.007 (0.011)	Loss 1.8646 (1.8323)	Loss@kd 2.6290 (2.6096)	Acc@1 57.812 (64.261)	Acc@5 98.438 (98.063)
Epoch: [11][500/875]	Time 0.521 (0.511)	Data 0.008 (0.010)	Loss 1.7513 (1.8328)	Loss@kd 2.5706 (2.6097)	Acc@1 64.062 (64.203)	Acc@5 96.875 (98.091)
Epoch: [11][600/875]	Time 0.464 (0.508)	Data 0.007 (0.009)	Loss 2.0663 (1.8242)	Loss@kd 2.6887 (2.6050)	Acc@1 70.312 (64.174)	Acc@5 98.438 (98.084)
Epoch: [11][700/875]	Time 0.525 (0.506)	Data 0.007 (0.009)	Loss 1.9487 (1.8207)	Loss@kd 2.6007 (2.6025)	Acc@1 67.188 (64.314)	Acc@5 95.312 (98.114)
Epoch: [11][800/875]	Time 0.506 (0.506)	Data 0.007 (0.009)	Loss 1.8272 (1.8221)	Loss@kd 2.6395 (2.6040)	Acc@1 68.750 (64.515)	Acc@5 96.875 (98.108)
 * Acc@1 64.409 Acc@5 98.102
epoch 11, total time 443.63
Test: [0/750]	Time 0.759 (0.759)	Loss 0.6807 (0.6807)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.020 (0.035)	Loss 0.5444 (0.7462)	Acc@1 78.125 (80.507)	Acc@5 96.875 (91.151)
Test: [200/750]	Time 0.035 (0.032)	Loss 1.3112 (0.7298)	Acc@1 43.750 (77.830)	Acc@5 90.625 (92.786)
Test: [300/750]	Time 0.023 (0.031)	Loss 1.8431 (0.9563)	Acc@1 34.375 (67.888)	Acc@5 84.375 (92.587)
Test: [400/750]	Time 0.035 (0.031)	Loss 1.0187 (1.1321)	Acc@1 71.875 (60.988)	Acc@5 87.500 (90.555)
Test: [500/750]	Time 0.045 (0.030)	Loss 0.7772 (1.1318)	Acc@1 65.625 (61.421)	Acc@5 100.000 (90.057)
Test: [600/750]	Time 0.025 (0.030)	Loss 0.9497 (1.1336)	Acc@1 65.625 (61.034)	Acc@5 87.500 (90.157)
Test: [700/750]	Time 0.023 (0.030)	Loss 1.1568 (1.1220)	Acc@1 62.500 (61.225)	Acc@5 87.500 (90.237)
 * Acc@1 61.592 Acc@5 90.221
==> training...
Epoch: [12][0/875]	Time 1.828 (1.828)	Data 1.322 (1.322)	Loss 1.9299 (1.9299)	Loss@kd 2.5219 (2.5219)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [12][100/875]	Time 0.510 (0.522)	Data 0.007 (0.020)	Loss 2.0103 (1.8423)	Loss@kd 2.6107 (2.6120)	Acc@1 68.750 (65.347)	Acc@5 98.438 (98.283)
Epoch: [12][200/875]	Time 0.515 (0.516)	Data 0.007 (0.014)	Loss 1.8737 (1.8187)	Loss@kd 2.5555 (2.5951)	Acc@1 67.188 (65.337)	Acc@5 95.312 (98.251)
Epoch: [12][300/875]	Time 0.528 (0.513)	Data 0.005 (0.011)	Loss 1.6928 (1.8133)	Loss@kd 2.5343 (2.5939)	Acc@1 64.062 (65.018)	Acc@5 98.438 (98.126)
Epoch: [12][400/875]	Time 0.491 (0.505)	Data 0.008 (0.010)	Loss 1.8826 (1.8072)	Loss@kd 2.5800 (2.5934)	Acc@1 68.750 (65.364)	Acc@5 98.438 (98.173)
Epoch: [12][500/875]	Time 0.499 (0.506)	Data 0.006 (0.010)	Loss 1.7332 (1.8073)	Loss@kd 2.5596 (2.5937)	Acc@1 65.625 (65.248)	Acc@5 96.875 (98.119)
Epoch: [12][600/875]	Time 0.499 (0.506)	Data 0.007 (0.009)	Loss 1.8598 (1.8088)	Loss@kd 2.4985 (2.5934)	Acc@1 68.750 (65.201)	Acc@5 95.312 (98.126)
Epoch: [12][700/875]	Time 0.503 (0.507)	Data 0.005 (0.009)	Loss 1.5750 (1.8141)	Loss@kd 2.4299 (2.5944)	Acc@1 64.062 (64.934)	Acc@5 100.000 (98.123)
Epoch: [12][800/875]	Time 0.510 (0.507)	Data 0.007 (0.009)	Loss 1.6820 (1.8126)	Loss@kd 2.6184 (2.5932)	Acc@1 68.750 (64.876)	Acc@5 100.000 (98.129)
 * Acc@1 64.895 Acc@5 98.125
epoch 12, total time 444.18
Test: [0/750]	Time 0.664 (0.664)	Loss 0.5864 (0.5864)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.041 (0.036)	Loss 0.2903 (0.6246)	Acc@1 87.500 (84.282)	Acc@5 100.000 (92.946)
Test: [200/750]	Time 0.026 (0.032)	Loss 1.8868 (0.5443)	Acc@1 40.625 (84.437)	Acc@5 71.875 (94.978)
Test: [300/750]	Time 0.026 (0.031)	Loss 1.6630 (0.9229)	Acc@1 46.875 (69.861)	Acc@5 96.875 (92.556)
Test: [400/750]	Time 0.024 (0.031)	Loss 0.7012 (1.0560)	Acc@1 78.125 (64.744)	Acc@5 93.750 (91.997)
Test: [500/750]	Time 0.044 (0.030)	Loss 1.5700 (1.0661)	Acc@1 46.875 (65.120)	Acc@5 81.250 (91.024)
Test: [600/750]	Time 0.024 (0.030)	Loss 0.9856 (1.1727)	Acc@1 78.125 (61.923)	Acc@5 93.750 (89.767)
Test: [700/750]	Time 0.019 (0.030)	Loss 1.1099 (1.1837)	Acc@1 65.625 (61.296)	Acc@5 81.250 (90.032)
 * Acc@1 61.854 Acc@5 89.896
==> training...
Epoch: [13][0/875]	Time 1.971 (1.971)	Data 1.477 (1.477)	Loss 1.6861 (1.6861)	Loss@kd 2.5350 (2.5350)	Acc@1 60.938 (60.938)	Acc@5 95.312 (95.312)
Epoch: [13][100/875]	Time 0.526 (0.524)	Data 0.007 (0.021)	Loss 1.6739 (1.7756)	Loss@kd 2.4894 (2.5800)	Acc@1 65.625 (65.532)	Acc@5 100.000 (98.298)
Epoch: [13][200/875]	Time 0.500 (0.500)	Data 0.007 (0.014)	Loss 1.5966 (1.7801)	Loss@kd 2.5174 (2.5840)	Acc@1 64.062 (65.104)	Acc@5 96.875 (98.266)
Epoch: [13][300/875]	Time 0.521 (0.503)	Data 0.008 (0.012)	Loss 1.8039 (1.7809)	Loss@kd 2.4456 (2.5834)	Acc@1 71.875 (65.018)	Acc@5 96.875 (98.303)
Epoch: [13][400/875]	Time 0.508 (0.505)	Data 0.010 (0.011)	Loss 1.7892 (1.7863)	Loss@kd 2.6118 (2.5838)	Acc@1 59.375 (65.044)	Acc@5 93.750 (98.274)
Epoch: [13][500/875]	Time 0.527 (0.506)	Data 0.007 (0.010)	Loss 1.7635 (1.7851)	Loss@kd 2.4571 (2.5832)	Acc@1 62.500 (64.986)	Acc@5 98.438 (98.188)
Epoch: [13][600/875]	Time 0.494 (0.506)	Data 0.007 (0.009)	Loss 1.6260 (1.7861)	Loss@kd 2.4721 (2.5823)	Acc@1 51.562 (64.863)	Acc@5 96.875 (98.141)
Epoch: [13][700/875]	Time 0.524 (0.507)	Data 0.010 (0.009)	Loss 1.8785 (1.7834)	Loss@kd 2.7111 (2.5822)	Acc@1 67.188 (64.885)	Acc@5 96.875 (98.174)
Epoch: [13][800/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss 1.8507 (1.7851)	Loss@kd 2.5817 (2.5809)	Acc@1 56.250 (64.718)	Acc@5 98.438 (98.141)
 * Acc@1 64.843 Acc@5 98.107
epoch 13, total time 442.23
Test: [0/750]	Time 0.623 (0.623)	Loss 0.4904 (0.4904)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.024 (0.031)	Loss 0.5771 (0.4636)	Acc@1 84.375 (86.417)	Acc@5 96.875 (94.462)
Test: [200/750]	Time 0.019 (0.031)	Loss 1.8934 (0.5540)	Acc@1 31.250 (82.898)	Acc@5 90.625 (95.087)
Test: [300/750]	Time 0.016 (0.030)	Loss 1.4599 (0.9055)	Acc@1 50.000 (69.643)	Acc@5 87.500 (93.086)
Test: [400/750]	Time 0.035 (0.029)	Loss 1.1231 (1.0821)	Acc@1 62.500 (62.843)	Acc@5 78.125 (91.124)
Test: [500/750]	Time 0.025 (0.029)	Loss 0.7757 (1.0785)	Acc@1 62.500 (63.417)	Acc@5 100.000 (90.363)
Test: [600/750]	Time 0.041 (0.029)	Loss 1.5437 (1.0910)	Acc@1 53.125 (62.687)	Acc@5 81.250 (90.412)
Test: [700/750]	Time 0.030 (0.029)	Loss 1.2420 (1.0970)	Acc@1 65.625 (62.357)	Acc@5 87.500 (90.237)
 * Acc@1 62.929 Acc@5 90.142
==> training...
Epoch: [14][0/875]	Time 1.755 (1.755)	Data 1.260 (1.260)	Loss 1.7382 (1.7382)	Loss@kd 2.4895 (2.4895)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)
Epoch: [14][100/875]	Time 0.527 (0.521)	Data 0.007 (0.020)	Loss 1.9450 (1.7434)	Loss@kd 2.4773 (2.5635)	Acc@1 59.375 (65.826)	Acc@5 98.438 (98.267)
Epoch: [14][200/875]	Time 0.513 (0.515)	Data 0.007 (0.013)	Loss 1.5819 (1.7461)	Loss@kd 2.4625 (2.5602)	Acc@1 59.375 (65.089)	Acc@5 98.438 (98.173)
Epoch: [14][300/875]	Time 0.525 (0.513)	Data 0.005 (0.011)	Loss 1.7996 (1.7540)	Loss@kd 2.6362 (2.5633)	Acc@1 70.312 (64.950)	Acc@5 100.000 (98.116)
Epoch: [14][400/875]	Time 0.512 (0.512)	Data 0.007 (0.010)	Loss 1.6585 (1.7636)	Loss@kd 2.5467 (2.5622)	Acc@1 64.062 (65.056)	Acc@5 98.438 (98.126)
Epoch: [14][500/875]	Time 0.510 (0.511)	Data 0.007 (0.010)	Loss 1.7450 (1.7702)	Loss@kd 2.5331 (2.5688)	Acc@1 59.375 (65.079)	Acc@5 98.438 (98.176)
Epoch: [14][600/875]	Time 0.492 (0.511)	Data 0.006 (0.009)	Loss 1.8984 (1.7715)	Loss@kd 2.6375 (2.5699)	Acc@1 62.500 (65.061)	Acc@5 96.875 (98.157)
Epoch: [14][700/875]	Time 0.509 (0.507)	Data 0.007 (0.009)	Loss 2.0816 (1.7704)	Loss@kd 2.5576 (2.5714)	Acc@1 56.250 (65.003)	Acc@5 98.438 (98.163)
Epoch: [14][800/875]	Time 0.494 (0.507)	Data 0.007 (0.009)	Loss 1.5077 (1.7660)	Loss@kd 2.4248 (2.5695)	Acc@1 65.625 (65.161)	Acc@5 96.875 (98.186)
 * Acc@1 65.143 Acc@5 98.170
epoch 14, total time 444.36
Test: [0/750]	Time 0.708 (0.708)	Loss 0.6158 (0.6158)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.034 (0.034)	Loss 0.2222 (0.6001)	Acc@1 90.625 (83.973)	Acc@5 100.000 (94.431)
Test: [200/750]	Time 0.017 (0.030)	Loss 3.4036 (0.6395)	Acc@1 9.375 (82.121)	Acc@5 59.375 (93.812)
Test: [300/750]	Time 0.036 (0.029)	Loss 1.6884 (1.4108)	Acc@1 37.500 (60.174)	Acc@5 90.625 (83.316)
Test: [400/750]	Time 0.021 (0.029)	Loss 1.2404 (1.5789)	Acc@1 59.375 (54.746)	Acc@5 87.500 (83.884)
Test: [500/750]	Time 0.034 (0.028)	Loss 0.4985 (1.5380)	Acc@1 81.250 (56.325)	Acc@5 96.875 (83.988)
Test: [600/750]	Time 0.021 (0.028)	Loss 1.0811 (1.4689)	Acc@1 68.750 (57.727)	Acc@5 87.500 (85.181)
Test: [700/750]	Time 0.019 (0.027)	Loss 0.9900 (1.4327)	Acc@1 71.875 (58.292)	Acc@5 87.500 (86.439)
 * Acc@1 59.188 Acc@5 86.729
==> training...
Epoch: [15][0/875]	Time 1.831 (1.831)	Data 1.324 (1.324)	Loss 1.6174 (1.6174)	Loss@kd 2.5923 (2.5923)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [15][100/875]	Time 0.525 (0.522)	Data 0.006 (0.020)	Loss 1.8220 (1.7402)	Loss@kd 2.4264 (2.5604)	Acc@1 54.688 (65.176)	Acc@5 95.312 (98.159)
Epoch: [15][200/875]	Time 0.497 (0.516)	Data 0.007 (0.014)	Loss 1.8763 (1.7395)	Loss@kd 2.5250 (2.5589)	Acc@1 48.438 (65.493)	Acc@5 96.875 (97.994)
Epoch: [15][300/875]	Time 0.522 (0.514)	Data 0.007 (0.011)	Loss 1.6641 (1.7416)	Loss@kd 2.5093 (2.5620)	Acc@1 59.375 (65.438)	Acc@5 98.438 (98.048)
Epoch: [15][400/875]	Time 0.461 (0.511)	Data 0.005 (0.010)	Loss 1.7917 (1.7459)	Loss@kd 2.4794 (2.5609)	Acc@1 67.188 (65.543)	Acc@5 100.000 (98.118)
Epoch: [15][500/875]	Time 0.494 (0.507)	Data 0.007 (0.010)	Loss 1.6424 (1.7437)	Loss@kd 2.4093 (2.5608)	Acc@1 68.750 (65.444)	Acc@5 98.438 (98.091)
Epoch: [15][600/875]	Time 0.506 (0.508)	Data 0.006 (0.009)	Loss 1.7491 (1.7433)	Loss@kd 2.4181 (2.5595)	Acc@1 60.938 (65.357)	Acc@5 98.438 (98.133)
Epoch: [15][700/875]	Time 0.493 (0.508)	Data 0.005 (0.009)	Loss 1.8744 (1.7471)	Loss@kd 2.7587 (2.5605)	Acc@1 78.125 (65.340)	Acc@5 100.000 (98.166)
Epoch: [15][800/875]	Time 0.512 (0.508)	Data 0.007 (0.009)	Loss 1.8111 (1.7501)	Loss@kd 2.4896 (2.5622)	Acc@1 64.062 (65.213)	Acc@5 100.000 (98.176)
 * Acc@1 65.204 Acc@5 98.173
epoch 15, total time 444.69
Test: [0/750]	Time 0.760 (0.760)	Loss 0.5159 (0.5159)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.039 (0.035)	Loss 0.4505 (0.7133)	Acc@1 81.250 (83.725)	Acc@5 100.000 (92.234)
Test: [200/750]	Time 0.024 (0.032)	Loss 1.8358 (0.5846)	Acc@1 40.625 (84.002)	Acc@5 90.625 (94.854)
Test: [300/750]	Time 0.022 (0.030)	Loss 1.1303 (0.8695)	Acc@1 50.000 (72.726)	Acc@5 93.750 (93.407)
Test: [400/750]	Time 0.019 (0.030)	Loss 1.2704 (1.0072)	Acc@1 59.375 (67.339)	Acc@5 84.375 (91.903)
Test: [500/750]	Time 0.039 (0.029)	Loss 1.1688 (1.0631)	Acc@1 56.250 (66.486)	Acc@5 90.625 (90.276)
Test: [600/750]	Time 0.020 (0.029)	Loss 0.9220 (1.1069)	Acc@1 59.375 (64.434)	Acc@5 93.750 (90.313)
Test: [700/750]	Time 0.020 (0.029)	Loss 2.6618 (1.1797)	Acc@1 31.250 (61.925)	Acc@5 59.375 (89.591)
 * Acc@1 60.188 Acc@5 88.421
==> training...
Epoch: [16][0/875]	Time 1.894 (1.894)	Data 1.359 (1.359)	Loss 1.7000 (1.7000)	Loss@kd 2.4527 (2.4527)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [16][100/875]	Time 0.500 (0.522)	Data 0.007 (0.021)	Loss 1.7454 (1.7552)	Loss@kd 2.5431 (2.5466)	Acc@1 50.000 (64.264)	Acc@5 96.875 (98.128)
Epoch: [16][200/875]	Time 0.468 (0.506)	Data 0.005 (0.014)	Loss 1.6991 (1.7488)	Loss@kd 2.5204 (2.5490)	Acc@1 57.812 (64.677)	Acc@5 96.875 (98.228)
Epoch: [16][300/875]	Time 0.523 (0.505)	Data 0.008 (0.012)	Loss 1.5195 (1.7479)	Loss@kd 2.4588 (2.5497)	Acc@1 78.125 (65.179)	Acc@5 100.000 (98.261)
Epoch: [16][400/875]	Time 0.488 (0.506)	Data 0.005 (0.011)	Loss 1.8228 (1.7441)	Loss@kd 2.5877 (2.5529)	Acc@1 68.750 (65.255)	Acc@5 96.875 (98.235)
Epoch: [16][500/875]	Time 0.506 (0.506)	Data 0.008 (0.010)	Loss 1.8023 (1.7500)	Loss@kd 2.5285 (2.5556)	Acc@1 65.625 (65.142)	Acc@5 98.438 (98.232)
Epoch: [16][600/875]	Time 0.497 (0.507)	Data 0.008 (0.010)	Loss 2.0192 (1.7482)	Loss@kd 2.6538 (2.5564)	Acc@1 56.250 (65.097)	Acc@5 100.000 (98.222)
Epoch: [16][700/875]	Time 0.497 (0.507)	Data 0.007 (0.009)	Loss 1.5291 (1.7481)	Loss@kd 2.4476 (2.5555)	Acc@1 70.312 (65.300)	Acc@5 100.000 (98.244)
Epoch: [16][800/875]	Time 0.530 (0.507)	Data 0.006 (0.009)	Loss 1.6236 (1.7459)	Loss@kd 2.5875 (2.5558)	Acc@1 71.875 (65.428)	Acc@5 100.000 (98.219)
 * Acc@1 65.402 Acc@5 98.234
epoch 16, total time 443.73
Test: [0/750]	Time 0.682 (0.682)	Loss 1.9779 (1.9779)	Acc@1 21.875 (21.875)	Acc@5 75.000 (75.000)
Test: [100/750]	Time 0.022 (0.029)	Loss 0.4169 (1.7040)	Acc@1 75.000 (33.137)	Acc@5 100.000 (86.757)
Test: [200/750]	Time 0.022 (0.025)	Loss 2.3830 (1.2013)	Acc@1 28.125 (54.073)	Acc@5 84.375 (91.262)
Test: [300/750]	Time 0.023 (0.024)	Loss 2.3973 (1.5666)	Acc@1 34.375 (45.214)	Acc@5 84.375 (87.033)
Test: [400/750]	Time 0.023 (0.023)	Loss 0.9908 (1.6756)	Acc@1 65.625 (42.932)	Acc@5 84.375 (86.183)
Test: [500/750]	Time 0.020 (0.023)	Loss 1.0751 (1.5500)	Acc@1 59.375 (47.798)	Acc@5 90.625 (86.876)
Test: [600/750]	Time 0.021 (0.023)	Loss 0.5804 (1.4758)	Acc@1 84.375 (50.723)	Acc@5 96.875 (87.666)
Test: [700/750]	Time 0.014 (0.022)	Loss 1.4622 (1.3833)	Acc@1 65.625 (53.856)	Acc@5 81.250 (88.646)
 * Acc@1 54.833 Acc@5 88.629
==> training...
Epoch: [17][0/875]	Time 1.714 (1.714)	Data 1.235 (1.235)	Loss 1.5174 (1.5174)	Loss@kd 2.4868 (2.4868)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [17][100/875]	Time 0.502 (0.521)	Data 0.007 (0.020)	Loss 1.4779 (1.7021)	Loss@kd 2.5127 (2.5271)	Acc@1 71.875 (66.166)	Acc@5 100.000 (98.267)
Epoch: [17][200/875]	Time 0.525 (0.515)	Data 0.007 (0.014)	Loss 1.5390 (1.7115)	Loss@kd 2.4974 (2.5417)	Acc@1 62.500 (66.091)	Acc@5 98.438 (98.274)
Epoch: [17][300/875]	Time 0.489 (0.513)	Data 0.007 (0.012)	Loss 1.5347 (1.7140)	Loss@kd 2.4690 (2.5384)	Acc@1 73.438 (66.097)	Acc@5 100.000 (98.251)
Epoch: [17][400/875]	Time 0.500 (0.513)	Data 0.007 (0.010)	Loss 1.6752 (1.7164)	Loss@kd 2.6027 (2.5399)	Acc@1 71.875 (66.194)	Acc@5 100.000 (98.309)
Epoch: [17][500/875]	Time 0.510 (0.512)	Data 0.008 (0.010)	Loss 1.9912 (1.7095)	Loss@kd 3.0210 (2.5380)	Acc@1 60.938 (66.074)	Acc@5 98.438 (98.219)
Epoch: [17][600/875]	Time 0.496 (0.511)	Data 0.007 (0.009)	Loss 1.6208 (1.7134)	Loss@kd 2.5139 (2.5415)	Acc@1 67.188 (65.812)	Acc@5 100.000 (98.217)
Epoch: [17][700/875]	Time 0.615 (0.508)	Data 0.008 (0.009)	Loss 2.0038 (1.7166)	Loss@kd 2.5142 (2.5434)	Acc@1 70.312 (65.734)	Acc@5 98.438 (98.217)
Epoch: [17][800/875]	Time 0.528 (0.508)	Data 0.008 (0.009)	Loss 1.5096 (1.7133)	Loss@kd 2.4884 (2.5411)	Acc@1 70.312 (65.650)	Acc@5 100.000 (98.231)
 * Acc@1 65.700 Acc@5 98.202
epoch 17, total time 444.93
Test: [0/750]	Time 0.731 (0.731)	Loss 0.7473 (0.7473)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.019 (0.035)	Loss 0.6794 (0.6573)	Acc@1 78.125 (82.890)	Acc@5 96.875 (91.368)
Test: [200/750]	Time 0.026 (0.031)	Loss 1.9871 (0.7387)	Acc@1 31.250 (76.975)	Acc@5 93.750 (93.128)
Test: [300/750]	Time 0.023 (0.031)	Loss 1.4930 (1.0382)	Acc@1 50.000 (65.272)	Acc@5 87.500 (92.058)
Test: [400/750]	Time 0.023 (0.030)	Loss 0.4509 (1.0938)	Acc@1 81.250 (62.290)	Acc@5 96.875 (92.332)
Test: [500/750]	Time 0.036 (0.029)	Loss 1.0476 (1.0185)	Acc@1 53.125 (65.238)	Acc@5 90.625 (92.421)
Test: [600/750]	Time 0.034 (0.029)	Loss 1.0673 (1.0571)	Acc@1 62.500 (64.346)	Acc@5 87.500 (91.504)
Test: [700/750]	Time 0.028 (0.029)	Loss 1.1256 (1.0542)	Acc@1 71.875 (64.283)	Acc@5 84.375 (91.481)
 * Acc@1 64.838 Acc@5 91.554
saving the best model!
==> training...
Epoch: [18][0/875]	Time 1.730 (1.730)	Data 1.254 (1.254)	Loss 1.6888 (1.6888)	Loss@kd 2.5640 (2.5640)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [18][100/875]	Time 0.521 (0.523)	Data 0.007 (0.020)	Loss 1.5229 (1.7185)	Loss@kd 2.5736 (2.5427)	Acc@1 84.375 (66.569)	Acc@5 100.000 (98.128)
Epoch: [18][200/875]	Time 0.510 (0.516)	Data 0.007 (0.014)	Loss 1.6349 (1.7187)	Loss@kd 2.5660 (2.5336)	Acc@1 54.688 (66.045)	Acc@5 93.750 (98.150)
Epoch: [18][300/875]	Time 0.497 (0.514)	Data 0.010 (0.012)	Loss 1.7599 (1.7205)	Loss@kd 2.5291 (2.5313)	Acc@1 67.188 (65.718)	Acc@5 96.875 (98.157)
Epoch: [18][400/875]	Time 0.519 (0.513)	Data 0.008 (0.010)	Loss 1.7480 (1.7236)	Loss@kd 2.5581 (2.5377)	Acc@1 62.500 (65.715)	Acc@5 96.875 (98.161)
Epoch: [18][500/875]	Time 0.509 (0.505)	Data 0.006 (0.010)	Loss 1.6900 (1.7183)	Loss@kd 2.8099 (2.5368)	Acc@1 73.438 (65.890)	Acc@5 100.000 (98.166)
Epoch: [18][600/875]	Time 0.617 (0.506)	Data 0.008 (0.009)	Loss 1.7505 (1.7145)	Loss@kd 2.5316 (2.5368)	Acc@1 65.625 (65.828)	Acc@5 98.438 (98.248)
Epoch: [18][700/875]	Time 0.529 (0.506)	Data 0.007 (0.009)	Loss 1.4624 (1.7103)	Loss@kd 2.4580 (2.5336)	Acc@1 70.312 (65.821)	Acc@5 98.438 (98.246)
Epoch: [18][800/875]	Time 0.510 (0.507)	Data 0.007 (0.009)	Loss 1.7602 (1.7069)	Loss@kd 2.5073 (2.5318)	Acc@1 68.750 (65.791)	Acc@5 98.438 (98.244)
 * Acc@1 65.782 Acc@5 98.229
epoch 18, total time 443.80
Test: [0/750]	Time 0.680 (0.680)	Loss 0.5602 (0.5602)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.017 (0.036)	Loss 0.5120 (0.5678)	Acc@1 81.250 (84.066)	Acc@5 96.875 (93.967)
Test: [200/750]	Time 0.024 (0.032)	Loss 2.5477 (0.6985)	Acc@1 15.625 (78.498)	Acc@5 90.625 (93.905)
Test: [300/750]	Time 0.027 (0.031)	Loss 2.3980 (1.1611)	Acc@1 40.625 (62.386)	Acc@5 84.375 (91.933)
Test: [400/750]	Time 0.041 (0.031)	Loss 2.7435 (1.5481)	Acc@1 21.875 (53.413)	Acc@5 71.875 (88.014)
Test: [500/750]	Time 0.026 (0.030)	Loss 0.8534 (1.7390)	Acc@1 81.250 (50.106)	Acc@5 96.875 (85.049)
Test: [600/750]	Time 0.023 (0.030)	Loss 1.6774 (1.6489)	Acc@1 46.875 (51.851)	Acc@5 71.875 (85.503)
Test: [700/750]	Time 0.032 (0.030)	Loss 0.4037 (1.5646)	Acc@1 87.500 (53.428)	Acc@5 93.750 (85.966)
 * Acc@1 55.708 Acc@5 86.737
==> training...
Epoch: [19][0/875]	Time 1.842 (1.842)	Data 1.305 (1.305)	Loss 1.6266 (1.6266)	Loss@kd 2.4498 (2.4498)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [19][100/875]	Time 0.495 (0.523)	Data 0.007 (0.020)	Loss 1.6410 (1.7220)	Loss@kd 2.5185 (2.5515)	Acc@1 64.062 (65.377)	Acc@5 100.000 (98.113)
Epoch: [19][200/875]	Time 0.509 (0.516)	Data 0.006 (0.014)	Loss 1.8588 (1.7070)	Loss@kd 2.5663 (2.5353)	Acc@1 64.062 (65.415)	Acc@5 96.875 (98.072)
Epoch: [19][300/875]	Time 0.496 (0.505)	Data 0.007 (0.011)	Loss 1.9194 (1.7133)	Loss@kd 2.4666 (2.5392)	Acc@1 57.812 (65.599)	Acc@5 100.000 (98.069)
Epoch: [19][400/875]	Time 0.524 (0.506)	Data 0.008 (0.010)	Loss 1.8072 (1.7057)	Loss@kd 2.6928 (2.5367)	Acc@1 62.500 (65.676)	Acc@5 98.438 (98.145)
Epoch: [19][500/875]	Time 0.496 (0.507)	Data 0.008 (0.010)	Loss 1.5566 (1.7094)	Loss@kd 2.4319 (2.5364)	Acc@1 68.750 (65.690)	Acc@5 100.000 (98.147)
Epoch: [19][600/875]	Time 0.512 (0.507)	Data 0.008 (0.009)	Loss 1.8072 (1.7084)	Loss@kd 2.4650 (2.5362)	Acc@1 73.438 (65.563)	Acc@5 96.875 (98.152)
Epoch: [19][700/875]	Time 0.522 (0.508)	Data 0.008 (0.009)	Loss 1.6468 (1.7100)	Loss@kd 2.4944 (2.5347)	Acc@1 73.438 (65.585)	Acc@5 96.875 (98.154)
Epoch: [19][800/875]	Time 0.520 (0.508)	Data 0.007 (0.009)	Loss 1.7400 (1.7118)	Loss@kd 2.6613 (2.5352)	Acc@1 68.750 (65.442)	Acc@5 100.000 (98.162)
 * Acc@1 65.541 Acc@5 98.170
epoch 19, total time 444.65
Test: [0/750]	Time 0.775 (0.775)	Loss 0.7923 (0.7923)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.025 (0.035)	Loss 0.5105 (0.5860)	Acc@1 84.375 (84.623)	Acc@5 96.875 (93.410)
Test: [200/750]	Time 0.038 (0.033)	Loss 2.1504 (0.6294)	Acc@1 21.875 (80.022)	Acc@5 71.875 (94.387)
Test: [300/750]	Time 0.021 (0.031)	Loss 1.0089 (1.0063)	Acc@1 59.375 (65.988)	Acc@5 96.875 (91.186)
Test: [400/750]	Time 0.044 (0.031)	Loss 1.0645 (1.0668)	Acc@1 68.750 (63.825)	Acc@5 84.375 (91.521)
Test: [500/750]	Time 0.029 (0.030)	Loss 1.1931 (1.1052)	Acc@1 56.250 (63.454)	Acc@5 87.500 (90.382)
Test: [600/750]	Time 0.025 (0.029)	Loss 0.5733 (1.1204)	Acc@1 81.250 (63.348)	Acc@5 96.875 (90.069)
Test: [700/750]	Time 0.021 (0.028)	Loss 1.3035 (1.0969)	Acc@1 50.000 (63.614)	Acc@5 87.500 (90.621)
 * Acc@1 63.442 Acc@5 90.571
==> training...
Epoch: [20][0/875]	Time 1.749 (1.749)	Data 1.295 (1.295)	Loss 1.5143 (1.5143)	Loss@kd 2.3956 (2.3956)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [20][100/875]	Time 0.499 (0.500)	Data 0.005 (0.019)	Loss 1.9640 (1.6791)	Loss@kd 2.5172 (2.5139)	Acc@1 56.250 (65.439)	Acc@5 95.312 (98.298)
Epoch: [20][200/875]	Time 0.525 (0.505)	Data 0.007 (0.013)	Loss 1.7624 (1.6903)	Loss@kd 2.5187 (2.5192)	Acc@1 59.375 (65.711)	Acc@5 100.000 (98.352)
Epoch: [20][300/875]	Time 0.497 (0.506)	Data 0.007 (0.011)	Loss 1.7596 (1.6881)	Loss@kd 2.5707 (2.5145)	Acc@1 71.875 (66.071)	Acc@5 98.438 (98.303)
Epoch: [20][400/875]	Time 0.521 (0.507)	Data 0.008 (0.010)	Loss 1.7023 (1.6936)	Loss@kd 2.4593 (2.5221)	Acc@1 50.000 (65.812)	Acc@5 98.438 (98.215)
Epoch: [20][500/875]	Time 0.493 (0.507)	Data 0.007 (0.010)	Loss 1.7122 (1.7013)	Loss@kd 2.5333 (2.5243)	Acc@1 65.625 (65.896)	Acc@5 98.438 (98.163)
Epoch: [20][600/875]	Time 0.529 (0.508)	Data 0.007 (0.009)	Loss 1.7858 (1.7016)	Loss@kd 2.5023 (2.5249)	Acc@1 70.312 (65.963)	Acc@5 98.438 (98.185)
Epoch: [20][700/875]	Time 0.471 (0.507)	Data 0.008 (0.009)	Loss 1.5276 (1.6981)	Loss@kd 2.5642 (2.5231)	Acc@1 64.062 (66.073)	Acc@5 98.438 (98.201)
Epoch: [20][800/875]	Time 0.520 (0.505)	Data 0.008 (0.009)	Loss 1.7872 (1.6934)	Loss@kd 2.4822 (2.5217)	Acc@1 67.188 (66.011)	Acc@5 100.000 (98.237)
 * Acc@1 65.934 Acc@5 98.241
epoch 20, total time 442.53
Test: [0/750]	Time 0.691 (0.691)	Loss 0.5578 (0.5578)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.026 (0.036)	Loss 0.2873 (0.6863)	Acc@1 93.750 (81.528)	Acc@5 100.000 (92.636)
Test: [200/750]	Time 0.035 (0.033)	Loss 3.1654 (0.7595)	Acc@1 15.625 (77.876)	Acc@5 37.500 (92.024)
Test: [300/750]	Time 0.027 (0.032)	Loss 2.6660 (1.5377)	Acc@1 21.875 (56.292)	Acc@5 71.875 (77.637)
Test: [400/750]	Time 0.019 (0.031)	Loss 0.3340 (1.6636)	Acc@1 81.250 (51.504)	Acc@5 93.750 (77.408)
Test: [500/750]	Time 0.018 (0.030)	Loss 1.1810 (1.4745)	Acc@1 46.875 (56.306)	Acc@5 100.000 (80.714)
Test: [600/750]	Time 0.038 (0.030)	Loss 0.7283 (1.4315)	Acc@1 71.875 (56.364)	Acc@5 93.750 (82.415)
Test: [700/750]	Time 0.025 (0.029)	Loss 1.5428 (1.3808)	Acc@1 46.875 (57.369)	Acc@5 81.250 (83.818)
 * Acc@1 57.879 Acc@5 83.958
==> training...
Epoch: [21][0/875]	Time 1.712 (1.712)	Data 1.215 (1.215)	Loss 1.8213 (1.8213)	Loss@kd 2.6190 (2.6190)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [21][100/875]	Time 0.519 (0.521)	Data 0.006 (0.019)	Loss 1.5475 (1.6749)	Loss@kd 2.7091 (2.5308)	Acc@1 70.312 (66.105)	Acc@5 100.000 (98.159)
Epoch: [21][200/875]	Time 0.491 (0.515)	Data 0.007 (0.013)	Loss 1.6758 (1.6755)	Loss@kd 2.5041 (2.5207)	Acc@1 68.750 (65.617)	Acc@5 100.000 (98.313)
Epoch: [21][300/875]	Time 0.529 (0.513)	Data 0.008 (0.011)	Loss 1.5535 (1.6749)	Loss@kd 2.5003 (2.5162)	Acc@1 68.750 (65.407)	Acc@5 96.875 (98.303)
Epoch: [21][400/875]	Time 0.512 (0.512)	Data 0.007 (0.010)	Loss 1.7826 (1.6751)	Loss@kd 2.7986 (2.5172)	Acc@1 65.625 (65.567)	Acc@5 98.438 (98.262)
Epoch: [21][500/875]	Time 0.467 (0.508)	Data 0.007 (0.010)	Loss 1.5182 (1.6792)	Loss@kd 2.4977 (2.5187)	Acc@1 64.062 (65.681)	Acc@5 98.438 (98.260)
Epoch: [21][600/875]	Time 0.524 (0.507)	Data 0.007 (0.009)	Loss 1.5153 (1.6773)	Loss@kd 2.4775 (2.5191)	Acc@1 67.188 (65.916)	Acc@5 100.000 (98.263)
Epoch: [21][700/875]	Time 0.505 (0.507)	Data 0.006 (0.009)	Loss 1.8644 (1.6787)	Loss@kd 2.6831 (2.5209)	Acc@1 67.188 (65.986)	Acc@5 96.875 (98.302)
Epoch: [21][800/875]	Time 0.521 (0.507)	Data 0.008 (0.009)	Loss 1.6325 (1.6827)	Loss@kd 2.5433 (2.5206)	Acc@1 64.062 (65.888)	Acc@5 96.875 (98.303)
 * Acc@1 65.843 Acc@5 98.280
epoch 21, total time 444.15
Test: [0/750]	Time 0.632 (0.632)	Loss 0.7979 (0.7979)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.016 (0.031)	Loss 0.4356 (0.8442)	Acc@1 90.625 (80.291)	Acc@5 96.875 (89.975)
Test: [200/750]	Time 0.015 (0.028)	Loss 1.7217 (0.7787)	Acc@1 37.500 (78.591)	Acc@5 96.875 (92.413)
Test: [300/750]	Time 0.032 (0.028)	Loss 1.8347 (1.0598)	Acc@1 25.000 (67.535)	Acc@5 90.625 (91.373)
Test: [400/750]	Time 0.024 (0.027)	Loss 0.4501 (1.2471)	Acc@1 87.500 (60.458)	Acc@5 93.750 (90.087)
Test: [500/750]	Time 0.014 (0.027)	Loss 0.4565 (1.1836)	Acc@1 87.500 (63.167)	Acc@5 96.875 (89.939)
Test: [600/750]	Time 0.018 (0.026)	Loss 1.1389 (1.1430)	Acc@1 59.375 (64.263)	Acc@5 90.625 (90.334)
Test: [700/750]	Time 0.024 (0.026)	Loss 3.1216 (1.2498)	Acc@1 28.125 (62.005)	Acc@5 62.500 (88.646)
 * Acc@1 60.112 Acc@5 86.883
==> training...
Epoch: [22][0/875]	Time 1.791 (1.791)	Data 1.278 (1.278)	Loss 1.6325 (1.6325)	Loss@kd 2.4010 (2.4010)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [22][100/875]	Time 0.524 (0.522)	Data 0.007 (0.019)	Loss 1.6837 (1.7160)	Loss@kd 2.4992 (2.5236)	Acc@1 65.625 (66.012)	Acc@5 98.438 (98.066)
Epoch: [22][200/875]	Time 0.497 (0.516)	Data 0.007 (0.013)	Loss 1.6396 (1.6992)	Loss@kd 2.3914 (2.5214)	Acc@1 62.500 (65.843)	Acc@5 93.750 (98.165)
Epoch: [22][300/875]	Time 0.423 (0.504)	Data 0.005 (0.011)	Loss 1.6485 (1.6926)	Loss@kd 2.6720 (2.5153)	Acc@1 65.625 (65.957)	Acc@5 100.000 (98.147)
Epoch: [22][400/875]	Time 0.493 (0.505)	Data 0.006 (0.010)	Loss 1.6518 (1.6879)	Loss@kd 2.4275 (2.5156)	Acc@1 65.625 (66.050)	Acc@5 100.000 (98.165)
Epoch: [22][500/875]	Time 0.521 (0.506)	Data 0.007 (0.009)	Loss 1.7136 (1.6825)	Loss@kd 2.5089 (2.5131)	Acc@1 65.625 (66.096)	Acc@5 96.875 (98.225)
Epoch: [22][600/875]	Time 0.497 (0.507)	Data 0.007 (0.009)	Loss 1.9956 (1.6817)	Loss@kd 3.0163 (2.5135)	Acc@1 67.188 (65.986)	Acc@5 95.312 (98.258)
Epoch: [22][700/875]	Time 0.510 (0.507)	Data 0.007 (0.009)	Loss 1.7749 (1.6825)	Loss@kd 2.5972 (2.5154)	Acc@1 68.750 (65.926)	Acc@5 100.000 (98.248)
Epoch: [22][800/875]	Time 0.526 (0.507)	Data 0.010 (0.008)	Loss 1.6895 (1.6803)	Loss@kd 2.4660 (2.5145)	Acc@1 54.688 (65.941)	Acc@5 96.875 (98.252)
 * Acc@1 65.918 Acc@5 98.239
epoch 22, total time 444.25
Test: [0/750]	Time 0.699 (0.699)	Loss 0.7110 (0.7110)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.028 (0.034)	Loss 0.4910 (0.6159)	Acc@1 81.250 (82.983)	Acc@5 96.875 (92.760)
Test: [200/750]	Time 0.019 (0.032)	Loss 1.0235 (0.5827)	Acc@1 50.000 (81.530)	Acc@5 100.000 (94.729)
Test: [300/750]	Time 0.023 (0.031)	Loss 1.2794 (0.7396)	Acc@1 46.875 (73.630)	Acc@5 87.500 (94.944)
Test: [400/750]	Time 0.026 (0.030)	Loss 1.2566 (0.8673)	Acc@1 71.875 (68.882)	Acc@5 84.375 (93.571)
Test: [500/750]	Time 0.028 (0.030)	Loss 0.4394 (0.9184)	Acc@1 81.250 (68.307)	Acc@5 100.000 (92.072)
Test: [600/750]	Time 0.026 (0.030)	Loss 1.2127 (0.9268)	Acc@1 59.375 (67.694)	Acc@5 81.250 (92.102)
Test: [700/750]	Time 0.017 (0.030)	Loss 2.0348 (0.9877)	Acc@1 43.750 (65.683)	Acc@5 71.875 (91.334)
 * Acc@1 64.871 Acc@5 90.608
saving the best model!
==> training...
Epoch: [23][0/875]	Time 1.775 (1.775)	Data 1.297 (1.297)	Loss 1.5203 (1.5203)	Loss@kd 2.4611 (2.4611)	Acc@1 59.375 (59.375)	Acc@5 96.875 (96.875)
Epoch: [23][100/875]	Time 0.496 (0.489)	Data 0.007 (0.019)	Loss 1.5843 (1.6804)	Loss@kd 2.4509 (2.5167)	Acc@1 65.625 (65.424)	Acc@5 98.438 (98.298)
Epoch: [23][200/875]	Time 0.489 (0.498)	Data 0.007 (0.013)	Loss 1.5925 (1.6688)	Loss@kd 2.4312 (2.5171)	Acc@1 64.062 (65.602)	Acc@5 98.438 (98.430)
Epoch: [23][300/875]	Time 0.522 (0.502)	Data 0.006 (0.011)	Loss 1.8875 (1.6792)	Loss@kd 2.4584 (2.5163)	Acc@1 68.750 (65.609)	Acc@5 100.000 (98.334)
Epoch: [23][400/875]	Time 0.509 (0.504)	Data 0.007 (0.010)	Loss 1.8464 (1.6839)	Loss@kd 2.6715 (2.5196)	Acc@1 64.062 (65.691)	Acc@5 98.438 (98.301)
Epoch: [23][500/875]	Time 0.525 (0.505)	Data 0.007 (0.009)	Loss 1.6079 (1.6839)	Loss@kd 2.4893 (2.5185)	Acc@1 65.625 (65.712)	Acc@5 96.875 (98.285)
Epoch: [23][600/875]	Time 0.511 (0.506)	Data 0.007 (0.009)	Loss 1.4586 (1.6844)	Loss@kd 2.3832 (2.5192)	Acc@1 65.625 (65.804)	Acc@5 98.438 (98.289)
Epoch: [23][700/875]	Time 0.514 (0.506)	Data 0.007 (0.009)	Loss 1.6678 (1.6829)	Loss@kd 2.5116 (2.5168)	Acc@1 64.062 (65.850)	Acc@5 98.438 (98.288)
Epoch: [23][800/875]	Time 0.497 (0.504)	Data 0.007 (0.008)	Loss 1.7441 (1.6802)	Loss@kd 2.5191 (2.5165)	Acc@1 64.062 (65.900)	Acc@5 100.000 (98.322)
 * Acc@1 65.982 Acc@5 98.338
epoch 23, total time 441.34
Test: [0/750]	Time 0.633 (0.633)	Loss 0.5818 (0.5818)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.030 (0.033)	Loss 0.5867 (0.4888)	Acc@1 75.000 (85.582)	Acc@5 96.875 (94.864)
Test: [200/750]	Time 0.035 (0.030)	Loss 1.9496 (0.5720)	Acc@1 21.875 (80.644)	Acc@5 78.125 (95.149)
Test: [300/750]	Time 0.020 (0.029)	Loss 1.1772 (0.9450)	Acc@1 62.500 (66.082)	Acc@5 96.875 (92.130)
Test: [400/750]	Time 0.028 (0.029)	Loss 1.2691 (1.0163)	Acc@1 68.750 (63.178)	Acc@5 78.125 (92.028)
Test: [500/750]	Time 0.018 (0.029)	Loss 1.1849 (1.0445)	Acc@1 59.375 (63.641)	Acc@5 90.625 (90.656)
Test: [600/750]	Time 0.025 (0.029)	Loss 1.0568 (1.0701)	Acc@1 59.375 (63.082)	Acc@5 87.500 (90.089)
Test: [700/750]	Time 0.040 (0.029)	Loss 1.3611 (1.0564)	Acc@1 53.125 (63.512)	Acc@5 81.250 (90.255)
 * Acc@1 63.954 Acc@5 90.125
==> training...
Epoch: [24][0/875]	Time 1.730 (1.730)	Data 1.214 (1.214)	Loss 1.4985 (1.4985)	Loss@kd 2.4670 (2.4670)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [24][100/875]	Time 0.498 (0.522)	Data 0.007 (0.019)	Loss 1.8054 (1.6627)	Loss@kd 2.5530 (2.5028)	Acc@1 57.812 (66.476)	Acc@5 100.000 (98.329)
Epoch: [24][200/875]	Time 0.504 (0.517)	Data 0.007 (0.013)	Loss 1.6341 (1.6511)	Loss@kd 2.5693 (2.5045)	Acc@1 67.188 (66.472)	Acc@5 95.312 (98.352)
Epoch: [24][300/875]	Time 0.504 (0.514)	Data 0.006 (0.011)	Loss 2.0414 (1.6620)	Loss@kd 2.6239 (2.5063)	Acc@1 53.125 (66.180)	Acc@5 95.312 (98.339)
Epoch: [24][400/875]	Time 0.522 (0.513)	Data 0.007 (0.010)	Loss 1.7151 (1.6625)	Loss@kd 2.6372 (2.5041)	Acc@1 59.375 (66.400)	Acc@5 96.875 (98.286)
Epoch: [24][500/875]	Time 0.501 (0.512)	Data 0.007 (0.010)	Loss 1.4487 (1.6669)	Loss@kd 2.4768 (2.5079)	Acc@1 67.188 (66.414)	Acc@5 98.438 (98.238)
Epoch: [24][600/875]	Time 0.499 (0.507)	Data 0.006 (0.009)	Loss 1.8297 (1.6695)	Loss@kd 2.5366 (2.5104)	Acc@1 60.938 (66.327)	Acc@5 96.875 (98.227)
Epoch: [24][700/875]	Time 0.520 (0.507)	Data 0.008 (0.009)	Loss 1.5573 (1.6704)	Loss@kd 2.4394 (2.5105)	Acc@1 65.625 (66.289)	Acc@5 98.438 (98.186)
Epoch: [24][800/875]	Time 0.466 (0.507)	Data 0.007 (0.009)	Loss 1.4282 (1.6677)	Loss@kd 2.4284 (2.5094)	Acc@1 78.125 (66.245)	Acc@5 100.000 (98.201)
 * Acc@1 66.327 Acc@5 98.186
epoch 24, total time 444.37
Test: [0/750]	Time 0.720 (0.720)	Loss 0.9619 (0.9619)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.034 (0.035)	Loss 0.3063 (0.8874)	Acc@1 90.625 (79.455)	Acc@5 100.000 (89.821)
Test: [200/750]	Time 0.019 (0.032)	Loss 2.1527 (0.7330)	Acc@1 18.750 (80.519)	Acc@5 81.250 (93.439)
Test: [300/750]	Time 0.018 (0.030)	Loss 1.0669 (1.1229)	Acc@1 56.250 (63.445)	Acc@5 100.000 (92.162)
Test: [400/750]	Time 0.021 (0.029)	Loss 1.7857 (1.2341)	Acc@1 50.000 (59.695)	Acc@5 87.500 (91.521)
Test: [500/750]	Time 0.036 (0.029)	Loss 0.6145 (1.3131)	Acc@1 78.125 (58.913)	Acc@5 100.000 (89.303)
Test: [600/750]	Time 0.015 (0.028)	Loss 1.3627 (1.2954)	Acc@1 53.125 (59.484)	Acc@5 87.500 (89.211)
Test: [700/750]	Time 0.018 (0.028)	Loss 0.7032 (1.2657)	Acc@1 78.125 (59.874)	Acc@5 93.750 (89.925)
 * Acc@1 61.188 Acc@5 90.458
==> training...
Epoch: [25][0/875]	Time 1.830 (1.830)	Data 1.317 (1.317)	Loss 1.9576 (1.9576)	Loss@kd 2.5173 (2.5173)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [25][100/875]	Time 0.515 (0.522)	Data 0.007 (0.020)	Loss 1.5678 (1.6599)	Loss@kd 2.4477 (2.4984)	Acc@1 67.188 (65.176)	Acc@5 98.438 (98.221)
Epoch: [25][200/875]	Time 0.495 (0.516)	Data 0.007 (0.014)	Loss 1.7994 (1.6462)	Loss@kd 2.6042 (2.4964)	Acc@1 65.625 (65.843)	Acc@5 98.438 (98.336)
Epoch: [25][300/875]	Time 0.464 (0.512)	Data 0.007 (0.012)	Loss 1.6150 (1.6466)	Loss@kd 2.5361 (2.5017)	Acc@1 60.938 (66.004)	Acc@5 98.438 (98.365)
Epoch: [25][400/875]	Time 0.488 (0.506)	Data 0.007 (0.010)	Loss 1.7964 (1.6590)	Loss@kd 2.4125 (2.5063)	Acc@1 57.812 (65.999)	Acc@5 98.438 (98.297)
Epoch: [25][500/875]	Time 0.503 (0.507)	Data 0.008 (0.010)	Loss 1.7705 (1.6567)	Loss@kd 2.4576 (2.5025)	Acc@1 68.750 (65.996)	Acc@5 98.438 (98.244)
Epoch: [25][600/875]	Time 0.498 (0.507)	Data 0.007 (0.009)	Loss 1.6940 (1.6609)	Loss@kd 2.5630 (2.5084)	Acc@1 70.312 (66.051)	Acc@5 98.438 (98.276)
Epoch: [25][700/875]	Time 0.522 (0.507)	Data 0.006 (0.009)	Loss 1.7221 (1.6585)	Loss@kd 2.5369 (2.5054)	Acc@1 67.188 (66.200)	Acc@5 95.312 (98.339)
Epoch: [25][800/875]	Time 0.492 (0.508)	Data 0.007 (0.009)	Loss 1.7244 (1.6580)	Loss@kd 2.6029 (2.5045)	Acc@1 65.625 (66.216)	Acc@5 98.438 (98.348)
 * Acc@1 66.207 Acc@5 98.336
epoch 25, total time 444.48
Test: [0/750]	Time 0.706 (0.706)	Loss 0.7619 (0.7619)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.021 (0.036)	Loss 0.9056 (0.6725)	Acc@1 59.375 (81.621)	Acc@5 96.875 (92.110)
Test: [200/750]	Time 0.032 (0.034)	Loss 1.9670 (0.9432)	Acc@1 34.375 (70.802)	Acc@5 81.250 (91.371)
Test: [300/750]	Time 0.030 (0.032)	Loss 1.2260 (1.2057)	Acc@1 62.500 (59.894)	Acc@5 96.875 (89.379)
Test: [400/750]	Time 0.023 (0.031)	Loss 1.0640 (1.2054)	Acc@1 68.750 (58.674)	Acc@5 87.500 (90.563)
Test: [500/750]	Time 0.021 (0.031)	Loss 1.3328 (1.1945)	Acc@1 50.000 (59.712)	Acc@5 93.750 (89.808)
Test: [600/750]	Time 0.028 (0.030)	Loss 0.8504 (1.2107)	Acc@1 62.500 (59.365)	Acc@5 90.625 (89.127)
Test: [700/750]	Time 0.036 (0.030)	Loss 0.9780 (1.1604)	Acc@1 62.500 (60.966)	Acc@5 90.625 (89.867)
 * Acc@1 62.013 Acc@5 90.204
==> training...
Epoch: [26][0/875]	Time 1.897 (1.897)	Data 1.382 (1.382)	Loss 1.6590 (1.6590)	Loss@kd 2.3893 (2.3893)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [26][100/875]	Time 0.473 (0.509)	Data 0.008 (0.020)	Loss 1.7017 (1.6734)	Loss@kd 2.5926 (2.5015)	Acc@1 54.688 (65.517)	Acc@5 100.000 (97.896)
Epoch: [26][200/875]	Time 0.503 (0.504)	Data 0.007 (0.014)	Loss 1.7003 (1.6709)	Loss@kd 2.5048 (2.5002)	Acc@1 67.188 (65.501)	Acc@5 98.438 (98.197)
Epoch: [26][300/875]	Time 0.492 (0.506)	Data 0.008 (0.012)	Loss 1.4785 (1.6639)	Loss@kd 2.4639 (2.5026)	Acc@1 73.438 (66.222)	Acc@5 98.438 (98.235)
Epoch: [26][400/875]	Time 0.531 (0.507)	Data 0.007 (0.010)	Loss 1.7321 (1.6578)	Loss@kd 2.5992 (2.5003)	Acc@1 62.500 (66.186)	Acc@5 100.000 (98.282)
Epoch: [26][500/875]	Time 0.497 (0.507)	Data 0.007 (0.010)	Loss 1.8254 (1.6591)	Loss@kd 2.5949 (2.5018)	Acc@1 56.250 (66.336)	Acc@5 96.875 (98.275)
Epoch: [26][600/875]	Time 0.497 (0.508)	Data 0.006 (0.009)	Loss 1.7314 (1.6560)	Loss@kd 2.4949 (2.5024)	Acc@1 73.438 (66.389)	Acc@5 96.875 (98.297)
Epoch: [26][700/875]	Time 0.525 (0.508)	Data 0.008 (0.009)	Loss 1.3512 (1.6571)	Loss@kd 2.3965 (2.5030)	Acc@1 73.438 (66.394)	Acc@5 100.000 (98.344)
Epoch: [26][800/875]	Time 0.468 (0.506)	Data 0.007 (0.009)	Loss 1.5291 (1.6573)	Loss@kd 2.3814 (2.5022)	Acc@1 65.625 (66.380)	Acc@5 98.438 (98.348)
 * Acc@1 66.375 Acc@5 98.334
epoch 26, total time 442.48
Test: [0/750]	Time 0.817 (0.817)	Loss 0.6576 (0.6576)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.025 (0.038)	Loss 0.3781 (0.5330)	Acc@1 90.625 (85.210)	Acc@5 96.875 (93.750)
Test: [200/750]	Time 0.029 (0.033)	Loss 1.4166 (0.5701)	Acc@1 40.625 (82.494)	Acc@5 87.500 (94.512)
Test: [300/750]	Time 0.027 (0.032)	Loss 1.6971 (0.8492)	Acc@1 53.125 (70.037)	Acc@5 87.500 (93.137)
Test: [400/750]	Time 0.038 (0.031)	Loss 0.8337 (0.9811)	Acc@1 75.000 (65.625)	Acc@5 93.750 (92.113)
Test: [500/750]	Time 0.027 (0.030)	Loss 0.5419 (0.9697)	Acc@1 81.250 (66.442)	Acc@5 100.000 (91.748)
Test: [600/750]	Time 0.028 (0.030)	Loss 1.5698 (0.9982)	Acc@1 50.000 (65.479)	Acc@5 87.500 (91.467)
Test: [700/750]	Time 0.022 (0.030)	Loss 1.1363 (1.0354)	Acc@1 68.750 (64.185)	Acc@5 84.375 (90.937)
 * Acc@1 64.329 Acc@5 90.671
==> training...
Epoch: [27][0/875]	Time 1.928 (1.928)	Data 1.371 (1.371)	Loss 1.4866 (1.4866)	Loss@kd 2.3776 (2.3776)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [27][100/875]	Time 0.524 (0.524)	Data 0.008 (0.021)	Loss 1.6318 (1.6814)	Loss@kd 2.6186 (2.5015)	Acc@1 62.500 (66.182)	Acc@5 96.875 (98.159)
Epoch: [27][200/875]	Time 0.498 (0.516)	Data 0.007 (0.014)	Loss 1.5309 (1.6872)	Loss@kd 2.6036 (2.5169)	Acc@1 65.625 (66.472)	Acc@5 98.438 (98.313)
Epoch: [27][300/875]	Time 0.494 (0.514)	Data 0.007 (0.012)	Loss 1.8562 (1.6778)	Loss@kd 2.5426 (2.5194)	Acc@1 59.375 (66.523)	Acc@5 95.312 (98.334)
Epoch: [27][400/875]	Time 0.513 (0.513)	Data 0.006 (0.010)	Loss 1.7261 (1.6647)	Loss@kd 2.4832 (2.5085)	Acc@1 65.625 (66.654)	Acc@5 100.000 (98.317)
Epoch: [27][500/875]	Time 0.497 (0.513)	Data 0.007 (0.010)	Loss 1.7924 (1.6523)	Loss@kd 2.5037 (2.5007)	Acc@1 71.875 (66.582)	Acc@5 100.000 (98.338)
Epoch: [27][600/875]	Time 0.520 (0.508)	Data 0.007 (0.009)	Loss 1.6766 (1.6574)	Loss@kd 2.4008 (2.5023)	Acc@1 62.500 (66.486)	Acc@5 100.000 (98.328)
Epoch: [27][700/875]	Time 0.501 (0.508)	Data 0.006 (0.009)	Loss 1.7103 (1.6552)	Loss@kd 2.4436 (2.4990)	Acc@1 68.750 (66.532)	Acc@5 98.438 (98.281)
Epoch: [27][800/875]	Time 0.506 (0.509)	Data 0.007 (0.009)	Loss 1.6324 (1.6559)	Loss@kd 2.4127 (2.4985)	Acc@1 73.438 (66.542)	Acc@5 100.000 (98.221)
 * Acc@1 66.554 Acc@5 98.243
epoch 27, total time 445.23
Test: [0/750]	Time 0.760 (0.760)	Loss 0.6611 (0.6611)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.029 (0.037)	Loss 0.5804 (0.4825)	Acc@1 81.250 (85.458)	Acc@5 96.875 (94.121)
Test: [200/750]	Time 0.022 (0.033)	Loss 1.4454 (0.6036)	Acc@1 46.875 (80.239)	Acc@5 90.625 (94.683)
Test: [300/750]	Time 0.038 (0.032)	Loss 1.7710 (0.9278)	Acc@1 40.625 (67.805)	Acc@5 84.375 (93.106)
Test: [400/750]	Time 0.030 (0.031)	Loss 1.1553 (1.0967)	Acc@1 68.750 (62.469)	Acc@5 87.500 (91.397)
Test: [500/750]	Time 0.023 (0.031)	Loss 0.2804 (1.0985)	Acc@1 93.750 (63.367)	Acc@5 100.000 (90.725)
Test: [600/750]	Time 0.023 (0.030)	Loss 0.9407 (1.0534)	Acc@1 71.875 (64.907)	Acc@5 87.500 (91.098)
Test: [700/750]	Time 0.028 (0.030)	Loss 0.9497 (1.0437)	Acc@1 71.875 (65.291)	Acc@5 87.500 (91.316)
 * Acc@1 65.842 Acc@5 91.321
saving the best model!
==> training...
Epoch: [28][0/875]	Time 1.751 (1.751)	Data 1.264 (1.264)	Loss 1.7116 (1.7116)	Loss@kd 2.4896 (2.4896)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [28][100/875]	Time 0.493 (0.522)	Data 0.007 (0.019)	Loss 1.4100 (1.6631)	Loss@kd 2.4409 (2.4937)	Acc@1 71.875 (67.141)	Acc@5 98.438 (98.376)
Epoch: [28][200/875]	Time 0.459 (0.515)	Data 0.007 (0.013)	Loss 1.7934 (1.6573)	Loss@kd 2.5359 (2.5009)	Acc@1 76.562 (66.581)	Acc@5 98.438 (98.445)
Epoch: [28][300/875]	Time 0.501 (0.513)	Data 0.007 (0.011)	Loss 1.4093 (1.6498)	Loss@kd 2.5031 (2.5023)	Acc@1 70.312 (66.705)	Acc@5 98.438 (98.391)
Epoch: [28][400/875]	Time 0.532 (0.506)	Data 0.007 (0.010)	Loss 1.7582 (1.6482)	Loss@kd 2.4141 (2.5006)	Acc@1 60.938 (66.541)	Acc@5 98.438 (98.301)
Epoch: [28][500/875]	Time 0.497 (0.506)	Data 0.009 (0.009)	Loss 1.5129 (1.6446)	Loss@kd 2.3637 (2.4984)	Acc@1 62.500 (66.492)	Acc@5 96.875 (98.331)
Epoch: [28][600/875]	Time 0.522 (0.507)	Data 0.008 (0.009)	Loss 1.6955 (1.6421)	Loss@kd 2.5405 (2.4950)	Acc@1 64.062 (66.470)	Acc@5 95.312 (98.326)
Epoch: [28][700/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss 1.5680 (1.6390)	Loss@kd 2.6628 (2.4955)	Acc@1 76.562 (66.541)	Acc@5 100.000 (98.324)
Epoch: [28][800/875]	Time 0.515 (0.507)	Data 0.007 (0.009)	Loss 1.7021 (1.6401)	Loss@kd 2.4219 (2.4951)	Acc@1 60.938 (66.520)	Acc@5 98.438 (98.348)
 * Acc@1 66.463 Acc@5 98.366
epoch 28, total time 444.32
Test: [0/750]	Time 0.696 (0.696)	Loss 0.6804 (0.6804)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.030 (0.036)	Loss 0.7880 (0.6824)	Acc@1 62.500 (83.168)	Acc@5 96.875 (92.667)
Test: [200/750]	Time 0.026 (0.033)	Loss 2.0747 (0.7907)	Acc@1 18.750 (75.078)	Acc@5 84.375 (93.299)
Test: [300/750]	Time 0.038 (0.031)	Loss 1.0590 (1.0544)	Acc@1 71.875 (64.120)	Acc@5 100.000 (91.923)
Test: [400/750]	Time 0.036 (0.031)	Loss 1.2159 (1.0673)	Acc@1 68.750 (63.544)	Acc@5 87.500 (92.620)
Test: [500/750]	Time 0.020 (0.030)	Loss 1.0371 (1.1004)	Acc@1 59.375 (63.673)	Acc@5 90.625 (91.511)
Test: [600/750]	Time 0.041 (0.030)	Loss 0.9468 (1.1118)	Acc@1 59.375 (63.738)	Acc@5 90.625 (90.880)
Test: [700/750]	Time 0.023 (0.030)	Loss 1.3980 (1.0897)	Acc@1 65.625 (64.190)	Acc@5 87.500 (90.968)
 * Acc@1 64.383 Acc@5 90.950
==> training...
Epoch: [29][0/875]	Time 1.817 (1.817)	Data 1.309 (1.309)	Loss 1.5020 (1.5020)	Loss@kd 2.4917 (2.4917)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [29][100/875]	Time 0.464 (0.517)	Data 0.007 (0.020)	Loss 1.5933 (1.6509)	Loss@kd 2.5347 (2.5026)	Acc@1 54.688 (65.424)	Acc@5 96.875 (98.035)
Epoch: [29][200/875]	Time 0.487 (0.503)	Data 0.004 (0.013)	Loss 1.4270 (1.6507)	Loss@kd 2.3859 (2.4942)	Acc@1 67.188 (66.037)	Acc@5 100.000 (98.212)
Epoch: [29][300/875]	Time 0.501 (0.505)	Data 0.007 (0.011)	Loss 1.5773 (1.6516)	Loss@kd 2.5704 (2.4927)	Acc@1 62.500 (66.310)	Acc@5 95.312 (98.292)
Epoch: [29][400/875]	Time 0.493 (0.506)	Data 0.007 (0.010)	Loss 1.6853 (1.6433)	Loss@kd 2.5124 (2.4907)	Acc@1 82.812 (66.564)	Acc@5 98.438 (98.348)
Epoch: [29][500/875]	Time 0.489 (0.507)	Data 0.007 (0.009)	Loss 1.7439 (1.6453)	Loss@kd 2.6960 (2.4924)	Acc@1 73.438 (66.520)	Acc@5 98.438 (98.378)
Epoch: [29][600/875]	Time 0.501 (0.507)	Data 0.007 (0.009)	Loss 1.6481 (1.6417)	Loss@kd 2.6131 (2.4925)	Acc@1 57.812 (66.759)	Acc@5 98.438 (98.367)
Epoch: [29][700/875]	Time 0.572 (0.507)	Data 0.005 (0.009)	Loss 1.5566 (1.6388)	Loss@kd 2.4470 (2.4903)	Acc@1 62.500 (66.704)	Acc@5 93.750 (98.351)
Epoch: [29][800/875]	Time 0.471 (0.507)	Data 0.007 (0.009)	Loss 1.6128 (1.6389)	Loss@kd 2.4580 (2.4910)	Acc@1 64.062 (66.559)	Acc@5 98.438 (98.342)
 * Acc@1 66.645 Acc@5 98.343
epoch 29, total time 442.09
Test: [0/750]	Time 0.681 (0.681)	Loss 0.5454 (0.5454)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.031 (0.035)	Loss 0.4896 (0.6355)	Acc@1 84.375 (82.797)	Acc@5 96.875 (93.038)
Test: [200/750]	Time 0.018 (0.032)	Loss 1.3883 (0.6366)	Acc@1 40.625 (79.058)	Acc@5 84.375 (95.118)
Test: [300/750]	Time 0.020 (0.031)	Loss 1.1317 (0.8574)	Acc@1 62.500 (69.726)	Acc@5 90.625 (93.999)
Test: [400/750]	Time 0.042 (0.031)	Loss 0.7183 (0.9576)	Acc@1 81.250 (65.594)	Acc@5 87.500 (93.314)
Test: [500/750]	Time 0.024 (0.031)	Loss 0.5589 (0.9453)	Acc@1 71.875 (66.960)	Acc@5 100.000 (92.540)
Test: [600/750]	Time 0.024 (0.031)	Loss 0.8849 (0.9375)	Acc@1 78.125 (67.616)	Acc@5 90.625 (92.575)
Test: [700/750]	Time 0.039 (0.030)	Loss 1.9996 (0.9821)	Acc@1 34.375 (66.044)	Acc@5 71.875 (91.909)
 * Acc@1 64.363 Acc@5 91.338
==> training...
Epoch: [30][0/875]	Time 1.891 (1.891)	Data 1.400 (1.400)	Loss 1.4462 (1.4462)	Loss@kd 2.3835 (2.3835)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [30][100/875]	Time 0.502 (0.524)	Data 0.007 (0.021)	Loss 1.5537 (1.6016)	Loss@kd 2.5129 (2.4831)	Acc@1 65.625 (66.429)	Acc@5 100.000 (98.283)
Epoch: [30][200/875]	Time 0.502 (0.517)	Data 0.006 (0.014)	Loss 1.5247 (1.6402)	Loss@kd 2.4452 (2.5093)	Acc@1 68.750 (66.200)	Acc@5 100.000 (98.391)
Epoch: [30][300/875]	Time 0.524 (0.514)	Data 0.007 (0.012)	Loss 1.5453 (1.6399)	Loss@kd 2.4257 (2.5055)	Acc@1 62.500 (66.404)	Acc@5 100.000 (98.375)
Epoch: [30][400/875]	Time 0.514 (0.513)	Data 0.007 (0.011)	Loss 1.6079 (1.6337)	Loss@kd 2.4977 (2.4981)	Acc@1 70.312 (66.334)	Acc@5 96.875 (98.363)
Epoch: [30][500/875]	Time 0.522 (0.512)	Data 0.007 (0.010)	Loss 1.5903 (1.6341)	Loss@kd 2.4513 (2.4972)	Acc@1 64.062 (66.274)	Acc@5 98.438 (98.347)
Epoch: [30][600/875]	Time 0.533 (0.509)	Data 0.007 (0.009)	Loss 1.6702 (1.6347)	Loss@kd 2.4858 (2.4954)	Acc@1 71.875 (66.306)	Acc@5 100.000 (98.365)
Epoch: [30][700/875]	Time 0.529 (0.507)	Data 0.007 (0.009)	Loss 1.3930 (1.6363)	Loss@kd 2.4663 (2.4956)	Acc@1 62.500 (66.254)	Acc@5 100.000 (98.306)
Epoch: [30][800/875]	Time 0.513 (0.507)	Data 0.007 (0.009)	Loss 1.7994 (1.6330)	Loss@kd 2.3743 (2.4937)	Acc@1 53.125 (66.333)	Acc@5 96.875 (98.303)
 * Acc@1 66.334 Acc@5 98.334
epoch 30, total time 444.16
Test: [0/750]	Time 0.721 (0.721)	Loss 0.4906 (0.4906)	Acc@1 90.625 (90.625)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.031 (0.036)	Loss 0.4733 (0.7059)	Acc@1 87.500 (82.395)	Acc@5 93.750 (93.069)
Test: [200/750]	Time 0.039 (0.032)	Loss 1.7458 (0.6883)	Acc@1 40.625 (80.799)	Acc@5 78.125 (93.766)
Test: [300/750]	Time 0.024 (0.031)	Loss 0.9781 (1.0261)	Acc@1 71.875 (67.203)	Acc@5 96.875 (90.345)
Test: [400/750]	Time 0.018 (0.030)	Loss 0.7941 (1.0435)	Acc@1 84.375 (65.017)	Acc@5 87.500 (91.038)
Test: [500/750]	Time 0.023 (0.030)	Loss 0.6651 (1.0286)	Acc@1 75.000 (66.305)	Acc@5 93.750 (90.475)
Test: [600/750]	Time 0.022 (0.029)	Loss 1.3733 (1.0517)	Acc@1 43.750 (65.277)	Acc@5 87.500 (90.308)
Test: [700/750]	Time 0.024 (0.029)	Loss 2.9242 (1.1663)	Acc@1 28.125 (61.675)	Acc@5 62.500 (89.096)
 * Acc@1 59.642 Acc@5 87.946
==> training...
Epoch: [31][0/875]	Time 1.889 (1.889)	Data 1.346 (1.346)	Loss 1.7229 (1.7229)	Loss@kd 2.4954 (2.4954)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [31][100/875]	Time 0.503 (0.524)	Data 0.007 (0.020)	Loss 1.4880 (1.6414)	Loss@kd 2.3574 (2.5073)	Acc@1 62.500 (67.095)	Acc@5 98.438 (98.515)
Epoch: [31][200/875]	Time 0.495 (0.517)	Data 0.005 (0.014)	Loss 1.4176 (1.6249)	Loss@kd 2.3323 (2.4888)	Acc@1 71.875 (66.659)	Acc@5 98.438 (98.313)
Epoch: [31][300/875]	Time 0.513 (0.514)	Data 0.007 (0.012)	Loss 1.4107 (1.6290)	Loss@kd 2.4346 (2.4858)	Acc@1 65.625 (66.518)	Acc@5 100.000 (98.251)
Epoch: [31][400/875]	Time 0.500 (0.507)	Data 0.007 (0.011)	Loss 1.4954 (1.6320)	Loss@kd 2.3864 (2.4879)	Acc@1 65.625 (66.369)	Acc@5 95.312 (98.231)
Epoch: [31][500/875]	Time 0.521 (0.508)	Data 0.009 (0.010)	Loss 1.7156 (1.6320)	Loss@kd 2.4168 (2.4910)	Acc@1 60.938 (66.458)	Acc@5 98.438 (98.257)
Epoch: [31][600/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss 1.4530 (1.6345)	Loss@kd 2.4004 (2.4906)	Acc@1 65.625 (66.629)	Acc@5 98.438 (98.282)
Epoch: [31][700/875]	Time 0.519 (0.508)	Data 0.008 (0.009)	Loss 1.6788 (1.6303)	Loss@kd 2.4888 (2.4892)	Acc@1 64.062 (66.664)	Acc@5 96.875 (98.290)
Epoch: [31][800/875]	Time 0.512 (0.508)	Data 0.008 (0.009)	Loss 1.6370 (1.6305)	Loss@kd 2.5054 (2.4886)	Acc@1 70.312 (66.608)	Acc@5 100.000 (98.291)
 * Acc@1 66.570 Acc@5 98.289
epoch 31, total time 444.97
Test: [0/750]	Time 0.785 (0.785)	Loss 0.6187 (0.6187)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.020 (0.033)	Loss 0.4205 (0.5824)	Acc@1 84.375 (84.189)	Acc@5 96.875 (92.234)
Test: [200/750]	Time 0.017 (0.029)	Loss 1.2834 (0.5467)	Acc@1 53.125 (83.333)	Acc@5 93.750 (94.558)
Test: [300/750]	Time 0.015 (0.028)	Loss 1.2347 (0.7643)	Acc@1 59.375 (74.024)	Acc@5 96.875 (94.632)
Test: [400/750]	Time 0.018 (0.027)	Loss 1.0800 (0.8957)	Acc@1 65.625 (68.594)	Acc@5 84.375 (93.968)
Test: [500/750]	Time 0.017 (0.026)	Loss 1.0399 (0.9672)	Acc@1 53.125 (67.315)	Acc@5 93.750 (92.178)
Test: [600/750]	Time 0.016 (0.026)	Loss 1.1722 (1.0203)	Acc@1 65.625 (65.422)	Acc@5 81.250 (91.389)
Test: [700/750]	Time 0.027 (0.026)	Loss 1.0803 (1.0242)	Acc@1 65.625 (64.872)	Acc@5 84.375 (91.575)
 * Acc@1 65.321 Acc@5 91.771
==> training...
Epoch: [32][0/875]	Time 1.874 (1.874)	Data 1.335 (1.335)	Loss 1.7678 (1.7678)	Loss@kd 2.4604 (2.4604)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [32][100/875]	Time 0.507 (0.523)	Data 0.007 (0.020)	Loss 1.6985 (1.6503)	Loss@kd 2.4965 (2.5023)	Acc@1 60.938 (65.996)	Acc@5 96.875 (98.190)
Epoch: [32][200/875]	Time 0.507 (0.504)	Data 0.007 (0.014)	Loss 1.5047 (1.6237)	Loss@kd 2.5121 (2.4864)	Acc@1 68.750 (65.866)	Acc@5 96.875 (98.266)
Epoch: [32][300/875]	Time 0.496 (0.506)	Data 0.007 (0.012)	Loss 1.6466 (1.6342)	Loss@kd 2.5112 (2.4946)	Acc@1 62.500 (65.942)	Acc@5 100.000 (98.318)
Epoch: [32][400/875]	Time 0.507 (0.507)	Data 0.008 (0.011)	Loss 1.5852 (1.6197)	Loss@kd 2.5188 (2.4867)	Acc@1 64.062 (66.264)	Acc@5 96.875 (98.278)
Epoch: [32][500/875]	Time 0.494 (0.508)	Data 0.007 (0.010)	Loss 1.7844 (1.6215)	Loss@kd 2.4762 (2.4881)	Acc@1 56.250 (66.314)	Acc@5 93.750 (98.266)
Epoch: [32][600/875]	Time 0.491 (0.508)	Data 0.007 (0.010)	Loss 1.9186 (1.6206)	Loss@kd 2.5322 (2.4865)	Acc@1 67.188 (66.405)	Acc@5 98.438 (98.276)
Epoch: [32][700/875]	Time 0.526 (0.508)	Data 0.008 (0.009)	Loss 1.9520 (1.6248)	Loss@kd 2.5302 (2.4892)	Acc@1 50.000 (66.497)	Acc@5 96.875 (98.284)
Epoch: [32][800/875]	Time 0.496 (0.508)	Data 0.007 (0.009)	Loss 1.5370 (1.6242)	Loss@kd 2.3885 (2.4874)	Acc@1 56.250 (66.526)	Acc@5 96.875 (98.285)
 * Acc@1 66.580 Acc@5 98.305
epoch 32, total time 443.37
Test: [0/750]	Time 0.646 (0.646)	Loss 0.5939 (0.5939)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.035 (0.028)	Loss 0.8566 (0.5252)	Acc@1 84.375 (84.251)	Acc@5 96.875 (94.926)
Test: [200/750]	Time 0.023 (0.029)	Loss 1.4864 (0.7224)	Acc@1 43.750 (77.456)	Acc@5 84.375 (94.356)
Test: [300/750]	Time 0.028 (0.029)	Loss 1.8409 (1.0459)	Acc@1 37.500 (64.452)	Acc@5 87.500 (92.068)
Test: [400/750]	Time 0.023 (0.029)	Loss 0.9622 (1.2182)	Acc@1 75.000 (58.284)	Acc@5 81.250 (89.698)
Test: [500/750]	Time 0.035 (0.028)	Loss 0.3906 (1.1529)	Acc@1 84.375 (60.704)	Acc@5 100.000 (89.827)
Test: [600/750]	Time 0.020 (0.029)	Loss 1.9635 (1.1538)	Acc@1 50.000 (61.299)	Acc@5 81.250 (89.278)
Test: [700/750]	Time 0.019 (0.028)	Loss 0.8483 (1.1896)	Acc@1 71.875 (60.717)	Acc@5 90.625 (88.512)
 * Acc@1 62.013 Acc@5 89.046
==> training...
Epoch: [33][0/875]	Time 1.766 (1.766)	Data 1.272 (1.272)	Loss 1.6120 (1.6120)	Loss@kd 2.4019 (2.4019)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [33][100/875]	Time 0.497 (0.523)	Data 0.007 (0.020)	Loss 1.6601 (1.6423)	Loss@kd 2.4347 (2.4767)	Acc@1 67.188 (66.337)	Acc@5 96.875 (98.298)
Epoch: [33][200/875]	Time 0.524 (0.516)	Data 0.007 (0.014)	Loss 1.7511 (1.6341)	Loss@kd 2.5988 (2.4805)	Acc@1 68.750 (66.698)	Acc@5 98.438 (98.259)
Epoch: [33][300/875]	Time 0.509 (0.514)	Data 0.006 (0.011)	Loss 1.6605 (1.6267)	Loss@kd 2.4500 (2.4807)	Acc@1 64.062 (66.591)	Acc@5 98.438 (98.214)
Epoch: [33][400/875]	Time 0.528 (0.513)	Data 0.007 (0.010)	Loss 1.4764 (1.6291)	Loss@kd 2.4950 (2.4839)	Acc@1 70.312 (66.611)	Acc@5 98.438 (98.200)
Epoch: [33][500/875]	Time 0.501 (0.512)	Data 0.007 (0.010)	Loss 1.6872 (1.6268)	Loss@kd 2.4802 (2.4837)	Acc@1 59.375 (66.745)	Acc@5 98.438 (98.213)
Epoch: [33][600/875]	Time 0.519 (0.511)	Data 0.007 (0.009)	Loss 1.6010 (1.6243)	Loss@kd 2.5137 (2.4823)	Acc@1 71.875 (66.899)	Acc@5 98.438 (98.250)
Epoch: [33][700/875]	Time 0.498 (0.507)	Data 0.006 (0.009)	Loss 1.6924 (1.6199)	Loss@kd 2.5194 (2.4814)	Acc@1 60.938 (66.965)	Acc@5 98.438 (98.295)
Epoch: [33][800/875]	Time 0.533 (0.507)	Data 0.006 (0.009)	Loss 1.8374 (1.6208)	Loss@kd 2.4961 (2.4812)	Acc@1 71.875 (66.803)	Acc@5 100.000 (98.281)
 * Acc@1 66.791 Acc@5 98.286
epoch 33, total time 444.03
Test: [0/750]	Time 0.670 (0.670)	Loss 0.8429 (0.8429)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.043 (0.034)	Loss 0.5514 (0.7924)	Acc@1 84.375 (80.446)	Acc@5 93.750 (90.130)
Test: [200/750]	Time 0.028 (0.032)	Loss 1.4211 (0.7043)	Acc@1 43.750 (80.302)	Acc@5 96.875 (92.910)
Test: [300/750]	Time 0.026 (0.031)	Loss 0.9036 (0.8748)	Acc@1 53.125 (71.179)	Acc@5 96.875 (92.961)
Test: [400/750]	Time 0.028 (0.030)	Loss 1.0668 (0.9344)	Acc@1 75.000 (68.430)	Acc@5 78.125 (92.791)
Test: [500/750]	Time 0.036 (0.030)	Loss 1.0325 (0.9851)	Acc@1 53.125 (68.083)	Acc@5 96.875 (91.311)
Test: [600/750]	Time 0.024 (0.030)	Loss 0.9643 (1.0175)	Acc@1 56.250 (66.613)	Acc@5 96.875 (91.207)
Test: [700/750]	Time 0.033 (0.030)	Loss 2.6861 (1.0828)	Acc@1 21.875 (64.109)	Acc@5 78.125 (91.026)
 * Acc@1 62.304 Acc@5 90.554
==> training...
Epoch: [34][0/875]	Time 1.793 (1.793)	Data 1.299 (1.299)	Loss 1.5014 (1.5014)	Loss@kd 2.4556 (2.4556)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [34][100/875]	Time 0.500 (0.520)	Data 0.008 (0.020)	Loss 1.5936 (1.6135)	Loss@kd 2.4547 (2.4795)	Acc@1 68.750 (66.723)	Acc@5 98.438 (98.082)
Epoch: [34][200/875]	Time 0.533 (0.515)	Data 0.006 (0.013)	Loss 1.6401 (1.6168)	Loss@kd 2.4584 (2.4818)	Acc@1 67.188 (66.581)	Acc@5 100.000 (98.142)
Epoch: [34][300/875]	Time 0.499 (0.513)	Data 0.007 (0.011)	Loss 1.4870 (1.6187)	Loss@kd 2.4496 (2.4835)	Acc@1 75.000 (66.627)	Acc@5 98.438 (98.225)
Epoch: [34][400/875]	Time 0.449 (0.509)	Data 0.006 (0.010)	Loss 1.6270 (1.6120)	Loss@kd 2.4343 (2.4783)	Acc@1 59.375 (66.638)	Acc@5 95.312 (98.274)
Epoch: [34][500/875]	Time 0.496 (0.504)	Data 0.008 (0.009)	Loss 1.5742 (1.6177)	Loss@kd 2.4924 (2.4814)	Acc@1 64.062 (66.788)	Acc@5 100.000 (98.288)
Epoch: [34][600/875]	Time 0.501 (0.505)	Data 0.006 (0.009)	Loss 1.4286 (1.6135)	Loss@kd 2.5110 (2.4775)	Acc@1 81.250 (66.876)	Acc@5 98.438 (98.289)
Epoch: [34][700/875]	Time 0.528 (0.505)	Data 0.007 (0.009)	Loss 1.6552 (1.6117)	Loss@kd 2.4365 (2.4790)	Acc@1 62.500 (66.842)	Acc@5 100.000 (98.324)
Epoch: [34][800/875]	Time 0.494 (0.506)	Data 0.008 (0.009)	Loss 1.4688 (1.6170)	Loss@kd 2.4839 (2.4803)	Acc@1 78.125 (66.780)	Acc@5 98.438 (98.322)
 * Acc@1 66.791 Acc@5 98.316
epoch 34, total time 443.12
Test: [0/750]	Time 0.669 (0.669)	Loss 0.6324 (0.6324)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.028 (0.036)	Loss 0.5258 (0.6434)	Acc@1 75.000 (83.292)	Acc@5 93.750 (93.255)
Test: [200/750]	Time 0.020 (0.032)	Loss 1.3797 (0.7244)	Acc@1 46.875 (77.192)	Acc@5 96.875 (94.325)
Test: [300/750]	Time 0.033 (0.030)	Loss 1.1365 (0.8989)	Acc@1 50.000 (69.321)	Acc@5 90.625 (93.708)
Test: [400/750]	Time 0.040 (0.029)	Loss 1.1986 (0.9947)	Acc@1 59.375 (66.077)	Acc@5 81.250 (92.846)
Test: [500/750]	Time 0.026 (0.028)	Loss 1.2978 (1.0509)	Acc@1 56.250 (65.594)	Acc@5 93.750 (91.243)
Test: [600/750]	Time 0.020 (0.028)	Loss 1.5952 (1.1427)	Acc@1 50.000 (63.015)	Acc@5 81.250 (89.871)
Test: [700/750]	Time 0.018 (0.027)	Loss 2.5689 (1.2212)	Acc@1 34.375 (60.926)	Acc@5 68.750 (88.775)
 * Acc@1 59.842 Acc@5 88.100
==> training...
Epoch: [35][0/875]	Time 1.745 (1.745)	Data 1.240 (1.240)	Loss 1.6893 (1.6893)	Loss@kd 2.5720 (2.5720)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [35][100/875]	Time 0.499 (0.522)	Data 0.006 (0.020)	Loss 1.7048 (1.5885)	Loss@kd 2.4039 (2.4773)	Acc@1 62.500 (66.445)	Acc@5 98.438 (98.561)
Epoch: [35][200/875]	Time 0.470 (0.509)	Data 0.008 (0.014)	Loss 1.8641 (1.6024)	Loss@kd 2.5601 (2.4774)	Acc@1 64.062 (66.682)	Acc@5 96.875 (98.430)
Epoch: [35][300/875]	Time 0.496 (0.505)	Data 0.007 (0.011)	Loss 1.5550 (1.6140)	Loss@kd 2.4553 (2.4862)	Acc@1 57.812 (66.658)	Acc@5 100.000 (98.308)
Epoch: [35][400/875]	Time 0.527 (0.507)	Data 0.006 (0.010)	Loss 1.8058 (1.6098)	Loss@kd 2.5235 (2.4798)	Acc@1 64.062 (66.736)	Acc@5 96.875 (98.325)
Epoch: [35][500/875]	Time 0.496 (0.507)	Data 0.007 (0.010)	Loss 1.5930 (1.6144)	Loss@kd 2.4832 (2.4806)	Acc@1 59.375 (66.757)	Acc@5 98.438 (98.322)
Epoch: [35][600/875]	Time 0.510 (0.508)	Data 0.007 (0.009)	Loss 1.6987 (1.6171)	Loss@kd 2.4473 (2.4814)	Acc@1 67.188 (66.655)	Acc@5 96.875 (98.331)
Epoch: [35][700/875]	Time 0.529 (0.508)	Data 0.007 (0.009)	Loss 1.7445 (1.6192)	Loss@kd 2.5423 (2.4814)	Acc@1 64.062 (66.867)	Acc@5 100.000 (98.357)
Epoch: [35][800/875]	Time 0.494 (0.508)	Data 0.007 (0.009)	Loss 1.4590 (1.6199)	Loss@kd 2.4873 (2.4806)	Acc@1 73.438 (66.760)	Acc@5 100.000 (98.381)
 * Acc@1 66.771 Acc@5 98.366
epoch 35, total time 444.83
Test: [0/750]	Time 0.724 (0.724)	Loss 0.5712 (0.5712)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.018 (0.029)	Loss 0.4701 (0.6746)	Acc@1 81.250 (83.787)	Acc@5 100.000 (92.822)
Test: [200/750]	Time 0.020 (0.025)	Loss 1.3375 (0.5807)	Acc@1 43.750 (82.680)	Acc@5 90.625 (95.398)
Test: [300/750]	Time 0.021 (0.024)	Loss 1.5996 (0.8227)	Acc@1 40.625 (72.114)	Acc@5 90.625 (94.653)
Test: [400/750]	Time 0.028 (0.024)	Loss 1.4773 (0.9975)	Acc@1 68.750 (66.584)	Acc@5 81.250 (92.589)
Test: [500/750]	Time 0.021 (0.023)	Loss 0.6550 (1.0777)	Acc@1 75.000 (65.993)	Acc@5 100.000 (90.138)
Test: [600/750]	Time 0.022 (0.023)	Loss 1.0078 (1.0557)	Acc@1 68.750 (66.036)	Acc@5 87.500 (90.578)
Test: [700/750]	Time 0.024 (0.023)	Loss 1.8118 (1.0460)	Acc@1 43.750 (65.794)	Acc@5 68.750 (90.803)
 * Acc@1 65.471 Acc@5 90.546
==> training...
Epoch: [36][0/875]	Time 1.624 (1.624)	Data 1.232 (1.232)	Loss 1.3881 (1.3881)	Loss@kd 2.3890 (2.3890)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [36][100/875]	Time 0.518 (0.519)	Data 0.006 (0.019)	Loss 1.7514 (1.6329)	Loss@kd 2.5142 (2.4992)	Acc@1 70.312 (66.816)	Acc@5 98.438 (98.360)
Epoch: [36][200/875]	Time 0.535 (0.514)	Data 0.007 (0.013)	Loss 1.7258 (1.6260)	Loss@kd 2.9741 (2.4861)	Acc@1 71.875 (67.055)	Acc@5 98.438 (98.313)
Epoch: [36][300/875]	Time 0.506 (0.513)	Data 0.007 (0.011)	Loss 1.5138 (1.6330)	Loss@kd 2.5273 (2.4868)	Acc@1 73.438 (66.710)	Acc@5 96.875 (98.287)
Epoch: [36][400/875]	Time 0.527 (0.512)	Data 0.007 (0.010)	Loss 1.4679 (1.6239)	Loss@kd 2.5002 (2.4822)	Acc@1 68.750 (66.747)	Acc@5 100.000 (98.286)
Epoch: [36][500/875]	Time 0.505 (0.511)	Data 0.007 (0.009)	Loss 1.5139 (1.6107)	Loss@kd 2.5562 (2.4762)	Acc@1 67.188 (66.735)	Acc@5 100.000 (98.350)
Epoch: [36][600/875]	Time 0.500 (0.511)	Data 0.007 (0.009)	Loss 1.7578 (1.6137)	Loss@kd 2.5429 (2.4776)	Acc@1 67.188 (66.694)	Acc@5 98.438 (98.357)
Epoch: [36][700/875]	Time 0.468 (0.508)	Data 0.008 (0.009)	Loss 1.5592 (1.6148)	Loss@kd 2.5206 (2.4771)	Acc@1 76.562 (66.581)	Acc@5 100.000 (98.348)
Epoch: [36][800/875]	Time 0.523 (0.507)	Data 0.007 (0.009)	Loss 1.4730 (1.6108)	Loss@kd 2.3832 (2.4752)	Acc@1 65.625 (66.649)	Acc@5 98.438 (98.367)
 * Acc@1 66.657 Acc@5 98.354
epoch 36, total time 444.12
Test: [0/750]	Time 0.647 (0.647)	Loss 0.5543 (0.5543)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.016 (0.031)	Loss 0.2458 (0.5416)	Acc@1 93.750 (86.077)	Acc@5 100.000 (93.162)
Test: [200/750]	Time 0.029 (0.027)	Loss 1.1540 (0.4511)	Acc@1 50.000 (87.174)	Acc@5 90.625 (95.507)
Test: [300/750]	Time 0.028 (0.026)	Loss 1.3406 (0.7372)	Acc@1 56.250 (74.740)	Acc@5 93.750 (94.134)
Test: [400/750]	Time 0.018 (0.026)	Loss 0.8179 (0.8721)	Acc@1 81.250 (69.467)	Acc@5 87.500 (93.610)
Test: [500/750]	Time 0.023 (0.025)	Loss 1.0794 (0.9153)	Acc@1 53.125 (68.893)	Acc@5 87.500 (92.078)
Test: [600/750]	Time 0.039 (0.025)	Loss 1.3847 (1.0062)	Acc@1 50.000 (65.807)	Acc@5 84.375 (91.103)
Test: [700/750]	Time 0.021 (0.025)	Loss 0.9840 (1.0322)	Acc@1 65.625 (64.332)	Acc@5 87.500 (91.254)
 * Acc@1 64.783 Acc@5 91.225
==> training...
Epoch: [37][0/875]	Time 1.810 (1.810)	Data 1.293 (1.293)	Loss 1.4717 (1.4717)	Loss@kd 2.3390 (2.3390)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [37][100/875]	Time 0.528 (0.523)	Data 0.007 (0.020)	Loss 1.5262 (1.6210)	Loss@kd 2.6572 (2.4848)	Acc@1 75.000 (65.811)	Acc@5 98.438 (98.051)
Epoch: [37][200/875]	Time 0.497 (0.516)	Data 0.008 (0.014)	Loss 1.9403 (1.6324)	Loss@kd 2.6452 (2.4891)	Acc@1 76.562 (66.527)	Acc@5 100.000 (98.251)
Epoch: [37][300/875]	Time 0.488 (0.513)	Data 0.005 (0.011)	Loss 1.5652 (1.6360)	Loss@kd 2.4742 (2.4945)	Acc@1 62.500 (66.471)	Acc@5 100.000 (98.360)
Epoch: [37][400/875]	Time 0.525 (0.512)	Data 0.006 (0.010)	Loss 1.4465 (1.6248)	Loss@kd 2.3591 (2.4893)	Acc@1 60.938 (66.626)	Acc@5 98.438 (98.406)
Epoch: [37][500/875]	Time 0.500 (0.505)	Data 0.007 (0.010)	Loss 1.5699 (1.6166)	Loss@kd 2.3799 (2.4836)	Acc@1 73.438 (66.664)	Acc@5 98.438 (98.384)
Epoch: [37][600/875]	Time 0.497 (0.506)	Data 0.006 (0.009)	Loss 1.7126 (1.6126)	Loss@kd 2.3294 (2.4814)	Acc@1 60.938 (66.787)	Acc@5 98.438 (98.393)
Epoch: [37][700/875]	Time 0.531 (0.506)	Data 0.008 (0.009)	Loss 1.8146 (1.6148)	Loss@kd 2.4242 (2.4820)	Acc@1 53.125 (66.851)	Acc@5 100.000 (98.413)
Epoch: [37][800/875]	Time 0.507 (0.507)	Data 0.005 (0.009)	Loss 1.5280 (1.6158)	Loss@kd 2.5615 (2.4824)	Acc@1 78.125 (66.870)	Acc@5 100.000 (98.414)
 * Acc@1 66.818 Acc@5 98.414
epoch 37, total time 443.63
Test: [0/750]	Time 0.667 (0.667)	Loss 0.5892 (0.5892)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.042 (0.035)	Loss 0.2405 (0.6235)	Acc@1 90.625 (84.097)	Acc@5 96.875 (93.472)
Test: [200/750]	Time 0.028 (0.033)	Loss 1.6511 (0.5620)	Acc@1 37.500 (83.815)	Acc@5 90.625 (95.211)
Test: [300/750]	Time 0.035 (0.032)	Loss 1.7550 (0.8526)	Acc@1 40.625 (72.706)	Acc@5 84.375 (93.522)
Test: [400/750]	Time 0.032 (0.031)	Loss 0.8338 (1.0082)	Acc@1 75.000 (66.778)	Acc@5 90.625 (91.872)
Test: [500/750]	Time 0.027 (0.030)	Loss 1.1791 (1.0104)	Acc@1 59.375 (67.028)	Acc@5 90.625 (91.218)
Test: [600/750]	Time 0.040 (0.030)	Loss 0.9181 (1.0298)	Acc@1 65.625 (65.942)	Acc@5 93.750 (91.389)
Test: [700/750]	Time 0.037 (0.030)	Loss 1.1797 (1.0200)	Acc@1 59.375 (65.901)	Acc@5 84.375 (91.682)
 * Acc@1 66.058 Acc@5 91.642
saving the best model!
==> training...
Epoch: [38][0/875]	Time 1.715 (1.715)	Data 1.215 (1.215)	Loss 1.6741 (1.6741)	Loss@kd 2.5350 (2.5350)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [38][100/875]	Time 0.527 (0.521)	Data 0.008 (0.019)	Loss 1.6829 (1.6439)	Loss@kd 2.6703 (2.4881)	Acc@1 60.938 (67.172)	Acc@5 100.000 (98.236)
Epoch: [38][200/875]	Time 0.501 (0.515)	Data 0.004 (0.013)	Loss 1.5680 (1.6204)	Loss@kd 2.3752 (2.4747)	Acc@1 54.688 (66.845)	Acc@5 96.875 (98.274)
Epoch: [38][300/875]	Time 0.512 (0.503)	Data 0.007 (0.011)	Loss 1.8231 (1.6201)	Loss@kd 2.7235 (2.4720)	Acc@1 67.188 (66.502)	Acc@5 100.000 (98.303)
Epoch: [38][400/875]	Time 0.496 (0.504)	Data 0.006 (0.010)	Loss 1.7329 (1.6201)	Loss@kd 2.7465 (2.4736)	Acc@1 71.875 (66.584)	Acc@5 96.875 (98.293)
Epoch: [38][500/875]	Time 0.501 (0.505)	Data 0.008 (0.010)	Loss 1.6462 (1.6187)	Loss@kd 2.3919 (2.4752)	Acc@1 54.688 (66.726)	Acc@5 95.312 (98.356)
Epoch: [38][600/875]	Time 0.522 (0.506)	Data 0.008 (0.009)	Loss 1.5511 (1.6145)	Loss@kd 2.4415 (2.4772)	Acc@1 71.875 (66.740)	Acc@5 100.000 (98.370)
Epoch: [38][700/875]	Time 0.504 (0.506)	Data 0.007 (0.009)	Loss 1.6668 (1.6185)	Loss@kd 2.4452 (2.4787)	Acc@1 70.312 (66.684)	Acc@5 100.000 (98.322)
Epoch: [38][800/875]	Time 0.515 (0.507)	Data 0.007 (0.009)	Loss 1.5698 (1.6125)	Loss@kd 2.4758 (2.4754)	Acc@1 71.875 (66.713)	Acc@5 100.000 (98.342)
 * Acc@1 66.745 Acc@5 98.332
epoch 38, total time 443.93
Test: [0/750]	Time 0.718 (0.718)	Loss 0.4819 (0.4819)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.036 (0.031)	Loss 0.5879 (0.6475)	Acc@1 81.250 (83.571)	Acc@5 100.000 (94.059)
Test: [200/750]	Time 0.023 (0.028)	Loss 2.9393 (0.7716)	Acc@1 25.000 (77.814)	Acc@5 56.250 (93.688)
Test: [300/750]	Time 0.038 (0.028)	Loss 1.0753 (1.3270)	Acc@1 68.750 (61.472)	Acc@5 96.875 (86.130)
Test: [400/750]	Time 0.025 (0.027)	Loss 0.4694 (1.2824)	Acc@1 84.375 (61.183)	Acc@5 93.750 (87.952)
Test: [500/750]	Time 0.019 (0.027)	Loss 1.9320 (1.2391)	Acc@1 40.625 (62.625)	Acc@5 75.000 (87.862)
Test: [600/750]	Time 0.023 (0.028)	Loss 0.5429 (1.2816)	Acc@1 84.375 (61.361)	Acc@5 96.875 (87.360)
Test: [700/750]	Time 0.018 (0.027)	Loss 2.2795 (1.2894)	Acc@1 28.125 (60.815)	Acc@5 68.750 (87.438)
 * Acc@1 59.296 Acc@5 86.637
==> training...
Epoch: [39][0/875]	Time 1.768 (1.768)	Data 1.254 (1.254)	Loss 1.8441 (1.8441)	Loss@kd 2.5747 (2.5747)	Acc@1 56.250 (56.250)	Acc@5 96.875 (96.875)
Epoch: [39][100/875]	Time 0.497 (0.488)	Data 0.007 (0.019)	Loss 1.8219 (1.5811)	Loss@kd 2.5453 (2.4685)	Acc@1 53.125 (67.064)	Acc@5 96.875 (98.113)
Epoch: [39][200/875]	Time 0.497 (0.499)	Data 0.007 (0.013)	Loss 1.7533 (1.5980)	Loss@kd 2.4544 (2.4717)	Acc@1 59.375 (66.325)	Acc@5 100.000 (98.243)
Epoch: [39][300/875]	Time 0.503 (0.502)	Data 0.008 (0.011)	Loss 1.7482 (1.6143)	Loss@kd 2.8749 (2.4757)	Acc@1 70.312 (66.591)	Acc@5 100.000 (98.313)
Epoch: [39][400/875]	Time 0.525 (0.504)	Data 0.008 (0.010)	Loss 1.7343 (1.6210)	Loss@kd 2.4474 (2.4797)	Acc@1 68.750 (66.432)	Acc@5 100.000 (98.418)
Epoch: [39][500/875]	Time 0.492 (0.505)	Data 0.007 (0.010)	Loss 1.5893 (1.6183)	Loss@kd 2.5480 (2.4763)	Acc@1 67.188 (66.445)	Acc@5 100.000 (98.438)
Epoch: [39][600/875]	Time 0.525 (0.506)	Data 0.007 (0.009)	Loss 1.7921 (1.6165)	Loss@kd 2.5386 (2.4765)	Acc@1 57.812 (66.525)	Acc@5 98.438 (98.424)
Epoch: [39][700/875]	Time 0.508 (0.506)	Data 0.007 (0.009)	Loss 1.6982 (1.6160)	Loss@kd 2.3886 (2.4757)	Acc@1 68.750 (66.606)	Acc@5 98.438 (98.411)
Epoch: [39][800/875]	Time 0.525 (0.503)	Data 0.008 (0.009)	Loss 1.6045 (1.6141)	Loss@kd 2.4130 (2.4745)	Acc@1 60.938 (66.612)	Acc@5 95.312 (98.406)
 * Acc@1 66.562 Acc@5 98.404
epoch 39, total time 440.67
Test: [0/750]	Time 0.755 (0.755)	Loss 0.6286 (0.6286)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.023 (0.035)	Loss 0.5627 (0.6371)	Acc@1 78.125 (82.704)	Acc@5 96.875 (93.750)
Test: [200/750]	Time 0.025 (0.033)	Loss 1.6137 (0.6945)	Acc@1 31.250 (78.483)	Acc@5 87.500 (94.216)
Test: [300/750]	Time 0.032 (0.032)	Loss 1.7864 (1.0055)	Acc@1 37.500 (65.563)	Acc@5 87.500 (91.985)
Test: [400/750]	Time 0.027 (0.032)	Loss 1.1954 (1.1758)	Acc@1 65.625 (60.162)	Acc@5 84.375 (90.337)
Test: [500/750]	Time 0.022 (0.031)	Loss 0.2853 (1.1992)	Acc@1 84.375 (60.647)	Acc@5 100.000 (89.134)
Test: [600/750]	Time 0.023 (0.030)	Loss 1.0767 (1.1440)	Acc@1 71.875 (62.578)	Acc@5 90.625 (89.658)
Test: [700/750]	Time 0.030 (0.030)	Loss 0.8978 (1.1324)	Acc@1 71.875 (62.874)	Acc@5 93.750 (89.965)
 * Acc@1 63.708 Acc@5 90.233
==> training...
Epoch: [40][0/875]	Time 1.808 (1.808)	Data 1.297 (1.297)	Loss 1.5677 (1.5677)	Loss@kd 2.3685 (2.3685)	Acc@1 60.938 (60.938)	Acc@5 95.312 (95.312)
Epoch: [40][100/875]	Time 0.495 (0.521)	Data 0.007 (0.020)	Loss 1.3823 (1.6225)	Loss@kd 2.4101 (2.4805)	Acc@1 73.438 (65.671)	Acc@5 100.000 (98.236)
Epoch: [40][200/875]	Time 0.505 (0.515)	Data 0.008 (0.014)	Loss 1.7141 (1.6087)	Loss@kd 2.7069 (2.4729)	Acc@1 53.125 (66.270)	Acc@5 96.875 (98.259)
Epoch: [40][300/875]	Time 0.521 (0.513)	Data 0.007 (0.012)	Loss 1.7107 (1.6145)	Loss@kd 2.5586 (2.4721)	Acc@1 67.188 (66.549)	Acc@5 96.875 (98.287)
Epoch: [40][400/875]	Time 0.490 (0.512)	Data 0.008 (0.010)	Loss 1.6792 (1.6125)	Loss@kd 2.5534 (2.4768)	Acc@1 60.938 (66.568)	Acc@5 96.875 (98.321)
Epoch: [40][500/875]	Time 0.392 (0.511)	Data 0.007 (0.010)	Loss 1.7166 (1.6074)	Loss@kd 2.4084 (2.4729)	Acc@1 62.500 (66.879)	Acc@5 100.000 (98.341)
Epoch: [40][600/875]	Time 0.510 (0.505)	Data 0.008 (0.009)	Loss 1.4715 (1.6113)	Loss@kd 2.4177 (2.4748)	Acc@1 64.062 (66.818)	Acc@5 93.750 (98.326)
Epoch: [40][700/875]	Time 0.500 (0.506)	Data 0.009 (0.009)	Loss 1.7592 (1.6069)	Loss@kd 2.5157 (2.4740)	Acc@1 60.938 (66.904)	Acc@5 100.000 (98.368)
Epoch: [40][800/875]	Time 0.494 (0.506)	Data 0.007 (0.009)	Loss 1.5309 (1.6078)	Loss@kd 2.4397 (2.4725)	Acc@1 67.188 (66.772)	Acc@5 98.438 (98.363)
 * Acc@1 66.855 Acc@5 98.396
epoch 40, total time 443.53
Test: [0/750]	Time 0.662 (0.662)	Loss 1.4656 (1.4656)	Acc@1 40.625 (40.625)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.028 (0.033)	Loss 0.2363 (1.7150)	Acc@1 90.625 (36.417)	Acc@5 100.000 (90.532)
Test: [200/750]	Time 0.027 (0.030)	Loss 1.7818 (1.1041)	Acc@1 15.625 (60.059)	Acc@5 90.625 (93.781)
Test: [300/750]	Time 0.027 (0.030)	Loss 1.3139 (1.2492)	Acc@1 65.625 (54.298)	Acc@5 93.750 (92.774)
Test: [400/750]	Time 0.037 (0.030)	Loss 0.7809 (1.2175)	Acc@1 65.625 (55.291)	Acc@5 93.750 (92.620)
Test: [500/750]	Time 0.019 (0.030)	Loss 1.3462 (1.2028)	Acc@1 53.125 (56.375)	Acc@5 81.250 (92.041)
Test: [600/750]	Time 0.025 (0.030)	Loss 1.7397 (1.2614)	Acc@1 50.000 (55.439)	Acc@5 78.125 (90.823)
Test: [700/750]	Time 0.025 (0.029)	Loss 1.5383 (1.3083)	Acc@1 43.750 (54.449)	Acc@5 75.000 (89.836)
 * Acc@1 54.675 Acc@5 89.425
==> Saving...
==> training...
Epoch: [41][0/875]	Time 1.783 (1.783)	Data 1.269 (1.269)	Loss 1.6537 (1.6537)	Loss@kd 2.4261 (2.4261)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [41][100/875]	Time 0.511 (0.522)	Data 0.007 (0.020)	Loss 1.6136 (1.6153)	Loss@kd 2.5125 (2.4874)	Acc@1 65.625 (67.512)	Acc@5 98.438 (98.252)
Epoch: [41][200/875]	Time 0.494 (0.516)	Data 0.007 (0.014)	Loss 1.4956 (1.6109)	Loss@kd 2.4591 (2.4782)	Acc@1 59.375 (66.706)	Acc@5 100.000 (98.220)
Epoch: [41][300/875]	Time 0.471 (0.510)	Data 0.007 (0.011)	Loss 1.6295 (1.6090)	Loss@kd 2.4475 (2.4741)	Acc@1 59.375 (66.533)	Acc@5 96.875 (98.318)
Epoch: [41][400/875]	Time 0.505 (0.506)	Data 0.007 (0.010)	Loss 1.7979 (1.6091)	Loss@kd 2.5233 (2.4761)	Acc@1 68.750 (66.716)	Acc@5 96.875 (98.321)
Epoch: [41][500/875]	Time 0.495 (0.507)	Data 0.007 (0.010)	Loss 1.5715 (1.6009)	Loss@kd 2.5268 (2.4740)	Acc@1 76.562 (66.751)	Acc@5 98.438 (98.338)
Epoch: [41][600/875]	Time 0.522 (0.507)	Data 0.005 (0.009)	Loss 1.4924 (1.6021)	Loss@kd 2.4342 (2.4707)	Acc@1 67.188 (66.837)	Acc@5 100.000 (98.339)
Epoch: [41][700/875]	Time 0.602 (0.508)	Data 0.007 (0.009)	Loss 1.7064 (1.6061)	Loss@kd 2.4263 (2.4729)	Acc@1 67.188 (66.762)	Acc@5 100.000 (98.299)
Epoch: [41][800/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss 1.5066 (1.6088)	Loss@kd 2.4517 (2.4723)	Acc@1 64.062 (66.846)	Acc@5 98.438 (98.322)
 * Acc@1 66.863 Acc@5 98.346
epoch 41, total time 444.79
Test: [0/750]	Time 0.751 (0.751)	Loss 0.5754 (0.5754)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.029 (0.033)	Loss 0.1550 (0.5959)	Acc@1 93.750 (86.108)	Acc@5 100.000 (93.441)
Test: [200/750]	Time 0.025 (0.029)	Loss 2.2006 (0.4892)	Acc@1 34.375 (87.189)	Acc@5 81.250 (95.087)
Test: [300/750]	Time 0.024 (0.028)	Loss 2.0525 (0.9523)	Acc@1 31.250 (71.449)	Acc@5 81.250 (90.417)
Test: [400/750]	Time 0.018 (0.027)	Loss 0.7203 (1.0944)	Acc@1 78.125 (65.757)	Acc@5 93.750 (89.433)
Test: [500/750]	Time 0.015 (0.027)	Loss 1.2627 (1.0655)	Acc@1 46.875 (66.398)	Acc@5 93.750 (89.571)
Test: [600/750]	Time 0.019 (0.027)	Loss 1.3178 (1.1333)	Acc@1 59.375 (63.400)	Acc@5 87.500 (89.606)
Test: [700/750]	Time 0.025 (0.027)	Loss 1.5431 (1.1788)	Acc@1 56.250 (61.336)	Acc@5 78.125 (89.756)
 * Acc@1 61.237 Acc@5 89.425
==> training...
Epoch: [42][0/875]	Time 1.856 (1.856)	Data 1.347 (1.347)	Loss 1.5202 (1.5202)	Loss@kd 2.4054 (2.4054)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [42][100/875]	Time 0.446 (0.501)	Data 0.005 (0.020)	Loss 1.8943 (1.5855)	Loss@kd 2.5023 (2.4669)	Acc@1 73.438 (68.317)	Acc@5 98.438 (98.654)
Epoch: [42][200/875]	Time 0.505 (0.500)	Data 0.006 (0.013)	Loss 1.7595 (1.5936)	Loss@kd 2.5747 (2.4714)	Acc@1 76.562 (67.638)	Acc@5 100.000 (98.360)
Epoch: [42][300/875]	Time 0.525 (0.503)	Data 0.007 (0.011)	Loss 1.5499 (1.6097)	Loss@kd 2.4823 (2.4725)	Acc@1 75.000 (66.954)	Acc@5 98.438 (98.308)
Epoch: [42][400/875]	Time 0.528 (0.504)	Data 0.010 (0.010)	Loss 1.4776 (1.6039)	Loss@kd 2.3836 (2.4719)	Acc@1 75.000 (66.891)	Acc@5 100.000 (98.352)
Epoch: [42][500/875]	Time 0.494 (0.505)	Data 0.007 (0.010)	Loss 1.5575 (1.6016)	Loss@kd 2.4667 (2.4735)	Acc@1 70.312 (66.969)	Acc@5 100.000 (98.381)
Epoch: [42][600/875]	Time 0.612 (0.506)	Data 0.005 (0.009)	Loss 1.6683 (1.6017)	Loss@kd 2.5175 (2.4722)	Acc@1 68.750 (67.055)	Acc@5 100.000 (98.362)
Epoch: [42][700/875]	Time 0.524 (0.506)	Data 0.007 (0.009)	Loss 1.6314 (1.6018)	Loss@kd 2.4697 (2.4711)	Acc@1 75.000 (67.007)	Acc@5 100.000 (98.377)
Epoch: [42][800/875]	Time 0.467 (0.505)	Data 0.007 (0.009)	Loss 1.6725 (1.5986)	Loss@kd 2.4957 (2.4703)	Acc@1 59.375 (66.996)	Acc@5 96.875 (98.381)
 * Acc@1 66.968 Acc@5 98.391
epoch 42, total time 441.43
Test: [0/750]	Time 0.739 (0.739)	Loss 0.6099 (0.6099)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.022 (0.034)	Loss 0.5463 (0.6831)	Acc@1 71.875 (81.250)	Acc@5 100.000 (92.234)
Test: [200/750]	Time 0.037 (0.030)	Loss 1.4938 (0.6749)	Acc@1 34.375 (77.534)	Acc@5 84.375 (94.465)
Test: [300/750]	Time 0.027 (0.028)	Loss 1.1898 (0.9273)	Acc@1 62.500 (66.539)	Acc@5 93.750 (92.795)
Test: [400/750]	Time 0.036 (0.027)	Loss 0.8225 (0.9848)	Acc@1 75.000 (64.121)	Acc@5 84.375 (92.137)
Test: [500/750]	Time 0.018 (0.027)	Loss 0.6562 (0.9828)	Acc@1 75.000 (65.276)	Acc@5 100.000 (91.218)
Test: [600/750]	Time 0.031 (0.026)	Loss 0.9327 (0.9822)	Acc@1 71.875 (65.739)	Acc@5 87.500 (91.213)
Test: [700/750]	Time 0.016 (0.026)	Loss 1.4271 (0.9832)	Acc@1 50.000 (65.661)	Acc@5 81.250 (91.343)
 * Acc@1 65.408 Acc@5 91.196
==> training...
Epoch: [43][0/875]	Time 1.828 (1.828)	Data 1.288 (1.288)	Loss 1.6630 (1.6630)	Loss@kd 2.5645 (2.5645)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
Epoch: [43][100/875]	Time 0.502 (0.523)	Data 0.007 (0.020)	Loss 1.7432 (1.5519)	Loss@kd 2.7732 (2.4532)	Acc@1 60.938 (67.126)	Acc@5 100.000 (98.639)
Epoch: [43][200/875]	Time 0.498 (0.517)	Data 0.007 (0.013)	Loss 1.4834 (1.5780)	Loss@kd 2.4049 (2.4599)	Acc@1 73.438 (66.877)	Acc@5 100.000 (98.570)
Epoch: [43][300/875]	Time 0.512 (0.514)	Data 0.006 (0.011)	Loss 1.4770 (1.5838)	Loss@kd 2.4279 (2.4640)	Acc@1 60.938 (66.803)	Acc@5 98.438 (98.500)
Epoch: [43][400/875]	Time 0.498 (0.513)	Data 0.007 (0.010)	Loss 1.6430 (1.5926)	Loss@kd 2.5850 (2.4683)	Acc@1 64.062 (66.747)	Acc@5 100.000 (98.434)
Epoch: [43][500/875]	Time 0.510 (0.512)	Data 0.005 (0.010)	Loss 1.6282 (1.5904)	Loss@kd 2.6525 (2.4702)	Acc@1 70.312 (66.810)	Acc@5 100.000 (98.462)
Epoch: [43][600/875]	Time 0.531 (0.508)	Data 0.005 (0.009)	Loss 1.4595 (1.5957)	Loss@kd 2.3758 (2.4692)	Acc@1 70.312 (66.818)	Acc@5 98.438 (98.430)
Epoch: [43][700/875]	Time 0.497 (0.508)	Data 0.006 (0.009)	Loss 1.7940 (1.5998)	Loss@kd 2.4500 (2.4705)	Acc@1 78.125 (66.835)	Acc@5 98.438 (98.402)
Epoch: [43][800/875]	Time 0.525 (0.508)	Data 0.008 (0.009)	Loss 1.6307 (1.6022)	Loss@kd 2.5537 (2.4709)	Acc@1 68.750 (66.829)	Acc@5 100.000 (98.395)
 * Acc@1 66.780 Acc@5 98.396
epoch 43, total time 445.05
Test: [0/750]	Time 0.725 (0.725)	Loss 0.9923 (0.9923)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.017 (0.032)	Loss 0.5173 (1.2145)	Acc@1 81.250 (74.536)	Acc@5 93.750 (89.975)
Test: [200/750]	Time 0.016 (0.029)	Loss 1.5613 (0.9371)	Acc@1 40.625 (75.435)	Acc@5 81.250 (92.957)
Test: [300/750]	Time 0.017 (0.027)	Loss 1.7041 (1.1678)	Acc@1 46.875 (63.466)	Acc@5 87.500 (90.532)
Test: [400/750]	Time 0.027 (0.027)	Loss 0.7391 (1.2206)	Acc@1 81.250 (60.482)	Acc@5 93.750 (89.885)
Test: [500/750]	Time 0.015 (0.026)	Loss 0.6565 (1.1452)	Acc@1 75.000 (62.899)	Acc@5 100.000 (90.145)
Test: [600/750]	Time 0.021 (0.026)	Loss 0.8621 (1.1146)	Acc@1 65.625 (63.431)	Acc@5 90.625 (90.521)
Test: [700/750]	Time 0.025 (0.026)	Loss 2.4478 (1.1360)	Acc@1 34.375 (62.897)	Acc@5 65.625 (90.077)
 * Acc@1 62.462 Acc@5 89.304
==> training...
Epoch: [44][0/875]	Time 1.739 (1.739)	Data 1.243 (1.243)	Loss 1.8373 (1.8373)	Loss@kd 2.4513 (2.4513)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [44][100/875]	Time 0.508 (0.521)	Data 0.007 (0.019)	Loss 1.3406 (1.6050)	Loss@kd 2.3515 (2.4575)	Acc@1 75.000 (66.600)	Acc@5 96.875 (98.298)
Epoch: [44][200/875]	Time 0.528 (0.515)	Data 0.007 (0.013)	Loss 1.4550 (1.6163)	Loss@kd 2.5537 (2.4697)	Acc@1 70.312 (66.573)	Acc@5 96.875 (98.313)
Epoch: [44][300/875]	Time 0.503 (0.513)	Data 0.008 (0.011)	Loss 1.4989 (1.6077)	Loss@kd 2.3958 (2.4682)	Acc@1 81.250 (66.689)	Acc@5 100.000 (98.303)
Epoch: [44][400/875]	Time 0.505 (0.506)	Data 0.008 (0.010)	Loss 1.4907 (1.6048)	Loss@kd 2.4498 (2.4689)	Acc@1 70.312 (66.965)	Acc@5 100.000 (98.348)
Epoch: [44][500/875]	Time 0.518 (0.507)	Data 0.008 (0.010)	Loss 1.6906 (1.6009)	Loss@kd 2.4725 (2.4677)	Acc@1 64.062 (67.013)	Acc@5 98.438 (98.394)
Epoch: [44][600/875]	Time 0.514 (0.508)	Data 0.008 (0.009)	Loss 1.6900 (1.6017)	Loss@kd 2.3682 (2.4679)	Acc@1 59.375 (67.016)	Acc@5 96.875 (98.388)
Epoch: [44][700/875]	Time 0.529 (0.508)	Data 0.009 (0.009)	Loss 1.8035 (1.6024)	Loss@kd 2.4519 (2.4681)	Acc@1 68.750 (67.007)	Acc@5 96.875 (98.380)
Epoch: [44][800/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 1.8277 (1.6051)	Loss@kd 2.8055 (2.4702)	Acc@1 78.125 (66.950)	Acc@5 100.000 (98.381)
 * Acc@1 66.887 Acc@5 98.387
epoch 44, total time 444.90
Test: [0/750]	Time 0.681 (0.681)	Loss 0.4897 (0.4897)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.033 (0.033)	Loss 0.8004 (0.5839)	Acc@1 68.750 (84.870)	Acc@5 96.875 (95.297)
Test: [200/750]	Time 0.029 (0.031)	Loss 1.0412 (0.6376)	Acc@1 46.875 (80.768)	Acc@5 100.000 (95.258)
Test: [300/750]	Time 0.022 (0.030)	Loss 1.4323 (0.7928)	Acc@1 37.500 (73.879)	Acc@5 87.500 (94.664)
Test: [400/750]	Time 0.028 (0.029)	Loss 0.9797 (0.9521)	Acc@1 75.000 (67.659)	Acc@5 87.500 (93.166)
Test: [500/750]	Time 0.040 (0.029)	Loss 1.4023 (1.0045)	Acc@1 50.000 (66.598)	Acc@5 93.750 (91.929)
Test: [600/750]	Time 0.027 (0.029)	Loss 1.6612 (1.0690)	Acc@1 53.125 (64.450)	Acc@5 75.000 (90.994)
Test: [700/750]	Time 0.025 (0.029)	Loss 1.6453 (1.1256)	Acc@1 53.125 (63.164)	Acc@5 81.250 (90.045)
 * Acc@1 63.025 Acc@5 89.779
==> training...
Epoch: [45][0/875]	Time 1.763 (1.763)	Data 1.269 (1.269)	Loss 1.6276 (1.6276)	Loss@kd 2.4892 (2.4892)	Acc@1 64.062 (64.062)	Acc@5 95.312 (95.312)
Epoch: [45][100/875]	Time 0.526 (0.522)	Data 0.007 (0.020)	Loss 1.8076 (1.5935)	Loss@kd 2.5935 (2.4679)	Acc@1 54.688 (67.543)	Acc@5 95.312 (98.329)
Epoch: [45][200/875]	Time 0.498 (0.499)	Data 0.007 (0.013)	Loss 1.5269 (1.5853)	Loss@kd 2.4123 (2.4668)	Acc@1 62.500 (67.265)	Acc@5 98.438 (98.399)
Epoch: [45][300/875]	Time 0.522 (0.502)	Data 0.007 (0.011)	Loss 1.7147 (1.5848)	Loss@kd 2.4252 (2.4658)	Acc@1 64.062 (67.255)	Acc@5 98.438 (98.365)
Epoch: [45][400/875]	Time 0.512 (0.504)	Data 0.007 (0.010)	Loss 1.6101 (1.5831)	Loss@kd 2.6426 (2.4675)	Acc@1 70.312 (67.160)	Acc@5 98.438 (98.363)
Epoch: [45][500/875]	Time 0.514 (0.505)	Data 0.007 (0.010)	Loss 1.6983 (1.5865)	Loss@kd 2.4144 (2.4686)	Acc@1 62.500 (67.178)	Acc@5 98.438 (98.391)
Epoch: [45][600/875]	Time 0.494 (0.506)	Data 0.004 (0.009)	Loss 1.5992 (1.5867)	Loss@kd 2.5252 (2.4680)	Acc@1 57.812 (66.946)	Acc@5 96.875 (98.388)
Epoch: [45][700/875]	Time 0.520 (0.506)	Data 0.007 (0.009)	Loss 1.5947 (1.5862)	Loss@kd 2.5176 (2.4696)	Acc@1 68.750 (66.869)	Acc@5 95.312 (98.384)
Epoch: [45][800/875]	Time 0.503 (0.507)	Data 0.005 (0.009)	Loss 1.4847 (1.5860)	Loss@kd 2.5615 (2.4672)	Acc@1 71.875 (66.891)	Acc@5 96.875 (98.383)
 * Acc@1 66.916 Acc@5 98.380
epoch 45, total time 441.45
Test: [0/750]	Time 0.675 (0.675)	Loss 0.3420 (0.3420)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.020 (0.032)	Loss 0.9297 (0.4102)	Acc@1 62.500 (88.088)	Acc@5 93.750 (95.545)
Test: [200/750]	Time 0.024 (0.030)	Loss 2.2144 (0.6978)	Acc@1 21.875 (77.037)	Acc@5 87.500 (94.636)
Test: [300/750]	Time 0.019 (0.030)	Loss 1.1542 (1.0909)	Acc@1 53.125 (63.621)	Acc@5 100.000 (91.954)
Test: [400/750]	Time 0.032 (0.030)	Loss 1.8046 (1.1983)	Acc@1 46.875 (60.349)	Acc@5 84.375 (91.864)
Test: [500/750]	Time 0.041 (0.030)	Loss 2.1738 (1.3570)	Acc@1 34.375 (57.747)	Acc@5 75.000 (88.205)
Test: [600/750]	Time 0.019 (0.029)	Loss 1.2422 (1.4529)	Acc@1 59.375 (55.470)	Acc@5 87.500 (86.039)
Test: [700/750]	Time 0.020 (0.029)	Loss 1.3091 (1.4084)	Acc@1 62.500 (56.473)	Acc@5 93.750 (86.666)
 * Acc@1 57.104 Acc@5 86.762
==> training...
Epoch: [46][0/875]	Time 1.905 (1.905)	Data 1.399 (1.399)	Loss 1.5595 (1.5595)	Loss@kd 2.3778 (2.3778)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [46][100/875]	Time 0.521 (0.523)	Data 0.007 (0.021)	Loss 1.4465 (1.6357)	Loss@kd 2.4111 (2.4804)	Acc@1 78.125 (66.321)	Acc@5 100.000 (98.329)
Epoch: [46][200/875]	Time 0.510 (0.516)	Data 0.007 (0.014)	Loss 1.5103 (1.6098)	Loss@kd 2.4965 (2.4678)	Acc@1 70.312 (66.775)	Acc@5 100.000 (98.375)
Epoch: [46][300/875]	Time 0.501 (0.514)	Data 0.007 (0.012)	Loss 1.6243 (1.6047)	Loss@kd 2.5563 (2.4664)	Acc@1 65.625 (66.658)	Acc@5 100.000 (98.391)
Epoch: [46][400/875]	Time 0.489 (0.513)	Data 0.007 (0.011)	Loss 1.4069 (1.6071)	Loss@kd 2.4109 (2.4718)	Acc@1 78.125 (66.802)	Acc@5 98.438 (98.360)
Epoch: [46][500/875]	Time 0.497 (0.512)	Data 0.007 (0.010)	Loss 1.5372 (1.6040)	Loss@kd 2.4958 (2.4728)	Acc@1 65.625 (66.729)	Acc@5 98.438 (98.344)
Epoch: [46][600/875]	Time 0.463 (0.511)	Data 0.007 (0.009)	Loss 1.6335 (1.6036)	Loss@kd 2.4357 (2.4715)	Acc@1 70.312 (66.798)	Acc@5 96.875 (98.282)
Epoch: [46][700/875]	Time 0.526 (0.507)	Data 0.005 (0.009)	Loss 1.6831 (1.6071)	Loss@kd 2.5557 (2.4729)	Acc@1 67.188 (66.918)	Acc@5 96.875 (98.288)
Epoch: [46][800/875]	Time 0.490 (0.507)	Data 0.008 (0.009)	Loss 1.6100 (1.6068)	Loss@kd 2.3556 (2.4711)	Acc@1 64.062 (66.762)	Acc@5 96.875 (98.301)
 * Acc@1 66.829 Acc@5 98.266
epoch 46, total time 443.93
Test: [0/750]	Time 0.680 (0.680)	Loss 0.4826 (0.4826)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.021 (0.034)	Loss 0.6435 (0.4493)	Acc@1 81.250 (87.438)	Acc@5 96.875 (95.823)
Test: [200/750]	Time 0.025 (0.031)	Loss 1.3927 (0.5357)	Acc@1 40.625 (83.147)	Acc@5 96.875 (95.802)
Test: [300/750]	Time 0.025 (0.031)	Loss 0.8847 (0.7588)	Acc@1 75.000 (72.321)	Acc@5 100.000 (95.567)
Test: [400/750]	Time 0.027 (0.030)	Loss 1.6473 (0.8705)	Acc@1 56.250 (68.688)	Acc@5 78.125 (94.264)
Test: [500/750]	Time 0.027 (0.030)	Loss 1.0557 (1.0081)	Acc@1 56.250 (66.349)	Acc@5 93.750 (91.074)
Test: [600/750]	Time 0.021 (0.030)	Loss 1.9988 (1.1084)	Acc@1 37.500 (63.275)	Acc@5 75.000 (89.382)
Test: [700/750]	Time 0.026 (0.030)	Loss 1.4369 (1.1841)	Acc@1 53.125 (60.886)	Acc@5 90.625 (88.146)
 * Acc@1 61.008 Acc@5 88.054
==> training...
Epoch: [47][0/875]	Time 1.762 (1.762)	Data 1.265 (1.265)	Loss 1.4862 (1.4862)	Loss@kd 2.5054 (2.5054)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [47][100/875]	Time 0.493 (0.522)	Data 0.007 (0.019)	Loss 1.6279 (1.6095)	Loss@kd 2.4922 (2.4772)	Acc@1 68.750 (67.110)	Acc@5 98.438 (98.345)
Epoch: [47][200/875]	Time 0.497 (0.516)	Data 0.005 (0.014)	Loss 1.4118 (1.5851)	Loss@kd 2.4107 (2.4656)	Acc@1 75.000 (67.397)	Acc@5 98.438 (98.476)
Epoch: [47][300/875]	Time 0.508 (0.513)	Data 0.007 (0.011)	Loss 1.3712 (1.5832)	Loss@kd 2.3774 (2.4666)	Acc@1 81.250 (67.598)	Acc@5 98.438 (98.463)
Epoch: [47][400/875]	Time 0.471 (0.509)	Data 0.008 (0.010)	Loss 1.5783 (1.5874)	Loss@kd 2.4991 (2.4651)	Acc@1 68.750 (67.351)	Acc@5 98.438 (98.414)
Epoch: [47][500/875]	Time 0.498 (0.507)	Data 0.007 (0.010)	Loss 1.4064 (1.5872)	Loss@kd 2.3496 (2.4627)	Acc@1 71.875 (67.347)	Acc@5 98.438 (98.360)
Epoch: [47][600/875]	Time 0.511 (0.507)	Data 0.007 (0.009)	Loss 1.5499 (1.5878)	Loss@kd 2.5799 (2.4635)	Acc@1 68.750 (67.110)	Acc@5 98.438 (98.367)
Epoch: [47][700/875]	Time 0.520 (0.507)	Data 0.006 (0.009)	Loss 1.5029 (1.5896)	Loss@kd 2.4498 (2.4627)	Acc@1 68.750 (67.138)	Acc@5 98.438 (98.413)
Epoch: [47][800/875]	Time 0.497 (0.508)	Data 0.007 (0.009)	Loss 1.6170 (1.5904)	Loss@kd 2.4311 (2.4635)	Acc@1 67.188 (67.109)	Acc@5 98.438 (98.397)
 * Acc@1 67.130 Acc@5 98.404
epoch 47, total time 444.67
Test: [0/750]	Time 0.695 (0.695)	Loss 0.7620 (0.7620)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.031 (0.031)	Loss 0.2370 (0.6225)	Acc@1 93.750 (83.911)	Acc@5 100.000 (91.986)
Test: [200/750]	Time 0.019 (0.028)	Loss 1.8594 (0.5425)	Acc@1 28.125 (84.313)	Acc@5 90.625 (94.450)
Test: [300/750]	Time 0.035 (0.027)	Loss 1.8234 (0.9320)	Acc@1 31.250 (68.968)	Acc@5 84.375 (91.975)
Test: [400/750]	Time 0.031 (0.026)	Loss 0.6999 (1.0966)	Acc@1 68.750 (63.669)	Acc@5 87.500 (90.368)
Test: [500/750]	Time 0.017 (0.026)	Loss 0.6530 (1.0398)	Acc@1 75.000 (65.937)	Acc@5 96.875 (90.538)
Test: [600/750]	Time 0.019 (0.026)	Loss 1.2215 (1.0590)	Acc@1 53.125 (65.422)	Acc@5 93.750 (90.765)
Test: [700/750]	Time 0.019 (0.025)	Loss 1.2100 (1.0879)	Acc@1 65.625 (64.114)	Acc@5 84.375 (91.147)
 * Acc@1 64.304 Acc@5 91.258
==> training...
Epoch: [48][0/875]	Time 1.790 (1.790)	Data 1.264 (1.264)	Loss 1.3868 (1.3868)	Loss@kd 2.3203 (2.3203)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [48][100/875]	Time 0.504 (0.523)	Data 0.007 (0.020)	Loss 1.6754 (1.6205)	Loss@kd 2.4373 (2.4664)	Acc@1 53.125 (66.785)	Acc@5 98.438 (98.190)
Epoch: [48][200/875]	Time 0.447 (0.505)	Data 0.005 (0.013)	Loss 1.7237 (1.5934)	Loss@kd 2.3400 (2.4603)	Acc@1 60.938 (67.242)	Acc@5 100.000 (98.375)
Epoch: [48][300/875]	Time 0.519 (0.505)	Data 0.007 (0.011)	Loss 1.4680 (1.5955)	Loss@kd 2.3889 (2.4602)	Acc@1 67.188 (67.182)	Acc@5 95.312 (98.380)
Epoch: [48][400/875]	Time 0.498 (0.506)	Data 0.006 (0.010)	Loss 1.5872 (1.5894)	Loss@kd 2.4565 (2.4579)	Acc@1 73.438 (67.176)	Acc@5 98.438 (98.363)
Epoch: [48][500/875]	Time 0.525 (0.507)	Data 0.007 (0.010)	Loss 1.7286 (1.5910)	Loss@kd 2.4210 (2.4592)	Acc@1 54.688 (67.209)	Acc@5 95.312 (98.403)
Epoch: [48][600/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss 1.5609 (1.6012)	Loss@kd 2.4396 (2.4672)	Acc@1 68.750 (67.128)	Acc@5 100.000 (98.308)
Epoch: [48][700/875]	Time 0.507 (0.508)	Data 0.006 (0.009)	Loss 1.6407 (1.5989)	Loss@kd 2.7136 (2.4658)	Acc@1 71.875 (67.147)	Acc@5 100.000 (98.286)
Epoch: [48][800/875]	Time 0.510 (0.508)	Data 0.008 (0.009)	Loss 1.5686 (1.5995)	Loss@kd 2.3699 (2.4655)	Acc@1 60.938 (67.065)	Acc@5 98.438 (98.311)
 * Acc@1 67.091 Acc@5 98.348
epoch 48, total time 444.14
Test: [0/750]	Time 0.703 (0.703)	Loss 0.5661 (0.5661)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.026 (0.030)	Loss 0.4765 (0.5383)	Acc@1 84.375 (85.736)	Acc@5 93.750 (93.843)
Test: [200/750]	Time 0.029 (0.027)	Loss 1.2923 (0.5434)	Acc@1 50.000 (84.220)	Acc@5 90.625 (94.994)
Test: [300/750]	Time 0.024 (0.026)	Loss 2.0772 (0.8660)	Acc@1 28.125 (71.667)	Acc@5 84.375 (92.992)
Test: [400/750]	Time 0.020 (0.025)	Loss 1.9114 (1.2654)	Acc@1 43.750 (59.710)	Acc@5 65.625 (87.422)
Test: [500/750]	Time 0.021 (0.024)	Loss 0.9711 (1.4342)	Acc@1 68.750 (56.824)	Acc@5 96.875 (83.807)
Test: [600/750]	Time 0.017 (0.024)	Loss 1.7128 (1.4177)	Acc@1 50.000 (56.640)	Acc@5 84.375 (84.484)
Test: [700/750]	Time 0.024 (0.025)	Loss 0.9479 (1.3979)	Acc@1 68.750 (56.504)	Acc@5 87.500 (85.066)
 * Acc@1 57.804 Acc@5 85.671
==> training...
Epoch: [49][0/875]	Time 1.765 (1.765)	Data 1.260 (1.260)	Loss 1.4994 (1.4994)	Loss@kd 2.4397 (2.4397)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [49][100/875]	Time 0.495 (0.521)	Data 0.007 (0.020)	Loss 1.5878 (1.5777)	Loss@kd 2.4624 (2.4700)	Acc@1 70.312 (67.110)	Acc@5 98.438 (98.329)
Epoch: [49][200/875]	Time 0.510 (0.515)	Data 0.008 (0.014)	Loss 1.5443 (1.5850)	Loss@kd 2.3831 (2.4636)	Acc@1 73.438 (67.327)	Acc@5 98.438 (98.383)
Epoch: [49][300/875]	Time 0.501 (0.513)	Data 0.006 (0.012)	Loss 1.5562 (1.5872)	Loss@kd 2.3731 (2.4693)	Acc@1 65.625 (67.317)	Acc@5 98.438 (98.396)
Epoch: [49][400/875]	Time 0.524 (0.513)	Data 0.008 (0.011)	Loss 1.4775 (1.5981)	Loss@kd 2.4305 (2.4728)	Acc@1 75.000 (67.191)	Acc@5 98.438 (98.453)
Epoch: [49][500/875]	Time 0.498 (0.512)	Data 0.005 (0.010)	Loss 2.0809 (1.5913)	Loss@kd 2.6947 (2.4664)	Acc@1 60.938 (67.166)	Acc@5 96.875 (98.484)
Epoch: [49][600/875]	Time 0.524 (0.512)	Data 0.007 (0.010)	Loss 1.5477 (1.5925)	Loss@kd 2.4138 (2.4658)	Acc@1 73.438 (67.325)	Acc@5 98.438 (98.502)
Epoch: [49][700/875]	Time 0.523 (0.507)	Data 0.007 (0.009)	Loss 1.6292 (1.5896)	Loss@kd 2.5155 (2.4650)	Acc@1 62.500 (67.237)	Acc@5 96.875 (98.498)
Epoch: [49][800/875]	Time 0.489 (0.507)	Data 0.005 (0.009)	Loss 1.4807 (1.5904)	Loss@kd 2.3569 (2.4642)	Acc@1 62.500 (67.244)	Acc@5 98.438 (98.443)
 * Acc@1 67.179 Acc@5 98.457
epoch 49, total time 444.10
Test: [0/750]	Time 0.731 (0.731)	Loss 0.7742 (0.7742)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.021 (0.036)	Loss 0.3634 (0.7927)	Acc@1 87.500 (81.126)	Acc@5 100.000 (90.718)
Test: [200/750]	Time 0.027 (0.033)	Loss 2.0101 (0.6725)	Acc@1 31.250 (81.328)	Acc@5 81.250 (93.734)
Test: [300/750]	Time 0.019 (0.032)	Loss 1.8985 (1.0097)	Acc@1 40.625 (68.013)	Acc@5 90.625 (92.556)
Test: [400/750]	Time 0.037 (0.031)	Loss 0.8902 (1.1717)	Acc@1 71.875 (61.713)	Acc@5 93.750 (91.763)
Test: [500/750]	Time 0.040 (0.030)	Loss 0.4792 (1.1056)	Acc@1 84.375 (64.047)	Acc@5 100.000 (91.897)
Test: [600/750]	Time 0.038 (0.030)	Loss 0.9640 (1.0688)	Acc@1 68.750 (64.959)	Acc@5 90.625 (92.071)
Test: [700/750]	Time 0.016 (0.030)	Loss 0.6190 (1.0335)	Acc@1 84.375 (65.830)	Acc@5 90.625 (92.377)
 * Acc@1 66.925 Acc@5 92.592
saving the best model!
==> training...
Epoch: [50][0/875]	Time 1.823 (1.823)	Data 1.344 (1.344)	Loss 1.5012 (1.5012)	Loss@kd 2.5309 (2.5309)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [50][100/875]	Time 0.523 (0.523)	Data 0.007 (0.020)	Loss 1.5519 (1.5633)	Loss@kd 2.3494 (2.4487)	Acc@1 57.812 (67.079)	Acc@5 98.438 (98.515)
Epoch: [50][200/875]	Time 0.522 (0.516)	Data 0.008 (0.014)	Loss 1.5721 (1.5858)	Loss@kd 2.4034 (2.4562)	Acc@1 76.562 (66.962)	Acc@5 96.875 (98.453)
Epoch: [50][300/875]	Time 0.496 (0.514)	Data 0.010 (0.011)	Loss 1.5809 (1.5886)	Loss@kd 2.4476 (2.4623)	Acc@1 57.812 (67.011)	Acc@5 100.000 (98.422)
Epoch: [50][400/875]	Time 0.512 (0.513)	Data 0.008 (0.010)	Loss 1.7897 (1.5941)	Loss@kd 2.5564 (2.4643)	Acc@1 68.750 (66.962)	Acc@5 96.875 (98.395)
Epoch: [50][500/875]	Time 0.509 (0.505)	Data 0.006 (0.010)	Loss 1.4329 (1.5913)	Loss@kd 2.4195 (2.4656)	Acc@1 75.000 (67.234)	Acc@5 98.438 (98.378)
Epoch: [50][600/875]	Time 0.491 (0.506)	Data 0.007 (0.009)	Loss 1.5745 (1.5961)	Loss@kd 2.5069 (2.4665)	Acc@1 65.625 (67.094)	Acc@5 96.875 (98.406)
Epoch: [50][700/875]	Time 0.526 (0.507)	Data 0.007 (0.009)	Loss 1.5533 (1.5900)	Loss@kd 2.4426 (2.4618)	Acc@1 65.625 (67.081)	Acc@5 98.438 (98.384)
Epoch: [50][800/875]	Time 0.499 (0.507)	Data 0.007 (0.009)	Loss 1.4478 (1.5870)	Loss@kd 2.3876 (2.4594)	Acc@1 59.375 (67.139)	Acc@5 100.000 (98.375)
 * Acc@1 67.214 Acc@5 98.382
epoch 50, total time 444.10
Test: [0/750]	Time 0.765 (0.765)	Loss 0.9192 (0.9192)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.023 (0.036)	Loss 0.6281 (0.8990)	Acc@1 78.125 (79.177)	Acc@5 96.875 (90.439)
Test: [200/750]	Time 0.027 (0.033)	Loss 1.3467 (0.8756)	Acc@1 40.625 (76.073)	Acc@5 100.000 (91.931)
Test: [300/750]	Time 0.033 (0.032)	Loss 2.1964 (1.0973)	Acc@1 21.875 (65.189)	Acc@5 78.125 (91.663)
Test: [400/750]	Time 0.038 (0.031)	Loss 1.1979 (1.3235)	Acc@1 65.625 (57.684)	Acc@5 81.250 (89.191)
Test: [500/750]	Time 0.025 (0.030)	Loss 0.5783 (1.3141)	Acc@1 68.750 (58.446)	Acc@5 100.000 (88.560)
Test: [600/750]	Time 0.029 (0.030)	Loss 1.4901 (1.2743)	Acc@1 59.375 (59.593)	Acc@5 78.125 (88.639)
Test: [700/750]	Time 0.025 (0.029)	Loss 0.5186 (1.2475)	Acc@1 81.250 (60.226)	Acc@5 100.000 (88.828)
 * Acc@1 61.629 Acc@5 89.350
==> training...
Epoch: [51][0/875]	Time 1.698 (1.698)	Data 1.223 (1.223)	Loss 1.6067 (1.6067)	Loss@kd 2.4209 (2.4209)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [51][100/875]	Time 0.505 (0.521)	Data 0.007 (0.019)	Loss 1.3754 (1.3893)	Loss@kd 2.4544 (2.3741)	Acc@1 68.750 (69.709)	Acc@5 98.438 (98.809)
Epoch: [51][200/875]	Time 0.532 (0.516)	Data 0.007 (0.013)	Loss 1.2144 (1.3559)	Loss@kd 2.2082 (2.3571)	Acc@1 67.188 (70.204)	Acc@5 98.438 (98.733)
Epoch: [51][300/875]	Time 0.495 (0.504)	Data 0.007 (0.011)	Loss 1.2697 (1.3384)	Loss@kd 2.3151 (2.3478)	Acc@1 64.062 (70.069)	Acc@5 100.000 (98.624)
Epoch: [51][400/875]	Time 0.508 (0.506)	Data 0.008 (0.010)	Loss 1.1634 (1.3267)	Loss@kd 2.2275 (2.3410)	Acc@1 71.875 (70.114)	Acc@5 98.438 (98.574)
Epoch: [51][500/875]	Time 0.504 (0.506)	Data 0.007 (0.009)	Loss 1.2340 (1.3151)	Loss@kd 2.2549 (2.3347)	Acc@1 57.812 (70.284)	Acc@5 100.000 (98.637)
Epoch: [51][600/875]	Time 0.508 (0.507)	Data 0.006 (0.009)	Loss 1.3525 (1.3071)	Loss@kd 2.3278 (2.3302)	Acc@1 71.875 (70.227)	Acc@5 96.875 (98.687)
Epoch: [51][700/875]	Time 0.501 (0.507)	Data 0.008 (0.009)	Loss 1.3211 (1.3014)	Loss@kd 2.4008 (2.3265)	Acc@1 78.125 (70.163)	Acc@5 100.000 (98.674)
Epoch: [51][800/875]	Time 0.513 (0.508)	Data 0.007 (0.009)	Loss 1.2835 (1.2949)	Loss@kd 2.3163 (2.3218)	Acc@1 70.312 (70.215)	Acc@5 96.875 (98.685)
 * Acc@1 70.241 Acc@5 98.691
epoch 51, total time 444.41
Test: [0/750]	Time 0.774 (0.774)	Loss 0.4978 (0.4978)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.026 (0.035)	Loss 0.4349 (0.6075)	Acc@1 87.500 (85.241)	Acc@5 96.875 (94.554)
Test: [200/750]	Time 0.035 (0.033)	Loss 1.2429 (0.5631)	Acc@1 53.125 (83.909)	Acc@5 96.875 (95.833)
Test: [300/750]	Time 0.029 (0.032)	Loss 1.3420 (0.7865)	Acc@1 62.500 (73.951)	Acc@5 90.625 (94.923)
Test: [400/750]	Time 0.018 (0.031)	Loss 0.6331 (0.8924)	Acc@1 81.250 (69.857)	Acc@5 90.625 (94.101)
Test: [500/750]	Time 0.020 (0.030)	Loss 0.5087 (0.8546)	Acc@1 84.375 (71.544)	Acc@5 100.000 (93.700)
Test: [600/750]	Time 0.021 (0.029)	Loss 0.9009 (0.8643)	Acc@1 65.625 (71.246)	Acc@5 90.625 (93.610)
Test: [700/750]	Time 0.021 (0.028)	Loss 0.8347 (0.8678)	Acc@1 71.875 (70.805)	Acc@5 93.750 (93.719)
 * Acc@1 71.100 Acc@5 93.713
saving the best model!
==> training...
Epoch: [52][0/875]	Time 1.679 (1.679)	Data 1.218 (1.218)	Loss 1.2184 (1.2184)	Loss@kd 2.4052 (2.4052)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Epoch: [52][100/875]	Time 0.503 (0.501)	Data 0.007 (0.019)	Loss 1.3109 (1.2363)	Loss@kd 2.3813 (2.3048)	Acc@1 71.875 (70.978)	Acc@5 98.438 (98.639)
Epoch: [52][200/875]	Time 0.522 (0.506)	Data 0.005 (0.013)	Loss 1.2004 (1.2369)	Loss@kd 2.3493 (2.3026)	Acc@1 82.812 (70.942)	Acc@5 100.000 (98.694)
Epoch: [52][300/875]	Time 0.502 (0.507)	Data 0.007 (0.011)	Loss 1.2325 (1.2343)	Loss@kd 2.2654 (2.2969)	Acc@1 75.000 (70.961)	Acc@5 98.438 (98.853)
Epoch: [52][400/875]	Time 0.518 (0.508)	Data 0.007 (0.010)	Loss 1.2868 (1.2324)	Loss@kd 2.1827 (2.2928)	Acc@1 60.938 (70.971)	Acc@5 96.875 (98.808)
Epoch: [52][500/875]	Time 0.531 (0.508)	Data 0.007 (0.009)	Loss 1.4724 (1.2327)	Loss@kd 2.5925 (2.2918)	Acc@1 78.125 (71.039)	Acc@5 100.000 (98.802)
Epoch: [52][600/875]	Time 0.508 (0.508)	Data 0.007 (0.009)	Loss 1.2488 (1.2334)	Loss@kd 2.2753 (2.2910)	Acc@1 73.438 (71.152)	Acc@5 98.438 (98.799)
Epoch: [52][700/875]	Time 0.467 (0.507)	Data 0.007 (0.009)	Loss 1.1433 (1.2310)	Loss@kd 2.2368 (2.2889)	Acc@1 78.125 (71.275)	Acc@5 98.438 (98.772)
Epoch: [52][800/875]	Time 0.521 (0.504)	Data 0.004 (0.008)	Loss 1.2276 (1.2309)	Loss@kd 2.2459 (2.2869)	Acc@1 71.875 (71.023)	Acc@5 98.438 (98.746)
 * Acc@1 70.995 Acc@5 98.748
epoch 52, total time 441.90
Test: [0/750]	Time 0.790 (0.790)	Loss 0.4450 (0.4450)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.024 (0.035)	Loss 0.4823 (0.5417)	Acc@1 84.375 (85.953)	Acc@5 96.875 (94.493)
Test: [200/750]	Time 0.021 (0.033)	Loss 1.3466 (0.5406)	Acc@1 53.125 (83.784)	Acc@5 96.875 (95.647)
Test: [300/750]	Time 0.022 (0.030)	Loss 1.2831 (0.7820)	Acc@1 62.500 (73.339)	Acc@5 90.625 (94.425)
Test: [400/750]	Time 0.041 (0.030)	Loss 0.5722 (0.8719)	Acc@1 81.250 (69.576)	Acc@5 90.625 (93.851)
Test: [500/750]	Time 0.025 (0.030)	Loss 0.4923 (0.8297)	Acc@1 84.375 (71.382)	Acc@5 100.000 (93.787)
Test: [600/750]	Time 0.022 (0.030)	Loss 0.9667 (0.8332)	Acc@1 65.625 (71.391)	Acc@5 90.625 (93.708)
Test: [700/750]	Time 0.025 (0.030)	Loss 0.8169 (0.8322)	Acc@1 75.000 (71.251)	Acc@5 90.625 (93.808)
 * Acc@1 71.617 Acc@5 93.792
saving the best model!
==> training...
Epoch: [53][0/875]	Time 1.792 (1.792)	Data 1.304 (1.304)	Loss 1.1515 (1.1515)	Loss@kd 2.0934 (2.0934)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [53][100/875]	Time 0.504 (0.522)	Data 0.007 (0.020)	Loss 1.1741 (1.2223)	Loss@kd 2.2719 (2.2680)	Acc@1 71.875 (70.529)	Acc@5 98.438 (98.902)
Epoch: [53][200/875]	Time 0.532 (0.516)	Data 0.008 (0.014)	Loss 1.3700 (1.2284)	Loss@kd 2.3836 (2.2800)	Acc@1 73.438 (70.647)	Acc@5 100.000 (98.780)
Epoch: [53][300/875]	Time 0.496 (0.514)	Data 0.005 (0.011)	Loss 1.3114 (1.2247)	Loss@kd 2.3118 (2.2782)	Acc@1 78.125 (70.640)	Acc@5 100.000 (98.816)
Epoch: [53][400/875]	Time 0.527 (0.513)	Data 0.007 (0.010)	Loss 1.2820 (1.2261)	Loss@kd 2.3362 (2.2813)	Acc@1 68.750 (70.706)	Acc@5 100.000 (98.808)
Epoch: [53][500/875]	Time 0.470 (0.509)	Data 0.007 (0.010)	Loss 1.2151 (1.2236)	Loss@kd 2.3031 (2.2809)	Acc@1 76.562 (70.752)	Acc@5 100.000 (98.840)
Epoch: [53][600/875]	Time 0.527 (0.508)	Data 0.007 (0.009)	Loss 1.1440 (1.2201)	Loss@kd 2.2886 (2.2795)	Acc@1 71.875 (70.866)	Acc@5 98.438 (98.866)
Epoch: [53][700/875]	Time 0.613 (0.508)	Data 0.006 (0.009)	Loss 1.2373 (1.2183)	Loss@kd 2.1662 (2.2792)	Acc@1 67.188 (70.919)	Acc@5 98.438 (98.886)
Epoch: [53][800/875]	Time 0.508 (0.508)	Data 0.007 (0.009)	Loss 1.0902 (1.2161)	Loss@kd 2.3726 (2.2772)	Acc@1 79.688 (70.985)	Acc@5 98.438 (98.861)
 * Acc@1 70.963 Acc@5 98.843
epoch 53, total time 445.22
Test: [0/750]	Time 0.643 (0.643)	Loss 0.4592 (0.4592)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.019 (0.033)	Loss 0.4419 (0.5841)	Acc@1 84.375 (85.025)	Acc@5 96.875 (94.183)
Test: [200/750]	Time 0.038 (0.031)	Loss 1.3205 (0.5454)	Acc@1 40.625 (83.971)	Acc@5 93.750 (95.631)
Test: [300/750]	Time 0.041 (0.030)	Loss 1.2186 (0.7967)	Acc@1 62.500 (72.924)	Acc@5 90.625 (94.404)
Test: [400/750]	Time 0.028 (0.030)	Loss 0.6583 (0.8905)	Acc@1 84.375 (69.070)	Acc@5 93.750 (94.046)
Test: [500/750]	Time 0.018 (0.029)	Loss 0.5356 (0.8643)	Acc@1 81.250 (70.565)	Acc@5 100.000 (93.476)
Test: [600/750]	Time 0.027 (0.029)	Loss 0.8996 (0.8695)	Acc@1 68.750 (70.507)	Acc@5 90.625 (93.381)
Test: [700/750]	Time 0.022 (0.029)	Loss 0.6265 (0.8572)	Acc@1 84.375 (70.680)	Acc@5 96.875 (93.665)
 * Acc@1 71.287 Acc@5 93.817
==> training...
Epoch: [54][0/875]	Time 1.779 (1.779)	Data 1.297 (1.297)	Loss 1.1358 (1.1358)	Loss@kd 2.1098 (2.1098)	Acc@1 67.188 (67.188)	Acc@5 93.750 (93.750)
Epoch: [54][100/875]	Time 0.502 (0.522)	Data 0.005 (0.020)	Loss 1.1745 (1.2057)	Loss@kd 2.1630 (2.2781)	Acc@1 71.875 (71.241)	Acc@5 95.312 (98.855)
Epoch: [54][200/875]	Time 0.526 (0.516)	Data 0.007 (0.013)	Loss 1.1227 (1.1993)	Loss@kd 2.1864 (2.2749)	Acc@1 68.750 (71.261)	Acc@5 98.438 (98.834)
Epoch: [54][300/875]	Time 0.502 (0.504)	Data 0.005 (0.011)	Loss 1.2320 (1.1941)	Loss@kd 2.3860 (2.2701)	Acc@1 75.000 (71.475)	Acc@5 96.875 (98.842)
Epoch: [54][400/875]	Time 0.493 (0.505)	Data 0.007 (0.010)	Loss 1.1475 (1.1934)	Loss@kd 2.3121 (2.2688)	Acc@1 76.562 (71.407)	Acc@5 100.000 (98.819)
Epoch: [54][500/875]	Time 0.506 (0.506)	Data 0.006 (0.010)	Loss 1.2015 (1.1922)	Loss@kd 2.2502 (2.2638)	Acc@1 76.562 (71.301)	Acc@5 100.000 (98.834)
Epoch: [54][600/875]	Time 0.608 (0.507)	Data 0.007 (0.009)	Loss 1.1861 (1.1919)	Loss@kd 2.2580 (2.2626)	Acc@1 73.438 (71.306)	Acc@5 98.438 (98.882)
Epoch: [54][700/875]	Time 0.503 (0.507)	Data 0.007 (0.009)	Loss 1.4088 (1.1923)	Loss@kd 3.0021 (2.2636)	Acc@1 78.125 (71.340)	Acc@5 100.000 (98.912)
Epoch: [54][800/875]	Time 0.525 (0.507)	Data 0.007 (0.009)	Loss 1.1649 (1.1917)	Loss@kd 2.2637 (2.2634)	Acc@1 76.562 (71.428)	Acc@5 98.438 (98.913)
 * Acc@1 71.459 Acc@5 98.918
epoch 54, total time 444.28
Test: [0/750]	Time 0.774 (0.774)	Loss 0.4827 (0.4827)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.022 (0.037)	Loss 0.4449 (0.5747)	Acc@1 84.375 (85.458)	Acc@5 96.875 (94.121)
Test: [200/750]	Time 0.026 (0.033)	Loss 1.2808 (0.5436)	Acc@1 40.625 (83.738)	Acc@5 93.750 (95.740)
Test: [300/750]	Time 0.020 (0.032)	Loss 1.1479 (0.7693)	Acc@1 71.875 (73.692)	Acc@5 90.625 (94.840)
Test: [400/750]	Time 0.025 (0.031)	Loss 0.6118 (0.8342)	Acc@1 81.250 (70.955)	Acc@5 90.625 (94.623)
Test: [500/750]	Time 0.023 (0.031)	Loss 0.5488 (0.8094)	Acc@1 75.000 (72.218)	Acc@5 100.000 (94.193)
Test: [600/750]	Time 0.036 (0.030)	Loss 0.8475 (0.8265)	Acc@1 71.875 (71.745)	Acc@5 93.750 (93.896)
Test: [700/750]	Time 0.019 (0.030)	Loss 0.7979 (0.8247)	Acc@1 62.500 (71.621)	Acc@5 90.625 (94.022)
 * Acc@1 71.783 Acc@5 93.996
saving the best model!
==> training...
Epoch: [55][0/875]	Time 1.809 (1.809)	Data 1.310 (1.310)	Loss 1.1923 (1.1923)	Loss@kd 2.2955 (2.2955)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [55][100/875]	Time 0.519 (0.502)	Data 0.008 (0.020)	Loss 1.1394 (1.1872)	Loss@kd 2.2140 (2.2583)	Acc@1 57.812 (70.947)	Acc@5 96.875 (98.747)
Epoch: [55][200/875]	Time 0.505 (0.506)	Data 0.008 (0.014)	Loss 1.1181 (1.1943)	Loss@kd 2.2616 (2.2575)	Acc@1 71.875 (71.067)	Acc@5 100.000 (98.834)
Epoch: [55][300/875]	Time 0.495 (0.507)	Data 0.006 (0.012)	Loss 1.3213 (1.1934)	Loss@kd 2.4395 (2.2566)	Acc@1 68.750 (71.231)	Acc@5 100.000 (98.879)
Epoch: [55][400/875]	Time 0.524 (0.508)	Data 0.008 (0.011)	Loss 1.1598 (1.1926)	Loss@kd 2.2226 (2.2572)	Acc@1 78.125 (71.528)	Acc@5 96.875 (98.843)
Epoch: [55][500/875]	Time 0.504 (0.508)	Data 0.007 (0.010)	Loss 1.2056 (1.1907)	Loss@kd 2.3770 (2.2590)	Acc@1 68.750 (71.616)	Acc@5 100.000 (98.821)
Epoch: [55][600/875]	Time 0.506 (0.508)	Data 0.007 (0.010)	Loss 1.1723 (1.1885)	Loss@kd 2.2087 (2.2583)	Acc@1 64.062 (71.670)	Acc@5 100.000 (98.843)
Epoch: [55][700/875]	Time 0.531 (0.508)	Data 0.007 (0.009)	Loss 1.2315 (1.1859)	Loss@kd 2.4276 (2.2568)	Acc@1 78.125 (71.663)	Acc@5 98.438 (98.810)
Epoch: [55][800/875]	Time 0.501 (0.505)	Data 0.010 (0.009)	Loss 1.1740 (1.1844)	Loss@kd 2.2876 (2.2551)	Acc@1 70.312 (71.598)	Acc@5 96.875 (98.824)
 * Acc@1 71.588 Acc@5 98.820
epoch 55, total time 442.76
Test: [0/750]	Time 0.710 (0.710)	Loss 0.4538 (0.4538)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.020 (0.034)	Loss 0.4351 (0.5065)	Acc@1 84.375 (86.386)	Acc@5 96.875 (94.678)
Test: [200/750]	Time 0.044 (0.032)	Loss 1.4117 (0.5061)	Acc@1 43.750 (84.826)	Acc@5 96.875 (95.942)
Test: [300/750]	Time 0.039 (0.031)	Loss 1.2305 (0.7615)	Acc@1 65.625 (73.931)	Acc@5 90.625 (94.809)
Test: [400/750]	Time 0.024 (0.031)	Loss 0.6716 (0.8574)	Acc@1 81.250 (70.176)	Acc@5 90.625 (94.319)
Test: [500/750]	Time 0.019 (0.030)	Loss 0.6900 (0.8510)	Acc@1 71.875 (70.914)	Acc@5 96.875 (93.806)
Test: [600/750]	Time 0.016 (0.030)	Loss 0.8531 (0.8710)	Acc@1 68.750 (70.471)	Acc@5 93.750 (93.459)
Test: [700/750]	Time 0.020 (0.030)	Loss 0.6233 (0.8551)	Acc@1 78.125 (70.658)	Acc@5 96.875 (93.790)
 * Acc@1 71.233 Acc@5 93.883
==> training...
Epoch: [56][0/875]	Time 1.909 (1.909)	Data 1.360 (1.360)	Loss 1.1321 (1.1321)	Loss@kd 2.2305 (2.2305)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [56][100/875]	Time 0.530 (0.523)	Data 0.008 (0.021)	Loss 1.1021 (1.1702)	Loss@kd 2.2535 (2.2444)	Acc@1 75.000 (72.757)	Acc@5 98.438 (98.933)
Epoch: [56][200/875]	Time 0.503 (0.516)	Data 0.006 (0.014)	Loss 1.1008 (1.1736)	Loss@kd 2.1721 (2.2497)	Acc@1 81.250 (72.225)	Acc@5 100.000 (98.935)
Epoch: [56][300/875]	Time 0.521 (0.514)	Data 0.008 (0.012)	Loss 1.1327 (1.1727)	Loss@kd 2.2055 (2.2480)	Acc@1 65.625 (72.088)	Acc@5 100.000 (98.910)
Epoch: [56][400/875]	Time 0.504 (0.513)	Data 0.008 (0.011)	Loss 1.2653 (1.1734)	Loss@kd 2.2083 (2.2459)	Acc@1 71.875 (72.035)	Acc@5 100.000 (98.870)
Epoch: [56][500/875]	Time 0.396 (0.512)	Data 0.008 (0.010)	Loss 1.0327 (1.1727)	Loss@kd 2.1752 (2.2482)	Acc@1 64.062 (72.047)	Acc@5 100.000 (98.862)
Epoch: [56][600/875]	Time 0.490 (0.508)	Data 0.007 (0.010)	Loss 1.2590 (1.1733)	Loss@kd 2.5208 (2.2479)	Acc@1 71.875 (72.148)	Acc@5 100.000 (98.874)
Epoch: [56][700/875]	Time 0.527 (0.508)	Data 0.008 (0.009)	Loss 1.1086 (1.1736)	Loss@kd 2.3384 (2.2479)	Acc@1 78.125 (72.136)	Acc@5 98.438 (98.883)
Epoch: [56][800/875]	Time 0.491 (0.508)	Data 0.007 (0.009)	Loss 1.1801 (1.1734)	Loss@kd 2.1700 (2.2473)	Acc@1 67.188 (71.974)	Acc@5 100.000 (98.876)
 * Acc@1 71.889 Acc@5 98.871
epoch 56, total time 445.03
Test: [0/750]	Time 0.802 (0.802)	Loss 0.4627 (0.4627)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.028 (0.037)	Loss 0.4970 (0.5693)	Acc@1 81.250 (85.149)	Acc@5 96.875 (94.090)
Test: [200/750]	Time 0.029 (0.033)	Loss 1.3994 (0.5389)	Acc@1 40.625 (83.706)	Acc@5 93.750 (95.771)
Test: [300/750]	Time 0.043 (0.032)	Loss 1.1582 (0.7745)	Acc@1 62.500 (72.955)	Acc@5 90.625 (94.674)
Test: [400/750]	Time 0.026 (0.032)	Loss 0.6230 (0.8577)	Acc@1 81.250 (69.677)	Acc@5 90.625 (94.179)
Test: [500/750]	Time 0.031 (0.031)	Loss 0.4772 (0.8263)	Acc@1 78.125 (71.270)	Acc@5 100.000 (93.869)
Test: [600/750]	Time 0.020 (0.030)	Loss 0.7881 (0.8284)	Acc@1 68.750 (71.464)	Acc@5 90.625 (93.760)
Test: [700/750]	Time 0.033 (0.030)	Loss 0.7255 (0.8154)	Acc@1 71.875 (71.554)	Acc@5 93.750 (94.058)
 * Acc@1 71.996 Acc@5 94.167
saving the best model!
==> training...
Epoch: [57][0/875]	Time 1.782 (1.782)	Data 1.298 (1.298)	Loss 1.0832 (1.0832)	Loss@kd 2.2424 (2.2424)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [57][100/875]	Time 0.524 (0.523)	Data 0.007 (0.020)	Loss 1.0477 (1.1556)	Loss@kd 2.1402 (2.2397)	Acc@1 68.750 (71.983)	Acc@5 100.000 (98.855)
Epoch: [57][200/875]	Time 0.502 (0.516)	Data 0.007 (0.013)	Loss 1.1105 (1.1542)	Loss@kd 2.1949 (2.2301)	Acc@1 75.000 (72.069)	Acc@5 98.438 (98.873)
Epoch: [57][300/875]	Time 0.469 (0.508)	Data 0.007 (0.011)	Loss 1.0973 (1.1581)	Loss@kd 2.1677 (2.2339)	Acc@1 68.750 (71.859)	Acc@5 100.000 (98.822)
Epoch: [57][400/875]	Time 0.526 (0.506)	Data 0.005 (0.010)	Loss 1.1513 (1.1589)	Loss@kd 2.2279 (2.2326)	Acc@1 73.438 (71.715)	Acc@5 96.875 (98.804)
Epoch: [57][500/875]	Time 0.494 (0.506)	Data 0.007 (0.010)	Loss 1.3962 (1.1613)	Loss@kd 2.2983 (2.2352)	Acc@1 71.875 (71.884)	Acc@5 98.438 (98.846)
Epoch: [57][600/875]	Time 0.504 (0.507)	Data 0.006 (0.009)	Loss 1.1420 (1.1628)	Loss@kd 2.2623 (2.2370)	Acc@1 68.750 (71.729)	Acc@5 100.000 (98.853)
Epoch: [57][700/875]	Time 0.504 (0.507)	Data 0.007 (0.009)	Loss 1.1845 (1.1642)	Loss@kd 2.2065 (2.2363)	Acc@1 68.750 (71.815)	Acc@5 96.875 (98.850)
Epoch: [57][800/875]	Time 0.505 (0.508)	Data 0.008 (0.009)	Loss 1.2028 (1.1652)	Loss@kd 2.4848 (2.2382)	Acc@1 81.250 (71.809)	Acc@5 98.438 (98.865)
 * Acc@1 71.761 Acc@5 98.859
epoch 57, total time 444.70
Test: [0/750]	Time 0.703 (0.703)	Loss 0.4381 (0.4381)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.029 (0.034)	Loss 0.4225 (0.5382)	Acc@1 84.375 (85.798)	Acc@5 100.000 (94.585)
Test: [200/750]	Time 0.028 (0.030)	Loss 1.4399 (0.5230)	Acc@1 43.750 (84.017)	Acc@5 93.750 (95.725)
Test: [300/750]	Time 0.041 (0.030)	Loss 1.3501 (0.7926)	Acc@1 65.625 (72.633)	Acc@5 90.625 (94.113)
Test: [400/750]	Time 0.027 (0.029)	Loss 0.4660 (0.8861)	Acc@1 87.500 (69.405)	Acc@5 96.875 (93.656)
Test: [500/750]	Time 0.030 (0.029)	Loss 0.4485 (0.8280)	Acc@1 84.375 (71.601)	Acc@5 100.000 (93.881)
Test: [600/750]	Time 0.021 (0.029)	Loss 0.8895 (0.8364)	Acc@1 68.750 (71.475)	Acc@5 93.750 (93.729)
Test: [700/750]	Time 0.033 (0.029)	Loss 0.7206 (0.8296)	Acc@1 71.875 (71.371)	Acc@5 90.625 (93.960)
 * Acc@1 71.904 Acc@5 94.067
==> training...
Epoch: [58][0/875]	Time 1.972 (1.972)	Data 1.471 (1.471)	Loss 1.1489 (1.1489)	Loss@kd 2.2430 (2.2430)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [58][100/875]	Time 0.527 (0.499)	Data 0.008 (0.022)	Loss 1.1437 (1.1717)	Loss@kd 2.2642 (2.2525)	Acc@1 71.875 (72.061)	Acc@5 100.000 (98.793)
Epoch: [58][200/875]	Time 0.511 (0.504)	Data 0.007 (0.015)	Loss 1.3087 (1.1641)	Loss@kd 2.3534 (2.2403)	Acc@1 65.625 (71.937)	Acc@5 100.000 (98.857)
Epoch: [58][300/875]	Time 0.499 (0.506)	Data 0.006 (0.012)	Loss 1.0908 (1.1620)	Loss@kd 2.2131 (2.2363)	Acc@1 73.438 (71.761)	Acc@5 96.875 (98.739)
Epoch: [58][400/875]	Time 0.524 (0.507)	Data 0.007 (0.011)	Loss 1.1368 (1.1630)	Loss@kd 2.2868 (2.2367)	Acc@1 75.000 (71.785)	Acc@5 100.000 (98.796)
Epoch: [58][500/875]	Time 0.514 (0.508)	Data 0.010 (0.010)	Loss 1.1745 (1.1619)	Loss@kd 2.3347 (2.2373)	Acc@1 73.438 (71.897)	Acc@5 98.438 (98.806)
Epoch: [58][600/875]	Time 0.526 (0.508)	Data 0.007 (0.010)	Loss 1.1414 (1.1632)	Loss@kd 2.2342 (2.2373)	Acc@1 73.438 (71.870)	Acc@5 100.000 (98.840)
Epoch: [58][700/875]	Time 0.518 (0.508)	Data 0.007 (0.010)	Loss 1.2100 (1.1617)	Loss@kd 2.2211 (2.2350)	Acc@1 78.125 (72.015)	Acc@5 98.438 (98.872)
Epoch: [58][800/875]	Time 0.388 (0.505)	Data 0.005 (0.009)	Loss 1.1394 (1.1604)	Loss@kd 2.2415 (2.2339)	Acc@1 65.625 (72.064)	Acc@5 98.438 (98.867)
 * Acc@1 72.141 Acc@5 98.873
epoch 58, total time 442.22
Test: [0/750]	Time 0.624 (0.624)	Loss 0.4353 (0.4353)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.031 (0.035)	Loss 0.4516 (0.5371)	Acc@1 84.375 (86.015)	Acc@5 96.875 (95.297)
Test: [200/750]	Time 0.046 (0.032)	Loss 1.4515 (0.5478)	Acc@1 43.750 (83.442)	Acc@5 93.750 (95.958)
Test: [300/750]	Time 0.038 (0.030)	Loss 1.2693 (0.8028)	Acc@1 65.625 (72.612)	Acc@5 90.625 (94.549)
Test: [400/750]	Time 0.018 (0.030)	Loss 0.6026 (0.8766)	Acc@1 84.375 (69.506)	Acc@5 90.625 (94.015)
Test: [500/750]	Time 0.019 (0.029)	Loss 0.4368 (0.8560)	Acc@1 84.375 (70.821)	Acc@5 100.000 (93.569)
Test: [600/750]	Time 0.023 (0.029)	Loss 0.7669 (0.8539)	Acc@1 75.000 (71.017)	Acc@5 93.750 (93.558)
Test: [700/750]	Time 0.022 (0.029)	Loss 0.8348 (0.8441)	Acc@1 62.500 (70.979)	Acc@5 93.750 (93.830)
 * Acc@1 71.371 Acc@5 93.854
==> training...
Epoch: [59][0/875]	Time 1.831 (1.831)	Data 1.326 (1.326)	Loss 1.2005 (1.2005)	Loss@kd 2.2230 (2.2230)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [59][100/875]	Time 0.529 (0.523)	Data 0.006 (0.020)	Loss 1.2908 (1.1598)	Loss@kd 2.3496 (2.2377)	Acc@1 65.625 (72.045)	Acc@5 96.875 (98.886)
Epoch: [59][200/875]	Time 0.509 (0.516)	Data 0.007 (0.014)	Loss 1.1119 (1.1670)	Loss@kd 2.2335 (2.2361)	Acc@1 70.312 (71.339)	Acc@5 100.000 (98.943)
Epoch: [59][300/875]	Time 0.507 (0.514)	Data 0.006 (0.012)	Loss 1.1500 (1.1648)	Loss@kd 2.2405 (2.2342)	Acc@1 75.000 (71.673)	Acc@5 98.438 (98.920)
Epoch: [59][400/875]	Time 0.499 (0.513)	Data 0.007 (0.011)	Loss 1.2990 (1.1616)	Loss@kd 2.2574 (2.2305)	Acc@1 71.875 (71.898)	Acc@5 98.438 (98.909)
Epoch: [59][500/875]	Time 0.509 (0.512)	Data 0.007 (0.010)	Loss 1.2490 (1.1590)	Loss@kd 2.2105 (2.2309)	Acc@1 68.750 (71.831)	Acc@5 100.000 (98.908)
Epoch: [59][600/875]	Time 0.515 (0.507)	Data 0.007 (0.009)	Loss 1.1573 (1.1573)	Loss@kd 2.1223 (2.2279)	Acc@1 84.375 (71.854)	Acc@5 98.438 (98.895)
Epoch: [59][700/875]	Time 0.529 (0.508)	Data 0.007 (0.009)	Loss 1.2759 (1.1571)	Loss@kd 2.3165 (2.2293)	Acc@1 70.312 (71.893)	Acc@5 100.000 (98.899)
Epoch: [59][800/875]	Time 0.489 (0.508)	Data 0.007 (0.009)	Loss 1.2403 (1.1573)	Loss@kd 2.3106 (2.2309)	Acc@1 65.625 (71.959)	Acc@5 98.438 (98.915)
 * Acc@1 72.005 Acc@5 98.904
epoch 59, total time 444.79
Test: [0/750]	Time 0.708 (0.708)	Loss 0.3747 (0.3747)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.017 (0.032)	Loss 0.3983 (0.5037)	Acc@1 84.375 (86.479)	Acc@5 96.875 (95.019)
Test: [200/750]	Time 0.021 (0.028)	Loss 1.3149 (0.4920)	Acc@1 43.750 (84.950)	Acc@5 93.750 (96.129)
Test: [300/750]	Time 0.019 (0.028)	Loss 1.0793 (0.7374)	Acc@1 75.000 (74.336)	Acc@5 93.750 (94.902)
Test: [400/750]	Time 0.024 (0.027)	Loss 0.6741 (0.8131)	Acc@1 81.250 (71.174)	Acc@5 87.500 (94.724)
Test: [500/750]	Time 0.035 (0.027)	Loss 0.6919 (0.8110)	Acc@1 75.000 (71.831)	Acc@5 96.875 (93.975)
Test: [600/750]	Time 0.018 (0.027)	Loss 0.8757 (0.8347)	Acc@1 68.750 (71.235)	Acc@5 93.750 (93.708)
Test: [700/750]	Time 0.027 (0.026)	Loss 0.7960 (0.8320)	Acc@1 68.750 (71.032)	Acc@5 87.500 (93.861)
 * Acc@1 71.517 Acc@5 93.954
==> training...
Epoch: [60][0/875]	Time 1.726 (1.726)	Data 1.227 (1.227)	Loss 1.1812 (1.1812)	Loss@kd 2.2373 (2.2373)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [60][100/875]	Time 0.515 (0.523)	Data 0.007 (0.019)	Loss 1.2091 (1.1486)	Loss@kd 2.2369 (2.2368)	Acc@1 76.562 (72.649)	Acc@5 96.875 (98.994)
Epoch: [60][200/875]	Time 0.522 (0.516)	Data 0.005 (0.013)	Loss 1.0852 (1.1545)	Loss@kd 2.3433 (2.2324)	Acc@1 70.312 (72.404)	Acc@5 98.438 (98.974)
Epoch: [60][300/875]	Time 0.513 (0.514)	Data 0.005 (0.011)	Loss 1.1456 (1.1519)	Loss@kd 2.1938 (2.2291)	Acc@1 65.625 (72.046)	Acc@5 100.000 (99.009)
Epoch: [60][400/875]	Time 0.524 (0.506)	Data 0.007 (0.010)	Loss 1.2620 (1.1531)	Loss@kd 2.3973 (2.2280)	Acc@1 78.125 (71.976)	Acc@5 100.000 (99.010)
Epoch: [60][500/875]	Time 0.506 (0.507)	Data 0.007 (0.010)	Loss 1.0534 (1.1513)	Loss@kd 2.1407 (2.2281)	Acc@1 68.750 (71.909)	Acc@5 100.000 (98.983)
Epoch: [60][600/875]	Time 0.526 (0.507)	Data 0.008 (0.009)	Loss 1.0219 (1.1517)	Loss@kd 2.1759 (2.2281)	Acc@1 75.000 (71.909)	Acc@5 100.000 (98.968)
Epoch: [60][700/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 1.0762 (1.1512)	Loss@kd 2.2640 (2.2272)	Acc@1 76.562 (71.931)	Acc@5 100.000 (98.941)
Epoch: [60][800/875]	Time 0.509 (0.508)	Data 0.007 (0.009)	Loss 1.1188 (1.1517)	Loss@kd 2.1408 (2.2276)	Acc@1 71.875 (72.021)	Acc@5 100.000 (98.913)
 * Acc@1 71.982 Acc@5 98.900
epoch 60, total time 444.77
Test: [0/750]	Time 0.706 (0.706)	Loss 0.5110 (0.5110)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.034 (0.036)	Loss 0.4171 (0.5218)	Acc@1 84.375 (86.603)	Acc@5 96.875 (94.709)
Test: [200/750]	Time 0.027 (0.032)	Loss 1.3002 (0.5104)	Acc@1 43.750 (84.779)	Acc@5 93.750 (95.864)
Test: [300/750]	Time 0.031 (0.031)	Loss 0.9480 (0.7446)	Acc@1 75.000 (74.605)	Acc@5 93.750 (94.902)
Test: [400/750]	Time 0.037 (0.030)	Loss 0.6767 (0.7975)	Acc@1 81.250 (72.218)	Acc@5 87.500 (94.833)
Test: [500/750]	Time 0.027 (0.030)	Loss 0.6225 (0.7846)	Acc@1 78.125 (73.179)	Acc@5 100.000 (94.299)
Test: [600/750]	Time 0.030 (0.029)	Loss 0.8695 (0.8093)	Acc@1 68.750 (72.468)	Acc@5 93.750 (93.979)
Test: [700/750]	Time 0.024 (0.029)	Loss 1.0887 (0.8200)	Acc@1 53.125 (71.857)	Acc@5 87.500 (94.013)
 * Acc@1 72.042 Acc@5 93.958
saving the best model!
==> training...
Epoch: [61][0/875]	Time 1.744 (1.744)	Data 1.270 (1.270)	Loss 1.0999 (1.0999)	Loss@kd 2.2190 (2.2190)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [61][100/875]	Time 0.449 (0.516)	Data 0.007 (0.020)	Loss 1.2081 (1.1198)	Loss@kd 2.4266 (2.2097)	Acc@1 75.000 (72.339)	Acc@5 100.000 (99.010)
Epoch: [61][200/875]	Time 0.525 (0.499)	Data 0.007 (0.013)	Loss 1.2001 (1.1160)	Loss@kd 2.4908 (2.2150)	Acc@1 67.188 (72.987)	Acc@5 100.000 (99.106)
Epoch: [61][300/875]	Time 0.508 (0.503)	Data 0.007 (0.011)	Loss 1.0496 (1.1093)	Loss@kd 2.1081 (2.2116)	Acc@1 75.000 (72.643)	Acc@5 98.438 (99.092)
Epoch: [61][400/875]	Time 0.525 (0.504)	Data 0.008 (0.010)	Loss 1.0346 (1.1073)	Loss@kd 2.1739 (2.2106)	Acc@1 75.000 (72.705)	Acc@5 98.438 (99.069)
Epoch: [61][500/875]	Time 0.498 (0.506)	Data 0.007 (0.010)	Loss 1.1601 (1.1043)	Loss@kd 2.1927 (2.2084)	Acc@1 71.875 (72.811)	Acc@5 98.438 (99.039)
Epoch: [61][600/875]	Time 0.531 (0.506)	Data 0.007 (0.009)	Loss 1.1021 (1.1055)	Loss@kd 2.2133 (2.2086)	Acc@1 67.188 (72.658)	Acc@5 98.438 (99.025)
Epoch: [61][700/875]	Time 0.512 (0.507)	Data 0.007 (0.009)	Loss 1.0684 (1.1049)	Loss@kd 2.1660 (2.2077)	Acc@1 79.688 (72.635)	Acc@5 100.000 (99.008)
Epoch: [61][800/875]	Time 0.397 (0.507)	Data 0.010 (0.009)	Loss 1.1975 (1.1056)	Loss@kd 2.3060 (2.2079)	Acc@1 78.125 (72.575)	Acc@5 100.000 (99.007)
 * Acc@1 72.596 Acc@5 99.014
epoch 61, total time 438.59
Test: [0/750]	Time 0.796 (0.796)	Loss 0.4681 (0.4681)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.019 (0.029)	Loss 0.4077 (0.5176)	Acc@1 84.375 (86.139)	Acc@5 96.875 (94.678)
Test: [200/750]	Time 0.024 (0.027)	Loss 1.3112 (0.4985)	Acc@1 40.625 (84.748)	Acc@5 96.875 (96.051)
Test: [300/750]	Time 0.026 (0.026)	Loss 0.9573 (0.7397)	Acc@1 75.000 (74.242)	Acc@5 90.625 (94.892)
Test: [400/750]	Time 0.027 (0.025)	Loss 0.6845 (0.8031)	Acc@1 81.250 (71.532)	Acc@5 90.625 (94.810)
Test: [500/750]	Time 0.023 (0.025)	Loss 0.6600 (0.7948)	Acc@1 78.125 (72.380)	Acc@5 100.000 (94.218)
Test: [600/750]	Time 0.021 (0.025)	Loss 0.8341 (0.8156)	Acc@1 71.875 (71.870)	Acc@5 93.750 (93.974)
Test: [700/750]	Time 0.019 (0.025)	Loss 0.8066 (0.8137)	Acc@1 62.500 (71.683)	Acc@5 93.750 (94.133)
 * Acc@1 72.050 Acc@5 94.183
saving the best model!
==> training...
Epoch: [62][0/875]	Time 1.752 (1.752)	Data 1.346 (1.346)	Loss 1.1524 (1.1524)	Loss@kd 2.1711 (2.1711)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [62][100/875]	Time 0.404 (0.413)	Data 0.006 (0.020)	Loss 1.1379 (1.1008)	Loss@kd 2.2754 (2.1981)	Acc@1 62.500 (73.376)	Acc@5 96.875 (98.933)
Epoch: [62][200/875]	Time 0.396 (0.406)	Data 0.007 (0.013)	Loss 1.1821 (1.1049)	Loss@kd 2.2990 (2.2084)	Acc@1 75.000 (72.987)	Acc@5 96.875 (98.958)
Epoch: [62][300/875]	Time 0.398 (0.404)	Data 0.007 (0.011)	Loss 1.1071 (1.1019)	Loss@kd 2.2208 (2.2081)	Acc@1 75.000 (73.074)	Acc@5 96.875 (98.998)
Epoch: [62][400/875]	Time 0.394 (0.403)	Data 0.007 (0.010)	Loss 1.0827 (1.1023)	Loss@kd 2.0937 (2.2089)	Acc@1 70.312 (72.939)	Acc@5 100.000 (98.940)
Epoch: [62][500/875]	Time 0.400 (0.402)	Data 0.006 (0.009)	Loss 1.0648 (1.1028)	Loss@kd 2.1442 (2.2099)	Acc@1 67.188 (72.645)	Acc@5 96.875 (98.990)
Epoch: [62][600/875]	Time 0.395 (0.402)	Data 0.007 (0.009)	Loss 0.9788 (1.1008)	Loss@kd 2.0797 (2.2083)	Acc@1 73.438 (72.535)	Acc@5 98.438 (98.986)
Epoch: [62][700/875]	Time 0.401 (0.402)	Data 0.006 (0.009)	Loss 1.1164 (1.0995)	Loss@kd 2.3558 (2.2065)	Acc@1 84.375 (72.664)	Acc@5 100.000 (98.986)
Epoch: [62][800/875]	Time 0.401 (0.402)	Data 0.006 (0.008)	Loss 1.0907 (1.0987)	Loss@kd 2.2190 (2.2052)	Acc@1 76.562 (72.644)	Acc@5 100.000 (98.978)
 * Acc@1 72.612 Acc@5 98.973
epoch 62, total time 351.83
Test: [0/750]	Time 0.741 (0.741)	Loss 0.4286 (0.4286)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.016 (0.029)	Loss 0.4137 (0.4923)	Acc@1 84.375 (86.850)	Acc@5 96.875 (94.740)
Test: [200/750]	Time 0.016 (0.025)	Loss 1.4424 (0.4876)	Acc@1 37.500 (84.935)	Acc@5 93.750 (96.004)
Test: [300/750]	Time 0.021 (0.023)	Loss 1.0923 (0.7489)	Acc@1 65.625 (73.744)	Acc@5 90.625 (94.518)
Test: [400/750]	Time 0.019 (0.022)	Loss 0.5342 (0.8270)	Acc@1 84.375 (70.550)	Acc@5 90.625 (94.257)
Test: [500/750]	Time 0.020 (0.022)	Loss 0.6031 (0.7955)	Acc@1 81.250 (72.106)	Acc@5 96.875 (94.099)
Test: [600/750]	Time 0.022 (0.022)	Loss 0.8135 (0.8106)	Acc@1 71.875 (71.797)	Acc@5 96.875 (93.911)
Test: [700/750]	Time 0.015 (0.021)	Loss 0.6793 (0.8016)	Acc@1 71.875 (71.817)	Acc@5 96.875 (94.178)
 * Acc@1 72.296 Acc@5 94.246
saving the best model!
==> training...
Epoch: [63][0/875]	Time 1.747 (1.747)	Data 1.341 (1.341)	Loss 1.1177 (1.1177)	Loss@kd 2.2253 (2.2253)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [63][100/875]	Time 0.399 (0.413)	Data 0.007 (0.020)	Loss 1.0894 (1.0998)	Loss@kd 2.2362 (2.2003)	Acc@1 76.562 (72.726)	Acc@5 100.000 (98.917)
Epoch: [63][200/875]	Time 0.401 (0.407)	Data 0.007 (0.013)	Loss 1.0726 (1.0999)	Loss@kd 2.1595 (2.2008)	Acc@1 67.188 (72.318)	Acc@5 100.000 (99.036)
Epoch: [63][300/875]	Time 0.397 (0.405)	Data 0.007 (0.011)	Loss 1.2062 (1.0968)	Loss@kd 2.3277 (2.2042)	Acc@1 75.000 (72.648)	Acc@5 100.000 (98.972)
Epoch: [63][400/875]	Time 0.398 (0.404)	Data 0.006 (0.010)	Loss 1.0305 (1.0965)	Loss@kd 2.0502 (2.2059)	Acc@1 78.125 (72.530)	Acc@5 100.000 (99.026)
Epoch: [63][500/875]	Time 0.402 (0.403)	Data 0.008 (0.009)	Loss 1.2168 (1.0969)	Loss@kd 2.2415 (2.2038)	Acc@1 71.875 (72.542)	Acc@5 100.000 (99.027)
Epoch: [63][600/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss 1.0623 (1.0960)	Loss@kd 2.1741 (2.2028)	Acc@1 75.000 (72.663)	Acc@5 100.000 (99.025)
Epoch: [63][700/875]	Time 0.395 (0.403)	Data 0.007 (0.009)	Loss 1.0464 (1.0968)	Loss@kd 2.1409 (2.2046)	Acc@1 62.500 (72.726)	Acc@5 100.000 (99.024)
Epoch: [63][800/875]	Time 0.398 (0.402)	Data 0.008 (0.008)	Loss 1.0672 (1.0970)	Loss@kd 2.1951 (2.2041)	Acc@1 73.438 (72.599)	Acc@5 98.438 (99.007)
 * Acc@1 72.679 Acc@5 99.007
epoch 63, total time 352.36
Test: [0/750]	Time 0.743 (0.743)	Loss 0.4112 (0.4112)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.018 (0.030)	Loss 0.4487 (0.4870)	Acc@1 81.250 (86.757)	Acc@5 96.875 (95.019)
Test: [200/750]	Time 0.016 (0.025)	Loss 1.2765 (0.4880)	Acc@1 40.625 (84.966)	Acc@5 93.750 (96.253)
Test: [300/750]	Time 0.016 (0.022)	Loss 1.0995 (0.7158)	Acc@1 68.750 (74.813)	Acc@5 90.625 (95.235)
Test: [400/750]	Time 0.015 (0.021)	Loss 0.6102 (0.7966)	Acc@1 81.250 (71.579)	Acc@5 90.625 (94.825)
Test: [500/750]	Time 0.022 (0.021)	Loss 0.6138 (0.7814)	Acc@1 81.250 (72.636)	Acc@5 100.000 (94.417)
Test: [600/750]	Time 0.020 (0.020)	Loss 0.8156 (0.8013)	Acc@1 75.000 (72.041)	Acc@5 96.875 (94.208)
Test: [700/750]	Time 0.015 (0.020)	Loss 0.7980 (0.7974)	Acc@1 68.750 (71.826)	Acc@5 93.750 (94.370)
 * Acc@1 72.117 Acc@5 94.383
==> training...
Epoch: [64][0/875]	Time 1.715 (1.715)	Data 1.302 (1.302)	Loss 1.1367 (1.1367)	Loss@kd 2.2047 (2.2047)	Acc@1 65.625 (65.625)	Acc@5 93.750 (93.750)
Epoch: [64][100/875]	Time 0.400 (0.414)	Data 0.007 (0.020)	Loss 1.1745 (1.0942)	Loss@kd 2.1812 (2.2018)	Acc@1 71.875 (72.092)	Acc@5 96.875 (98.793)
Epoch: [64][200/875]	Time 0.397 (0.407)	Data 0.007 (0.013)	Loss 1.0978 (1.0919)	Loss@kd 2.3022 (2.2020)	Acc@1 68.750 (72.388)	Acc@5 96.875 (98.826)
Epoch: [64][300/875]	Time 0.405 (0.405)	Data 0.007 (0.011)	Loss 1.0916 (1.0944)	Loss@kd 2.1358 (2.2036)	Acc@1 76.562 (72.488)	Acc@5 100.000 (98.848)
Epoch: [64][400/875]	Time 0.399 (0.404)	Data 0.007 (0.010)	Loss 1.0307 (1.0951)	Loss@kd 2.1073 (2.2035)	Acc@1 76.562 (72.561)	Acc@5 96.875 (98.854)
Epoch: [64][500/875]	Time 0.402 (0.403)	Data 0.007 (0.009)	Loss 0.9846 (1.0966)	Loss@kd 2.1776 (2.2081)	Acc@1 79.688 (72.795)	Acc@5 100.000 (98.890)
Epoch: [64][600/875]	Time 0.400 (0.403)	Data 0.005 (0.009)	Loss 1.1623 (1.0960)	Loss@kd 2.3013 (2.2084)	Acc@1 76.562 (72.806)	Acc@5 100.000 (98.861)
Epoch: [64][700/875]	Time 0.399 (0.402)	Data 0.005 (0.009)	Loss 1.0647 (1.0972)	Loss@kd 2.0984 (2.2089)	Acc@1 78.125 (72.903)	Acc@5 96.875 (98.892)
Epoch: [64][800/875]	Time 0.399 (0.402)	Data 0.005 (0.008)	Loss 1.1506 (1.0980)	Loss@kd 2.2432 (2.2103)	Acc@1 54.688 (72.854)	Acc@5 98.438 (98.900)
 * Acc@1 72.764 Acc@5 98.923
epoch 64, total time 351.98
Test: [0/750]	Time 0.804 (0.804)	Loss 0.4309 (0.4309)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.025 (0.028)	Loss 0.4235 (0.5180)	Acc@1 84.375 (86.355)	Acc@5 96.875 (94.647)
Test: [200/750]	Time 0.017 (0.023)	Loss 1.2980 (0.5053)	Acc@1 40.625 (84.624)	Acc@5 96.875 (95.989)
Test: [300/750]	Time 0.019 (0.022)	Loss 1.0387 (0.7355)	Acc@1 71.875 (74.564)	Acc@5 90.625 (94.996)
Test: [400/750]	Time 0.026 (0.021)	Loss 0.6369 (0.8086)	Acc@1 84.375 (71.509)	Acc@5 87.500 (94.709)
Test: [500/750]	Time 0.018 (0.022)	Loss 0.6124 (0.7889)	Acc@1 78.125 (72.592)	Acc@5 100.000 (94.336)
Test: [600/750]	Time 0.022 (0.022)	Loss 0.8170 (0.8045)	Acc@1 71.875 (72.260)	Acc@5 96.875 (94.140)
Test: [700/750]	Time 0.029 (0.022)	Loss 0.7898 (0.8002)	Acc@1 65.625 (72.089)	Acc@5 96.875 (94.334)
 * Acc@1 72.433 Acc@5 94.362
saving the best model!
==> training...
Epoch: [65][0/875]	Time 1.757 (1.757)	Data 1.345 (1.345)	Loss 1.1131 (1.1131)	Loss@kd 2.1359 (2.1359)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [65][100/875]	Time 0.398 (0.414)	Data 0.007 (0.020)	Loss 1.2098 (1.0923)	Loss@kd 2.2074 (2.2030)	Acc@1 59.375 (73.484)	Acc@5 98.438 (98.979)
Epoch: [65][200/875]	Time 0.402 (0.407)	Data 0.007 (0.013)	Loss 1.0585 (1.0901)	Loss@kd 2.2211 (2.2017)	Acc@1 78.125 (73.368)	Acc@5 100.000 (99.052)
Epoch: [65][300/875]	Time 0.399 (0.405)	Data 0.007 (0.011)	Loss 1.0136 (1.0927)	Loss@kd 2.1466 (2.2064)	Acc@1 76.562 (72.877)	Acc@5 100.000 (99.050)
Epoch: [65][400/875]	Time 0.398 (0.404)	Data 0.006 (0.010)	Loss 0.9926 (1.0889)	Loss@kd 2.1680 (2.2026)	Acc@1 75.000 (73.056)	Acc@5 96.875 (99.030)
Epoch: [65][500/875]	Time 0.395 (0.403)	Data 0.007 (0.010)	Loss 1.1588 (1.0891)	Loss@kd 2.2618 (2.2024)	Acc@1 71.875 (73.004)	Acc@5 100.000 (99.039)
Epoch: [65][600/875]	Time 0.399 (0.403)	Data 0.006 (0.009)	Loss 1.0111 (1.0910)	Loss@kd 2.0416 (2.2036)	Acc@1 81.250 (72.910)	Acc@5 98.438 (99.007)
Epoch: [65][700/875]	Time 0.502 (0.402)	Data 0.007 (0.009)	Loss 1.0419 (1.0919)	Loss@kd 2.1288 (2.2048)	Acc@1 65.625 (72.945)	Acc@5 98.438 (99.004)
Epoch: [65][800/875]	Time 0.395 (0.402)	Data 0.007 (0.009)	Loss 0.9730 (1.0901)	Loss@kd 2.1580 (2.2029)	Acc@1 65.625 (72.848)	Acc@5 98.438 (99.007)
 * Acc@1 72.873 Acc@5 99.007
epoch 65, total time 352.12
Test: [0/750]	Time 0.798 (0.798)	Loss 0.4463 (0.4463)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.023 (0.029)	Loss 0.3952 (0.5409)	Acc@1 84.375 (86.046)	Acc@5 96.875 (94.431)
Test: [200/750]	Time 0.025 (0.025)	Loss 1.3187 (0.5011)	Acc@1 43.750 (85.137)	Acc@5 96.875 (95.911)
Test: [300/750]	Time 0.017 (0.023)	Loss 1.1195 (0.7410)	Acc@1 71.875 (74.522)	Acc@5 90.625 (94.736)
Test: [400/750]	Time 0.018 (0.023)	Loss 0.5992 (0.8183)	Acc@1 81.250 (71.446)	Acc@5 93.750 (94.436)
Test: [500/750]	Time 0.019 (0.023)	Loss 0.6156 (0.7964)	Acc@1 78.125 (72.561)	Acc@5 100.000 (94.143)
Test: [600/750]	Time 0.021 (0.022)	Loss 0.8069 (0.8136)	Acc@1 71.875 (72.093)	Acc@5 96.875 (93.974)
Test: [700/750]	Time 0.021 (0.022)	Loss 0.7083 (0.8060)	Acc@1 68.750 (72.004)	Acc@5 96.875 (94.240)
 * Acc@1 72.446 Acc@5 94.317
saving the best model!
==> training...
Epoch: [66][0/875]	Time 1.755 (1.755)	Data 1.347 (1.347)	Loss 1.0356 (1.0356)	Loss@kd 2.1631 (2.1631)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [66][100/875]	Time 0.399 (0.414)	Data 0.007 (0.020)	Loss 1.1171 (1.0889)	Loss@kd 2.2070 (2.2093)	Acc@1 73.438 (72.942)	Acc@5 100.000 (98.917)
Epoch: [66][200/875]	Time 0.396 (0.407)	Data 0.007 (0.013)	Loss 1.0784 (1.0916)	Loss@kd 2.2996 (2.2052)	Acc@1 78.125 (72.652)	Acc@5 100.000 (98.857)
Epoch: [66][300/875]	Time 0.400 (0.405)	Data 0.007 (0.011)	Loss 1.0301 (1.0895)	Loss@kd 2.1817 (2.2056)	Acc@1 70.312 (72.664)	Acc@5 98.438 (98.899)
Epoch: [66][400/875]	Time 0.397 (0.404)	Data 0.006 (0.010)	Loss 1.1213 (1.0921)	Loss@kd 2.2562 (2.2082)	Acc@1 76.562 (72.779)	Acc@5 100.000 (98.913)
Epoch: [66][500/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss 1.1997 (1.0921)	Loss@kd 2.2863 (2.2078)	Acc@1 68.750 (72.773)	Acc@5 100.000 (98.924)
Epoch: [66][600/875]	Time 0.493 (0.403)	Data 0.010 (0.009)	Loss 1.0157 (1.0919)	Loss@kd 2.1550 (2.2076)	Acc@1 75.000 (72.689)	Acc@5 100.000 (98.905)
Epoch: [66][700/875]	Time 0.398 (0.402)	Data 0.006 (0.009)	Loss 1.0525 (1.0916)	Loss@kd 2.1028 (2.2069)	Acc@1 71.875 (72.695)	Acc@5 96.875 (98.899)
Epoch: [66][800/875]	Time 0.404 (0.402)	Data 0.007 (0.008)	Loss 1.0241 (1.0904)	Loss@kd 2.1394 (2.2044)	Acc@1 82.812 (72.768)	Acc@5 98.438 (98.923)
 * Acc@1 72.846 Acc@5 98.920
epoch 66, total time 351.99
Test: [0/750]	Time 0.798 (0.798)	Loss 0.4750 (0.4750)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.015 (0.030)	Loss 0.4325 (0.5210)	Acc@1 78.125 (86.046)	Acc@5 100.000 (94.647)
Test: [200/750]	Time 0.022 (0.026)	Loss 1.3721 (0.5123)	Acc@1 50.000 (84.313)	Acc@5 96.875 (95.973)
Test: [300/750]	Time 0.018 (0.024)	Loss 1.1374 (0.7625)	Acc@1 71.875 (73.650)	Acc@5 90.625 (94.705)
Test: [400/750]	Time 0.025 (0.023)	Loss 0.5772 (0.8406)	Acc@1 81.250 (70.519)	Acc@5 90.625 (94.303)
Test: [500/750]	Time 0.021 (0.023)	Loss 0.5723 (0.8052)	Acc@1 84.375 (72.106)	Acc@5 96.875 (94.124)
Test: [600/750]	Time 0.015 (0.022)	Loss 0.7787 (0.8148)	Acc@1 71.875 (71.943)	Acc@5 93.750 (93.989)
Test: [700/750]	Time 0.026 (0.022)	Loss 0.7117 (0.8054)	Acc@1 68.750 (71.951)	Acc@5 93.750 (94.236)
 * Acc@1 72.396 Acc@5 94.258
==> training...
Epoch: [67][0/875]	Time 1.761 (1.761)	Data 1.344 (1.344)	Loss 1.0910 (1.0910)	Loss@kd 2.1705 (2.1705)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [67][100/875]	Time 0.418 (0.414)	Data 0.007 (0.020)	Loss 1.0981 (1.0808)	Loss@kd 2.2578 (2.1877)	Acc@1 78.125 (73.113)	Acc@5 98.438 (98.963)
Epoch: [67][200/875]	Time 0.398 (0.407)	Data 0.007 (0.013)	Loss 1.0176 (1.0831)	Loss@kd 2.1217 (2.1963)	Acc@1 78.125 (73.127)	Acc@5 98.438 (98.997)
Epoch: [67][300/875]	Time 0.401 (0.405)	Data 0.007 (0.011)	Loss 1.0964 (1.0898)	Loss@kd 2.2531 (2.2009)	Acc@1 71.875 (73.162)	Acc@5 100.000 (98.946)
Epoch: [67][400/875]	Time 0.400 (0.404)	Data 0.007 (0.010)	Loss 1.1347 (1.0904)	Loss@kd 2.1682 (2.1992)	Acc@1 65.625 (73.017)	Acc@5 100.000 (98.936)
Epoch: [67][500/875]	Time 0.397 (0.403)	Data 0.006 (0.009)	Loss 1.2289 (1.0897)	Loss@kd 2.2318 (2.1978)	Acc@1 78.125 (72.901)	Acc@5 96.875 (98.990)
Epoch: [67][600/875]	Time 0.399 (0.403)	Data 0.007 (0.009)	Loss 1.0864 (1.0877)	Loss@kd 2.1615 (2.1968)	Acc@1 70.312 (72.902)	Acc@5 98.438 (98.989)
Epoch: [67][700/875]	Time 0.400 (0.402)	Data 0.007 (0.009)	Loss 1.0822 (1.0897)	Loss@kd 2.1141 (2.1980)	Acc@1 70.312 (72.898)	Acc@5 93.750 (98.961)
Epoch: [67][800/875]	Time 0.399 (0.402)	Data 0.006 (0.008)	Loss 1.0502 (1.0900)	Loss@kd 2.1416 (2.1996)	Acc@1 73.438 (72.924)	Acc@5 95.312 (98.952)
 * Acc@1 72.875 Acc@5 98.936
epoch 67, total time 352.08
Test: [0/750]	Time 0.760 (0.760)	Loss 0.4784 (0.4784)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.021 (0.029)	Loss 0.4518 (0.5233)	Acc@1 81.250 (86.200)	Acc@5 100.000 (94.462)
Test: [200/750]	Time 0.017 (0.026)	Loss 1.3687 (0.5221)	Acc@1 46.875 (83.940)	Acc@5 96.875 (95.911)
Test: [300/750]	Time 0.017 (0.025)	Loss 1.1409 (0.7583)	Acc@1 68.750 (73.557)	Acc@5 90.625 (94.809)
Test: [400/750]	Time 0.015 (0.023)	Loss 0.5774 (0.8389)	Acc@1 84.375 (70.394)	Acc@5 90.625 (94.397)
Test: [500/750]	Time 0.019 (0.023)	Loss 0.6311 (0.8120)	Acc@1 78.125 (71.781)	Acc@5 100.000 (94.137)
Test: [600/750]	Time 0.023 (0.022)	Loss 0.7146 (0.8232)	Acc@1 71.875 (71.620)	Acc@5 93.750 (93.942)
Test: [700/750]	Time 0.015 (0.022)	Loss 0.6440 (0.8042)	Acc@1 71.875 (71.955)	Acc@5 96.875 (94.249)
 * Acc@1 72.512 Acc@5 94.354
saving the best model!
==> training...
Epoch: [68][0/875]	Time 1.784 (1.784)	Data 1.371 (1.371)	Loss 1.1505 (1.1505)	Loss@kd 2.2475 (2.2475)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [68][100/875]	Time 0.397 (0.415)	Data 0.007 (0.020)	Loss 1.0933 (1.0835)	Loss@kd 2.2382 (2.1983)	Acc@1 67.188 (71.968)	Acc@5 96.875 (98.917)
Epoch: [68][200/875]	Time 0.402 (0.408)	Data 0.007 (0.013)	Loss 1.0483 (1.0865)	Loss@kd 2.1439 (2.1985)	Acc@1 67.188 (72.512)	Acc@5 98.438 (98.966)
Epoch: [68][300/875]	Time 0.400 (0.405)	Data 0.005 (0.011)	Loss 1.0388 (1.0872)	Loss@kd 2.2133 (2.1968)	Acc@1 81.250 (72.664)	Acc@5 100.000 (98.998)
Epoch: [68][400/875]	Time 0.399 (0.404)	Data 0.007 (0.010)	Loss 1.1158 (1.0891)	Loss@kd 2.2925 (2.1989)	Acc@1 84.375 (72.541)	Acc@5 100.000 (98.971)
Epoch: [68][500/875]	Time 0.401 (0.403)	Data 0.007 (0.010)	Loss 1.2059 (1.0885)	Loss@kd 2.1979 (2.1994)	Acc@1 73.438 (72.761)	Acc@5 100.000 (98.971)
Epoch: [68][600/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss 1.0492 (1.0898)	Loss@kd 2.2229 (2.2008)	Acc@1 70.312 (72.699)	Acc@5 100.000 (98.989)
Epoch: [68][700/875]	Time 0.404 (0.402)	Data 0.006 (0.009)	Loss 1.0287 (1.0900)	Loss@kd 2.2554 (2.2014)	Acc@1 82.812 (72.722)	Acc@5 100.000 (98.988)
Epoch: [68][800/875]	Time 0.400 (0.402)	Data 0.007 (0.008)	Loss 1.0256 (1.0883)	Loss@kd 2.1672 (2.2001)	Acc@1 78.125 (72.755)	Acc@5 100.000 (98.984)
 * Acc@1 72.779 Acc@5 98.959
epoch 68, total time 352.03
Test: [0/750]	Time 0.747 (0.747)	Loss 0.4545 (0.4545)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.022 (0.028)	Loss 0.4394 (0.5300)	Acc@1 81.250 (86.077)	Acc@5 96.875 (94.585)
Test: [200/750]	Time 0.018 (0.025)	Loss 1.4157 (0.5168)	Acc@1 37.500 (84.220)	Acc@5 93.750 (95.709)
Test: [300/750]	Time 0.016 (0.024)	Loss 0.9696 (0.7654)	Acc@1 75.000 (73.287)	Acc@5 90.625 (94.487)
Test: [400/750]	Time 0.016 (0.023)	Loss 0.6046 (0.8134)	Acc@1 81.250 (71.080)	Acc@5 93.750 (94.631)
Test: [500/750]	Time 0.023 (0.023)	Loss 0.6096 (0.7897)	Acc@1 81.250 (72.380)	Acc@5 100.000 (94.349)
Test: [600/750]	Time 0.015 (0.022)	Loss 0.7994 (0.8053)	Acc@1 71.875 (72.067)	Acc@5 96.875 (94.130)
Test: [700/750]	Time 0.025 (0.022)	Loss 0.7809 (0.8000)	Acc@1 65.625 (72.000)	Acc@5 93.750 (94.307)
 * Acc@1 72.362 Acc@5 94.350
==> training...
Epoch: [69][0/875]	Time 1.715 (1.715)	Data 1.306 (1.306)	Loss 1.2691 (1.2691)	Loss@kd 2.5472 (2.5472)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [69][100/875]	Time 0.398 (0.413)	Data 0.007 (0.020)	Loss 1.0486 (1.0905)	Loss@kd 2.1937 (2.2022)	Acc@1 76.562 (72.169)	Acc@5 100.000 (99.010)
Epoch: [69][200/875]	Time 0.401 (0.407)	Data 0.011 (0.013)	Loss 1.1182 (1.0847)	Loss@kd 2.2112 (2.1963)	Acc@1 71.875 (72.256)	Acc@5 100.000 (98.896)
Epoch: [69][300/875]	Time 0.400 (0.405)	Data 0.007 (0.011)	Loss 1.0910 (1.0842)	Loss@kd 2.1060 (2.1971)	Acc@1 68.750 (72.633)	Acc@5 100.000 (98.925)
Epoch: [69][400/875]	Time 0.413 (0.404)	Data 0.008 (0.010)	Loss 1.2829 (1.0848)	Loss@kd 2.2953 (2.2007)	Acc@1 68.750 (72.495)	Acc@5 98.438 (98.975)
Epoch: [69][500/875]	Time 0.392 (0.403)	Data 0.005 (0.009)	Loss 0.9642 (1.0826)	Loss@kd 2.0523 (2.1990)	Acc@1 75.000 (72.726)	Acc@5 96.875 (98.943)
Epoch: [69][600/875]	Time 0.402 (0.403)	Data 0.007 (0.009)	Loss 1.0629 (1.0836)	Loss@kd 2.3091 (2.1991)	Acc@1 78.125 (72.762)	Acc@5 98.438 (98.970)
Epoch: [69][700/875]	Time 0.393 (0.403)	Data 0.006 (0.009)	Loss 1.0965 (1.0836)	Loss@kd 2.2066 (2.1984)	Acc@1 75.000 (72.871)	Acc@5 100.000 (98.979)
Epoch: [69][800/875]	Time 0.400 (0.402)	Data 0.011 (0.008)	Loss 1.0690 (1.0849)	Loss@kd 2.1247 (2.1994)	Acc@1 71.875 (72.788)	Acc@5 100.000 (99.009)
 * Acc@1 72.775 Acc@5 99.002
epoch 69, total time 352.30
Test: [0/750]	Time 0.798 (0.798)	Loss 0.4400 (0.4400)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.021 (0.030)	Loss 0.4418 (0.5263)	Acc@1 78.125 (86.046)	Acc@5 96.875 (94.709)
Test: [200/750]	Time 0.019 (0.025)	Loss 1.2931 (0.5096)	Acc@1 46.875 (84.422)	Acc@5 93.750 (95.927)
Test: [300/750]	Time 0.016 (0.023)	Loss 1.0663 (0.7404)	Acc@1 75.000 (74.387)	Acc@5 90.625 (94.913)
Test: [400/750]	Time 0.017 (0.023)	Loss 0.5870 (0.8116)	Acc@1 84.375 (71.376)	Acc@5 87.500 (94.670)
Test: [500/750]	Time 0.020 (0.023)	Loss 0.6257 (0.7876)	Acc@1 84.375 (72.661)	Acc@5 96.875 (94.386)
Test: [600/750]	Time 0.019 (0.023)	Loss 0.7775 (0.8040)	Acc@1 75.000 (72.229)	Acc@5 93.750 (94.171)
Test: [700/750]	Time 0.015 (0.022)	Loss 0.7868 (0.8010)	Acc@1 68.750 (72.044)	Acc@5 93.750 (94.361)
 * Acc@1 72.333 Acc@5 94.375
==> training...
Epoch: [70][0/875]	Time 1.769 (1.769)	Data 1.358 (1.358)	Loss 1.1146 (1.1146)	Loss@kd 2.3164 (2.3164)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [70][100/875]	Time 0.396 (0.415)	Data 0.007 (0.020)	Loss 1.0845 (1.0862)	Loss@kd 2.1536 (2.2058)	Acc@1 73.438 (72.772)	Acc@5 100.000 (99.118)
Epoch: [70][200/875]	Time 0.395 (0.408)	Data 0.007 (0.013)	Loss 1.1159 (1.0890)	Loss@kd 2.1796 (2.2069)	Acc@1 68.750 (72.862)	Acc@5 100.000 (99.137)
Epoch: [70][300/875]	Time 0.398 (0.405)	Data 0.005 (0.011)	Loss 1.0690 (1.0834)	Loss@kd 2.2105 (2.1999)	Acc@1 68.750 (72.903)	Acc@5 96.875 (99.102)
Epoch: [70][400/875]	Time 0.402 (0.404)	Data 0.007 (0.010)	Loss 1.0122 (1.0829)	Loss@kd 2.0924 (2.1992)	Acc@1 71.875 (73.180)	Acc@5 100.000 (99.108)
Epoch: [70][500/875]	Time 0.404 (0.403)	Data 0.007 (0.009)	Loss 1.1364 (1.0823)	Loss@kd 2.2138 (2.1970)	Acc@1 76.562 (73.157)	Acc@5 100.000 (99.133)
Epoch: [70][600/875]	Time 0.396 (0.403)	Data 0.009 (0.009)	Loss 1.1582 (1.0820)	Loss@kd 2.2775 (2.1981)	Acc@1 70.312 (73.019)	Acc@5 100.000 (99.134)
Epoch: [70][700/875]	Time 0.394 (0.402)	Data 0.007 (0.009)	Loss 1.0784 (1.0812)	Loss@kd 2.1532 (2.1961)	Acc@1 73.438 (72.967)	Acc@5 100.000 (99.097)
Epoch: [70][800/875]	Time 0.398 (0.402)	Data 0.005 (0.008)	Loss 1.0185 (1.0820)	Loss@kd 2.1379 (2.1983)	Acc@1 75.000 (73.002)	Acc@5 100.000 (99.077)
 * Acc@1 72.963 Acc@5 99.055
epoch 70, total time 352.12
Test: [0/750]	Time 0.796 (0.796)	Loss 0.4343 (0.4343)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.018 (0.029)	Loss 0.4307 (0.5328)	Acc@1 81.250 (86.046)	Acc@5 96.875 (94.678)
Test: [200/750]	Time 0.026 (0.025)	Loss 1.3125 (0.5171)	Acc@1 40.625 (84.359)	Acc@5 93.750 (95.818)
Test: [300/750]	Time 0.017 (0.023)	Loss 1.0663 (0.7609)	Acc@1 71.875 (73.484)	Acc@5 90.625 (94.664)
Test: [400/750]	Time 0.026 (0.023)	Loss 0.5760 (0.8171)	Acc@1 84.375 (71.119)	Acc@5 93.750 (94.638)
Test: [500/750]	Time 0.026 (0.023)	Loss 0.5939 (0.7905)	Acc@1 84.375 (72.555)	Acc@5 100.000 (94.343)
Test: [600/750]	Time 0.014 (0.022)	Loss 0.7497 (0.8053)	Acc@1 71.875 (72.208)	Acc@5 96.875 (94.145)
Test: [700/750]	Time 0.019 (0.021)	Loss 0.7809 (0.8007)	Acc@1 65.625 (72.053)	Acc@5 93.750 (94.325)
 * Acc@1 72.400 Acc@5 94.379
==> training...
Epoch: [71][0/875]	Time 1.609 (1.609)	Data 1.210 (1.210)	Loss 1.0930 (1.0930)	Loss@kd 2.2434 (2.2434)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [71][100/875]	Time 0.399 (0.412)	Data 0.008 (0.019)	Loss 1.0063 (1.0798)	Loss@kd 2.1334 (2.2031)	Acc@1 68.750 (73.082)	Acc@5 98.438 (98.948)
Epoch: [71][200/875]	Time 0.396 (0.406)	Data 0.007 (0.013)	Loss 1.0136 (1.0849)	Loss@kd 2.1211 (2.2028)	Acc@1 75.000 (72.287)	Acc@5 96.875 (99.013)
Epoch: [71][300/875]	Time 0.400 (0.404)	Data 0.007 (0.011)	Loss 1.0013 (1.0847)	Loss@kd 2.0875 (2.2023)	Acc@1 70.312 (72.555)	Acc@5 100.000 (99.014)
Epoch: [71][400/875]	Time 0.398 (0.403)	Data 0.007 (0.010)	Loss 0.9176 (1.0862)	Loss@kd 2.0512 (2.2023)	Acc@1 79.688 (72.456)	Acc@5 100.000 (98.999)
Epoch: [71][500/875]	Time 0.399 (0.403)	Data 0.007 (0.009)	Loss 1.2195 (1.0846)	Loss@kd 2.3139 (2.1990)	Acc@1 67.188 (72.468)	Acc@5 100.000 (98.990)
Epoch: [71][600/875]	Time 0.403 (0.402)	Data 0.006 (0.009)	Loss 1.0246 (1.0830)	Loss@kd 2.1234 (2.1992)	Acc@1 78.125 (72.606)	Acc@5 100.000 (98.991)
Epoch: [71][700/875]	Time 0.398 (0.402)	Data 0.006 (0.008)	Loss 1.0449 (1.0829)	Loss@kd 2.2503 (2.2002)	Acc@1 73.438 (72.831)	Acc@5 100.000 (99.001)
Epoch: [71][800/875]	Time 0.403 (0.402)	Data 0.006 (0.008)	Loss 0.9920 (1.0812)	Loss@kd 2.1181 (2.1990)	Acc@1 70.312 (72.973)	Acc@5 100.000 (98.999)
 * Acc@1 72.932 Acc@5 98.980
epoch 71, total time 351.70
Test: [0/750]	Time 0.785 (0.785)	Loss 0.4476 (0.4476)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.021 (0.030)	Loss 0.4290 (0.5323)	Acc@1 84.375 (86.200)	Acc@5 96.875 (94.585)
Test: [200/750]	Time 0.026 (0.026)	Loss 1.3107 (0.5151)	Acc@1 43.750 (84.515)	Acc@5 93.750 (95.958)
Test: [300/750]	Time 0.015 (0.025)	Loss 1.0498 (0.7373)	Acc@1 71.875 (74.450)	Acc@5 90.625 (95.017)
Test: [400/750]	Time 0.028 (0.024)	Loss 0.6156 (0.7985)	Acc@1 81.250 (71.781)	Acc@5 87.500 (94.810)
Test: [500/750]	Time 0.019 (0.023)	Loss 0.6203 (0.7823)	Acc@1 84.375 (72.779)	Acc@5 100.000 (94.436)
Test: [600/750]	Time 0.018 (0.023)	Loss 0.7998 (0.8021)	Acc@1 71.875 (72.197)	Acc@5 96.875 (94.197)
Test: [700/750]	Time 0.025 (0.022)	Loss 0.7678 (0.7969)	Acc@1 65.625 (72.102)	Acc@5 93.750 (94.365)
 * Acc@1 72.463 Acc@5 94.387
==> training...
Epoch: [72][0/875]	Time 1.732 (1.732)	Data 1.316 (1.316)	Loss 1.0475 (1.0475)	Loss@kd 2.2563 (2.2563)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [72][100/875]	Time 0.399 (0.414)	Data 0.006 (0.020)	Loss 1.1283 (1.0761)	Loss@kd 2.2922 (2.1921)	Acc@1 81.250 (73.267)	Acc@5 98.438 (99.041)
Epoch: [72][200/875]	Time 0.400 (0.407)	Data 0.006 (0.013)	Loss 1.3058 (1.0784)	Loss@kd 2.3837 (2.1945)	Acc@1 71.875 (72.932)	Acc@5 100.000 (99.036)
Epoch: [72][300/875]	Time 0.400 (0.405)	Data 0.006 (0.011)	Loss 1.0549 (1.0795)	Loss@kd 2.1339 (2.1948)	Acc@1 67.188 (72.898)	Acc@5 100.000 (98.962)
Epoch: [72][400/875]	Time 0.402 (0.404)	Data 0.007 (0.010)	Loss 0.9961 (1.0778)	Loss@kd 2.2810 (2.1974)	Acc@1 75.000 (73.075)	Acc@5 98.438 (98.928)
Epoch: [72][500/875]	Time 0.399 (0.403)	Data 0.006 (0.009)	Loss 1.0452 (1.0767)	Loss@kd 2.1186 (2.1965)	Acc@1 65.625 (73.048)	Acc@5 96.875 (98.927)
Epoch: [72][600/875]	Time 0.400 (0.402)	Data 0.006 (0.009)	Loss 1.0829 (1.0771)	Loss@kd 2.1592 (2.1957)	Acc@1 67.188 (72.996)	Acc@5 98.438 (98.950)
Epoch: [72][700/875]	Time 0.398 (0.402)	Data 0.007 (0.009)	Loss 1.0977 (1.0775)	Loss@kd 2.2527 (2.1973)	Acc@1 81.250 (73.074)	Acc@5 100.000 (98.988)
Epoch: [72][800/875]	Time 0.404 (0.402)	Data 0.007 (0.008)	Loss 1.0999 (1.0764)	Loss@kd 2.2118 (2.1959)	Acc@1 79.688 (73.149)	Acc@5 100.000 (98.984)
 * Acc@1 73.150 Acc@5 98.996
epoch 72, total time 351.92
Test: [0/750]	Time 0.762 (0.762)	Loss 0.4360 (0.4360)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.021 (0.032)	Loss 0.4190 (0.5152)	Acc@1 81.250 (86.262)	Acc@5 96.875 (94.616)
Test: [200/750]	Time 0.022 (0.027)	Loss 1.3368 (0.4987)	Acc@1 43.750 (85.075)	Acc@5 96.875 (95.927)
Test: [300/750]	Time 0.016 (0.025)	Loss 1.1427 (0.7459)	Acc@1 65.625 (74.284)	Acc@5 90.625 (94.684)
Test: [400/750]	Time 0.019 (0.023)	Loss 0.5851 (0.8271)	Acc@1 84.375 (71.041)	Acc@5 90.625 (94.350)
Test: [500/750]	Time 0.015 (0.022)	Loss 0.5867 (0.7958)	Acc@1 84.375 (72.486)	Acc@5 100.000 (94.168)
Test: [600/750]	Time 0.019 (0.021)	Loss 0.7725 (0.8061)	Acc@1 71.875 (72.239)	Acc@5 93.750 (94.114)
Test: [700/750]	Time 0.016 (0.020)	Loss 0.7222 (0.7982)	Acc@1 68.750 (72.160)	Acc@5 96.875 (94.334)
 * Acc@1 72.596 Acc@5 94.404
saving the best model!
==> training...
Epoch: [73][0/875]	Time 1.691 (1.691)	Data 1.277 (1.277)	Loss 1.2059 (1.2059)	Loss@kd 2.3298 (2.3298)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [73][100/875]	Time 0.400 (0.414)	Data 0.006 (0.019)	Loss 1.0464 (1.0739)	Loss@kd 2.3034 (2.1989)	Acc@1 79.688 (73.267)	Acc@5 100.000 (98.933)
Epoch: [73][200/875]	Time 0.398 (0.407)	Data 0.006 (0.013)	Loss 0.9754 (1.0755)	Loss@kd 2.0300 (2.1936)	Acc@1 71.875 (73.088)	Acc@5 100.000 (98.997)
Epoch: [73][300/875]	Time 0.400 (0.405)	Data 0.007 (0.011)	Loss 0.9671 (1.0801)	Loss@kd 2.1049 (2.1944)	Acc@1 79.688 (73.064)	Acc@5 98.438 (99.040)
Epoch: [73][400/875]	Time 0.402 (0.404)	Data 0.006 (0.010)	Loss 1.0720 (1.0791)	Loss@kd 2.2094 (2.1958)	Acc@1 71.875 (73.235)	Acc@5 100.000 (99.073)
Epoch: [73][500/875]	Time 0.404 (0.403)	Data 0.007 (0.009)	Loss 1.0782 (1.0802)	Loss@kd 2.2350 (2.1989)	Acc@1 75.000 (73.113)	Acc@5 100.000 (99.055)
Epoch: [73][600/875]	Time 0.400 (0.402)	Data 0.008 (0.009)	Loss 1.0943 (1.0796)	Loss@kd 2.1911 (2.1972)	Acc@1 62.500 (72.821)	Acc@5 98.438 (99.035)
Epoch: [73][700/875]	Time 0.397 (0.402)	Data 0.007 (0.008)	Loss 1.0351 (1.0801)	Loss@kd 2.2134 (2.1956)	Acc@1 84.375 (72.854)	Acc@5 98.438 (99.033)
Epoch: [73][800/875]	Time 0.394 (0.402)	Data 0.007 (0.008)	Loss 1.1547 (1.0798)	Loss@kd 2.2179 (2.1954)	Acc@1 68.750 (72.909)	Acc@5 96.875 (99.019)
 * Acc@1 72.998 Acc@5 99.016
epoch 73, total time 351.85
Test: [0/750]	Time 0.801 (0.801)	Loss 0.4218 (0.4218)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.018 (0.030)	Loss 0.4583 (0.5083)	Acc@1 78.125 (86.355)	Acc@5 96.875 (94.833)
Test: [200/750]	Time 0.017 (0.025)	Loss 1.3591 (0.5128)	Acc@1 43.750 (84.080)	Acc@5 96.875 (95.927)
Test: [300/750]	Time 0.016 (0.023)	Loss 1.1017 (0.7568)	Acc@1 71.875 (73.713)	Acc@5 90.625 (94.716)
Test: [400/750]	Time 0.023 (0.022)	Loss 0.5967 (0.8245)	Acc@1 84.375 (70.971)	Acc@5 90.625 (94.529)
Test: [500/750]	Time 0.014 (0.021)	Loss 0.6670 (0.8025)	Acc@1 75.000 (72.231)	Acc@5 96.875 (94.212)
Test: [600/750]	Time 0.027 (0.020)	Loss 0.7100 (0.8158)	Acc@1 75.000 (71.943)	Acc@5 96.875 (94.015)
Test: [700/750]	Time 0.017 (0.020)	Loss 0.7608 (0.8033)	Acc@1 65.625 (72.080)	Acc@5 93.750 (94.240)
 * Acc@1 72.425 Acc@5 94.287
==> training...
Epoch: [74][0/875]	Time 1.752 (1.752)	Data 1.340 (1.340)	Loss 1.0544 (1.0544)	Loss@kd 2.3036 (2.3036)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [74][100/875]	Time 0.404 (0.414)	Data 0.005 (0.020)	Loss 1.0611 (1.0936)	Loss@kd 2.2162 (2.2149)	Acc@1 71.875 (71.318)	Acc@5 98.438 (98.886)
Epoch: [74][200/875]	Time 0.394 (0.407)	Data 0.006 (0.013)	Loss 1.0728 (1.0827)	Loss@kd 2.1330 (2.2045)	Acc@1 76.562 (72.186)	Acc@5 100.000 (98.943)
Epoch: [74][300/875]	Time 0.396 (0.405)	Data 0.008 (0.011)	Loss 1.1871 (1.0841)	Loss@kd 2.3248 (2.2047)	Acc@1 75.000 (72.353)	Acc@5 98.438 (98.967)
Epoch: [74][400/875]	Time 0.402 (0.404)	Data 0.007 (0.010)	Loss 1.1206 (1.0821)	Loss@kd 2.2023 (2.2011)	Acc@1 76.562 (72.752)	Acc@5 98.438 (98.967)
Epoch: [74][500/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss 1.1090 (1.0807)	Loss@kd 2.1903 (2.1983)	Acc@1 70.312 (72.948)	Acc@5 98.438 (98.974)
Epoch: [74][600/875]	Time 0.396 (0.403)	Data 0.007 (0.009)	Loss 0.9835 (1.0801)	Loss@kd 2.1621 (2.1983)	Acc@1 87.500 (72.920)	Acc@5 100.000 (99.015)
Epoch: [74][700/875]	Time 0.399 (0.402)	Data 0.007 (0.009)	Loss 1.0248 (1.0786)	Loss@kd 2.1779 (2.1977)	Acc@1 71.875 (72.983)	Acc@5 100.000 (99.046)
Epoch: [74][800/875]	Time 0.401 (0.402)	Data 0.007 (0.008)	Loss 1.1035 (1.0781)	Loss@kd 2.3018 (2.1968)	Acc@1 78.125 (72.995)	Acc@5 100.000 (99.038)
 * Acc@1 72.980 Acc@5 99.061
epoch 74, total time 352.03
Test: [0/750]	Time 0.762 (0.762)	Loss 0.4416 (0.4416)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.026 (0.030)	Loss 0.4158 (0.4974)	Acc@1 84.375 (86.634)	Acc@5 96.875 (94.802)
Test: [200/750]	Time 0.017 (0.026)	Loss 1.3920 (0.4952)	Acc@1 43.750 (84.779)	Acc@5 96.875 (95.973)
Test: [300/750]	Time 0.015 (0.024)	Loss 1.0622 (0.7523)	Acc@1 71.875 (73.858)	Acc@5 90.625 (94.487)
Test: [400/750]	Time 0.015 (0.023)	Loss 0.6380 (0.8251)	Acc@1 81.250 (70.800)	Acc@5 87.500 (94.288)
Test: [500/750]	Time 0.014 (0.022)	Loss 0.6031 (0.7983)	Acc@1 84.375 (72.156)	Acc@5 100.000 (94.099)
Test: [600/750]	Time 0.017 (0.021)	Loss 0.8029 (0.8079)	Acc@1 68.750 (72.005)	Acc@5 93.750 (94.000)
Test: [700/750]	Time 0.025 (0.021)	Loss 0.7137 (0.7984)	Acc@1 71.875 (72.004)	Acc@5 96.875 (94.263)
 * Acc@1 72.479 Acc@5 94.342
==> training...
Epoch: [75][0/875]	Time 1.785 (1.785)	Data 1.379 (1.379)	Loss 1.0623 (1.0623)	Loss@kd 2.2068 (2.2068)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [75][100/875]	Time 0.397 (0.415)	Data 0.007 (0.020)	Loss 1.0336 (1.0837)	Loss@kd 2.2261 (2.2019)	Acc@1 76.562 (73.298)	Acc@5 100.000 (98.979)
Epoch: [75][200/875]	Time 0.399 (0.408)	Data 0.005 (0.013)	Loss 1.1531 (1.0853)	Loss@kd 2.2023 (2.2052)	Acc@1 75.000 (72.730)	Acc@5 95.312 (98.989)
Epoch: [75][300/875]	Time 0.404 (0.405)	Data 0.007 (0.011)	Loss 1.0131 (1.0796)	Loss@kd 2.1685 (2.1967)	Acc@1 81.250 (72.877)	Acc@5 100.000 (98.931)
Epoch: [75][400/875]	Time 0.401 (0.404)	Data 0.007 (0.010)	Loss 1.0954 (1.0773)	Loss@kd 2.2331 (2.1946)	Acc@1 68.750 (72.989)	Acc@5 100.000 (98.928)
Epoch: [75][500/875]	Time 0.405 (0.403)	Data 0.007 (0.009)	Loss 1.0540 (1.0773)	Loss@kd 2.2276 (2.1942)	Acc@1 82.812 (73.104)	Acc@5 100.000 (98.952)
Epoch: [75][600/875]	Time 0.399 (0.403)	Data 0.005 (0.009)	Loss 1.0117 (1.0792)	Loss@kd 2.1988 (2.1976)	Acc@1 78.125 (72.959)	Acc@5 96.875 (98.944)
Epoch: [75][700/875]	Time 0.395 (0.402)	Data 0.007 (0.009)	Loss 1.0875 (1.0796)	Loss@kd 2.2416 (2.1972)	Acc@1 70.312 (72.972)	Acc@5 100.000 (98.957)
Epoch: [75][800/875]	Time 0.405 (0.402)	Data 0.007 (0.008)	Loss 1.0690 (1.0792)	Loss@kd 2.2239 (2.1976)	Acc@1 76.562 (72.983)	Acc@5 100.000 (98.976)
 * Acc@1 73.012 Acc@5 98.995
epoch 75, total time 352.01
Test: [0/750]	Time 0.818 (0.818)	Loss 0.4498 (0.4498)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.018 (0.030)	Loss 0.4420 (0.5180)	Acc@1 78.125 (86.046)	Acc@5 96.875 (94.524)
Test: [200/750]	Time 0.018 (0.025)	Loss 1.3573 (0.5106)	Acc@1 46.875 (84.220)	Acc@5 93.750 (95.896)
Test: [300/750]	Time 0.021 (0.023)	Loss 1.0823 (0.7459)	Acc@1 71.875 (73.972)	Acc@5 90.625 (94.788)
Test: [400/750]	Time 0.022 (0.022)	Loss 0.6385 (0.8247)	Acc@1 81.250 (70.737)	Acc@5 87.500 (94.444)
Test: [500/750]	Time 0.016 (0.021)	Loss 0.6776 (0.8018)	Acc@1 81.250 (71.969)	Acc@5 96.875 (94.149)
Test: [600/750]	Time 0.019 (0.021)	Loss 0.7798 (0.8161)	Acc@1 68.750 (71.714)	Acc@5 93.750 (93.963)
Test: [700/750]	Time 0.016 (0.020)	Loss 0.7175 (0.8024)	Acc@1 68.750 (71.866)	Acc@5 96.875 (94.263)
 * Acc@1 72.338 Acc@5 94.346
==> training...
Epoch: [76][0/875]	Time 1.733 (1.733)	Data 1.324 (1.324)	Loss 1.0199 (1.0199)	Loss@kd 2.2198 (2.2198)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [76][100/875]	Time 0.398 (0.414)	Data 0.008 (0.020)	Loss 1.0213 (1.0868)	Loss@kd 2.1310 (2.2063)	Acc@1 71.875 (72.602)	Acc@5 98.438 (99.180)
Epoch: [76][200/875]	Time 0.402 (0.407)	Data 0.006 (0.013)	Loss 1.0777 (1.0858)	Loss@kd 2.2738 (2.2070)	Acc@1 70.312 (72.870)	Acc@5 98.438 (99.044)
Epoch: [76][300/875]	Time 0.402 (0.405)	Data 0.010 (0.011)	Loss 1.1331 (1.0832)	Loss@kd 2.1869 (2.2027)	Acc@1 65.625 (73.214)	Acc@5 100.000 (99.050)
Epoch: [76][400/875]	Time 0.401 (0.404)	Data 0.007 (0.010)	Loss 1.0682 (1.0830)	Loss@kd 2.1848 (2.2002)	Acc@1 70.312 (73.005)	Acc@5 100.000 (99.045)
Epoch: [76][500/875]	Time 0.399 (0.403)	Data 0.006 (0.009)	Loss 1.0034 (1.0807)	Loss@kd 2.1443 (2.1986)	Acc@1 73.438 (72.876)	Acc@5 100.000 (99.061)
Epoch: [76][600/875]	Time 0.402 (0.403)	Data 0.007 (0.009)	Loss 1.0355 (1.0801)	Loss@kd 2.1413 (2.1977)	Acc@1 67.188 (73.045)	Acc@5 98.438 (99.041)
Epoch: [76][700/875]	Time 0.397 (0.402)	Data 0.007 (0.009)	Loss 1.0800 (1.0782)	Loss@kd 2.2339 (2.1958)	Acc@1 73.438 (73.023)	Acc@5 95.312 (99.033)
Epoch: [76][800/875]	Time 0.402 (0.402)	Data 0.008 (0.008)	Loss 1.1678 (1.0782)	Loss@kd 2.1847 (2.1947)	Acc@1 68.750 (73.012)	Acc@5 98.438 (99.019)
 * Acc@1 73.048 Acc@5 99.011
epoch 76, total time 351.95
Test: [0/750]	Time 0.750 (0.750)	Loss 0.4366 (0.4366)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.021 (0.026)	Loss 0.4242 (0.5046)	Acc@1 81.250 (86.448)	Acc@5 96.875 (94.740)
Test: [200/750]	Time 0.020 (0.022)	Loss 1.3284 (0.5009)	Acc@1 43.750 (84.453)	Acc@5 96.875 (95.973)
Test: [300/750]	Time 0.023 (0.021)	Loss 1.0698 (0.7383)	Acc@1 75.000 (74.201)	Acc@5 90.625 (94.850)
Test: [400/750]	Time 0.020 (0.020)	Loss 0.5761 (0.8041)	Acc@1 84.375 (71.392)	Acc@5 90.625 (94.701)
Test: [500/750]	Time 0.023 (0.020)	Loss 0.6442 (0.7810)	Acc@1 81.250 (72.686)	Acc@5 100.000 (94.455)
Test: [600/750]	Time 0.016 (0.020)	Loss 0.7986 (0.8020)	Acc@1 68.750 (72.213)	Acc@5 93.750 (94.171)
Test: [700/750]	Time 0.017 (0.019)	Loss 0.7653 (0.7962)	Acc@1 71.875 (72.142)	Acc@5 93.750 (94.356)
 * Acc@1 72.537 Acc@5 94.421
==> training...
Epoch: [77][0/875]	Time 1.628 (1.628)	Data 1.221 (1.221)	Loss 1.1713 (1.1713)	Loss@kd 2.2529 (2.2529)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [77][100/875]	Time 0.404 (0.413)	Data 0.008 (0.019)	Loss 1.0090 (1.0754)	Loss@kd 2.1633 (2.1970)	Acc@1 78.125 (73.407)	Acc@5 98.438 (98.994)
Epoch: [77][200/875]	Time 0.401 (0.407)	Data 0.006 (0.013)	Loss 1.1119 (1.0811)	Loss@kd 2.1810 (2.1998)	Acc@1 70.312 (72.839)	Acc@5 95.312 (98.951)
Epoch: [77][300/875]	Time 0.397 (0.405)	Data 0.007 (0.011)	Loss 1.0240 (1.0801)	Loss@kd 2.1312 (2.1996)	Acc@1 70.312 (72.944)	Acc@5 96.875 (98.983)
Epoch: [77][400/875]	Time 0.402 (0.404)	Data 0.006 (0.010)	Loss 1.1392 (1.0801)	Loss@kd 2.3682 (2.2007)	Acc@1 75.000 (72.849)	Acc@5 98.438 (99.018)
Epoch: [77][500/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss 1.0916 (1.0784)	Loss@kd 2.2437 (2.1995)	Acc@1 76.562 (73.020)	Acc@5 98.438 (99.005)
Epoch: [77][600/875]	Time 0.398 (0.403)	Data 0.006 (0.009)	Loss 0.9521 (1.0783)	Loss@kd 2.0754 (2.2000)	Acc@1 82.812 (73.102)	Acc@5 100.000 (98.986)
Epoch: [77][700/875]	Time 0.401 (0.402)	Data 0.005 (0.008)	Loss 1.1621 (1.0775)	Loss@kd 2.4244 (2.1985)	Acc@1 75.000 (72.985)	Acc@5 100.000 (98.979)
Epoch: [77][800/875]	Time 0.400 (0.402)	Data 0.006 (0.008)	Loss 0.9912 (1.0782)	Loss@kd 2.1056 (2.1984)	Acc@1 75.000 (72.942)	Acc@5 98.438 (98.968)
 * Acc@1 72.998 Acc@5 98.977
epoch 77, total time 351.86
Test: [0/750]	Time 0.879 (0.879)	Loss 0.4295 (0.4295)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.014 (0.031)	Loss 0.4100 (0.5114)	Acc@1 78.125 (86.231)	Acc@5 96.875 (94.771)
Test: [200/750]	Time 0.017 (0.025)	Loss 1.3643 (0.4967)	Acc@1 43.750 (84.857)	Acc@5 93.750 (95.989)
Test: [300/750]	Time 0.020 (0.023)	Loss 1.0692 (0.7459)	Acc@1 71.875 (74.242)	Acc@5 90.625 (94.632)
Test: [400/750]	Time 0.021 (0.023)	Loss 0.6093 (0.8128)	Acc@1 81.250 (71.431)	Acc@5 87.500 (94.553)
Test: [500/750]	Time 0.019 (0.023)	Loss 0.6752 (0.7949)	Acc@1 78.125 (72.524)	Acc@5 96.875 (94.149)
Test: [600/750]	Time 0.020 (0.022)	Loss 0.7363 (0.8144)	Acc@1 71.875 (72.036)	Acc@5 93.750 (93.942)
Test: [700/750]	Time 0.018 (0.022)	Loss 0.7389 (0.8047)	Acc@1 65.625 (72.062)	Acc@5 96.875 (94.200)
 * Acc@1 72.450 Acc@5 94.271
==> training...
Epoch: [78][0/875]	Time 1.739 (1.739)	Data 1.324 (1.324)	Loss 1.2240 (1.2240)	Loss@kd 2.3774 (2.3774)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [78][100/875]	Time 0.397 (0.414)	Data 0.007 (0.020)	Loss 1.0081 (1.0708)	Loss@kd 2.0746 (2.1926)	Acc@1 78.125 (73.592)	Acc@5 100.000 (99.056)
Epoch: [78][200/875]	Time 0.404 (0.407)	Data 0.004 (0.013)	Loss 1.1192 (1.0746)	Loss@kd 2.2164 (2.1882)	Acc@1 78.125 (72.878)	Acc@5 98.438 (99.013)
Epoch: [78][300/875]	Time 0.398 (0.405)	Data 0.006 (0.011)	Loss 1.0526 (1.0771)	Loss@kd 2.1476 (2.1920)	Acc@1 75.000 (72.841)	Acc@5 100.000 (98.983)
Epoch: [78][400/875]	Time 0.397 (0.404)	Data 0.006 (0.010)	Loss 1.0194 (1.0781)	Loss@kd 2.1297 (2.1942)	Acc@1 85.938 (72.919)	Acc@5 100.000 (98.948)
Epoch: [78][500/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss 1.1236 (1.0794)	Loss@kd 2.1772 (2.1977)	Acc@1 70.312 (72.982)	Acc@5 96.875 (98.905)
Epoch: [78][600/875]	Time 0.394 (0.402)	Data 0.006 (0.009)	Loss 1.1191 (1.0783)	Loss@kd 2.1432 (2.1957)	Acc@1 68.750 (73.061)	Acc@5 100.000 (98.918)
Epoch: [78][700/875]	Time 0.397 (0.402)	Data 0.007 (0.008)	Loss 1.0515 (1.0786)	Loss@kd 2.2556 (2.1965)	Acc@1 64.062 (73.034)	Acc@5 100.000 (98.957)
Epoch: [78][800/875]	Time 0.399 (0.402)	Data 0.007 (0.008)	Loss 1.0913 (1.0784)	Loss@kd 2.1520 (2.1951)	Acc@1 65.625 (72.999)	Acc@5 100.000 (98.964)
 * Acc@1 73.132 Acc@5 98.970
epoch 78, total time 351.80
Test: [0/750]	Time 0.786 (0.786)	Loss 0.4559 (0.4559)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.020 (0.030)	Loss 0.4409 (0.5311)	Acc@1 81.250 (85.984)	Acc@5 96.875 (94.400)
Test: [200/750]	Time 0.015 (0.025)	Loss 1.4101 (0.5141)	Acc@1 43.750 (84.359)	Acc@5 93.750 (95.849)
Test: [300/750]	Time 0.018 (0.023)	Loss 1.0026 (0.7594)	Acc@1 68.750 (73.609)	Acc@5 90.625 (94.435)
Test: [400/750]	Time 0.017 (0.022)	Loss 0.5823 (0.8118)	Acc@1 81.250 (71.259)	Acc@5 90.625 (94.506)
Test: [500/750]	Time 0.015 (0.021)	Loss 0.6817 (0.7911)	Acc@1 78.125 (72.411)	Acc@5 96.875 (94.224)
Test: [600/750]	Time 0.018 (0.021)	Loss 0.7895 (0.8142)	Acc@1 71.875 (71.818)	Acc@5 93.750 (93.911)
Test: [700/750]	Time 0.021 (0.021)	Loss 0.6932 (0.8048)	Acc@1 71.875 (71.813)	Acc@5 96.875 (94.178)
 * Acc@1 72.221 Acc@5 94.254
==> training...
Epoch: [79][0/875]	Time 1.648 (1.648)	Data 1.234 (1.234)	Loss 1.0873 (1.0873)	Loss@kd 2.2465 (2.2465)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [79][100/875]	Time 0.424 (0.413)	Data 0.007 (0.019)	Loss 1.0184 (1.0645)	Loss@kd 2.2259 (2.1948)	Acc@1 85.938 (73.654)	Acc@5 100.000 (99.072)
Epoch: [79][200/875]	Time 0.398 (0.407)	Data 0.007 (0.013)	Loss 1.2481 (1.0743)	Loss@kd 2.5058 (2.1955)	Acc@1 78.125 (73.033)	Acc@5 98.438 (99.075)
Epoch: [79][300/875]	Time 0.404 (0.404)	Data 0.011 (0.011)	Loss 1.0617 (1.0744)	Loss@kd 2.1132 (2.1948)	Acc@1 73.438 (73.048)	Acc@5 98.438 (99.019)
Epoch: [79][400/875]	Time 0.398 (0.403)	Data 0.007 (0.010)	Loss 1.1049 (1.0748)	Loss@kd 2.3269 (2.1925)	Acc@1 75.000 (73.110)	Acc@5 98.438 (99.010)
Epoch: [79][500/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss 1.1448 (1.0757)	Loss@kd 2.2111 (2.1915)	Acc@1 71.875 (72.898)	Acc@5 100.000 (98.971)
Epoch: [79][600/875]	Time 0.396 (0.402)	Data 0.007 (0.009)	Loss 1.1546 (1.0756)	Loss@kd 2.3714 (2.1916)	Acc@1 73.438 (72.946)	Acc@5 100.000 (98.929)
Epoch: [79][700/875]	Time 0.397 (0.402)	Data 0.007 (0.008)	Loss 1.1936 (1.0763)	Loss@kd 2.2961 (2.1936)	Acc@1 71.875 (73.036)	Acc@5 96.875 (98.914)
Epoch: [79][800/875]	Time 0.401 (0.402)	Data 0.007 (0.008)	Loss 1.0629 (1.0762)	Loss@kd 2.1682 (2.1950)	Acc@1 75.000 (73.131)	Acc@5 100.000 (98.945)
 * Acc@1 73.202 Acc@5 98.954
epoch 79, total time 351.58
Test: [0/750]	Time 0.700 (0.700)	Loss 0.4655 (0.4655)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.017 (0.029)	Loss 0.4048 (0.5394)	Acc@1 84.375 (86.139)	Acc@5 96.875 (94.276)
Test: [200/750]	Time 0.019 (0.025)	Loss 1.3063 (0.5045)	Acc@1 46.875 (85.152)	Acc@5 96.875 (95.802)
Test: [300/750]	Time 0.020 (0.024)	Loss 1.1821 (0.7431)	Acc@1 71.875 (74.678)	Acc@5 90.625 (94.591)
Test: [400/750]	Time 0.019 (0.023)	Loss 0.5761 (0.8358)	Acc@1 84.375 (70.948)	Acc@5 90.625 (94.163)
Test: [500/750]	Time 0.015 (0.022)	Loss 0.6474 (0.8026)	Acc@1 84.375 (72.318)	Acc@5 100.000 (94.074)
Test: [600/750]	Time 0.016 (0.022)	Loss 0.7763 (0.8164)	Acc@1 68.750 (72.021)	Acc@5 93.750 (93.922)
Test: [700/750]	Time 0.022 (0.022)	Loss 0.7003 (0.8044)	Acc@1 68.750 (72.165)	Acc@5 100.000 (94.196)
 * Acc@1 72.671 Acc@5 94.312
saving the best model!
==> training...
Epoch: [80][0/875]	Time 1.737 (1.737)	Data 1.323 (1.323)	Loss 1.1776 (1.1776)	Loss@kd 2.1863 (2.1863)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [80][100/875]	Time 0.397 (0.415)	Data 0.007 (0.020)	Loss 1.0782 (1.0781)	Loss@kd 2.1729 (2.1921)	Acc@1 79.688 (72.757)	Acc@5 100.000 (98.963)
Epoch: [80][200/875]	Time 0.397 (0.407)	Data 0.007 (0.013)	Loss 1.0564 (1.0794)	Loss@kd 2.1491 (2.1961)	Acc@1 70.312 (73.033)	Acc@5 98.438 (98.873)
Epoch: [80][300/875]	Time 0.401 (0.405)	Data 0.007 (0.011)	Loss 1.1302 (1.0823)	Loss@kd 2.3484 (2.1972)	Acc@1 73.438 (73.142)	Acc@5 98.438 (98.863)
Epoch: [80][400/875]	Time 0.397 (0.404)	Data 0.007 (0.010)	Loss 1.1903 (1.0792)	Loss@kd 2.3545 (2.1955)	Acc@1 78.125 (73.406)	Acc@5 100.000 (98.932)
Epoch: [80][500/875]	Time 0.400 (0.403)	Data 0.007 (0.009)	Loss 1.0216 (1.0773)	Loss@kd 2.1893 (2.1949)	Acc@1 78.125 (73.197)	Acc@5 100.000 (98.961)
Epoch: [80][600/875]	Time 0.396 (0.403)	Data 0.007 (0.009)	Loss 1.0195 (1.0757)	Loss@kd 2.1226 (2.1938)	Acc@1 68.750 (73.178)	Acc@5 98.438 (99.004)
Epoch: [80][700/875]	Time 0.397 (0.402)	Data 0.007 (0.009)	Loss 1.1534 (1.0752)	Loss@kd 2.1789 (2.1941)	Acc@1 67.188 (73.134)	Acc@5 100.000 (99.017)
Epoch: [80][800/875]	Time 0.395 (0.402)	Data 0.006 (0.008)	Loss 1.4493 (1.0766)	Loss@kd 2.6724 (2.1942)	Acc@1 68.750 (73.038)	Acc@5 100.000 (99.001)
 * Acc@1 73.071 Acc@5 99.016
epoch 80, total time 351.96
Test: [0/750]	Time 0.829 (0.829)	Loss 0.4529 (0.4529)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.023 (0.033)	Loss 0.4056 (0.5201)	Acc@1 81.250 (86.077)	Acc@5 96.875 (94.585)
Test: [200/750]	Time 0.024 (0.028)	Loss 1.3812 (0.4993)	Acc@1 46.875 (84.655)	Acc@5 96.875 (95.973)
Test: [300/750]	Time 0.020 (0.027)	Loss 1.0396 (0.7431)	Acc@1 75.000 (74.159)	Acc@5 90.625 (94.757)
Test: [400/750]	Time 0.023 (0.026)	Loss 0.5777 (0.8071)	Acc@1 84.375 (71.415)	Acc@5 90.625 (94.592)
Test: [500/750]	Time 0.020 (0.025)	Loss 0.6275 (0.7781)	Acc@1 84.375 (72.885)	Acc@5 100.000 (94.436)
Test: [600/750]	Time 0.023 (0.025)	Loss 0.7931 (0.7930)	Acc@1 71.875 (72.561)	Acc@5 93.750 (94.270)
Test: [700/750]	Time 0.022 (0.024)	Loss 0.7804 (0.7901)	Acc@1 65.625 (72.383)	Acc@5 93.750 (94.410)
 * Acc@1 72.679 Acc@5 94.417
saving the best model!
==> Saving...
best accuracy: tensor(72.6792, device='cuda:0')
