==> loading teacher model
==> done
Test: [0/750]	Time 32.739 (32.739)	Loss 0.5613 (0.5613)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.056 (0.374)	Loss 0.6912 (0.4886)	Acc@1 75.000 (87.098)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.042 (0.212)	Loss 1.2877 (0.4868)	Acc@1 50.000 (85.106)	Acc@5 93.750 (96.253)
Test: [300/750]	Time 0.039 (0.158)	Loss 1.1032 (0.6946)	Acc@1 56.250 (76.412)	Acc@5 93.750 (95.515)
Test: [400/750]	Time 0.050 (0.131)	Loss 0.5579 (0.7766)	Acc@1 84.375 (73.208)	Acc@5 93.750 (94.966)
Test: [500/750]	Time 0.056 (0.115)	Loss 0.4078 (0.7378)	Acc@1 84.375 (75.087)	Acc@5 100.000 (94.966)
Test: [600/750]	Time 0.036 (0.103)	Loss 0.5665 (0.7392)	Acc@1 71.875 (75.151)	Acc@5 96.875 (94.982)
Test: [700/750]	Time 0.037 (0.094)	Loss 1.0252 (0.7310)	Acc@1 68.750 (75.334)	Acc@5 81.250 (95.136)
 * Acc@1 75.533 Acc@5 95.092
teacher accuracy:  tensor(75.5333, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 3.510 (3.510)	Data 1.538 (1.538)	Loss 28.1778 (28.1778)	Loss@kd 36.4184 (36.4184)	Acc@1 14.062 (14.062)	Acc@5 64.062 (64.062)
Epoch: [1][100/875]	Time 0.652 (0.691)	Data 0.007 (0.022)	Loss 5.9939 (33.7696)	Loss@kd 6.0102 (11.2521)	Acc@1 25.000 (26.361)	Acc@5 90.625 (76.655)
Epoch: [1][200/875]	Time 0.660 (0.684)	Data 0.006 (0.015)	Loss 5.5045 (19.6841)	Loss@kd 4.8159 (8.2299)	Acc@1 31.250 (31.056)	Acc@5 76.562 (81.957)
Epoch: [1][300/875]	Time 0.680 (0.682)	Data 0.006 (0.012)	Loss 5.0187 (14.7770)	Loss@kd 4.3699 (7.0457)	Acc@1 31.250 (33.456)	Acc@5 89.062 (85.013)
Epoch: [1][400/875]	Time 0.689 (0.682)	Data 0.007 (0.011)	Loss 5.2527 (12.2654)	Loss@kd 4.3334 (6.3765)	Acc@1 39.062 (34.710)	Acc@5 81.250 (86.444)
Epoch: [1][500/875]	Time 0.670 (0.682)	Data 0.008 (0.010)	Loss 4.9985 (10.7422)	Loss@kd 3.8196 (5.9331)	Acc@1 35.938 (35.541)	Acc@5 81.250 (87.173)
Epoch: [1][600/875]	Time 0.672 (0.680)	Data 0.007 (0.010)	Loss 3.8981 (9.7195)	Loss@kd 3.6430 (5.5782)	Acc@1 43.750 (35.904)	Acc@5 92.188 (87.432)
Epoch: [1][700/875]	Time 0.635 (0.677)	Data 0.007 (0.009)	Loss 3.9128 (8.9301)	Loss@kd 3.1972 (5.2566)	Acc@1 34.375 (36.100)	Acc@5 89.062 (87.649)
Epoch: [1][800/875]	Time 0.652 (0.675)	Data 0.007 (0.009)	Loss 3.9356 (8.2937)	Loss@kd 2.9379 (4.9779)	Acc@1 40.625 (36.607)	Acc@5 87.500 (88.044)
 * Acc@1 37.043 Acc@5 88.143
epoch 1, total time 591.12
Test: [0/750]	Time 1.673 (1.673)	Loss 0.6181 (0.6181)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.114 (0.137)	Loss 0.9285 (0.5548)	Acc@1 65.625 (82.673)	Acc@5 93.750 (89.821)
Test: [200/750]	Time 0.149 (0.127)	Loss 3.6031 (0.8451)	Acc@1 0.000 (72.575)	Acc@5 0.000 (85.759)
Test: [300/750]	Time 0.110 (0.123)	Loss 2.1585 (1.5836)	Acc@1 6.250 (48.931)	Acc@5 75.000 (62.656)
Test: [400/750]	Time 0.114 (0.121)	Loss 1.0173 (1.6292)	Acc@1 65.625 (42.207)	Acc@5 90.625 (68.430)
Test: [500/750]	Time 0.189 (0.120)	Loss 0.9653 (1.4936)	Acc@1 65.625 (47.486)	Acc@5 96.875 (73.721)
Test: [600/750]	Time 0.116 (0.120)	Loss 1.5550 (1.4421)	Acc@1 34.375 (49.126)	Acc@5 81.250 (76.336)
Test: [700/750]	Time 0.119 (0.119)	Loss 1.5569 (1.4368)	Acc@1 37.500 (48.070)	Acc@5 81.250 (77.710)
 * Acc@1 48.229 Acc@5 78.092
saving the best model!
==> training...
Epoch: [2][0/875]	Time 2.360 (2.360)	Data 1.549 (1.549)	Loss 3.4726 (3.4726)	Loss@kd 2.8357 (2.8357)	Acc@1 45.312 (45.312)	Acc@5 93.750 (93.750)
Epoch: [2][100/875]	Time 0.648 (0.693)	Data 0.006 (0.022)	Loss 3.7231 (3.5340)	Loss@kd 2.9248 (2.8700)	Acc@1 43.750 (44.121)	Acc@5 85.938 (92.311)
Epoch: [2][200/875]	Time 0.667 (0.686)	Data 0.007 (0.015)	Loss 3.4294 (3.4999)	Loss@kd 2.7082 (2.8318)	Acc@1 32.812 (43.727)	Acc@5 92.188 (92.576)
Epoch: [2][300/875]	Time 0.645 (0.681)	Data 0.007 (0.012)	Loss 3.4390 (3.4805)	Loss@kd 2.7594 (2.8066)	Acc@1 35.938 (43.532)	Acc@5 96.875 (92.727)
Epoch: [2][400/875]	Time 0.620 (0.676)	Data 0.006 (0.011)	Loss 3.5323 (3.4528)	Loss@kd 2.8131 (2.7801)	Acc@1 45.312 (43.773)	Acc@5 89.062 (92.858)
Epoch: [2][500/875]	Time 0.672 (0.676)	Data 0.007 (0.010)	Loss 3.3512 (3.4193)	Loss@kd 2.5960 (2.7547)	Acc@1 39.062 (44.212)	Acc@5 93.750 (93.051)
Epoch: [2][600/875]	Time 0.699 (0.676)	Data 0.007 (0.010)	Loss 3.2095 (3.3937)	Loss@kd 2.4774 (2.7386)	Acc@1 42.188 (44.577)	Acc@5 96.875 (93.331)
Epoch: [2][700/875]	Time 0.656 (0.676)	Data 0.006 (0.010)	Loss 2.9859 (3.3664)	Loss@kd 2.4975 (2.7200)	Acc@1 40.625 (45.092)	Acc@5 100.000 (93.478)
Epoch: [2][800/875]	Time 0.677 (0.676)	Data 0.007 (0.009)	Loss 3.2184 (3.3346)	Loss@kd 2.5412 (2.7030)	Acc@1 48.438 (45.732)	Acc@5 96.875 (93.686)
 * Acc@1 45.927 Acc@5 93.764
epoch 2, total time 591.74
Test: [0/750]	Time 0.922 (0.922)	Loss 0.8171 (0.8171)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.123 (0.133)	Loss 0.6860 (0.6843)	Acc@1 78.125 (80.229)	Acc@5 93.750 (86.417)
Test: [200/750]	Time 0.088 (0.128)	Loss 2.6244 (0.7648)	Acc@1 0.000 (74.052)	Acc@5 46.875 (88.775)
Test: [300/750]	Time 0.103 (0.126)	Loss 1.1317 (1.2013)	Acc@1 62.500 (53.821)	Acc@5 90.625 (80.108)
Test: [400/750]	Time 0.118 (0.125)	Loss 2.1063 (1.2332)	Acc@1 18.750 (53.951)	Acc@5 62.500 (82.310)
Test: [500/750]	Time 0.125 (0.124)	Loss 1.2702 (1.3507)	Acc@1 62.500 (50.805)	Acc@5 78.125 (79.765)
Test: [600/750]	Time 0.126 (0.124)	Loss 0.9555 (1.3393)	Acc@1 62.500 (51.799)	Acc@5 93.750 (80.912)
Test: [700/750]	Time 0.117 (0.124)	Loss 1.4394 (1.3122)	Acc@1 31.250 (50.932)	Acc@5 84.375 (82.953)
 * Acc@1 50.125 Acc@5 83.379
saving the best model!
==> training...
Epoch: [3][0/875]	Time 2.213 (2.213)	Data 1.599 (1.599)	Loss 3.2130 (3.2130)	Loss@kd 2.5722 (2.5722)	Acc@1 45.312 (45.312)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.677 (0.685)	Data 0.008 (0.023)	Loss 2.9289 (3.0855)	Loss@kd 2.4763 (2.5540)	Acc@1 51.562 (50.046)	Acc@5 96.875 (95.374)
Epoch: [3][200/875]	Time 0.684 (0.682)	Data 0.007 (0.015)	Loss 2.9936 (3.0762)	Loss@kd 2.4781 (2.5412)	Acc@1 50.000 (50.148)	Acc@5 96.875 (95.639)
Epoch: [3][300/875]	Time 0.668 (0.680)	Data 0.007 (0.012)	Loss 3.0160 (3.0749)	Loss@kd 2.4747 (2.5263)	Acc@1 48.438 (49.849)	Acc@5 96.875 (95.411)
Epoch: [3][400/875]	Time 0.660 (0.680)	Data 0.005 (0.011)	Loss 2.8624 (3.0594)	Loss@kd 2.4659 (2.5160)	Acc@1 59.375 (50.144)	Acc@5 100.000 (95.476)
Epoch: [3][500/875]	Time 0.765 (0.681)	Data 0.007 (0.010)	Loss 3.2255 (3.0468)	Loss@kd 2.4860 (2.5060)	Acc@1 43.750 (50.471)	Acc@5 96.875 (95.525)
Epoch: [3][600/875]	Time 0.664 (0.679)	Data 0.007 (0.010)	Loss 3.0790 (3.0379)	Loss@kd 2.5988 (2.4991)	Acc@1 50.000 (50.673)	Acc@5 96.875 (95.596)
Epoch: [3][700/875]	Time 0.666 (0.677)	Data 0.008 (0.010)	Loss 2.8536 (3.0301)	Loss@kd 2.5025 (2.4902)	Acc@1 67.188 (50.836)	Acc@5 98.438 (95.529)
Epoch: [3][800/875]	Time 0.650 (0.677)	Data 0.007 (0.009)	Loss 3.0212 (3.0206)	Loss@kd 2.3185 (2.4803)	Acc@1 54.688 (50.983)	Acc@5 93.750 (95.560)
 * Acc@1 51.087 Acc@5 95.584
epoch 3, total time 592.31
Test: [0/750]	Time 0.897 (0.897)	Loss 0.6624 (0.6624)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.124 (0.132)	Loss 0.5041 (0.5597)	Acc@1 81.250 (83.478)	Acc@5 96.875 (88.428)
Test: [200/750]	Time 0.105 (0.126)	Loss 2.2183 (0.6035)	Acc@1 6.250 (81.157)	Acc@5 59.375 (90.703)
Test: [300/750]	Time 0.115 (0.124)	Loss 1.6034 (1.0223)	Acc@1 34.375 (58.804)	Acc@5 90.625 (85.102)
Test: [400/750]	Time 0.127 (0.124)	Loss 1.0603 (1.1263)	Acc@1 71.875 (52.276)	Acc@5 87.500 (86.495)
Test: [500/750]	Time 0.129 (0.123)	Loss 1.2561 (1.1304)	Acc@1 65.625 (54.379)	Acc@5 81.250 (85.735)
Test: [600/750]	Time 0.191 (0.123)	Loss 1.6695 (1.1903)	Acc@1 28.125 (52.886)	Acc@5 78.125 (84.807)
Test: [700/750]	Time 0.112 (0.122)	Loss 1.0251 (1.2206)	Acc@1 75.000 (51.516)	Acc@5 90.625 (84.999)
 * Acc@1 52.908 Acc@5 85.658
saving the best model!
==> training...
Epoch: [4][0/875]	Time 2.248 (2.248)	Data 1.582 (1.582)	Loss 2.9290 (2.9290)	Loss@kd 2.3326 (2.3326)	Acc@1 48.438 (48.438)	Acc@5 98.438 (98.438)
Epoch: [4][100/875]	Time 0.653 (0.689)	Data 0.007 (0.023)	Loss 2.8839 (2.9234)	Loss@kd 2.3058 (2.3867)	Acc@1 54.688 (52.568)	Acc@5 96.875 (95.684)
Epoch: [4][200/875]	Time 0.650 (0.680)	Data 0.008 (0.015)	Loss 2.9030 (2.9187)	Loss@kd 2.3852 (2.3913)	Acc@1 53.125 (52.736)	Acc@5 95.312 (96.160)
Epoch: [4][300/875]	Time 0.650 (0.669)	Data 0.010 (0.012)	Loss 2.8227 (2.9117)	Loss@kd 2.3338 (2.3865)	Acc@1 51.562 (52.969)	Acc@5 95.312 (96.283)
Epoch: [4][400/875]	Time 0.660 (0.669)	Data 0.007 (0.011)	Loss 3.0211 (2.9113)	Loss@kd 2.4013 (2.3853)	Acc@1 53.125 (52.981)	Acc@5 95.312 (96.178)
Epoch: [4][500/875]	Time 0.777 (0.671)	Data 0.007 (0.010)	Loss 3.1051 (2.9027)	Loss@kd 2.4070 (2.3816)	Acc@1 39.062 (53.203)	Acc@5 92.188 (96.242)
Epoch: [4][600/875]	Time 0.708 (0.672)	Data 0.008 (0.010)	Loss 2.8126 (2.8996)	Loss@kd 2.3099 (2.3768)	Acc@1 65.625 (53.094)	Acc@5 96.875 (96.207)
Epoch: [4][700/875]	Time 0.661 (0.673)	Data 0.008 (0.009)	Loss 2.8816 (2.8909)	Loss@kd 2.2287 (2.3723)	Acc@1 45.312 (53.406)	Acc@5 98.438 (96.249)
Epoch: [4][800/875]	Time 0.669 (0.674)	Data 0.006 (0.009)	Loss 3.0342 (2.8835)	Loss@kd 2.5333 (2.3679)	Acc@1 57.812 (53.580)	Acc@5 95.312 (96.266)
 * Acc@1 53.648 Acc@5 96.273
epoch 4, total time 589.92
Test: [0/750]	Time 0.898 (0.898)	Loss 0.8503 (0.8503)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.087 (0.124)	Loss 0.4620 (0.7095)	Acc@1 81.250 (81.002)	Acc@5 96.875 (86.448)
Test: [200/750]	Time 0.113 (0.118)	Loss 1.7853 (0.6452)	Acc@1 25.000 (80.255)	Acc@5 87.500 (91.402)
Test: [300/750]	Time 0.108 (0.115)	Loss 1.8823 (0.9405)	Acc@1 12.500 (65.563)	Acc@5 81.250 (89.961)
Test: [400/750]	Time 0.112 (0.114)	Loss 0.9740 (1.1103)	Acc@1 71.875 (56.211)	Acc@5 90.625 (88.209)
Test: [500/750]	Time 0.088 (0.114)	Loss 1.5326 (1.1238)	Acc@1 43.750 (56.824)	Acc@5 81.250 (87.357)
Test: [600/750]	Time 0.090 (0.114)	Loss 1.1248 (1.1865)	Acc@1 53.125 (55.345)	Acc@5 87.500 (86.340)
Test: [700/750]	Time 0.125 (0.114)	Loss 1.0826 (1.1768)	Acc@1 65.625 (55.354)	Acc@5 84.375 (87.059)
 * Acc@1 56.229 Acc@5 87.408
saving the best model!
==> training...
Epoch: [5][0/875]	Time 2.230 (2.230)	Data 1.565 (1.565)	Loss 2.6649 (2.6649)	Loss@kd 2.2361 (2.2361)	Acc@1 54.688 (54.688)	Acc@5 98.438 (98.438)
Epoch: [5][100/875]	Time 0.686 (0.695)	Data 0.008 (0.022)	Loss 2.4957 (2.8096)	Loss@kd 2.2709 (2.2975)	Acc@1 65.625 (55.152)	Acc@5 98.438 (96.457)
Epoch: [5][200/875]	Time 0.786 (0.690)	Data 0.005 (0.015)	Loss 2.5487 (2.8144)	Loss@kd 2.2354 (2.3062)	Acc@1 67.188 (55.115)	Acc@5 98.438 (96.276)
Epoch: [5][300/875]	Time 0.661 (0.687)	Data 0.007 (0.012)	Loss 2.7521 (2.8102)	Loss@kd 2.3284 (2.3060)	Acc@1 67.188 (55.046)	Acc@5 96.875 (96.366)
Epoch: [5][400/875]	Time 0.686 (0.685)	Data 0.007 (0.011)	Loss 2.8962 (2.8124)	Loss@kd 2.2123 (2.3046)	Acc@1 50.000 (54.952)	Acc@5 93.750 (96.372)
Epoch: [5][500/875]	Time 0.665 (0.684)	Data 0.008 (0.010)	Loss 2.6984 (2.8032)	Loss@kd 2.2166 (2.2991)	Acc@1 59.375 (55.146)	Acc@5 96.875 (96.445)
Epoch: [5][600/875]	Time 0.655 (0.680)	Data 0.007 (0.010)	Loss 2.8224 (2.7974)	Loss@kd 2.2985 (2.2956)	Acc@1 46.875 (55.309)	Acc@5 96.875 (96.469)
Epoch: [5][700/875]	Time 0.687 (0.680)	Data 0.007 (0.010)	Loss 2.7498 (2.7951)	Loss@kd 2.2210 (2.2905)	Acc@1 60.938 (55.289)	Acc@5 96.875 (96.451)
Epoch: [5][800/875]	Time 0.680 (0.680)	Data 0.007 (0.009)	Loss 2.4741 (2.7928)	Loss@kd 2.1168 (2.2874)	Acc@1 67.188 (55.245)	Acc@5 98.438 (96.448)
 * Acc@1 55.298 Acc@5 96.441
epoch 5, total time 595.29
Test: [0/750]	Time 0.857 (0.857)	Loss 0.7308 (0.7308)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.198 (0.129)	Loss 0.7499 (0.6341)	Acc@1 75.000 (81.374)	Acc@5 93.750 (87.964)
Test: [200/750]	Time 0.119 (0.123)	Loss 1.8044 (0.6937)	Acc@1 25.000 (76.570)	Acc@5 84.375 (91.231)
Test: [300/750]	Time 0.122 (0.122)	Loss 1.3564 (0.9539)	Acc@1 40.625 (63.486)	Acc@5 93.750 (90.345)
Test: [400/750]	Time 0.111 (0.121)	Loss 1.2420 (1.0430)	Acc@1 56.250 (58.377)	Acc@5 81.250 (90.555)
Test: [500/750]	Time 0.123 (0.120)	Loss 1.1269 (1.0848)	Acc@1 65.625 (58.701)	Acc@5 81.250 (88.149)
Test: [600/750]	Time 0.110 (0.120)	Loss 1.0012 (1.0975)	Acc@1 62.500 (59.105)	Acc@5 90.625 (87.890)
Test: [700/750]	Time 0.100 (0.119)	Loss 1.3384 (1.1025)	Acc@1 46.875 (58.836)	Acc@5 84.375 (88.298)
 * Acc@1 58.779 Acc@5 88.267
saving the best model!
==> training...
Epoch: [6][0/875]	Time 2.226 (2.226)	Data 1.599 (1.599)	Loss 2.8673 (2.8673)	Loss@kd 2.2470 (2.2470)	Acc@1 48.438 (48.438)	Acc@5 92.188 (92.188)
Epoch: [6][100/875]	Time 0.656 (0.695)	Data 0.005 (0.023)	Loss 2.4394 (2.7360)	Loss@kd 2.1536 (2.2523)	Acc@1 60.938 (55.894)	Acc@5 100.000 (96.751)
Epoch: [6][200/875]	Time 0.647 (0.678)	Data 0.007 (0.015)	Loss 2.8085 (2.7453)	Loss@kd 2.3667 (2.2511)	Acc@1 54.688 (55.799)	Acc@5 96.875 (96.634)
Epoch: [6][300/875]	Time 0.673 (0.675)	Data 0.007 (0.013)	Loss 2.8595 (2.7359)	Loss@kd 2.2431 (2.2411)	Acc@1 48.438 (56.027)	Acc@5 98.438 (96.693)
Epoch: [6][400/875]	Time 0.663 (0.677)	Data 0.007 (0.011)	Loss 2.5304 (2.7377)	Loss@kd 2.1003 (2.2400)	Acc@1 54.688 (55.946)	Acc@5 95.312 (96.696)
Epoch: [6][500/875]	Time 0.665 (0.678)	Data 0.007 (0.011)	Loss 2.7964 (2.7357)	Loss@kd 2.1878 (2.2374)	Acc@1 53.125 (55.910)	Acc@5 95.312 (96.694)
Epoch: [6][600/875]	Time 0.701 (0.678)	Data 0.008 (0.010)	Loss 3.0497 (2.7303)	Loss@kd 2.1940 (2.2343)	Acc@1 42.188 (56.141)	Acc@5 96.875 (96.716)
Epoch: [6][700/875]	Time 0.765 (0.679)	Data 0.007 (0.010)	Loss 2.6907 (2.7263)	Loss@kd 2.1985 (2.2312)	Acc@1 57.812 (56.205)	Acc@5 98.438 (96.708)
Epoch: [6][800/875]	Time 0.675 (0.678)	Data 0.007 (0.009)	Loss 2.9281 (2.7256)	Loss@kd 2.2849 (2.2288)	Acc@1 51.562 (56.258)	Acc@5 93.750 (96.676)
 * Acc@1 56.305 Acc@5 96.682
epoch 6, total time 592.15
Test: [0/750]	Time 0.993 (0.993)	Loss 0.6737 (0.6737)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.077 (0.120)	Loss 0.7404 (0.5286)	Acc@1 81.250 (83.385)	Acc@5 93.750 (90.006)
Test: [200/750]	Time 0.132 (0.119)	Loss 2.0258 (0.7037)	Acc@1 15.625 (75.233)	Acc@5 62.500 (90.672)
Test: [300/750]	Time 0.091 (0.119)	Loss 1.6533 (1.0635)	Acc@1 18.750 (58.254)	Acc@5 87.500 (85.839)
Test: [400/750]	Time 0.127 (0.119)	Loss 0.6054 (1.1515)	Acc@1 90.625 (53.491)	Acc@5 93.750 (86.892)
Test: [500/750]	Time 0.190 (0.120)	Loss 0.8805 (1.0783)	Acc@1 75.000 (58.520)	Acc@5 87.500 (87.731)
Test: [600/750]	Time 0.125 (0.120)	Loss 0.9811 (1.0658)	Acc@1 65.625 (60.165)	Acc@5 93.750 (87.999)
Test: [700/750]	Time 0.122 (0.119)	Loss 1.6091 (1.0867)	Acc@1 37.500 (59.250)	Acc@5 78.125 (88.285)
 * Acc@1 58.138 Acc@5 88.071
==> training...
Epoch: [7][0/875]	Time 2.174 (2.174)	Data 1.533 (1.533)	Loss 2.4613 (2.4613)	Loss@kd 2.1983 (2.1983)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [7][100/875]	Time 0.641 (0.694)	Data 0.007 (0.022)	Loss 2.5467 (2.7062)	Loss@kd 2.1066 (2.2211)	Acc@1 59.375 (56.791)	Acc@5 100.000 (96.566)
Epoch: [7][200/875]	Time 0.684 (0.687)	Data 0.007 (0.015)	Loss 2.5926 (2.6896)	Loss@kd 2.1935 (2.2007)	Acc@1 59.375 (56.468)	Acc@5 96.875 (96.883)
Epoch: [7][300/875]	Time 0.701 (0.684)	Data 0.007 (0.012)	Loss 2.5043 (2.6819)	Loss@kd 2.1330 (2.1946)	Acc@1 64.062 (56.868)	Acc@5 93.750 (96.911)
Epoch: [7][400/875]	Time 0.766 (0.682)	Data 0.007 (0.011)	Loss 2.4496 (2.6769)	Loss@kd 2.0543 (2.1908)	Acc@1 59.375 (56.873)	Acc@5 100.000 (96.902)
Epoch: [7][500/875]	Time 0.653 (0.678)	Data 0.007 (0.010)	Loss 2.5550 (2.6771)	Loss@kd 2.2087 (2.1892)	Acc@1 64.062 (56.680)	Acc@5 100.000 (96.900)
Epoch: [7][600/875]	Time 0.668 (0.677)	Data 0.007 (0.010)	Loss 2.6871 (2.6754)	Loss@kd 2.0779 (2.1886)	Acc@1 50.000 (56.754)	Acc@5 95.312 (96.909)
Epoch: [7][700/875]	Time 0.670 (0.677)	Data 0.005 (0.010)	Loss 2.8540 (2.6730)	Loss@kd 2.3605 (2.1849)	Acc@1 59.375 (56.769)	Acc@5 96.875 (96.913)
Epoch: [7][800/875]	Time 0.746 (0.677)	Data 0.007 (0.009)	Loss 2.9960 (2.6709)	Loss@kd 2.1066 (2.1813)	Acc@1 46.875 (56.796)	Acc@5 95.312 (96.861)
 * Acc@1 56.805 Acc@5 96.862
epoch 7, total time 592.50
Test: [0/750]	Time 0.975 (0.975)	Loss 0.7237 (0.7237)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.114 (0.126)	Loss 0.6003 (0.6325)	Acc@1 84.375 (80.879)	Acc@5 100.000 (88.490)
Test: [200/750]	Time 0.127 (0.122)	Loss 1.7133 (0.6645)	Acc@1 34.375 (78.234)	Acc@5 84.375 (91.682)
Test: [300/750]	Time 0.104 (0.121)	Loss 1.6820 (0.9539)	Acc@1 21.875 (65.002)	Acc@5 78.125 (89.971)
Test: [400/750]	Time 0.112 (0.119)	Loss 0.7544 (1.0778)	Acc@1 84.375 (57.512)	Acc@5 90.625 (88.677)
Test: [500/750]	Time 0.183 (0.119)	Loss 0.7301 (1.0220)	Acc@1 75.000 (61.109)	Acc@5 96.875 (89.047)
Test: [600/750]	Time 0.109 (0.119)	Loss 1.0551 (1.0159)	Acc@1 71.875 (62.120)	Acc@5 87.500 (89.387)
Test: [700/750]	Time 0.112 (0.118)	Loss 1.4161 (1.0520)	Acc@1 53.125 (60.610)	Acc@5 78.125 (89.488)
 * Acc@1 60.183 Acc@5 89.221
saving the best model!
==> training...
Epoch: [8][0/875]	Time 2.244 (2.244)	Data 1.595 (1.595)	Loss 2.8897 (2.8897)	Loss@kd 2.4230 (2.4230)	Acc@1 50.000 (50.000)	Acc@5 98.438 (98.438)
Epoch: [8][100/875]	Time 0.654 (0.684)	Data 0.007 (0.023)	Loss 2.6485 (2.6439)	Loss@kd 2.1501 (2.1595)	Acc@1 54.688 (57.627)	Acc@5 96.875 (97.107)
Epoch: [8][200/875]	Time 0.686 (0.674)	Data 0.007 (0.015)	Loss 2.6155 (2.6349)	Loss@kd 2.1366 (2.1502)	Acc@1 59.375 (57.696)	Acc@5 93.750 (96.922)
Epoch: [8][300/875]	Time 0.663 (0.675)	Data 0.007 (0.013)	Loss 2.7291 (2.6337)	Loss@kd 2.1219 (2.1471)	Acc@1 53.125 (57.755)	Acc@5 93.750 (96.911)
Epoch: [8][400/875]	Time 0.652 (0.675)	Data 0.007 (0.011)	Loss 2.4430 (2.6238)	Loss@kd 2.0183 (2.1417)	Acc@1 62.500 (58.031)	Acc@5 98.438 (96.891)
Epoch: [8][500/875]	Time 0.667 (0.676)	Data 0.008 (0.011)	Loss 2.6207 (2.6265)	Loss@kd 2.0969 (2.1404)	Acc@1 59.375 (57.750)	Acc@5 96.875 (96.906)
Epoch: [8][600/875]	Time 0.670 (0.677)	Data 0.007 (0.010)	Loss 2.6462 (2.6255)	Loss@kd 2.0850 (2.1394)	Acc@1 53.125 (57.797)	Acc@5 93.750 (96.862)
Epoch: [8][700/875]	Time 0.670 (0.677)	Data 0.007 (0.010)	Loss 2.4893 (2.6248)	Loss@kd 2.1236 (2.1367)	Acc@1 60.938 (57.763)	Acc@5 96.875 (96.913)
Epoch: [8][800/875]	Time 0.668 (0.675)	Data 0.007 (0.009)	Loss 2.4384 (2.6221)	Loss@kd 2.0625 (2.1352)	Acc@1 60.938 (57.793)	Acc@5 98.438 (96.930)
 * Acc@1 57.870 Acc@5 96.952
epoch 8, total time 590.81
Test: [0/750]	Time 0.946 (0.946)	Loss 0.7158 (0.7158)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.102 (0.131)	Loss 0.4744 (0.5661)	Acc@1 84.375 (82.952)	Acc@5 96.875 (88.830)
Test: [200/750]	Time 0.097 (0.126)	Loss 1.6850 (0.5710)	Acc@1 34.375 (82.245)	Acc@5 78.125 (92.118)
Test: [300/750]	Time 0.211 (0.124)	Loss 1.5307 (0.8698)	Acc@1 25.000 (67.868)	Acc@5 96.875 (90.781)
Test: [400/750]	Time 0.131 (0.123)	Loss 0.4932 (0.9739)	Acc@1 84.375 (61.978)	Acc@5 100.000 (90.789)
Test: [500/750]	Time 0.127 (0.123)	Loss 0.9711 (0.9227)	Acc@1 62.500 (65.276)	Acc@5 90.625 (91.130)
Test: [600/750]	Time 0.121 (0.123)	Loss 1.3580 (0.9819)	Acc@1 40.625 (63.290)	Acc@5 84.375 (90.365)
Test: [700/750]	Time 0.122 (0.123)	Loss 1.7617 (1.0632)	Acc@1 40.625 (59.540)	Acc@5 71.875 (89.328)
 * Acc@1 58.529 Acc@5 88.617
==> training...
Epoch: [9][0/875]	Time 2.151 (2.151)	Data 1.503 (1.503)	Loss 2.5134 (2.5134)	Loss@kd 2.0960 (2.0960)	Acc@1 57.812 (57.812)	Acc@5 96.875 (96.875)
Epoch: [9][100/875]	Time 0.677 (0.695)	Data 0.007 (0.022)	Loss 2.5947 (2.5937)	Loss@kd 2.0838 (2.1086)	Acc@1 62.500 (58.524)	Acc@5 98.438 (97.092)
Epoch: [9][200/875]	Time 0.662 (0.688)	Data 0.008 (0.015)	Loss 2.5608 (2.5787)	Loss@kd 2.0563 (2.1009)	Acc@1 59.375 (58.535)	Acc@5 98.438 (97.248)
Epoch: [9][300/875]	Time 0.660 (0.686)	Data 0.007 (0.012)	Loss 2.7778 (2.5888)	Loss@kd 2.0999 (2.1052)	Acc@1 51.562 (58.228)	Acc@5 95.312 (97.171)
Epoch: [9][400/875]	Time 0.646 (0.679)	Data 0.007 (0.011)	Loss 2.6542 (2.5835)	Loss@kd 2.1852 (2.1033)	Acc@1 51.562 (58.319)	Acc@5 96.875 (97.210)
Epoch: [9][500/875]	Time 0.661 (0.677)	Data 0.008 (0.010)	Loss 2.3775 (2.5787)	Loss@kd 2.0136 (2.0990)	Acc@1 54.688 (58.389)	Acc@5 98.438 (97.125)
Epoch: [9][600/875]	Time 0.662 (0.677)	Data 0.007 (0.010)	Loss 2.7099 (2.5790)	Loss@kd 2.1246 (2.0981)	Acc@1 51.562 (58.325)	Acc@5 96.875 (97.140)
Epoch: [9][700/875]	Time 0.680 (0.677)	Data 0.007 (0.009)	Loss 2.4484 (2.5819)	Loss@kd 2.1495 (2.0974)	Acc@1 64.062 (58.247)	Acc@5 95.312 (97.114)
Epoch: [9][800/875]	Time 0.669 (0.677)	Data 0.007 (0.009)	Loss 2.4066 (2.5801)	Loss@kd 2.0316 (2.0954)	Acc@1 68.750 (58.277)	Acc@5 100.000 (97.152)
 * Acc@1 58.316 Acc@5 97.127
epoch 9, total time 592.93
Test: [0/750]	Time 0.865 (0.865)	Loss 0.6302 (0.6302)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.127 (0.129)	Loss 0.6063 (0.4980)	Acc@1 84.375 (84.437)	Acc@5 96.875 (90.223)
Test: [200/750]	Time 0.112 (0.122)	Loss 1.6855 (0.6022)	Acc@1 15.625 (78.871)	Acc@5 84.375 (92.242)
Test: [300/750]	Time 0.117 (0.120)	Loss 1.0332 (0.8851)	Acc@1 81.250 (63.393)	Acc@5 96.875 (91.289)
Test: [400/750]	Time 0.128 (0.120)	Loss 0.6755 (0.9205)	Acc@1 81.250 (63.575)	Acc@5 93.750 (92.324)
Test: [500/750]	Time 0.125 (0.119)	Loss 1.1186 (0.9270)	Acc@1 68.750 (64.939)	Acc@5 87.500 (91.529)
Test: [600/750]	Time 0.119 (0.119)	Loss 1.0534 (0.9813)	Acc@1 62.500 (63.602)	Acc@5 87.500 (90.724)
Test: [700/750]	Time 0.108 (0.119)	Loss 1.9871 (1.0479)	Acc@1 18.750 (60.342)	Acc@5 68.750 (89.974)
 * Acc@1 58.204 Acc@5 88.833
==> training...
Epoch: [10][0/875]	Time 2.150 (2.150)	Data 1.527 (1.527)	Loss 2.4149 (2.4149)	Loss@kd 1.9352 (1.9352)	Acc@1 54.688 (54.688)	Acc@5 100.000 (100.000)
Epoch: [10][100/875]	Time 0.670 (0.684)	Data 0.006 (0.022)	Loss 2.5692 (2.5740)	Loss@kd 2.0587 (2.0925)	Acc@1 54.688 (58.462)	Acc@5 100.000 (97.169)
Epoch: [10][200/875]	Time 0.654 (0.682)	Data 0.007 (0.015)	Loss 2.3953 (2.5531)	Loss@kd 2.0698 (2.0777)	Acc@1 65.625 (59.010)	Acc@5 98.438 (97.303)
Epoch: [10][300/875]	Time 0.677 (0.681)	Data 0.007 (0.012)	Loss 2.3884 (2.5507)	Loss@kd 2.0962 (2.0730)	Acc@1 64.062 (58.804)	Acc@5 100.000 (97.264)
Epoch: [10][400/875]	Time 0.652 (0.681)	Data 0.007 (0.011)	Loss 2.5400 (2.5499)	Loss@kd 2.0565 (2.0714)	Acc@1 62.500 (58.849)	Acc@5 96.875 (97.280)
Epoch: [10][500/875]	Time 0.683 (0.681)	Data 0.007 (0.011)	Loss 2.4793 (2.5466)	Loss@kd 2.0727 (2.0679)	Acc@1 60.938 (58.764)	Acc@5 96.875 (97.299)
Epoch: [10][600/875]	Time 0.636 (0.681)	Data 0.007 (0.010)	Loss 2.2523 (2.5445)	Loss@kd 1.9618 (2.0651)	Acc@1 67.188 (58.694)	Acc@5 100.000 (97.291)
Epoch: [10][700/875]	Time 0.669 (0.678)	Data 0.007 (0.010)	Loss 2.6267 (2.5418)	Loss@kd 1.9968 (2.0630)	Acc@1 54.688 (58.742)	Acc@5 96.875 (97.314)
Epoch: [10][800/875]	Time 0.678 (0.677)	Data 0.007 (0.009)	Loss 2.4656 (2.5392)	Loss@kd 2.0804 (2.0600)	Acc@1 57.812 (58.749)	Acc@5 100.000 (97.324)
 * Acc@1 58.730 Acc@5 97.295
epoch 10, total time 593.21
Test: [0/750]	Time 0.841 (0.841)	Loss 0.6452 (0.6452)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.084 (0.122)	Loss 0.7265 (0.5559)	Acc@1 68.750 (82.178)	Acc@5 100.000 (89.790)
Test: [200/750]	Time 0.104 (0.120)	Loss 1.9397 (0.6728)	Acc@1 15.625 (74.907)	Acc@5 68.750 (91.822)
Test: [300/750]	Time 0.108 (0.118)	Loss 1.5996 (1.0159)	Acc@1 28.125 (59.500)	Acc@5 84.375 (88.497)
Test: [400/750]	Time 0.091 (0.117)	Loss 0.5205 (1.1143)	Acc@1 87.500 (54.512)	Acc@5 93.750 (88.451)
Test: [500/750]	Time 0.112 (0.117)	Loss 0.9686 (1.0352)	Acc@1 71.875 (59.375)	Acc@5 93.750 (89.184)
Test: [600/750]	Time 0.125 (0.117)	Loss 0.8002 (1.0314)	Acc@1 75.000 (60.795)	Acc@5 93.750 (89.497)
Test: [700/750]	Time 0.105 (0.117)	Loss 1.3775 (1.0352)	Acc@1 62.500 (61.100)	Acc@5 78.125 (89.943)
 * Acc@1 60.808 Acc@5 89.808
saving the best model!
==> training...
Epoch: [11][0/875]	Time 2.219 (2.219)	Data 1.577 (1.577)	Loss 2.5134 (2.5134)	Loss@kd 2.0350 (2.0350)	Acc@1 56.250 (56.250)	Acc@5 96.875 (96.875)
Epoch: [11][100/875]	Time 0.726 (0.693)	Data 0.007 (0.023)	Loss 2.4160 (2.5182)	Loss@kd 2.0735 (2.0459)	Acc@1 59.375 (58.957)	Acc@5 100.000 (97.494)
Epoch: [11][200/875]	Time 0.670 (0.687)	Data 0.007 (0.015)	Loss 2.4508 (2.5211)	Loss@kd 2.0971 (2.0405)	Acc@1 59.375 (58.652)	Acc@5 98.438 (97.240)
Epoch: [11][300/875]	Time 0.638 (0.680)	Data 0.008 (0.013)	Loss 2.4711 (2.5070)	Loss@kd 2.0651 (2.0369)	Acc@1 64.062 (59.271)	Acc@5 96.875 (97.353)
Epoch: [11][400/875]	Time 0.661 (0.677)	Data 0.007 (0.011)	Loss 2.7886 (2.5153)	Loss@kd 2.0302 (2.0374)	Acc@1 51.562 (58.931)	Acc@5 98.438 (97.276)
Epoch: [11][500/875]	Time 0.688 (0.679)	Data 0.007 (0.011)	Loss 2.4821 (2.5069)	Loss@kd 1.9948 (2.0328)	Acc@1 53.125 (59.154)	Acc@5 95.312 (97.365)
Epoch: [11][600/875]	Time 0.669 (0.678)	Data 0.007 (0.010)	Loss 2.6005 (2.5036)	Loss@kd 2.0349 (2.0296)	Acc@1 56.250 (59.053)	Acc@5 96.875 (97.348)
Epoch: [11][700/875]	Time 0.687 (0.678)	Data 0.007 (0.010)	Loss 2.3688 (2.5023)	Loss@kd 2.0296 (2.0272)	Acc@1 64.062 (59.128)	Acc@5 98.438 (97.310)
Epoch: [11][800/875]	Time 0.692 (0.678)	Data 0.007 (0.009)	Loss 2.4180 (2.5025)	Loss@kd 2.1269 (2.0271)	Acc@1 67.188 (59.106)	Acc@5 100.000 (97.314)
 * Acc@1 59.250 Acc@5 97.298
epoch 11, total time 594.00
Test: [0/750]	Time 1.085 (1.085)	Loss 0.7094 (0.7094)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.113 (0.127)	Loss 0.5958 (0.6124)	Acc@1 78.125 (81.281)	Acc@5 96.875 (88.707)
Test: [200/750]	Time 0.124 (0.123)	Loss 1.5767 (0.6425)	Acc@1 31.250 (77.643)	Acc@5 87.500 (92.320)
Test: [300/750]	Time 0.123 (0.122)	Loss 1.3143 (0.8897)	Acc@1 31.250 (66.009)	Acc@5 100.000 (91.736)
Test: [400/750]	Time 0.112 (0.122)	Loss 0.8742 (0.9865)	Acc@1 71.875 (60.809)	Acc@5 90.625 (91.552)
Test: [500/750]	Time 0.096 (0.121)	Loss 0.7720 (0.9685)	Acc@1 78.125 (63.236)	Acc@5 93.750 (90.569)
Test: [600/750]	Time 0.115 (0.121)	Loss 0.8190 (0.9679)	Acc@1 75.000 (64.039)	Acc@5 93.750 (90.511)
Test: [700/750]	Time 0.124 (0.121)	Loss 1.3803 (0.9799)	Acc@1 53.125 (63.530)	Acc@5 84.375 (90.576)
 * Acc@1 62.979 Acc@5 90.188
saving the best model!
==> training...
Epoch: [12][0/875]	Time 2.307 (2.307)	Data 1.622 (1.622)	Loss 2.5488 (2.5488)	Loss@kd 1.9910 (1.9910)	Acc@1 56.250 (56.250)	Acc@5 100.000 (100.000)
Epoch: [12][100/875]	Time 0.665 (0.694)	Data 0.009 (0.023)	Loss 2.3353 (2.5086)	Loss@kd 1.9791 (1.9991)	Acc@1 62.500 (58.261)	Acc@5 98.438 (97.107)
Epoch: [12][200/875]	Time 0.670 (0.686)	Data 0.008 (0.015)	Loss 2.4713 (2.5012)	Loss@kd 2.0426 (2.0078)	Acc@1 62.500 (58.582)	Acc@5 95.312 (97.240)
Epoch: [12][300/875]	Time 0.682 (0.684)	Data 0.007 (0.013)	Loss 2.1443 (2.4889)	Loss@kd 2.0049 (2.0049)	Acc@1 70.312 (59.006)	Acc@5 100.000 (97.358)
Epoch: [12][400/875]	Time 0.660 (0.683)	Data 0.007 (0.011)	Loss 2.3333 (2.4790)	Loss@kd 1.9427 (2.0025)	Acc@1 57.812 (59.597)	Acc@5 100.000 (97.358)
Epoch: [12][500/875]	Time 0.667 (0.682)	Data 0.007 (0.011)	Loss 2.4297 (2.4785)	Loss@kd 2.0317 (2.0031)	Acc@1 56.250 (59.587)	Acc@5 100.000 (97.358)
Epoch: [12][600/875]	Time 0.637 (0.679)	Data 0.007 (0.010)	Loss 2.3809 (2.4749)	Loss@kd 1.9542 (2.0010)	Acc@1 57.812 (59.726)	Acc@5 95.312 (97.385)
Epoch: [12][700/875]	Time 0.669 (0.677)	Data 0.007 (0.010)	Loss 2.4539 (2.4724)	Loss@kd 1.8905 (1.9985)	Acc@1 57.812 (59.716)	Acc@5 96.875 (97.403)
Epoch: [12][800/875]	Time 0.690 (0.678)	Data 0.007 (0.009)	Loss 2.3867 (2.4706)	Loss@kd 1.9033 (1.9964)	Acc@1 62.500 (59.701)	Acc@5 98.438 (97.382)
 * Acc@1 59.761 Acc@5 97.350
epoch 12, total time 593.58
Test: [0/750]	Time 0.854 (0.854)	Loss 0.7503 (0.7503)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.123 (0.129)	Loss 0.6086 (0.6520)	Acc@1 75.000 (81.002)	Acc@5 100.000 (88.243)
Test: [200/750]	Time 0.188 (0.125)	Loss 1.9172 (0.7011)	Acc@1 21.875 (76.026)	Acc@5 71.875 (91.433)
Test: [300/750]	Time 0.105 (0.123)	Loss 1.3599 (1.0057)	Acc@1 43.750 (60.963)	Acc@5 93.750 (89.244)
Test: [400/750]	Time 0.111 (0.122)	Loss 0.6338 (1.0574)	Acc@1 75.000 (57.622)	Acc@5 93.750 (89.947)
Test: [500/750]	Time 0.170 (0.122)	Loss 0.7527 (0.9957)	Acc@1 81.250 (61.465)	Acc@5 90.625 (90.126)
Test: [600/750]	Time 0.115 (0.121)	Loss 0.8489 (0.9919)	Acc@1 68.750 (62.630)	Acc@5 93.750 (90.214)
Test: [700/750]	Time 0.111 (0.121)	Loss 1.2352 (0.9974)	Acc@1 62.500 (62.629)	Acc@5 84.375 (90.531)
 * Acc@1 62.633 Acc@5 90.362
==> training...
Epoch: [13][0/875]	Time 2.293 (2.293)	Data 1.585 (1.585)	Loss 2.4862 (2.4862)	Loss@kd 2.0532 (2.0532)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [13][100/875]	Time 0.657 (0.694)	Data 0.007 (0.023)	Loss 2.2871 (2.4422)	Loss@kd 1.9618 (1.9628)	Acc@1 68.750 (59.886)	Acc@5 100.000 (97.215)
Epoch: [13][200/875]	Time 0.649 (0.681)	Data 0.007 (0.015)	Loss 2.4812 (2.4509)	Loss@kd 2.0038 (1.9745)	Acc@1 60.938 (59.655)	Acc@5 96.875 (97.318)
Epoch: [13][300/875]	Time 0.683 (0.675)	Data 0.007 (0.013)	Loss 2.2526 (2.4514)	Loss@kd 1.9660 (1.9754)	Acc@1 67.188 (59.998)	Acc@5 98.438 (97.342)
Epoch: [13][400/875]	Time 0.667 (0.677)	Data 0.007 (0.011)	Loss 2.3756 (2.4492)	Loss@kd 1.9245 (1.9716)	Acc@1 62.500 (59.987)	Acc@5 100.000 (97.323)
Epoch: [13][500/875]	Time 0.694 (0.678)	Data 0.009 (0.011)	Loss 2.2946 (2.4493)	Loss@kd 1.9532 (1.9723)	Acc@1 64.062 (60.017)	Acc@5 100.000 (97.340)
Epoch: [13][600/875]	Time 0.667 (0.679)	Data 0.007 (0.010)	Loss 2.3935 (2.4452)	Loss@kd 1.9592 (1.9710)	Acc@1 56.250 (60.064)	Acc@5 98.438 (97.374)
Epoch: [13][700/875]	Time 0.661 (0.679)	Data 0.007 (0.010)	Loss 2.2976 (2.4451)	Loss@kd 1.8908 (1.9709)	Acc@1 64.062 (60.084)	Acc@5 98.438 (97.392)
Epoch: [13][800/875]	Time 0.739 (0.679)	Data 0.007 (0.009)	Loss 2.4132 (2.4437)	Loss@kd 1.8749 (1.9695)	Acc@1 64.062 (60.105)	Acc@5 96.875 (97.392)
 * Acc@1 60.175 Acc@5 97.379
epoch 13, total time 592.98
Test: [0/750]	Time 0.927 (0.927)	Loss 0.7221 (0.7221)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.117 (0.127)	Loss 0.6403 (0.6313)	Acc@1 75.000 (81.374)	Acc@5 96.875 (88.212)
Test: [200/750]	Time 0.113 (0.123)	Loss 1.5177 (0.6784)	Acc@1 31.250 (77.192)	Acc@5 78.125 (91.107)
Test: [300/750]	Time 0.127 (0.119)	Loss 1.1995 (0.9225)	Acc@1 43.750 (63.684)	Acc@5 100.000 (90.698)
Test: [400/750]	Time 0.125 (0.119)	Loss 0.8447 (0.9898)	Acc@1 65.625 (59.959)	Acc@5 93.750 (91.046)
Test: [500/750]	Time 0.115 (0.120)	Loss 0.7988 (0.9771)	Acc@1 75.000 (62.051)	Acc@5 93.750 (90.382)
Test: [600/750]	Time 0.104 (0.120)	Loss 1.0110 (0.9935)	Acc@1 65.625 (62.469)	Acc@5 87.500 (89.913)
Test: [700/750]	Time 0.117 (0.120)	Loss 1.0624 (1.0013)	Acc@1 62.500 (62.299)	Acc@5 90.625 (90.184)
 * Acc@1 62.779 Acc@5 90.417
==> training...
Epoch: [14][0/875]	Time 2.247 (2.247)	Data 1.565 (1.565)	Loss 2.5679 (2.5679)	Loss@kd 1.8894 (1.8894)	Acc@1 57.812 (57.812)	Acc@5 96.875 (96.875)
Epoch: [14][100/875]	Time 0.689 (0.700)	Data 0.008 (0.023)	Loss 2.5088 (2.4398)	Loss@kd 1.9070 (1.9527)	Acc@1 54.688 (59.870)	Acc@5 93.750 (97.293)
Epoch: [14][200/875]	Time 0.678 (0.691)	Data 0.007 (0.015)	Loss 2.3264 (2.4429)	Loss@kd 1.9840 (1.9574)	Acc@1 68.750 (59.709)	Acc@5 100.000 (97.373)
Epoch: [14][300/875]	Time 0.665 (0.687)	Data 0.007 (0.013)	Loss 2.3554 (2.4351)	Loss@kd 1.9206 (1.9548)	Acc@1 65.625 (59.977)	Acc@5 98.438 (97.513)
Epoch: [14][400/875]	Time 0.684 (0.685)	Data 0.008 (0.011)	Loss 2.3801 (2.4311)	Loss@kd 1.9303 (1.9530)	Acc@1 59.375 (60.271)	Acc@5 100.000 (97.432)
Epoch: [14][500/875]	Time 0.647 (0.680)	Data 0.007 (0.011)	Loss 2.1572 (2.4217)	Loss@kd 1.9350 (1.9498)	Acc@1 71.875 (60.591)	Acc@5 100.000 (97.489)
Epoch: [14][600/875]	Time 0.706 (0.679)	Data 0.008 (0.010)	Loss 2.1287 (2.4189)	Loss@kd 1.8437 (1.9482)	Acc@1 68.750 (60.693)	Acc@5 98.438 (97.470)
Epoch: [14][700/875]	Time 0.693 (0.679)	Data 0.007 (0.010)	Loss 2.2501 (2.4145)	Loss@kd 1.8970 (1.9472)	Acc@1 70.312 (60.926)	Acc@5 100.000 (97.472)
Epoch: [14][800/875]	Time 0.722 (0.679)	Data 0.007 (0.009)	Loss 2.4126 (2.4108)	Loss@kd 1.9826 (1.9459)	Acc@1 57.812 (60.973)	Acc@5 98.438 (97.497)
 * Acc@1 60.959 Acc@5 97.484
epoch 14, total time 594.10
Test: [0/750]	Time 1.035 (1.035)	Loss 0.7272 (0.7272)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.119 (0.127)	Loss 0.4034 (0.5496)	Acc@1 81.250 (83.385)	Acc@5 100.000 (90.408)
Test: [200/750]	Time 0.114 (0.121)	Loss 1.7388 (0.5315)	Acc@1 28.125 (81.919)	Acc@5 84.375 (93.532)
Test: [300/750]	Time 0.123 (0.120)	Loss 1.2867 (0.8488)	Acc@1 37.500 (67.722)	Acc@5 100.000 (91.570)
Test: [400/750]	Time 0.104 (0.119)	Loss 0.6598 (0.9316)	Acc@1 87.500 (64.090)	Acc@5 93.750 (92.043)
Test: [500/750]	Time 0.123 (0.118)	Loss 0.8037 (0.9072)	Acc@1 68.750 (66.498)	Acc@5 96.875 (91.554)
Test: [600/750]	Time 0.110 (0.118)	Loss 0.7723 (0.9235)	Acc@1 71.875 (66.395)	Acc@5 100.000 (91.592)
Test: [700/750]	Time 0.126 (0.117)	Loss 2.0572 (0.9888)	Acc@1 28.125 (63.597)	Acc@5 62.500 (90.705)
 * Acc@1 61.546 Acc@5 89.213
==> training...
Epoch: [15][0/875]	Time 2.203 (2.203)	Data 1.543 (1.543)	Loss 2.1274 (2.1274)	Loss@kd 1.8671 (1.8671)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [15][100/875]	Time 0.651 (0.684)	Data 0.007 (0.023)	Loss 2.3428 (2.3863)	Loss@kd 1.8948 (1.9263)	Acc@1 56.250 (60.675)	Acc@5 100.000 (97.788)
Epoch: [15][200/875]	Time 0.648 (0.673)	Data 0.007 (0.015)	Loss 2.3464 (2.3991)	Loss@kd 1.8682 (1.9313)	Acc@1 60.938 (60.891)	Acc@5 98.438 (97.652)
Epoch: [15][300/875]	Time 0.680 (0.674)	Data 0.007 (0.012)	Loss 2.2259 (2.3934)	Loss@kd 1.8867 (1.9305)	Acc@1 67.188 (61.062)	Acc@5 100.000 (97.638)
Epoch: [15][400/875]	Time 0.680 (0.676)	Data 0.007 (0.011)	Loss 2.7023 (2.3925)	Loss@kd 1.9710 (1.9297)	Acc@1 43.750 (61.167)	Acc@5 98.438 (97.619)
Epoch: [15][500/875]	Time 0.682 (0.677)	Data 0.007 (0.010)	Loss 2.2571 (2.3961)	Loss@kd 1.8566 (1.9313)	Acc@1 68.750 (61.156)	Acc@5 96.875 (97.546)
Epoch: [15][600/875]	Time 0.668 (0.678)	Data 0.007 (0.010)	Loss 2.0939 (2.3945)	Loss@kd 1.7994 (1.9298)	Acc@1 68.750 (61.088)	Acc@5 98.438 (97.481)
Epoch: [15][700/875]	Time 0.664 (0.678)	Data 0.007 (0.010)	Loss 2.3110 (2.3909)	Loss@kd 1.8900 (1.9284)	Acc@1 65.625 (61.116)	Acc@5 100.000 (97.519)
Epoch: [15][800/875]	Time 0.655 (0.676)	Data 0.007 (0.009)	Loss 2.4089 (2.3902)	Loss@kd 1.8970 (1.9267)	Acc@1 62.500 (61.096)	Acc@5 96.875 (97.517)
 * Acc@1 60.995 Acc@5 97.495
epoch 15, total time 591.55
Test: [0/750]	Time 0.948 (0.948)	Loss 0.7104 (0.7104)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.134 (0.132)	Loss 0.4502 (0.5823)	Acc@1 87.500 (81.498)	Acc@5 100.000 (90.192)
Test: [200/750]	Time 0.093 (0.127)	Loss 1.6223 (0.5733)	Acc@1 31.250 (80.877)	Acc@5 81.250 (93.252)
Test: [300/750]	Time 0.091 (0.125)	Loss 1.2845 (0.8636)	Acc@1 40.625 (67.203)	Acc@5 100.000 (91.798)
Test: [400/750]	Time 0.101 (0.123)	Loss 0.4719 (0.9367)	Acc@1 84.375 (64.035)	Acc@5 96.875 (92.059)
Test: [500/750]	Time 0.124 (0.122)	Loss 0.7085 (0.8872)	Acc@1 78.125 (67.241)	Acc@5 93.750 (92.085)
Test: [600/750]	Time 0.108 (0.122)	Loss 1.1537 (0.9084)	Acc@1 56.250 (66.707)	Acc@5 90.625 (91.769)
Test: [700/750]	Time 0.119 (0.122)	Loss 1.6410 (0.9764)	Acc@1 43.750 (63.521)	Acc@5 71.875 (91.124)
 * Acc@1 62.037 Acc@5 90.433
==> training...
Epoch: [16][0/875]	Time 2.275 (2.275)	Data 1.601 (1.601)	Loss 2.3277 (2.3277)	Loss@kd 1.9527 (1.9527)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [16][100/875]	Time 0.753 (0.690)	Data 0.008 (0.023)	Loss 2.3401 (2.3418)	Loss@kd 1.9510 (1.9136)	Acc@1 59.375 (62.546)	Acc@5 98.438 (97.819)
Epoch: [16][200/875]	Time 0.656 (0.683)	Data 0.008 (0.015)	Loss 2.2853 (2.3527)	Loss@kd 1.8489 (1.9152)	Acc@1 65.625 (62.251)	Acc@5 96.875 (97.582)
Epoch: [16][300/875]	Time 0.668 (0.682)	Data 0.007 (0.013)	Loss 2.3958 (2.3613)	Loss@kd 1.9109 (1.9143)	Acc@1 57.812 (61.867)	Acc@5 96.875 (97.565)
Epoch: [16][400/875]	Time 0.654 (0.677)	Data 0.006 (0.011)	Loss 2.3646 (2.3618)	Loss@kd 2.0118 (1.9129)	Acc@1 62.500 (61.912)	Acc@5 98.438 (97.537)
Epoch: [16][500/875]	Time 0.650 (0.674)	Data 0.007 (0.010)	Loss 2.3796 (2.3651)	Loss@kd 1.9078 (1.9105)	Acc@1 56.250 (61.833)	Acc@5 100.000 (97.524)
Epoch: [16][600/875]	Time 0.674 (0.675)	Data 0.007 (0.010)	Loss 2.3778 (2.3668)	Loss@kd 1.8934 (1.9103)	Acc@1 53.125 (61.673)	Acc@5 98.438 (97.520)
Epoch: [16][700/875]	Time 0.652 (0.676)	Data 0.007 (0.010)	Loss 2.5614 (2.3660)	Loss@kd 1.8453 (1.9082)	Acc@1 48.438 (61.689)	Acc@5 93.750 (97.512)
Epoch: [16][800/875]	Time 0.661 (0.677)	Data 0.010 (0.009)	Loss 2.3642 (2.3645)	Loss@kd 1.9319 (1.9073)	Acc@1 62.500 (61.636)	Acc@5 96.875 (97.532)
 * Acc@1 61.811 Acc@5 97.559
epoch 16, total time 592.95
Test: [0/750]	Time 1.043 (1.043)	Loss 0.5617 (0.5617)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.109 (0.128)	Loss 0.2752 (0.4524)	Acc@1 90.625 (86.108)	Acc@5 100.000 (92.698)
Test: [200/750]	Time 0.110 (0.124)	Loss 1.3162 (0.4247)	Acc@1 53.125 (86.318)	Acc@5 87.500 (95.211)
Test: [300/750]	Time 0.118 (0.122)	Loss 1.7602 (0.7279)	Acc@1 15.625 (73.920)	Acc@5 84.375 (93.698)
Test: [400/750]	Time 0.119 (0.122)	Loss 0.8527 (0.9451)	Acc@1 78.125 (64.183)	Acc@5 90.625 (90.344)
Test: [500/750]	Time 0.108 (0.121)	Loss 0.5911 (0.9296)	Acc@1 84.375 (65.962)	Acc@5 96.875 (89.777)
Test: [600/750]	Time 0.144 (0.121)	Loss 1.1358 (0.9521)	Acc@1 62.500 (65.053)	Acc@5 96.875 (90.505)
Test: [700/750]	Time 0.089 (0.120)	Loss 1.6497 (1.0254)	Acc@1 40.625 (61.813)	Acc@5 81.250 (90.175)
 * Acc@1 60.871 Acc@5 89.367
==> training...
Epoch: [17][0/875]	Time 2.238 (2.238)	Data 1.600 (1.600)	Loss 2.5900 (2.5900)	Loss@kd 1.8491 (1.8491)	Acc@1 53.125 (53.125)	Acc@5 95.312 (95.312)
Epoch: [17][100/875]	Time 0.695 (0.681)	Data 0.007 (0.023)	Loss 2.2153 (2.3424)	Loss@kd 1.9211 (1.8929)	Acc@1 70.312 (62.330)	Acc@5 98.438 (97.633)
Epoch: [17][200/875]	Time 0.763 (0.680)	Data 0.007 (0.015)	Loss 2.4765 (2.3421)	Loss@kd 1.9214 (1.8892)	Acc@1 57.812 (62.111)	Acc@5 95.312 (97.645)
Epoch: [17][300/875]	Time 0.662 (0.680)	Data 0.007 (0.013)	Loss 2.3759 (2.3485)	Loss@kd 1.9296 (1.8901)	Acc@1 57.812 (62.163)	Acc@5 95.312 (97.524)
Epoch: [17][400/875]	Time 0.677 (0.680)	Data 0.007 (0.011)	Loss 2.4690 (2.3449)	Loss@kd 1.9403 (1.8908)	Acc@1 65.625 (62.399)	Acc@5 98.438 (97.537)
Epoch: [17][500/875]	Time 0.654 (0.680)	Data 0.006 (0.011)	Loss 2.0991 (2.3393)	Loss@kd 1.7887 (1.8892)	Acc@1 68.750 (62.400)	Acc@5 98.438 (97.624)
Epoch: [17][600/875]	Time 0.662 (0.680)	Data 0.007 (0.010)	Loss 2.3158 (2.3428)	Loss@kd 1.9452 (1.8898)	Acc@1 60.938 (62.232)	Acc@5 96.875 (97.660)
Epoch: [17][700/875]	Time 0.661 (0.678)	Data 0.007 (0.010)	Loss 2.2615 (2.3421)	Loss@kd 1.8110 (1.8882)	Acc@1 65.625 (62.175)	Acc@5 98.438 (97.702)
Epoch: [17][800/875]	Time 0.675 (0.678)	Data 0.007 (0.009)	Loss 2.2632 (2.3444)	Loss@kd 1.8189 (1.8881)	Acc@1 67.188 (62.100)	Acc@5 95.312 (97.681)
 * Acc@1 62.002 Acc@5 97.668
epoch 17, total time 593.48
Test: [0/750]	Time 0.853 (0.853)	Loss 0.6529 (0.6529)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.112 (0.124)	Loss 0.6642 (0.5899)	Acc@1 71.875 (82.178)	Acc@5 100.000 (90.285)
Test: [200/750]	Time 0.100 (0.120)	Loss 1.7719 (0.6510)	Acc@1 21.875 (76.539)	Acc@5 81.250 (92.926)
Test: [300/750]	Time 0.112 (0.117)	Loss 0.9565 (0.9182)	Acc@1 71.875 (63.175)	Acc@5 100.000 (91.497)
Test: [400/750]	Time 0.089 (0.117)	Loss 0.6992 (0.9383)	Acc@1 81.250 (62.913)	Acc@5 90.625 (92.184)
Test: [500/750]	Time 0.105 (0.117)	Loss 0.7357 (0.9289)	Acc@1 81.250 (64.833)	Acc@5 93.750 (91.486)
Test: [600/750]	Time 0.166 (0.117)	Loss 0.7286 (0.9349)	Acc@1 78.125 (65.443)	Acc@5 96.875 (91.311)
Test: [700/750]	Time 0.113 (0.116)	Loss 1.2602 (0.9434)	Acc@1 43.750 (65.045)	Acc@5 81.250 (91.597)
 * Acc@1 64.592 Acc@5 91.325
saving the best model!
==> training...
Epoch: [18][0/875]	Time 2.241 (2.241)	Data 1.558 (1.558)	Loss 2.5439 (2.5439)	Loss@kd 1.8864 (1.8864)	Acc@1 56.250 (56.250)	Acc@5 93.750 (93.750)
Epoch: [18][100/875]	Time 0.667 (0.696)	Data 0.007 (0.023)	Loss 2.2565 (2.3206)	Loss@kd 1.8555 (1.8721)	Acc@1 62.500 (63.041)	Acc@5 100.000 (97.556)
Epoch: [18][200/875]	Time 0.679 (0.688)	Data 0.007 (0.015)	Loss 2.6728 (2.3190)	Loss@kd 2.2401 (1.8771)	Acc@1 54.688 (62.430)	Acc@5 96.875 (97.777)
Epoch: [18][300/875]	Time 0.666 (0.683)	Data 0.007 (0.012)	Loss 2.4720 (2.3221)	Loss@kd 1.9111 (1.8780)	Acc@1 60.938 (62.318)	Acc@5 95.312 (97.716)
Epoch: [18][400/875]	Time 0.669 (0.678)	Data 0.007 (0.011)	Loss 2.3388 (2.3216)	Loss@kd 1.9064 (1.8761)	Acc@1 64.062 (62.153)	Acc@5 100.000 (97.771)
Epoch: [18][500/875]	Time 0.652 (0.679)	Data 0.007 (0.010)	Loss 2.0763 (2.3179)	Loss@kd 1.8597 (1.8744)	Acc@1 65.625 (62.229)	Acc@5 100.000 (97.801)
Epoch: [18][600/875]	Time 0.737 (0.680)	Data 0.007 (0.010)	Loss 2.3489 (2.3174)	Loss@kd 1.8830 (1.8728)	Acc@1 62.500 (62.321)	Acc@5 100.000 (97.798)
Epoch: [18][700/875]	Time 0.686 (0.681)	Data 0.007 (0.010)	Loss 2.3152 (2.3209)	Loss@kd 1.8360 (1.8722)	Acc@1 62.500 (62.181)	Acc@5 96.875 (97.776)
Epoch: [18][800/875]	Time 0.722 (0.681)	Data 0.007 (0.009)	Loss 2.3886 (2.3224)	Loss@kd 1.8062 (1.8705)	Acc@1 65.625 (62.147)	Acc@5 93.750 (97.733)
 * Acc@1 62.143 Acc@5 97.736
epoch 18, total time 596.50
Test: [0/750]	Time 0.932 (0.932)	Loss 0.6995 (0.6995)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.122 (0.131)	Loss 0.3347 (0.5359)	Acc@1 90.625 (83.354)	Acc@5 100.000 (90.811)
Test: [200/750]	Time 0.123 (0.125)	Loss 1.3572 (0.4855)	Acc@1 43.750 (84.919)	Acc@5 87.500 (94.419)
Test: [300/750]	Time 0.100 (0.123)	Loss 1.2355 (0.7235)	Acc@1 50.000 (74.315)	Acc@5 100.000 (93.708)
Test: [400/750]	Time 0.177 (0.123)	Loss 0.8068 (0.8390)	Acc@1 78.125 (68.633)	Acc@5 90.625 (93.353)
Test: [500/750]	Time 0.127 (0.122)	Loss 0.7004 (0.8425)	Acc@1 71.875 (69.636)	Acc@5 96.875 (92.440)
Test: [600/750]	Time 0.091 (0.121)	Loss 1.0334 (0.8763)	Acc@1 68.750 (68.376)	Acc@5 96.875 (92.221)
Test: [700/750]	Time 0.098 (0.120)	Loss 1.6027 (0.9454)	Acc@1 37.500 (64.970)	Acc@5 75.000 (91.646)
 * Acc@1 63.337 Acc@5 90.912
==> training...
Epoch: [19][0/875]	Time 2.187 (2.187)	Data 1.559 (1.559)	Loss 2.3234 (2.3234)	Loss@kd 1.8165 (1.8165)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [19][100/875]	Time 0.668 (0.694)	Data 0.007 (0.023)	Loss 2.4413 (2.3174)	Loss@kd 1.8915 (1.8628)	Acc@1 57.812 (62.299)	Acc@5 98.438 (97.726)
Epoch: [19][200/875]	Time 0.669 (0.688)	Data 0.007 (0.015)	Loss 2.2054 (2.3145)	Loss@kd 1.7727 (1.8617)	Acc@1 53.125 (62.259)	Acc@5 96.875 (97.738)
Epoch: [19][300/875]	Time 0.772 (0.687)	Data 0.007 (0.013)	Loss 2.1378 (2.3157)	Loss@kd 1.8918 (1.8584)	Acc@1 65.625 (62.064)	Acc@5 100.000 (97.768)
Epoch: [19][400/875]	Time 0.669 (0.685)	Data 0.007 (0.011)	Loss 2.3564 (2.3110)	Loss@kd 1.9532 (1.8583)	Acc@1 67.188 (62.344)	Acc@5 98.438 (97.795)
Epoch: [19][500/875]	Time 0.666 (0.685)	Data 0.007 (0.011)	Loss 2.3679 (2.3081)	Loss@kd 1.8700 (1.8565)	Acc@1 53.125 (62.447)	Acc@5 100.000 (97.832)
Epoch: [19][600/875]	Time 0.654 (0.682)	Data 0.007 (0.010)	Loss 2.1718 (2.3064)	Loss@kd 1.7345 (1.8534)	Acc@1 59.375 (62.323)	Acc@5 100.000 (97.775)
Epoch: [19][700/875]	Time 0.649 (0.681)	Data 0.009 (0.010)	Loss 2.2260 (2.3045)	Loss@kd 1.7667 (1.8534)	Acc@1 62.500 (62.389)	Acc@5 100.000 (97.771)
Epoch: [19][800/875]	Time 0.666 (0.681)	Data 0.008 (0.010)	Loss 2.3107 (2.3066)	Loss@kd 1.7742 (1.8522)	Acc@1 56.250 (62.248)	Acc@5 96.875 (97.745)
 * Acc@1 62.352 Acc@5 97.741
epoch 19, total time 596.03
Test: [0/750]	Time 0.866 (0.866)	Loss 0.6709 (0.6709)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.128 (0.128)	Loss 0.4742 (0.5823)	Acc@1 87.500 (82.457)	Acc@5 100.000 (90.130)
Test: [200/750]	Time 0.117 (0.124)	Loss 1.5729 (0.5983)	Acc@1 31.250 (79.944)	Acc@5 87.500 (93.050)
Test: [300/750]	Time 0.116 (0.121)	Loss 1.3979 (0.8681)	Acc@1 43.750 (67.255)	Acc@5 96.875 (91.715)
Test: [400/750]	Time 0.110 (0.120)	Loss 0.6087 (0.9730)	Acc@1 81.250 (61.666)	Acc@5 93.750 (91.778)
Test: [500/750]	Time 0.128 (0.121)	Loss 0.7523 (0.9237)	Acc@1 78.125 (64.889)	Acc@5 93.750 (91.698)
Test: [600/750]	Time 0.119 (0.120)	Loss 0.9020 (0.9311)	Acc@1 68.750 (65.173)	Acc@5 100.000 (91.540)
Test: [700/750]	Time 0.122 (0.120)	Loss 0.9312 (0.9467)	Acc@1 75.000 (64.769)	Acc@5 84.375 (91.655)
 * Acc@1 64.842 Acc@5 91.688
saving the best model!
==> training...
Epoch: [20][0/875]	Time 2.268 (2.268)	Data 1.598 (1.598)	Loss 2.4432 (2.4432)	Loss@kd 1.7723 (1.7723)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [20][100/875]	Time 0.656 (0.695)	Data 0.007 (0.023)	Loss 2.4137 (2.3121)	Loss@kd 1.8842 (1.8442)	Acc@1 56.250 (61.340)	Acc@5 100.000 (97.942)
Epoch: [20][200/875]	Time 0.662 (0.682)	Data 0.007 (0.015)	Loss 2.1494 (2.2935)	Loss@kd 1.8267 (1.8440)	Acc@1 71.875 (62.407)	Acc@5 100.000 (97.909)
Epoch: [20][300/875]	Time 0.661 (0.676)	Data 0.007 (0.013)	Loss 2.4079 (2.2950)	Loss@kd 1.8056 (1.8403)	Acc@1 60.938 (62.495)	Acc@5 100.000 (97.804)
Epoch: [20][400/875]	Time 0.697 (0.676)	Data 0.007 (0.011)	Loss 2.0660 (2.2946)	Loss@kd 1.7970 (1.8402)	Acc@1 62.500 (62.504)	Acc@5 100.000 (97.857)
Epoch: [20][500/875]	Time 0.656 (0.677)	Data 0.007 (0.011)	Loss 2.1075 (2.2928)	Loss@kd 1.7906 (1.8395)	Acc@1 67.188 (62.422)	Acc@5 98.438 (97.783)
Epoch: [20][600/875]	Time 0.698 (0.677)	Data 0.007 (0.010)	Loss 2.0838 (2.2868)	Loss@kd 1.7824 (1.8366)	Acc@1 64.062 (62.594)	Acc@5 100.000 (97.829)
Epoch: [20][700/875]	Time 0.734 (0.677)	Data 0.007 (0.010)	Loss 2.4464 (2.2865)	Loss@kd 1.7920 (1.8362)	Acc@1 56.250 (62.611)	Acc@5 96.875 (97.838)
Epoch: [20][800/875]	Time 0.682 (0.677)	Data 0.007 (0.009)	Loss 2.1243 (2.2861)	Loss@kd 1.8171 (1.8357)	Acc@1 71.875 (62.711)	Acc@5 98.438 (97.778)
 * Acc@1 62.775 Acc@5 97.805
epoch 20, total time 591.29
Test: [0/750]	Time 0.962 (0.962)	Loss 0.6647 (0.6647)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.105 (0.122)	Loss 0.6833 (0.5762)	Acc@1 71.875 (82.364)	Acc@5 96.875 (90.842)
Test: [200/750]	Time 0.096 (0.116)	Loss 1.3860 (0.5965)	Acc@1 31.250 (79.275)	Acc@5 84.375 (93.890)
Test: [300/750]	Time 0.100 (0.113)	Loss 0.9723 (0.8203)	Acc@1 53.125 (69.113)	Acc@5 100.000 (93.096)
Test: [400/750]	Time 0.100 (0.111)	Loss 0.6639 (0.8722)	Acc@1 78.125 (66.817)	Acc@5 93.750 (93.430)
Test: [500/750]	Time 0.100 (0.113)	Loss 0.7255 (0.8631)	Acc@1 75.000 (67.927)	Acc@5 96.875 (92.920)
Test: [600/750]	Time 0.124 (0.113)	Loss 0.8622 (0.8880)	Acc@1 78.125 (67.596)	Acc@5 90.625 (92.497)
Test: [700/750]	Time 0.159 (0.114)	Loss 2.0171 (0.9596)	Acc@1 28.125 (64.577)	Acc@5 71.875 (91.303)
 * Acc@1 62.500 Acc@5 90.092
==> training...
Epoch: [21][0/875]	Time 2.325 (2.325)	Data 1.619 (1.619)	Loss 2.2091 (2.2091)	Loss@kd 1.7710 (1.7710)	Acc@1 70.312 (70.312)	Acc@5 93.750 (93.750)
Epoch: [21][100/875]	Time 0.673 (0.699)	Data 0.007 (0.023)	Loss 2.2295 (2.2547)	Loss@kd 1.8745 (1.8232)	Acc@1 64.062 (63.970)	Acc@5 100.000 (97.973)
Epoch: [21][200/875]	Time 0.645 (0.691)	Data 0.007 (0.016)	Loss 2.1631 (2.2650)	Loss@kd 1.7789 (1.8213)	Acc@1 67.188 (63.262)	Acc@5 98.438 (97.715)
Epoch: [21][300/875]	Time 0.768 (0.689)	Data 0.007 (0.013)	Loss 2.1778 (2.2670)	Loss@kd 1.8049 (1.8194)	Acc@1 67.188 (63.107)	Acc@5 98.438 (97.841)
Epoch: [21][400/875]	Time 0.667 (0.687)	Data 0.007 (0.011)	Loss 2.1572 (2.2662)	Loss@kd 1.7477 (1.8180)	Acc@1 67.188 (63.084)	Acc@5 98.438 (97.802)
Epoch: [21][500/875]	Time 0.654 (0.683)	Data 0.008 (0.011)	Loss 2.2426 (2.2653)	Loss@kd 1.8154 (1.8175)	Acc@1 57.812 (63.027)	Acc@5 100.000 (97.786)
Epoch: [21][600/875]	Time 0.684 (0.680)	Data 0.007 (0.010)	Loss 2.5221 (2.2670)	Loss@kd 1.7806 (1.8158)	Acc@1 57.812 (62.851)	Acc@5 95.312 (97.769)
Epoch: [21][700/875]	Time 0.702 (0.680)	Data 0.010 (0.010)	Loss 2.4344 (2.2641)	Loss@kd 1.7738 (1.8154)	Acc@1 57.812 (62.988)	Acc@5 93.750 (97.809)
Epoch: [21][800/875]	Time 0.677 (0.680)	Data 0.008 (0.009)	Loss 2.3769 (2.2627)	Loss@kd 1.7956 (1.8150)	Acc@1 53.125 (63.009)	Acc@5 100.000 (97.854)
 * Acc@1 63.039 Acc@5 97.855
epoch 21, total time 595.54
Test: [0/750]	Time 0.831 (0.831)	Loss 0.5773 (0.5773)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.116 (0.127)	Loss 0.4704 (0.5214)	Acc@1 81.250 (83.354)	Acc@5 96.875 (91.337)
Test: [200/750]	Time 0.115 (0.123)	Loss 1.1293 (0.5204)	Acc@1 37.500 (82.478)	Acc@5 96.875 (94.092)
Test: [300/750]	Time 0.120 (0.122)	Loss 1.1292 (0.7194)	Acc@1 56.250 (73.287)	Acc@5 100.000 (94.383)
Test: [400/750]	Time 0.118 (0.119)	Loss 0.7074 (0.8277)	Acc@1 75.000 (68.508)	Acc@5 93.750 (93.711)
Test: [500/750]	Time 0.098 (0.119)	Loss 0.6890 (0.8219)	Acc@1 75.000 (69.605)	Acc@5 96.875 (93.033)
Test: [600/750]	Time 0.108 (0.119)	Loss 1.0604 (0.8499)	Acc@1 59.375 (68.714)	Acc@5 90.625 (92.856)
Test: [700/750]	Time 0.098 (0.119)	Loss 1.5791 (0.9209)	Acc@1 43.750 (65.794)	Acc@5 81.250 (91.838)
 * Acc@1 64.300 Acc@5 90.800
==> training...
Epoch: [22][0/875]	Time 2.208 (2.208)	Data 1.552 (1.552)	Loss 2.4355 (2.4355)	Loss@kd 1.7452 (1.7452)	Acc@1 57.812 (57.812)	Acc@5 89.062 (89.062)
Epoch: [22][100/875]	Time 0.666 (0.691)	Data 0.007 (0.022)	Loss 2.2833 (2.2318)	Loss@kd 1.8471 (1.8064)	Acc@1 64.062 (63.815)	Acc@5 98.438 (97.664)
Epoch: [22][200/875]	Time 0.661 (0.677)	Data 0.007 (0.015)	Loss 2.2863 (2.2438)	Loss@kd 1.9204 (1.8081)	Acc@1 65.625 (63.270)	Acc@5 95.312 (97.785)
Epoch: [22][300/875]	Time 0.771 (0.677)	Data 0.007 (0.012)	Loss 2.0638 (2.2442)	Loss@kd 1.8032 (1.8055)	Acc@1 67.188 (63.268)	Acc@5 100.000 (97.809)
Epoch: [22][400/875]	Time 0.652 (0.679)	Data 0.010 (0.011)	Loss 1.9910 (2.2413)	Loss@kd 1.7862 (1.8039)	Acc@1 75.000 (63.275)	Acc@5 96.875 (97.865)
Epoch: [22][500/875]	Time 0.646 (0.679)	Data 0.008 (0.010)	Loss 1.8975 (2.2429)	Loss@kd 1.8146 (1.8041)	Acc@1 82.812 (63.355)	Acc@5 98.438 (97.783)
Epoch: [22][600/875]	Time 0.678 (0.679)	Data 0.006 (0.010)	Loss 2.2400 (2.2463)	Loss@kd 1.8046 (1.8051)	Acc@1 59.375 (63.270)	Acc@5 98.438 (97.837)
Epoch: [22][700/875]	Time 0.756 (0.680)	Data 0.007 (0.009)	Loss 2.2309 (2.2441)	Loss@kd 1.7966 (1.8033)	Acc@1 60.938 (63.351)	Acc@5 100.000 (97.849)
Epoch: [22][800/875]	Time 0.654 (0.678)	Data 0.007 (0.009)	Loss 1.9784 (2.2467)	Loss@kd 1.7861 (1.8027)	Acc@1 70.312 (63.296)	Acc@5 98.438 (97.833)
 * Acc@1 63.177 Acc@5 97.820
epoch 22, total time 592.55
Test: [0/750]	Time 0.961 (0.961)	Loss 0.6497 (0.6497)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.125 (0.131)	Loss 0.5143 (0.5862)	Acc@1 78.125 (82.364)	Acc@5 96.875 (90.192)
Test: [200/750]	Time 0.098 (0.125)	Loss 1.5502 (0.6010)	Acc@1 31.250 (79.338)	Acc@5 81.250 (93.175)
Test: [300/750]	Time 0.116 (0.123)	Loss 1.3981 (0.8737)	Acc@1 37.500 (65.833)	Acc@5 93.750 (92.265)
Test: [400/750]	Time 0.131 (0.123)	Loss 0.8483 (0.9769)	Acc@1 75.000 (60.723)	Acc@5 90.625 (91.677)
Test: [500/750]	Time 0.101 (0.122)	Loss 0.6340 (0.9544)	Acc@1 78.125 (63.118)	Acc@5 100.000 (91.143)
Test: [600/750]	Time 0.117 (0.121)	Loss 0.7217 (0.9414)	Acc@1 81.250 (64.595)	Acc@5 96.875 (91.270)
Test: [700/750]	Time 0.128 (0.121)	Loss 0.8452 (0.9308)	Acc@1 71.875 (65.215)	Acc@5 90.625 (91.780)
 * Acc@1 65.704 Acc@5 91.879
saving the best model!
==> training...
Epoch: [23][0/875]	Time 2.181 (2.181)	Data 1.510 (1.510)	Loss 2.0761 (2.0761)	Loss@kd 1.7392 (1.7392)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [23][100/875]	Time 0.660 (0.698)	Data 0.007 (0.022)	Loss 2.2091 (2.2234)	Loss@kd 1.7210 (1.7772)	Acc@1 57.812 (62.871)	Acc@5 96.875 (98.097)
Epoch: [23][200/875]	Time 0.671 (0.690)	Data 0.010 (0.015)	Loss 2.3868 (2.2243)	Loss@kd 1.8063 (1.7811)	Acc@1 62.500 (63.759)	Acc@5 96.875 (98.041)
Epoch: [23][300/875]	Time 0.666 (0.687)	Data 0.006 (0.012)	Loss 2.2916 (2.2221)	Loss@kd 1.7802 (1.7842)	Acc@1 62.500 (63.678)	Acc@5 96.875 (98.017)
Epoch: [23][400/875]	Time 0.657 (0.683)	Data 0.007 (0.011)	Loss 2.0972 (2.2229)	Loss@kd 1.6915 (1.7859)	Acc@1 65.625 (63.891)	Acc@5 100.000 (97.997)
Epoch: [23][500/875]	Time 0.760 (0.677)	Data 0.008 (0.010)	Loss 2.0792 (2.2199)	Loss@kd 1.8775 (1.7855)	Acc@1 73.438 (63.963)	Acc@5 98.438 (97.992)
Epoch: [23][600/875]	Time 0.668 (0.678)	Data 0.007 (0.010)	Loss 2.3234 (2.2215)	Loss@kd 1.8211 (1.7841)	Acc@1 54.688 (63.899)	Acc@5 98.438 (97.959)
Epoch: [23][700/875]	Time 0.661 (0.678)	Data 0.007 (0.009)	Loss 2.3044 (2.2209)	Loss@kd 1.7419 (1.7828)	Acc@1 65.625 (63.855)	Acc@5 93.750 (97.927)
Epoch: [23][800/875]	Time 0.650 (0.679)	Data 0.007 (0.009)	Loss 2.1175 (2.2196)	Loss@kd 1.9051 (1.7819)	Acc@1 70.312 (63.840)	Acc@5 100.000 (97.917)
 * Acc@1 63.757 Acc@5 97.909
epoch 23, total time 594.29
Test: [0/750]	Time 1.072 (1.072)	Loss 0.7213 (0.7213)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.122 (0.130)	Loss 0.3803 (0.6356)	Acc@1 84.375 (81.312)	Acc@5 100.000 (89.542)
Test: [200/750]	Time 0.122 (0.124)	Loss 1.7089 (0.5665)	Acc@1 34.375 (81.312)	Acc@5 78.125 (93.113)
Test: [300/750]	Time 0.178 (0.122)	Loss 1.4722 (0.8886)	Acc@1 37.500 (66.892)	Acc@5 90.625 (90.853)
Test: [400/750]	Time 0.126 (0.120)	Loss 0.5199 (0.9992)	Acc@1 81.250 (61.339)	Acc@5 93.750 (90.516)
Test: [500/750]	Time 0.121 (0.119)	Loss 0.6535 (0.9366)	Acc@1 75.000 (64.845)	Acc@5 100.000 (90.937)
Test: [600/750]	Time 0.200 (0.119)	Loss 0.7102 (0.9299)	Acc@1 78.125 (65.661)	Acc@5 96.875 (91.379)
Test: [700/750]	Time 0.113 (0.118)	Loss 1.0432 (0.9324)	Acc@1 65.625 (65.549)	Acc@5 84.375 (91.811)
 * Acc@1 65.433 Acc@5 91.708
==> training...
Epoch: [24][0/875]	Time 2.137 (2.137)	Data 1.521 (1.521)	Loss 2.1535 (2.1535)	Loss@kd 1.7493 (1.7493)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [24][100/875]	Time 0.647 (0.675)	Data 0.006 (0.022)	Loss 2.2542 (2.2176)	Loss@kd 1.7824 (1.7818)	Acc@1 67.188 (63.769)	Acc@5 100.000 (97.865)
Epoch: [24][200/875]	Time 0.647 (0.668)	Data 0.008 (0.015)	Loss 2.2055 (2.2148)	Loss@kd 1.8390 (1.7752)	Acc@1 64.062 (63.658)	Acc@5 98.438 (97.971)
Epoch: [24][300/875]	Time 0.658 (0.666)	Data 0.007 (0.012)	Loss 2.0708 (2.2117)	Loss@kd 1.6648 (1.7703)	Acc@1 68.750 (63.564)	Acc@5 100.000 (97.996)
Epoch: [24][400/875]	Time 0.654 (0.664)	Data 0.007 (0.011)	Loss 2.3651 (2.2108)	Loss@kd 1.7957 (1.7709)	Acc@1 54.688 (63.794)	Acc@5 100.000 (97.982)
Epoch: [24][500/875]	Time 0.644 (0.662)	Data 0.006 (0.010)	Loss 2.3157 (2.2097)	Loss@kd 1.7615 (1.7703)	Acc@1 62.500 (63.607)	Acc@5 100.000 (98.013)
Epoch: [24][600/875]	Time 0.720 (0.661)	Data 0.007 (0.010)	Loss 2.5405 (2.2107)	Loss@kd 1.7945 (1.7706)	Acc@1 51.562 (63.735)	Acc@5 93.750 (97.954)
Epoch: [24][700/875]	Time 0.627 (0.659)	Data 0.008 (0.010)	Loss 2.1171 (2.2070)	Loss@kd 1.7724 (1.7680)	Acc@1 73.438 (63.826)	Acc@5 95.312 (97.972)
Epoch: [24][800/875]	Time 0.639 (0.657)	Data 0.007 (0.009)	Loss 2.1146 (2.2051)	Loss@kd 1.7160 (1.7675)	Acc@1 67.188 (63.871)	Acc@5 100.000 (98.004)
 * Acc@1 63.966 Acc@5 97.975
epoch 24, total time 575.25
Test: [0/750]	Time 0.967 (0.967)	Loss 0.6643 (0.6643)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.137 (0.137)	Loss 0.4400 (0.5145)	Acc@1 84.375 (84.406)	Acc@5 100.000 (91.522)
Test: [200/750]	Time 0.117 (0.129)	Loss 1.1894 (0.4795)	Acc@1 46.875 (84.530)	Acc@5 90.625 (94.776)
Test: [300/750]	Time 0.126 (0.128)	Loss 1.2608 (0.7084)	Acc@1 43.750 (74.221)	Acc@5 93.750 (94.352)
Test: [400/750]	Time 0.121 (0.126)	Loss 0.7502 (0.8444)	Acc@1 84.375 (67.877)	Acc@5 87.500 (93.368)
Test: [500/750]	Time 0.112 (0.126)	Loss 0.6967 (0.8385)	Acc@1 81.250 (69.112)	Acc@5 93.750 (92.509)
Test: [600/750]	Time 0.199 (0.125)	Loss 1.0792 (0.8680)	Acc@1 62.500 (68.355)	Acc@5 90.625 (92.299)
Test: [700/750]	Time 0.135 (0.125)	Loss 1.3132 (0.9135)	Acc@1 53.125 (66.320)	Acc@5 81.250 (92.141)
 * Acc@1 65.471 Acc@5 91.875
==> training...
Epoch: [25][0/875]	Time 2.242 (2.242)	Data 1.582 (1.582)	Loss 1.9384 (1.9384)	Loss@kd 1.7411 (1.7411)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [25][100/875]	Time 0.647 (0.674)	Data 0.007 (0.023)	Loss 2.1716 (2.1789)	Loss@kd 1.7555 (1.7609)	Acc@1 60.938 (64.929)	Acc@5 98.438 (98.515)
Epoch: [25][200/875]	Time 0.728 (0.664)	Data 0.007 (0.015)	Loss 2.2848 (2.1889)	Loss@kd 1.7890 (1.7660)	Acc@1 68.750 (64.925)	Acc@5 93.750 (98.127)
Epoch: [25][300/875]	Time 0.631 (0.659)	Data 0.007 (0.012)	Loss 2.3042 (2.1965)	Loss@kd 1.7625 (1.7665)	Acc@1 57.812 (64.384)	Acc@5 96.875 (98.053)
Epoch: [25][400/875]	Time 0.641 (0.657)	Data 0.007 (0.011)	Loss 2.0316 (2.1967)	Loss@kd 1.7016 (1.7656)	Acc@1 70.312 (64.327)	Acc@5 98.438 (98.075)
Epoch: [25][500/875]	Time 0.642 (0.656)	Data 0.008 (0.010)	Loss 2.3552 (2.1991)	Loss@kd 1.7627 (1.7635)	Acc@1 60.938 (64.156)	Acc@5 98.438 (98.048)
Epoch: [25][600/875]	Time 0.740 (0.656)	Data 0.007 (0.010)	Loss 2.1257 (2.1958)	Loss@kd 1.6882 (1.7609)	Acc@1 64.062 (64.208)	Acc@5 96.875 (98.076)
Epoch: [25][700/875]	Time 0.636 (0.656)	Data 0.007 (0.010)	Loss 1.9924 (2.1939)	Loss@kd 1.6578 (1.7593)	Acc@1 62.500 (64.185)	Acc@5 98.438 (98.067)
Epoch: [25][800/875]	Time 0.662 (0.655)	Data 0.007 (0.009)	Loss 1.9910 (2.1924)	Loss@kd 1.7480 (1.7579)	Acc@1 71.875 (64.195)	Acc@5 98.438 (98.086)
 * Acc@1 64.159 Acc@5 98.068
epoch 25, total time 573.39
Test: [0/750]	Time 0.932 (0.932)	Loss 0.7060 (0.7060)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.119 (0.129)	Loss 0.4827 (0.5687)	Acc@1 81.250 (83.849)	Acc@5 100.000 (90.687)
Test: [200/750]	Time 0.128 (0.128)	Loss 1.3404 (0.5486)	Acc@1 43.750 (82.121)	Acc@5 84.375 (93.812)
Test: [300/750]	Time 0.108 (0.125)	Loss 1.1677 (0.7678)	Acc@1 40.625 (71.782)	Acc@5 93.750 (93.324)
Test: [400/750]	Time 0.116 (0.125)	Loss 0.7137 (0.8679)	Acc@1 81.250 (66.334)	Acc@5 87.500 (93.064)
Test: [500/750]	Time 0.112 (0.124)	Loss 0.9405 (0.8790)	Acc@1 68.750 (67.259)	Acc@5 87.500 (91.704)
Test: [600/750]	Time 0.115 (0.124)	Loss 0.8049 (0.9094)	Acc@1 71.875 (66.826)	Acc@5 93.750 (91.332)
Test: [700/750]	Time 0.119 (0.124)	Loss 1.2593 (0.9206)	Acc@1 50.000 (66.106)	Acc@5 90.625 (91.722)
 * Acc@1 65.625 Acc@5 91.733
==> training...
Epoch: [26][0/875]	Time 2.285 (2.285)	Data 1.598 (1.598)	Loss 2.2667 (2.2667)	Loss@kd 1.7646 (1.7646)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [26][100/875]	Time 0.635 (0.669)	Data 0.007 (0.023)	Loss 2.0106 (2.1839)	Loss@kd 1.7431 (1.7558)	Acc@1 73.438 (64.233)	Acc@5 100.000 (98.097)
Epoch: [26][200/875]	Time 0.629 (0.660)	Data 0.007 (0.015)	Loss 2.1239 (2.1919)	Loss@kd 1.6872 (1.7522)	Acc@1 67.188 (63.837)	Acc@5 93.750 (97.979)
Epoch: [26][300/875]	Time 0.695 (0.658)	Data 0.007 (0.013)	Loss 2.2134 (2.1735)	Loss@kd 1.7600 (1.7447)	Acc@1 65.625 (64.135)	Acc@5 96.875 (98.152)
Epoch: [26][400/875]	Time 0.626 (0.656)	Data 0.005 (0.011)	Loss 2.2699 (2.1736)	Loss@kd 1.8300 (1.7439)	Acc@1 60.938 (64.082)	Acc@5 98.438 (98.110)
Epoch: [26][500/875]	Time 0.641 (0.656)	Data 0.007 (0.011)	Loss 2.1642 (2.1718)	Loss@kd 1.7539 (1.7428)	Acc@1 67.188 (64.268)	Acc@5 96.875 (98.060)
Epoch: [26][600/875]	Time 0.632 (0.654)	Data 0.006 (0.010)	Loss 2.0819 (2.1695)	Loss@kd 1.6639 (1.7412)	Acc@1 60.938 (64.439)	Acc@5 100.000 (98.074)
Epoch: [26][700/875]	Time 0.647 (0.654)	Data 0.007 (0.010)	Loss 2.2036 (2.1709)	Loss@kd 1.6802 (1.7412)	Acc@1 62.500 (64.430)	Acc@5 98.438 (98.050)
Epoch: [26][800/875]	Time 0.652 (0.655)	Data 0.007 (0.009)	Loss 2.2165 (2.1733)	Loss@kd 1.7023 (1.7436)	Acc@1 56.250 (64.470)	Acc@5 96.875 (98.042)
 * Acc@1 64.471 Acc@5 98.041
epoch 26, total time 573.90
Test: [0/750]	Time 0.988 (0.988)	Loss 0.6691 (0.6691)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.116 (0.138)	Loss 0.8595 (0.5934)	Acc@1 56.250 (81.869)	Acc@5 93.750 (90.594)
Test: [200/750]	Time 0.118 (0.132)	Loss 1.4007 (0.6939)	Acc@1 34.375 (73.896)	Acc@5 93.750 (93.284)
Test: [300/750]	Time 0.099 (0.129)	Loss 1.1636 (0.8816)	Acc@1 53.125 (64.981)	Acc@5 93.750 (93.428)
Test: [400/750]	Time 0.092 (0.128)	Loss 0.6885 (0.9476)	Acc@1 84.375 (61.635)	Acc@5 84.375 (93.189)
Test: [500/750]	Time 0.135 (0.127)	Loss 0.8571 (0.9208)	Acc@1 65.625 (64.091)	Acc@5 96.875 (92.322)
Test: [600/750]	Time 0.115 (0.126)	Loss 0.6878 (0.9243)	Acc@1 78.125 (65.001)	Acc@5 93.750 (91.873)
Test: [700/750]	Time 0.185 (0.125)	Loss 1.0208 (0.9119)	Acc@1 71.875 (65.835)	Acc@5 87.500 (92.176)
 * Acc@1 65.617 Acc@5 92.000
==> training...
Epoch: [27][0/875]	Time 2.283 (2.283)	Data 1.617 (1.617)	Loss 2.0465 (2.0465)	Loss@kd 1.6794 (1.6794)	Acc@1 64.062 (64.062)	Acc@5 98.438 (98.438)
Epoch: [27][100/875]	Time 0.646 (0.678)	Data 0.007 (0.023)	Loss 2.1662 (2.1466)	Loss@kd 1.8103 (1.7394)	Acc@1 64.062 (65.393)	Acc@5 98.438 (98.298)
Epoch: [27][200/875]	Time 0.652 (0.668)	Data 0.007 (0.016)	Loss 2.1625 (2.1565)	Loss@kd 1.7329 (1.7371)	Acc@1 57.812 (64.785)	Acc@5 100.000 (98.321)
Epoch: [27][300/875]	Time 0.652 (0.664)	Data 0.007 (0.013)	Loss 2.1622 (2.1613)	Loss@kd 1.6913 (1.7360)	Acc@1 71.875 (64.685)	Acc@5 95.312 (98.282)
Epoch: [27][400/875]	Time 0.641 (0.662)	Data 0.007 (0.011)	Loss 2.2404 (2.1646)	Loss@kd 1.7249 (1.7353)	Acc@1 59.375 (64.401)	Acc@5 96.875 (98.239)
Epoch: [27][500/875]	Time 0.649 (0.661)	Data 0.010 (0.011)	Loss 2.1320 (2.1667)	Loss@kd 1.7271 (1.7353)	Acc@1 64.062 (64.396)	Acc@5 100.000 (98.166)
Epoch: [27][600/875]	Time 0.642 (0.659)	Data 0.005 (0.010)	Loss 2.2237 (2.1673)	Loss@kd 1.7593 (1.7357)	Acc@1 65.625 (64.411)	Acc@5 96.875 (98.167)
Epoch: [27][700/875]	Time 0.652 (0.658)	Data 0.007 (0.010)	Loss 2.0781 (2.1664)	Loss@kd 1.6999 (1.7341)	Acc@1 67.188 (64.334)	Acc@5 100.000 (98.143)
Epoch: [27][800/875]	Time 0.655 (0.658)	Data 0.008 (0.009)	Loss 2.3750 (2.1633)	Loss@kd 1.7219 (1.7318)	Acc@1 59.375 (64.396)	Acc@5 95.312 (98.135)
 * Acc@1 64.491 Acc@5 98.137
epoch 27, total time 576.28
Test: [0/750]	Time 1.017 (1.017)	Loss 0.6803 (0.6803)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.096 (0.130)	Loss 0.5550 (0.5821)	Acc@1 75.000 (82.488)	Acc@5 96.875 (90.811)
Test: [200/750]	Time 0.099 (0.127)	Loss 1.3084 (0.5678)	Acc@1 46.875 (80.659)	Acc@5 87.500 (94.030)
Test: [300/750]	Time 0.129 (0.126)	Loss 1.2598 (0.7774)	Acc@1 43.750 (71.366)	Acc@5 100.000 (93.843)
Test: [400/750]	Time 0.103 (0.125)	Loss 0.7948 (0.8750)	Acc@1 78.125 (66.100)	Acc@5 84.375 (93.563)
Test: [500/750]	Time 0.088 (0.125)	Loss 0.6258 (0.8659)	Acc@1 84.375 (67.328)	Acc@5 96.875 (92.696)
Test: [600/750]	Time 0.089 (0.124)	Loss 0.7961 (0.8778)	Acc@1 81.250 (67.507)	Acc@5 93.750 (92.419)
Test: [700/750]	Time 0.098 (0.124)	Loss 1.1701 (0.8920)	Acc@1 56.250 (66.989)	Acc@5 87.500 (92.288)
 * Acc@1 66.646 Acc@5 91.912
saving the best model!
==> training...
Epoch: [28][0/875]	Time 2.329 (2.329)	Data 1.569 (1.569)	Loss 2.0955 (2.0955)	Loss@kd 1.6436 (1.6436)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [28][100/875]	Time 0.645 (0.673)	Data 0.008 (0.023)	Loss 2.0935 (2.1293)	Loss@kd 1.7400 (1.7125)	Acc@1 70.312 (65.563)	Acc@5 98.438 (98.144)
Epoch: [28][200/875]	Time 0.650 (0.665)	Data 0.007 (0.015)	Loss 2.2953 (2.1278)	Loss@kd 1.7608 (1.7132)	Acc@1 64.062 (65.672)	Acc@5 96.875 (98.165)
Epoch: [28][300/875]	Time 0.649 (0.662)	Data 0.007 (0.013)	Loss 1.9650 (2.1309)	Loss@kd 1.6911 (1.7121)	Acc@1 73.438 (65.381)	Acc@5 100.000 (98.199)
Epoch: [28][400/875]	Time 0.631 (0.660)	Data 0.007 (0.011)	Loss 2.2317 (2.1343)	Loss@kd 1.7083 (1.7154)	Acc@1 68.750 (65.473)	Acc@5 98.438 (98.130)
Epoch: [28][500/875]	Time 0.652 (0.659)	Data 0.008 (0.011)	Loss 2.1524 (2.1392)	Loss@kd 1.6992 (1.7158)	Acc@1 65.625 (65.254)	Acc@5 95.312 (98.154)
Epoch: [28][600/875]	Time 0.636 (0.657)	Data 0.007 (0.010)	Loss 2.1548 (2.1398)	Loss@kd 1.6745 (1.7153)	Acc@1 65.625 (65.183)	Acc@5 98.438 (98.136)
Epoch: [28][700/875]	Time 0.639 (0.656)	Data 0.007 (0.010)	Loss 2.0834 (2.1400)	Loss@kd 1.7089 (1.7152)	Acc@1 70.312 (65.248)	Acc@5 98.438 (98.134)
Epoch: [28][800/875]	Time 0.712 (0.656)	Data 0.007 (0.009)	Loss 2.2324 (2.1404)	Loss@kd 1.6657 (1.7138)	Acc@1 65.625 (65.266)	Acc@5 96.875 (98.096)
 * Acc@1 65.198 Acc@5 98.084
epoch 28, total time 573.35
Test: [0/750]	Time 1.039 (1.039)	Loss 0.6039 (0.6039)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.118 (0.141)	Loss 0.5512 (0.5847)	Acc@1 81.250 (82.364)	Acc@5 96.875 (91.089)
Test: [200/750]	Time 0.127 (0.137)	Loss 1.4528 (0.6057)	Acc@1 40.625 (78.840)	Acc@5 90.625 (93.937)
Test: [300/750]	Time 0.113 (0.132)	Loss 1.2413 (0.8372)	Acc@1 50.000 (68.252)	Acc@5 96.875 (93.314)
Test: [400/750]	Time 0.095 (0.130)	Loss 0.8922 (0.9265)	Acc@1 71.875 (63.568)	Acc@5 87.500 (93.329)
Test: [500/750]	Time 0.116 (0.129)	Loss 0.8425 (0.9257)	Acc@1 75.000 (64.533)	Acc@5 96.875 (92.184)
Test: [600/750]	Time 0.122 (0.128)	Loss 0.6814 (0.9418)	Acc@1 84.375 (64.949)	Acc@5 93.750 (91.639)
Test: [700/750]	Time 0.129 (0.127)	Loss 1.0421 (0.9282)	Acc@1 65.625 (65.607)	Acc@5 87.500 (91.940)
 * Acc@1 65.779 Acc@5 91.871
==> training...
Epoch: [29][0/875]	Time 2.281 (2.281)	Data 1.592 (1.592)	Loss 2.1844 (2.1844)	Loss@kd 1.7784 (1.7784)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [29][100/875]	Time 0.633 (0.668)	Data 0.007 (0.023)	Loss 1.6822 (2.0992)	Loss@kd 1.6000 (1.7021)	Acc@1 87.500 (66.770)	Acc@5 100.000 (98.360)
Epoch: [29][200/875]	Time 0.633 (0.659)	Data 0.007 (0.015)	Loss 2.0262 (2.1150)	Loss@kd 1.7623 (1.7016)	Acc@1 68.750 (66.060)	Acc@5 100.000 (98.228)
Epoch: [29][300/875]	Time 0.645 (0.655)	Data 0.010 (0.013)	Loss 2.0345 (2.1159)	Loss@kd 1.6484 (1.6999)	Acc@1 60.938 (65.838)	Acc@5 100.000 (98.204)
Epoch: [29][400/875]	Time 0.651 (0.654)	Data 0.008 (0.011)	Loss 2.1524 (2.1196)	Loss@kd 1.6936 (1.7001)	Acc@1 62.500 (65.602)	Acc@5 98.438 (98.102)
Epoch: [29][500/875]	Time 0.660 (0.654)	Data 0.007 (0.010)	Loss 2.0964 (2.1199)	Loss@kd 1.6935 (1.7000)	Acc@1 62.500 (65.609)	Acc@5 100.000 (98.169)
Epoch: [29][600/875]	Time 0.634 (0.653)	Data 0.007 (0.010)	Loss 2.1101 (2.1204)	Loss@kd 1.6067 (1.6996)	Acc@1 64.062 (65.518)	Acc@5 100.000 (98.170)
Epoch: [29][700/875]	Time 0.649 (0.653)	Data 0.007 (0.010)	Loss 2.0695 (2.1192)	Loss@kd 1.7000 (1.6997)	Acc@1 70.312 (65.545)	Acc@5 100.000 (98.157)
Epoch: [29][800/875]	Time 0.641 (0.653)	Data 0.007 (0.009)	Loss 2.3115 (2.1256)	Loss@kd 1.6996 (1.7006)	Acc@1 57.812 (65.303)	Acc@5 89.062 (98.121)
 * Acc@1 65.195 Acc@5 98.120
epoch 29, total time 572.18
Test: [0/750]	Time 0.932 (0.932)	Loss 0.7448 (0.7448)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.118 (0.140)	Loss 0.4000 (0.5934)	Acc@1 81.250 (83.106)	Acc@5 100.000 (90.037)
Test: [200/750]	Time 0.119 (0.131)	Loss 1.6832 (0.5462)	Acc@1 28.125 (82.494)	Acc@5 78.125 (93.486)
Test: [300/750]	Time 0.185 (0.129)	Loss 1.1384 (0.8609)	Acc@1 59.375 (67.380)	Acc@5 100.000 (91.580)
Test: [400/750]	Time 0.111 (0.128)	Loss 0.8834 (0.9055)	Acc@1 71.875 (65.352)	Acc@5 84.375 (92.121)
Test: [500/750]	Time 0.107 (0.127)	Loss 0.7033 (0.9096)	Acc@1 81.250 (66.174)	Acc@5 96.875 (91.230)
Test: [600/750]	Time 0.128 (0.126)	Loss 0.7068 (0.9217)	Acc@1 71.875 (66.322)	Acc@5 93.750 (91.311)
Test: [700/750]	Time 0.108 (0.125)	Loss 1.2067 (0.9282)	Acc@1 46.875 (65.665)	Acc@5 84.375 (91.699)
 * Acc@1 65.404 Acc@5 91.504
==> training...
Epoch: [30][0/875]	Time 2.256 (2.256)	Data 1.583 (1.583)	Loss 2.0474 (2.0474)	Loss@kd 1.6103 (1.6103)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [30][100/875]	Time 0.633 (0.669)	Data 0.007 (0.023)	Loss 1.8738 (2.0961)	Loss@kd 1.6207 (1.6946)	Acc@1 73.438 (66.275)	Acc@5 100.000 (97.973)
Epoch: [30][200/875]	Time 0.712 (0.659)	Data 0.007 (0.015)	Loss 2.1069 (2.0862)	Loss@kd 1.7130 (1.6919)	Acc@1 70.312 (66.231)	Acc@5 98.438 (98.251)
Epoch: [30][300/875]	Time 0.639 (0.655)	Data 0.007 (0.013)	Loss 2.2751 (2.0967)	Loss@kd 1.6887 (1.6890)	Acc@1 59.375 (65.869)	Acc@5 98.438 (98.297)
Epoch: [30][400/875]	Time 0.628 (0.652)	Data 0.007 (0.011)	Loss 2.1786 (2.1009)	Loss@kd 1.7164 (1.6857)	Acc@1 67.188 (65.746)	Acc@5 95.312 (98.192)
Epoch: [30][500/875]	Time 0.624 (0.650)	Data 0.007 (0.010)	Loss 2.3452 (2.1065)	Loss@kd 1.7129 (1.6867)	Acc@1 64.062 (65.781)	Acc@5 96.875 (98.135)
Epoch: [30][600/875]	Time 0.645 (0.650)	Data 0.007 (0.010)	Loss 1.8667 (2.1107)	Loss@kd 1.7255 (1.6883)	Acc@1 78.125 (65.599)	Acc@5 100.000 (98.123)
Epoch: [30][700/875]	Time 0.636 (0.651)	Data 0.007 (0.010)	Loss 2.0337 (2.1108)	Loss@kd 1.6704 (1.6869)	Acc@1 65.625 (65.618)	Acc@5 100.000 (98.103)
Epoch: [30][800/875]	Time 0.659 (0.650)	Data 0.007 (0.009)	Loss 2.1373 (2.1087)	Loss@kd 1.6581 (1.6866)	Acc@1 53.125 (65.674)	Acc@5 100.000 (98.123)
 * Acc@1 65.584 Acc@5 98.114
epoch 30, total time 568.61
Test: [0/750]	Time 0.908 (0.908)	Loss 0.7008 (0.7008)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.197 (0.141)	Loss 0.4589 (0.5994)	Acc@1 87.500 (82.085)	Acc@5 96.875 (90.532)
Test: [200/750]	Time 0.130 (0.132)	Loss 1.5972 (0.6020)	Acc@1 21.875 (78.871)	Acc@5 87.500 (93.501)
Test: [300/750]	Time 0.122 (0.131)	Loss 1.0037 (0.8819)	Acc@1 71.875 (64.639)	Acc@5 96.875 (92.255)
Test: [400/750]	Time 0.121 (0.129)	Loss 0.8173 (0.9066)	Acc@1 71.875 (64.635)	Acc@5 87.500 (92.737)
Test: [500/750]	Time 0.117 (0.128)	Loss 0.7030 (0.9016)	Acc@1 78.125 (66.180)	Acc@5 96.875 (91.841)
Test: [600/750]	Time 0.121 (0.128)	Loss 0.6924 (0.9021)	Acc@1 78.125 (66.946)	Acc@5 93.750 (91.759)
Test: [700/750]	Time 0.131 (0.127)	Loss 1.0625 (0.9032)	Acc@1 53.125 (66.517)	Acc@5 93.750 (92.150)
 * Acc@1 66.075 Acc@5 92.108
==> training...
Epoch: [31][0/875]	Time 2.253 (2.253)	Data 1.606 (1.606)	Loss 2.3165 (2.3165)	Loss@kd 1.9173 (1.9173)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [31][100/875]	Time 0.661 (0.676)	Data 0.007 (0.023)	Loss 2.1098 (2.1103)	Loss@kd 1.6174 (1.6823)	Acc@1 68.750 (65.099)	Acc@5 98.438 (98.267)
Epoch: [31][200/875]	Time 0.661 (0.669)	Data 0.007 (0.015)	Loss 2.2722 (2.1129)	Loss@kd 1.6911 (1.6853)	Acc@1 57.812 (64.949)	Acc@5 96.875 (98.142)
Epoch: [31][300/875]	Time 0.645 (0.667)	Data 0.007 (0.013)	Loss 2.0371 (2.0998)	Loss@kd 1.6733 (1.6818)	Acc@1 75.000 (65.568)	Acc@5 98.438 (98.214)
Epoch: [31][400/875]	Time 0.655 (0.665)	Data 0.008 (0.011)	Loss 2.1217 (2.0975)	Loss@kd 1.6648 (1.6795)	Acc@1 65.625 (65.757)	Acc@5 96.875 (98.173)
Epoch: [31][500/875]	Time 0.640 (0.664)	Data 0.007 (0.011)	Loss 2.0765 (2.0996)	Loss@kd 1.6078 (1.6780)	Acc@1 65.625 (65.637)	Acc@5 98.438 (98.194)
Epoch: [31][600/875]	Time 0.737 (0.663)	Data 0.007 (0.010)	Loss 2.0874 (2.0987)	Loss@kd 1.6450 (1.6774)	Acc@1 59.375 (65.664)	Acc@5 96.875 (98.196)
Epoch: [31][700/875]	Time 0.613 (0.662)	Data 0.007 (0.010)	Loss 1.9983 (2.0972)	Loss@kd 1.7090 (1.6773)	Acc@1 71.875 (65.683)	Acc@5 100.000 (98.219)
Epoch: [31][800/875]	Time 0.611 (0.660)	Data 0.004 (0.009)	Loss 2.1111 (2.0959)	Loss@kd 1.6210 (1.6764)	Acc@1 65.625 (65.730)	Acc@5 98.438 (98.293)
 * Acc@1 65.773 Acc@5 98.289
epoch 31, total time 576.72
Test: [0/750]	Time 0.915 (0.915)	Loss 0.7486 (0.7486)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.129 (0.138)	Loss 0.5767 (0.6345)	Acc@1 75.000 (81.343)	Acc@5 96.875 (90.223)
Test: [200/750]	Time 0.128 (0.134)	Loss 1.4376 (0.6800)	Acc@1 28.125 (77.472)	Acc@5 96.875 (92.413)
Test: [300/750]	Time 0.121 (0.133)	Loss 1.2791 (0.9312)	Acc@1 43.750 (65.189)	Acc@5 90.625 (91.570)
Test: [400/750]	Time 0.131 (0.133)	Loss 0.5625 (1.0009)	Acc@1 84.375 (62.017)	Acc@5 93.750 (90.867)
Test: [500/750]	Time 0.139 (0.133)	Loss 0.3816 (0.9168)	Acc@1 87.500 (66.049)	Acc@5 100.000 (91.498)
Test: [600/750]	Time 0.102 (0.133)	Loss 1.0013 (0.8884)	Acc@1 56.250 (67.616)	Acc@5 90.625 (91.982)
Test: [700/750]	Time 0.116 (0.133)	Loss 1.3361 (0.9111)	Acc@1 53.125 (66.499)	Acc@5 81.250 (91.985)
 * Acc@1 66.088 Acc@5 91.708
==> training...
Epoch: [32][0/875]	Time 2.437 (2.437)	Data 1.663 (1.663)	Loss 1.9025 (1.9025)	Loss@kd 1.5964 (1.5964)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [32][100/875]	Time 0.616 (0.660)	Data 0.008 (0.023)	Loss 2.0927 (2.0657)	Loss@kd 1.6342 (1.6590)	Acc@1 62.500 (66.646)	Acc@5 100.000 (98.236)
Epoch: [32][200/875]	Time 0.630 (0.656)	Data 0.005 (0.015)	Loss 2.1163 (2.0660)	Loss@kd 1.6742 (1.6636)	Acc@1 64.062 (66.643)	Acc@5 98.438 (98.298)
Epoch: [32][300/875]	Time 0.640 (0.654)	Data 0.008 (0.012)	Loss 2.2265 (2.0728)	Loss@kd 1.6881 (1.6666)	Acc@1 62.500 (66.487)	Acc@5 96.875 (98.277)
Epoch: [32][400/875]	Time 0.646 (0.653)	Data 0.006 (0.011)	Loss 2.0882 (2.0741)	Loss@kd 1.6304 (1.6640)	Acc@1 62.500 (66.369)	Acc@5 96.875 (98.262)
Epoch: [32][500/875]	Time 0.643 (0.653)	Data 0.007 (0.010)	Loss 2.2547 (2.0752)	Loss@kd 1.6570 (1.6649)	Acc@1 64.062 (66.423)	Acc@5 93.750 (98.275)
Epoch: [32][600/875]	Time 0.649 (0.653)	Data 0.007 (0.009)	Loss 2.1384 (2.0803)	Loss@kd 1.5987 (1.6647)	Acc@1 59.375 (66.213)	Acc@5 100.000 (98.245)
Epoch: [32][700/875]	Time 0.647 (0.652)	Data 0.007 (0.009)	Loss 1.9952 (2.0813)	Loss@kd 1.6617 (1.6662)	Acc@1 62.500 (66.193)	Acc@5 100.000 (98.264)
Epoch: [32][800/875]	Time 0.680 (0.652)	Data 0.005 (0.009)	Loss 1.8696 (2.0811)	Loss@kd 1.6754 (1.6644)	Acc@1 70.312 (66.105)	Acc@5 100.000 (98.242)
 * Acc@1 66.012 Acc@5 98.248
epoch 32, total time 571.24
Test: [0/750]	Time 0.933 (0.933)	Loss 0.4872 (0.4872)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.117 (0.135)	Loss 0.4844 (0.4818)	Acc@1 84.375 (84.777)	Acc@5 100.000 (93.379)
Test: [200/750]	Time 0.124 (0.130)	Loss 1.0913 (0.5098)	Acc@1 46.875 (81.965)	Acc@5 93.750 (95.382)
Test: [300/750]	Time 0.112 (0.128)	Loss 1.2779 (0.7225)	Acc@1 50.000 (72.020)	Acc@5 93.750 (95.193)
Test: [400/750]	Time 0.115 (0.126)	Loss 0.6906 (0.8313)	Acc@1 75.000 (67.675)	Acc@5 93.750 (94.319)
Test: [500/750]	Time 0.116 (0.126)	Loss 0.8136 (0.8387)	Acc@1 68.750 (68.700)	Acc@5 90.625 (93.089)
Test: [600/750]	Time 0.138 (0.125)	Loss 0.9716 (0.8667)	Acc@1 65.625 (68.485)	Acc@5 87.500 (92.408)
Test: [700/750]	Time 0.115 (0.125)	Loss 1.2749 (0.8847)	Acc@1 53.125 (67.644)	Acc@5 90.625 (92.266)
 * Acc@1 67.321 Acc@5 92.104
saving the best model!
==> training...
Epoch: [33][0/875]	Time 2.184 (2.184)	Data 1.521 (1.521)	Loss 1.9944 (1.9944)	Loss@kd 1.6658 (1.6658)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [33][100/875]	Time 0.657 (0.667)	Data 0.007 (0.021)	Loss 2.0295 (2.0606)	Loss@kd 1.6907 (1.6587)	Acc@1 65.625 (66.662)	Acc@5 96.875 (98.422)
Epoch: [33][200/875]	Time 0.619 (0.657)	Data 0.007 (0.014)	Loss 2.3330 (2.0690)	Loss@kd 1.6293 (1.6596)	Acc@1 53.125 (66.200)	Acc@5 95.312 (98.204)
Epoch: [33][300/875]	Time 0.631 (0.654)	Data 0.007 (0.012)	Loss 2.0742 (2.0695)	Loss@kd 1.7500 (1.6563)	Acc@1 65.625 (66.160)	Acc@5 98.438 (98.225)
Epoch: [33][400/875]	Time 0.635 (0.651)	Data 0.007 (0.011)	Loss 2.1061 (2.0731)	Loss@kd 1.7009 (1.6554)	Acc@1 62.500 (66.011)	Acc@5 100.000 (98.247)
Epoch: [33][500/875]	Time 0.628 (0.651)	Data 0.005 (0.010)	Loss 2.0456 (2.0743)	Loss@kd 1.6608 (1.6532)	Acc@1 64.062 (65.996)	Acc@5 100.000 (98.269)
Epoch: [33][600/875]	Time 0.632 (0.650)	Data 0.007 (0.009)	Loss 2.0852 (2.0705)	Loss@kd 1.6156 (1.6518)	Acc@1 65.625 (66.109)	Acc@5 100.000 (98.250)
Epoch: [33][700/875]	Time 0.716 (0.650)	Data 0.007 (0.009)	Loss 2.0216 (2.0710)	Loss@kd 1.6340 (1.6520)	Acc@1 68.750 (66.158)	Acc@5 98.438 (98.230)
Epoch: [33][800/875]	Time 0.652 (0.650)	Data 0.005 (0.009)	Loss 2.0711 (2.0687)	Loss@kd 1.6332 (1.6504)	Acc@1 62.500 (66.193)	Acc@5 96.875 (98.237)
 * Acc@1 66.209 Acc@5 98.266
epoch 33, total time 568.80
Test: [0/750]	Time 0.866 (0.866)	Loss 0.7821 (0.7821)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.126 (0.134)	Loss 0.5841 (0.7242)	Acc@1 78.125 (80.569)	Acc@5 96.875 (88.985)
Test: [200/750]	Time 0.178 (0.132)	Loss 1.4457 (0.7129)	Acc@1 34.375 (76.290)	Acc@5 90.625 (92.273)
Test: [300/750]	Time 0.112 (0.130)	Loss 0.8365 (0.8965)	Acc@1 68.750 (65.199)	Acc@5 100.000 (92.608)
Test: [400/750]	Time 0.103 (0.129)	Loss 0.8584 (0.8935)	Acc@1 84.375 (66.007)	Acc@5 87.500 (93.197)
Test: [500/750]	Time 0.123 (0.128)	Loss 0.8174 (0.9021)	Acc@1 68.750 (66.735)	Acc@5 93.750 (92.297)
Test: [600/750]	Time 0.094 (0.127)	Loss 0.7971 (0.9209)	Acc@1 62.500 (66.504)	Acc@5 100.000 (91.727)
Test: [700/750]	Time 0.186 (0.127)	Loss 1.0929 (0.9262)	Acc@1 59.375 (65.933)	Acc@5 93.750 (92.052)
 * Acc@1 65.387 Acc@5 92.071
==> training...
Epoch: [34][0/875]	Time 2.262 (2.262)	Data 1.579 (1.579)	Loss 1.9573 (1.9573)	Loss@kd 1.6375 (1.6375)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [34][100/875]	Time 0.640 (0.668)	Data 0.007 (0.022)	Loss 2.0251 (2.0574)	Loss@kd 1.6493 (1.6459)	Acc@1 67.188 (66.646)	Acc@5 98.438 (98.113)
Epoch: [34][200/875]	Time 0.635 (0.659)	Data 0.007 (0.015)	Loss 1.8850 (2.0572)	Loss@kd 1.6061 (1.6429)	Acc@1 71.875 (66.348)	Acc@5 100.000 (98.360)
Epoch: [34][300/875]	Time 0.648 (0.656)	Data 0.007 (0.012)	Loss 2.0402 (2.0487)	Loss@kd 1.7315 (1.6427)	Acc@1 75.000 (66.788)	Acc@5 98.438 (98.303)
Epoch: [34][400/875]	Time 0.628 (0.654)	Data 0.007 (0.011)	Loss 1.8993 (2.0487)	Loss@kd 1.6657 (1.6423)	Acc@1 82.812 (66.880)	Acc@5 98.438 (98.282)
Epoch: [34][500/875]	Time 0.645 (0.653)	Data 0.006 (0.010)	Loss 2.0442 (2.0482)	Loss@kd 1.5717 (1.6421)	Acc@1 70.312 (66.745)	Acc@5 96.875 (98.288)
Epoch: [34][600/875]	Time 0.651 (0.651)	Data 0.006 (0.010)	Loss 2.1310 (2.0497)	Loss@kd 1.6117 (1.6426)	Acc@1 56.250 (66.652)	Acc@5 98.438 (98.347)
Epoch: [34][700/875]	Time 0.622 (0.651)	Data 0.005 (0.009)	Loss 1.9114 (2.0539)	Loss@kd 1.5098 (1.6432)	Acc@1 67.188 (66.497)	Acc@5 100.000 (98.337)
Epoch: [34][800/875]	Time 0.729 (0.650)	Data 0.007 (0.009)	Loss 1.9695 (2.0546)	Loss@kd 1.6027 (1.6418)	Acc@1 67.188 (66.386)	Acc@5 96.875 (98.319)
 * Acc@1 66.473 Acc@5 98.325
epoch 34, total time 569.30
Test: [0/750]	Time 0.970 (0.970)	Loss 0.5230 (0.5230)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.123 (0.140)	Loss 0.3593 (0.4592)	Acc@1 90.625 (85.860)	Acc@5 96.875 (92.915)
Test: [200/750]	Time 0.141 (0.136)	Loss 1.0137 (0.4395)	Acc@1 56.250 (86.241)	Acc@5 96.875 (95.398)
Test: [300/750]	Time 0.126 (0.134)	Loss 1.5855 (0.6571)	Acc@1 18.750 (77.357)	Acc@5 90.625 (94.965)
Test: [400/750]	Time 0.116 (0.133)	Loss 0.7046 (0.8595)	Acc@1 75.000 (67.371)	Acc@5 87.500 (92.714)
Test: [500/750]	Time 0.217 (0.132)	Loss 0.6153 (0.8381)	Acc@1 71.875 (68.756)	Acc@5 100.000 (92.334)
Test: [600/750]	Time 0.104 (0.132)	Loss 1.0965 (0.8567)	Acc@1 59.375 (68.277)	Acc@5 90.625 (92.419)
Test: [700/750]	Time 0.130 (0.131)	Loss 1.2394 (0.8875)	Acc@1 53.125 (66.896)	Acc@5 87.500 (92.377)
 * Acc@1 66.646 Acc@5 92.242
==> training...
Epoch: [35][0/875]	Time 2.213 (2.213)	Data 1.578 (1.578)	Loss 2.0613 (2.0613)	Loss@kd 1.6609 (1.6609)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [35][100/875]	Time 0.635 (0.665)	Data 0.007 (0.022)	Loss 2.0868 (2.0201)	Loss@kd 1.6152 (1.6211)	Acc@1 62.500 (67.574)	Acc@5 96.875 (98.546)
Epoch: [35][200/875]	Time 0.634 (0.657)	Data 0.005 (0.015)	Loss 1.8774 (2.0255)	Loss@kd 1.6285 (1.6283)	Acc@1 76.562 (67.257)	Acc@5 98.438 (98.577)
Epoch: [35][300/875]	Time 0.633 (0.654)	Data 0.007 (0.012)	Loss 1.9800 (2.0330)	Loss@kd 1.6397 (1.6302)	Acc@1 73.438 (67.110)	Acc@5 95.312 (98.531)
Epoch: [35][400/875]	Time 0.726 (0.652)	Data 0.008 (0.011)	Loss 2.1105 (2.0371)	Loss@kd 1.6331 (1.6304)	Acc@1 65.625 (66.891)	Acc@5 95.312 (98.457)
Epoch: [35][500/875]	Time 0.655 (0.651)	Data 0.007 (0.010)	Loss 2.0756 (2.0385)	Loss@kd 1.7178 (1.6313)	Acc@1 65.625 (66.795)	Acc@5 100.000 (98.416)
Epoch: [35][600/875]	Time 0.639 (0.650)	Data 0.007 (0.009)	Loss 2.0361 (2.0379)	Loss@kd 1.6385 (1.6300)	Acc@1 67.188 (66.709)	Acc@5 96.875 (98.385)
Epoch: [35][700/875]	Time 0.627 (0.650)	Data 0.005 (0.009)	Loss 1.9747 (2.0417)	Loss@kd 1.6777 (1.6297)	Acc@1 73.438 (66.581)	Acc@5 98.438 (98.355)
Epoch: [35][800/875]	Time 0.644 (0.650)	Data 0.005 (0.009)	Loss 2.2047 (2.0426)	Loss@kd 1.5923 (1.6291)	Acc@1 62.500 (66.614)	Acc@5 98.438 (98.319)
 * Acc@1 66.661 Acc@5 98.300
epoch 35, total time 568.92
Test: [0/750]	Time 0.858 (0.858)	Loss 0.6103 (0.6103)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.120 (0.134)	Loss 0.4210 (0.5190)	Acc@1 87.500 (84.994)	Acc@5 96.875 (92.110)
Test: [200/750]	Time 0.099 (0.131)	Loss 1.4485 (0.5270)	Acc@1 31.250 (82.307)	Acc@5 87.500 (94.590)
Test: [300/750]	Time 0.114 (0.128)	Loss 0.8788 (0.7913)	Acc@1 71.875 (69.176)	Acc@5 100.000 (93.823)
Test: [400/750]	Time 0.112 (0.127)	Loss 0.7602 (0.8186)	Acc@1 78.125 (68.828)	Acc@5 87.500 (94.077)
Test: [500/750]	Time 0.131 (0.127)	Loss 0.7845 (0.8260)	Acc@1 71.875 (69.417)	Acc@5 100.000 (93.170)
Test: [600/750]	Time 0.117 (0.126)	Loss 0.6958 (0.8655)	Acc@1 71.875 (68.422)	Acc@5 96.875 (92.273)
Test: [700/750]	Time 0.137 (0.125)	Loss 1.0655 (0.8745)	Acc@1 56.250 (67.653)	Acc@5 87.500 (92.546)
 * Acc@1 67.283 Acc@5 92.500
==> training...
Epoch: [36][0/875]	Time 2.166 (2.166)	Data 1.483 (1.483)	Loss 2.0272 (2.0272)	Loss@kd 1.7336 (1.7336)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Epoch: [36][100/875]	Time 0.652 (0.664)	Data 0.006 (0.021)	Loss 1.9607 (2.0259)	Loss@kd 1.6706 (1.6301)	Acc@1 71.875 (67.311)	Acc@5 100.000 (98.236)
Epoch: [36][200/875]	Time 0.633 (0.656)	Data 0.007 (0.014)	Loss 2.2948 (2.0251)	Loss@kd 1.6596 (1.6255)	Acc@1 54.688 (67.320)	Acc@5 98.438 (98.274)
Epoch: [36][300/875]	Time 0.640 (0.654)	Data 0.005 (0.012)	Loss 1.9872 (2.0235)	Loss@kd 1.6255 (1.6220)	Acc@1 70.312 (67.245)	Acc@5 98.438 (98.365)
Epoch: [36][400/875]	Time 0.645 (0.652)	Data 0.005 (0.010)	Loss 2.0843 (2.0282)	Loss@kd 1.5684 (1.6242)	Acc@1 68.750 (67.106)	Acc@5 98.438 (98.391)
Epoch: [36][500/875]	Time 0.621 (0.651)	Data 0.007 (0.010)	Loss 2.0274 (2.0307)	Loss@kd 1.7285 (1.6224)	Acc@1 70.312 (67.028)	Acc@5 100.000 (98.356)
Epoch: [36][600/875]	Time 0.646 (0.650)	Data 0.006 (0.009)	Loss 2.1074 (2.0300)	Loss@kd 1.6587 (1.6215)	Acc@1 64.062 (67.034)	Acc@5 96.875 (98.401)
Epoch: [36][700/875]	Time 0.651 (0.650)	Data 0.007 (0.009)	Loss 1.9337 (2.0267)	Loss@kd 1.6007 (1.6191)	Acc@1 71.875 (67.056)	Acc@5 98.438 (98.366)
Epoch: [36][800/875]	Time 0.632 (0.649)	Data 0.005 (0.009)	Loss 2.0070 (2.0286)	Loss@kd 1.6005 (1.6182)	Acc@1 70.312 (66.940)	Acc@5 96.875 (98.338)
 * Acc@1 66.957 Acc@5 98.343
epoch 36, total time 568.64
Test: [0/750]	Time 0.923 (0.923)	Loss 0.5215 (0.5215)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.112 (0.142)	Loss 0.5909 (0.5248)	Acc@1 75.000 (84.066)	Acc@5 100.000 (92.822)
Test: [200/750]	Time 0.124 (0.133)	Loss 1.1554 (0.5317)	Acc@1 53.125 (81.732)	Acc@5 93.750 (95.227)
Test: [300/750]	Time 0.125 (0.131)	Loss 1.4143 (0.7604)	Acc@1 46.875 (72.051)	Acc@5 87.500 (94.581)
Test: [400/750]	Time 0.121 (0.130)	Loss 0.9280 (0.8976)	Acc@1 71.875 (66.163)	Acc@5 87.500 (93.586)
Test: [500/750]	Time 0.137 (0.129)	Loss 0.6439 (0.9092)	Acc@1 78.125 (66.511)	Acc@5 93.750 (92.340)
Test: [600/750]	Time 0.119 (0.128)	Loss 0.7511 (0.9009)	Acc@1 68.750 (67.419)	Acc@5 93.750 (92.284)
Test: [700/750]	Time 0.104 (0.128)	Loss 1.0937 (0.8976)	Acc@1 62.500 (67.386)	Acc@5 87.500 (92.444)
 * Acc@1 66.992 Acc@5 92.292
==> training...
Epoch: [37][0/875]	Time 2.452 (2.452)	Data 1.629 (1.629)	Loss 1.7669 (1.7669)	Loss@kd 1.6182 (1.6182)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [37][100/875]	Time 0.639 (0.668)	Data 0.007 (0.023)	Loss 2.0102 (2.0093)	Loss@kd 1.5720 (1.6080)	Acc@1 71.875 (66.955)	Acc@5 98.438 (98.422)
Epoch: [37][200/875]	Time 0.665 (0.657)	Data 0.007 (0.015)	Loss 1.8852 (2.0060)	Loss@kd 1.6376 (1.6108)	Acc@1 78.125 (67.413)	Acc@5 100.000 (98.430)
Epoch: [37][300/875]	Time 0.627 (0.654)	Data 0.005 (0.012)	Loss 1.6978 (2.0048)	Loss@kd 1.5550 (1.6107)	Acc@1 75.000 (67.603)	Acc@5 98.438 (98.401)
Epoch: [37][400/875]	Time 0.656 (0.653)	Data 0.008 (0.011)	Loss 2.2470 (2.0152)	Loss@kd 1.6132 (1.6120)	Acc@1 62.500 (67.219)	Acc@5 96.875 (98.406)
Epoch: [37][500/875]	Time 0.624 (0.652)	Data 0.007 (0.010)	Loss 1.7422 (2.0148)	Loss@kd 1.5317 (1.6119)	Acc@1 73.438 (67.172)	Acc@5 100.000 (98.366)
Epoch: [37][600/875]	Time 0.656 (0.651)	Data 0.007 (0.009)	Loss 2.1021 (2.0113)	Loss@kd 1.6419 (1.6101)	Acc@1 65.625 (67.226)	Acc@5 98.438 (98.398)
Epoch: [37][700/875]	Time 0.646 (0.651)	Data 0.007 (0.009)	Loss 2.1897 (2.0129)	Loss@kd 1.6227 (1.6091)	Acc@1 60.938 (67.130)	Acc@5 96.875 (98.346)
Epoch: [37][800/875]	Time 0.747 (0.651)	Data 0.007 (0.009)	Loss 1.9163 (2.0154)	Loss@kd 1.5611 (1.6095)	Acc@1 70.312 (67.070)	Acc@5 98.438 (98.369)
 * Acc@1 67.046 Acc@5 98.338
epoch 37, total time 570.15
Test: [0/750]	Time 0.900 (0.900)	Loss 0.5326 (0.5326)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.139 (0.135)	Loss 0.5914 (0.4761)	Acc@1 78.125 (84.592)	Acc@5 93.750 (93.224)
Test: [200/750]	Time 0.190 (0.131)	Loss 1.0982 (0.5518)	Acc@1 65.625 (80.286)	Acc@5 93.750 (94.729)
Test: [300/750]	Time 0.123 (0.130)	Loss 1.2277 (0.7464)	Acc@1 40.625 (72.062)	Acc@5 96.875 (94.622)
Test: [400/750]	Time 0.123 (0.129)	Loss 0.7081 (0.8289)	Acc@1 78.125 (68.088)	Acc@5 87.500 (94.241)
Test: [500/750]	Time 0.128 (0.128)	Loss 0.5565 (0.8182)	Acc@1 81.250 (69.299)	Acc@5 96.875 (93.419)
Test: [600/750]	Time 0.107 (0.127)	Loss 0.8266 (0.8243)	Acc@1 71.875 (69.696)	Acc@5 90.625 (93.282)
Test: [700/750]	Time 0.118 (0.126)	Loss 1.4241 (0.8522)	Acc@1 50.000 (68.661)	Acc@5 78.125 (92.912)
 * Acc@1 67.721 Acc@5 92.404
saving the best model!
==> training...
Epoch: [38][0/875]	Time 2.253 (2.253)	Data 1.584 (1.584)	Loss 2.0709 (2.0709)	Loss@kd 1.6593 (1.6593)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [38][100/875]	Time 0.647 (0.664)	Data 0.005 (0.022)	Loss 2.1318 (2.0078)	Loss@kd 1.5770 (1.6054)	Acc@1 59.375 (66.909)	Acc@5 100.000 (98.345)
Epoch: [38][200/875]	Time 0.632 (0.655)	Data 0.007 (0.015)	Loss 2.0680 (2.0155)	Loss@kd 1.5500 (1.6049)	Acc@1 64.062 (67.118)	Acc@5 100.000 (98.383)
Epoch: [38][300/875]	Time 0.636 (0.651)	Data 0.006 (0.012)	Loss 1.8034 (2.0146)	Loss@kd 1.6353 (1.6038)	Acc@1 81.250 (67.058)	Acc@5 98.438 (98.349)
Epoch: [38][400/875]	Time 0.713 (0.650)	Data 0.006 (0.011)	Loss 2.1461 (2.0114)	Loss@kd 1.6352 (1.6027)	Acc@1 60.938 (67.125)	Acc@5 96.875 (98.375)
Epoch: [38][500/875]	Time 0.650 (0.650)	Data 0.007 (0.010)	Loss 2.1313 (2.0099)	Loss@kd 1.6237 (1.6014)	Acc@1 64.062 (67.110)	Acc@5 100.000 (98.381)
Epoch: [38][600/875]	Time 0.632 (0.649)	Data 0.008 (0.009)	Loss 1.8084 (2.0063)	Loss@kd 1.5688 (1.6009)	Acc@1 76.562 (67.224)	Acc@5 98.438 (98.404)
Epoch: [38][700/875]	Time 0.638 (0.649)	Data 0.005 (0.009)	Loss 2.0876 (2.0044)	Loss@kd 1.6236 (1.6000)	Acc@1 60.938 (67.279)	Acc@5 93.750 (98.411)
Epoch: [38][800/875]	Time 0.631 (0.649)	Data 0.006 (0.009)	Loss 2.0833 (2.0061)	Loss@kd 1.5799 (1.5995)	Acc@1 60.938 (67.271)	Acc@5 100.000 (98.387)
 * Acc@1 67.295 Acc@5 98.375
epoch 38, total time 568.06
Test: [0/750]	Time 0.933 (0.933)	Loss 0.5762 (0.5762)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.109 (0.136)	Loss 0.5512 (0.5986)	Acc@1 78.125 (82.457)	Acc@5 96.875 (90.903)
Test: [200/750]	Time 0.119 (0.134)	Loss 1.5802 (0.6341)	Acc@1 18.750 (77.783)	Acc@5 84.375 (93.455)
Test: [300/750]	Time 0.119 (0.131)	Loss 0.9510 (0.8758)	Acc@1 68.750 (64.691)	Acc@5 100.000 (92.546)
Test: [400/750]	Time 0.123 (0.129)	Loss 0.5552 (0.8769)	Acc@1 84.375 (65.656)	Acc@5 87.500 (93.360)
Test: [500/750]	Time 0.203 (0.128)	Loss 0.6011 (0.8366)	Acc@1 81.250 (68.201)	Acc@5 93.750 (93.170)
Test: [600/750]	Time 0.137 (0.127)	Loss 0.7677 (0.8377)	Acc@1 71.875 (69.052)	Acc@5 93.750 (92.835)
Test: [700/750]	Time 0.123 (0.126)	Loss 1.1587 (0.8467)	Acc@1 56.250 (68.478)	Acc@5 84.375 (93.032)
 * Acc@1 67.792 Acc@5 92.946
saving the best model!
==> training...
Epoch: [39][0/875]	Time 2.258 (2.258)	Data 1.575 (1.575)	Loss 2.0096 (2.0096)	Loss@kd 1.5347 (1.5347)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [39][100/875]	Time 0.663 (0.664)	Data 0.007 (0.022)	Loss 2.1339 (1.9970)	Loss@kd 1.5732 (1.5894)	Acc@1 57.812 (67.667)	Acc@5 96.875 (98.298)
Epoch: [39][200/875]	Time 0.663 (0.658)	Data 0.011 (0.015)	Loss 1.9147 (1.9981)	Loss@kd 1.6177 (1.5936)	Acc@1 71.875 (67.374)	Acc@5 100.000 (98.422)
Epoch: [39][300/875]	Time 0.625 (0.656)	Data 0.007 (0.012)	Loss 2.1043 (1.9930)	Loss@kd 1.6300 (1.5950)	Acc@1 68.750 (67.670)	Acc@5 100.000 (98.489)
Epoch: [39][400/875]	Time 0.630 (0.655)	Data 0.006 (0.011)	Loss 1.7441 (1.9974)	Loss@kd 1.5499 (1.5926)	Acc@1 75.000 (67.402)	Acc@5 100.000 (98.480)
Epoch: [39][500/875]	Time 0.639 (0.654)	Data 0.007 (0.010)	Loss 1.8050 (1.9947)	Loss@kd 1.5428 (1.5902)	Acc@1 70.312 (67.347)	Acc@5 100.000 (98.472)
Epoch: [39][600/875]	Time 0.629 (0.653)	Data 0.005 (0.009)	Loss 1.9473 (1.9941)	Loss@kd 1.5630 (1.5895)	Acc@1 71.875 (67.401)	Acc@5 96.875 (98.458)
Epoch: [39][700/875]	Time 0.653 (0.653)	Data 0.007 (0.009)	Loss 2.2026 (1.9958)	Loss@kd 1.5458 (1.5900)	Acc@1 54.688 (67.348)	Acc@5 100.000 (98.440)
Epoch: [39][800/875]	Time 0.633 (0.653)	Data 0.005 (0.009)	Loss 2.1021 (1.9930)	Loss@kd 1.5776 (1.5896)	Acc@1 59.375 (67.443)	Acc@5 98.438 (98.436)
 * Acc@1 67.425 Acc@5 98.455
epoch 39, total time 571.34
Test: [0/750]	Time 1.023 (1.023)	Loss 0.5101 (0.5101)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.112 (0.139)	Loss 0.4955 (0.4736)	Acc@1 81.250 (85.551)	Acc@5 93.750 (93.069)
Test: [200/750]	Time 0.113 (0.131)	Loss 1.2861 (0.5029)	Acc@1 40.625 (82.680)	Acc@5 96.875 (94.947)
Test: [300/750]	Time 0.092 (0.128)	Loss 1.1409 (0.7481)	Acc@1 56.250 (71.262)	Acc@5 93.750 (94.124)
Test: [400/750]	Time 0.113 (0.127)	Loss 0.5874 (0.8251)	Acc@1 78.125 (68.197)	Acc@5 93.750 (93.867)
Test: [500/750]	Time 0.112 (0.126)	Loss 0.4446 (0.7991)	Acc@1 87.500 (70.022)	Acc@5 100.000 (93.569)
Test: [600/750]	Time 0.197 (0.126)	Loss 0.8680 (0.8062)	Acc@1 68.750 (70.268)	Acc@5 90.625 (93.448)
Test: [700/750]	Time 0.117 (0.125)	Loss 1.1359 (0.8324)	Acc@1 62.500 (69.223)	Acc@5 87.500 (93.233)
 * Acc@1 68.496 Acc@5 92.846
saving the best model!
==> training...
Epoch: [40][0/875]	Time 2.261 (2.261)	Data 1.583 (1.583)	Loss 1.7853 (1.7853)	Loss@kd 1.5019 (1.5019)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [40][100/875]	Time 0.649 (0.665)	Data 0.005 (0.022)	Loss 1.8926 (1.9804)	Loss@kd 1.6866 (1.5823)	Acc@1 78.125 (67.389)	Acc@5 98.438 (98.360)
Epoch: [40][200/875]	Time 0.661 (0.658)	Data 0.005 (0.014)	Loss 1.9751 (1.9728)	Loss@kd 1.6035 (1.5807)	Acc@1 71.875 (67.755)	Acc@5 100.000 (98.406)
Epoch: [40][300/875]	Time 0.645 (0.654)	Data 0.007 (0.012)	Loss 1.9800 (1.9730)	Loss@kd 1.5535 (1.5802)	Acc@1 62.500 (67.790)	Acc@5 100.000 (98.422)
Epoch: [40][400/875]	Time 0.632 (0.653)	Data 0.007 (0.011)	Loss 1.7138 (1.9760)	Loss@kd 1.5294 (1.5804)	Acc@1 76.562 (67.811)	Acc@5 100.000 (98.422)
Epoch: [40][500/875]	Time 0.621 (0.652)	Data 0.007 (0.010)	Loss 1.9746 (1.9796)	Loss@kd 1.6355 (1.5814)	Acc@1 73.438 (67.593)	Acc@5 98.438 (98.456)
Epoch: [40][600/875]	Time 0.741 (0.651)	Data 0.008 (0.009)	Loss 2.0674 (1.9831)	Loss@kd 1.6083 (1.5819)	Acc@1 62.500 (67.515)	Acc@5 98.438 (98.458)
Epoch: [40][700/875]	Time 0.631 (0.651)	Data 0.005 (0.009)	Loss 2.0448 (1.9826)	Loss@kd 1.5358 (1.5807)	Acc@1 65.625 (67.504)	Acc@5 93.750 (98.484)
Epoch: [40][800/875]	Time 0.648 (0.650)	Data 0.007 (0.009)	Loss 1.9492 (1.9810)	Loss@kd 1.5601 (1.5807)	Acc@1 60.938 (67.470)	Acc@5 98.438 (98.492)
 * Acc@1 67.496 Acc@5 98.470
epoch 40, total time 569.42
Test: [0/750]	Time 0.854 (0.854)	Loss 0.5779 (0.5779)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.121 (0.135)	Loss 0.5877 (0.5860)	Acc@1 75.000 (81.838)	Acc@5 93.750 (92.450)
Test: [200/750]	Time 0.135 (0.129)	Loss 1.5842 (0.6139)	Acc@1 31.250 (78.389)	Acc@5 78.125 (94.481)
Test: [300/750]	Time 0.129 (0.127)	Loss 1.2640 (0.9000)	Acc@1 65.625 (65.386)	Acc@5 96.875 (92.618)
Test: [400/750]	Time 0.104 (0.127)	Loss 0.7802 (0.9647)	Acc@1 78.125 (62.944)	Acc@5 90.625 (92.207)
Test: [500/750]	Time 0.124 (0.127)	Loss 0.3234 (0.9027)	Acc@1 84.375 (66.005)	Acc@5 100.000 (92.203)
Test: [600/750]	Time 0.201 (0.127)	Loss 0.7310 (0.8564)	Acc@1 75.000 (68.225)	Acc@5 96.875 (92.705)
Test: [700/750]	Time 0.108 (0.126)	Loss 0.9306 (0.8491)	Acc@1 65.625 (68.647)	Acc@5 84.375 (92.925)
 * Acc@1 68.692 Acc@5 92.900
saving the best model!
==> Saving...
==> training...
Epoch: [41][0/875]	Time 2.262 (2.262)	Data 1.572 (1.572)	Loss 1.7070 (1.7070)	Loss@kd 1.4452 (1.4452)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [41][100/875]	Time 0.648 (0.670)	Data 0.007 (0.022)	Loss 1.8217 (1.9540)	Loss@kd 1.6207 (1.5696)	Acc@1 73.438 (67.760)	Acc@5 100.000 (98.623)
Epoch: [41][200/875]	Time 0.668 (0.661)	Data 0.007 (0.015)	Loss 2.1527 (1.9653)	Loss@kd 1.5669 (1.5735)	Acc@1 56.250 (68.050)	Acc@5 98.438 (98.624)
Epoch: [41][300/875]	Time 0.651 (0.657)	Data 0.008 (0.012)	Loss 1.8948 (1.9687)	Loss@kd 1.5459 (1.5739)	Acc@1 70.312 (67.665)	Acc@5 98.438 (98.453)
Epoch: [41][400/875]	Time 0.641 (0.655)	Data 0.007 (0.011)	Loss 1.7385 (1.9701)	Loss@kd 1.5402 (1.5716)	Acc@1 75.000 (67.737)	Acc@5 100.000 (98.430)
Epoch: [41][500/875]	Time 0.644 (0.653)	Data 0.007 (0.010)	Loss 1.8030 (1.9732)	Loss@kd 1.5018 (1.5710)	Acc@1 76.562 (67.502)	Acc@5 98.438 (98.447)
Epoch: [41][600/875]	Time 0.631 (0.652)	Data 0.005 (0.009)	Loss 2.0205 (1.9703)	Loss@kd 1.5070 (1.5694)	Acc@1 64.062 (67.601)	Acc@5 100.000 (98.458)
Epoch: [41][700/875]	Time 0.638 (0.652)	Data 0.007 (0.009)	Loss 1.8996 (1.9709)	Loss@kd 1.5829 (1.5703)	Acc@1 68.750 (67.531)	Acc@5 96.875 (98.471)
Epoch: [41][800/875]	Time 0.628 (0.651)	Data 0.007 (0.009)	Loss 1.9517 (1.9723)	Loss@kd 1.6989 (1.5707)	Acc@1 76.562 (67.550)	Acc@5 98.438 (98.467)
 * Acc@1 67.564 Acc@5 98.477
epoch 41, total time 570.17
Test: [0/750]	Time 0.916 (0.916)	Loss 0.4458 (0.4458)	Acc@1 90.625 (90.625)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.102 (0.140)	Loss 0.5704 (0.5134)	Acc@1 71.875 (84.870)	Acc@5 96.875 (92.946)
Test: [200/750]	Time 0.108 (0.134)	Loss 2.0554 (0.6137)	Acc@1 12.500 (78.032)	Acc@5 68.750 (94.232)
Test: [300/750]	Time 0.132 (0.131)	Loss 0.9878 (0.9852)	Acc@1 65.625 (62.230)	Acc@5 90.625 (90.397)
Test: [400/750]	Time 0.112 (0.129)	Loss 0.4887 (0.9770)	Acc@1 81.250 (62.929)	Acc@5 93.750 (91.178)
Test: [500/750]	Time 0.115 (0.128)	Loss 0.5300 (0.8950)	Acc@1 90.625 (66.854)	Acc@5 100.000 (91.791)
Test: [600/750]	Time 0.129 (0.127)	Loss 0.7929 (0.8723)	Acc@1 75.000 (68.381)	Acc@5 96.875 (92.169)
Test: [700/750]	Time 0.097 (0.127)	Loss 1.7053 (0.9061)	Acc@1 43.750 (67.292)	Acc@5 75.000 (91.815)
 * Acc@1 66.046 Acc@5 91.150
==> training...
Epoch: [42][0/875]	Time 2.286 (2.286)	Data 1.618 (1.618)	Loss 2.0227 (2.0227)	Loss@kd 1.7605 (1.7605)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [42][100/875]	Time 0.631 (0.665)	Data 0.007 (0.023)	Loss 1.8504 (1.9472)	Loss@kd 1.5823 (1.5642)	Acc@1 71.875 (68.131)	Acc@5 100.000 (98.577)
Epoch: [42][200/875]	Time 0.619 (0.656)	Data 0.006 (0.015)	Loss 1.9402 (1.9547)	Loss@kd 1.5588 (1.5625)	Acc@1 68.750 (67.802)	Acc@5 100.000 (98.515)
Epoch: [42][300/875]	Time 0.772 (0.652)	Data 0.010 (0.012)	Loss 1.9152 (1.9457)	Loss@kd 1.4991 (1.5595)	Acc@1 68.750 (67.961)	Acc@5 98.438 (98.593)
Epoch: [42][400/875]	Time 0.639 (0.651)	Data 0.007 (0.011)	Loss 1.9846 (1.9482)	Loss@kd 1.6100 (1.5605)	Acc@1 70.312 (67.881)	Acc@5 98.438 (98.589)
Epoch: [42][500/875]	Time 0.657 (0.651)	Data 0.005 (0.010)	Loss 1.7878 (1.9484)	Loss@kd 1.5296 (1.5592)	Acc@1 75.000 (67.998)	Acc@5 100.000 (98.609)
Epoch: [42][600/875]	Time 0.638 (0.650)	Data 0.007 (0.009)	Loss 1.9054 (1.9545)	Loss@kd 1.5850 (1.5611)	Acc@1 71.875 (67.879)	Acc@5 100.000 (98.557)
Epoch: [42][700/875]	Time 0.621 (0.650)	Data 0.007 (0.009)	Loss 1.7578 (1.9559)	Loss@kd 1.5776 (1.5606)	Acc@1 76.562 (67.827)	Acc@5 100.000 (98.544)
Epoch: [42][800/875]	Time 0.646 (0.651)	Data 0.007 (0.009)	Loss 1.8150 (1.9578)	Loss@kd 1.5157 (1.5598)	Acc@1 71.875 (67.782)	Acc@5 100.000 (98.533)
 * Acc@1 67.825 Acc@5 98.537
epoch 42, total time 569.94
Test: [0/750]	Time 0.946 (0.946)	Loss 0.6175 (0.6175)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.133 (0.138)	Loss 0.4262 (0.5151)	Acc@1 84.375 (84.777)	Acc@5 93.750 (92.265)
Test: [200/750]	Time 0.196 (0.134)	Loss 1.4021 (0.5149)	Acc@1 40.625 (82.882)	Acc@5 81.250 (94.714)
Test: [300/750]	Time 0.139 (0.131)	Loss 1.3667 (0.7971)	Acc@1 46.875 (70.484)	Acc@5 93.750 (93.200)
Test: [400/750]	Time 0.119 (0.131)	Loss 0.6779 (0.9194)	Acc@1 81.250 (65.641)	Acc@5 90.625 (92.519)
Test: [500/750]	Time 0.105 (0.131)	Loss 0.6777 (0.9002)	Acc@1 75.000 (67.197)	Acc@5 100.000 (91.929)
Test: [600/750]	Time 0.127 (0.131)	Loss 0.7969 (0.8943)	Acc@1 71.875 (67.710)	Acc@5 96.875 (92.185)
Test: [700/750]	Time 0.109 (0.131)	Loss 1.0198 (0.8891)	Acc@1 68.750 (67.716)	Acc@5 87.500 (92.533)
 * Acc@1 67.546 Acc@5 92.408
==> training...
Epoch: [43][0/875]	Time 2.269 (2.269)	Data 1.572 (1.572)	Loss 1.7759 (1.7759)	Loss@kd 1.5380 (1.5380)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [43][100/875]	Time 0.643 (0.671)	Data 0.007 (0.023)	Loss 1.8978 (1.9320)	Loss@kd 1.5669 (1.5558)	Acc@1 71.875 (68.905)	Acc@5 100.000 (98.623)
Epoch: [43][200/875]	Time 0.669 (0.665)	Data 0.007 (0.015)	Loss 1.8163 (1.9409)	Loss@kd 1.5663 (1.5583)	Acc@1 68.750 (68.190)	Acc@5 98.438 (98.476)
Epoch: [43][300/875]	Time 0.666 (0.661)	Data 0.008 (0.012)	Loss 1.6905 (1.9436)	Loss@kd 1.5663 (1.5562)	Acc@1 78.125 (68.231)	Acc@5 100.000 (98.448)
Epoch: [43][400/875]	Time 0.692 (0.659)	Data 0.009 (0.011)	Loss 1.8393 (1.9490)	Loss@kd 1.5633 (1.5553)	Acc@1 78.125 (68.158)	Acc@5 98.438 (98.441)
Epoch: [43][500/875]	Time 0.644 (0.658)	Data 0.007 (0.010)	Loss 1.9008 (1.9522)	Loss@kd 1.5266 (1.5565)	Acc@1 65.625 (68.042)	Acc@5 100.000 (98.475)
Epoch: [43][600/875]	Time 0.645 (0.657)	Data 0.007 (0.010)	Loss 1.9027 (1.9490)	Loss@kd 1.5639 (1.5555)	Acc@1 70.312 (68.129)	Acc@5 100.000 (98.521)
Epoch: [43][700/875]	Time 0.638 (0.657)	Data 0.005 (0.009)	Loss 1.6716 (1.9500)	Loss@kd 1.5399 (1.5559)	Acc@1 76.562 (68.199)	Acc@5 100.000 (98.516)
Epoch: [43][800/875]	Time 0.647 (0.657)	Data 0.007 (0.009)	Loss 2.1257 (1.9501)	Loss@kd 1.5990 (1.5550)	Acc@1 65.625 (68.155)	Acc@5 98.438 (98.486)
 * Acc@1 68.252 Acc@5 98.511
epoch 43, total time 575.27
Test: [0/750]	Time 0.894 (0.894)	Loss 0.4494 (0.4494)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.118 (0.134)	Loss 0.5427 (0.4798)	Acc@1 75.000 (84.251)	Acc@5 93.750 (93.781)
Test: [200/750]	Time 0.121 (0.128)	Loss 1.3790 (0.5254)	Acc@1 40.625 (81.545)	Acc@5 87.500 (95.274)
Test: [300/750]	Time 0.114 (0.127)	Loss 1.2587 (0.8043)	Acc@1 53.125 (69.228)	Acc@5 96.875 (93.594)
Test: [400/750]	Time 0.122 (0.125)	Loss 0.5173 (0.8959)	Acc@1 81.250 (65.539)	Acc@5 96.875 (93.610)
Test: [500/750]	Time 0.106 (0.124)	Loss 0.6073 (0.8617)	Acc@1 81.250 (67.783)	Acc@5 93.750 (93.351)
Test: [600/750]	Time 0.116 (0.124)	Loss 0.7704 (0.8597)	Acc@1 65.625 (68.266)	Acc@5 93.750 (93.126)
Test: [700/750]	Time 0.116 (0.124)	Loss 1.1616 (0.8613)	Acc@1 62.500 (68.260)	Acc@5 87.500 (93.175)
 * Acc@1 68.154 Acc@5 92.921
==> training...
Epoch: [44][0/875]	Time 2.273 (2.273)	Data 1.607 (1.607)	Loss 1.9714 (1.9714)	Loss@kd 1.5359 (1.5359)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [44][100/875]	Time 0.650 (0.670)	Data 0.008 (0.023)	Loss 2.1016 (1.9429)	Loss@kd 1.5293 (1.5572)	Acc@1 65.625 (68.239)	Acc@5 100.000 (98.670)
Epoch: [44][200/875]	Time 0.731 (0.661)	Data 0.007 (0.015)	Loss 1.8421 (1.9458)	Loss@kd 1.5719 (1.5597)	Acc@1 71.875 (68.307)	Acc@5 100.000 (98.624)
Epoch: [44][300/875]	Time 0.631 (0.659)	Data 0.008 (0.013)	Loss 1.9463 (1.9445)	Loss@kd 1.6298 (1.5539)	Acc@1 73.438 (68.163)	Acc@5 98.438 (98.583)
Epoch: [44][400/875]	Time 0.641 (0.658)	Data 0.008 (0.011)	Loss 1.8623 (1.9411)	Loss@kd 1.5804 (1.5502)	Acc@1 73.438 (68.329)	Acc@5 96.875 (98.550)
Epoch: [44][500/875]	Time 0.635 (0.657)	Data 0.007 (0.010)	Loss 1.9503 (1.9382)	Loss@kd 1.6246 (1.5475)	Acc@1 68.750 (68.407)	Acc@5 98.438 (98.503)
Epoch: [44][600/875]	Time 0.739 (0.657)	Data 0.007 (0.010)	Loss 2.1381 (1.9392)	Loss@kd 1.4935 (1.5472)	Acc@1 56.250 (68.316)	Acc@5 96.875 (98.510)
Epoch: [44][700/875]	Time 0.651 (0.656)	Data 0.007 (0.010)	Loss 1.8454 (1.9375)	Loss@kd 1.5159 (1.5471)	Acc@1 76.562 (68.322)	Acc@5 98.438 (98.542)
Epoch: [44][800/875]	Time 0.659 (0.656)	Data 0.007 (0.009)	Loss 1.7444 (1.9383)	Loss@kd 1.5117 (1.5464)	Acc@1 70.312 (68.348)	Acc@5 100.000 (98.545)
 * Acc@1 68.243 Acc@5 98.525
epoch 44, total time 574.23
Test: [0/750]	Time 0.934 (0.934)	Loss 0.4966 (0.4966)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.129 (0.142)	Loss 0.3138 (0.4428)	Acc@1 90.625 (86.417)	Acc@5 93.750 (93.472)
Test: [200/750]	Time 0.113 (0.136)	Loss 1.4273 (0.4284)	Acc@1 31.250 (85.774)	Acc@5 93.750 (95.538)
Test: [300/750]	Time 0.137 (0.134)	Loss 1.2033 (0.7444)	Acc@1 62.500 (71.044)	Acc@5 93.750 (93.916)
Test: [400/750]	Time 0.122 (0.134)	Loss 0.5948 (0.8163)	Acc@1 78.125 (69.023)	Acc@5 93.750 (93.633)
Test: [500/750]	Time 0.130 (0.133)	Loss 0.5991 (0.7911)	Acc@1 84.375 (70.702)	Acc@5 96.875 (93.426)
Test: [600/750]	Time 0.133 (0.133)	Loss 1.1146 (0.8213)	Acc@1 65.625 (69.785)	Acc@5 87.500 (93.183)
Test: [700/750]	Time 0.133 (0.132)	Loss 1.0450 (0.8551)	Acc@1 56.250 (68.179)	Acc@5 90.625 (93.202)
 * Acc@1 68.017 Acc@5 93.133
==> training...
Epoch: [45][0/875]	Time 2.268 (2.268)	Data 1.610 (1.610)	Loss 1.9652 (1.9652)	Loss@kd 1.5388 (1.5388)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [45][100/875]	Time 0.651 (0.669)	Data 0.007 (0.023)	Loss 1.8810 (1.9169)	Loss@kd 1.6328 (1.5346)	Acc@1 70.312 (68.518)	Acc@5 100.000 (98.530)
Epoch: [45][200/875]	Time 0.651 (0.661)	Data 0.006 (0.015)	Loss 1.8817 (1.9232)	Loss@kd 1.5820 (1.5417)	Acc@1 70.312 (68.284)	Acc@5 100.000 (98.507)
Epoch: [45][300/875]	Time 0.656 (0.661)	Data 0.007 (0.013)	Loss 1.8594 (1.9216)	Loss@kd 1.4676 (1.5397)	Acc@1 70.312 (68.636)	Acc@5 98.438 (98.526)
Epoch: [45][400/875]	Time 0.648 (0.659)	Data 0.007 (0.011)	Loss 1.8547 (1.9240)	Loss@kd 1.5142 (1.5386)	Acc@1 67.188 (68.618)	Acc@5 100.000 (98.504)
Epoch: [45][500/875]	Time 0.653 (0.658)	Data 0.007 (0.010)	Loss 1.9369 (1.9267)	Loss@kd 1.4979 (1.5386)	Acc@1 68.750 (68.560)	Acc@5 96.875 (98.531)
Epoch: [45][600/875]	Time 0.642 (0.657)	Data 0.007 (0.010)	Loss 2.0219 (1.9228)	Loss@kd 1.4953 (1.5372)	Acc@1 67.188 (68.698)	Acc@5 98.438 (98.554)
Epoch: [45][700/875]	Time 0.724 (0.656)	Data 0.007 (0.010)	Loss 1.8015 (1.9242)	Loss@kd 1.5100 (1.5374)	Acc@1 71.875 (68.699)	Acc@5 98.438 (98.542)
Epoch: [45][800/875]	Time 0.648 (0.656)	Data 0.007 (0.009)	Loss 1.7951 (1.9244)	Loss@kd 1.5467 (1.5372)	Acc@1 73.438 (68.660)	Acc@5 98.438 (98.516)
 * Acc@1 68.630 Acc@5 98.514
epoch 45, total time 574.50
Test: [0/750]	Time 1.031 (1.031)	Loss 0.5045 (0.5045)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.125 (0.143)	Loss 0.6571 (0.4314)	Acc@1 78.125 (86.696)	Acc@5 96.875 (94.028)
Test: [200/750]	Time 0.114 (0.134)	Loss 1.8115 (0.5598)	Acc@1 21.875 (79.757)	Acc@5 81.250 (94.387)
Test: [300/750]	Time 0.111 (0.131)	Loss 1.0502 (0.9014)	Acc@1 75.000 (65.490)	Acc@5 96.875 (90.511)
Test: [400/750]	Time 0.118 (0.129)	Loss 0.6333 (0.9351)	Acc@1 78.125 (63.825)	Acc@5 90.625 (91.568)
Test: [500/750]	Time 0.116 (0.128)	Loss 0.7348 (0.9095)	Acc@1 68.750 (65.625)	Acc@5 96.875 (91.342)
Test: [600/750]	Time 0.117 (0.127)	Loss 0.7109 (0.9130)	Acc@1 75.000 (66.187)	Acc@5 93.750 (91.187)
Test: [700/750]	Time 0.121 (0.127)	Loss 0.8362 (0.8849)	Acc@1 75.000 (67.457)	Acc@5 93.750 (91.949)
 * Acc@1 68.004 Acc@5 92.167
==> training...
Epoch: [46][0/875]	Time 2.238 (2.238)	Data 1.572 (1.572)	Loss 1.8768 (1.8768)	Loss@kd 1.5461 (1.5461)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [46][100/875]	Time 0.647 (0.672)	Data 0.007 (0.023)	Loss 1.9294 (1.9094)	Loss@kd 1.4524 (1.5315)	Acc@1 56.250 (68.626)	Acc@5 98.438 (98.623)
Epoch: [46][200/875]	Time 0.650 (0.661)	Data 0.007 (0.015)	Loss 2.1669 (1.9107)	Loss@kd 1.5226 (1.5336)	Acc@1 64.062 (68.626)	Acc@5 95.312 (98.601)
Epoch: [46][300/875]	Time 0.624 (0.659)	Data 0.007 (0.013)	Loss 1.9124 (1.9177)	Loss@kd 1.4583 (1.5320)	Acc@1 71.875 (68.620)	Acc@5 96.875 (98.598)
Epoch: [46][400/875]	Time 0.650 (0.658)	Data 0.007 (0.011)	Loss 1.9091 (1.9174)	Loss@kd 1.5414 (1.5296)	Acc@1 68.750 (68.621)	Acc@5 98.438 (98.566)
Epoch: [46][500/875]	Time 0.659 (0.658)	Data 0.008 (0.010)	Loss 1.9962 (1.9193)	Loss@kd 1.5658 (1.5296)	Acc@1 71.875 (68.466)	Acc@5 95.312 (98.547)
Epoch: [46][600/875]	Time 0.653 (0.657)	Data 0.007 (0.010)	Loss 2.0158 (1.9196)	Loss@kd 1.5938 (1.5292)	Acc@1 64.062 (68.568)	Acc@5 98.438 (98.552)
Epoch: [46][700/875]	Time 0.641 (0.656)	Data 0.006 (0.010)	Loss 1.8242 (1.9198)	Loss@kd 1.4969 (1.5288)	Acc@1 76.562 (68.514)	Acc@5 96.875 (98.547)
Epoch: [46][800/875]	Time 0.660 (0.656)	Data 0.007 (0.009)	Loss 1.8561 (1.9183)	Loss@kd 1.5285 (1.5274)	Acc@1 65.625 (68.621)	Acc@5 100.000 (98.551)
 * Acc@1 68.661 Acc@5 98.568
epoch 46, total time 574.30
Test: [0/750]	Time 1.013 (1.013)	Loss 0.4970 (0.4970)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.129 (0.139)	Loss 0.4324 (0.4190)	Acc@1 84.375 (87.129)	Acc@5 100.000 (94.028)
Test: [200/750]	Time 0.133 (0.136)	Loss 1.4048 (0.4573)	Acc@1 46.875 (84.904)	Acc@5 90.625 (95.569)
Test: [300/750]	Time 0.128 (0.135)	Loss 1.3686 (0.7713)	Acc@1 40.625 (70.941)	Acc@5 93.750 (93.698)
Test: [400/750]	Time 0.124 (0.133)	Loss 0.4357 (0.8879)	Acc@1 84.375 (66.326)	Acc@5 93.750 (92.947)
Test: [500/750]	Time 0.138 (0.133)	Loss 0.6088 (0.8533)	Acc@1 75.000 (68.444)	Acc@5 100.000 (92.833)
Test: [600/750]	Time 0.138 (0.132)	Loss 0.9689 (0.8647)	Acc@1 78.125 (68.469)	Acc@5 90.625 (92.585)
Test: [700/750]	Time 0.136 (0.132)	Loss 0.7156 (0.8579)	Acc@1 75.000 (68.545)	Acc@5 90.625 (92.961)
 * Acc@1 69.133 Acc@5 93.112
saving the best model!
==> training...
Epoch: [47][0/875]	Time 2.235 (2.235)	Data 1.581 (1.581)	Loss 1.9169 (1.9169)	Loss@kd 1.5296 (1.5296)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [47][100/875]	Time 0.649 (0.672)	Data 0.007 (0.023)	Loss 1.6706 (1.9038)	Loss@kd 1.5775 (1.5258)	Acc@1 78.125 (69.848)	Acc@5 100.000 (98.670)
Epoch: [47][200/875]	Time 0.664 (0.661)	Data 0.007 (0.015)	Loss 1.5207 (1.9110)	Loss@kd 1.4721 (1.5277)	Acc@1 81.250 (69.403)	Acc@5 100.000 (98.539)
Epoch: [47][300/875]	Time 0.663 (0.658)	Data 0.007 (0.012)	Loss 1.8966 (1.9060)	Loss@kd 1.5014 (1.5251)	Acc@1 75.000 (69.295)	Acc@5 98.438 (98.619)
Epoch: [47][400/875]	Time 0.722 (0.657)	Data 0.007 (0.011)	Loss 1.9272 (1.9102)	Loss@kd 1.4988 (1.5262)	Acc@1 67.188 (69.124)	Acc@5 100.000 (98.578)
Epoch: [47][500/875]	Time 0.665 (0.656)	Data 0.007 (0.010)	Loss 1.8441 (1.9105)	Loss@kd 1.4824 (1.5238)	Acc@1 70.312 (68.859)	Acc@5 95.312 (98.556)
Epoch: [47][600/875]	Time 0.644 (0.656)	Data 0.007 (0.010)	Loss 1.7877 (1.9142)	Loss@kd 1.5162 (1.5226)	Acc@1 70.312 (68.672)	Acc@5 98.438 (98.539)
Epoch: [47][700/875]	Time 0.646 (0.656)	Data 0.007 (0.010)	Loss 1.9691 (1.9133)	Loss@kd 1.5097 (1.5225)	Acc@1 68.750 (68.590)	Acc@5 96.875 (98.553)
Epoch: [47][800/875]	Time 0.737 (0.656)	Data 0.007 (0.009)	Loss 1.9310 (1.9101)	Loss@kd 1.4978 (1.5207)	Acc@1 60.938 (68.635)	Acc@5 100.000 (98.564)
 * Acc@1 68.618 Acc@5 98.570
epoch 47, total time 574.02
Test: [0/750]	Time 0.929 (0.929)	Loss 0.7538 (0.7538)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.128 (0.139)	Loss 0.3908 (0.6077)	Acc@1 81.250 (83.447)	Acc@5 100.000 (91.708)
Test: [200/750]	Time 0.127 (0.130)	Loss 1.2697 (0.5734)	Acc@1 53.125 (82.105)	Acc@5 84.375 (94.263)
Test: [300/750]	Time 0.092 (0.128)	Loss 1.4803 (0.7977)	Acc@1 40.625 (71.169)	Acc@5 90.625 (93.729)
Test: [400/750]	Time 0.118 (0.127)	Loss 0.5976 (0.9264)	Acc@1 81.250 (65.157)	Acc@5 87.500 (92.791)
Test: [500/750]	Time 0.174 (0.126)	Loss 0.4042 (0.8834)	Acc@1 87.500 (67.415)	Acc@5 100.000 (92.602)
Test: [600/750]	Time 0.122 (0.125)	Loss 0.7376 (0.8490)	Acc@1 71.875 (68.968)	Acc@5 96.875 (92.882)
Test: [700/750]	Time 0.119 (0.125)	Loss 0.7850 (0.8333)	Acc@1 71.875 (69.584)	Acc@5 90.625 (93.273)
 * Acc@1 69.933 Acc@5 93.354
saving the best model!
==> training...
Epoch: [48][0/875]	Time 2.269 (2.269)	Data 1.599 (1.599)	Loss 2.0177 (2.0177)	Loss@kd 1.5390 (1.5390)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [48][100/875]	Time 0.654 (0.673)	Data 0.007 (0.023)	Loss 1.7884 (1.9109)	Loss@kd 1.5175 (1.5273)	Acc@1 73.438 (69.276)	Acc@5 98.438 (98.700)
Epoch: [48][200/875]	Time 0.649 (0.665)	Data 0.007 (0.015)	Loss 1.9093 (1.9053)	Loss@kd 1.4983 (1.5238)	Acc@1 67.188 (68.843)	Acc@5 100.000 (98.725)
Epoch: [48][300/875]	Time 0.626 (0.661)	Data 0.004 (0.013)	Loss 1.9547 (1.9017)	Loss@kd 1.4846 (1.5181)	Acc@1 67.188 (68.937)	Acc@5 100.000 (98.681)
Epoch: [48][400/875]	Time 0.677 (0.659)	Data 0.007 (0.011)	Loss 1.9135 (1.8994)	Loss@kd 1.5095 (1.5201)	Acc@1 65.625 (69.233)	Acc@5 100.000 (98.679)
Epoch: [48][500/875]	Time 0.654 (0.658)	Data 0.007 (0.010)	Loss 1.9408 (1.8981)	Loss@kd 1.5284 (1.5181)	Acc@1 67.188 (69.152)	Acc@5 100.000 (98.687)
Epoch: [48][600/875]	Time 0.663 (0.657)	Data 0.007 (0.010)	Loss 1.7115 (1.8943)	Loss@kd 1.4972 (1.5157)	Acc@1 79.688 (69.265)	Acc@5 100.000 (98.677)
Epoch: [48][700/875]	Time 0.630 (0.657)	Data 0.007 (0.009)	Loss 1.9377 (1.8978)	Loss@kd 1.4423 (1.5163)	Acc@1 59.375 (69.078)	Acc@5 98.438 (98.651)
Epoch: [48][800/875]	Time 0.633 (0.656)	Data 0.007 (0.009)	Loss 1.7813 (1.8984)	Loss@kd 1.4810 (1.5154)	Acc@1 70.312 (68.968)	Acc@5 98.438 (98.650)
 * Acc@1 68.938 Acc@5 98.629
epoch 48, total time 574.32
Test: [0/750]	Time 0.958 (0.958)	Loss 0.4947 (0.4947)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.103 (0.140)	Loss 0.3921 (0.4897)	Acc@1 87.500 (85.582)	Acc@5 100.000 (93.100)
Test: [200/750]	Time 0.123 (0.136)	Loss 1.5650 (0.5042)	Acc@1 37.500 (83.085)	Acc@5 84.375 (95.351)
Test: [300/750]	Time 0.127 (0.131)	Loss 1.6553 (0.7968)	Acc@1 40.625 (69.736)	Acc@5 87.500 (93.584)
Test: [400/750]	Time 0.128 (0.129)	Loss 0.6564 (0.9466)	Acc@1 81.250 (63.295)	Acc@5 93.750 (92.293)
Test: [500/750]	Time 0.091 (0.128)	Loss 0.6458 (0.9282)	Acc@1 71.875 (64.958)	Acc@5 96.875 (91.897)
Test: [600/750]	Time 0.137 (0.127)	Loss 0.6587 (0.9125)	Acc@1 68.750 (66.129)	Acc@5 96.875 (92.050)
Test: [700/750]	Time 0.121 (0.127)	Loss 0.7757 (0.8793)	Acc@1 71.875 (67.488)	Acc@5 90.625 (92.622)
 * Acc@1 68.221 Acc@5 92.754
==> training...
Epoch: [49][0/875]	Time 2.328 (2.328)	Data 1.637 (1.637)	Loss 1.8504 (1.8504)	Loss@kd 1.5535 (1.5535)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [49][100/875]	Time 0.745 (0.674)	Data 0.007 (0.023)	Loss 2.0160 (1.9000)	Loss@kd 1.4996 (1.5187)	Acc@1 59.375 (69.152)	Acc@5 98.438 (98.685)
Epoch: [49][200/875]	Time 0.639 (0.663)	Data 0.007 (0.015)	Loss 1.7740 (1.8962)	Loss@kd 1.4461 (1.5124)	Acc@1 73.438 (68.944)	Acc@5 98.438 (98.640)
Epoch: [49][300/875]	Time 0.651 (0.660)	Data 0.007 (0.013)	Loss 1.8579 (1.8955)	Loss@kd 1.5227 (1.5099)	Acc@1 68.750 (69.072)	Acc@5 100.000 (98.614)
Epoch: [49][400/875]	Time 0.668 (0.657)	Data 0.008 (0.011)	Loss 2.1287 (1.8988)	Loss@kd 1.4919 (1.5084)	Acc@1 62.500 (68.906)	Acc@5 96.875 (98.652)
Epoch: [49][500/875]	Time 0.759 (0.657)	Data 0.007 (0.010)	Loss 1.8100 (1.8973)	Loss@kd 1.4852 (1.5099)	Acc@1 70.312 (68.968)	Acc@5 98.438 (98.687)
Epoch: [49][600/875]	Time 0.638 (0.656)	Data 0.007 (0.010)	Loss 1.8124 (1.8970)	Loss@kd 1.5015 (1.5091)	Acc@1 75.000 (68.906)	Acc@5 100.000 (98.687)
Epoch: [49][700/875]	Time 0.660 (0.656)	Data 0.007 (0.010)	Loss 1.8610 (1.8955)	Loss@kd 1.5383 (1.5079)	Acc@1 70.312 (68.922)	Acc@5 96.875 (98.689)
Epoch: [49][800/875]	Time 0.645 (0.656)	Data 0.007 (0.009)	Loss 1.7876 (1.8957)	Loss@kd 1.5417 (1.5087)	Acc@1 70.312 (68.908)	Acc@5 100.000 (98.689)
 * Acc@1 69.045 Acc@5 98.700
epoch 49, total time 573.86
Test: [0/750]	Time 0.936 (0.936)	Loss 0.6335 (0.6335)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.134 (0.145)	Loss 0.5373 (0.6402)	Acc@1 71.875 (82.178)	Acc@5 100.000 (90.532)
Test: [200/750]	Time 0.120 (0.137)	Loss 1.1226 (0.6024)	Acc@1 50.000 (80.162)	Acc@5 93.750 (93.983)
Test: [300/750]	Time 0.199 (0.136)	Loss 1.1701 (0.7714)	Acc@1 56.250 (71.958)	Acc@5 93.750 (94.093)
Test: [400/750]	Time 0.138 (0.134)	Loss 0.4593 (0.8429)	Acc@1 78.125 (68.446)	Acc@5 93.750 (93.875)
Test: [500/750]	Time 0.130 (0.133)	Loss 0.7074 (0.8062)	Acc@1 75.000 (70.347)	Acc@5 96.875 (93.557)
Test: [600/750]	Time 0.134 (0.133)	Loss 0.7685 (0.8153)	Acc@1 75.000 (70.513)	Acc@5 93.750 (93.235)
Test: [700/750]	Time 0.109 (0.132)	Loss 1.3895 (0.8263)	Acc@1 53.125 (69.896)	Acc@5 81.250 (93.384)
 * Acc@1 69.554 Acc@5 93.271
==> training...
Epoch: [50][0/875]	Time 2.343 (2.343)	Data 1.646 (1.646)	Loss 1.9745 (1.9745)	Loss@kd 1.5020 (1.5020)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [50][100/875]	Time 0.766 (0.673)	Data 0.007 (0.023)	Loss 1.7967 (1.9004)	Loss@kd 1.4945 (1.5204)	Acc@1 73.438 (68.487)	Acc@5 100.000 (98.468)
Epoch: [50][200/875]	Time 0.649 (0.666)	Data 0.007 (0.015)	Loss 1.9368 (1.8824)	Loss@kd 1.5014 (1.5143)	Acc@1 62.500 (69.426)	Acc@5 98.438 (98.640)
Epoch: [50][300/875]	Time 0.655 (0.665)	Data 0.007 (0.013)	Loss 2.0160 (1.8783)	Loss@kd 1.4079 (1.5059)	Acc@1 68.750 (69.560)	Acc@5 95.312 (98.624)
Epoch: [50][400/875]	Time 0.655 (0.664)	Data 0.007 (0.011)	Loss 1.9863 (1.8791)	Loss@kd 1.5907 (1.5045)	Acc@1 73.438 (69.455)	Acc@5 100.000 (98.749)
Epoch: [50][500/875]	Time 0.659 (0.664)	Data 0.007 (0.011)	Loss 1.8203 (1.8838)	Loss@kd 1.4851 (1.5050)	Acc@1 65.625 (69.190)	Acc@5 100.000 (98.731)
Epoch: [50][600/875]	Time 0.665 (0.663)	Data 0.007 (0.010)	Loss 1.7335 (1.8811)	Loss@kd 1.5310 (1.5039)	Acc@1 76.562 (69.314)	Acc@5 100.000 (98.744)
Epoch: [50][700/875]	Time 0.655 (0.663)	Data 0.007 (0.010)	Loss 1.6874 (1.8795)	Loss@kd 1.4360 (1.5031)	Acc@1 71.875 (69.338)	Acc@5 100.000 (98.752)
Epoch: [50][800/875]	Time 0.653 (0.663)	Data 0.007 (0.009)	Loss 1.9769 (1.8797)	Loss@kd 1.5146 (1.5021)	Acc@1 62.500 (69.210)	Acc@5 100.000 (98.732)
 * Acc@1 69.204 Acc@5 98.698
epoch 50, total time 580.50
Test: [0/750]	Time 1.104 (1.104)	Loss 0.5334 (0.5334)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.129 (0.144)	Loss 0.3619 (0.4871)	Acc@1 87.500 (85.675)	Acc@5 100.000 (92.822)
Test: [200/750]	Time 0.119 (0.137)	Loss 1.5125 (0.5040)	Acc@1 43.750 (83.318)	Acc@5 87.500 (95.149)
Test: [300/750]	Time 0.126 (0.132)	Loss 1.4222 (0.7674)	Acc@1 43.750 (71.885)	Acc@5 90.625 (93.615)
Test: [400/750]	Time 0.120 (0.129)	Loss 0.4945 (0.8830)	Acc@1 81.250 (66.171)	Acc@5 90.625 (93.290)
Test: [500/750]	Time 0.120 (0.129)	Loss 0.5768 (0.8295)	Acc@1 75.000 (68.875)	Acc@5 96.875 (93.320)
Test: [600/750]	Time 0.108 (0.128)	Loss 0.8873 (0.8278)	Acc@1 65.625 (69.629)	Acc@5 87.500 (93.386)
Test: [700/750]	Time 0.108 (0.127)	Loss 1.2348 (0.8369)	Acc@1 62.500 (69.343)	Acc@5 81.250 (93.318)
 * Acc@1 69.100 Acc@5 92.933
==> training...
Epoch: [51][0/875]	Time 2.284 (2.284)	Data 1.606 (1.606)	Loss 2.0411 (2.0411)	Loss@kd 1.4547 (1.4547)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [51][100/875]	Time 0.656 (0.683)	Data 0.007 (0.023)	Loss 1.9310 (1.8613)	Loss@kd 1.4864 (1.4939)	Acc@1 60.938 (70.003)	Acc@5 98.438 (98.731)
Epoch: [51][200/875]	Time 0.641 (0.672)	Data 0.007 (0.015)	Loss 1.8062 (1.8752)	Loss@kd 1.4790 (1.5022)	Acc@1 78.125 (69.450)	Acc@5 95.312 (98.710)
Epoch: [51][300/875]	Time 0.656 (0.668)	Data 0.007 (0.013)	Loss 1.7832 (1.8667)	Loss@kd 1.4627 (1.4986)	Acc@1 76.562 (69.710)	Acc@5 100.000 (98.770)
Epoch: [51][400/875]	Time 0.644 (0.667)	Data 0.007 (0.011)	Loss 1.7774 (1.8692)	Loss@kd 1.5001 (1.4998)	Acc@1 75.000 (69.549)	Acc@5 98.438 (98.776)
Epoch: [51][500/875]	Time 0.676 (0.666)	Data 0.007 (0.011)	Loss 1.6773 (1.8755)	Loss@kd 1.4658 (1.4991)	Acc@1 78.125 (69.349)	Acc@5 100.000 (98.774)
Epoch: [51][600/875]	Time 0.666 (0.665)	Data 0.007 (0.010)	Loss 2.1078 (1.8730)	Loss@kd 1.7025 (1.4991)	Acc@1 62.500 (69.473)	Acc@5 98.438 (98.757)
Epoch: [51][700/875]	Time 0.653 (0.664)	Data 0.007 (0.010)	Loss 1.8581 (1.8729)	Loss@kd 1.4826 (1.4974)	Acc@1 71.875 (69.434)	Acc@5 98.438 (98.703)
Epoch: [51][800/875]	Time 0.652 (0.664)	Data 0.007 (0.009)	Loss 1.9767 (1.8734)	Loss@kd 1.4583 (1.4960)	Acc@1 71.875 (69.427)	Acc@5 100.000 (98.701)
 * Acc@1 69.446 Acc@5 98.691
epoch 51, total time 581.49
Test: [0/750]	Time 0.924 (0.924)	Loss 0.5557 (0.5557)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.199 (0.142)	Loss 0.6860 (0.5846)	Acc@1 68.750 (82.457)	Acc@5 93.750 (92.822)
Test: [200/750]	Time 0.127 (0.136)	Loss 0.9082 (0.6079)	Acc@1 68.750 (80.177)	Acc@5 96.875 (94.667)
Test: [300/750]	Time 0.111 (0.134)	Loss 1.2564 (0.7330)	Acc@1 37.500 (74.045)	Acc@5 93.750 (95.048)
Test: [400/750]	Time 0.134 (0.134)	Loss 0.5654 (0.8460)	Acc@1 78.125 (68.173)	Acc@5 93.750 (94.210)
Test: [500/750]	Time 0.120 (0.133)	Loss 0.5081 (0.8191)	Acc@1 81.250 (69.835)	Acc@5 100.000 (93.688)
Test: [600/750]	Time 0.132 (0.133)	Loss 1.0493 (0.8210)	Acc@1 65.625 (70.102)	Acc@5 87.500 (93.594)
Test: [700/750]	Time 0.139 (0.133)	Loss 1.2607 (0.8385)	Acc@1 53.125 (69.472)	Acc@5 78.125 (93.402)
 * Acc@1 69.100 Acc@5 93.262
==> training...
Epoch: [52][0/875]	Time 2.238 (2.238)	Data 1.581 (1.581)	Loss 1.8575 (1.8575)	Loss@kd 1.5009 (1.5009)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [52][100/875]	Time 0.661 (0.676)	Data 0.008 (0.023)	Loss 1.8228 (1.8739)	Loss@kd 1.4910 (1.4974)	Acc@1 75.000 (69.462)	Acc@5 98.438 (98.716)
Epoch: [52][200/875]	Time 0.736 (0.669)	Data 0.009 (0.015)	Loss 1.8916 (1.8755)	Loss@kd 1.5061 (1.4934)	Acc@1 70.312 (69.387)	Acc@5 98.438 (98.725)
Epoch: [52][300/875]	Time 0.644 (0.667)	Data 0.007 (0.013)	Loss 1.8270 (1.8658)	Loss@kd 1.5116 (1.4892)	Acc@1 75.000 (69.825)	Acc@5 100.000 (98.770)
Epoch: [52][400/875]	Time 0.665 (0.665)	Data 0.008 (0.011)	Loss 2.0707 (1.8642)	Loss@kd 1.4942 (1.4873)	Acc@1 60.938 (69.724)	Acc@5 98.438 (98.792)
Epoch: [52][500/875]	Time 0.670 (0.665)	Data 0.007 (0.011)	Loss 1.6427 (1.8619)	Loss@kd 1.5074 (1.4875)	Acc@1 78.125 (69.689)	Acc@5 100.000 (98.777)
Epoch: [52][600/875]	Time 0.660 (0.664)	Data 0.007 (0.010)	Loss 1.7295 (1.8608)	Loss@kd 1.4613 (1.4875)	Acc@1 79.688 (69.634)	Acc@5 96.875 (98.768)
Epoch: [52][700/875]	Time 0.663 (0.664)	Data 0.007 (0.010)	Loss 1.8297 (1.8631)	Loss@kd 1.4906 (1.4887)	Acc@1 64.062 (69.577)	Acc@5 100.000 (98.727)
Epoch: [52][800/875]	Time 0.652 (0.663)	Data 0.008 (0.009)	Loss 1.7495 (1.8614)	Loss@kd 1.4679 (1.4887)	Acc@1 75.000 (69.595)	Acc@5 98.438 (98.707)
 * Acc@1 69.534 Acc@5 98.705
epoch 52, total time 580.91
Test: [0/750]	Time 0.992 (0.992)	Loss 0.5204 (0.5204)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.203 (0.141)	Loss 0.6625 (0.5507)	Acc@1 71.875 (83.416)	Acc@5 93.750 (92.358)
Test: [200/750]	Time 0.136 (0.135)	Loss 0.9040 (0.6024)	Acc@1 68.750 (79.555)	Acc@5 93.750 (94.108)
Test: [300/750]	Time 0.095 (0.131)	Loss 1.1684 (0.7385)	Acc@1 50.000 (73.328)	Acc@5 93.750 (94.549)
Test: [400/750]	Time 0.103 (0.129)	Loss 0.6867 (0.8375)	Acc@1 81.250 (68.243)	Acc@5 87.500 (94.101)
Test: [500/750]	Time 0.131 (0.128)	Loss 0.5750 (0.8100)	Acc@1 78.125 (69.948)	Acc@5 96.875 (93.656)
Test: [600/750]	Time 0.119 (0.127)	Loss 0.8548 (0.8120)	Acc@1 62.500 (70.383)	Acc@5 93.750 (93.589)
Test: [700/750]	Time 0.089 (0.126)	Loss 1.0499 (0.8180)	Acc@1 53.125 (70.078)	Acc@5 90.625 (93.630)
 * Acc@1 69.887 Acc@5 93.537
==> training...
Epoch: [53][0/875]	Time 2.299 (2.299)	Data 1.627 (1.627)	Loss 1.7588 (1.7588)	Loss@kd 1.3876 (1.3876)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [53][100/875]	Time 0.737 (0.678)	Data 0.007 (0.023)	Loss 1.7061 (1.8441)	Loss@kd 1.5252 (1.4806)	Acc@1 75.000 (70.003)	Acc@5 98.438 (98.778)
Epoch: [53][200/875]	Time 0.655 (0.670)	Data 0.007 (0.015)	Loss 1.9310 (1.8383)	Loss@kd 1.4795 (1.4789)	Acc@1 68.750 (70.289)	Acc@5 96.875 (98.756)
Epoch: [53][300/875]	Time 0.647 (0.667)	Data 0.008 (0.013)	Loss 2.0336 (1.8463)	Loss@kd 1.5719 (1.4803)	Acc@1 67.188 (69.871)	Acc@5 98.438 (98.744)
Epoch: [53][400/875]	Time 0.640 (0.666)	Data 0.007 (0.011)	Loss 1.7303 (1.8511)	Loss@kd 1.5453 (1.4817)	Acc@1 75.000 (69.771)	Acc@5 100.000 (98.714)
Epoch: [53][500/875]	Time 0.629 (0.664)	Data 0.009 (0.011)	Loss 1.8816 (1.8488)	Loss@kd 1.4696 (1.4805)	Acc@1 67.188 (69.882)	Acc@5 98.438 (98.703)
Epoch: [53][600/875]	Time 0.647 (0.662)	Data 0.007 (0.010)	Loss 2.0578 (1.8505)	Loss@kd 1.5128 (1.4810)	Acc@1 65.625 (69.845)	Acc@5 98.438 (98.703)
Epoch: [53][700/875]	Time 0.648 (0.661)	Data 0.007 (0.010)	Loss 1.8011 (1.8518)	Loss@kd 1.5394 (1.4805)	Acc@1 71.875 (69.815)	Acc@5 98.438 (98.709)
Epoch: [53][800/875]	Time 0.642 (0.659)	Data 0.006 (0.009)	Loss 1.7704 (1.8555)	Loss@kd 1.4576 (1.4826)	Acc@1 71.875 (69.739)	Acc@5 98.438 (98.716)
 * Acc@1 69.698 Acc@5 98.730
epoch 53, total time 576.89
Test: [0/750]	Time 1.076 (1.076)	Loss 0.4987 (0.4987)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.134 (0.135)	Loss 0.5589 (0.4730)	Acc@1 81.250 (85.427)	Acc@5 93.750 (93.905)
Test: [200/750]	Time 0.118 (0.128)	Loss 1.1896 (0.5308)	Acc@1 53.125 (81.172)	Acc@5 93.750 (95.305)
Test: [300/750]	Time 0.190 (0.125)	Loss 1.2158 (0.7534)	Acc@1 50.000 (71.605)	Acc@5 93.750 (94.228)
Test: [400/750]	Time 0.093 (0.124)	Loss 0.5500 (0.8421)	Acc@1 81.250 (67.714)	Acc@5 90.625 (93.812)
Test: [500/750]	Time 0.118 (0.123)	Loss 0.8511 (0.8210)	Acc@1 65.625 (69.112)	Acc@5 90.625 (93.419)
Test: [600/750]	Time 0.130 (0.124)	Loss 0.7579 (0.8444)	Acc@1 78.125 (68.901)	Acc@5 90.625 (93.012)
Test: [700/750]	Time 0.138 (0.124)	Loss 0.9779 (0.8347)	Acc@1 68.750 (69.263)	Acc@5 87.500 (93.300)
 * Acc@1 69.250 Acc@5 93.258
==> training...
Epoch: [54][0/875]	Time 2.263 (2.263)	Data 1.591 (1.591)	Loss 2.0933 (2.0933)	Loss@kd 1.5939 (1.5939)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [54][100/875]	Time 0.696 (0.671)	Data 0.007 (0.023)	Loss 1.9284 (1.8239)	Loss@kd 1.4758 (1.4686)	Acc@1 65.625 (71.009)	Acc@5 98.438 (98.948)
Epoch: [54][200/875]	Time 0.649 (0.661)	Data 0.007 (0.015)	Loss 1.9081 (1.8296)	Loss@kd 1.4811 (1.4740)	Acc@1 68.750 (70.639)	Acc@5 95.312 (98.982)
Epoch: [54][300/875]	Time 0.627 (0.659)	Data 0.007 (0.012)	Loss 1.7110 (1.8313)	Loss@kd 1.4717 (1.4737)	Acc@1 70.312 (70.525)	Acc@5 100.000 (98.967)
Epoch: [54][400/875]	Time 0.639 (0.658)	Data 0.006 (0.011)	Loss 1.9955 (1.8392)	Loss@kd 1.4771 (1.4730)	Acc@1 67.188 (70.223)	Acc@5 100.000 (98.944)
Epoch: [54][500/875]	Time 0.621 (0.657)	Data 0.006 (0.010)	Loss 2.0192 (1.8413)	Loss@kd 1.5017 (1.4729)	Acc@1 67.188 (70.082)	Acc@5 95.312 (98.905)
Epoch: [54][600/875]	Time 0.643 (0.657)	Data 0.007 (0.010)	Loss 1.8553 (1.8443)	Loss@kd 1.4877 (1.4736)	Acc@1 65.625 (69.920)	Acc@5 96.875 (98.843)
Epoch: [54][700/875]	Time 0.656 (0.656)	Data 0.007 (0.009)	Loss 2.0329 (1.8444)	Loss@kd 1.4728 (1.4740)	Acc@1 60.938 (70.047)	Acc@5 98.438 (98.814)
Epoch: [54][800/875]	Time 0.643 (0.656)	Data 0.007 (0.009)	Loss 1.9470 (1.8441)	Loss@kd 1.4817 (1.4748)	Acc@1 73.438 (70.061)	Acc@5 100.000 (98.789)
 * Acc@1 70.046 Acc@5 98.780
epoch 54, total time 574.61
Test: [0/750]	Time 0.904 (0.904)	Loss 0.4900 (0.4900)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.122 (0.141)	Loss 0.4454 (0.4855)	Acc@1 84.375 (85.613)	Acc@5 96.875 (93.998)
Test: [200/750]	Time 0.113 (0.133)	Loss 1.4003 (0.5062)	Acc@1 56.250 (83.162)	Acc@5 90.625 (95.538)
Test: [300/750]	Time 0.110 (0.129)	Loss 1.1329 (0.7867)	Acc@1 56.250 (70.463)	Acc@5 93.750 (93.449)
Test: [400/750]	Time 0.115 (0.127)	Loss 0.6051 (0.8573)	Acc@1 84.375 (67.293)	Acc@5 87.500 (93.415)
Test: [500/750]	Time 0.138 (0.125)	Loss 0.7829 (0.8340)	Acc@1 81.250 (69.056)	Acc@5 93.750 (92.895)
Test: [600/750]	Time 0.132 (0.125)	Loss 0.6882 (0.8524)	Acc@1 75.000 (69.078)	Acc@5 96.875 (92.564)
Test: [700/750]	Time 0.105 (0.125)	Loss 1.0503 (0.8493)	Acc@1 68.750 (69.191)	Acc@5 84.375 (92.876)
 * Acc@1 68.912 Acc@5 92.721
==> training...
Epoch: [55][0/875]	Time 2.277 (2.277)	Data 1.588 (1.588)	Loss 1.8409 (1.8409)	Loss@kd 1.4535 (1.4535)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [55][100/875]	Time 0.625 (0.672)	Data 0.005 (0.023)	Loss 2.0072 (1.8305)	Loss@kd 1.4877 (1.4698)	Acc@1 64.062 (70.050)	Acc@5 96.875 (98.948)
Epoch: [55][200/875]	Time 0.658 (0.664)	Data 0.007 (0.015)	Loss 1.6231 (1.8339)	Loss@kd 1.4562 (1.4693)	Acc@1 78.125 (69.916)	Acc@5 98.438 (98.795)
Epoch: [55][300/875]	Time 0.660 (0.661)	Data 0.007 (0.012)	Loss 1.5716 (1.8344)	Loss@kd 1.4608 (1.4709)	Acc@1 79.688 (70.053)	Acc@5 100.000 (98.811)
Epoch: [55][400/875]	Time 0.641 (0.660)	Data 0.007 (0.011)	Loss 1.6140 (1.8359)	Loss@kd 1.4292 (1.4710)	Acc@1 76.562 (70.083)	Acc@5 100.000 (98.757)
Epoch: [55][500/875]	Time 0.654 (0.660)	Data 0.007 (0.010)	Loss 1.8943 (1.8355)	Loss@kd 1.4547 (1.4709)	Acc@1 67.188 (70.188)	Acc@5 96.875 (98.731)
Epoch: [55][600/875]	Time 0.656 (0.660)	Data 0.007 (0.010)	Loss 1.7532 (1.8360)	Loss@kd 1.4189 (1.4695)	Acc@1 67.188 (70.073)	Acc@5 98.438 (98.768)
Epoch: [55][700/875]	Time 0.660 (0.660)	Data 0.007 (0.010)	Loss 1.7759 (1.8347)	Loss@kd 1.5089 (1.4686)	Acc@1 68.750 (70.023)	Acc@5 100.000 (98.765)
Epoch: [55][800/875]	Time 0.673 (0.660)	Data 0.007 (0.009)	Loss 2.0124 (1.8330)	Loss@kd 1.4875 (1.4692)	Acc@1 64.062 (70.145)	Acc@5 95.312 (98.793)
 * Acc@1 70.043 Acc@5 98.768
epoch 55, total time 578.55
Test: [0/750]	Time 1.003 (1.003)	Loss 0.5976 (0.5976)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.129 (0.135)	Loss 0.3252 (0.5674)	Acc@1 84.375 (83.818)	Acc@5 100.000 (92.017)
Test: [200/750]	Time 0.121 (0.127)	Loss 1.1286 (0.4961)	Acc@1 62.500 (84.810)	Acc@5 96.875 (94.823)
Test: [300/750]	Time 0.122 (0.126)	Loss 1.4735 (0.6906)	Acc@1 37.500 (75.903)	Acc@5 90.625 (94.238)
Test: [400/750]	Time 0.115 (0.125)	Loss 0.8116 (0.8177)	Acc@1 71.875 (69.615)	Acc@5 87.500 (93.438)
Test: [500/750]	Time 0.113 (0.125)	Loss 0.8309 (0.8358)	Acc@1 62.500 (69.480)	Acc@5 100.000 (92.758)
Test: [600/750]	Time 0.120 (0.125)	Loss 0.8864 (0.8664)	Acc@1 65.625 (68.303)	Acc@5 90.625 (92.700)
Test: [700/750]	Time 0.189 (0.125)	Loss 1.0954 (0.8662)	Acc@1 56.250 (68.072)	Acc@5 87.500 (93.010)
 * Acc@1 68.217 Acc@5 92.979
==> training...
Epoch: [56][0/875]	Time 2.250 (2.250)	Data 1.584 (1.584)	Loss 1.9496 (1.9496)	Loss@kd 1.5185 (1.5185)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [56][100/875]	Time 0.644 (0.677)	Data 0.007 (0.023)	Loss 1.7729 (1.8271)	Loss@kd 1.4334 (1.4702)	Acc@1 67.188 (70.065)	Acc@5 100.000 (98.762)
Epoch: [56][200/875]	Time 0.649 (0.669)	Data 0.007 (0.015)	Loss 1.8853 (1.8262)	Loss@kd 1.4402 (1.4685)	Acc@1 75.000 (70.406)	Acc@5 98.438 (98.663)
Epoch: [56][300/875]	Time 0.649 (0.666)	Data 0.007 (0.013)	Loss 1.7497 (1.8204)	Loss@kd 1.4240 (1.4691)	Acc@1 75.000 (70.541)	Acc@5 98.438 (98.749)
Epoch: [56][400/875]	Time 0.654 (0.665)	Data 0.008 (0.011)	Loss 1.6829 (1.8232)	Loss@kd 1.4904 (1.4697)	Acc@1 75.000 (70.433)	Acc@5 98.438 (98.866)
Epoch: [56][500/875]	Time 0.664 (0.664)	Data 0.007 (0.011)	Loss 1.5937 (1.8239)	Loss@kd 1.3823 (1.4701)	Acc@1 71.875 (70.453)	Acc@5 100.000 (98.852)
Epoch: [56][600/875]	Time 0.644 (0.664)	Data 0.007 (0.010)	Loss 2.1516 (1.8268)	Loss@kd 1.5149 (1.4681)	Acc@1 56.250 (70.318)	Acc@5 98.438 (98.874)
Epoch: [56][700/875]	Time 0.663 (0.663)	Data 0.007 (0.010)	Loss 1.6921 (1.8294)	Loss@kd 1.4078 (1.4668)	Acc@1 76.562 (70.228)	Acc@5 98.438 (98.850)
Epoch: [56][800/875]	Time 0.659 (0.663)	Data 0.007 (0.009)	Loss 1.8489 (1.8297)	Loss@kd 1.4585 (1.4661)	Acc@1 70.312 (70.297)	Acc@5 100.000 (98.826)
 * Acc@1 70.279 Acc@5 98.789
epoch 56, total time 580.87
Test: [0/750]	Time 1.051 (1.051)	Loss 0.5612 (0.5612)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.109 (0.136)	Loss 0.3942 (0.5047)	Acc@1 87.500 (85.025)	Acc@5 96.875 (93.069)
Test: [200/750]	Time 0.121 (0.129)	Loss 1.4216 (0.4896)	Acc@1 43.750 (84.344)	Acc@5 87.500 (95.009)
Test: [300/750]	Time 0.104 (0.126)	Loss 1.2080 (0.7311)	Acc@1 56.250 (73.536)	Acc@5 96.875 (93.594)
Test: [400/750]	Time 0.116 (0.126)	Loss 0.4507 (0.8062)	Acc@1 81.250 (69.755)	Acc@5 96.875 (93.851)
Test: [500/750]	Time 0.130 (0.126)	Loss 0.6678 (0.7925)	Acc@1 78.125 (71.039)	Acc@5 90.625 (93.550)
Test: [600/750]	Time 0.127 (0.126)	Loss 1.0802 (0.8247)	Acc@1 68.750 (70.102)	Acc@5 84.375 (93.074)
Test: [700/750]	Time 0.118 (0.125)	Loss 1.0501 (0.8376)	Acc@1 65.625 (69.387)	Acc@5 90.625 (93.179)
 * Acc@1 69.188 Acc@5 93.133
==> training...
Epoch: [57][0/875]	Time 2.289 (2.289)	Data 1.611 (1.611)	Loss 1.7187 (1.7187)	Loss@kd 1.4927 (1.4927)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [57][100/875]	Time 0.657 (0.680)	Data 0.012 (0.023)	Loss 1.8500 (1.8195)	Loss@kd 1.5199 (1.4641)	Acc@1 75.000 (70.498)	Acc@5 98.438 (98.824)
Epoch: [57][200/875]	Time 0.651 (0.670)	Data 0.007 (0.015)	Loss 1.9053 (1.8082)	Loss@kd 1.4154 (1.4578)	Acc@1 70.312 (70.717)	Acc@5 98.438 (98.787)
Epoch: [57][300/875]	Time 0.655 (0.667)	Data 0.008 (0.013)	Loss 1.8078 (1.8162)	Loss@kd 1.5193 (1.4560)	Acc@1 73.438 (70.525)	Acc@5 100.000 (98.765)
Epoch: [57][400/875]	Time 0.742 (0.665)	Data 0.007 (0.011)	Loss 2.0243 (1.8151)	Loss@kd 1.4301 (1.4565)	Acc@1 67.188 (70.640)	Acc@5 98.438 (98.812)
Epoch: [57][500/875]	Time 0.649 (0.665)	Data 0.007 (0.011)	Loss 1.7456 (1.8168)	Loss@kd 1.4533 (1.4574)	Acc@1 71.875 (70.565)	Acc@5 100.000 (98.784)
Epoch: [57][600/875]	Time 0.646 (0.664)	Data 0.007 (0.010)	Loss 1.5729 (1.8218)	Loss@kd 1.3913 (1.4582)	Acc@1 76.562 (70.419)	Acc@5 100.000 (98.770)
Epoch: [57][700/875]	Time 0.661 (0.663)	Data 0.007 (0.010)	Loss 1.7870 (1.8231)	Loss@kd 1.4422 (1.4584)	Acc@1 73.438 (70.259)	Acc@5 100.000 (98.781)
Epoch: [57][800/875]	Time 0.742 (0.663)	Data 0.010 (0.009)	Loss 1.8110 (1.8226)	Loss@kd 1.4628 (1.4580)	Acc@1 75.000 (70.211)	Acc@5 98.438 (98.791)
 * Acc@1 70.236 Acc@5 98.811
epoch 57, total time 580.45
Test: [0/750]	Time 1.011 (1.011)	Loss 0.5376 (0.5376)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.129 (0.140)	Loss 0.4361 (0.5535)	Acc@1 87.500 (84.901)	Acc@5 100.000 (92.358)
Test: [200/750]	Time 0.139 (0.134)	Loss 1.0092 (0.5258)	Acc@1 59.375 (83.504)	Acc@5 93.750 (94.994)
Test: [300/750]	Time 0.123 (0.131)	Loss 1.6371 (0.6796)	Acc@1 31.250 (76.350)	Acc@5 90.625 (95.017)
Test: [400/750]	Time 0.127 (0.130)	Loss 0.9049 (0.8353)	Acc@1 71.875 (68.805)	Acc@5 87.500 (94.023)
Test: [500/750]	Time 0.124 (0.129)	Loss 0.7575 (0.8602)	Acc@1 71.875 (68.750)	Acc@5 96.875 (92.777)
Test: [600/750]	Time 0.124 (0.129)	Loss 0.7339 (0.8765)	Acc@1 75.000 (68.563)	Acc@5 96.875 (92.554)
Test: [700/750]	Time 0.129 (0.129)	Loss 0.9212 (0.8587)	Acc@1 68.750 (69.049)	Acc@5 87.500 (92.894)
 * Acc@1 69.129 Acc@5 92.946
==> training...
Epoch: [58][0/875]	Time 2.310 (2.310)	Data 1.615 (1.615)	Loss 1.8196 (1.8196)	Loss@kd 1.4059 (1.4059)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [58][100/875]	Time 0.654 (0.677)	Data 0.007 (0.023)	Loss 1.8448 (1.8166)	Loss@kd 1.3978 (1.4539)	Acc@1 73.438 (70.591)	Acc@5 98.438 (98.747)
Epoch: [58][200/875]	Time 0.641 (0.668)	Data 0.007 (0.015)	Loss 2.0251 (1.8056)	Loss@kd 1.4473 (1.4508)	Acc@1 60.938 (70.631)	Acc@5 98.438 (98.888)
Epoch: [58][300/875]	Time 0.654 (0.667)	Data 0.007 (0.013)	Loss 1.9008 (1.8080)	Loss@kd 1.4613 (1.4504)	Acc@1 65.625 (70.634)	Acc@5 96.875 (98.858)
Epoch: [58][400/875]	Time 0.639 (0.665)	Data 0.007 (0.011)	Loss 1.8549 (1.8117)	Loss@kd 1.4237 (1.4515)	Acc@1 64.062 (70.515)	Acc@5 98.438 (98.843)
Epoch: [58][500/875]	Time 0.743 (0.665)	Data 0.007 (0.011)	Loss 1.8248 (1.8157)	Loss@kd 1.4881 (1.4513)	Acc@1 71.875 (70.546)	Acc@5 100.000 (98.815)
Epoch: [58][600/875]	Time 0.655 (0.664)	Data 0.007 (0.010)	Loss 2.0908 (1.8137)	Loss@kd 1.5442 (1.4504)	Acc@1 60.938 (70.507)	Acc@5 100.000 (98.833)
Epoch: [58][700/875]	Time 0.657 (0.663)	Data 0.007 (0.010)	Loss 1.9990 (1.8119)	Loss@kd 1.5126 (1.4502)	Acc@1 64.062 (70.509)	Acc@5 96.875 (98.814)
Epoch: [58][800/875]	Time 0.651 (0.663)	Data 0.007 (0.009)	Loss 2.1025 (1.8127)	Loss@kd 1.4757 (1.4507)	Acc@1 59.375 (70.519)	Acc@5 98.438 (98.820)
 * Acc@1 70.521 Acc@5 98.827
epoch 58, total time 580.48
Test: [0/750]	Time 0.981 (0.981)	Loss 0.5854 (0.5854)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.115 (0.137)	Loss 0.3199 (0.4852)	Acc@1 87.500 (84.932)	Acc@5 96.875 (94.554)
Test: [200/750]	Time 0.122 (0.132)	Loss 1.1586 (0.4745)	Acc@1 53.125 (84.593)	Acc@5 90.625 (95.771)
Test: [300/750]	Time 0.119 (0.129)	Loss 1.4511 (0.7001)	Acc@1 56.250 (74.460)	Acc@5 84.375 (94.892)
Test: [400/750]	Time 0.090 (0.128)	Loss 0.5652 (0.8192)	Acc@1 84.375 (69.031)	Acc@5 90.625 (94.272)
Test: [500/750]	Time 0.111 (0.127)	Loss 0.5670 (0.7820)	Acc@1 75.000 (71.264)	Acc@5 96.875 (94.000)
Test: [600/750]	Time 0.139 (0.126)	Loss 1.1819 (0.8100)	Acc@1 50.000 (70.700)	Acc@5 84.375 (93.537)
Test: [700/750]	Time 0.117 (0.126)	Loss 0.8635 (0.8373)	Acc@1 59.375 (69.704)	Acc@5 87.500 (93.269)
 * Acc@1 69.908 Acc@5 93.279
==> training...
Epoch: [59][0/875]	Time 2.283 (2.283)	Data 1.580 (1.580)	Loss 1.9163 (1.9163)	Loss@kd 1.4578 (1.4578)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [59][100/875]	Time 0.654 (0.680)	Data 0.007 (0.023)	Loss 1.7727 (1.8066)	Loss@kd 1.4042 (1.4453)	Acc@1 73.438 (70.746)	Acc@5 100.000 (98.809)
Epoch: [59][200/875]	Time 0.655 (0.671)	Data 0.007 (0.015)	Loss 1.6698 (1.8014)	Loss@kd 1.3954 (1.4485)	Acc@1 75.000 (71.416)	Acc@5 100.000 (98.857)
Epoch: [59][300/875]	Time 0.654 (0.668)	Data 0.008 (0.013)	Loss 1.7291 (1.8001)	Loss@kd 1.4828 (1.4495)	Acc@1 75.000 (71.242)	Acc@5 98.438 (98.946)
Epoch: [59][400/875]	Time 0.647 (0.666)	Data 0.007 (0.011)	Loss 1.7442 (1.8043)	Loss@kd 1.4231 (1.4489)	Acc@1 73.438 (70.940)	Acc@5 100.000 (98.932)
Epoch: [59][500/875]	Time 0.646 (0.665)	Data 0.008 (0.010)	Loss 1.8084 (1.8004)	Loss@kd 1.4371 (1.4481)	Acc@1 70.312 (71.073)	Acc@5 100.000 (98.930)
Epoch: [59][600/875]	Time 0.653 (0.664)	Data 0.007 (0.010)	Loss 1.9557 (1.8020)	Loss@kd 1.4889 (1.4476)	Acc@1 70.312 (71.069)	Acc@5 98.438 (98.924)
Epoch: [59][700/875]	Time 0.655 (0.664)	Data 0.007 (0.010)	Loss 1.7577 (1.7992)	Loss@kd 1.4228 (1.4467)	Acc@1 70.312 (71.001)	Acc@5 96.875 (98.919)
Epoch: [59][800/875]	Time 0.666 (0.663)	Data 0.007 (0.009)	Loss 1.6776 (1.8026)	Loss@kd 1.4958 (1.4480)	Acc@1 79.688 (70.945)	Acc@5 100.000 (98.904)
 * Acc@1 70.880 Acc@5 98.879
epoch 59, total time 580.61
Test: [0/750]	Time 1.019 (1.019)	Loss 0.4475 (0.4475)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.108 (0.142)	Loss 0.4646 (0.5120)	Acc@1 87.500 (85.427)	Acc@5 96.875 (93.967)
Test: [200/750]	Time 0.113 (0.135)	Loss 1.8390 (0.5812)	Acc@1 25.000 (80.177)	Acc@5 84.375 (94.932)
Test: [300/750]	Time 0.091 (0.131)	Loss 0.9469 (0.8961)	Acc@1 62.500 (66.362)	Acc@5 96.875 (91.902)
Test: [400/750]	Time 0.113 (0.128)	Loss 0.8955 (0.8904)	Acc@1 71.875 (66.856)	Acc@5 87.500 (92.807)
Test: [500/750]	Time 0.104 (0.126)	Loss 0.5815 (0.8867)	Acc@1 75.000 (67.758)	Acc@5 100.000 (92.147)
Test: [600/750]	Time 0.110 (0.125)	Loss 0.7457 (0.8867)	Acc@1 78.125 (68.199)	Acc@5 93.750 (91.998)
Test: [700/750]	Time 0.117 (0.125)	Loss 0.8831 (0.8631)	Acc@1 56.250 (68.714)	Acc@5 93.750 (92.631)
 * Acc@1 68.958 Acc@5 92.842
==> training...
Epoch: [60][0/875]	Time 2.290 (2.290)	Data 1.599 (1.599)	Loss 1.8783 (1.8783)	Loss@kd 1.4159 (1.4159)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [60][100/875]	Time 0.660 (0.678)	Data 0.007 (0.023)	Loss 1.6872 (1.7938)	Loss@kd 1.4844 (1.4434)	Acc@1 76.562 (71.581)	Acc@5 100.000 (98.917)
Epoch: [60][200/875]	Time 0.654 (0.665)	Data 0.008 (0.015)	Loss 1.8086 (1.7875)	Loss@kd 1.3921 (1.4433)	Acc@1 75.000 (71.580)	Acc@5 100.000 (98.842)
Epoch: [60][300/875]	Time 0.643 (0.660)	Data 0.007 (0.012)	Loss 1.7800 (1.7910)	Loss@kd 1.5031 (1.4473)	Acc@1 75.000 (71.382)	Acc@5 98.438 (98.848)
Epoch: [60][400/875]	Time 0.631 (0.657)	Data 0.007 (0.011)	Loss 1.7087 (1.8025)	Loss@kd 1.5067 (1.4477)	Acc@1 76.562 (70.881)	Acc@5 98.438 (98.831)
Epoch: [60][500/875]	Time 0.740 (0.656)	Data 0.008 (0.010)	Loss 1.8756 (1.8014)	Loss@kd 1.3695 (1.4453)	Acc@1 70.312 (70.846)	Acc@5 96.875 (98.827)
Epoch: [60][600/875]	Time 0.648 (0.655)	Data 0.007 (0.010)	Loss 1.7566 (1.8018)	Loss@kd 1.4256 (1.4449)	Acc@1 64.062 (70.809)	Acc@5 100.000 (98.838)
Epoch: [60][700/875]	Time 0.648 (0.654)	Data 0.007 (0.010)	Loss 1.8026 (1.8008)	Loss@kd 1.4062 (1.4430)	Acc@1 71.875 (70.850)	Acc@5 98.438 (98.808)
Epoch: [60][800/875]	Time 0.640 (0.654)	Data 0.007 (0.009)	Loss 1.8326 (1.8007)	Loss@kd 1.5267 (1.4424)	Acc@1 65.625 (70.843)	Acc@5 98.438 (98.802)
 * Acc@1 70.879 Acc@5 98.804
epoch 60, total time 572.82
Test: [0/750]	Time 1.007 (1.007)	Loss 0.4308 (0.4308)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.124 (0.143)	Loss 0.1762 (0.3869)	Acc@1 93.750 (88.459)	Acc@5 100.000 (96.040)
Test: [200/750]	Time 0.127 (0.135)	Loss 1.1967 (0.3536)	Acc@1 53.125 (89.303)	Acc@5 90.625 (97.046)
Test: [300/750]	Time 0.120 (0.131)	Loss 1.4804 (0.6436)	Acc@1 46.875 (76.921)	Acc@5 87.500 (95.349)
Test: [400/750]	Time 0.115 (0.128)	Loss 0.5162 (0.7980)	Acc@1 81.250 (70.729)	Acc@5 93.750 (93.610)
Test: [500/750]	Time 0.125 (0.127)	Loss 0.4672 (0.7594)	Acc@1 81.250 (72.705)	Acc@5 100.000 (93.744)
Test: [600/750]	Time 0.128 (0.127)	Loss 1.3595 (0.8010)	Acc@1 46.875 (71.220)	Acc@5 87.500 (93.646)
Test: [700/750]	Time 0.132 (0.126)	Loss 1.0036 (0.8634)	Acc@1 62.500 (68.679)	Acc@5 87.500 (93.326)
 * Acc@1 68.746 Acc@5 93.246
==> training...
Epoch: [61][0/875]	Time 2.290 (2.290)	Data 1.594 (1.594)	Loss 1.5042 (1.5042)	Loss@kd 1.4378 (1.4378)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [61][100/875]	Time 0.657 (0.676)	Data 0.007 (0.023)	Loss 1.6776 (1.7951)	Loss@kd 1.4135 (1.4438)	Acc@1 78.125 (71.241)	Acc@5 100.000 (98.824)
Epoch: [61][200/875]	Time 0.756 (0.669)	Data 0.007 (0.015)	Loss 1.8677 (1.7848)	Loss@kd 1.4008 (1.4404)	Acc@1 71.875 (71.463)	Acc@5 96.875 (98.912)
Epoch: [61][300/875]	Time 0.642 (0.666)	Data 0.007 (0.013)	Loss 1.6220 (1.7948)	Loss@kd 1.3803 (1.4423)	Acc@1 76.562 (71.112)	Acc@5 98.438 (98.842)
Epoch: [61][400/875]	Time 0.655 (0.665)	Data 0.007 (0.011)	Loss 1.8652 (1.7953)	Loss@kd 1.3883 (1.4407)	Acc@1 71.875 (71.022)	Acc@5 98.438 (98.815)
Epoch: [61][500/875]	Time 0.647 (0.664)	Data 0.007 (0.010)	Loss 1.6751 (1.7912)	Loss@kd 1.4542 (1.4394)	Acc@1 78.125 (71.014)	Acc@5 100.000 (98.855)
Epoch: [61][600/875]	Time 0.632 (0.664)	Data 0.007 (0.010)	Loss 1.9011 (1.7938)	Loss@kd 1.3896 (1.4386)	Acc@1 67.188 (70.939)	Acc@5 98.438 (98.833)
Epoch: [61][700/875]	Time 0.649 (0.663)	Data 0.007 (0.010)	Loss 1.8958 (1.7941)	Loss@kd 1.3713 (1.4387)	Acc@1 65.625 (70.910)	Acc@5 100.000 (98.848)
Epoch: [61][800/875]	Time 0.651 (0.662)	Data 0.007 (0.009)	Loss 1.7701 (1.7917)	Loss@kd 1.5197 (1.4378)	Acc@1 73.438 (71.036)	Acc@5 100.000 (98.859)
 * Acc@1 70.907 Acc@5 98.839
epoch 61, total time 580.13
Test: [0/750]	Time 0.988 (0.988)	Loss 0.6872 (0.6872)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.116 (0.143)	Loss 0.3659 (0.6143)	Acc@1 84.375 (83.385)	Acc@5 100.000 (91.429)
Test: [200/750]	Time 0.127 (0.138)	Loss 1.1290 (0.5151)	Acc@1 53.125 (84.235)	Acc@5 87.500 (94.698)
Test: [300/750]	Time 0.128 (0.135)	Loss 1.1694 (0.6816)	Acc@1 56.250 (75.415)	Acc@5 93.750 (94.695)
Test: [400/750]	Time 0.129 (0.134)	Loss 0.7203 (0.7666)	Acc@1 81.250 (71.314)	Acc@5 90.625 (94.568)
Test: [500/750]	Time 0.130 (0.133)	Loss 0.7385 (0.7977)	Acc@1 68.750 (71.151)	Acc@5 96.875 (93.557)
Test: [600/750]	Time 0.112 (0.133)	Loss 0.8944 (0.8206)	Acc@1 71.875 (70.700)	Acc@5 90.625 (93.469)
Test: [700/750]	Time 0.132 (0.133)	Loss 1.3133 (0.8424)	Acc@1 53.125 (69.606)	Acc@5 84.375 (93.549)
 * Acc@1 69.092 Acc@5 93.387
==> training...
Epoch: [62][0/875]	Time 2.300 (2.300)	Data 1.586 (1.586)	Loss 1.6662 (1.6662)	Loss@kd 1.3779 (1.3779)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [62][100/875]	Time 0.649 (0.679)	Data 0.007 (0.023)	Loss 1.8593 (1.7767)	Loss@kd 1.4299 (1.4329)	Acc@1 73.438 (72.184)	Acc@5 100.000 (98.933)
Epoch: [62][200/875]	Time 0.755 (0.670)	Data 0.007 (0.015)	Loss 1.7399 (1.7850)	Loss@kd 1.4526 (1.4321)	Acc@1 65.625 (71.393)	Acc@5 100.000 (98.912)
Epoch: [62][300/875]	Time 0.654 (0.666)	Data 0.007 (0.013)	Loss 1.7921 (1.7745)	Loss@kd 1.4098 (1.4300)	Acc@1 68.750 (71.782)	Acc@5 98.438 (98.957)
Epoch: [62][400/875]	Time 0.637 (0.664)	Data 0.009 (0.011)	Loss 1.7426 (1.7722)	Loss@kd 1.4007 (1.4314)	Acc@1 68.750 (71.902)	Acc@5 98.438 (98.928)
Epoch: [62][500/875]	Time 0.639 (0.663)	Data 0.007 (0.011)	Loss 1.8390 (1.7792)	Loss@kd 1.4350 (1.4323)	Acc@1 67.188 (71.585)	Acc@5 98.438 (98.952)
Epoch: [62][600/875]	Time 0.644 (0.662)	Data 0.007 (0.010)	Loss 1.7455 (1.7801)	Loss@kd 1.4283 (1.4309)	Acc@1 73.438 (71.498)	Acc@5 98.438 (98.957)
Epoch: [62][700/875]	Time 0.650 (0.661)	Data 0.007 (0.010)	Loss 1.8008 (1.7798)	Loss@kd 1.5157 (1.4302)	Acc@1 73.438 (71.451)	Acc@5 96.875 (98.928)
Epoch: [62][800/875]	Time 0.654 (0.661)	Data 0.007 (0.009)	Loss 1.7357 (1.7804)	Loss@kd 1.3965 (1.4308)	Acc@1 76.562 (71.381)	Acc@5 100.000 (98.929)
 * Acc@1 71.316 Acc@5 98.909
epoch 62, total time 578.80
Test: [0/750]	Time 0.933 (0.933)	Loss 0.6563 (0.6563)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.124 (0.138)	Loss 0.7158 (0.6275)	Acc@1 68.750 (81.838)	Acc@5 93.750 (91.955)
Test: [200/750]	Time 0.121 (0.131)	Loss 1.4974 (0.6874)	Acc@1 43.750 (76.182)	Acc@5 87.500 (93.890)
Test: [300/750]	Time 0.109 (0.128)	Loss 1.0686 (0.8907)	Acc@1 65.625 (66.580)	Acc@5 93.750 (92.909)
Test: [400/750]	Time 0.124 (0.127)	Loss 0.5609 (0.9077)	Acc@1 81.250 (65.726)	Acc@5 90.625 (93.088)
Test: [500/750]	Time 0.121 (0.127)	Loss 0.8409 (0.8769)	Acc@1 65.625 (67.596)	Acc@5 93.750 (92.777)
Test: [600/750]	Time 0.103 (0.126)	Loss 0.4586 (0.8813)	Acc@1 81.250 (68.188)	Acc@5 96.875 (92.538)
Test: [700/750]	Time 0.122 (0.126)	Loss 1.1470 (0.8590)	Acc@1 53.125 (69.049)	Acc@5 84.375 (92.854)
 * Acc@1 68.829 Acc@5 92.733
==> training...
Epoch: [63][0/875]	Time 2.262 (2.262)	Data 1.591 (1.591)	Loss 1.7744 (1.7744)	Loss@kd 1.4146 (1.4146)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [63][100/875]	Time 0.654 (0.679)	Data 0.007 (0.023)	Loss 1.7536 (1.7441)	Loss@kd 1.4116 (1.4166)	Acc@1 73.438 (72.494)	Acc@5 100.000 (99.072)
Epoch: [63][200/875]	Time 0.647 (0.670)	Data 0.007 (0.015)	Loss 1.9946 (1.7577)	Loss@kd 1.4565 (1.4216)	Acc@1 70.312 (71.906)	Acc@5 96.875 (98.974)
Epoch: [63][300/875]	Time 0.746 (0.667)	Data 0.007 (0.013)	Loss 1.7979 (1.7583)	Loss@kd 1.4855 (1.4237)	Acc@1 70.312 (72.062)	Acc@5 100.000 (99.034)
Epoch: [63][400/875]	Time 0.662 (0.665)	Data 0.008 (0.011)	Loss 1.7342 (1.7705)	Loss@kd 1.3664 (1.4247)	Acc@1 73.438 (71.645)	Acc@5 100.000 (98.975)
Epoch: [63][500/875]	Time 0.660 (0.665)	Data 0.007 (0.011)	Loss 1.6893 (1.7685)	Loss@kd 1.3931 (1.4258)	Acc@1 75.000 (71.728)	Acc@5 98.438 (98.958)
Epoch: [63][600/875]	Time 0.645 (0.664)	Data 0.010 (0.010)	Loss 1.6190 (1.7754)	Loss@kd 1.3925 (1.4261)	Acc@1 78.125 (71.438)	Acc@5 98.438 (98.937)
Epoch: [63][700/875]	Time 0.647 (0.664)	Data 0.007 (0.010)	Loss 1.5135 (1.7782)	Loss@kd 1.3406 (1.4272)	Acc@1 82.812 (71.307)	Acc@5 100.000 (98.917)
Epoch: [63][800/875]	Time 0.660 (0.663)	Data 0.007 (0.009)	Loss 1.6431 (1.7773)	Loss@kd 1.3904 (1.4275)	Acc@1 75.000 (71.298)	Acc@5 98.438 (98.913)
 * Acc@1 71.264 Acc@5 98.905
epoch 63, total time 580.84
Test: [0/750]	Time 1.046 (1.046)	Loss 0.5091 (0.5091)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.194 (0.139)	Loss 0.5578 (0.5604)	Acc@1 78.125 (83.818)	Acc@5 96.875 (94.864)
Test: [200/750]	Time 0.119 (0.131)	Loss 1.8681 (0.6143)	Acc@1 25.000 (79.384)	Acc@5 71.875 (94.900)
Test: [300/750]	Time 0.108 (0.127)	Loss 0.9239 (0.9520)	Acc@1 68.750 (65.864)	Acc@5 96.875 (90.168)
Test: [400/750]	Time 0.114 (0.126)	Loss 0.6454 (0.9577)	Acc@1 84.375 (65.352)	Acc@5 90.625 (91.209)
Test: [500/750]	Time 0.124 (0.125)	Loss 0.6856 (0.9190)	Acc@1 75.000 (67.384)	Acc@5 100.000 (91.299)
Test: [600/750]	Time 0.118 (0.124)	Loss 0.7239 (0.9044)	Acc@1 78.125 (68.240)	Acc@5 93.750 (91.639)
Test: [700/750]	Time 0.136 (0.125)	Loss 1.4153 (0.8986)	Acc@1 43.750 (68.135)	Acc@5 78.125 (91.846)
 * Acc@1 67.354 Acc@5 91.554
==> training...
Epoch: [64][0/875]	Time 2.237 (2.237)	Data 1.594 (1.594)	Loss 1.6967 (1.6967)	Loss@kd 1.4721 (1.4721)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [64][100/875]	Time 0.651 (0.678)	Data 0.007 (0.023)	Loss 2.0287 (1.7694)	Loss@kd 1.4544 (1.4277)	Acc@1 62.500 (72.153)	Acc@5 95.312 (99.196)
Epoch: [64][200/875]	Time 0.659 (0.670)	Data 0.007 (0.015)	Loss 1.7659 (1.7618)	Loss@kd 1.4601 (1.4233)	Acc@1 75.000 (71.859)	Acc@5 100.000 (99.129)
Epoch: [64][300/875]	Time 0.643 (0.667)	Data 0.007 (0.013)	Loss 1.8379 (1.7601)	Loss@kd 1.3754 (1.4196)	Acc@1 68.750 (71.683)	Acc@5 98.438 (99.050)
Epoch: [64][400/875]	Time 0.657 (0.665)	Data 0.007 (0.011)	Loss 1.8969 (1.7626)	Loss@kd 1.4492 (1.4223)	Acc@1 59.375 (71.723)	Acc@5 100.000 (99.010)
Epoch: [64][500/875]	Time 0.642 (0.664)	Data 0.007 (0.011)	Loss 1.8541 (1.7672)	Loss@kd 1.4063 (1.4212)	Acc@1 70.312 (71.482)	Acc@5 98.438 (98.933)
Epoch: [64][600/875]	Time 0.662 (0.664)	Data 0.007 (0.010)	Loss 1.8376 (1.7674)	Loss@kd 1.4307 (1.4238)	Acc@1 67.188 (71.579)	Acc@5 100.000 (98.950)
Epoch: [64][700/875]	Time 0.644 (0.663)	Data 0.007 (0.010)	Loss 1.7469 (1.7669)	Loss@kd 1.3963 (1.4228)	Acc@1 71.875 (71.565)	Acc@5 98.438 (98.959)
Epoch: [64][800/875]	Time 0.659 (0.662)	Data 0.007 (0.009)	Loss 1.9312 (1.7686)	Loss@kd 1.4775 (1.4236)	Acc@1 62.500 (71.510)	Acc@5 100.000 (98.952)
 * Acc@1 71.600 Acc@5 98.959
epoch 64, total time 579.99
Test: [0/750]	Time 0.918 (0.918)	Loss 0.4718 (0.4718)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.109 (0.136)	Loss 0.4406 (0.4919)	Acc@1 84.375 (85.272)	Acc@5 96.875 (94.214)
Test: [200/750]	Time 0.180 (0.129)	Loss 1.3219 (0.4757)	Acc@1 43.750 (84.608)	Acc@5 93.750 (95.787)
Test: [300/750]	Time 0.106 (0.128)	Loss 1.0765 (0.7281)	Acc@1 56.250 (73.121)	Acc@5 96.875 (94.664)
Test: [400/750]	Time 0.093 (0.127)	Loss 0.6795 (0.8208)	Acc@1 87.500 (69.685)	Acc@5 87.500 (93.828)
Test: [500/750]	Time 0.101 (0.127)	Loss 0.5281 (0.7997)	Acc@1 75.000 (71.133)	Acc@5 96.875 (93.432)
Test: [600/750]	Time 0.126 (0.126)	Loss 1.0178 (0.8060)	Acc@1 68.750 (71.178)	Acc@5 87.500 (93.428)
Test: [700/750]	Time 0.116 (0.126)	Loss 0.7989 (0.8150)	Acc@1 71.875 (70.613)	Acc@5 93.750 (93.652)
 * Acc@1 70.662 Acc@5 93.667
saving the best model!
==> training...
Epoch: [65][0/875]	Time 2.289 (2.289)	Data 1.595 (1.595)	Loss 1.8779 (1.8779)	Loss@kd 1.4225 (1.4225)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [65][100/875]	Time 0.713 (0.673)	Data 0.007 (0.023)	Loss 1.7597 (1.7428)	Loss@kd 1.4637 (1.4110)	Acc@1 70.312 (71.860)	Acc@5 100.000 (99.087)
Epoch: [65][200/875]	Time 0.641 (0.663)	Data 0.007 (0.015)	Loss 1.9126 (1.7434)	Loss@kd 1.3839 (1.4125)	Acc@1 71.875 (72.015)	Acc@5 100.000 (99.005)
Epoch: [65][300/875]	Time 0.650 (0.661)	Data 0.007 (0.013)	Loss 1.8498 (1.7503)	Loss@kd 1.4232 (1.4176)	Acc@1 73.438 (72.000)	Acc@5 96.875 (98.957)
Epoch: [65][400/875]	Time 0.650 (0.660)	Data 0.010 (0.011)	Loss 1.5296 (1.7486)	Loss@kd 1.3708 (1.4190)	Acc@1 78.125 (72.070)	Acc@5 100.000 (98.979)
Epoch: [65][500/875]	Time 0.637 (0.660)	Data 0.007 (0.011)	Loss 1.4664 (1.7521)	Loss@kd 1.3157 (1.4188)	Acc@1 82.812 (71.972)	Acc@5 100.000 (98.983)
Epoch: [65][600/875]	Time 0.641 (0.660)	Data 0.007 (0.010)	Loss 1.9316 (1.7553)	Loss@kd 1.5039 (1.4187)	Acc@1 67.188 (71.753)	Acc@5 98.438 (98.973)
Epoch: [65][700/875]	Time 0.632 (0.660)	Data 0.006 (0.010)	Loss 1.8711 (1.7574)	Loss@kd 1.4443 (1.4169)	Acc@1 68.750 (71.599)	Acc@5 95.312 (98.952)
Epoch: [65][800/875]	Time 0.650 (0.660)	Data 0.007 (0.009)	Loss 1.9362 (1.7602)	Loss@kd 1.3500 (1.4172)	Acc@1 56.250 (71.565)	Acc@5 98.438 (98.939)
 * Acc@1 71.586 Acc@5 98.932
epoch 65, total time 578.17
Test: [0/750]	Time 1.146 (1.146)	Loss 0.4956 (0.4956)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.132 (0.139)	Loss 0.6510 (0.4909)	Acc@1 68.750 (84.097)	Acc@5 93.750 (94.616)
Test: [200/750]	Time 0.124 (0.130)	Loss 1.0747 (0.5474)	Acc@1 56.250 (80.302)	Acc@5 90.625 (95.896)
Test: [300/750]	Time 0.113 (0.129)	Loss 1.0139 (0.7149)	Acc@1 56.250 (72.643)	Acc@5 93.750 (95.349)
Test: [400/750]	Time 0.102 (0.127)	Loss 0.6373 (0.7550)	Acc@1 81.250 (71.205)	Acc@5 90.625 (95.215)
Test: [500/750]	Time 0.120 (0.126)	Loss 0.7517 (0.7557)	Acc@1 75.000 (72.255)	Acc@5 90.625 (94.667)
Test: [600/750]	Time 0.110 (0.126)	Loss 0.8446 (0.7870)	Acc@1 62.500 (71.547)	Acc@5 93.750 (94.213)
Test: [700/750]	Time 0.078 (0.126)	Loss 1.2832 (0.8132)	Acc@1 56.250 (70.448)	Acc@5 87.500 (93.982)
 * Acc@1 69.508 Acc@5 93.717
==> training...
Epoch: [66][0/875]	Time 2.250 (2.250)	Data 1.591 (1.591)	Loss 1.7727 (1.7727)	Loss@kd 1.5497 (1.5497)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [66][100/875]	Time 0.643 (0.677)	Data 0.007 (0.023)	Loss 1.7356 (1.7479)	Loss@kd 1.3440 (1.4019)	Acc@1 70.312 (72.386)	Acc@5 98.438 (99.041)
Epoch: [66][200/875]	Time 0.655 (0.669)	Data 0.007 (0.015)	Loss 1.7901 (1.7482)	Loss@kd 1.4101 (1.4093)	Acc@1 68.750 (72.217)	Acc@5 100.000 (99.059)
Epoch: [66][300/875]	Time 0.648 (0.666)	Data 0.007 (0.013)	Loss 1.9192 (1.7426)	Loss@kd 1.4270 (1.4085)	Acc@1 62.500 (72.337)	Acc@5 98.438 (99.071)
Epoch: [66][400/875]	Time 0.642 (0.665)	Data 0.007 (0.011)	Loss 1.7099 (1.7529)	Loss@kd 1.3881 (1.4126)	Acc@1 71.875 (72.120)	Acc@5 98.438 (98.964)
Epoch: [66][500/875]	Time 0.653 (0.664)	Data 0.007 (0.010)	Loss 1.6293 (1.7542)	Loss@kd 1.4987 (1.4133)	Acc@1 78.125 (72.056)	Acc@5 100.000 (98.940)
Epoch: [66][600/875]	Time 0.653 (0.663)	Data 0.005 (0.010)	Loss 1.8289 (1.7548)	Loss@kd 1.3340 (1.4130)	Acc@1 71.875 (71.930)	Acc@5 100.000 (98.918)
Epoch: [66][700/875]	Time 0.631 (0.663)	Data 0.007 (0.010)	Loss 1.7448 (1.7570)	Loss@kd 1.3798 (1.4130)	Acc@1 71.875 (71.837)	Acc@5 100.000 (98.919)
Epoch: [66][800/875]	Time 0.656 (0.662)	Data 0.007 (0.009)	Loss 1.7208 (1.7576)	Loss@kd 1.4228 (1.4133)	Acc@1 75.000 (71.760)	Acc@5 98.438 (98.919)
 * Acc@1 71.802 Acc@5 98.927
epoch 66, total time 579.77
Test: [0/750]	Time 0.990 (0.990)	Loss 0.4027 (0.4027)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.106 (0.140)	Loss 0.3353 (0.4201)	Acc@1 87.500 (87.376)	Acc@5 100.000 (95.637)
Test: [200/750]	Time 0.117 (0.136)	Loss 0.9162 (0.4335)	Acc@1 68.750 (86.521)	Acc@5 90.625 (96.844)
Test: [300/750]	Time 0.134 (0.133)	Loss 1.3775 (0.6236)	Acc@1 50.000 (78.551)	Acc@5 93.750 (96.179)
Test: [400/750]	Time 0.219 (0.133)	Loss 0.4567 (0.7557)	Acc@1 84.375 (72.545)	Acc@5 96.875 (95.059)
Test: [500/750]	Time 0.134 (0.132)	Loss 0.6396 (0.7291)	Acc@1 68.750 (73.921)	Acc@5 100.000 (94.798)
Test: [600/750]	Time 0.133 (0.131)	Loss 1.0265 (0.7716)	Acc@1 62.500 (72.359)	Acc@5 87.500 (94.234)
Test: [700/750]	Time 0.125 (0.131)	Loss 1.2113 (0.8022)	Acc@1 56.250 (70.992)	Acc@5 90.625 (93.973)
 * Acc@1 70.479 Acc@5 93.637
==> training...
Epoch: [67][0/875]	Time 2.263 (2.263)	Data 1.574 (1.574)	Loss 1.6792 (1.6792)	Loss@kd 1.3884 (1.3884)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [67][100/875]	Time 0.652 (0.676)	Data 0.006 (0.023)	Loss 1.6295 (1.7365)	Loss@kd 1.4261 (1.4105)	Acc@1 75.000 (71.890)	Acc@5 100.000 (99.041)
Epoch: [67][200/875]	Time 0.660 (0.667)	Data 0.007 (0.015)	Loss 1.8451 (1.7423)	Loss@kd 1.4509 (1.4110)	Acc@1 62.500 (71.914)	Acc@5 98.438 (99.021)
Epoch: [67][300/875]	Time 0.697 (0.664)	Data 0.007 (0.013)	Loss 1.7989 (1.7408)	Loss@kd 1.3882 (1.4120)	Acc@1 67.188 (72.135)	Acc@5 98.438 (99.019)
Epoch: [67][400/875]	Time 0.644 (0.660)	Data 0.007 (0.011)	Loss 1.9229 (1.7385)	Loss@kd 1.3830 (1.4091)	Acc@1 68.750 (72.159)	Acc@5 96.875 (99.073)
Epoch: [67][500/875]	Time 0.653 (0.659)	Data 0.007 (0.010)	Loss 1.6055 (1.7392)	Loss@kd 1.4569 (1.4086)	Acc@1 75.000 (72.153)	Acc@5 100.000 (99.005)
Epoch: [67][600/875]	Time 0.628 (0.657)	Data 0.008 (0.010)	Loss 1.7134 (1.7406)	Loss@kd 1.3270 (1.4084)	Acc@1 65.625 (72.047)	Acc@5 100.000 (99.038)
Epoch: [67][700/875]	Time 0.646 (0.658)	Data 0.007 (0.010)	Loss 1.8875 (1.7459)	Loss@kd 1.4515 (1.4096)	Acc@1 71.875 (72.013)	Acc@5 98.438 (98.995)
Epoch: [67][800/875]	Time 0.652 (0.659)	Data 0.007 (0.009)	Loss 1.8516 (1.7451)	Loss@kd 1.3935 (1.4100)	Acc@1 70.312 (72.092)	Acc@5 96.875 (98.976)
 * Acc@1 71.995 Acc@5 98.961
epoch 67, total time 577.07
Test: [0/750]	Time 1.066 (1.066)	Loss 0.4924 (0.4924)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.109 (0.140)	Loss 0.3989 (0.5463)	Acc@1 81.250 (84.530)	Acc@5 100.000 (94.152)
Test: [200/750]	Time 0.136 (0.134)	Loss 1.3384 (0.5252)	Acc@1 50.000 (83.007)	Acc@5 81.250 (95.818)
Test: [300/750]	Time 0.106 (0.130)	Loss 1.2392 (0.7462)	Acc@1 40.625 (73.463)	Acc@5 96.875 (94.269)
Test: [400/750]	Time 0.119 (0.129)	Loss 0.7485 (0.8504)	Acc@1 84.375 (69.249)	Acc@5 90.625 (93.290)
Test: [500/750]	Time 0.112 (0.128)	Loss 0.6880 (0.8225)	Acc@1 78.125 (70.746)	Acc@5 100.000 (93.139)
Test: [600/750]	Time 0.125 (0.128)	Loss 0.7523 (0.8264)	Acc@1 75.000 (70.923)	Acc@5 93.750 (93.282)
Test: [700/750]	Time 0.212 (0.128)	Loss 1.1359 (0.8263)	Acc@1 56.250 (70.832)	Acc@5 78.125 (93.313)
 * Acc@1 70.579 Acc@5 93.129
==> training...
Epoch: [68][0/875]	Time 2.292 (2.292)	Data 1.605 (1.605)	Loss 1.5981 (1.5981)	Loss@kd 1.3656 (1.3656)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [68][100/875]	Time 0.648 (0.680)	Data 0.007 (0.023)	Loss 1.7407 (1.7101)	Loss@kd 1.3394 (1.4073)	Acc@1 73.438 (73.438)	Acc@5 96.875 (99.087)
Epoch: [68][200/875]	Time 0.643 (0.671)	Data 0.007 (0.015)	Loss 1.4786 (1.7325)	Loss@kd 1.3522 (1.4091)	Acc@1 82.812 (72.761)	Acc@5 100.000 (98.982)
Epoch: [68][300/875]	Time 0.651 (0.667)	Data 0.007 (0.013)	Loss 1.6868 (1.7418)	Loss@kd 1.4511 (1.4104)	Acc@1 71.875 (72.446)	Acc@5 100.000 (98.951)
Epoch: [68][400/875]	Time 0.665 (0.665)	Data 0.007 (0.011)	Loss 1.6985 (1.7468)	Loss@kd 1.3427 (1.4092)	Acc@1 70.312 (72.284)	Acc@5 100.000 (98.917)
Epoch: [68][500/875]	Time 0.645 (0.665)	Data 0.007 (0.011)	Loss 1.5577 (1.7407)	Loss@kd 1.4226 (1.4072)	Acc@1 84.375 (72.446)	Acc@5 98.438 (98.983)
Epoch: [68][600/875]	Time 0.651 (0.664)	Data 0.007 (0.010)	Loss 1.6609 (1.7410)	Loss@kd 1.3790 (1.4080)	Acc@1 73.438 (72.322)	Acc@5 100.000 (98.986)
Epoch: [68][700/875]	Time 0.648 (0.664)	Data 0.007 (0.010)	Loss 1.7310 (1.7411)	Loss@kd 1.3863 (1.4075)	Acc@1 73.438 (72.272)	Acc@5 98.438 (98.993)
Epoch: [68][800/875]	Time 0.654 (0.663)	Data 0.007 (0.009)	Loss 1.5741 (1.7463)	Loss@kd 1.3843 (1.4080)	Acc@1 78.125 (72.115)	Acc@5 98.438 (98.968)
 * Acc@1 72.020 Acc@5 98.982
epoch 68, total time 580.56
Test: [0/750]	Time 1.014 (1.014)	Loss 0.5249 (0.5249)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.130 (0.140)	Loss 0.3301 (0.4785)	Acc@1 84.375 (85.891)	Acc@5 100.000 (94.245)
Test: [200/750]	Time 0.118 (0.134)	Loss 1.2860 (0.4636)	Acc@1 43.750 (85.183)	Acc@5 93.750 (95.958)
Test: [300/750]	Time 0.122 (0.133)	Loss 1.3625 (0.7297)	Acc@1 43.750 (73.775)	Acc@5 93.750 (94.487)
Test: [400/750]	Time 0.121 (0.132)	Loss 0.6813 (0.8553)	Acc@1 81.250 (68.766)	Acc@5 87.500 (93.579)
Test: [500/750]	Time 0.106 (0.131)	Loss 0.4316 (0.8084)	Acc@1 84.375 (71.008)	Acc@5 100.000 (93.719)
Test: [600/750]	Time 0.128 (0.131)	Loss 0.8208 (0.8056)	Acc@1 75.000 (71.147)	Acc@5 93.750 (93.932)
Test: [700/750]	Time 0.113 (0.131)	Loss 1.3649 (0.8236)	Acc@1 56.250 (70.315)	Acc@5 87.500 (93.746)
 * Acc@1 70.179 Acc@5 93.500
==> training...
Epoch: [69][0/875]	Time 2.311 (2.311)	Data 1.609 (1.609)	Loss 1.7185 (1.7185)	Loss@kd 1.4182 (1.4182)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [69][100/875]	Time 0.648 (0.678)	Data 0.007 (0.023)	Loss 1.7643 (1.7289)	Loss@kd 1.3963 (1.3979)	Acc@1 70.312 (72.339)	Acc@5 98.438 (98.963)
Epoch: [69][200/875]	Time 0.657 (0.670)	Data 0.007 (0.015)	Loss 1.6852 (1.7346)	Loss@kd 1.4161 (1.4046)	Acc@1 79.688 (72.559)	Acc@5 98.438 (99.005)
Epoch: [69][300/875]	Time 0.642 (0.667)	Data 0.007 (0.013)	Loss 1.7663 (1.7394)	Loss@kd 1.4405 (1.4064)	Acc@1 70.312 (72.270)	Acc@5 100.000 (99.009)
Epoch: [69][400/875]	Time 0.751 (0.665)	Data 0.007 (0.011)	Loss 1.8942 (1.7448)	Loss@kd 1.4259 (1.4093)	Acc@1 71.875 (71.976)	Acc@5 96.875 (99.002)
Epoch: [69][500/875]	Time 0.645 (0.664)	Data 0.007 (0.011)	Loss 1.5485 (1.7431)	Loss@kd 1.4005 (1.4079)	Acc@1 81.250 (71.940)	Acc@5 100.000 (99.043)
Epoch: [69][600/875]	Time 0.660 (0.663)	Data 0.007 (0.010)	Loss 1.6007 (1.7452)	Loss@kd 1.4316 (1.4078)	Acc@1 75.000 (71.867)	Acc@5 100.000 (99.017)
Epoch: [69][700/875]	Time 0.646 (0.663)	Data 0.007 (0.010)	Loss 1.7389 (1.7450)	Loss@kd 1.4188 (1.4072)	Acc@1 70.312 (71.868)	Acc@5 100.000 (99.010)
Epoch: [69][800/875]	Time 0.642 (0.662)	Data 0.008 (0.009)	Loss 1.8180 (1.7432)	Loss@kd 1.4267 (1.4073)	Acc@1 67.188 (71.969)	Acc@5 100.000 (99.011)
 * Acc@1 71.929 Acc@5 99.000
epoch 69, total time 579.72
Test: [0/750]	Time 1.013 (1.013)	Loss 0.5195 (0.5195)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.124 (0.141)	Loss 0.2921 (0.5409)	Acc@1 84.375 (84.189)	Acc@5 100.000 (93.905)
Test: [200/750]	Time 0.174 (0.134)	Loss 1.3022 (0.4747)	Acc@1 50.000 (85.012)	Acc@5 87.500 (95.864)
Test: [300/750]	Time 0.130 (0.131)	Loss 1.3303 (0.7104)	Acc@1 59.375 (74.855)	Acc@5 96.875 (94.591)
Test: [400/750]	Time 0.084 (0.130)	Loss 0.9584 (0.8150)	Acc@1 71.875 (70.114)	Acc@5 87.500 (93.773)
Test: [500/750]	Time 0.108 (0.129)	Loss 0.6491 (0.8267)	Acc@1 71.875 (70.715)	Acc@5 96.875 (92.852)
Test: [600/750]	Time 0.126 (0.128)	Loss 0.9681 (0.8412)	Acc@1 62.500 (70.248)	Acc@5 90.625 (92.986)
Test: [700/750]	Time 0.094 (0.127)	Loss 1.2586 (0.8619)	Acc@1 56.250 (69.231)	Acc@5 84.375 (93.028)
 * Acc@1 69.125 Acc@5 92.762
==> training...
Epoch: [70][0/875]	Time 2.309 (2.309)	Data 1.599 (1.599)	Loss 1.5864 (1.5864)	Loss@kd 1.3816 (1.3816)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [70][100/875]	Time 0.653 (0.678)	Data 0.007 (0.023)	Loss 1.6367 (1.7378)	Loss@kd 1.3827 (1.3988)	Acc@1 78.125 (72.215)	Acc@5 98.438 (98.933)
Epoch: [70][200/875]	Time 0.657 (0.667)	Data 0.007 (0.015)	Loss 1.7632 (1.7307)	Loss@kd 1.4315 (1.4034)	Acc@1 75.000 (72.373)	Acc@5 98.438 (98.989)
Epoch: [70][300/875]	Time 0.654 (0.665)	Data 0.008 (0.013)	Loss 1.6042 (1.7355)	Loss@kd 1.4194 (1.4034)	Acc@1 84.375 (72.264)	Acc@5 100.000 (98.962)
Epoch: [70][400/875]	Time 0.731 (0.664)	Data 0.007 (0.011)	Loss 1.9665 (1.7372)	Loss@kd 1.5864 (1.4032)	Acc@1 73.438 (72.226)	Acc@5 96.875 (98.975)
Epoch: [70][500/875]	Time 0.652 (0.663)	Data 0.007 (0.010)	Loss 1.7370 (1.7382)	Loss@kd 1.4129 (1.4022)	Acc@1 73.438 (72.178)	Acc@5 96.875 (98.999)
Epoch: [70][600/875]	Time 0.649 (0.663)	Data 0.007 (0.010)	Loss 1.7614 (1.7364)	Loss@kd 1.3512 (1.4010)	Acc@1 71.875 (72.239)	Acc@5 98.438 (98.978)
Epoch: [70][700/875]	Time 0.639 (0.662)	Data 0.007 (0.010)	Loss 1.6300 (1.7353)	Loss@kd 1.4329 (1.4003)	Acc@1 84.375 (72.301)	Acc@5 98.438 (98.970)
Epoch: [70][800/875]	Time 0.656 (0.662)	Data 0.007 (0.009)	Loss 1.7551 (1.7375)	Loss@kd 1.3844 (1.3996)	Acc@1 70.312 (72.138)	Acc@5 100.000 (98.974)
 * Acc@1 72.055 Acc@5 98.966
epoch 70, total time 579.91
Test: [0/750]	Time 1.020 (1.020)	Loss 0.5512 (0.5512)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.112 (0.143)	Loss 0.3208 (0.5774)	Acc@1 87.500 (83.973)	Acc@5 100.000 (93.007)
Test: [200/750]	Time 0.102 (0.132)	Loss 1.4041 (0.5275)	Acc@1 46.875 (83.458)	Acc@5 84.375 (95.087)
Test: [300/750]	Time 0.111 (0.130)	Loss 1.0539 (0.7834)	Acc@1 68.750 (71.782)	Acc@5 90.625 (93.563)
Test: [400/750]	Time 0.098 (0.128)	Loss 0.6620 (0.8340)	Acc@1 81.250 (69.716)	Acc@5 90.625 (93.430)
Test: [500/750]	Time 0.121 (0.128)	Loss 0.3928 (0.8214)	Acc@1 84.375 (70.933)	Acc@5 100.000 (92.927)
Test: [600/750]	Time 0.130 (0.127)	Loss 0.7813 (0.8209)	Acc@1 65.625 (71.261)	Acc@5 96.875 (92.913)
Test: [700/750]	Time 0.115 (0.127)	Loss 1.0680 (0.8247)	Acc@1 56.250 (70.573)	Acc@5 90.625 (93.344)
 * Acc@1 70.404 Acc@5 93.463
==> training...
Epoch: [71][0/875]	Time 2.332 (2.332)	Data 1.673 (1.673)	Loss 1.7615 (1.7615)	Loss@kd 1.4641 (1.4641)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [71][100/875]	Time 0.645 (0.678)	Data 0.005 (0.024)	Loss 1.7461 (1.7270)	Loss@kd 1.4163 (1.3995)	Acc@1 73.438 (72.525)	Acc@5 98.438 (98.933)
Epoch: [71][200/875]	Time 0.656 (0.669)	Data 0.007 (0.016)	Loss 1.8046 (1.7225)	Loss@kd 1.3595 (1.3950)	Acc@1 67.188 (72.442)	Acc@5 100.000 (98.989)
Epoch: [71][300/875]	Time 0.652 (0.667)	Data 0.007 (0.013)	Loss 1.4538 (1.7255)	Loss@kd 1.3597 (1.3967)	Acc@1 84.375 (72.321)	Acc@5 100.000 (99.003)
Epoch: [71][400/875]	Time 0.644 (0.665)	Data 0.007 (0.012)	Loss 1.9191 (1.7332)	Loss@kd 1.4328 (1.3971)	Acc@1 70.312 (72.187)	Acc@5 95.312 (99.049)
Epoch: [71][500/875]	Time 0.730 (0.664)	Data 0.007 (0.011)	Loss 1.7938 (1.7289)	Loss@kd 1.3616 (1.3985)	Acc@1 67.188 (72.337)	Acc@5 98.438 (99.049)
Epoch: [71][600/875]	Time 0.645 (0.663)	Data 0.007 (0.010)	Loss 1.6786 (1.7288)	Loss@kd 1.4179 (1.3952)	Acc@1 73.438 (72.309)	Acc@5 98.438 (99.043)
Epoch: [71][700/875]	Time 0.654 (0.662)	Data 0.007 (0.010)	Loss 1.9846 (1.7293)	Loss@kd 1.7265 (1.3958)	Acc@1 68.750 (72.345)	Acc@5 100.000 (99.006)
Epoch: [71][800/875]	Time 0.646 (0.661)	Data 0.007 (0.009)	Loss 1.8283 (1.7291)	Loss@kd 1.3437 (1.3954)	Acc@1 67.188 (72.302)	Acc@5 95.312 (98.982)
 * Acc@1 72.329 Acc@5 98.980
epoch 71, total time 578.87
Test: [0/750]	Time 1.094 (1.094)	Loss 0.6633 (0.6633)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.120 (0.143)	Loss 0.4097 (0.5877)	Acc@1 87.500 (83.818)	Acc@5 100.000 (92.450)
Test: [200/750]	Time 0.114 (0.134)	Loss 1.1721 (0.5879)	Acc@1 56.250 (80.566)	Acc@5 87.500 (94.481)
Test: [300/750]	Time 0.116 (0.131)	Loss 1.3623 (0.7612)	Acc@1 62.500 (72.436)	Acc@5 93.750 (94.352)
Test: [400/750]	Time 0.124 (0.129)	Loss 0.7519 (0.8410)	Acc@1 81.250 (68.602)	Acc@5 90.625 (94.155)
Test: [500/750]	Time 0.112 (0.128)	Loss 0.5496 (0.8299)	Acc@1 78.125 (69.785)	Acc@5 100.000 (93.681)
Test: [600/750]	Time 0.100 (0.127)	Loss 0.7774 (0.8289)	Acc@1 65.625 (70.029)	Acc@5 93.750 (93.630)
Test: [700/750]	Time 0.126 (0.126)	Loss 1.0291 (0.8135)	Acc@1 68.750 (70.618)	Acc@5 87.500 (93.897)
 * Acc@1 71.058 Acc@5 94.025
saving the best model!
==> training...
Epoch: [72][0/875]	Time 2.290 (2.290)	Data 1.615 (1.615)	Loss 1.5988 (1.5988)	Loss@kd 1.3359 (1.3359)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [72][100/875]	Time 0.633 (0.677)	Data 0.006 (0.023)	Loss 1.6949 (1.6977)	Loss@kd 1.3638 (1.3950)	Acc@1 78.125 (73.654)	Acc@5 98.438 (99.226)
Epoch: [72][200/875]	Time 0.643 (0.668)	Data 0.007 (0.015)	Loss 1.8286 (1.7219)	Loss@kd 1.4280 (1.3956)	Acc@1 71.875 (72.466)	Acc@5 96.875 (99.028)
Epoch: [72][300/875]	Time 0.643 (0.664)	Data 0.007 (0.013)	Loss 1.7408 (1.7254)	Loss@kd 1.3754 (1.3952)	Acc@1 75.000 (72.467)	Acc@5 98.438 (99.009)
Epoch: [72][400/875]	Time 0.654 (0.662)	Data 0.007 (0.011)	Loss 1.6199 (1.7203)	Loss@kd 1.4104 (1.3942)	Acc@1 79.688 (72.647)	Acc@5 100.000 (98.987)
Epoch: [72][500/875]	Time 0.658 (0.662)	Data 0.007 (0.011)	Loss 1.9060 (1.7204)	Loss@kd 1.4480 (1.3956)	Acc@1 67.188 (72.555)	Acc@5 100.000 (98.996)
Epoch: [72][600/875]	Time 0.646 (0.661)	Data 0.007 (0.010)	Loss 1.8383 (1.7209)	Loss@kd 1.4406 (1.3954)	Acc@1 70.312 (72.561)	Acc@5 98.438 (98.999)
Epoch: [72][700/875]	Time 0.635 (0.661)	Data 0.007 (0.010)	Loss 1.7701 (1.7227)	Loss@kd 1.3734 (1.3950)	Acc@1 67.188 (72.479)	Acc@5 100.000 (99.008)
Epoch: [72][800/875]	Time 0.661 (0.661)	Data 0.007 (0.009)	Loss 1.7432 (1.7241)	Loss@kd 1.3270 (1.3953)	Acc@1 70.312 (72.450)	Acc@5 100.000 (99.009)
 * Acc@1 72.432 Acc@5 99.000
epoch 72, total time 579.02
Test: [0/750]	Time 1.044 (1.044)	Loss 0.5058 (0.5058)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.123 (0.139)	Loss 0.4015 (0.4480)	Acc@1 84.375 (86.077)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.094 (0.132)	Loss 1.3065 (0.4756)	Acc@1 53.125 (83.924)	Acc@5 87.500 (95.647)
Test: [300/750]	Time 0.125 (0.129)	Loss 1.3441 (0.7369)	Acc@1 50.000 (72.747)	Acc@5 93.750 (94.477)
Test: [400/750]	Time 0.117 (0.128)	Loss 0.7382 (0.8584)	Acc@1 81.250 (67.675)	Acc@5 87.500 (93.820)
Test: [500/750]	Time 0.117 (0.127)	Loss 0.4939 (0.8334)	Acc@1 87.500 (69.330)	Acc@5 100.000 (93.370)
Test: [600/750]	Time 0.127 (0.126)	Loss 0.9698 (0.8396)	Acc@1 65.625 (69.520)	Acc@5 93.750 (93.214)
Test: [700/750]	Time 0.129 (0.126)	Loss 0.6846 (0.8203)	Acc@1 75.000 (70.239)	Acc@5 90.625 (93.625)
 * Acc@1 71.188 Acc@5 93.850
saving the best model!
==> training...
Epoch: [73][0/875]	Time 2.295 (2.295)	Data 1.588 (1.588)	Loss 1.6429 (1.6429)	Loss@kd 1.3999 (1.3999)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [73][100/875]	Time 0.741 (0.680)	Data 0.007 (0.023)	Loss 1.7165 (1.7013)	Loss@kd 1.3780 (1.3920)	Acc@1 67.188 (73.283)	Acc@5 100.000 (99.041)
Epoch: [73][200/875]	Time 0.662 (0.671)	Data 0.007 (0.015)	Loss 1.9457 (1.7036)	Loss@kd 1.3837 (1.3910)	Acc@1 56.250 (73.158)	Acc@5 98.438 (99.059)
Epoch: [73][300/875]	Time 0.646 (0.668)	Data 0.007 (0.013)	Loss 1.6333 (1.7114)	Loss@kd 1.3884 (1.3954)	Acc@1 76.562 (73.059)	Acc@5 98.438 (99.092)
Epoch: [73][400/875]	Time 0.650 (0.667)	Data 0.008 (0.011)	Loss 1.5870 (1.7144)	Loss@kd 1.3817 (1.3940)	Acc@1 78.125 (72.986)	Acc@5 100.000 (99.069)
Epoch: [73][500/875]	Time 0.639 (0.666)	Data 0.010 (0.011)	Loss 1.6737 (1.7196)	Loss@kd 1.3306 (1.3953)	Acc@1 73.438 (72.761)	Acc@5 100.000 (99.055)
Epoch: [73][600/875]	Time 0.658 (0.664)	Data 0.007 (0.010)	Loss 1.6644 (1.7179)	Loss@kd 1.3281 (1.3953)	Acc@1 73.438 (72.777)	Acc@5 100.000 (99.064)
Epoch: [73][700/875]	Time 0.649 (0.664)	Data 0.011 (0.010)	Loss 1.6924 (1.7150)	Loss@kd 1.3872 (1.3937)	Acc@1 71.875 (72.778)	Acc@5 100.000 (99.066)
Epoch: [73][800/875]	Time 0.659 (0.663)	Data 0.008 (0.010)	Loss 1.6991 (1.7196)	Loss@kd 1.3433 (1.3939)	Acc@1 70.312 (72.612)	Acc@5 100.000 (99.036)
 * Acc@1 72.523 Acc@5 99.029
epoch 73, total time 580.58
Test: [0/750]	Time 1.122 (1.122)	Loss 0.5641 (0.5641)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.119 (0.137)	Loss 0.4534 (0.5104)	Acc@1 81.250 (84.808)	Acc@5 96.875 (93.100)
Test: [200/750]	Time 0.122 (0.132)	Loss 1.2364 (0.5291)	Acc@1 46.875 (82.167)	Acc@5 93.750 (95.103)
Test: [300/750]	Time 0.135 (0.128)	Loss 1.1789 (0.7421)	Acc@1 50.000 (72.456)	Acc@5 96.875 (94.238)
Test: [400/750]	Time 0.100 (0.127)	Loss 0.7607 (0.8167)	Acc@1 81.250 (69.311)	Acc@5 87.500 (94.124)
Test: [500/750]	Time 0.113 (0.126)	Loss 0.3955 (0.7946)	Acc@1 87.500 (70.846)	Acc@5 100.000 (93.725)
Test: [600/750]	Time 0.134 (0.125)	Loss 1.1085 (0.7967)	Acc@1 65.625 (71.313)	Acc@5 87.500 (93.677)
Test: [700/750]	Time 0.115 (0.125)	Loss 0.9918 (0.8111)	Acc@1 62.500 (70.654)	Acc@5 90.625 (93.697)
 * Acc@1 70.542 Acc@5 93.704
==> training...
Epoch: [74][0/875]	Time 2.288 (2.288)	Data 1.608 (1.608)	Loss 1.7713 (1.7713)	Loss@kd 1.3699 (1.3699)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [74][100/875]	Time 0.735 (0.678)	Data 0.007 (0.023)	Loss 1.6118 (1.6689)	Loss@kd 1.3881 (1.3778)	Acc@1 75.000 (73.809)	Acc@5 100.000 (99.134)
Epoch: [74][200/875]	Time 0.640 (0.668)	Data 0.007 (0.015)	Loss 1.7002 (1.6871)	Loss@kd 1.3728 (1.3814)	Acc@1 76.562 (73.469)	Acc@5 98.438 (99.192)
Epoch: [74][300/875]	Time 0.644 (0.665)	Data 0.007 (0.013)	Loss 1.7613 (1.7003)	Loss@kd 1.3735 (1.3856)	Acc@1 71.875 (73.105)	Acc@5 100.000 (99.123)
Epoch: [74][400/875]	Time 0.652 (0.665)	Data 0.007 (0.011)	Loss 1.5456 (1.7029)	Loss@kd 1.3795 (1.3857)	Acc@1 75.000 (72.865)	Acc@5 100.000 (99.127)
Epoch: [74][500/875]	Time 0.649 (0.664)	Data 0.007 (0.011)	Loss 1.5661 (1.7039)	Loss@kd 1.4010 (1.3861)	Acc@1 82.812 (72.892)	Acc@5 100.000 (99.105)
Epoch: [74][600/875]	Time 0.647 (0.663)	Data 0.006 (0.010)	Loss 1.6933 (1.7037)	Loss@kd 1.3479 (1.3855)	Acc@1 73.438 (72.863)	Acc@5 96.875 (99.116)
Epoch: [74][700/875]	Time 0.654 (0.663)	Data 0.007 (0.010)	Loss 2.0485 (1.7058)	Loss@kd 1.4272 (1.3847)	Acc@1 67.188 (72.865)	Acc@5 96.875 (99.100)
Epoch: [74][800/875]	Time 0.656 (0.663)	Data 0.007 (0.009)	Loss 1.8168 (1.7076)	Loss@kd 1.3476 (1.3850)	Acc@1 67.188 (72.794)	Acc@5 98.438 (99.105)
 * Acc@1 72.784 Acc@5 99.086
epoch 74, total time 580.76
Test: [0/750]	Time 0.949 (0.949)	Loss 0.6383 (0.6383)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.212 (0.137)	Loss 0.2131 (0.5413)	Acc@1 90.625 (85.056)	Acc@5 100.000 (93.100)
Test: [200/750]	Time 0.131 (0.133)	Loss 0.9451 (0.4291)	Acc@1 68.750 (87.609)	Acc@5 100.000 (95.818)
Test: [300/750]	Time 0.133 (0.132)	Loss 1.7614 (0.6034)	Acc@1 31.250 (80.025)	Acc@5 84.375 (95.505)
Test: [400/750]	Time 0.143 (0.132)	Loss 0.4142 (0.8023)	Acc@1 84.375 (71.587)	Acc@5 93.750 (93.485)
Test: [500/750]	Time 0.132 (0.133)	Loss 0.5995 (0.7764)	Acc@1 81.250 (72.692)	Acc@5 96.875 (93.669)
Test: [600/750]	Time 0.131 (0.133)	Loss 1.2435 (0.8112)	Acc@1 59.375 (71.454)	Acc@5 87.500 (93.573)
Test: [700/750]	Time 0.134 (0.132)	Loss 1.3826 (0.8535)	Acc@1 62.500 (69.731)	Acc@5 84.375 (93.505)
 * Acc@1 69.225 Acc@5 93.325
==> training...
Epoch: [75][0/875]	Time 2.296 (2.296)	Data 1.601 (1.601)	Loss 1.6641 (1.6641)	Loss@kd 1.4320 (1.4320)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [75][100/875]	Time 0.617 (0.676)	Data 0.005 (0.023)	Loss 1.6793 (1.7094)	Loss@kd 1.3689 (1.3830)	Acc@1 71.875 (72.509)	Acc@5 98.438 (98.994)
Epoch: [75][200/875]	Time 0.732 (0.668)	Data 0.007 (0.015)	Loss 1.7609 (1.6994)	Loss@kd 1.4143 (1.3793)	Acc@1 70.312 (72.839)	Acc@5 98.438 (99.036)
Epoch: [75][300/875]	Time 0.657 (0.666)	Data 0.007 (0.013)	Loss 1.9011 (1.6941)	Loss@kd 1.4259 (1.3798)	Acc@1 70.312 (73.090)	Acc@5 96.875 (99.092)
Epoch: [75][400/875]	Time 0.651 (0.665)	Data 0.007 (0.011)	Loss 1.7411 (1.6964)	Loss@kd 1.4093 (1.3801)	Acc@1 75.000 (73.083)	Acc@5 100.000 (99.080)
Epoch: [75][500/875]	Time 0.653 (0.664)	Data 0.007 (0.011)	Loss 1.6082 (1.7001)	Loss@kd 1.3189 (1.3814)	Acc@1 70.312 (73.016)	Acc@5 98.438 (99.105)
Epoch: [75][600/875]	Time 0.634 (0.663)	Data 0.007 (0.010)	Loss 1.4806 (1.7020)	Loss@kd 1.3476 (1.3829)	Acc@1 79.688 (72.894)	Acc@5 100.000 (99.093)
Epoch: [75][700/875]	Time 0.651 (0.663)	Data 0.010 (0.010)	Loss 1.8805 (1.7019)	Loss@kd 1.4311 (1.3830)	Acc@1 68.750 (72.862)	Acc@5 96.875 (99.106)
Epoch: [75][800/875]	Time 0.652 (0.663)	Data 0.007 (0.009)	Loss 1.5764 (1.7028)	Loss@kd 1.3860 (1.3839)	Acc@1 78.125 (72.841)	Acc@5 100.000 (99.126)
 * Acc@1 72.820 Acc@5 99.107
epoch 75, total time 580.21
Test: [0/750]	Time 1.018 (1.018)	Loss 0.5696 (0.5696)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.135 (0.147)	Loss 0.5609 (0.5615)	Acc@1 81.250 (84.158)	Acc@5 96.875 (93.626)
Test: [200/750]	Time 0.127 (0.140)	Loss 1.1279 (0.6356)	Acc@1 50.000 (78.451)	Acc@5 93.750 (94.543)
Test: [300/750]	Time 0.132 (0.136)	Loss 0.9961 (0.7919)	Acc@1 56.250 (71.501)	Acc@5 93.750 (94.279)
Test: [400/750]	Time 0.117 (0.135)	Loss 0.6440 (0.8266)	Acc@1 78.125 (69.981)	Acc@5 90.625 (94.163)
Test: [500/750]	Time 0.139 (0.134)	Loss 0.7318 (0.7973)	Acc@1 71.875 (71.638)	Acc@5 100.000 (94.006)
Test: [600/750]	Time 0.213 (0.133)	Loss 0.7806 (0.8089)	Acc@1 68.750 (71.573)	Acc@5 93.750 (93.828)
Test: [700/750]	Time 0.135 (0.132)	Loss 1.2104 (0.8120)	Acc@1 59.375 (71.309)	Acc@5 81.250 (93.919)
 * Acc@1 70.812 Acc@5 93.754
==> training...
Epoch: [76][0/875]	Time 2.262 (2.262)	Data 1.590 (1.590)	Loss 1.7806 (1.7806)	Loss@kd 1.3989 (1.3989)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [76][100/875]	Time 0.644 (0.676)	Data 0.007 (0.023)	Loss 1.6716 (1.6280)	Loss@kd 1.3205 (1.3599)	Acc@1 75.000 (75.309)	Acc@5 98.438 (99.273)
Epoch: [76][200/875]	Time 0.653 (0.666)	Data 0.007 (0.015)	Loss 1.5387 (1.6019)	Loss@kd 1.3602 (1.3438)	Acc@1 81.250 (76.119)	Acc@5 100.000 (99.269)
Epoch: [76][300/875]	Time 0.650 (0.664)	Data 0.007 (0.013)	Loss 1.5202 (1.5915)	Loss@kd 1.4001 (1.3340)	Acc@1 84.375 (76.152)	Acc@5 100.000 (99.268)
Epoch: [76][400/875]	Time 0.659 (0.662)	Data 0.007 (0.011)	Loss 1.3670 (1.5852)	Loss@kd 1.3053 (1.3294)	Acc@1 85.938 (76.317)	Acc@5 100.000 (99.334)
Epoch: [76][500/875]	Time 0.652 (0.662)	Data 0.007 (0.010)	Loss 1.5205 (1.5810)	Loss@kd 1.3573 (1.3253)	Acc@1 79.688 (76.503)	Acc@5 100.000 (99.333)
Epoch: [76][600/875]	Time 0.715 (0.662)	Data 0.007 (0.010)	Loss 1.5795 (1.5772)	Loss@kd 1.2824 (1.3233)	Acc@1 70.312 (76.503)	Acc@5 100.000 (99.314)
Epoch: [76][700/875]	Time 0.649 (0.662)	Data 0.007 (0.010)	Loss 1.8298 (1.5757)	Loss@kd 1.4997 (1.3223)	Acc@1 76.562 (76.571)	Acc@5 98.438 (99.313)
Epoch: [76][800/875]	Time 0.651 (0.661)	Data 0.007 (0.009)	Loss 1.6730 (1.5726)	Loss@kd 1.4023 (1.3221)	Acc@1 78.125 (76.699)	Acc@5 100.000 (99.325)
 * Acc@1 76.764 Acc@5 99.332
epoch 76, total time 578.99
Test: [0/750]	Time 1.057 (1.057)	Loss 0.4803 (0.4803)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.132 (0.143)	Loss 0.3871 (0.4574)	Acc@1 87.500 (86.355)	Acc@5 100.000 (94.988)
Test: [200/750]	Time 0.140 (0.138)	Loss 1.0444 (0.4565)	Acc@1 50.000 (85.028)	Acc@5 93.750 (96.238)
Test: [300/750]	Time 0.110 (0.132)	Loss 0.8868 (0.6441)	Acc@1 65.625 (76.547)	Acc@5 93.750 (95.608)
Test: [400/750]	Time 0.112 (0.130)	Loss 0.5758 (0.7019)	Acc@1 84.375 (74.158)	Acc@5 90.625 (95.394)
Test: [500/750]	Time 0.118 (0.128)	Loss 0.6572 (0.6953)	Acc@1 75.000 (75.094)	Acc@5 100.000 (94.854)
Test: [600/750]	Time 0.118 (0.127)	Loss 0.8783 (0.7247)	Acc@1 65.625 (74.262)	Acc@5 96.875 (94.561)
Test: [700/750]	Time 0.109 (0.126)	Loss 1.0398 (0.7360)	Acc@1 53.125 (73.591)	Acc@5 87.500 (94.668)
 * Acc@1 73.458 Acc@5 94.654
saving the best model!
==> training...
Epoch: [77][0/875]	Time 2.272 (2.272)	Data 1.597 (1.597)	Loss 1.3520 (1.3520)	Loss@kd 1.2864 (1.2864)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [77][100/875]	Time 0.655 (0.681)	Data 0.007 (0.023)	Loss 1.7549 (1.5563)	Loss@kd 1.2802 (1.3145)	Acc@1 64.062 (77.444)	Acc@5 96.875 (99.288)
Epoch: [77][200/875]	Time 0.649 (0.671)	Data 0.007 (0.015)	Loss 1.6241 (1.5631)	Loss@kd 1.3327 (1.3135)	Acc@1 75.000 (77.060)	Acc@5 98.438 (99.137)
Epoch: [77][300/875]	Time 0.655 (0.669)	Data 0.007 (0.013)	Loss 1.6058 (1.5555)	Loss@kd 1.2810 (1.3100)	Acc@1 73.438 (77.211)	Acc@5 98.438 (99.227)
Epoch: [77][400/875]	Time 0.647 (0.665)	Data 0.007 (0.011)	Loss 1.5713 (1.5502)	Loss@kd 1.3335 (1.3098)	Acc@1 81.250 (77.369)	Acc@5 100.000 (99.271)
Epoch: [77][500/875]	Time 0.636 (0.662)	Data 0.007 (0.010)	Loss 1.5252 (1.5450)	Loss@kd 1.2975 (1.3098)	Acc@1 78.125 (77.529)	Acc@5 98.438 (99.286)
Epoch: [77][600/875]	Time 0.638 (0.661)	Data 0.010 (0.010)	Loss 1.5397 (1.5416)	Loss@kd 1.3946 (1.3091)	Acc@1 81.250 (77.660)	Acc@5 100.000 (99.295)
Epoch: [77][700/875]	Time 0.643 (0.660)	Data 0.008 (0.010)	Loss 1.5627 (1.5427)	Loss@kd 1.3338 (1.3087)	Acc@1 75.000 (77.592)	Acc@5 100.000 (99.307)
Epoch: [77][800/875]	Time 0.637 (0.659)	Data 0.007 (0.009)	Loss 1.6447 (1.5399)	Loss@kd 1.3305 (1.3078)	Acc@1 78.125 (77.575)	Acc@5 100.000 (99.333)
 * Acc@1 77.555 Acc@5 99.332
epoch 77, total time 577.49
Test: [0/750]	Time 0.902 (0.902)	Loss 0.4195 (0.4195)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.112 (0.137)	Loss 0.4268 (0.4196)	Acc@1 84.375 (87.562)	Acc@5 100.000 (95.390)
Test: [200/750]	Time 0.122 (0.130)	Loss 1.1965 (0.4476)	Acc@1 53.125 (85.292)	Acc@5 90.625 (96.362)
Test: [300/750]	Time 0.121 (0.128)	Loss 1.0962 (0.6750)	Acc@1 56.250 (75.260)	Acc@5 93.750 (95.069)
Test: [400/750]	Time 0.088 (0.127)	Loss 0.5558 (0.7560)	Acc@1 84.375 (72.062)	Acc@5 90.625 (94.724)
Test: [500/750]	Time 0.113 (0.126)	Loss 0.5718 (0.7300)	Acc@1 75.000 (73.640)	Acc@5 96.875 (94.368)
Test: [600/750]	Time 0.127 (0.126)	Loss 0.7750 (0.7416)	Acc@1 71.875 (73.466)	Acc@5 96.875 (94.270)
Test: [700/750]	Time 0.111 (0.125)	Loss 0.9022 (0.7384)	Acc@1 62.500 (73.480)	Acc@5 84.375 (94.472)
 * Acc@1 73.646 Acc@5 94.504
saving the best model!
==> training...
Epoch: [78][0/875]	Time 2.301 (2.301)	Data 1.580 (1.580)	Loss 1.4714 (1.4714)	Loss@kd 1.2768 (1.2768)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [78][100/875]	Time 0.634 (0.674)	Data 0.007 (0.023)	Loss 1.4597 (1.5391)	Loss@kd 1.2735 (1.3042)	Acc@1 87.500 (77.661)	Acc@5 100.000 (99.350)
Epoch: [78][200/875]	Time 0.647 (0.664)	Data 0.008 (0.015)	Loss 1.3965 (1.5305)	Loss@kd 1.3049 (1.3026)	Acc@1 81.250 (77.853)	Acc@5 100.000 (99.370)
Epoch: [78][300/875]	Time 0.627 (0.661)	Data 0.006 (0.013)	Loss 1.6371 (1.5255)	Loss@kd 1.3019 (1.3007)	Acc@1 76.562 (78.058)	Acc@5 96.875 (99.398)
Epoch: [78][400/875]	Time 0.740 (0.659)	Data 0.008 (0.011)	Loss 1.4361 (1.5273)	Loss@kd 1.3255 (1.3021)	Acc@1 81.250 (78.059)	Acc@5 100.000 (99.392)
Epoch: [78][500/875]	Time 0.638 (0.658)	Data 0.010 (0.010)	Loss 1.4233 (1.5297)	Loss@kd 1.2971 (1.3022)	Acc@1 78.125 (77.966)	Acc@5 100.000 (99.389)
Epoch: [78][600/875]	Time 0.651 (0.657)	Data 0.007 (0.010)	Loss 1.4960 (1.5295)	Loss@kd 1.2420 (1.3012)	Acc@1 73.438 (77.940)	Acc@5 100.000 (99.407)
Epoch: [78][700/875]	Time 0.634 (0.656)	Data 0.007 (0.010)	Loss 1.6204 (1.5307)	Loss@kd 1.2593 (1.3021)	Acc@1 71.875 (77.829)	Acc@5 98.438 (99.398)
Epoch: [78][800/875]	Time 0.658 (0.656)	Data 0.007 (0.009)	Loss 1.5645 (1.5309)	Loss@kd 1.2930 (1.3017)	Acc@1 75.000 (77.733)	Acc@5 100.000 (99.397)
 * Acc@1 77.782 Acc@5 99.400
epoch 78, total time 574.03
Test: [0/750]	Time 0.927 (0.927)	Loss 0.4087 (0.4087)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.147 (0.137)	Loss 0.4102 (0.4391)	Acc@1 87.500 (87.005)	Acc@5 100.000 (95.390)
Test: [200/750]	Time 0.092 (0.129)	Loss 1.2677 (0.4590)	Acc@1 46.875 (84.888)	Acc@5 93.750 (96.440)
Test: [300/750]	Time 0.098 (0.128)	Loss 1.0700 (0.6897)	Acc@1 62.500 (74.751)	Acc@5 93.750 (95.235)
Test: [400/750]	Time 0.103 (0.126)	Loss 0.4878 (0.7615)	Acc@1 84.375 (71.836)	Acc@5 90.625 (94.864)
Test: [500/750]	Time 0.104 (0.125)	Loss 0.6030 (0.7327)	Acc@1 75.000 (73.584)	Acc@5 100.000 (94.698)
Test: [600/750]	Time 0.101 (0.125)	Loss 0.8384 (0.7491)	Acc@1 65.625 (73.263)	Acc@5 96.875 (94.483)
Test: [700/750]	Time 0.135 (0.125)	Loss 0.8066 (0.7385)	Acc@1 65.625 (73.475)	Acc@5 87.500 (94.735)
 * Acc@1 73.825 Acc@5 94.787
saving the best model!
==> training...
Epoch: [79][0/875]	Time 2.302 (2.302)	Data 1.608 (1.608)	Loss 1.6909 (1.6909)	Loss@kd 1.3197 (1.3197)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [79][100/875]	Time 0.641 (0.673)	Data 0.007 (0.023)	Loss 1.6588 (1.5449)	Loss@kd 1.3718 (1.3097)	Acc@1 68.750 (77.429)	Acc@5 100.000 (99.211)
Epoch: [79][200/875]	Time 0.646 (0.664)	Data 0.009 (0.015)	Loss 1.4561 (1.5349)	Loss@kd 1.2485 (1.3063)	Acc@1 81.250 (77.744)	Acc@5 100.000 (99.316)
Epoch: [79][300/875]	Time 0.635 (0.660)	Data 0.007 (0.013)	Loss 1.4356 (1.5271)	Loss@kd 1.2575 (1.3032)	Acc@1 81.250 (77.917)	Acc@5 100.000 (99.336)
Epoch: [79][400/875]	Time 0.641 (0.659)	Data 0.007 (0.011)	Loss 1.6428 (1.5222)	Loss@kd 1.4792 (1.3023)	Acc@1 75.000 (78.199)	Acc@5 100.000 (99.384)
Epoch: [79][500/875]	Time 0.656 (0.658)	Data 0.007 (0.010)	Loss 1.6789 (1.5244)	Loss@kd 1.3328 (1.3007)	Acc@1 73.438 (78.103)	Acc@5 100.000 (99.370)
Epoch: [79][600/875]	Time 0.662 (0.657)	Data 0.007 (0.010)	Loss 1.3920 (1.5198)	Loss@kd 1.2422 (1.2998)	Acc@1 79.688 (78.284)	Acc@5 100.000 (99.376)
Epoch: [79][700/875]	Time 0.636 (0.657)	Data 0.007 (0.010)	Loss 1.6162 (1.5195)	Loss@kd 1.2747 (1.2987)	Acc@1 67.188 (78.176)	Acc@5 100.000 (99.378)
Epoch: [79][800/875]	Time 0.758 (0.657)	Data 0.007 (0.009)	Loss 1.7588 (1.5190)	Loss@kd 1.3245 (1.2981)	Acc@1 71.875 (78.168)	Acc@5 98.438 (99.399)
 * Acc@1 78.073 Acc@5 99.393
epoch 79, total time 575.03
Test: [0/750]	Time 1.116 (1.116)	Loss 0.5086 (0.5086)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.115 (0.145)	Loss 0.3364 (0.5099)	Acc@1 90.625 (85.860)	Acc@5 100.000 (94.338)
Test: [200/750]	Time 0.100 (0.133)	Loss 1.2463 (0.4786)	Acc@1 50.000 (85.339)	Acc@5 90.625 (95.973)
Test: [300/750]	Time 0.128 (0.130)	Loss 1.0802 (0.6887)	Acc@1 68.750 (75.706)	Acc@5 93.750 (94.934)
Test: [400/750]	Time 0.125 (0.128)	Loss 0.5305 (0.7547)	Acc@1 84.375 (72.904)	Acc@5 90.625 (94.802)
Test: [500/750]	Time 0.122 (0.129)	Loss 0.5942 (0.7336)	Acc@1 75.000 (74.270)	Acc@5 100.000 (94.505)
Test: [600/750]	Time 0.104 (0.127)	Loss 0.8079 (0.7465)	Acc@1 65.625 (73.981)	Acc@5 96.875 (94.374)
Test: [700/750]	Time 0.107 (0.127)	Loss 0.9136 (0.7436)	Acc@1 62.500 (73.685)	Acc@5 93.750 (94.677)
 * Acc@1 73.762 Acc@5 94.688
==> training...
Epoch: [80][0/875]	Time 2.263 (2.263)	Data 1.570 (1.570)	Loss 1.5069 (1.5069)	Loss@kd 1.2954 (1.2954)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [80][100/875]	Time 0.629 (0.669)	Data 0.007 (0.023)	Loss 1.5633 (1.5361)	Loss@kd 1.3915 (1.3025)	Acc@1 79.688 (77.723)	Acc@5 100.000 (99.397)
Epoch: [80][200/875]	Time 0.671 (0.662)	Data 0.008 (0.015)	Loss 1.6058 (1.5264)	Loss@kd 1.2839 (1.3006)	Acc@1 79.688 (77.884)	Acc@5 100.000 (99.339)
Epoch: [80][300/875]	Time 0.643 (0.659)	Data 0.007 (0.013)	Loss 1.6092 (1.5204)	Loss@kd 1.2777 (1.3009)	Acc@1 71.875 (78.089)	Acc@5 100.000 (99.346)
Epoch: [80][400/875]	Time 0.664 (0.658)	Data 0.007 (0.011)	Loss 1.4881 (1.5133)	Loss@kd 1.2817 (1.2989)	Acc@1 76.562 (78.285)	Acc@5 100.000 (99.357)
Epoch: [80][500/875]	Time 0.656 (0.657)	Data 0.007 (0.010)	Loss 1.4386 (1.5130)	Loss@kd 1.3284 (1.2970)	Acc@1 81.250 (78.194)	Acc@5 100.000 (99.389)
Epoch: [80][600/875]	Time 0.651 (0.657)	Data 0.007 (0.010)	Loss 1.5857 (1.5148)	Loss@kd 1.2777 (1.2979)	Acc@1 75.000 (78.276)	Acc@5 100.000 (99.410)
Epoch: [80][700/875]	Time 0.647 (0.657)	Data 0.007 (0.010)	Loss 1.4404 (1.5132)	Loss@kd 1.3204 (1.2968)	Acc@1 82.812 (78.223)	Acc@5 100.000 (99.434)
Epoch: [80][800/875]	Time 0.644 (0.656)	Data 0.005 (0.009)	Loss 1.5146 (1.5145)	Loss@kd 1.2764 (1.2974)	Acc@1 75.000 (78.226)	Acc@5 100.000 (99.442)
 * Acc@1 78.343 Acc@5 99.450
epoch 80, total time 575.06
Test: [0/750]	Time 0.936 (0.936)	Loss 0.4044 (0.4044)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.136 (0.142)	Loss 0.4082 (0.4313)	Acc@1 87.500 (87.407)	Acc@5 96.875 (95.637)
Test: [200/750]	Time 0.112 (0.136)	Loss 1.1273 (0.4420)	Acc@1 53.125 (85.883)	Acc@5 93.750 (96.704)
Test: [300/750]	Time 0.120 (0.133)	Loss 1.1889 (0.6474)	Acc@1 53.125 (76.910)	Acc@5 90.625 (95.723)
Test: [400/750]	Time 0.124 (0.131)	Loss 0.5049 (0.7469)	Acc@1 84.375 (72.841)	Acc@5 90.625 (94.919)
Test: [500/750]	Time 0.117 (0.131)	Loss 0.5699 (0.7196)	Acc@1 75.000 (74.414)	Acc@5 96.875 (94.686)
Test: [600/750]	Time 0.125 (0.131)	Loss 0.7650 (0.7362)	Acc@1 65.625 (74.002)	Acc@5 93.750 (94.561)
Test: [700/750]	Time 0.131 (0.131)	Loss 0.9355 (0.7351)	Acc@1 62.500 (73.810)	Acc@5 90.625 (94.713)
 * Acc@1 73.917 Acc@5 94.713
saving the best model!
==> Saving...
==> training...
Epoch: [81][0/875]	Time 2.320 (2.320)	Data 1.591 (1.591)	Loss 1.3911 (1.3911)	Loss@kd 1.2987 (1.2987)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [81][100/875]	Time 0.640 (0.671)	Data 0.007 (0.023)	Loss 1.3286 (1.4949)	Loss@kd 1.2425 (1.2927)	Acc@1 81.250 (78.713)	Acc@5 100.000 (99.304)
Epoch: [81][200/875]	Time 0.651 (0.663)	Data 0.007 (0.015)	Loss 1.4935 (1.5066)	Loss@kd 1.2526 (1.2972)	Acc@1 82.812 (78.187)	Acc@5 100.000 (99.269)
Epoch: [81][300/875]	Time 0.656 (0.660)	Data 0.007 (0.013)	Loss 1.4543 (1.5047)	Loss@kd 1.2712 (1.2952)	Acc@1 79.688 (78.296)	Acc@5 100.000 (99.341)
Epoch: [81][400/875]	Time 0.743 (0.658)	Data 0.007 (0.011)	Loss 1.5235 (1.5112)	Loss@kd 1.2715 (1.2943)	Acc@1 79.688 (78.129)	Acc@5 98.438 (99.353)
Epoch: [81][500/875]	Time 0.648 (0.658)	Data 0.008 (0.010)	Loss 1.5307 (1.5094)	Loss@kd 1.2728 (1.2933)	Acc@1 71.875 (78.128)	Acc@5 100.000 (99.382)
Epoch: [81][600/875]	Time 0.653 (0.657)	Data 0.007 (0.010)	Loss 1.6091 (1.5091)	Loss@kd 1.2671 (1.2935)	Acc@1 76.562 (78.122)	Acc@5 98.438 (99.407)
Epoch: [81][700/875]	Time 0.641 (0.656)	Data 0.007 (0.010)	Loss 1.4683 (1.5070)	Loss@kd 1.3213 (1.2936)	Acc@1 85.938 (78.245)	Acc@5 100.000 (99.429)
Epoch: [81][800/875]	Time 0.644 (0.656)	Data 0.007 (0.009)	Loss 1.4093 (1.5061)	Loss@kd 1.2766 (1.2941)	Acc@1 84.375 (78.312)	Acc@5 98.438 (99.432)
 * Acc@1 78.355 Acc@5 99.443
epoch 81, total time 575.01
Test: [0/750]	Time 1.010 (1.010)	Loss 0.4224 (0.4224)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.116 (0.139)	Loss 0.4309 (0.4787)	Acc@1 87.500 (85.860)	Acc@5 100.000 (95.019)
Test: [200/750]	Time 0.126 (0.129)	Loss 1.1574 (0.4780)	Acc@1 50.000 (84.422)	Acc@5 90.625 (96.129)
Test: [300/750]	Time 0.127 (0.128)	Loss 0.9946 (0.6738)	Acc@1 71.875 (75.623)	Acc@5 96.875 (95.287)
Test: [400/750]	Time 0.116 (0.126)	Loss 0.5141 (0.7424)	Acc@1 84.375 (72.896)	Acc@5 90.625 (95.051)
Test: [500/750]	Time 0.208 (0.126)	Loss 0.4888 (0.7154)	Acc@1 81.250 (74.482)	Acc@5 100.000 (94.867)
Test: [600/750]	Time 0.117 (0.125)	Loss 0.8103 (0.7270)	Acc@1 65.625 (74.251)	Acc@5 93.750 (94.759)
Test: [700/750]	Time 0.113 (0.125)	Loss 0.9311 (0.7287)	Acc@1 65.625 (74.019)	Acc@5 84.375 (94.909)
 * Acc@1 74.104 Acc@5 94.883
saving the best model!
==> training...
Epoch: [82][0/875]	Time 2.378 (2.378)	Data 1.545 (1.545)	Loss 1.4253 (1.4253)	Loss@kd 1.3250 (1.3250)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [82][100/875]	Time 0.751 (0.674)	Data 0.007 (0.022)	Loss 1.4629 (1.5066)	Loss@kd 1.3416 (1.2921)	Acc@1 84.375 (78.682)	Acc@5 100.000 (99.489)
Epoch: [82][200/875]	Time 0.645 (0.664)	Data 0.006 (0.015)	Loss 1.4281 (1.5008)	Loss@kd 1.2874 (1.2923)	Acc@1 79.688 (78.700)	Acc@5 100.000 (99.487)
Epoch: [82][300/875]	Time 0.661 (0.662)	Data 0.007 (0.012)	Loss 1.4817 (1.5068)	Loss@kd 1.2880 (1.2931)	Acc@1 79.688 (78.504)	Acc@5 100.000 (99.476)
Epoch: [82][400/875]	Time 0.653 (0.660)	Data 0.007 (0.011)	Loss 1.4672 (1.5024)	Loss@kd 1.3046 (1.2927)	Acc@1 82.812 (78.694)	Acc@5 100.000 (99.470)
Epoch: [82][500/875]	Time 0.634 (0.659)	Data 0.007 (0.010)	Loss 1.4517 (1.5043)	Loss@kd 1.2637 (1.2921)	Acc@1 81.250 (78.649)	Acc@5 96.875 (99.457)
Epoch: [82][600/875]	Time 0.645 (0.658)	Data 0.007 (0.010)	Loss 1.5244 (1.5027)	Loss@kd 1.3273 (1.2920)	Acc@1 76.562 (78.583)	Acc@5 100.000 (99.446)
Epoch: [82][700/875]	Time 0.627 (0.658)	Data 0.010 (0.009)	Loss 1.3812 (1.5044)	Loss@kd 1.2500 (1.2923)	Acc@1 78.125 (78.459)	Acc@5 100.000 (99.447)
Epoch: [82][800/875]	Time 0.657 (0.657)	Data 0.006 (0.009)	Loss 1.3850 (1.5049)	Loss@kd 1.3044 (1.2922)	Acc@1 84.375 (78.388)	Acc@5 100.000 (99.440)
 * Acc@1 78.446 Acc@5 99.439
epoch 82, total time 575.54
Test: [0/750]	Time 0.997 (0.997)	Loss 0.4662 (0.4662)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.128 (0.138)	Loss 0.4318 (0.4828)	Acc@1 87.500 (85.984)	Acc@5 96.875 (95.142)
Test: [200/750]	Time 0.125 (0.131)	Loss 1.2737 (0.4676)	Acc@1 53.125 (85.106)	Acc@5 90.625 (96.424)
Test: [300/750]	Time 0.115 (0.128)	Loss 1.0506 (0.6951)	Acc@1 65.625 (75.093)	Acc@5 93.750 (94.996)
Test: [400/750]	Time 0.128 (0.128)	Loss 0.5156 (0.7602)	Acc@1 84.375 (72.483)	Acc@5 90.625 (94.685)
Test: [500/750]	Time 0.120 (0.127)	Loss 0.5083 (0.7260)	Acc@1 78.125 (74.308)	Acc@5 100.000 (94.611)
Test: [600/750]	Time 0.124 (0.127)	Loss 0.8558 (0.7369)	Acc@1 65.625 (74.163)	Acc@5 96.875 (94.488)
Test: [700/750]	Time 0.119 (0.127)	Loss 0.9792 (0.7394)	Acc@1 65.625 (73.863)	Acc@5 87.500 (94.646)
 * Acc@1 73.929 Acc@5 94.621
==> training...
Epoch: [83][0/875]	Time 2.304 (2.304)	Data 1.609 (1.609)	Loss 1.7179 (1.7179)	Loss@kd 1.2957 (1.2957)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [83][100/875]	Time 0.633 (0.677)	Data 0.007 (0.023)	Loss 1.5347 (1.4988)	Loss@kd 1.2972 (1.2933)	Acc@1 75.000 (78.527)	Acc@5 98.438 (99.366)
Epoch: [83][200/875]	Time 0.640 (0.665)	Data 0.007 (0.015)	Loss 1.5834 (1.4967)	Loss@kd 1.3584 (1.2948)	Acc@1 84.375 (78.677)	Acc@5 98.438 (99.433)
Epoch: [83][300/875]	Time 0.652 (0.662)	Data 0.008 (0.012)	Loss 1.4450 (1.5015)	Loss@kd 1.3552 (1.2939)	Acc@1 87.500 (78.478)	Acc@5 98.438 (99.429)
Epoch: [83][400/875]	Time 0.632 (0.660)	Data 0.007 (0.011)	Loss 1.4744 (1.5022)	Loss@kd 1.3301 (1.2942)	Acc@1 82.812 (78.526)	Acc@5 100.000 (99.423)
Epoch: [83][500/875]	Time 0.632 (0.659)	Data 0.007 (0.010)	Loss 1.3555 (1.4993)	Loss@kd 1.2697 (1.2925)	Acc@1 82.812 (78.574)	Acc@5 100.000 (99.423)
Epoch: [83][600/875]	Time 0.668 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (73.682)	Acc@5 67.188 (96.688)
Epoch: [83][700/875]	Time 0.646 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (64.972)	Acc@5 48.438 (91.795)
Epoch: [83][800/875]	Time 0.657 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 21.875 (58.390)	Acc@5 73.438 (88.072)
 * Acc@1 54.482 Acc@5 85.948
epoch 83, total time 573.96
Test: [0/750]	Time 0.895 (0.895)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.128 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.135 (0.136)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.194 (0.134)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.123 (0.133)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.130 (0.133)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.115 (0.133)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.126 (0.133)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [84][0/875]	Time 2.264 (2.264)	Data 1.566 (1.566)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 60.938 (60.938)
Epoch: [84][100/875]	Time 0.641 (0.667)	Data 0.008 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.376)	Acc@5 46.875 (62.593)
Epoch: [84][200/875]	Time 0.622 (0.661)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.671)	Acc@5 62.500 (62.943)
Epoch: [84][300/875]	Time 0.650 (0.659)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.671)	Acc@5 56.250 (62.635)
Epoch: [84][400/875]	Time 0.658 (0.658)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.539)	Acc@5 50.000 (62.547)
Epoch: [84][500/875]	Time 0.730 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.572)	Acc@5 68.750 (62.463)
Epoch: [84][600/875]	Time 0.656 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.503)	Acc@5 65.625 (62.503)
Epoch: [84][700/875]	Time 0.637 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.565)	Acc@5 54.688 (62.484)
Epoch: [84][800/875]	Time 0.656 (0.657)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.484)	Acc@5 70.312 (62.410)
 * Acc@1 12.500 Acc@5 62.500
epoch 84, total time 574.96
Test: [0/750]	Time 0.958 (0.958)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.116 (0.133)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.121 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.125 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.127 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.107 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.105 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.108 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [85][0/875]	Time 2.343 (2.343)	Data 1.631 (1.631)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 64.062 (64.062)
Epoch: [85][100/875]	Time 0.659 (0.670)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.562)	Acc@5 65.625 (63.057)
Epoch: [85][200/875]	Time 0.651 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.500)	Acc@5 65.625 (62.733)
Epoch: [85][300/875]	Time 0.643 (0.659)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.464)	Acc@5 64.062 (62.433)
Epoch: [85][400/875]	Time 0.652 (0.658)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.391)	Acc@5 68.750 (62.500)
Epoch: [85][500/875]	Time 0.765 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.385)	Acc@5 54.688 (62.394)
Epoch: [85][600/875]	Time 0.647 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.412)	Acc@5 60.938 (62.570)
Epoch: [85][700/875]	Time 0.651 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 21.875 (12.455)	Acc@5 57.812 (62.551)
Epoch: [85][800/875]	Time 0.638 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.479)	Acc@5 60.938 (62.430)
 * Acc@1 12.500 Acc@5 62.500
epoch 85, total time 574.40
Test: [0/750]	Time 1.013 (1.013)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.131 (0.145)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.112 (0.139)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.203 (0.137)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.132 (0.136)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.135 (0.136)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.133 (0.136)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.126 (0.136)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [86][0/875]	Time 2.298 (2.298)	Data 1.618 (1.618)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (18.750)	Acc@5 67.188 (67.188)
Epoch: [86][100/875]	Time 0.661 (0.672)	Data 0.008 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.933)	Acc@5 62.500 (63.645)
Epoch: [86][200/875]	Time 0.671 (0.664)	Data 0.008 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.500)	Acc@5 75.000 (62.826)
Epoch: [86][300/875]	Time 0.652 (0.661)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.324)	Acc@5 59.375 (62.526)
Epoch: [86][400/875]	Time 0.662 (0.660)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.445)	Acc@5 71.875 (62.679)
Epoch: [86][500/875]	Time 0.642 (0.659)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.394)	Acc@5 68.750 (62.615)
Epoch: [86][600/875]	Time 0.746 (0.659)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.495)	Acc@5 59.375 (62.573)
Epoch: [86][700/875]	Time 0.637 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.460)	Acc@5 73.438 (62.596)
Epoch: [86][800/875]	Time 0.657 (0.658)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.492)	Acc@5 68.750 (62.619)
 * Acc@1 12.500 Acc@5 62.500
epoch 86, total time 575.28
Test: [0/750]	Time 0.935 (0.935)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.110 (0.138)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.124 (0.131)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.113 (0.128)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.133 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.130 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.128 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.134 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [87][0/875]	Time 2.317 (2.317)	Data 1.604 (1.604)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 70.312 (70.312)
Epoch: [87][100/875]	Time 0.660 (0.674)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.485)	Acc@5 67.188 (62.299)
Epoch: [87][200/875]	Time 0.639 (0.665)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (13.044)	Acc@5 60.938 (63.083)
Epoch: [87][300/875]	Time 0.648 (0.660)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.562)	Acc@5 60.938 (62.801)
Epoch: [87][400/875]	Time 0.659 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.430)	Acc@5 53.125 (62.500)
Epoch: [87][500/875]	Time 0.630 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.512)	Acc@5 54.688 (62.631)
Epoch: [87][600/875]	Time 0.656 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.430)	Acc@5 62.500 (62.497)
Epoch: [87][700/875]	Time 0.646 (0.657)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.413)	Acc@5 67.188 (62.513)
Epoch: [87][800/875]	Time 0.650 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.467)	Acc@5 56.250 (62.438)
 * Acc@1 12.500 Acc@5 62.500
epoch 87, total time 574.58
Test: [0/750]	Time 0.915 (0.915)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.135 (0.146)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.104 (0.139)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.137 (0.134)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.125 (0.133)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.116 (0.133)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.117 (0.134)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.127 (0.134)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [88][0/875]	Time 2.324 (2.324)	Data 1.621 (1.621)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 57.812 (57.812)
Epoch: [88][100/875]	Time 0.662 (0.673)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.160)	Acc@5 59.375 (62.531)
Epoch: [88][200/875]	Time 0.648 (0.664)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.243)	Acc@5 56.250 (62.352)
Epoch: [88][300/875]	Time 0.661 (0.662)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.298)	Acc@5 57.812 (62.469)
Epoch: [88][400/875]	Time 0.631 (0.660)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.344)	Acc@5 56.250 (62.375)
Epoch: [88][500/875]	Time 0.641 (0.658)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.375)	Acc@5 59.375 (62.300)
Epoch: [88][600/875]	Time 0.636 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.354)	Acc@5 68.750 (62.336)
Epoch: [88][700/875]	Time 0.655 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.406)	Acc@5 70.312 (62.478)
Epoch: [88][800/875]	Time 0.639 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.451)	Acc@5 65.625 (62.607)
 * Acc@1 12.500 Acc@5 62.500
epoch 88, total time 575.34
Test: [0/750]	Time 0.880 (0.880)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.124 (0.132)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.093 (0.127)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.129 (0.127)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.116 (0.125)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.106 (0.125)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.115 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.187 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [89][0/875]	Time 2.259 (2.259)	Data 1.538 (1.538)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 64.062 (64.062)
Epoch: [89][100/875]	Time 0.666 (0.674)	Data 0.007 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.500)	Acc@5 62.500 (62.005)
Epoch: [89][200/875]	Time 0.659 (0.665)	Data 0.008 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.554)	Acc@5 64.062 (61.824)
Epoch: [89][300/875]	Time 0.646 (0.661)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.427)	Acc@5 62.500 (62.194)
Epoch: [89][400/875]	Time 0.642 (0.659)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.340)	Acc@5 67.188 (62.251)
Epoch: [89][500/875]	Time 0.638 (0.657)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.388)	Acc@5 73.438 (62.335)
Epoch: [89][600/875]	Time 0.661 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.456)	Acc@5 57.812 (62.261)
Epoch: [89][700/875]	Time 0.720 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.540)	Acc@5 68.750 (62.373)
Epoch: [89][800/875]	Time 0.639 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.492)	Acc@5 64.062 (62.467)
 * Acc@1 12.500 Acc@5 62.500
epoch 89, total time 573.97
Test: [0/750]	Time 0.987 (0.987)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.125 (0.138)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.118 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.096 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.131 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.114 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.119 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.190 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [90][0/875]	Time 2.236 (2.236)	Data 1.577 (1.577)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 57.812 (57.812)
Epoch: [90][100/875]	Time 0.634 (0.675)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.361)	Acc@5 59.375 (61.680)
Epoch: [90][200/875]	Time 0.654 (0.666)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.407)	Acc@5 71.875 (62.158)
Epoch: [90][300/875]	Time 0.651 (0.662)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.313)	Acc@5 65.625 (62.516)
Epoch: [90][400/875]	Time 0.668 (0.660)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.305)	Acc@5 60.938 (62.535)
Epoch: [90][500/875]	Time 0.645 (0.659)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.463)	Acc@5 70.312 (62.715)
Epoch: [90][600/875]	Time 0.647 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.557)	Acc@5 60.938 (62.851)
Epoch: [90][700/875]	Time 0.639 (0.657)	Data 0.004 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.598)	Acc@5 56.250 (62.747)
Epoch: [90][800/875]	Time 0.636 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.520)	Acc@5 71.875 (62.592)
 * Acc@1 12.500 Acc@5 62.500
epoch 90, total time 574.64
Test: [0/750]	Time 0.862 (0.862)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.129 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.123 (0.135)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.094 (0.131)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.117 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.127 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.136 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.131 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [91][0/875]	Time 2.394 (2.394)	Data 1.609 (1.609)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 60.938 (60.938)
Epoch: [91][100/875]	Time 0.641 (0.670)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.794)	Acc@5 60.938 (63.134)
Epoch: [91][200/875]	Time 0.656 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.461)	Acc@5 64.062 (62.694)
Epoch: [91][300/875]	Time 0.651 (0.661)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.059)	Acc@5 75.000 (62.318)
Epoch: [91][400/875]	Time 0.768 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.216)	Acc@5 51.562 (62.504)
Epoch: [91][500/875]	Time 0.635 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.341)	Acc@5 59.375 (62.603)
Epoch: [91][600/875]	Time 0.667 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.386)	Acc@5 68.750 (62.560)
Epoch: [91][700/875]	Time 0.653 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.473)	Acc@5 60.938 (62.518)
Epoch: [91][800/875]	Time 0.655 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.480)	Acc@5 62.500 (62.475)
 * Acc@1 12.500 Acc@5 62.500
epoch 91, total time 575.10
Test: [0/750]	Time 1.062 (1.062)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.110 (0.132)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.141 (0.128)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.100 (0.126)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.116 (0.125)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.137 (0.124)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.116 (0.124)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.128 (0.124)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [92][0/875]	Time 2.307 (2.307)	Data 1.588 (1.588)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 62.500 (62.500)
Epoch: [92][100/875]	Time 0.646 (0.676)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.175)	Acc@5 65.625 (62.345)
Epoch: [92][200/875]	Time 0.661 (0.668)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.718)	Acc@5 65.625 (62.858)
Epoch: [92][300/875]	Time 0.662 (0.664)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.422)	Acc@5 59.375 (62.614)
Epoch: [92][400/875]	Time 0.666 (0.662)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.403)	Acc@5 60.938 (62.531)
Epoch: [92][500/875]	Time 0.667 (0.661)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.556)	Acc@5 59.375 (62.428)
Epoch: [92][600/875]	Time 0.643 (0.661)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.503)	Acc@5 64.062 (62.484)
Epoch: [92][700/875]	Time 0.649 (0.660)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.404)	Acc@5 68.750 (62.558)
Epoch: [92][800/875]	Time 0.633 (0.659)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.531)	Acc@5 53.125 (62.555)
 * Acc@1 12.500 Acc@5 62.500
epoch 92, total time 577.26
Test: [0/750]	Time 0.871 (0.871)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.110 (0.140)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.184 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.127 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.115 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.121 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.124 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.118 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [93][0/875]	Time 2.445 (2.445)	Data 1.628 (1.628)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 59.375 (59.375)
Epoch: [93][100/875]	Time 0.651 (0.677)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.082)	Acc@5 53.125 (61.912)
Epoch: [93][200/875]	Time 0.643 (0.667)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.251)	Acc@5 57.812 (62.104)
Epoch: [93][300/875]	Time 0.663 (0.663)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.183)	Acc@5 65.625 (62.064)
Epoch: [93][400/875]	Time 0.653 (0.660)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.286)	Acc@5 60.938 (62.064)
Epoch: [93][500/875]	Time 0.643 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.397)	Acc@5 60.938 (62.400)
Epoch: [93][600/875]	Time 0.643 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.495)	Acc@5 68.750 (62.448)
Epoch: [93][700/875]	Time 0.642 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.540)	Acc@5 59.375 (62.556)
Epoch: [93][800/875]	Time 0.648 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.529)	Acc@5 57.812 (62.496)
 * Acc@1 12.500 Acc@5 62.500
epoch 93, total time 574.41
Test: [0/750]	Time 1.034 (1.034)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.131 (0.143)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.137 (0.137)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.203 (0.135)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.130 (0.134)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.135 (0.133)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.140 (0.134)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.123 (0.133)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [94][0/875]	Time 2.384 (2.384)	Data 1.666 (1.666)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 51.562 (51.562)
Epoch: [94][100/875]	Time 0.724 (0.677)	Data 0.007 (0.024)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.485)	Acc@5 70.312 (61.757)
Epoch: [94][200/875]	Time 0.640 (0.666)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.306)	Acc@5 68.750 (62.290)
Epoch: [94][300/875]	Time 0.643 (0.663)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.531)	Acc@5 73.438 (62.609)
Epoch: [94][400/875]	Time 0.660 (0.662)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.539)	Acc@5 51.562 (62.379)
Epoch: [94][500/875]	Time 0.670 (0.662)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.491)	Acc@5 65.625 (62.609)
Epoch: [94][600/875]	Time 0.652 (0.661)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.451)	Acc@5 60.938 (62.633)
Epoch: [94][700/875]	Time 0.646 (0.661)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 3.125 (12.504)	Acc@5 48.438 (62.574)
Epoch: [94][800/875]	Time 0.653 (0.661)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.549)	Acc@5 68.750 (62.588)
 * Acc@1 12.500 Acc@5 62.500
epoch 94, total time 578.95
Test: [0/750]	Time 0.942 (0.942)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.120 (0.141)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.113 (0.133)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.105 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.108 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.129 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.119 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.113 (0.127)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [95][0/875]	Time 2.364 (2.364)	Data 1.669 (1.669)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 59.375 (59.375)
Epoch: [95][100/875]	Time 0.662 (0.681)	Data 0.008 (0.024)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.639)	Acc@5 62.500 (62.175)
Epoch: [95][200/875]	Time 0.657 (0.672)	Data 0.006 (0.016)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.920)	Acc@5 59.375 (62.484)
Epoch: [95][300/875]	Time 0.644 (0.668)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.843)	Acc@5 65.625 (62.567)
Epoch: [95][400/875]	Time 0.687 (0.667)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.691)	Acc@5 65.625 (62.457)
Epoch: [95][500/875]	Time 0.662 (0.666)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.631)	Acc@5 56.250 (62.662)
Epoch: [95][600/875]	Time 0.761 (0.665)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.552)	Acc@5 60.938 (62.692)
Epoch: [95][700/875]	Time 0.661 (0.665)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.556)	Acc@5 56.250 (62.600)
Epoch: [95][800/875]	Time 0.658 (0.664)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.527)	Acc@5 50.000 (62.463)
 * Acc@1 12.500 Acc@5 62.500
epoch 95, total time 581.64
Test: [0/750]	Time 0.983 (0.983)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.119 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.112 (0.136)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.140 (0.135)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.199 (0.135)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.135 (0.134)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.128 (0.134)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.134 (0.134)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [96][0/875]	Time 2.254 (2.254)	Data 1.558 (1.558)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (6.250)	Acc@5 60.938 (60.938)
Epoch: [96][100/875]	Time 0.657 (0.680)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.562)	Acc@5 56.250 (63.304)
Epoch: [96][200/875]	Time 0.642 (0.671)	Data 0.006 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.337)	Acc@5 59.375 (62.974)
Epoch: [96][300/875]	Time 0.645 (0.667)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.261)	Acc@5 64.062 (62.536)
Epoch: [96][400/875]	Time 0.662 (0.665)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.278)	Acc@5 64.062 (62.609)
Epoch: [96][500/875]	Time 0.670 (0.664)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.332)	Acc@5 54.688 (62.597)
Epoch: [96][600/875]	Time 0.656 (0.664)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.401)	Acc@5 60.938 (62.599)
Epoch: [96][700/875]	Time 0.750 (0.664)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.435)	Acc@5 68.750 (62.496)
Epoch: [96][800/875]	Time 0.644 (0.663)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.514)	Acc@5 62.500 (62.453)
 * Acc@1 12.500 Acc@5 62.500
epoch 96, total time 579.89
Test: [0/750]	Time 0.937 (0.937)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.108 (0.138)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.117 (0.131)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.129 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.107 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.119 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.122 (0.128)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.174 (0.127)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [97][0/875]	Time 2.284 (2.284)	Data 1.584 (1.584)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 3.125 (3.125)	Acc@5 65.625 (65.625)
Epoch: [97][100/875]	Time 0.643 (0.667)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.082)	Acc@5 65.625 (61.959)
Epoch: [97][200/875]	Time 0.657 (0.660)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.345)	Acc@5 60.938 (62.189)
Epoch: [97][300/875]	Time 0.634 (0.657)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.443)	Acc@5 71.875 (62.656)
Epoch: [97][400/875]	Time 0.660 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.403)	Acc@5 54.688 (62.578)
Epoch: [97][500/875]	Time 0.659 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.381)	Acc@5 56.250 (62.550)
Epoch: [97][600/875]	Time 0.656 (0.656)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.458)	Acc@5 56.250 (62.516)
Epoch: [97][700/875]	Time 0.653 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.424)	Acc@5 67.188 (62.458)
Epoch: [97][800/875]	Time 0.734 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.555)	Acc@5 60.938 (62.445)
 * Acc@1 12.500 Acc@5 62.500
epoch 97, total time 574.19
Test: [0/750]	Time 1.050 (1.050)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.122 (0.135)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.114 (0.128)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.112 (0.126)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.134 (0.126)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.120 (0.126)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.107 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.115 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [98][0/875]	Time 2.344 (2.344)	Data 1.545 (1.545)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (7.812)	Acc@5 56.250 (56.250)
Epoch: [98][100/875]	Time 0.650 (0.666)	Data 0.007 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.980)	Acc@5 62.500 (62.918)
Epoch: [98][200/875]	Time 0.653 (0.660)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.539)	Acc@5 64.062 (63.106)
Epoch: [98][300/875]	Time 0.632 (0.658)	Data 0.004 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.687)	Acc@5 64.062 (63.055)
Epoch: [98][400/875]	Time 0.643 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.613)	Acc@5 57.812 (62.855)
Epoch: [98][500/875]	Time 0.669 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.643)	Acc@5 53.125 (62.762)
Epoch: [98][600/875]	Time 0.663 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.583)	Acc@5 67.188 (62.523)
Epoch: [98][700/875]	Time 0.655 (0.658)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.600)	Acc@5 57.812 (62.560)
Epoch: [98][800/875]	Time 0.652 (0.658)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 21.875 (12.543)	Acc@5 68.750 (62.488)
 * Acc@1 12.500 Acc@5 62.500
epoch 98, total time 577.07
Test: [0/750]	Time 1.024 (1.024)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.141 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.090 (0.133)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.127 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.099 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.125 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.105 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.119 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [99][0/875]	Time 2.313 (2.313)	Data 1.594 (1.594)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 71.875 (71.875)
Epoch: [99][100/875]	Time 0.753 (0.681)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.314)	Acc@5 46.875 (62.098)
Epoch: [99][200/875]	Time 0.656 (0.671)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.749)	Acc@5 68.750 (62.383)
Epoch: [99][300/875]	Time 0.639 (0.668)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.396)	Acc@5 60.938 (62.012)
Epoch: [99][400/875]	Time 0.645 (0.666)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.484)	Acc@5 62.500 (62.079)
Epoch: [99][500/875]	Time 0.748 (0.665)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.503)	Acc@5 59.375 (62.241)
Epoch: [99][600/875]	Time 0.660 (0.663)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.583)	Acc@5 60.938 (62.388)
Epoch: [99][700/875]	Time 0.662 (0.662)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.562)	Acc@5 57.812 (62.418)
Epoch: [99][800/875]	Time 0.647 (0.661)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.520)	Acc@5 59.375 (62.537)
 * Acc@1 12.500 Acc@5 62.500
epoch 99, total time 577.79
Test: [0/750]	Time 0.966 (0.966)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.122 (0.137)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.107 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.098 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.135 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.116 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.125 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.134 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [100][0/875]	Time 2.305 (2.305)	Data 1.618 (1.618)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 59.375 (59.375)
Epoch: [100][100/875]	Time 0.732 (0.672)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.113)	Acc@5 64.062 (63.119)
Epoch: [100][200/875]	Time 0.644 (0.664)	Data 0.011 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.562)	Acc@5 64.062 (62.617)
Epoch: [100][300/875]	Time 0.649 (0.659)	Data 0.008 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.474)	Acc@5 60.938 (62.843)
Epoch: [100][400/875]	Time 0.645 (0.658)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.679)	Acc@5 64.062 (62.808)
Epoch: [100][500/875]	Time 0.705 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.687)	Acc@5 59.375 (62.768)
Epoch: [100][600/875]	Time 0.665 (0.655)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.601)	Acc@5 73.438 (62.516)
Epoch: [100][700/875]	Time 0.671 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.629)	Acc@5 60.938 (62.518)
Epoch: [100][800/875]	Time 0.646 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.607)	Acc@5 54.688 (62.617)
 * Acc@1 12.500 Acc@5 62.500
epoch 100, total time 573.86
Test: [0/750]	Time 1.033 (1.033)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.140 (0.146)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.127 (0.137)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.189 (0.132)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.098 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.093 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.124 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.119 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [101][0/875]	Time 2.337 (2.337)	Data 1.624 (1.624)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 67.188 (67.188)
Epoch: [101][100/875]	Time 0.620 (0.672)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.748)	Acc@5 64.062 (63.103)
Epoch: [101][200/875]	Time 0.655 (0.663)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.562)	Acc@5 64.062 (62.718)
Epoch: [101][300/875]	Time 0.640 (0.659)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 3.125 (12.526)	Acc@5 59.375 (62.391)
Epoch: [101][400/875]	Time 0.658 (0.660)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.496)	Acc@5 59.375 (62.453)
Epoch: [101][500/875]	Time 0.646 (0.660)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.425)	Acc@5 65.625 (62.491)
Epoch: [101][600/875]	Time 0.668 (0.661)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.492)	Acc@5 65.625 (62.565)
Epoch: [101][700/875]	Time 0.664 (0.660)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.507)	Acc@5 57.812 (62.531)
Epoch: [101][800/875]	Time 0.660 (0.660)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 56.250 (62.496)
 * Acc@1 12.500 Acc@5 62.500
epoch 101, total time 578.49
Test: [0/750]	Time 1.086 (1.086)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.126 (0.135)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.131 (0.128)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.113 (0.126)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.120 (0.126)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.117 (0.126)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.117 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.116 (0.124)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [102][0/875]	Time 2.298 (2.298)	Data 1.605 (1.605)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 62.500 (62.500)
Epoch: [102][100/875]	Time 0.635 (0.680)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.577)	Acc@5 59.375 (61.417)
Epoch: [102][200/875]	Time 0.640 (0.669)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.461)	Acc@5 60.938 (61.995)
Epoch: [102][300/875]	Time 0.643 (0.666)	Data 0.008 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.329)	Acc@5 54.688 (62.069)
Epoch: [102][400/875]	Time 0.734 (0.665)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.352)	Acc@5 65.625 (62.290)
Epoch: [102][500/875]	Time 0.644 (0.664)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.481)	Acc@5 65.625 (62.459)
Epoch: [102][600/875]	Time 0.653 (0.663)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.508)	Acc@5 67.188 (62.555)
Epoch: [102][700/875]	Time 0.663 (0.663)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.567)	Acc@5 62.500 (62.489)
Epoch: [102][800/875]	Time 0.653 (0.662)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.418)	Acc@5 71.875 (62.377)
 * Acc@1 12.500 Acc@5 62.500
epoch 102, total time 580.11
Test: [0/750]	Time 0.942 (0.942)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.130 (0.141)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.119 (0.133)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.107 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.134 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.204 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.141 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.131 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [103][0/875]	Time 2.351 (2.351)	Data 1.632 (1.632)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 60.938 (60.938)
Epoch: [103][100/875]	Time 0.635 (0.677)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.485)	Acc@5 54.688 (62.314)
Epoch: [103][200/875]	Time 0.642 (0.666)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.399)	Acc@5 70.312 (62.601)
Epoch: [103][300/875]	Time 0.629 (0.661)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.474)	Acc@5 67.188 (62.261)
Epoch: [103][400/875]	Time 0.735 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.410)	Acc@5 51.562 (62.500)
Epoch: [103][500/875]	Time 0.636 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.494)	Acc@5 68.750 (62.640)
Epoch: [103][600/875]	Time 0.632 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.573)	Acc@5 60.938 (62.516)
Epoch: [103][700/875]	Time 0.660 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.451)	Acc@5 59.375 (62.418)
Epoch: [103][800/875]	Time 0.716 (0.655)	Data 0.011 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.447)	Acc@5 71.875 (62.463)
 * Acc@1 12.500 Acc@5 62.500
epoch 103, total time 573.61
Test: [0/750]	Time 0.881 (0.881)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.134 (0.144)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.118 (0.135)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.127 (0.132)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.132 (0.130)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.129 (0.129)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.130 (0.129)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.132 (0.129)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [104][0/875]	Time 2.287 (2.287)	Data 1.597 (1.597)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 65.625 (65.625)
Epoch: [104][100/875]	Time 0.644 (0.670)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.175)	Acc@5 57.812 (61.912)
Epoch: [104][200/875]	Time 0.649 (0.661)	Data 0.006 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.313)	Acc@5 64.062 (62.212)
Epoch: [104][300/875]	Time 0.652 (0.658)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.318)	Acc@5 59.375 (62.272)
Epoch: [104][400/875]	Time 0.628 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.231)	Acc@5 54.688 (62.309)
Epoch: [104][500/875]	Time 0.738 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.322)	Acc@5 62.500 (62.135)
Epoch: [104][600/875]	Time 0.651 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.380)	Acc@5 57.812 (62.159)
Epoch: [104][700/875]	Time 0.662 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.453)	Acc@5 57.812 (62.371)
Epoch: [104][800/875]	Time 0.661 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.494)	Acc@5 65.625 (62.422)
 * Acc@1 12.500 Acc@5 62.500
epoch 104, total time 574.15
Test: [0/750]	Time 1.019 (1.019)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.138 (0.139)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.129 (0.131)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.117 (0.128)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.108 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.128 (0.125)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.095 (0.124)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.120 (0.124)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [105][0/875]	Time 2.333 (2.333)	Data 1.645 (1.645)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 23.438 (23.438)	Acc@5 64.062 (64.062)
Epoch: [105][100/875]	Time 0.653 (0.674)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.902)	Acc@5 59.375 (62.361)
Epoch: [105][200/875]	Time 0.629 (0.665)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.345)	Acc@5 62.500 (62.399)
Epoch: [105][300/875]	Time 0.712 (0.661)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.370)	Acc@5 68.750 (62.791)
Epoch: [105][400/875]	Time 0.653 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.368)	Acc@5 71.875 (62.625)
Epoch: [105][500/875]	Time 0.636 (0.657)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.350)	Acc@5 67.188 (62.590)
Epoch: [105][600/875]	Time 0.640 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.375)	Acc@5 65.625 (62.612)
Epoch: [105][700/875]	Time 0.643 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.464)	Acc@5 51.562 (62.547)
Epoch: [105][800/875]	Time 0.667 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.455)	Acc@5 64.062 (62.490)
 * Acc@1 12.500 Acc@5 62.500
epoch 105, total time 573.77
Test: [0/750]	Time 0.887 (0.887)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.126 (0.137)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.131 (0.130)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.125 (0.128)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.106 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.123 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.118 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.124 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [106][0/875]	Time 2.373 (2.373)	Data 1.547 (1.547)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 64.062 (64.062)
Epoch: [106][100/875]	Time 0.640 (0.678)	Data 0.007 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.717)	Acc@5 65.625 (62.500)
Epoch: [106][200/875]	Time 0.662 (0.668)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.725)	Acc@5 64.062 (62.461)
Epoch: [106][300/875]	Time 0.644 (0.664)	Data 0.006 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.718)	Acc@5 68.750 (62.645)
Epoch: [106][400/875]	Time 0.633 (0.661)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.617)	Acc@5 57.812 (62.625)
Epoch: [106][500/875]	Time 0.636 (0.660)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.622)	Acc@5 45.312 (62.509)
Epoch: [106][600/875]	Time 0.617 (0.659)	Data 0.004 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.677)	Acc@5 64.062 (62.510)
Epoch: [106][700/875]	Time 0.643 (0.658)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.547)	Acc@5 67.188 (62.482)
Epoch: [106][800/875]	Time 0.648 (0.658)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.523)	Acc@5 65.625 (62.560)
 * Acc@1 12.500 Acc@5 62.500
epoch 106, total time 575.53
Test: [0/750]	Time 0.964 (0.964)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.110 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.114 (0.133)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.107 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.125 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.114 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.101 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.118 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [107][0/875]	Time 2.299 (2.299)	Data 1.615 (1.615)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 59.375 (59.375)
Epoch: [107][100/875]	Time 0.660 (0.671)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.902)	Acc@5 65.625 (63.072)
Epoch: [107][200/875]	Time 0.645 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.741)	Acc@5 65.625 (62.718)
Epoch: [107][300/875]	Time 0.626 (0.658)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.749)	Acc@5 75.000 (62.464)
Epoch: [107][400/875]	Time 0.646 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.617)	Acc@5 64.062 (62.691)
Epoch: [107][500/875]	Time 0.656 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.643)	Acc@5 78.125 (62.519)
Epoch: [107][600/875]	Time 0.643 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.625)	Acc@5 57.812 (62.497)
Epoch: [107][700/875]	Time 0.665 (0.655)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.567)	Acc@5 57.812 (62.475)
Epoch: [107][800/875]	Time 0.731 (0.655)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.510)	Acc@5 64.062 (62.467)
 * Acc@1 12.500 Acc@5 62.500
epoch 107, total time 573.86
Test: [0/750]	Time 1.033 (1.033)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.125 (0.142)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.173 (0.134)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.115 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.129 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.121 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.120 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.100 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [108][0/875]	Time 2.430 (2.430)	Data 1.620 (1.620)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 76.562 (76.562)
Epoch: [108][100/875]	Time 0.652 (0.671)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (11.757)	Acc@5 50.000 (61.881)
Epoch: [108][200/875]	Time 0.657 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.189)	Acc@5 57.812 (62.368)
Epoch: [108][300/875]	Time 0.639 (0.658)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.375)	Acc@5 51.562 (62.313)
Epoch: [108][400/875]	Time 0.637 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.504)	Acc@5 67.188 (62.305)
Epoch: [108][500/875]	Time 0.640 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.456)	Acc@5 70.312 (62.469)
Epoch: [108][600/875]	Time 0.654 (0.655)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.479)	Acc@5 70.312 (62.456)
Epoch: [108][700/875]	Time 0.652 (0.655)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.464)	Acc@5 50.000 (62.382)
Epoch: [108][800/875]	Time 0.746 (0.655)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.516)	Acc@5 64.062 (62.488)
 * Acc@1 12.500 Acc@5 62.500
epoch 108, total time 573.60
Test: [0/750]	Time 1.022 (1.022)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.115 (0.136)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.185 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.135 (0.128)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.134 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.120 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.110 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.130 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [109][0/875]	Time 2.459 (2.459)	Data 1.642 (1.642)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 68.750 (68.750)
Epoch: [109][100/875]	Time 0.652 (0.673)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.485)	Acc@5 68.750 (63.026)
Epoch: [109][200/875]	Time 0.640 (0.664)	Data 0.009 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.376)	Acc@5 67.188 (63.060)
Epoch: [109][300/875]	Time 0.646 (0.659)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.235)	Acc@5 71.875 (62.863)
Epoch: [109][400/875]	Time 0.768 (0.659)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.274)	Acc@5 57.812 (62.855)
Epoch: [109][500/875]	Time 0.612 (0.657)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.332)	Acc@5 64.062 (62.809)
Epoch: [109][600/875]	Time 0.644 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.388)	Acc@5 67.188 (62.768)
Epoch: [109][700/875]	Time 0.634 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.420)	Acc@5 57.812 (62.616)
Epoch: [109][800/875]	Time 0.632 (0.655)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.510)	Acc@5 67.188 (62.480)
 * Acc@1 12.500 Acc@5 62.500
epoch 109, total time 574.04
Test: [0/750]	Time 0.934 (0.934)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.122 (0.134)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.119 (0.130)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.112 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.104 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.196 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.124 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.114 (0.127)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [110][0/875]	Time 2.288 (2.288)	Data 1.581 (1.581)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 60.938 (60.938)
Epoch: [110][100/875]	Time 0.642 (0.670)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.593)	Acc@5 64.062 (61.943)
Epoch: [110][200/875]	Time 0.639 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.337)	Acc@5 51.562 (61.583)
Epoch: [110][300/875]	Time 0.638 (0.660)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.453)	Acc@5 59.375 (61.945)
Epoch: [110][400/875]	Time 0.627 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.496)	Acc@5 54.688 (62.329)
Epoch: [110][500/875]	Time 0.634 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.435)	Acc@5 60.938 (62.484)
Epoch: [110][600/875]	Time 0.653 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.404)	Acc@5 60.938 (62.440)
Epoch: [110][700/875]	Time 0.633 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.471)	Acc@5 71.875 (62.496)
Epoch: [110][800/875]	Time 0.644 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.490)	Acc@5 57.812 (62.523)
 * Acc@1 12.500 Acc@5 62.500
epoch 110, total time 575.28
Test: [0/750]	Time 0.886 (0.886)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.126 (0.137)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.129 (0.131)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.133 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.121 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.090 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.116 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.099 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [111][0/875]	Time 2.365 (2.365)	Data 1.643 (1.643)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 62.500 (62.500)
Epoch: [111][100/875]	Time 0.652 (0.669)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.361)	Acc@5 67.188 (62.020)
Epoch: [111][200/875]	Time 0.665 (0.662)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.655)	Acc@5 60.938 (62.562)
Epoch: [111][300/875]	Time 0.639 (0.660)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.557)	Acc@5 57.812 (62.344)
Epoch: [111][400/875]	Time 0.654 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.555)	Acc@5 50.000 (62.368)
Epoch: [111][500/875]	Time 0.653 (0.658)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.584)	Acc@5 59.375 (62.544)
Epoch: [111][600/875]	Time 0.676 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.482)	Acc@5 57.812 (62.445)
Epoch: [111][700/875]	Time 0.658 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.444)	Acc@5 54.688 (62.469)
Epoch: [111][800/875]	Time 0.658 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.422)	Acc@5 62.500 (62.445)
 * Acc@1 12.500 Acc@5 62.500
epoch 111, total time 575.24
Test: [0/750]	Time 1.013 (1.013)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.107 (0.133)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.126 (0.128)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.189 (0.127)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.108 (0.126)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.115 (0.125)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.125 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.104 (0.124)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [112][0/875]	Time 2.294 (2.294)	Data 1.599 (1.599)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 57.812 (57.812)
Epoch: [112][100/875]	Time 0.641 (0.671)	Data 0.008 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.639)	Acc@5 68.750 (62.330)
Epoch: [112][200/875]	Time 0.630 (0.663)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.663)	Acc@5 62.500 (62.461)
Epoch: [112][300/875]	Time 0.653 (0.659)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.702)	Acc@5 65.625 (62.531)
Epoch: [112][400/875]	Time 0.642 (0.658)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.484)	Acc@5 57.812 (62.523)
Epoch: [112][500/875]	Time 0.751 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.522)	Acc@5 57.812 (62.353)
Epoch: [112][600/875]	Time 0.628 (0.656)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.466)	Acc@5 65.625 (62.471)
Epoch: [112][700/875]	Time 0.637 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.386)	Acc@5 57.812 (62.426)
Epoch: [112][800/875]	Time 0.647 (0.656)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.467)	Acc@5 67.188 (62.545)
 * Acc@1 12.500 Acc@5 62.500
epoch 112, total time 573.98
Test: [0/750]	Time 1.067 (1.067)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.096 (0.143)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.128 (0.134)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.121 (0.131)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.131 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.116 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.099 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.112 (0.127)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [113][0/875]	Time 2.288 (2.288)	Data 1.596 (1.596)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (6.250)	Acc@5 70.312 (70.312)
Epoch: [113][100/875]	Time 0.648 (0.674)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.206)	Acc@5 62.500 (61.618)
Epoch: [113][200/875]	Time 0.626 (0.664)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.298)	Acc@5 67.188 (61.909)
Epoch: [113][300/875]	Time 0.651 (0.660)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.251)	Acc@5 56.250 (62.147)
Epoch: [113][400/875]	Time 0.650 (0.658)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.375)	Acc@5 62.500 (62.442)
Epoch: [113][500/875]	Time 0.748 (0.658)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.416)	Acc@5 62.500 (62.562)
Epoch: [113][600/875]	Time 0.642 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.349)	Acc@5 59.375 (62.583)
Epoch: [113][700/875]	Time 0.630 (0.657)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.360)	Acc@5 68.750 (62.540)
Epoch: [113][800/875]	Time 0.652 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.477)	Acc@5 53.125 (62.557)
 * Acc@1 12.500 Acc@5 62.500
epoch 113, total time 574.76
Test: [0/750]	Time 0.969 (0.969)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.137 (0.140)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.134 (0.136)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.118 (0.134)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.131 (0.133)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.137 (0.132)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.115 (0.132)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.110 (0.132)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [114][0/875]	Time 2.336 (2.336)	Data 1.639 (1.639)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 53.125 (53.125)
Epoch: [114][100/875]	Time 0.644 (0.673)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.918)	Acc@5 51.562 (62.345)
Epoch: [114][200/875]	Time 0.647 (0.664)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.321)	Acc@5 62.500 (62.010)
Epoch: [114][300/875]	Time 0.640 (0.660)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.438)	Acc@5 46.875 (61.862)
Epoch: [114][400/875]	Time 0.648 (0.659)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.609)	Acc@5 65.625 (62.243)
Epoch: [114][500/875]	Time 0.642 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.516)	Acc@5 57.812 (62.238)
Epoch: [114][600/875]	Time 0.667 (0.658)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.508)	Acc@5 62.500 (62.396)
Epoch: [114][700/875]	Time 0.635 (0.657)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 21.875 (12.424)	Acc@5 57.812 (62.346)
Epoch: [114][800/875]	Time 0.690 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.496)	Acc@5 54.688 (62.420)
 * Acc@1 12.500 Acc@5 62.500
epoch 114, total time 574.91
Test: [0/750]	Time 0.978 (0.978)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.103 (0.140)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.220 (0.134)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.100 (0.131)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.130 (0.129)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.121 (0.128)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.126 (0.127)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.121 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [115][0/875]	Time 2.299 (2.299)	Data 1.611 (1.611)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 64.062 (64.062)
Epoch: [115][100/875]	Time 0.655 (0.680)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 23.438 (12.918)	Acc@5 65.625 (61.989)
Epoch: [115][200/875]	Time 0.660 (0.670)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.710)	Acc@5 71.875 (62.414)
Epoch: [115][300/875]	Time 0.630 (0.664)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.516)	Acc@5 56.250 (62.448)
Epoch: [115][400/875]	Time 0.660 (0.661)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.469)	Acc@5 59.375 (62.403)
Epoch: [115][500/875]	Time 0.632 (0.659)	Data 0.005 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.531)	Acc@5 62.500 (62.372)
Epoch: [115][600/875]	Time 0.653 (0.658)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.547)	Acc@5 60.938 (62.383)
Epoch: [115][700/875]	Time 0.650 (0.657)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.571)	Acc@5 75.000 (62.525)
Epoch: [115][800/875]	Time 0.661 (0.656)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.551)	Acc@5 60.938 (62.543)
 * Acc@1 12.500 Acc@5 62.500
epoch 115, total time 574.53
Test: [0/750]	Time 1.046 (1.046)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.117 (0.138)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.095 (0.129)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.126 (0.128)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.128 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.177 (0.126)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.124 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.106 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [116][0/875]	Time 2.334 (2.334)	Data 1.545 (1.545)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 65.625 (65.625)
Epoch: [116][100/875]	Time 0.625 (0.670)	Data 0.005 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.515)	Acc@5 57.812 (62.624)
Epoch: [116][200/875]	Time 0.638 (0.659)	Data 0.007 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.523)	Acc@5 62.500 (62.951)
Epoch: [116][300/875]	Time 0.638 (0.655)	Data 0.005 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.510)	Acc@5 56.250 (62.417)
Epoch: [116][400/875]	Time 0.707 (0.653)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.629)	Acc@5 56.250 (62.671)
Epoch: [116][500/875]	Time 0.648 (0.652)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.622)	Acc@5 54.688 (62.728)
Epoch: [116][600/875]	Time 0.640 (0.652)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.565)	Acc@5 50.000 (62.555)
Epoch: [116][700/875]	Time 0.644 (0.652)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.558)	Acc@5 56.250 (62.618)
Epoch: [116][800/875]	Time 0.653 (0.652)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.545)	Acc@5 56.250 (62.557)
 * Acc@1 12.500 Acc@5 62.500
epoch 116, total time 570.99
Test: [0/750]	Time 1.058 (1.058)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.134 (0.147)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.112 (0.137)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.121 (0.133)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.119 (0.130)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.128 (0.129)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.121 (0.128)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.130 (0.128)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [117][0/875]	Time 2.407 (2.407)	Data 1.591 (1.591)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (17.188)	Acc@5 59.375 (59.375)
Epoch: [117][100/875]	Time 0.634 (0.670)	Data 0.005 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (11.665)	Acc@5 67.188 (61.386)
Epoch: [117][200/875]	Time 0.637 (0.658)	Data 0.011 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (11.909)	Acc@5 59.375 (61.559)
Epoch: [117][300/875]	Time 0.639 (0.654)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.100)	Acc@5 64.062 (61.945)
Epoch: [117][400/875]	Time 0.655 (0.654)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.290)	Acc@5 67.188 (62.282)
Epoch: [117][500/875]	Time 0.633 (0.654)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.266)	Acc@5 60.938 (62.416)
Epoch: [117][600/875]	Time 0.646 (0.653)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.308)	Acc@5 67.188 (62.451)
Epoch: [117][700/875]	Time 0.653 (0.653)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.368)	Acc@5 60.938 (62.591)
Epoch: [117][800/875]	Time 0.637 (0.653)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.441)	Acc@5 51.562 (62.469)
 * Acc@1 12.500 Acc@5 62.500
epoch 117, total time 571.53
Test: [0/750]	Time 1.057 (1.057)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.115 (0.141)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.106 (0.136)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.167 (0.133)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.129 (0.131)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.126 (0.131)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.199 (0.131)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.115 (0.131)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [118][0/875]	Time 2.270 (2.270)	Data 1.596 (1.596)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 64.062 (64.062)
Epoch: [118][100/875]	Time 0.635 (0.674)	Data 0.005 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.995)	Acc@5 65.625 (63.506)
Epoch: [118][200/875]	Time 0.687 (0.660)	Data 0.005 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.966)	Acc@5 60.938 (62.873)
Epoch: [118][300/875]	Time 0.635 (0.657)	Data 0.005 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.874)	Acc@5 60.938 (62.484)
Epoch: [118][400/875]	Time 0.615 (0.655)	Data 0.005 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.648)	Acc@5 64.062 (62.473)
Epoch: [118][500/875]	Time 0.638 (0.653)	Data 0.005 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.647)	Acc@5 54.688 (62.628)
Epoch: [118][600/875]	Time 0.725 (0.653)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.643)	Acc@5 62.500 (62.747)
Epoch: [118][700/875]	Time 0.651 (0.652)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.609)	Acc@5 56.250 (62.600)
Epoch: [118][800/875]	Time 0.627 (0.651)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.484)	Acc@5 46.875 (62.539)
 * Acc@1 12.500 Acc@5 62.500
epoch 118, total time 570.56
Test: [0/750]	Time 1.009 (1.009)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.120 (0.141)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.131 (0.133)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.137 (0.130)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.191 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.123 (0.127)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.113 (0.126)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.142 (0.126)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [119][0/875]	Time 2.273 (2.273)	Data 1.572 (1.572)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 70.312 (70.312)
Epoch: [119][100/875]	Time 0.638 (0.673)	Data 0.006 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (11.711)	Acc@5 64.062 (61.912)
Epoch: [119][200/875]	Time 0.656 (0.665)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.321)	Acc@5 64.062 (62.251)
Epoch: [119][300/875]	Time 0.733 (0.664)	Data 0.008 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.417)	Acc@5 68.750 (62.547)
Epoch: [119][400/875]	Time 0.658 (0.663)	Data 0.010 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.527)	Acc@5 59.375 (62.523)
Epoch: [119][500/875]	Time 0.639 (0.663)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.528)	Acc@5 73.438 (62.466)
Epoch: [119][600/875]	Time 0.650 (0.662)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.477)	Acc@5 68.750 (62.464)
Epoch: [119][700/875]	Time 0.642 (0.662)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.471)	Acc@5 65.625 (62.513)
Epoch: [119][800/875]	Time 0.647 (0.662)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.484)	Acc@5 60.938 (62.539)
 * Acc@1 12.500 Acc@5 62.500
epoch 119, total time 579.82
Test: [0/750]	Time 1.046 (1.046)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.136 (0.144)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.187 (0.134)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.110 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.106 (0.127)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.213 (0.126)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.115 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.114 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [120][0/875]	Time 2.306 (2.306)	Data 1.606 (1.606)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 25.000 (25.000)	Acc@5 71.875 (71.875)
Epoch: [120][100/875]	Time 0.667 (0.682)	Data 0.007 (0.023)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.500)	Acc@5 68.750 (62.160)
Epoch: [120][200/875]	Time 0.647 (0.673)	Data 0.007 (0.015)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.422)	Acc@5 60.938 (61.894)
Epoch: [120][300/875]	Time 0.661 (0.669)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.583)	Acc@5 64.062 (62.375)
Epoch: [120][400/875]	Time 0.655 (0.667)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.714)	Acc@5 71.875 (62.547)
Epoch: [120][500/875]	Time 0.732 (0.666)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.656)	Acc@5 57.812 (62.578)
Epoch: [120][600/875]	Time 0.643 (0.665)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.596)	Acc@5 59.375 (62.552)
Epoch: [120][700/875]	Time 0.645 (0.665)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.569)	Acc@5 62.500 (62.511)
Epoch: [120][800/875]	Time 0.638 (0.665)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.564)	Acc@5 50.000 (62.574)
 * Acc@1 12.500 Acc@5 62.500
epoch 120, total time 581.96
Test: [0/750]	Time 1.016 (1.016)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.123 (0.140)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.110 (0.132)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.119 (0.129)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.093 (0.128)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.113 (0.126)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.116 (0.125)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.114 (0.125)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> Saving...
best accuracy: tensor(74.1042, device='cuda:0')
