==> loading teacher model
==> done
Test: [0/750]	Time 32.359 (32.359)	Loss 0.5613 (0.5613)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.067 (0.376)	Loss 0.6912 (0.4886)	Acc@1 75.000 (87.098)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.070 (0.217)	Loss 1.2877 (0.4868)	Acc@1 50.000 (85.106)	Acc@5 93.750 (96.253)
Test: [300/750]	Time 0.045 (0.162)	Loss 1.1032 (0.6946)	Acc@1 56.250 (76.412)	Acc@5 93.750 (95.515)
Test: [400/750]	Time 0.038 (0.135)	Loss 0.5579 (0.7766)	Acc@1 84.375 (73.208)	Acc@5 93.750 (94.966)
Test: [500/750]	Time 0.060 (0.119)	Loss 0.4078 (0.7378)	Acc@1 84.375 (75.087)	Acc@5 100.000 (94.966)
Test: [600/750]	Time 0.050 (0.108)	Loss 0.5665 (0.7392)	Acc@1 71.875 (75.151)	Acc@5 96.875 (94.982)
Test: [700/750]	Time 0.061 (0.101)	Loss 1.0252 (0.7310)	Acc@1 68.750 (75.334)	Acc@5 81.250 (95.136)
 * Acc@1 75.533 Acc@5 95.092
teacher accuracy:  tensor(75.5333, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 2.241 (2.241)	Data 1.252 (1.252)	Loss 22.1410 (22.1410)	Loss@kd 16.7717 (16.7717)	Acc@1 25.000 (25.000)	Acc@5 71.875 (71.875)
Epoch: [1][100/875]	Time 0.362 (0.377)	Data 0.008 (0.019)	Loss 5.5343 (8.4553)	Loss@kd 3.1281 (5.4566)	Acc@1 37.500 (27.831)	Acc@5 84.375 (79.950)
Epoch: [1][200/875]	Time 0.357 (0.369)	Data 0.008 (0.013)	Loss 5.1674 (6.9512)	Loss@kd 2.9665 (4.3016)	Acc@1 39.062 (32.673)	Acc@5 95.312 (85.370)
Epoch: [1][300/875]	Time 0.353 (0.351)	Data 0.007 (0.011)	Loss 5.1547 (6.3573)	Loss@kd 3.1592 (3.8725)	Acc@1 51.562 (34.972)	Acc@5 92.188 (88.019)
Epoch: [1][400/875]	Time 0.361 (0.353)	Data 0.005 (0.010)	Loss 4.9013 (6.0251)	Loss@kd 2.8293 (3.6447)	Acc@1 39.062 (36.830)	Acc@5 95.312 (89.639)
Epoch: [1][500/875]	Time 0.352 (0.354)	Data 0.006 (0.010)	Loss 4.9099 (5.8031)	Loss@kd 2.8998 (3.4943)	Acc@1 39.062 (38.249)	Acc@5 95.312 (90.603)
Epoch: [1][600/875]	Time 0.360 (0.355)	Data 0.008 (0.009)	Loss 4.8801 (5.6440)	Loss@kd 2.8774 (3.3870)	Acc@1 40.625 (39.429)	Acc@5 90.625 (91.140)
Epoch: [1][700/875]	Time 0.363 (0.355)	Data 0.007 (0.009)	Loss 5.1269 (5.5229)	Loss@kd 2.9184 (3.3066)	Acc@1 34.375 (40.384)	Acc@5 93.750 (91.610)
Epoch: [1][800/875]	Time 0.360 (0.356)	Data 0.008 (0.009)	Loss 4.5920 (5.4274)	Loss@kd 2.6766 (3.2424)	Acc@1 43.750 (41.000)	Acc@5 93.750 (92.022)
 * Acc@1 41.307 Acc@5 92.221
epoch 1, total time 311.90
Test: [0/750]	Time 0.831 (0.831)	Loss 0.8597 (0.8597)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.025 (0.039)	Loss 0.5632 (0.7024)	Acc@1 90.625 (81.993)	Acc@5 96.875 (86.262)
Test: [200/750]	Time 0.041 (0.036)	Loss 2.1380 (0.7334)	Acc@1 0.000 (80.846)	Acc@5 34.375 (88.588)
Test: [300/750]	Time 0.036 (0.033)	Loss 1.9124 (1.1317)	Acc@1 12.500 (56.458)	Acc@5 68.750 (76.277)
Test: [400/750]	Time 0.038 (0.033)	Loss 1.7346 (1.2859)	Acc@1 28.125 (49.221)	Acc@5 59.375 (76.364)
Test: [500/750]	Time 0.036 (0.032)	Loss 1.3883 (1.3372)	Acc@1 53.125 (47.536)	Acc@5 90.625 (77.270)
Test: [600/750]	Time 0.024 (0.032)	Loss 1.4654 (1.3496)	Acc@1 28.125 (46.485)	Acc@5 96.875 (79.420)
Test: [700/750]	Time 0.032 (0.032)	Loss 1.6821 (1.3694)	Acc@1 40.625 (44.820)	Acc@5 68.750 (80.577)
 * Acc@1 45.388 Acc@5 80.354
saving the best model!
==> training...
Epoch: [2][0/875]	Time 1.852 (1.852)	Data 1.491 (1.491)	Loss 4.6744 (4.6744)	Loss@kd 2.7551 (2.7551)	Acc@1 39.062 (39.062)	Acc@5 93.750 (93.750)
Epoch: [2][100/875]	Time 0.356 (0.371)	Data 0.007 (0.022)	Loss 4.8774 (4.6494)	Loss@kd 2.9550 (2.7333)	Acc@1 50.000 (46.813)	Acc@5 90.625 (95.189)
Epoch: [2][200/875]	Time 0.357 (0.364)	Data 0.008 (0.014)	Loss 4.6876 (4.6423)	Loss@kd 2.6884 (2.7181)	Acc@1 46.875 (46.308)	Acc@5 95.312 (94.970)
Epoch: [2][300/875]	Time 0.291 (0.346)	Data 0.007 (0.012)	Loss 4.6609 (4.6196)	Loss@kd 2.7635 (2.7021)	Acc@1 53.125 (46.548)	Acc@5 98.438 (94.944)
Epoch: [2][400/875]	Time 0.352 (0.349)	Data 0.007 (0.011)	Loss 4.5713 (4.6011)	Loss@kd 2.5637 (2.6909)	Acc@1 32.812 (46.785)	Acc@5 98.438 (95.048)
Epoch: [2][500/875]	Time 0.445 (0.351)	Data 0.007 (0.010)	Loss 4.5743 (4.5883)	Loss@kd 2.7517 (2.6803)	Acc@1 43.750 (46.713)	Acc@5 98.438 (94.985)
Epoch: [2][600/875]	Time 0.355 (0.353)	Data 0.009 (0.009)	Loss 4.3328 (4.5716)	Loss@kd 2.5774 (2.6678)	Acc@1 56.250 (46.896)	Acc@5 95.312 (94.969)
Epoch: [2][700/875]	Time 0.329 (0.354)	Data 0.006 (0.009)	Loss 4.3709 (4.5586)	Loss@kd 2.5821 (2.6583)	Acc@1 53.125 (47.011)	Acc@5 96.875 (94.960)
Epoch: [2][800/875]	Time 0.363 (0.354)	Data 0.007 (0.009)	Loss 4.5605 (4.5446)	Loss@kd 2.5891 (2.6490)	Acc@1 46.875 (47.267)	Acc@5 89.062 (94.969)
 * Acc@1 47.250 Acc@5 94.968
epoch 2, total time 310.64
Test: [0/750]	Time 0.823 (0.823)	Loss 0.8012 (0.8012)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.024 (0.040)	Loss 0.4970 (0.6365)	Acc@1 93.750 (81.281)	Acc@5 96.875 (87.252)
Test: [200/750]	Time 0.025 (0.036)	Loss 2.1292 (0.6528)	Acc@1 3.125 (80.597)	Acc@5 59.375 (90.423)
Test: [300/750]	Time 0.025 (0.035)	Loss 1.9327 (1.0718)	Acc@1 28.125 (58.814)	Acc@5 71.875 (82.776)
Test: [400/750]	Time 0.024 (0.034)	Loss 1.8704 (1.2554)	Acc@1 25.000 (51.216)	Acc@5 59.375 (79.871)
Test: [500/750]	Time 0.034 (0.033)	Loss 1.2330 (1.3163)	Acc@1 56.250 (48.971)	Acc@5 90.625 (78.749)
Test: [600/750]	Time 0.029 (0.033)	Loss 1.3265 (1.3066)	Acc@1 34.375 (48.866)	Acc@5 96.875 (81.078)
Test: [700/750]	Time 0.032 (0.033)	Loss 1.8585 (1.3305)	Acc@1 25.000 (47.053)	Acc@5 62.500 (81.731)
 * Acc@1 46.808 Acc@5 81.012
saving the best model!
==> training...
Epoch: [3][0/875]	Time 1.744 (1.744)	Data 1.397 (1.397)	Loss 4.4498 (4.4498)	Loss@kd 2.5441 (2.5441)	Acc@1 39.062 (39.062)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.359 (0.371)	Data 0.007 (0.021)	Loss 4.4545 (4.3966)	Loss@kd 2.6603 (2.5576)	Acc@1 51.562 (48.762)	Acc@5 95.312 (95.173)
Epoch: [3][200/875]	Time 0.364 (0.365)	Data 0.007 (0.014)	Loss 4.3523 (4.3906)	Loss@kd 2.5222 (2.5537)	Acc@1 54.688 (48.663)	Acc@5 98.438 (95.281)
Epoch: [3][300/875]	Time 0.308 (0.348)	Data 0.007 (0.011)	Loss 4.4752 (4.3786)	Loss@kd 2.4310 (2.5472)	Acc@1 39.062 (48.988)	Acc@5 93.750 (95.349)
Epoch: [3][400/875]	Time 0.360 (0.350)	Data 0.007 (0.010)	Loss 4.4385 (4.3791)	Loss@kd 2.5381 (2.5481)	Acc@1 48.438 (49.287)	Acc@5 93.750 (95.355)
Epoch: [3][500/875]	Time 0.360 (0.352)	Data 0.009 (0.010)	Loss 4.1658 (4.3751)	Loss@kd 2.4298 (2.5447)	Acc@1 53.125 (49.339)	Acc@5 95.312 (95.384)
Epoch: [3][600/875]	Time 0.350 (0.353)	Data 0.008 (0.009)	Loss 4.2783 (4.3637)	Loss@kd 2.4681 (2.5386)	Acc@1 48.438 (49.636)	Acc@5 92.188 (95.393)
Epoch: [3][700/875]	Time 0.356 (0.354)	Data 0.010 (0.009)	Loss 4.3639 (4.3566)	Loss@kd 2.5582 (2.5311)	Acc@1 56.250 (49.550)	Acc@5 95.312 (95.326)
Epoch: [3][800/875]	Time 0.352 (0.355)	Data 0.007 (0.009)	Loss 4.1891 (4.3485)	Loss@kd 2.4685 (2.5257)	Acc@1 53.125 (49.661)	Acc@5 100.000 (95.353)
 * Acc@1 49.832 Acc@5 95.391
epoch 3, total time 310.88
Test: [0/750]	Time 0.714 (0.714)	Loss 0.9146 (0.9146)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.040 (0.040)	Loss 0.6162 (0.7554)	Acc@1 78.125 (78.403)	Acc@5 96.875 (86.386)
Test: [200/750]	Time 0.040 (0.038)	Loss 1.8647 (0.7943)	Acc@1 12.500 (75.808)	Acc@5 75.000 (89.770)
Test: [300/750]	Time 0.027 (0.036)	Loss 1.7824 (1.0770)	Acc@1 12.500 (59.448)	Acc@5 71.875 (87.261)
Test: [400/750]	Time 0.031 (0.035)	Loss 1.2168 (1.1998)	Acc@1 62.500 (51.598)	Acc@5 87.500 (85.567)
Test: [500/750]	Time 0.033 (0.035)	Loss 1.4428 (1.2088)	Acc@1 53.125 (52.869)	Acc@5 87.500 (85.286)
Test: [600/750]	Time 0.034 (0.034)	Loss 1.3588 (1.2364)	Acc@1 37.500 (52.948)	Acc@5 81.250 (85.280)
Test: [700/750]	Time 0.045 (0.034)	Loss 1.3678 (1.2484)	Acc@1 62.500 (52.349)	Acc@5 78.125 (85.503)
 * Acc@1 52.908 Acc@5 85.454
saving the best model!
==> training...
Epoch: [4][0/875]	Time 1.680 (1.680)	Data 1.301 (1.301)	Loss 4.2380 (4.2380)	Loss@kd 2.4881 (2.4881)	Acc@1 57.812 (57.812)	Acc@5 92.188 (92.188)
Epoch: [4][100/875]	Time 0.351 (0.373)	Data 0.005 (0.020)	Loss 4.2402 (4.2509)	Loss@kd 2.4229 (2.4654)	Acc@1 43.750 (50.743)	Acc@5 98.438 (95.343)
Epoch: [4][200/875]	Time 0.359 (0.366)	Data 0.008 (0.014)	Loss 4.4072 (4.2420)	Loss@kd 2.5219 (2.4619)	Acc@1 50.000 (51.275)	Acc@5 95.312 (95.437)
Epoch: [4][300/875]	Time 0.303 (0.350)	Data 0.006 (0.011)	Loss 4.1198 (4.2417)	Loss@kd 2.4082 (2.4633)	Acc@1 51.562 (51.391)	Acc@5 98.438 (95.453)
Epoch: [4][400/875]	Time 0.365 (0.350)	Data 0.006 (0.010)	Loss 4.2389 (4.2387)	Loss@kd 2.4501 (2.4634)	Acc@1 42.188 (51.551)	Acc@5 93.750 (95.468)
Epoch: [4][500/875]	Time 0.358 (0.351)	Data 0.010 (0.010)	Loss 4.0615 (4.2291)	Loss@kd 2.3312 (2.4563)	Acc@1 46.875 (51.653)	Acc@5 96.875 (95.493)
Epoch: [4][600/875]	Time 0.338 (0.353)	Data 0.007 (0.009)	Loss 4.1808 (4.2202)	Loss@kd 2.5748 (2.4526)	Acc@1 54.688 (51.817)	Acc@5 98.438 (95.611)
Epoch: [4][700/875]	Time 0.354 (0.353)	Data 0.006 (0.009)	Loss 4.2996 (4.2158)	Loss@kd 2.3891 (2.4497)	Acc@1 48.438 (51.877)	Acc@5 93.750 (95.638)
Epoch: [4][800/875]	Time 0.358 (0.354)	Data 0.007 (0.009)	Loss 4.0528 (4.2132)	Loss@kd 2.3924 (2.4473)	Acc@1 46.875 (51.857)	Acc@5 98.438 (95.617)
 * Acc@1 51.805 Acc@5 95.609
epoch 4, total time 310.25
Test: [0/750]	Time 0.669 (0.669)	Loss 0.7693 (0.7693)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.047 (0.042)	Loss 0.4281 (0.5698)	Acc@1 87.500 (83.230)	Acc@5 100.000 (88.366)
Test: [200/750]	Time 0.022 (0.038)	Loss 2.1576 (0.5994)	Acc@1 6.250 (81.390)	Acc@5 50.000 (90.843)
Test: [300/750]	Time 0.036 (0.037)	Loss 1.6648 (1.0036)	Acc@1 34.375 (61.088)	Acc@5 84.375 (84.095)
Test: [400/750]	Time 0.032 (0.037)	Loss 1.3228 (1.1391)	Acc@1 59.375 (55.603)	Acc@5 87.500 (85.061)
Test: [500/750]	Time 0.024 (0.036)	Loss 1.8696 (1.2095)	Acc@1 40.625 (54.435)	Acc@5 75.000 (84.325)
Test: [600/750]	Time 0.033 (0.035)	Loss 1.2302 (1.2669)	Acc@1 46.875 (52.329)	Acc@5 90.625 (84.349)
Test: [700/750]	Time 0.027 (0.035)	Loss 1.6075 (1.2788)	Acc@1 31.250 (50.740)	Acc@5 78.125 (84.874)
 * Acc@1 50.454 Acc@5 84.546
==> training...
Epoch: [5][0/875]	Time 1.673 (1.673)	Data 1.295 (1.295)	Loss 4.2623 (4.2623)	Loss@kd 2.4265 (2.4265)	Acc@1 53.125 (53.125)	Acc@5 92.188 (92.188)
Epoch: [5][100/875]	Time 0.347 (0.373)	Data 0.007 (0.020)	Loss 4.2330 (4.1619)	Loss@kd 2.4371 (2.4233)	Acc@1 46.875 (52.243)	Acc@5 96.875 (95.746)
Epoch: [5][200/875]	Time 0.359 (0.367)	Data 0.006 (0.013)	Loss 4.1394 (4.1515)	Loss@kd 2.4521 (2.4133)	Acc@1 51.562 (52.542)	Acc@5 96.875 (95.841)
Epoch: [5][300/875]	Time 0.304 (0.351)	Data 0.007 (0.011)	Loss 4.1845 (4.1374)	Loss@kd 2.4420 (2.4050)	Acc@1 57.812 (52.824)	Acc@5 100.000 (95.811)
Epoch: [5][400/875]	Time 0.356 (0.353)	Data 0.007 (0.010)	Loss 4.0212 (4.1298)	Loss@kd 2.3154 (2.3999)	Acc@1 50.000 (52.981)	Acc@5 95.312 (95.835)
Epoch: [5][500/875]	Time 0.354 (0.354)	Data 0.008 (0.010)	Loss 4.1935 (4.1238)	Loss@kd 2.3409 (2.3957)	Acc@1 43.750 (53.137)	Acc@5 93.750 (95.818)
Epoch: [5][600/875]	Time 0.356 (0.354)	Data 0.007 (0.009)	Loss 4.1966 (4.1240)	Loss@kd 2.4041 (2.3944)	Acc@1 45.312 (53.044)	Acc@5 95.312 (95.809)
Epoch: [5][700/875]	Time 0.359 (0.355)	Data 0.007 (0.009)	Loss 4.1341 (4.1242)	Loss@kd 2.4332 (2.3925)	Acc@1 53.125 (52.965)	Acc@5 98.438 (95.794)
Epoch: [5][800/875]	Time 0.353 (0.355)	Data 0.007 (0.009)	Loss 4.3390 (4.1190)	Loss@kd 2.4621 (2.3909)	Acc@1 50.000 (53.080)	Acc@5 95.312 (95.872)
 * Acc@1 53.259 Acc@5 95.891
epoch 5, total time 311.29
Test: [0/750]	Time 0.692 (0.692)	Loss 0.9769 (0.9769)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.031 (0.039)	Loss 0.6942 (0.7467)	Acc@1 75.000 (78.899)	Acc@5 96.875 (86.850)
Test: [200/750]	Time 0.028 (0.037)	Loss 1.8395 (0.8307)	Acc@1 28.125 (73.228)	Acc@5 68.750 (89.925)
Test: [300/750]	Time 0.043 (0.036)	Loss 1.8064 (1.1011)	Acc@1 18.750 (59.624)	Acc@5 71.875 (87.967)
Test: [400/750]	Time 0.035 (0.035)	Loss 0.9653 (1.2228)	Acc@1 75.000 (52.696)	Acc@5 96.875 (86.245)
Test: [500/750]	Time 0.048 (0.034)	Loss 0.8533 (1.1731)	Acc@1 71.875 (56.581)	Acc@5 96.875 (87.269)
Test: [600/750]	Time 0.040 (0.034)	Loss 1.2708 (1.1497)	Acc@1 56.250 (58.143)	Acc@5 87.500 (87.854)
Test: [700/750]	Time 0.022 (0.033)	Loss 1.8465 (1.1884)	Acc@1 25.000 (56.152)	Acc@5 59.375 (86.907)
 * Acc@1 55.142 Acc@5 85.829
saving the best model!
==> training...
Epoch: [6][0/875]	Time 1.598 (1.598)	Data 1.269 (1.269)	Loss 4.0048 (4.0048)	Loss@kd 2.3666 (2.3666)	Acc@1 57.812 (57.812)	Acc@5 96.875 (96.875)
Epoch: [6][100/875]	Time 0.356 (0.372)	Data 0.008 (0.019)	Loss 4.0445 (4.0359)	Loss@kd 2.3261 (2.3459)	Acc@1 51.562 (53.837)	Acc@5 95.312 (96.241)
Epoch: [6][200/875]	Time 0.350 (0.365)	Data 0.005 (0.013)	Loss 4.2357 (4.0492)	Loss@kd 2.3760 (2.3488)	Acc@1 53.125 (53.553)	Acc@5 93.750 (95.989)
Epoch: [6][300/875]	Time 0.301 (0.350)	Data 0.007 (0.011)	Loss 4.0373 (4.0520)	Loss@kd 2.3592 (2.3531)	Acc@1 56.250 (53.950)	Acc@5 96.875 (96.086)
Epoch: [6][400/875]	Time 0.364 (0.349)	Data 0.006 (0.010)	Loss 3.7890 (4.0468)	Loss@kd 2.3184 (2.3518)	Acc@1 71.875 (54.111)	Acc@5 98.438 (96.178)
Epoch: [6][500/875]	Time 0.360 (0.351)	Data 0.011 (0.009)	Loss 4.1536 (4.0383)	Loss@kd 2.4825 (2.3471)	Acc@1 64.062 (54.188)	Acc@5 92.188 (96.189)
Epoch: [6][600/875]	Time 0.328 (0.352)	Data 0.007 (0.009)	Loss 4.1080 (4.0356)	Loss@kd 2.3532 (2.3457)	Acc@1 53.125 (54.230)	Acc@5 92.188 (96.199)
Epoch: [6][700/875]	Time 0.358 (0.353)	Data 0.007 (0.009)	Loss 3.8721 (4.0308)	Loss@kd 2.2779 (2.3431)	Acc@1 57.812 (54.275)	Acc@5 96.875 (96.197)
Epoch: [6][800/875]	Time 0.356 (0.354)	Data 0.008 (0.009)	Loss 4.0942 (4.0314)	Loss@kd 2.3048 (2.3415)	Acc@1 51.562 (54.210)	Acc@5 96.875 (96.171)
 * Acc@1 54.316 Acc@5 96.205
epoch 6, total time 310.69
Test: [0/750]	Time 0.660 (0.660)	Loss 0.9068 (0.9068)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.027 (0.041)	Loss 0.5730 (0.6919)	Acc@1 81.250 (81.126)	Acc@5 96.875 (86.881)
Test: [200/750]	Time 0.045 (0.039)	Loss 1.8708 (0.7340)	Acc@1 28.125 (78.420)	Acc@5 81.250 (90.470)
Test: [300/750]	Time 0.028 (0.037)	Loss 1.8986 (1.0142)	Acc@1 9.375 (64.358)	Acc@5 71.875 (88.746)
Test: [400/750]	Time 0.038 (0.037)	Loss 1.1764 (1.1840)	Acc@1 53.125 (54.060)	Acc@5 81.250 (85.365)
Test: [500/750]	Time 0.031 (0.036)	Loss 0.8151 (1.1507)	Acc@1 75.000 (56.562)	Acc@5 100.000 (85.311)
Test: [600/750]	Time 0.029 (0.036)	Loss 1.4858 (1.1492)	Acc@1 40.625 (57.134)	Acc@5 84.375 (85.883)
Test: [700/750]	Time 0.029 (0.036)	Loss 1.3351 (1.1806)	Acc@1 53.125 (55.091)	Acc@5 81.250 (85.975)
 * Acc@1 55.329 Acc@5 86.004
saving the best model!
==> training...
Epoch: [7][0/875]	Time 1.754 (1.754)	Data 1.420 (1.420)	Loss 3.8443 (3.8443)	Loss@kd 2.3348 (2.3348)	Acc@1 54.688 (54.688)	Acc@5 98.438 (98.438)
Epoch: [7][100/875]	Time 0.360 (0.372)	Data 0.008 (0.021)	Loss 3.8075 (3.9956)	Loss@kd 2.3504 (2.3285)	Acc@1 65.625 (54.703)	Acc@5 98.438 (96.117)
Epoch: [7][200/875]	Time 0.360 (0.365)	Data 0.007 (0.014)	Loss 4.0428 (3.9674)	Loss@kd 2.2881 (2.3140)	Acc@1 45.312 (55.045)	Acc@5 96.875 (96.494)
Epoch: [7][300/875]	Time 0.311 (0.351)	Data 0.008 (0.012)	Loss 4.2279 (3.9735)	Loss@kd 2.2965 (2.3141)	Acc@1 45.312 (55.035)	Acc@5 90.625 (96.397)
Epoch: [7][400/875]	Time 0.353 (0.350)	Data 0.006 (0.010)	Loss 3.8209 (3.9707)	Loss@kd 2.2166 (2.3090)	Acc@1 54.688 (55.050)	Acc@5 96.875 (96.322)
Epoch: [7][500/875]	Time 0.364 (0.352)	Data 0.005 (0.010)	Loss 4.0067 (3.9750)	Loss@kd 2.3388 (2.3084)	Acc@1 59.375 (54.934)	Acc@5 95.312 (96.251)
Epoch: [7][600/875]	Time 0.384 (0.354)	Data 0.007 (0.009)	Loss 3.8752 (3.9737)	Loss@kd 2.2925 (2.3078)	Acc@1 60.938 (55.010)	Acc@5 96.875 (96.316)
Epoch: [7][700/875]	Time 0.352 (0.354)	Data 0.007 (0.009)	Loss 3.7712 (3.9730)	Loss@kd 2.2007 (2.3061)	Acc@1 56.250 (55.026)	Acc@5 98.438 (96.300)
Epoch: [7][800/875]	Time 0.353 (0.355)	Data 0.007 (0.009)	Loss 3.9661 (3.9681)	Loss@kd 2.1752 (2.3053)	Acc@1 45.312 (55.204)	Acc@5 96.875 (96.342)
 * Acc@1 55.277 Acc@5 96.350
epoch 7, total time 311.32
Test: [0/750]	Time 0.734 (0.734)	Loss 0.8754 (0.8754)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.025 (0.041)	Loss 0.8236 (0.7144)	Acc@1 65.625 (78.589)	Acc@5 96.875 (86.170)
Test: [200/750]	Time 0.036 (0.037)	Loss 1.6231 (0.8375)	Acc@1 37.500 (72.932)	Acc@5 90.625 (88.977)
Test: [300/750]	Time 0.033 (0.037)	Loss 1.6643 (1.0175)	Acc@1 12.500 (64.203)	Acc@5 87.500 (89.929)
Test: [400/750]	Time 0.035 (0.036)	Loss 1.3009 (1.1494)	Acc@1 53.125 (55.120)	Acc@5 75.000 (88.272)
Test: [500/750]	Time 0.028 (0.036)	Loss 0.7773 (1.1439)	Acc@1 75.000 (56.911)	Acc@5 93.750 (86.708)
Test: [600/750]	Time 0.027 (0.035)	Loss 1.4229 (1.1343)	Acc@1 40.625 (58.143)	Acc@5 81.250 (87.006)
Test: [700/750]	Time 0.041 (0.035)	Loss 1.5190 (1.1675)	Acc@1 37.500 (56.388)	Acc@5 78.125 (86.791)
 * Acc@1 56.025 Acc@5 86.512
saving the best model!
==> training...
Epoch: [8][0/875]	Time 1.714 (1.714)	Data 1.347 (1.347)	Loss 3.8326 (3.8326)	Loss@kd 2.1847 (2.1847)	Acc@1 54.688 (54.688)	Acc@5 98.438 (98.438)
Epoch: [8][100/875]	Time 0.354 (0.372)	Data 0.007 (0.020)	Loss 3.9995 (3.9419)	Loss@kd 2.2581 (2.2805)	Acc@1 50.000 (54.842)	Acc@5 93.750 (96.380)
Epoch: [8][200/875]	Time 0.359 (0.366)	Data 0.008 (0.014)	Loss 3.9528 (3.9332)	Loss@kd 2.2348 (2.2818)	Acc@1 51.562 (55.504)	Acc@5 95.312 (96.401)
Epoch: [8][300/875]	Time 0.307 (0.352)	Data 0.007 (0.011)	Loss 4.0215 (3.9290)	Loss@kd 2.3670 (2.2803)	Acc@1 59.375 (55.684)	Acc@5 100.000 (96.403)
Epoch: [8][400/875]	Time 0.356 (0.351)	Data 0.008 (0.010)	Loss 3.8319 (3.9195)	Loss@kd 2.2327 (2.2786)	Acc@1 62.500 (56.164)	Acc@5 95.312 (96.458)
Epoch: [8][500/875]	Time 0.356 (0.353)	Data 0.008 (0.010)	Loss 3.9636 (3.9204)	Loss@kd 2.4494 (2.2776)	Acc@1 65.625 (56.078)	Acc@5 96.875 (96.413)
Epoch: [8][600/875]	Time 0.371 (0.354)	Data 0.007 (0.009)	Loss 3.7787 (3.9175)	Loss@kd 2.1278 (2.2751)	Acc@1 56.250 (55.899)	Acc@5 92.188 (96.443)
Epoch: [8][700/875]	Time 0.350 (0.355)	Data 0.006 (0.009)	Loss 3.8912 (3.9170)	Loss@kd 2.2547 (2.2731)	Acc@1 59.375 (55.766)	Acc@5 92.188 (96.396)
Epoch: [8][800/875]	Time 0.366 (0.356)	Data 0.006 (0.009)	Loss 3.8746 (3.9149)	Loss@kd 2.3117 (2.2733)	Acc@1 57.812 (55.842)	Acc@5 100.000 (96.420)
 * Acc@1 55.877 Acc@5 96.411
epoch 8, total time 312.15
Test: [0/750]	Time 0.717 (0.717)	Loss 0.7993 (0.7993)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.032 (0.040)	Loss 0.5164 (0.6113)	Acc@1 84.375 (82.024)	Acc@5 96.875 (87.933)
Test: [200/750]	Time 0.034 (0.038)	Loss 2.2259 (0.6850)	Acc@1 15.625 (78.141)	Acc@5 59.375 (90.283)
Test: [300/750]	Time 0.035 (0.037)	Loss 1.8766 (1.0784)	Acc@1 12.500 (58.908)	Acc@5 84.375 (85.019)
Test: [400/750]	Time 0.036 (0.036)	Loss 0.7086 (1.1926)	Acc@1 87.500 (52.408)	Acc@5 96.875 (84.562)
Test: [500/750]	Time 0.041 (0.036)	Loss 0.9327 (1.1079)	Acc@1 62.500 (57.647)	Acc@5 90.625 (86.346)
Test: [600/750]	Time 0.039 (0.035)	Loss 1.4365 (1.1147)	Acc@1 56.250 (57.976)	Acc@5 84.375 (86.793)
Test: [700/750]	Time 0.048 (0.035)	Loss 1.4143 (1.1471)	Acc@1 53.125 (56.375)	Acc@5 75.000 (86.742)
 * Acc@1 56.479 Acc@5 86.517
saving the best model!
==> training...
Epoch: [9][0/875]	Time 1.633 (1.633)	Data 1.234 (1.234)	Loss 3.8806 (3.8806)	Loss@kd 2.3429 (2.3429)	Acc@1 57.812 (57.812)	Acc@5 96.875 (96.875)
Epoch: [9][100/875]	Time 0.355 (0.371)	Data 0.006 (0.019)	Loss 4.0427 (3.9128)	Loss@kd 2.3537 (2.2710)	Acc@1 54.688 (55.507)	Acc@5 95.312 (96.364)
Epoch: [9][200/875]	Time 0.361 (0.365)	Data 0.007 (0.013)	Loss 4.0115 (3.8906)	Loss@kd 2.2568 (2.2585)	Acc@1 51.562 (55.558)	Acc@5 98.438 (96.385)
Epoch: [9][300/875]	Time 0.318 (0.351)	Data 0.007 (0.011)	Loss 3.7971 (3.8827)	Loss@kd 2.1717 (2.2552)	Acc@1 53.125 (55.881)	Acc@5 93.750 (96.392)
Epoch: [9][400/875]	Time 0.357 (0.349)	Data 0.008 (0.010)	Loss 3.7531 (3.8809)	Loss@kd 2.1883 (2.2524)	Acc@1 54.688 (56.005)	Acc@5 96.875 (96.411)
Epoch: [9][500/875]	Time 0.352 (0.351)	Data 0.008 (0.009)	Loss 3.7106 (3.8799)	Loss@kd 2.2212 (2.2512)	Acc@1 57.812 (55.994)	Acc@5 100.000 (96.435)
Epoch: [9][600/875]	Time 0.347 (0.352)	Data 0.007 (0.009)	Loss 4.4150 (3.8760)	Loss@kd 2.6044 (2.2489)	Acc@1 50.000 (56.177)	Acc@5 96.875 (96.428)
Epoch: [9][700/875]	Time 0.362 (0.353)	Data 0.008 (0.009)	Loss 3.8597 (3.8769)	Loss@kd 2.1567 (2.2481)	Acc@1 51.562 (56.130)	Acc@5 93.750 (96.407)
Epoch: [9][800/875]	Time 0.356 (0.353)	Data 0.006 (0.009)	Loss 3.8107 (3.8723)	Loss@kd 2.2365 (2.2471)	Acc@1 60.938 (56.260)	Acc@5 96.875 (96.442)
 * Acc@1 56.373 Acc@5 96.454
epoch 9, total time 309.56
Test: [0/750]	Time 0.752 (0.752)	Loss 0.8409 (0.8409)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.037 (0.042)	Loss 0.6371 (0.6577)	Acc@1 84.375 (81.188)	Acc@5 93.750 (87.314)
Test: [200/750]	Time 0.035 (0.036)	Loss 1.9442 (0.7518)	Acc@1 15.625 (76.104)	Acc@5 68.750 (89.817)
Test: [300/750]	Time 0.031 (0.036)	Loss 1.6445 (1.0490)	Acc@1 25.000 (60.112)	Acc@5 93.750 (87.220)
Test: [400/750]	Time 0.029 (0.036)	Loss 0.7656 (1.1369)	Acc@1 81.250 (54.660)	Acc@5 96.875 (87.609)
Test: [500/750]	Time 0.022 (0.035)	Loss 0.9413 (1.0780)	Acc@1 62.500 (58.938)	Acc@5 93.750 (88.386)
Test: [600/750]	Time 0.038 (0.034)	Loss 1.4966 (1.0948)	Acc@1 46.875 (59.094)	Acc@5 68.750 (88.036)
Test: [700/750]	Time 0.025 (0.034)	Loss 1.3759 (1.1306)	Acc@1 50.000 (57.414)	Acc@5 84.375 (87.545)
 * Acc@1 57.596 Acc@5 87.262
saving the best model!
==> training...
Epoch: [10][0/875]	Time 1.722 (1.722)	Data 1.402 (1.402)	Loss 3.6855 (3.6855)	Loss@kd 2.2106 (2.2106)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [10][100/875]	Time 0.357 (0.371)	Data 0.008 (0.021)	Loss 4.0833 (3.8666)	Loss@kd 2.2793 (2.2463)	Acc@1 51.562 (56.188)	Acc@5 93.750 (96.411)
Epoch: [10][200/875]	Time 0.352 (0.365)	Data 0.007 (0.014)	Loss 3.7926 (3.8561)	Loss@kd 2.1619 (2.2394)	Acc@1 51.562 (56.351)	Acc@5 98.438 (96.525)
Epoch: [10][300/875]	Time 0.299 (0.351)	Data 0.009 (0.012)	Loss 4.0152 (3.8497)	Loss@kd 2.2429 (2.2330)	Acc@1 53.125 (56.551)	Acc@5 95.312 (96.480)
Epoch: [10][400/875]	Time 0.352 (0.349)	Data 0.008 (0.011)	Loss 3.9244 (3.8482)	Loss@kd 2.3672 (2.2304)	Acc@1 64.062 (56.503)	Acc@5 96.875 (96.485)
Epoch: [10][500/875]	Time 0.347 (0.351)	Data 0.007 (0.010)	Loss 3.8700 (3.8452)	Loss@kd 2.2229 (2.2285)	Acc@1 54.688 (56.624)	Acc@5 98.438 (96.482)
Epoch: [10][600/875]	Time 0.374 (0.352)	Data 0.007 (0.009)	Loss 3.5783 (3.8353)	Loss@kd 2.1805 (2.2229)	Acc@1 62.500 (56.765)	Acc@5 96.875 (96.534)
Epoch: [10][700/875]	Time 0.443 (0.354)	Data 0.009 (0.009)	Loss 3.7178 (3.8341)	Loss@kd 2.1549 (2.2226)	Acc@1 53.125 (56.774)	Acc@5 96.875 (96.547)
Epoch: [10][800/875]	Time 0.358 (0.354)	Data 0.007 (0.009)	Loss 3.7294 (3.8305)	Loss@kd 2.1307 (2.2211)	Acc@1 51.562 (56.781)	Acc@5 98.438 (96.586)
 * Acc@1 56.807 Acc@5 96.575
epoch 10, total time 310.60
Test: [0/750]	Time 0.671 (0.671)	Loss 0.9170 (0.9170)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.027 (0.040)	Loss 0.5075 (0.7163)	Acc@1 81.250 (80.322)	Acc@5 100.000 (86.572)
Test: [200/750]	Time 0.032 (0.036)	Loss 1.9589 (0.7053)	Acc@1 28.125 (77.363)	Acc@5 59.375 (91.029)
Test: [300/750]	Time 0.048 (0.036)	Loss 1.6761 (1.0206)	Acc@1 28.125 (61.908)	Acc@5 84.375 (88.341)
Test: [400/750]	Time 0.038 (0.036)	Loss 1.1919 (1.1551)	Acc@1 75.000 (54.512)	Acc@5 84.375 (87.336)
Test: [500/750]	Time 0.039 (0.036)	Loss 0.9856 (1.1595)	Acc@1 59.375 (55.813)	Acc@5 90.625 (86.346)
Test: [600/750]	Time 0.035 (0.036)	Loss 0.9476 (1.1383)	Acc@1 68.750 (57.498)	Acc@5 93.750 (87.266)
Test: [700/750]	Time 0.043 (0.036)	Loss 1.4474 (1.1299)	Acc@1 43.750 (57.841)	Acc@5 75.000 (87.727)
 * Acc@1 58.058 Acc@5 87.308
saving the best model!
==> training...
Epoch: [11][0/875]	Time 1.638 (1.638)	Data 1.278 (1.278)	Loss 3.8511 (3.8511)	Loss@kd 2.1351 (2.1351)	Acc@1 51.562 (51.562)	Acc@5 95.312 (95.312)
Epoch: [11][100/875]	Time 0.357 (0.372)	Data 0.007 (0.020)	Loss 3.6923 (3.8012)	Loss@kd 2.1696 (2.2078)	Acc@1 57.812 (57.952)	Acc@5 96.875 (96.612)
Epoch: [11][200/875]	Time 0.353 (0.366)	Data 0.007 (0.013)	Loss 3.9110 (3.8131)	Loss@kd 2.2192 (2.2121)	Acc@1 48.438 (57.152)	Acc@5 98.438 (96.564)
Epoch: [11][300/875]	Time 0.304 (0.352)	Data 0.007 (0.011)	Loss 3.7446 (3.8159)	Loss@kd 2.2035 (2.2105)	Acc@1 65.625 (56.946)	Acc@5 98.438 (96.626)
Epoch: [11][400/875]	Time 0.350 (0.350)	Data 0.007 (0.010)	Loss 3.8293 (3.8115)	Loss@kd 2.1928 (2.2108)	Acc@1 53.125 (56.975)	Acc@5 95.312 (96.653)
Epoch: [11][500/875]	Time 0.356 (0.353)	Data 0.008 (0.009)	Loss 3.6244 (3.8094)	Loss@kd 2.1672 (2.2098)	Acc@1 68.750 (56.945)	Acc@5 96.875 (96.679)
Epoch: [11][600/875]	Time 0.361 (0.354)	Data 0.008 (0.009)	Loss 3.7280 (3.8066)	Loss@kd 2.2638 (2.2075)	Acc@1 62.500 (56.970)	Acc@5 100.000 (96.685)
Epoch: [11][700/875]	Time 0.362 (0.355)	Data 0.006 (0.009)	Loss 3.8270 (3.8065)	Loss@kd 2.2042 (2.2066)	Acc@1 51.562 (56.957)	Acc@5 92.188 (96.637)
Epoch: [11][800/875]	Time 0.354 (0.356)	Data 0.007 (0.009)	Loss 3.6558 (3.7992)	Loss@kd 2.1523 (2.2034)	Acc@1 57.812 (57.143)	Acc@5 98.438 (96.690)
 * Acc@1 57.125 Acc@5 96.677
epoch 11, total time 311.84
Test: [0/750]	Time 0.712 (0.712)	Loss 0.7647 (0.7647)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.032 (0.042)	Loss 0.4911 (0.5995)	Acc@1 78.125 (82.395)	Acc@5 96.875 (88.769)
Test: [200/750]	Time 0.026 (0.037)	Loss 2.6138 (0.6837)	Acc@1 9.375 (78.685)	Acc@5 53.125 (90.547)
Test: [300/750]	Time 0.024 (0.035)	Loss 2.1691 (1.1776)	Acc@1 9.375 (56.613)	Acc@5 75.000 (83.794)
Test: [400/750]	Time 0.035 (0.034)	Loss 0.3899 (1.2923)	Acc@1 96.875 (50.842)	Acc@5 100.000 (83.424)
Test: [500/750]	Time 0.044 (0.033)	Loss 1.1884 (1.1568)	Acc@1 56.250 (57.522)	Acc@5 100.000 (85.922)
Test: [600/750]	Time 0.029 (0.033)	Loss 1.2805 (1.1672)	Acc@1 59.375 (57.410)	Acc@5 87.500 (86.762)
Test: [700/750]	Time 0.039 (0.033)	Loss 1.8618 (1.2161)	Acc@1 28.125 (54.494)	Acc@5 68.750 (86.613)
 * Acc@1 52.908 Acc@5 86.017
==> training...
Epoch: [12][0/875]	Time 1.620 (1.620)	Data 1.245 (1.245)	Loss 3.8619 (3.8619)	Loss@kd 2.1692 (2.1692)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [12][100/875]	Time 0.362 (0.371)	Data 0.008 (0.019)	Loss 3.8159 (3.7584)	Loss@kd 2.1691 (2.1747)	Acc@1 57.812 (57.596)	Acc@5 92.188 (96.597)
Epoch: [12][200/875]	Time 0.354 (0.365)	Data 0.007 (0.013)	Loss 3.6014 (3.7704)	Loss@kd 2.1662 (2.1823)	Acc@1 62.500 (57.214)	Acc@5 98.438 (96.541)
Epoch: [12][300/875]	Time 0.308 (0.353)	Data 0.007 (0.011)	Loss 3.6275 (3.7750)	Loss@kd 2.1900 (2.1856)	Acc@1 67.188 (57.247)	Acc@5 98.438 (96.543)
Epoch: [12][400/875]	Time 0.370 (0.351)	Data 0.007 (0.010)	Loss 3.6742 (3.7722)	Loss@kd 2.2076 (2.1861)	Acc@1 65.625 (57.271)	Acc@5 98.438 (96.594)
Epoch: [12][500/875]	Time 0.361 (0.353)	Data 0.007 (0.009)	Loss 3.7350 (3.7652)	Loss@kd 2.1636 (2.1835)	Acc@1 59.375 (57.360)	Acc@5 98.438 (96.619)
Epoch: [12][600/875]	Time 0.364 (0.354)	Data 0.007 (0.009)	Loss 3.7306 (3.7675)	Loss@kd 2.1708 (2.1832)	Acc@1 65.625 (57.256)	Acc@5 95.312 (96.623)
Epoch: [12][700/875]	Time 0.358 (0.355)	Data 0.007 (0.009)	Loss 3.9035 (3.7659)	Loss@kd 2.1881 (2.1818)	Acc@1 62.500 (57.300)	Acc@5 96.875 (96.637)
Epoch: [12][800/875]	Time 0.354 (0.356)	Data 0.007 (0.009)	Loss 3.6801 (3.7685)	Loss@kd 2.1079 (2.1822)	Acc@1 56.250 (57.182)	Acc@5 98.438 (96.678)
 * Acc@1 57.191 Acc@5 96.664
epoch 12, total time 311.90
Test: [0/750]	Time 0.786 (0.786)	Loss 0.8723 (0.8723)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.032 (0.039)	Loss 0.5894 (0.6842)	Acc@1 78.125 (81.157)	Acc@5 96.875 (87.655)
Test: [200/750]	Time 0.031 (0.038)	Loss 2.6008 (0.7728)	Acc@1 0.000 (73.772)	Acc@5 56.250 (89.521)
Test: [300/750]	Time 0.036 (0.037)	Loss 1.5858 (1.1771)	Acc@1 31.250 (54.184)	Acc@5 96.875 (82.330)
Test: [400/750]	Time 0.053 (0.037)	Loss 0.7553 (1.2166)	Acc@1 78.125 (51.294)	Acc@5 87.500 (85.240)
Test: [500/750]	Time 0.044 (0.036)	Loss 1.6283 (1.1637)	Acc@1 56.250 (55.264)	Acc@5 75.000 (85.972)
Test: [600/750]	Time 0.046 (0.037)	Loss 1.0595 (1.2035)	Acc@1 65.625 (55.298)	Acc@5 93.750 (85.602)
Test: [700/750]	Time 0.039 (0.036)	Loss 1.3188 (1.1874)	Acc@1 56.250 (55.947)	Acc@5 81.250 (86.457)
 * Acc@1 56.204 Acc@5 86.529
==> training...
Epoch: [13][0/875]	Time 1.709 (1.709)	Data 1.363 (1.363)	Loss 3.5964 (3.5964)	Loss@kd 2.1643 (2.1643)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [13][100/875]	Time 0.358 (0.372)	Data 0.008 (0.021)	Loss 3.9921 (3.7298)	Loss@kd 2.1485 (2.1582)	Acc@1 35.938 (58.014)	Acc@5 95.312 (96.906)
Epoch: [13][200/875]	Time 0.354 (0.367)	Data 0.007 (0.014)	Loss 3.5504 (3.7412)	Loss@kd 2.0890 (2.1697)	Acc@1 59.375 (57.937)	Acc@5 98.438 (96.875)
Epoch: [13][300/875]	Time 0.306 (0.353)	Data 0.007 (0.012)	Loss 3.5006 (3.7278)	Loss@kd 2.1408 (2.1658)	Acc@1 64.062 (58.046)	Acc@5 96.875 (96.771)
Epoch: [13][400/875]	Time 0.355 (0.351)	Data 0.007 (0.010)	Loss 3.9208 (3.7355)	Loss@kd 2.1860 (2.1656)	Acc@1 48.438 (57.828)	Acc@5 96.875 (96.739)
Epoch: [13][500/875]	Time 0.355 (0.353)	Data 0.007 (0.010)	Loss 3.7573 (3.7361)	Loss@kd 2.1652 (2.1642)	Acc@1 59.375 (57.653)	Acc@5 92.188 (96.710)
Epoch: [13][600/875]	Time 0.363 (0.354)	Data 0.006 (0.009)	Loss 3.6186 (3.7337)	Loss@kd 2.0772 (2.1621)	Acc@1 57.812 (57.589)	Acc@5 98.438 (96.742)
Epoch: [13][700/875]	Time 0.358 (0.355)	Data 0.007 (0.009)	Loss 3.6685 (3.7304)	Loss@kd 2.0890 (2.1597)	Acc@1 62.500 (57.583)	Acc@5 92.188 (96.786)
Epoch: [13][800/875]	Time 0.360 (0.356)	Data 0.007 (0.009)	Loss 3.8746 (3.7317)	Loss@kd 2.1865 (2.1603)	Acc@1 54.688 (57.615)	Acc@5 92.188 (96.770)
 * Acc@1 57.720 Acc@5 96.795
epoch 13, total time 312.21
Test: [0/750]	Time 0.697 (0.697)	Loss 0.7723 (0.7723)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.023 (0.039)	Loss 0.7002 (0.6159)	Acc@1 75.000 (80.476)	Acc@5 96.875 (88.614)
Test: [200/750]	Time 0.035 (0.035)	Loss 2.0045 (0.7213)	Acc@1 18.750 (73.912)	Acc@5 68.750 (91.480)
Test: [300/750]	Time 0.039 (0.035)	Loss 1.5033 (1.0262)	Acc@1 34.375 (59.375)	Acc@5 84.375 (89.327)
Test: [400/750]	Time 0.032 (0.035)	Loss 1.3824 (1.1359)	Acc@1 46.875 (53.195)	Acc@5 81.250 (88.599)
Test: [500/750]	Time 0.032 (0.035)	Loss 0.7785 (1.1449)	Acc@1 71.875 (54.790)	Acc@5 93.750 (86.776)
Test: [600/750]	Time 0.032 (0.034)	Loss 0.9969 (1.1086)	Acc@1 65.625 (57.592)	Acc@5 93.750 (87.630)
Test: [700/750]	Time 0.024 (0.034)	Loss 1.3012 (1.0979)	Acc@1 53.125 (58.430)	Acc@5 81.250 (88.249)
 * Acc@1 58.829 Acc@5 88.037
saving the best model!
==> training...
Epoch: [14][0/875]	Time 1.668 (1.668)	Data 1.286 (1.286)	Loss 3.7600 (3.7600)	Loss@kd 2.0848 (2.0848)	Acc@1 51.562 (51.562)	Acc@5 95.312 (95.312)
Epoch: [14][100/875]	Time 0.358 (0.370)	Data 0.008 (0.020)	Loss 3.7856 (3.7457)	Loss@kd 2.0647 (2.1534)	Acc@1 48.438 (57.008)	Acc@5 98.438 (96.426)
Epoch: [14][200/875]	Time 0.352 (0.366)	Data 0.007 (0.013)	Loss 3.6030 (3.7297)	Loss@kd 2.1542 (2.1523)	Acc@1 67.188 (57.626)	Acc@5 95.312 (96.727)
Epoch: [14][300/875]	Time 0.306 (0.353)	Data 0.005 (0.011)	Loss 3.6419 (3.7239)	Loss@kd 2.1215 (2.1519)	Acc@1 60.938 (57.792)	Acc@5 96.875 (96.776)
Epoch: [14][400/875]	Time 0.356 (0.350)	Data 0.007 (0.010)	Loss 3.8904 (3.7187)	Loss@kd 2.1818 (2.1526)	Acc@1 48.438 (57.925)	Acc@5 92.188 (96.844)
Epoch: [14][500/875]	Time 0.360 (0.352)	Data 0.008 (0.009)	Loss 3.7400 (3.7119)	Loss@kd 2.2536 (2.1504)	Acc@1 56.250 (58.131)	Acc@5 98.438 (96.828)
Epoch: [14][600/875]	Time 0.349 (0.354)	Data 0.007 (0.009)	Loss 3.7382 (3.7095)	Loss@kd 2.2756 (2.1494)	Acc@1 60.938 (58.221)	Acc@5 96.875 (96.828)
Epoch: [14][700/875]	Time 0.440 (0.355)	Data 0.008 (0.009)	Loss 3.6965 (3.7088)	Loss@kd 2.0664 (2.1493)	Acc@1 64.062 (58.240)	Acc@5 98.438 (96.871)
Epoch: [14][800/875]	Time 0.366 (0.356)	Data 0.005 (0.009)	Loss 3.7465 (3.7080)	Loss@kd 2.1353 (2.1475)	Acc@1 60.938 (58.086)	Acc@5 96.875 (96.848)
 * Acc@1 57.943 Acc@5 96.768
epoch 14, total time 311.94
Test: [0/750]	Time 0.809 (0.809)	Loss 0.8353 (0.8353)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.025 (0.040)	Loss 0.6778 (0.6554)	Acc@1 75.000 (80.941)	Acc@5 96.875 (87.778)
Test: [200/750]	Time 0.050 (0.037)	Loss 1.9957 (0.7531)	Acc@1 15.625 (73.927)	Acc@5 68.750 (90.749)
Test: [300/750]	Time 0.028 (0.036)	Loss 1.4531 (1.0322)	Acc@1 25.000 (59.032)	Acc@5 93.750 (88.767)
Test: [400/750]	Time 0.029 (0.035)	Loss 1.0155 (1.0994)	Acc@1 71.875 (55.408)	Acc@5 84.375 (89.214)
Test: [500/750]	Time 0.022 (0.034)	Loss 0.9101 (1.0823)	Acc@1 65.625 (58.177)	Acc@5 90.625 (88.255)
Test: [600/750]	Time 0.023 (0.034)	Loss 1.0844 (1.0733)	Acc@1 59.375 (59.718)	Acc@5 90.625 (88.540)
Test: [700/750]	Time 0.041 (0.034)	Loss 1.2818 (1.0799)	Acc@1 53.125 (59.495)	Acc@5 84.375 (88.771)
 * Acc@1 59.500 Acc@5 88.608
saving the best model!
==> training...
Epoch: [15][0/875]	Time 1.646 (1.646)	Data 1.290 (1.290)	Loss 3.6006 (3.6006)	Loss@kd 2.1560 (2.1560)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [15][100/875]	Time 0.351 (0.370)	Data 0.010 (0.020)	Loss 3.6594 (3.7010)	Loss@kd 2.1180 (2.1345)	Acc@1 62.500 (57.580)	Acc@5 96.875 (96.736)
Epoch: [15][200/875]	Time 0.354 (0.364)	Data 0.007 (0.013)	Loss 3.5583 (3.6998)	Loss@kd 2.0531 (2.1354)	Acc@1 57.812 (57.540)	Acc@5 98.438 (96.743)
Epoch: [15][300/875]	Time 0.311 (0.353)	Data 0.008 (0.011)	Loss 3.4936 (3.6793)	Loss@kd 2.0885 (2.1307)	Acc@1 67.188 (58.072)	Acc@5 96.875 (96.896)
Epoch: [15][400/875]	Time 0.342 (0.351)	Data 0.007 (0.010)	Loss 3.6520 (3.6762)	Loss@kd 2.1478 (2.1292)	Acc@1 59.375 (58.124)	Acc@5 96.875 (96.949)
Epoch: [15][500/875]	Time 0.360 (0.353)	Data 0.007 (0.009)	Loss 3.5825 (3.6785)	Loss@kd 2.0565 (2.1303)	Acc@1 56.250 (58.168)	Acc@5 96.875 (96.903)
Epoch: [15][600/875]	Time 0.354 (0.354)	Data 0.007 (0.009)	Loss 3.8166 (3.6778)	Loss@kd 2.0680 (2.1298)	Acc@1 50.000 (58.088)	Acc@5 95.312 (96.870)
Epoch: [15][700/875]	Time 0.353 (0.355)	Data 0.007 (0.009)	Loss 3.6738 (3.6805)	Loss@kd 2.1003 (2.1311)	Acc@1 56.250 (58.011)	Acc@5 95.312 (96.888)
Epoch: [15][800/875]	Time 0.366 (0.356)	Data 0.007 (0.009)	Loss 3.7076 (3.6815)	Loss@kd 2.0960 (2.1308)	Acc@1 50.000 (58.017)	Acc@5 98.438 (96.900)
 * Acc@1 58.054 Acc@5 96.882
epoch 15, total time 312.23
Test: [0/750]	Time 0.715 (0.715)	Loss 0.8280 (0.8280)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.045 (0.041)	Loss 0.5600 (0.6282)	Acc@1 81.250 (82.085)	Acc@5 100.000 (88.150)
Test: [200/750]	Time 0.038 (0.037)	Loss 1.8046 (0.6760)	Acc@1 34.375 (77.659)	Acc@5 81.250 (91.620)
Test: [300/750]	Time 0.027 (0.035)	Loss 1.4367 (0.9483)	Acc@1 34.375 (64.265)	Acc@5 93.750 (90.407)
Test: [400/750]	Time 0.029 (0.034)	Loss 0.9478 (1.0443)	Acc@1 78.125 (59.243)	Acc@5 87.500 (89.970)
Test: [500/750]	Time 0.045 (0.034)	Loss 0.8250 (1.0303)	Acc@1 75.000 (61.652)	Acc@5 96.875 (89.116)
Test: [600/750]	Time 0.040 (0.034)	Loss 1.0753 (1.0227)	Acc@1 65.625 (62.776)	Acc@5 90.625 (89.523)
Test: [700/750]	Time 0.026 (0.033)	Loss 1.5649 (1.0498)	Acc@1 37.500 (61.363)	Acc@5 75.000 (89.386)
 * Acc@1 60.575 Acc@5 88.842
saving the best model!
==> training...
Epoch: [16][0/875]	Time 1.674 (1.674)	Data 1.270 (1.270)	Loss 3.5925 (3.5925)	Loss@kd 2.1525 (2.1525)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [16][100/875]	Time 0.363 (0.374)	Data 0.007 (0.020)	Loss 3.5553 (3.6585)	Loss@kd 2.1192 (2.1078)	Acc@1 60.938 (58.277)	Acc@5 100.000 (96.581)
Epoch: [16][200/875]	Time 0.352 (0.368)	Data 0.007 (0.013)	Loss 3.6074 (3.6483)	Loss@kd 2.0747 (2.1129)	Acc@1 56.250 (58.613)	Acc@5 96.875 (96.758)
Epoch: [16][300/875]	Time 0.305 (0.356)	Data 0.007 (0.011)	Loss 3.4670 (3.6589)	Loss@kd 2.0455 (2.1182)	Acc@1 60.938 (58.352)	Acc@5 100.000 (96.870)
Epoch: [16][400/875]	Time 0.353 (0.352)	Data 0.007 (0.010)	Loss 3.6807 (3.6572)	Loss@kd 2.0790 (2.1185)	Acc@1 56.250 (58.432)	Acc@5 96.875 (96.957)
Epoch: [16][500/875]	Time 0.354 (0.353)	Data 0.007 (0.010)	Loss 3.7910 (3.6566)	Loss@kd 2.2125 (2.1171)	Acc@1 54.688 (58.477)	Acc@5 98.438 (97.000)
Epoch: [16][600/875]	Time 0.361 (0.354)	Data 0.007 (0.009)	Loss 3.7201 (3.6581)	Loss@kd 2.0901 (2.1172)	Acc@1 62.500 (58.460)	Acc@5 96.875 (97.000)
Epoch: [16][700/875]	Time 0.346 (0.355)	Data 0.006 (0.009)	Loss 3.7576 (3.6560)	Loss@kd 2.1260 (2.1147)	Acc@1 50.000 (58.470)	Acc@5 95.312 (96.913)
Epoch: [16][800/875]	Time 0.367 (0.355)	Data 0.011 (0.009)	Loss 3.7005 (3.6542)	Loss@kd 2.1963 (2.1131)	Acc@1 62.500 (58.562)	Acc@5 96.875 (96.916)
 * Acc@1 58.605 Acc@5 96.918
epoch 16, total time 311.39
Test: [0/750]	Time 0.794 (0.794)	Loss 0.7149 (0.7149)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.024 (0.038)	Loss 0.7670 (0.5567)	Acc@1 78.125 (82.580)	Acc@5 96.875 (89.604)
Test: [200/750]	Time 0.037 (0.037)	Loss 1.9055 (0.7247)	Acc@1 28.125 (73.274)	Acc@5 75.000 (91.573)
Test: [300/750]	Time 0.025 (0.037)	Loss 1.4753 (0.9962)	Acc@1 18.750 (60.777)	Acc@5 93.750 (90.158)
Test: [400/750]	Time 0.027 (0.036)	Loss 1.0255 (1.0834)	Acc@1 75.000 (55.486)	Acc@5 84.375 (90.142)
Test: [500/750]	Time 0.039 (0.036)	Loss 0.9182 (1.0751)	Acc@1 65.625 (57.909)	Acc@5 90.625 (89.203)
Test: [600/750]	Time 0.032 (0.035)	Loss 0.9421 (1.0662)	Acc@1 68.750 (59.541)	Acc@5 93.750 (89.242)
Test: [700/750]	Time 0.030 (0.035)	Loss 1.4036 (1.0634)	Acc@1 46.875 (60.039)	Acc@5 78.125 (89.377)
 * Acc@1 60.054 Acc@5 89.096
==> training...
Epoch: [17][0/875]	Time 1.762 (1.762)	Data 1.395 (1.395)	Loss 3.4855 (3.4855)	Loss@kd 2.0148 (2.0148)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [17][100/875]	Time 0.365 (0.372)	Data 0.007 (0.021)	Loss 3.7420 (3.6464)	Loss@kd 2.2064 (2.1064)	Acc@1 57.812 (59.344)	Acc@5 98.438 (96.813)
Epoch: [17][200/875]	Time 0.353 (0.365)	Data 0.006 (0.014)	Loss 3.9402 (3.6391)	Loss@kd 2.2289 (2.1013)	Acc@1 60.938 (58.893)	Acc@5 92.188 (96.906)
Epoch: [17][300/875]	Time 0.304 (0.354)	Data 0.007 (0.012)	Loss 3.6754 (3.6390)	Loss@kd 2.1078 (2.1000)	Acc@1 51.562 (58.591)	Acc@5 95.312 (96.808)
Epoch: [17][400/875]	Time 0.360 (0.351)	Data 0.008 (0.011)	Loss 3.4462 (3.6373)	Loss@kd 2.0877 (2.0981)	Acc@1 73.438 (58.565)	Acc@5 98.438 (96.824)
Epoch: [17][500/875]	Time 0.361 (0.352)	Data 0.008 (0.010)	Loss 3.5337 (3.6360)	Loss@kd 2.1097 (2.1004)	Acc@1 65.625 (58.733)	Acc@5 96.875 (96.856)
Epoch: [17][600/875]	Time 0.355 (0.353)	Data 0.007 (0.009)	Loss 3.8257 (3.6310)	Loss@kd 2.0841 (2.1000)	Acc@1 53.125 (58.842)	Acc@5 92.188 (96.906)
Epoch: [17][700/875]	Time 0.357 (0.354)	Data 0.008 (0.009)	Loss 3.5986 (3.6337)	Loss@kd 2.0736 (2.1001)	Acc@1 59.375 (58.831)	Acc@5 96.875 (96.906)
Epoch: [17][800/875]	Time 0.354 (0.354)	Data 0.008 (0.009)	Loss 3.6948 (3.6324)	Loss@kd 2.1150 (2.0989)	Acc@1 54.688 (58.800)	Acc@5 96.875 (96.949)
 * Acc@1 58.932 Acc@5 96.959
epoch 17, total time 310.75
Test: [0/750]	Time 0.757 (0.757)	Loss 0.7170 (0.7170)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.022 (0.039)	Loss 0.6443 (0.5951)	Acc@1 81.250 (81.126)	Acc@5 96.875 (88.985)
Test: [200/750]	Time 0.022 (0.035)	Loss 2.1700 (0.7165)	Acc@1 12.500 (75.155)	Acc@5 75.000 (91.480)
Test: [300/750]	Time 0.039 (0.033)	Loss 2.0065 (1.0722)	Acc@1 15.625 (58.056)	Acc@5 78.125 (88.331)
Test: [400/750]	Time 0.023 (0.032)	Loss 0.7791 (1.2050)	Acc@1 78.125 (50.616)	Acc@5 87.500 (85.809)
Test: [500/750]	Time 0.036 (0.032)	Loss 0.9009 (1.1246)	Acc@1 71.875 (55.445)	Acc@5 93.750 (86.851)
Test: [600/750]	Time 0.022 (0.031)	Loss 1.1940 (1.1169)	Acc@1 62.500 (57.066)	Acc@5 90.625 (87.391)
Test: [700/750]	Time 0.021 (0.031)	Loss 1.2133 (1.1158)	Acc@1 62.500 (57.690)	Acc@5 84.375 (87.852)
 * Acc@1 58.433 Acc@5 87.867
==> training...
Epoch: [18][0/875]	Time 1.585 (1.585)	Data 1.222 (1.222)	Loss 3.7821 (3.7821)	Loss@kd 2.1624 (2.1624)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [18][100/875]	Time 0.340 (0.366)	Data 0.007 (0.019)	Loss 3.6211 (3.6368)	Loss@kd 2.0970 (2.1010)	Acc@1 56.250 (58.354)	Acc@5 95.312 (96.875)
Epoch: [18][200/875]	Time 0.357 (0.362)	Data 0.007 (0.013)	Loss 3.1513 (3.6233)	Loss@kd 1.9973 (2.0935)	Acc@1 73.438 (58.559)	Acc@5 96.875 (96.953)
Epoch: [18][300/875]	Time 0.316 (0.353)	Data 0.008 (0.011)	Loss 3.4488 (3.6113)	Loss@kd 2.1093 (2.0898)	Acc@1 65.625 (59.084)	Acc@5 98.438 (97.057)
Epoch: [18][400/875]	Time 0.349 (0.349)	Data 0.007 (0.010)	Loss 3.6084 (3.6165)	Loss@kd 2.1104 (2.0909)	Acc@1 57.812 (58.915)	Acc@5 98.438 (97.070)
Epoch: [18][500/875]	Time 0.356 (0.350)	Data 0.007 (0.009)	Loss 3.8165 (3.6158)	Loss@kd 2.1072 (2.0920)	Acc@1 46.875 (58.988)	Acc@5 96.875 (97.068)
Epoch: [18][600/875]	Time 0.358 (0.352)	Data 0.007 (0.009)	Loss 3.6222 (3.6132)	Loss@kd 2.2395 (2.0897)	Acc@1 64.062 (58.941)	Acc@5 100.000 (97.106)
Epoch: [18][700/875]	Time 0.449 (0.352)	Data 0.008 (0.009)	Loss 3.4830 (3.6118)	Loss@kd 2.1154 (2.0884)	Acc@1 67.188 (59.050)	Acc@5 98.438 (97.042)
Epoch: [18][800/875]	Time 0.356 (0.353)	Data 0.008 (0.009)	Loss 3.4495 (3.6112)	Loss@kd 2.0111 (2.0883)	Acc@1 60.938 (59.100)	Acc@5 98.438 (97.035)
 * Acc@1 59.027 Acc@5 97.009
epoch 18, total time 309.17
Test: [0/750]	Time 0.836 (0.836)	Loss 0.8351 (0.8351)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.034 (0.041)	Loss 0.5113 (0.6186)	Acc@1 84.375 (82.024)	Acc@5 100.000 (87.933)
Test: [200/750]	Time 0.038 (0.038)	Loss 2.2697 (0.6861)	Acc@1 9.375 (76.493)	Acc@5 59.375 (90.920)
Test: [300/750]	Time 0.034 (0.038)	Loss 1.8527 (1.1050)	Acc@1 15.625 (56.748)	Acc@5 90.625 (85.372)
Test: [400/750]	Time 0.034 (0.037)	Loss 0.4334 (1.2031)	Acc@1 90.625 (51.387)	Acc@5 96.875 (85.404)
Test: [500/750]	Time 0.129 (0.037)	Loss 1.0743 (1.0965)	Acc@1 59.375 (57.579)	Acc@5 93.750 (87.101)
Test: [600/750]	Time 0.039 (0.037)	Loss 0.9559 (1.0926)	Acc@1 68.750 (58.824)	Acc@5 93.750 (87.864)
Test: [700/750]	Time 0.036 (0.036)	Loss 1.6739 (1.1074)	Acc@1 37.500 (58.310)	Acc@5 71.875 (88.013)
 * Acc@1 57.537 Acc@5 87.429
==> training...
Epoch: [19][0/875]	Time 1.620 (1.620)	Data 1.286 (1.286)	Loss 3.4382 (3.4382)	Loss@kd 2.0424 (2.0424)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [19][100/875]	Time 0.360 (0.369)	Data 0.007 (0.020)	Loss 3.7127 (3.6097)	Loss@kd 2.0274 (2.0787)	Acc@1 54.688 (58.834)	Acc@5 95.312 (96.658)
Epoch: [19][200/875]	Time 0.360 (0.362)	Data 0.006 (0.014)	Loss 3.8472 (3.6158)	Loss@kd 2.1901 (2.0848)	Acc@1 57.812 (58.846)	Acc@5 93.750 (96.782)
Epoch: [19][300/875]	Time 0.299 (0.350)	Data 0.005 (0.011)	Loss 3.6506 (3.6048)	Loss@kd 2.0397 (2.0811)	Acc@1 57.812 (59.095)	Acc@5 98.438 (96.875)
Epoch: [19][400/875]	Time 0.354 (0.347)	Data 0.007 (0.010)	Loss 3.5263 (3.5984)	Loss@kd 2.0100 (2.0783)	Acc@1 60.938 (59.317)	Acc@5 95.312 (96.902)
Epoch: [19][500/875]	Time 0.345 (0.348)	Data 0.007 (0.010)	Loss 3.7545 (3.5967)	Loss@kd 2.0227 (2.0765)	Acc@1 57.812 (59.247)	Acc@5 95.312 (96.863)
Epoch: [19][600/875]	Time 0.353 (0.348)	Data 0.007 (0.009)	Loss 3.4678 (3.5947)	Loss@kd 2.0309 (2.0755)	Acc@1 60.938 (59.294)	Acc@5 96.875 (96.930)
Epoch: [19][700/875]	Time 0.348 (0.349)	Data 0.008 (0.009)	Loss 3.5839 (3.5922)	Loss@kd 2.0723 (2.0744)	Acc@1 59.375 (59.217)	Acc@5 95.312 (96.926)
Epoch: [19][800/875]	Time 0.350 (0.350)	Data 0.007 (0.009)	Loss 3.6077 (3.5926)	Loss@kd 2.0546 (2.0748)	Acc@1 50.000 (59.100)	Acc@5 98.438 (96.922)
 * Acc@1 59.138 Acc@5 96.918
epoch 19, total time 306.41
Test: [0/750]	Time 0.790 (0.790)	Loss 0.7881 (0.7881)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.032 (0.043)	Loss 0.5089 (0.6058)	Acc@1 84.375 (82.550)	Acc@5 96.875 (88.150)
Test: [200/750]	Time 0.038 (0.039)	Loss 1.8515 (0.6486)	Acc@1 25.000 (78.840)	Acc@5 78.125 (91.527)
Test: [300/750]	Time 0.023 (0.037)	Loss 1.4800 (0.9285)	Acc@1 31.250 (64.701)	Acc@5 93.750 (90.334)
Test: [400/750]	Time 0.031 (0.035)	Loss 1.1383 (1.0295)	Acc@1 65.625 (58.019)	Acc@5 81.250 (90.321)
Test: [500/750]	Time 0.026 (0.035)	Loss 0.9916 (1.0443)	Acc@1 71.875 (59.232)	Acc@5 90.625 (89.041)
Test: [600/750]	Time 0.026 (0.035)	Loss 1.2357 (1.0605)	Acc@1 53.125 (59.619)	Acc@5 87.500 (88.722)
Test: [700/750]	Time 0.034 (0.034)	Loss 1.1812 (1.0734)	Acc@1 59.375 (59.179)	Acc@5 84.375 (89.002)
 * Acc@1 59.671 Acc@5 89.104
==> training...
Epoch: [20][0/875]	Time 1.807 (1.807)	Data 1.412 (1.412)	Loss 3.3194 (3.3194)	Loss@kd 2.0400 (2.0400)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [20][100/875]	Time 0.352 (0.370)	Data 0.006 (0.021)	Loss 3.4392 (3.5862)	Loss@kd 1.9709 (2.0711)	Acc@1 51.562 (58.880)	Acc@5 98.438 (96.983)
Epoch: [20][200/875]	Time 0.357 (0.363)	Data 0.008 (0.014)	Loss 3.3886 (3.5859)	Loss@kd 1.9819 (2.0658)	Acc@1 62.500 (58.559)	Acc@5 100.000 (96.867)
Epoch: [20][300/875]	Time 0.299 (0.352)	Data 0.005 (0.012)	Loss 3.9230 (3.5790)	Loss@kd 2.2293 (2.0654)	Acc@1 56.250 (59.141)	Acc@5 92.188 (96.937)
Epoch: [20][400/875]	Time 0.349 (0.350)	Data 0.008 (0.011)	Loss 3.4430 (3.5773)	Loss@kd 2.0087 (2.0657)	Acc@1 57.812 (59.320)	Acc@5 96.875 (96.988)
Epoch: [20][500/875]	Time 0.350 (0.351)	Data 0.007 (0.010)	Loss 3.8927 (3.5751)	Loss@kd 2.0858 (2.0653)	Acc@1 59.375 (59.322)	Acc@5 93.750 (97.059)
Epoch: [20][600/875]	Time 0.351 (0.352)	Data 0.008 (0.010)	Loss 3.8784 (3.5753)	Loss@kd 2.0917 (2.0648)	Acc@1 56.250 (59.313)	Acc@5 90.625 (97.028)
Epoch: [20][700/875]	Time 0.353 (0.353)	Data 0.007 (0.009)	Loss 3.5044 (3.5694)	Loss@kd 2.0183 (2.0619)	Acc@1 60.938 (59.357)	Acc@5 96.875 (97.071)
Epoch: [20][800/875]	Time 0.354 (0.353)	Data 0.008 (0.009)	Loss 3.7608 (3.5694)	Loss@kd 2.1843 (2.0605)	Acc@1 53.125 (59.332)	Acc@5 96.875 (97.093)
 * Acc@1 59.345 Acc@5 97.071
epoch 20, total time 309.53
Test: [0/750]	Time 0.729 (0.729)	Loss 0.8018 (0.8018)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.029 (0.035)	Loss 0.6166 (0.5965)	Acc@1 81.250 (81.776)	Acc@5 93.750 (88.366)
Test: [200/750]	Time 0.042 (0.031)	Loss 1.7687 (0.6675)	Acc@1 28.125 (78.343)	Acc@5 87.500 (91.480)
Test: [300/750]	Time 0.027 (0.032)	Loss 1.6749 (0.9418)	Acc@1 18.750 (64.088)	Acc@5 87.500 (90.615)
Test: [400/750]	Time 0.029 (0.032)	Loss 0.6898 (1.0711)	Acc@1 84.375 (56.796)	Acc@5 90.625 (89.534)
Test: [500/750]	Time 0.028 (0.032)	Loss 0.9070 (1.0265)	Acc@1 65.625 (60.279)	Acc@5 96.875 (89.702)
Test: [600/750]	Time 0.038 (0.032)	Loss 1.3251 (1.0440)	Acc@1 53.125 (60.706)	Acc@5 84.375 (89.283)
Test: [700/750]	Time 0.039 (0.032)	Loss 1.1538 (1.0660)	Acc@1 62.500 (59.955)	Acc@5 84.375 (89.114)
 * Acc@1 60.412 Acc@5 89.162
==> training...
Epoch: [21][0/875]	Time 1.640 (1.640)	Data 1.261 (1.261)	Loss 3.4121 (3.4121)	Loss@kd 1.9807 (1.9807)	Acc@1 64.062 (64.062)	Acc@5 98.438 (98.438)
Epoch: [21][100/875]	Time 0.363 (0.368)	Data 0.008 (0.020)	Loss 3.2977 (3.5754)	Loss@kd 1.9823 (2.0672)	Acc@1 65.625 (60.087)	Acc@5 98.438 (96.627)
Epoch: [21][200/875]	Time 0.353 (0.361)	Data 0.006 (0.013)	Loss 3.5567 (3.5621)	Loss@kd 2.0427 (2.0574)	Acc@1 64.062 (60.168)	Acc@5 98.438 (96.844)
Epoch: [21][300/875]	Time 0.314 (0.349)	Data 0.008 (0.011)	Loss 3.4524 (3.5594)	Loss@kd 1.9771 (2.0596)	Acc@1 56.250 (60.086)	Acc@5 98.438 (97.015)
Epoch: [21][400/875]	Time 0.354 (0.347)	Data 0.008 (0.010)	Loss 3.6529 (3.5570)	Loss@kd 2.1225 (2.0582)	Acc@1 62.500 (59.967)	Acc@5 96.875 (97.078)
Epoch: [21][500/875]	Time 0.354 (0.348)	Data 0.010 (0.010)	Loss 3.3799 (3.5548)	Loss@kd 2.0886 (2.0579)	Acc@1 70.312 (60.036)	Acc@5 100.000 (97.149)
Epoch: [21][600/875]	Time 0.354 (0.349)	Data 0.008 (0.009)	Loss 3.5446 (3.5560)	Loss@kd 2.0256 (2.0561)	Acc@1 67.188 (59.838)	Acc@5 96.875 (97.138)
Epoch: [21][700/875]	Time 0.334 (0.350)	Data 0.007 (0.009)	Loss 3.4965 (3.5541)	Loss@kd 1.9716 (2.0537)	Acc@1 57.812 (59.812)	Acc@5 96.875 (97.134)
Epoch: [21][800/875]	Time 0.353 (0.351)	Data 0.008 (0.009)	Loss 3.3102 (3.5543)	Loss@kd 1.9612 (2.0527)	Acc@1 65.625 (59.683)	Acc@5 98.438 (97.109)
 * Acc@1 59.700 Acc@5 97.098
epoch 21, total time 307.39
Test: [0/750]	Time 0.686 (0.686)	Loss 0.7973 (0.7973)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.047 (0.040)	Loss 0.6427 (0.6234)	Acc@1 81.250 (80.600)	Acc@5 96.875 (87.840)
Test: [200/750]	Time 0.042 (0.037)	Loss 1.8825 (0.7102)	Acc@1 31.250 (74.705)	Acc@5 81.250 (91.091)
Test: [300/750]	Time 0.033 (0.037)	Loss 1.2227 (0.9654)	Acc@1 46.875 (61.337)	Acc@5 96.875 (90.407)
Test: [400/750]	Time 0.044 (0.035)	Loss 1.1763 (1.0286)	Acc@1 65.625 (58.050)	Acc@5 84.375 (90.804)
Test: [500/750]	Time 0.048 (0.034)	Loss 1.0124 (1.0566)	Acc@1 62.500 (58.913)	Acc@5 87.500 (89.116)
Test: [600/750]	Time 0.054 (0.033)	Loss 1.0228 (1.0653)	Acc@1 62.500 (59.994)	Acc@5 90.625 (88.758)
Test: [700/750]	Time 0.026 (0.032)	Loss 1.3354 (1.0673)	Acc@1 43.750 (59.803)	Acc@5 81.250 (89.176)
 * Acc@1 60.021 Acc@5 89.213
==> training...
Epoch: [22][0/875]	Time 1.700 (1.700)	Data 1.319 (1.319)	Loss 3.6477 (3.6477)	Loss@kd 2.0538 (2.0538)	Acc@1 46.875 (46.875)	Acc@5 98.438 (98.438)
Epoch: [22][100/875]	Time 0.351 (0.368)	Data 0.007 (0.020)	Loss 3.6443 (3.5651)	Loss@kd 2.0734 (2.0510)	Acc@1 59.375 (59.189)	Acc@5 92.188 (97.123)
Epoch: [22][200/875]	Time 0.358 (0.363)	Data 0.008 (0.014)	Loss 3.3091 (3.5513)	Loss@kd 1.9932 (2.0464)	Acc@1 68.750 (59.764)	Acc@5 96.875 (97.062)
Epoch: [22][300/875]	Time 0.311 (0.352)	Data 0.008 (0.012)	Loss 3.5205 (3.5465)	Loss@kd 2.1032 (2.0457)	Acc@1 62.500 (59.712)	Acc@5 98.438 (97.026)
Epoch: [22][400/875]	Time 0.353 (0.350)	Data 0.008 (0.010)	Loss 3.3683 (3.5471)	Loss@kd 2.0207 (2.0442)	Acc@1 64.062 (59.718)	Acc@5 98.438 (96.988)
Epoch: [22][500/875]	Time 0.350 (0.351)	Data 0.008 (0.010)	Loss 3.5526 (3.5415)	Loss@kd 2.0254 (2.0426)	Acc@1 62.500 (59.868)	Acc@5 95.312 (96.975)
Epoch: [22][600/875]	Time 0.357 (0.352)	Data 0.007 (0.009)	Loss 3.5611 (3.5391)	Loss@kd 2.0109 (2.0416)	Acc@1 62.500 (59.838)	Acc@5 95.312 (96.997)
Epoch: [22][700/875]	Time 0.445 (0.353)	Data 0.006 (0.009)	Loss 3.5878 (3.5327)	Loss@kd 2.0697 (2.0390)	Acc@1 53.125 (59.937)	Acc@5 98.438 (97.047)
Epoch: [22][800/875]	Time 0.360 (0.353)	Data 0.006 (0.009)	Loss 3.4881 (3.5342)	Loss@kd 2.0140 (2.0404)	Acc@1 62.500 (59.945)	Acc@5 98.438 (97.058)
 * Acc@1 59.880 Acc@5 97.052
epoch 22, total time 309.75
Test: [0/750]	Time 0.663 (0.663)	Loss 0.7909 (0.7909)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.021 (0.035)	Loss 0.6591 (0.6259)	Acc@1 78.125 (81.157)	Acc@5 100.000 (87.840)
Test: [200/750]	Time 0.028 (0.031)	Loss 1.6904 (0.7052)	Acc@1 34.375 (75.902)	Acc@5 84.375 (90.780)
Test: [300/750]	Time 0.036 (0.031)	Loss 1.4637 (0.9534)	Acc@1 15.625 (63.621)	Acc@5 96.875 (90.542)
Test: [400/750]	Time 0.022 (0.030)	Loss 0.5937 (1.0420)	Acc@1 84.375 (58.011)	Acc@5 93.750 (90.415)
Test: [500/750]	Time 0.026 (0.030)	Loss 1.0265 (0.9902)	Acc@1 62.500 (61.920)	Acc@5 96.875 (90.613)
Test: [600/750]	Time 0.020 (0.029)	Loss 1.0842 (1.0120)	Acc@1 68.750 (62.256)	Acc@5 90.625 (90.391)
Test: [700/750]	Time 0.023 (0.029)	Loss 1.6351 (1.0433)	Acc@1 40.625 (61.207)	Acc@5 75.000 (89.961)
 * Acc@1 60.537 Acc@5 89.292
==> training...
Epoch: [23][0/875]	Time 1.641 (1.641)	Data 1.270 (1.270)	Loss 3.6020 (3.6020)	Loss@kd 2.1645 (2.1645)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [23][100/875]	Time 0.353 (0.370)	Data 0.007 (0.020)	Loss 3.2733 (3.5161)	Loss@kd 1.9881 (2.0361)	Acc@1 60.938 (60.272)	Acc@5 98.438 (97.123)
Epoch: [23][200/875]	Time 0.354 (0.362)	Data 0.007 (0.013)	Loss 3.6075 (3.5114)	Loss@kd 2.0134 (2.0293)	Acc@1 59.375 (59.880)	Acc@5 93.750 (97.225)
Epoch: [23][300/875]	Time 0.321 (0.353)	Data 0.007 (0.011)	Loss 3.4066 (3.5166)	Loss@kd 1.9613 (2.0306)	Acc@1 67.188 (60.034)	Acc@5 95.312 (97.181)
Epoch: [23][400/875]	Time 0.357 (0.347)	Data 0.005 (0.010)	Loss 3.3738 (3.5135)	Loss@kd 1.9735 (2.0298)	Acc@1 57.812 (59.948)	Acc@5 98.438 (97.253)
Epoch: [23][500/875]	Time 0.353 (0.349)	Data 0.007 (0.009)	Loss 3.6024 (3.5205)	Loss@kd 2.0721 (2.0329)	Acc@1 54.688 (59.886)	Acc@5 96.875 (97.140)
Epoch: [23][600/875]	Time 0.352 (0.350)	Data 0.007 (0.009)	Loss 3.3660 (3.5206)	Loss@kd 2.0086 (2.0324)	Acc@1 65.625 (59.918)	Acc@5 98.438 (97.158)
Epoch: [23][700/875]	Time 0.351 (0.351)	Data 0.006 (0.009)	Loss 3.3903 (3.5174)	Loss@kd 2.0250 (2.0307)	Acc@1 68.750 (59.890)	Acc@5 98.438 (97.154)
Epoch: [23][800/875]	Time 0.356 (0.352)	Data 0.006 (0.008)	Loss 3.4640 (3.5193)	Loss@kd 1.9654 (2.0311)	Acc@1 57.812 (59.878)	Acc@5 95.312 (97.113)
 * Acc@1 59.955 Acc@5 97.116
epoch 23, total time 308.55
Test: [0/750]	Time 0.784 (0.784)	Loss 0.6683 (0.6683)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.035 (0.041)	Loss 0.8072 (0.5396)	Acc@1 71.875 (81.931)	Acc@5 93.750 (89.851)
Test: [200/750]	Time 0.023 (0.037)	Loss 1.7995 (0.7623)	Acc@1 40.625 (73.103)	Acc@5 81.250 (90.096)
Test: [300/750]	Time 0.041 (0.036)	Loss 1.6715 (0.9938)	Acc@1 15.625 (62.178)	Acc@5 84.375 (89.691)
Test: [400/750]	Time 0.038 (0.036)	Loss 0.8697 (1.0967)	Acc@1 81.250 (55.790)	Acc@5 84.375 (88.856)
Test: [500/750]	Time 0.029 (0.035)	Loss 0.8102 (1.0530)	Acc@1 78.125 (59.331)	Acc@5 93.750 (88.804)
Test: [600/750]	Time 0.021 (0.035)	Loss 1.2061 (1.0506)	Acc@1 62.500 (60.597)	Acc@5 84.375 (88.857)
Test: [700/750]	Time 0.030 (0.035)	Loss 1.4062 (1.0667)	Acc@1 50.000 (60.262)	Acc@5 81.250 (88.922)
 * Acc@1 60.158 Acc@5 88.804
==> training...
Epoch: [24][0/875]	Time 1.715 (1.715)	Data 1.356 (1.356)	Loss 3.3652 (3.3652)	Loss@kd 1.9707 (1.9707)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [24][100/875]	Time 0.353 (0.370)	Data 0.007 (0.020)	Loss 3.3773 (3.5075)	Loss@kd 2.0475 (2.0234)	Acc@1 64.062 (59.824)	Acc@5 96.875 (97.092)
Epoch: [24][200/875]	Time 0.349 (0.362)	Data 0.006 (0.013)	Loss 3.3926 (3.5156)	Loss@kd 1.9951 (2.0257)	Acc@1 64.062 (59.437)	Acc@5 96.875 (97.178)
Epoch: [24][300/875]	Time 0.311 (0.353)	Data 0.007 (0.011)	Loss 3.6810 (3.5144)	Loss@kd 2.0696 (2.0228)	Acc@1 51.562 (59.167)	Acc@5 93.750 (97.150)
Epoch: [24][400/875]	Time 0.349 (0.350)	Data 0.008 (0.010)	Loss 3.5142 (3.5123)	Loss@kd 2.0062 (2.0232)	Acc@1 57.812 (59.589)	Acc@5 98.438 (97.093)
Epoch: [24][500/875]	Time 0.357 (0.351)	Data 0.007 (0.010)	Loss 3.6812 (3.5118)	Loss@kd 2.0649 (2.0221)	Acc@1 56.250 (59.587)	Acc@5 93.750 (97.065)
Epoch: [24][600/875]	Time 0.355 (0.352)	Data 0.008 (0.009)	Loss 3.3696 (3.5124)	Loss@kd 2.0239 (2.0226)	Acc@1 57.812 (59.710)	Acc@5 96.875 (97.031)
Epoch: [24][700/875]	Time 0.350 (0.353)	Data 0.008 (0.009)	Loss 3.4659 (3.5101)	Loss@kd 2.0914 (2.0227)	Acc@1 67.188 (59.807)	Acc@5 96.875 (97.082)
Epoch: [24][800/875]	Time 0.350 (0.353)	Data 0.007 (0.009)	Loss 3.4962 (3.5145)	Loss@kd 2.0389 (2.0252)	Acc@1 64.062 (59.814)	Acc@5 98.438 (97.082)
 * Acc@1 59.902 Acc@5 97.111
epoch 24, total time 309.62
Test: [0/750]	Time 0.763 (0.763)	Loss 0.8770 (0.8770)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.038 (0.038)	Loss 0.4576 (0.6427)	Acc@1 84.375 (81.714)	Acc@5 100.000 (87.809)
Test: [200/750]	Time 0.024 (0.033)	Loss 1.9639 (0.6226)	Acc@1 21.875 (79.928)	Acc@5 71.875 (91.604)
Test: [300/750]	Time 0.033 (0.033)	Loss 1.4151 (0.9447)	Acc@1 37.500 (63.777)	Acc@5 93.750 (89.452)
Test: [400/750]	Time 0.023 (0.033)	Loss 0.7799 (1.0221)	Acc@1 87.500 (59.398)	Acc@5 87.500 (90.220)
Test: [500/750]	Time 0.031 (0.032)	Loss 1.0222 (1.0049)	Acc@1 56.250 (62.007)	Acc@5 90.625 (89.689)
Test: [600/750]	Time 0.030 (0.032)	Loss 1.0033 (1.0236)	Acc@1 65.625 (62.110)	Acc@5 90.625 (89.533)
Test: [700/750]	Time 0.025 (0.032)	Loss 1.3292 (1.0334)	Acc@1 53.125 (61.555)	Acc@5 78.125 (89.876)
 * Acc@1 61.533 Acc@5 89.713
saving the best model!
==> training...
Epoch: [25][0/875]	Time 1.804 (1.804)	Data 1.394 (1.394)	Loss 3.4352 (3.4352)	Loss@kd 1.9398 (1.9398)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [25][100/875]	Time 0.347 (0.370)	Data 0.005 (0.021)	Loss 3.2224 (3.4949)	Loss@kd 1.9502 (2.0202)	Acc@1 59.375 (60.798)	Acc@5 98.438 (96.983)
Epoch: [25][200/875]	Time 0.360 (0.364)	Data 0.008 (0.014)	Loss 3.3856 (3.4979)	Loss@kd 2.0084 (2.0236)	Acc@1 68.750 (60.588)	Acc@5 98.438 (97.287)
Epoch: [25][300/875]	Time 0.308 (0.354)	Data 0.007 (0.012)	Loss 3.4143 (3.4923)	Loss@kd 1.9620 (2.0166)	Acc@1 60.938 (60.341)	Acc@5 98.438 (97.259)
Epoch: [25][400/875]	Time 0.352 (0.352)	Data 0.008 (0.011)	Loss 3.3672 (3.4927)	Loss@kd 1.9777 (2.0161)	Acc@1 62.500 (60.076)	Acc@5 96.875 (97.226)
Epoch: [25][500/875]	Time 0.356 (0.352)	Data 0.008 (0.010)	Loss 3.5720 (3.4876)	Loss@kd 2.0909 (2.0140)	Acc@1 59.375 (60.314)	Acc@5 95.312 (97.252)
Epoch: [25][600/875]	Time 0.353 (0.353)	Data 0.005 (0.009)	Loss 3.5447 (3.4908)	Loss@kd 2.0703 (2.0151)	Acc@1 64.062 (60.225)	Acc@5 96.875 (97.247)
Epoch: [25][700/875]	Time 0.354 (0.354)	Data 0.006 (0.009)	Loss 3.7889 (3.4877)	Loss@kd 2.0752 (2.0147)	Acc@1 56.250 (60.385)	Acc@5 96.875 (97.245)
Epoch: [25][800/875]	Time 0.352 (0.354)	Data 0.008 (0.009)	Loss 3.6149 (3.4903)	Loss@kd 2.0750 (2.0135)	Acc@1 56.250 (60.136)	Acc@5 96.875 (97.193)
 * Acc@1 60.095 Acc@5 97.202
epoch 25, total time 310.28
Test: [0/750]	Time 0.706 (0.706)	Loss 0.8257 (0.8257)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.026 (0.039)	Loss 0.5990 (0.6029)	Acc@1 78.125 (80.972)	Acc@5 93.750 (87.964)
Test: [200/750]	Time 0.048 (0.038)	Loss 1.8337 (0.6647)	Acc@1 25.000 (76.290)	Acc@5 84.375 (91.542)
Test: [300/750]	Time 0.029 (0.037)	Loss 1.2770 (0.9287)	Acc@1 50.000 (63.320)	Acc@5 100.000 (90.999)
Test: [400/750]	Time 0.052 (0.036)	Loss 0.8793 (1.0049)	Acc@1 75.000 (59.204)	Acc@5 87.500 (91.311)
Test: [500/750]	Time 0.022 (0.036)	Loss 0.9182 (0.9997)	Acc@1 71.875 (61.215)	Acc@5 90.625 (90.226)
Test: [600/750]	Time 0.026 (0.035)	Loss 1.0179 (1.0041)	Acc@1 65.625 (62.276)	Acc@5 90.625 (90.199)
Test: [700/750]	Time 0.031 (0.035)	Loss 1.3726 (1.0150)	Acc@1 46.875 (61.871)	Acc@5 84.375 (90.215)
 * Acc@1 61.871 Acc@5 89.954
saving the best model!
==> training...
Epoch: [26][0/875]	Time 2.196 (2.196)	Data 1.828 (1.828)	Loss 3.3280 (3.3280)	Loss@kd 1.9446 (1.9446)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [26][100/875]	Time 0.352 (0.376)	Data 0.008 (0.025)	Loss 3.3544 (3.4543)	Loss@kd 1.9444 (1.9982)	Acc@1 65.625 (61.340)	Acc@5 96.875 (97.200)
Epoch: [26][200/875]	Time 0.354 (0.368)	Data 0.007 (0.016)	Loss 3.5466 (3.4826)	Loss@kd 2.0353 (2.0095)	Acc@1 64.062 (60.634)	Acc@5 98.438 (97.147)
Epoch: [26][300/875]	Time 0.309 (0.354)	Data 0.006 (0.013)	Loss 3.6715 (3.4801)	Loss@kd 2.0707 (2.0074)	Acc@1 51.562 (60.138)	Acc@5 100.000 (97.155)
Epoch: [26][400/875]	Time 0.384 (0.354)	Data 0.008 (0.011)	Loss 3.4612 (3.4781)	Loss@kd 1.9391 (2.0064)	Acc@1 62.500 (60.147)	Acc@5 96.875 (97.195)
Epoch: [26][500/875]	Time 0.362 (0.354)	Data 0.007 (0.011)	Loss 3.4673 (3.4830)	Loss@kd 2.0169 (2.0073)	Acc@1 64.062 (60.080)	Acc@5 93.750 (97.131)
Epoch: [26][600/875]	Time 0.359 (0.355)	Data 0.008 (0.010)	Loss 3.4686 (3.4798)	Loss@kd 1.9964 (2.0056)	Acc@1 67.188 (60.210)	Acc@5 98.438 (97.140)
Epoch: [26][700/875]	Time 0.437 (0.356)	Data 0.007 (0.010)	Loss 3.5125 (3.4757)	Loss@kd 1.9958 (2.0044)	Acc@1 56.250 (60.331)	Acc@5 98.438 (97.171)
Epoch: [26][800/875]	Time 0.350 (0.356)	Data 0.010 (0.009)	Loss 3.5862 (3.4758)	Loss@kd 2.0298 (2.0042)	Acc@1 53.125 (60.346)	Acc@5 98.438 (97.189)
 * Acc@1 60.286 Acc@5 97.175
epoch 26, total time 311.68
Test: [0/750]	Time 0.698 (0.698)	Loss 0.7675 (0.7675)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.047 (0.040)	Loss 0.6311 (0.5937)	Acc@1 78.125 (82.797)	Acc@5 100.000 (88.676)
Test: [200/750]	Time 0.038 (0.038)	Loss 1.9765 (0.6780)	Acc@1 21.875 (77.052)	Acc@5 81.250 (91.542)
Test: [300/750]	Time 0.031 (0.037)	Loss 1.5648 (0.9969)	Acc@1 25.000 (61.836)	Acc@5 87.500 (89.618)
Test: [400/750]	Time 0.022 (0.036)	Loss 0.6071 (1.0764)	Acc@1 84.375 (56.858)	Acc@5 90.625 (89.394)
Test: [500/750]	Time 0.033 (0.036)	Loss 0.9191 (1.0100)	Acc@1 68.750 (61.290)	Acc@5 93.750 (89.870)
Test: [600/750]	Time 0.028 (0.036)	Loss 0.9322 (1.0137)	Acc@1 75.000 (62.354)	Acc@5 90.625 (90.017)
Test: [700/750]	Time 0.036 (0.035)	Loss 1.4856 (1.0293)	Acc@1 43.750 (61.925)	Acc@5 75.000 (89.965)
 * Acc@1 61.600 Acc@5 89.592
==> training...
Epoch: [27][0/875]	Time 1.656 (1.656)	Data 1.287 (1.287)	Loss 3.4411 (3.4411)	Loss@kd 2.0234 (2.0234)	Acc@1 57.812 (57.812)	Acc@5 95.312 (95.312)
Epoch: [27][100/875]	Time 0.343 (0.369)	Data 0.008 (0.020)	Loss 3.3788 (3.4840)	Loss@kd 1.9398 (2.0069)	Acc@1 54.688 (59.623)	Acc@5 100.000 (97.649)
Epoch: [27][200/875]	Time 0.352 (0.362)	Data 0.007 (0.013)	Loss 3.0803 (3.4724)	Loss@kd 1.9626 (1.9987)	Acc@1 82.812 (59.989)	Acc@5 98.438 (97.536)
Epoch: [27][300/875]	Time 0.301 (0.347)	Data 0.005 (0.011)	Loss 3.5064 (3.4731)	Loss@kd 1.9687 (1.9979)	Acc@1 62.500 (60.226)	Acc@5 93.750 (97.301)
Epoch: [27][400/875]	Time 0.349 (0.348)	Data 0.007 (0.010)	Loss 3.4489 (3.4691)	Loss@kd 1.9792 (1.9972)	Acc@1 59.375 (60.248)	Acc@5 96.875 (97.284)
Epoch: [27][500/875]	Time 0.358 (0.349)	Data 0.007 (0.010)	Loss 3.3653 (3.4654)	Loss@kd 1.9788 (1.9964)	Acc@1 67.188 (60.301)	Acc@5 98.438 (97.271)
Epoch: [27][600/875]	Time 0.354 (0.351)	Data 0.005 (0.009)	Loss 3.5801 (3.4624)	Loss@kd 2.0382 (1.9942)	Acc@1 56.250 (60.280)	Acc@5 100.000 (97.312)
Epoch: [27][700/875]	Time 0.351 (0.352)	Data 0.007 (0.009)	Loss 3.5317 (3.4616)	Loss@kd 1.9678 (1.9936)	Acc@1 53.125 (60.380)	Acc@5 98.438 (97.292)
Epoch: [27][800/875]	Time 0.349 (0.352)	Data 0.007 (0.009)	Loss 3.6290 (3.4638)	Loss@kd 2.0825 (1.9946)	Acc@1 54.688 (60.276)	Acc@5 96.875 (97.290)
 * Acc@1 60.312 Acc@5 97.264
epoch 27, total time 308.74
Test: [0/750]	Time 0.697 (0.697)	Loss 0.7494 (0.7494)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.020 (0.039)	Loss 0.4885 (0.5440)	Acc@1 84.375 (82.921)	Acc@5 100.000 (89.325)
Test: [200/750]	Time 0.025 (0.034)	Loss 1.8547 (0.6069)	Acc@1 18.750 (78.654)	Acc@5 78.125 (92.491)
Test: [300/750]	Time 0.026 (0.033)	Loss 1.5714 (0.9295)	Acc@1 31.250 (63.362)	Acc@5 90.625 (90.542)
Test: [400/750]	Time 0.036 (0.032)	Loss 1.0354 (1.0689)	Acc@1 71.875 (56.242)	Acc@5 87.500 (89.659)
Test: [500/750]	Time 0.035 (0.031)	Loss 0.8325 (1.0724)	Acc@1 68.750 (58.040)	Acc@5 90.625 (88.723)
Test: [600/750]	Time 0.023 (0.031)	Loss 0.8572 (1.0559)	Acc@1 75.000 (59.853)	Acc@5 93.750 (89.138)
Test: [700/750]	Time 0.028 (0.031)	Loss 1.1346 (1.0425)	Acc@1 56.250 (60.588)	Acc@5 84.375 (89.738)
 * Acc@1 60.987 Acc@5 89.700
==> training...
Epoch: [28][0/875]	Time 1.669 (1.669)	Data 1.330 (1.330)	Loss 3.3816 (3.3816)	Loss@kd 1.9785 (1.9785)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [28][100/875]	Time 0.349 (0.367)	Data 0.007 (0.021)	Loss 3.3086 (3.4607)	Loss@kd 1.9714 (1.9891)	Acc@1 60.938 (60.303)	Acc@5 96.875 (97.246)
Epoch: [28][200/875]	Time 0.357 (0.362)	Data 0.008 (0.014)	Loss 3.7249 (3.4471)	Loss@kd 2.0455 (1.9888)	Acc@1 56.250 (61.031)	Acc@5 92.188 (97.349)
Epoch: [28][300/875]	Time 0.310 (0.349)	Data 0.006 (0.012)	Loss 3.6382 (3.4526)	Loss@kd 2.0213 (1.9904)	Acc@1 57.812 (60.553)	Acc@5 93.750 (97.238)
Epoch: [28][400/875]	Time 0.317 (0.350)	Data 0.006 (0.011)	Loss 3.5255 (3.4542)	Loss@kd 1.9792 (1.9892)	Acc@1 53.125 (60.447)	Acc@5 98.438 (97.206)
Epoch: [28][500/875]	Time 0.352 (0.351)	Data 0.008 (0.010)	Loss 3.0367 (3.4527)	Loss@kd 1.8535 (1.9883)	Acc@1 75.000 (60.361)	Acc@5 100.000 (97.243)
Epoch: [28][600/875]	Time 0.352 (0.352)	Data 0.007 (0.009)	Loss 3.4659 (3.4554)	Loss@kd 1.9774 (1.9889)	Acc@1 57.812 (60.225)	Acc@5 95.312 (97.249)
Epoch: [28][700/875]	Time 0.354 (0.352)	Data 0.008 (0.009)	Loss 3.5119 (3.4560)	Loss@kd 1.9295 (1.9881)	Acc@1 48.438 (60.113)	Acc@5 95.312 (97.249)
Epoch: [28][800/875]	Time 0.355 (0.353)	Data 0.007 (0.009)	Loss 3.4004 (3.4552)	Loss@kd 2.0665 (1.9882)	Acc@1 67.188 (60.138)	Acc@5 98.438 (97.224)
 * Acc@1 60.261 Acc@5 97.225
epoch 28, total time 309.58
Test: [0/750]	Time 0.875 (0.875)	Loss 0.7581 (0.7581)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.031 (0.041)	Loss 0.7737 (0.5522)	Acc@1 71.875 (82.457)	Acc@5 100.000 (89.821)
Test: [200/750]	Time 0.027 (0.037)	Loss 2.0401 (0.7104)	Acc@1 25.000 (73.290)	Acc@5 81.250 (92.537)
Test: [300/750]	Time 0.046 (0.037)	Loss 1.6504 (1.0249)	Acc@1 31.250 (59.718)	Acc@5 87.500 (90.604)
Test: [400/750]	Time 0.033 (0.036)	Loss 0.8540 (1.1247)	Acc@1 71.875 (54.278)	Acc@5 87.500 (89.853)
Test: [500/750]	Time 0.033 (0.036)	Loss 0.9137 (1.0825)	Acc@1 65.625 (57.828)	Acc@5 93.750 (89.265)
Test: [600/750]	Time 0.031 (0.036)	Loss 0.7073 (1.0560)	Acc@1 81.250 (60.030)	Acc@5 96.875 (89.731)
Test: [700/750]	Time 0.025 (0.035)	Loss 1.7332 (1.0512)	Acc@1 40.625 (60.931)	Acc@5 71.875 (89.658)
 * Acc@1 60.483 Acc@5 88.975
==> training...
Epoch: [29][0/875]	Time 1.705 (1.705)	Data 1.335 (1.335)	Loss 3.3797 (3.3797)	Loss@kd 1.9731 (1.9731)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [29][100/875]	Time 0.354 (0.370)	Data 0.007 (0.020)	Loss 3.3686 (3.4531)	Loss@kd 1.9302 (1.9846)	Acc@1 53.125 (60.149)	Acc@5 98.438 (97.525)
Epoch: [29][200/875]	Time 0.353 (0.363)	Data 0.007 (0.014)	Loss 3.7820 (3.4394)	Loss@kd 2.0429 (1.9800)	Acc@1 51.562 (60.331)	Acc@5 95.312 (97.466)
Epoch: [29][300/875]	Time 0.330 (0.348)	Data 0.006 (0.011)	Loss 3.4928 (3.4449)	Loss@kd 1.9569 (1.9794)	Acc@1 56.250 (60.143)	Acc@5 100.000 (97.306)
Epoch: [29][400/875]	Time 0.345 (0.350)	Data 0.007 (0.010)	Loss 3.3276 (3.4476)	Loss@kd 2.0222 (1.9778)	Acc@1 64.062 (59.971)	Acc@5 100.000 (97.202)
Epoch: [29][500/875]	Time 0.355 (0.351)	Data 0.008 (0.010)	Loss 3.4912 (3.4476)	Loss@kd 1.9200 (1.9793)	Acc@1 57.812 (60.139)	Acc@5 96.875 (97.168)
Epoch: [29][600/875]	Time 0.348 (0.351)	Data 0.008 (0.009)	Loss 3.6555 (3.4532)	Loss@kd 2.0943 (1.9844)	Acc@1 59.375 (60.376)	Acc@5 98.438 (97.156)
Epoch: [29][700/875]	Time 0.358 (0.351)	Data 0.007 (0.009)	Loss 3.3746 (3.4482)	Loss@kd 1.9303 (1.9833)	Acc@1 65.625 (60.507)	Acc@5 93.750 (97.200)
Epoch: [29][800/875]	Time 0.352 (0.352)	Data 0.007 (0.009)	Loss 3.2810 (3.4456)	Loss@kd 1.9549 (1.9826)	Acc@1 70.312 (60.621)	Acc@5 98.438 (97.197)
 * Acc@1 60.677 Acc@5 97.209
epoch 29, total time 308.16
Test: [0/750]	Time 0.699 (0.699)	Loss 0.9354 (0.9354)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.048 (0.038)	Loss 0.4833 (0.6895)	Acc@1 87.500 (81.157)	Acc@5 96.875 (86.665)
Test: [200/750]	Time 0.029 (0.035)	Loss 1.7522 (0.6580)	Acc@1 31.250 (78.731)	Acc@5 81.250 (91.527)
Test: [300/750]	Time 0.025 (0.033)	Loss 1.2799 (0.9010)	Acc@1 43.750 (66.269)	Acc@5 96.875 (91.445)
Test: [400/750]	Time 0.039 (0.032)	Loss 0.8085 (0.9636)	Acc@1 78.125 (62.742)	Acc@5 87.500 (92.036)
Test: [500/750]	Time 0.033 (0.032)	Loss 1.1921 (0.9772)	Acc@1 56.250 (63.891)	Acc@5 90.625 (90.924)
Test: [600/750]	Time 0.021 (0.031)	Loss 0.8767 (1.0089)	Acc@1 68.750 (63.218)	Acc@5 90.625 (90.365)
Test: [700/750]	Time 0.020 (0.031)	Loss 1.5542 (1.0213)	Acc@1 40.625 (62.496)	Acc@5 78.125 (90.380)
 * Acc@1 61.875 Acc@5 89.821
saving the best model!
==> training...
Epoch: [30][0/875]	Time 1.630 (1.630)	Data 1.262 (1.262)	Loss 3.4107 (3.4107)	Loss@kd 1.9417 (1.9417)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [30][100/875]	Time 0.351 (0.367)	Data 0.007 (0.020)	Loss 3.3344 (3.4382)	Loss@kd 1.9554 (1.9781)	Acc@1 60.938 (60.566)	Acc@5 96.875 (97.246)
Epoch: [30][200/875]	Time 0.363 (0.362)	Data 0.008 (0.013)	Loss 3.6790 (3.4360)	Loss@kd 1.9676 (1.9803)	Acc@1 50.000 (60.868)	Acc@5 98.438 (97.396)
Epoch: [30][300/875]	Time 0.287 (0.347)	Data 0.004 (0.011)	Loss 3.1768 (3.4274)	Loss@kd 2.0107 (1.9766)	Acc@1 73.438 (60.787)	Acc@5 100.000 (97.436)
Epoch: [30][400/875]	Time 0.355 (0.349)	Data 0.007 (0.010)	Loss 3.4878 (3.4313)	Loss@kd 1.9517 (1.9761)	Acc@1 54.688 (60.583)	Acc@5 92.188 (97.335)
Epoch: [30][500/875]	Time 0.351 (0.351)	Data 0.008 (0.010)	Loss 3.3687 (3.4273)	Loss@kd 1.8986 (1.9753)	Acc@1 62.500 (60.729)	Acc@5 98.438 (97.374)
Epoch: [30][600/875]	Time 0.354 (0.352)	Data 0.007 (0.009)	Loss 3.4172 (3.4289)	Loss@kd 2.0094 (1.9762)	Acc@1 60.938 (60.639)	Acc@5 98.438 (97.283)
Epoch: [30][700/875]	Time 0.438 (0.353)	Data 0.007 (0.009)	Loss 3.0449 (3.4283)	Loss@kd 1.8573 (1.9736)	Acc@1 67.188 (60.592)	Acc@5 95.312 (97.234)
Epoch: [30][800/875]	Time 0.356 (0.353)	Data 0.008 (0.009)	Loss 3.6345 (3.4301)	Loss@kd 1.9723 (1.9745)	Acc@1 56.250 (60.577)	Acc@5 96.875 (97.265)
 * Acc@1 60.634 Acc@5 97.257
epoch 30, total time 309.55
Test: [0/750]	Time 0.721 (0.721)	Loss 0.7928 (0.7928)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.028 (0.038)	Loss 0.6860 (0.6130)	Acc@1 71.875 (81.188)	Acc@5 96.875 (88.707)
Test: [200/750]	Time 0.026 (0.035)	Loss 1.5762 (0.7025)	Acc@1 31.250 (75.404)	Acc@5 87.500 (91.620)
Test: [300/750]	Time 0.039 (0.034)	Loss 1.3958 (0.9298)	Acc@1 31.250 (64.120)	Acc@5 96.875 (91.642)
Test: [400/750]	Time 0.021 (0.033)	Loss 1.0281 (1.0330)	Acc@1 71.875 (58.362)	Acc@5 87.500 (90.867)
Test: [500/750]	Time 0.023 (0.033)	Loss 0.7821 (1.0376)	Acc@1 71.875 (60.030)	Acc@5 100.000 (89.577)
Test: [600/750]	Time 0.034 (0.032)	Loss 0.9585 (1.0242)	Acc@1 75.000 (61.782)	Acc@5 90.625 (89.777)
Test: [700/750]	Time 0.026 (0.032)	Loss 1.3168 (1.0239)	Acc@1 43.750 (62.041)	Acc@5 81.250 (90.126)
 * Acc@1 61.888 Acc@5 90.021
saving the best model!
==> training...
Epoch: [31][0/875]	Time 1.620 (1.620)	Data 1.222 (1.222)	Loss 3.6575 (3.6575)	Loss@kd 1.9014 (1.9014)	Acc@1 48.438 (48.438)	Acc@5 92.188 (92.188)
Epoch: [31][100/875]	Time 0.352 (0.368)	Data 0.007 (0.019)	Loss 3.2596 (3.4048)	Loss@kd 1.9442 (1.9630)	Acc@1 64.062 (61.061)	Acc@5 100.000 (97.061)
Epoch: [31][200/875]	Time 0.348 (0.362)	Data 0.007 (0.013)	Loss 3.5699 (3.4192)	Loss@kd 1.9623 (1.9695)	Acc@1 57.812 (60.642)	Acc@5 92.188 (97.233)
Epoch: [31][300/875]	Time 0.355 (0.348)	Data 0.007 (0.011)	Loss 3.3724 (3.4215)	Loss@kd 1.9866 (1.9729)	Acc@1 64.062 (60.979)	Acc@5 95.312 (97.186)
Epoch: [31][400/875]	Time 0.357 (0.350)	Data 0.007 (0.010)	Loss 3.7038 (3.4109)	Loss@kd 2.0828 (1.9687)	Acc@1 65.625 (61.253)	Acc@5 95.312 (97.218)
Epoch: [31][500/875]	Time 0.354 (0.352)	Data 0.005 (0.009)	Loss 3.7098 (3.4179)	Loss@kd 2.0379 (1.9703)	Acc@1 54.688 (61.044)	Acc@5 96.875 (97.252)
Epoch: [31][600/875]	Time 0.361 (0.353)	Data 0.007 (0.009)	Loss 3.4966 (3.4159)	Loss@kd 1.9425 (1.9689)	Acc@1 57.812 (61.049)	Acc@5 96.875 (97.249)
Epoch: [31][700/875]	Time 0.351 (0.353)	Data 0.007 (0.009)	Loss 3.3379 (3.4159)	Loss@kd 1.9711 (1.9681)	Acc@1 64.062 (61.091)	Acc@5 96.875 (97.234)
Epoch: [31][800/875]	Time 0.353 (0.354)	Data 0.008 (0.009)	Loss 3.6668 (3.4169)	Loss@kd 1.9480 (1.9666)	Acc@1 59.375 (60.953)	Acc@5 90.625 (97.236)
 * Acc@1 60.970 Acc@5 97.248
epoch 31, total time 309.98
Test: [0/750]	Time 0.716 (0.716)	Loss 0.7981 (0.7981)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.027 (0.041)	Loss 0.4086 (0.6025)	Acc@1 87.500 (82.519)	Acc@5 100.000 (88.923)
Test: [200/750]	Time 0.027 (0.038)	Loss 2.2341 (0.6096)	Acc@1 18.750 (79.680)	Acc@5 71.875 (91.838)
Test: [300/750]	Time 0.047 (0.036)	Loss 1.1467 (0.9649)	Acc@1 56.250 (61.856)	Acc@5 93.750 (89.379)
Test: [400/750]	Time 0.047 (0.036)	Loss 1.0407 (0.9841)	Acc@1 65.625 (61.690)	Acc@5 90.625 (90.500)
Test: [500/750]	Time 0.035 (0.035)	Loss 0.9031 (0.9879)	Acc@1 71.875 (63.105)	Acc@5 87.500 (89.883)
Test: [600/750]	Time 0.026 (0.035)	Loss 1.0992 (1.0143)	Acc@1 65.625 (62.807)	Acc@5 90.625 (89.720)
Test: [700/750]	Time 0.034 (0.034)	Loss 1.4714 (1.0438)	Acc@1 43.750 (60.953)	Acc@5 81.250 (89.867)
 * Acc@1 60.554 Acc@5 89.646
==> training...
Epoch: [32][0/875]	Time 1.576 (1.576)	Data 1.240 (1.240)	Loss 3.1716 (3.1716)	Loss@kd 1.9697 (1.9697)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [32][100/875]	Time 0.353 (0.368)	Data 0.008 (0.019)	Loss 3.1564 (3.3915)	Loss@kd 1.8700 (1.9571)	Acc@1 70.312 (60.845)	Acc@5 98.438 (97.370)
Epoch: [32][200/875]	Time 0.350 (0.361)	Data 0.007 (0.013)	Loss 3.6523 (3.4137)	Loss@kd 1.9470 (1.9621)	Acc@1 54.688 (60.681)	Acc@5 90.625 (97.085)
Epoch: [32][300/875]	Time 0.351 (0.345)	Data 0.008 (0.011)	Loss 3.4084 (3.4190)	Loss@kd 1.9037 (1.9646)	Acc@1 56.250 (60.579)	Acc@5 98.438 (97.067)
Epoch: [32][400/875]	Time 0.363 (0.348)	Data 0.005 (0.010)	Loss 3.2073 (3.4224)	Loss@kd 1.8936 (1.9622)	Acc@1 68.750 (60.501)	Acc@5 100.000 (96.984)
Epoch: [32][500/875]	Time 0.352 (0.349)	Data 0.008 (0.009)	Loss 3.5262 (3.4174)	Loss@kd 2.0029 (1.9633)	Acc@1 53.125 (60.660)	Acc@5 96.875 (97.090)
Epoch: [32][600/875]	Time 0.347 (0.350)	Data 0.008 (0.009)	Loss 3.5196 (3.4150)	Loss@kd 1.9383 (1.9630)	Acc@1 56.250 (60.613)	Acc@5 98.438 (97.122)
Epoch: [32][700/875]	Time 0.354 (0.351)	Data 0.008 (0.009)	Loss 3.3286 (3.4172)	Loss@kd 2.0035 (1.9631)	Acc@1 62.500 (60.590)	Acc@5 100.000 (97.107)
Epoch: [32][800/875]	Time 0.364 (0.352)	Data 0.006 (0.009)	Loss 3.1664 (3.4130)	Loss@kd 1.9660 (1.9615)	Acc@1 75.000 (60.682)	Acc@5 96.875 (97.150)
 * Acc@1 60.854 Acc@5 97.204
epoch 32, total time 308.34
Test: [0/750]	Time 0.710 (0.710)	Loss 0.8015 (0.8015)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.039 (0.039)	Loss 0.6127 (0.5788)	Acc@1 81.250 (82.147)	Acc@5 93.750 (89.202)
Test: [200/750]	Time 0.022 (0.035)	Loss 1.6294 (0.6537)	Acc@1 31.250 (77.519)	Acc@5 87.500 (92.304)
Test: [300/750]	Time 0.024 (0.033)	Loss 1.3720 (0.8884)	Acc@1 28.125 (66.300)	Acc@5 93.750 (92.120)
Test: [400/750]	Time 0.023 (0.033)	Loss 1.1386 (0.9971)	Acc@1 71.875 (60.450)	Acc@5 84.375 (91.623)
Test: [500/750]	Time 0.031 (0.032)	Loss 0.6681 (1.0057)	Acc@1 78.125 (61.882)	Acc@5 93.750 (90.263)
Test: [600/750]	Time 0.031 (0.032)	Loss 0.9751 (0.9933)	Acc@1 68.750 (63.155)	Acc@5 90.625 (90.433)
Test: [700/750]	Time 0.035 (0.031)	Loss 1.2896 (1.0044)	Acc@1 50.000 (62.767)	Acc@5 84.375 (90.580)
 * Acc@1 62.679 Acc@5 90.354
saving the best model!
==> training...
Epoch: [33][0/875]	Time 1.630 (1.630)	Data 1.261 (1.261)	Loss 3.2717 (3.2717)	Loss@kd 2.0433 (2.0433)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [33][100/875]	Time 0.335 (0.370)	Data 0.006 (0.019)	Loss 3.2889 (3.3918)	Loss@kd 2.0123 (1.9513)	Acc@1 68.750 (61.108)	Acc@5 100.000 (97.478)
Epoch: [33][200/875]	Time 0.357 (0.364)	Data 0.007 (0.013)	Loss 3.6536 (3.3949)	Loss@kd 1.9607 (1.9509)	Acc@1 56.250 (61.140)	Acc@5 93.750 (97.481)
Epoch: [33][300/875]	Time 0.285 (0.347)	Data 0.007 (0.011)	Loss 3.6224 (3.4041)	Loss@kd 1.9712 (1.9544)	Acc@1 48.438 (60.751)	Acc@5 98.438 (97.316)
Epoch: [33][400/875]	Time 0.351 (0.350)	Data 0.008 (0.010)	Loss 3.4653 (3.4024)	Loss@kd 1.9056 (1.9537)	Acc@1 56.250 (60.754)	Acc@5 96.875 (97.378)
Epoch: [33][500/875]	Time 0.352 (0.351)	Data 0.008 (0.009)	Loss 3.3991 (3.3965)	Loss@kd 1.9156 (1.9532)	Acc@1 60.938 (61.209)	Acc@5 95.312 (97.305)
Epoch: [33][600/875]	Time 0.350 (0.352)	Data 0.007 (0.009)	Loss 3.6239 (3.3973)	Loss@kd 1.9862 (1.9538)	Acc@1 54.688 (61.119)	Acc@5 100.000 (97.353)
Epoch: [33][700/875]	Time 0.352 (0.353)	Data 0.007 (0.009)	Loss 3.5108 (3.3995)	Loss@kd 1.9611 (1.9554)	Acc@1 56.250 (61.131)	Acc@5 95.312 (97.332)
Epoch: [33][800/875]	Time 0.353 (0.353)	Data 0.007 (0.009)	Loss 3.6422 (3.3957)	Loss@kd 2.0326 (1.9535)	Acc@1 50.000 (61.244)	Acc@5 95.312 (97.353)
 * Acc@1 61.164 Acc@5 97.329
epoch 33, total time 309.75
Test: [0/750]	Time 0.717 (0.717)	Loss 0.7273 (0.7273)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.037 (0.034)	Loss 0.8336 (0.5920)	Acc@1 62.500 (80.415)	Acc@5 93.750 (89.202)
Test: [200/750]	Time 0.031 (0.032)	Loss 1.6258 (0.8008)	Acc@1 28.125 (70.460)	Acc@5 93.750 (89.785)
Test: [300/750]	Time 0.024 (0.031)	Loss 1.6282 (1.0316)	Acc@1 25.000 (57.807)	Acc@5 81.250 (89.815)
Test: [400/750]	Time 0.023 (0.030)	Loss 1.0943 (1.1799)	Acc@1 75.000 (50.600)	Acc@5 90.625 (87.905)
Test: [500/750]	Time 0.033 (0.029)	Loss 0.6885 (1.1617)	Acc@1 78.125 (53.780)	Acc@5 93.750 (87.201)
Test: [600/750]	Time 0.022 (0.029)	Loss 1.0881 (1.1345)	Acc@1 65.625 (56.463)	Acc@5 84.375 (87.297)
Test: [700/750]	Time 0.038 (0.029)	Loss 0.8190 (1.1094)	Acc@1 71.875 (58.256)	Acc@5 93.750 (87.924)
 * Acc@1 59.550 Acc@5 88.463
==> training...
Epoch: [34][0/875]	Time 1.671 (1.671)	Data 1.333 (1.333)	Loss 3.2810 (3.2810)	Loss@kd 1.9615 (1.9615)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [34][100/875]	Time 0.374 (0.365)	Data 0.007 (0.020)	Loss 3.3747 (3.4102)	Loss@kd 1.9374 (1.9560)	Acc@1 57.812 (60.535)	Acc@5 98.438 (97.324)
Epoch: [34][200/875]	Time 0.351 (0.362)	Data 0.008 (0.014)	Loss 3.2262 (3.4036)	Loss@kd 1.8597 (1.9483)	Acc@1 62.500 (60.588)	Acc@5 96.875 (97.124)
Epoch: [34][300/875]	Time 0.305 (0.349)	Data 0.008 (0.011)	Loss 3.4198 (3.3983)	Loss@kd 1.9640 (1.9458)	Acc@1 64.062 (60.662)	Acc@5 96.875 (97.046)
Epoch: [34][400/875]	Time 0.356 (0.350)	Data 0.007 (0.010)	Loss 3.3399 (3.3982)	Loss@kd 1.9904 (1.9484)	Acc@1 60.938 (60.657)	Acc@5 100.000 (97.117)
Epoch: [34][500/875]	Time 0.355 (0.351)	Data 0.007 (0.010)	Loss 3.2736 (3.3992)	Loss@kd 1.9738 (1.9492)	Acc@1 71.875 (60.613)	Acc@5 96.875 (97.128)
Epoch: [34][600/875]	Time 0.357 (0.352)	Data 0.007 (0.009)	Loss 3.5749 (3.3914)	Loss@kd 1.9451 (1.9477)	Acc@1 43.750 (60.828)	Acc@5 96.875 (97.164)
Epoch: [34][700/875]	Time 0.438 (0.352)	Data 0.006 (0.009)	Loss 3.2754 (3.3856)	Loss@kd 1.8949 (1.9464)	Acc@1 60.938 (61.051)	Acc@5 98.438 (97.214)
Epoch: [34][800/875]	Time 0.348 (0.353)	Data 0.006 (0.009)	Loss 3.4204 (3.3834)	Loss@kd 1.9175 (1.9473)	Acc@1 64.062 (61.144)	Acc@5 98.438 (97.236)
 * Acc@1 61.043 Acc@5 97.225
epoch 34, total time 309.31
Test: [0/750]	Time 0.811 (0.811)	Loss 0.7696 (0.7696)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.024 (0.037)	Loss 0.6717 (0.6351)	Acc@1 75.000 (81.590)	Acc@5 100.000 (88.769)
Test: [200/750]	Time 0.021 (0.032)	Loss 1.9878 (0.7413)	Acc@1 18.750 (73.601)	Acc@5 84.375 (91.076)
Test: [300/750]	Time 0.020 (0.030)	Loss 1.1623 (1.0405)	Acc@1 56.250 (58.275)	Acc@5 87.500 (89.192)
Test: [400/750]	Time 0.021 (0.029)	Loss 0.8548 (1.0566)	Acc@1 81.250 (58.222)	Acc@5 90.625 (89.955)
Test: [500/750]	Time 0.021 (0.029)	Loss 0.6129 (1.0254)	Acc@1 78.125 (61.090)	Acc@5 96.875 (89.677)
Test: [600/750]	Time 0.024 (0.028)	Loss 0.8981 (1.0001)	Acc@1 68.750 (63.030)	Acc@5 90.625 (90.105)
Test: [700/750]	Time 0.028 (0.029)	Loss 1.6747 (1.0221)	Acc@1 34.375 (61.836)	Acc@5 71.875 (90.019)
 * Acc@1 60.671 Acc@5 89.400
==> training...
Epoch: [35][0/875]	Time 1.620 (1.620)	Data 1.228 (1.228)	Loss 3.1829 (3.1829)	Loss@kd 1.9505 (1.9505)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [35][100/875]	Time 0.359 (0.370)	Data 0.007 (0.019)	Loss 3.6379 (3.3977)	Loss@kd 1.9401 (1.9608)	Acc@1 51.562 (61.340)	Acc@5 100.000 (97.014)
Epoch: [35][200/875]	Time 0.351 (0.363)	Data 0.008 (0.013)	Loss 3.4415 (3.3798)	Loss@kd 1.9543 (1.9486)	Acc@1 59.375 (61.264)	Acc@5 96.875 (97.116)
Epoch: [35][300/875]	Time 0.314 (0.351)	Data 0.007 (0.011)	Loss 3.3473 (3.3706)	Loss@kd 1.9561 (1.9418)	Acc@1 70.312 (61.379)	Acc@5 100.000 (97.212)
Epoch: [35][400/875]	Time 0.353 (0.349)	Data 0.005 (0.010)	Loss 3.3659 (3.3748)	Loss@kd 1.9984 (1.9446)	Acc@1 64.062 (61.234)	Acc@5 100.000 (97.300)
Epoch: [35][500/875]	Time 0.358 (0.351)	Data 0.005 (0.009)	Loss 3.5385 (3.3739)	Loss@kd 1.9923 (1.9414)	Acc@1 57.812 (61.106)	Acc@5 96.875 (97.287)
Epoch: [35][600/875]	Time 0.352 (0.352)	Data 0.006 (0.009)	Loss 3.4448 (3.3758)	Loss@kd 1.9986 (1.9420)	Acc@1 68.750 (61.122)	Acc@5 95.312 (97.307)
Epoch: [35][700/875]	Time 0.357 (0.353)	Data 0.008 (0.009)	Loss 3.5725 (3.3770)	Loss@kd 1.9606 (1.9419)	Acc@1 54.688 (61.082)	Acc@5 96.875 (97.296)
Epoch: [35][800/875]	Time 0.348 (0.354)	Data 0.007 (0.008)	Loss 3.1992 (3.3764)	Loss@kd 1.8469 (1.9414)	Acc@1 65.625 (61.164)	Acc@5 100.000 (97.269)
 * Acc@1 61.202 Acc@5 97.277
epoch 35, total time 310.05
Test: [0/750]	Time 0.665 (0.665)	Loss 0.8339 (0.8339)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.025 (0.041)	Loss 0.5827 (0.6141)	Acc@1 84.375 (82.054)	Acc@5 96.875 (88.181)
Test: [200/750]	Time 0.041 (0.037)	Loss 1.4411 (0.6355)	Acc@1 31.250 (79.820)	Acc@5 87.500 (91.356)
Test: [300/750]	Time 0.024 (0.036)	Loss 1.4693 (0.8501)	Acc@1 21.875 (68.792)	Acc@5 87.500 (92.058)
Test: [400/750]	Time 0.040 (0.036)	Loss 0.8704 (1.0028)	Acc@1 75.000 (60.957)	Acc@5 93.750 (90.500)
Test: [500/750]	Time 0.030 (0.036)	Loss 0.7982 (1.0002)	Acc@1 68.750 (62.456)	Acc@5 96.875 (89.758)
Test: [600/750]	Time 0.045 (0.036)	Loss 1.2671 (1.0197)	Acc@1 56.250 (62.391)	Acc@5 84.375 (89.351)
Test: [700/750]	Time 0.044 (0.036)	Loss 1.0064 (1.0364)	Acc@1 71.875 (61.622)	Acc@5 93.750 (89.354)
 * Acc@1 62.046 Acc@5 89.575
==> training...
Epoch: [36][0/875]	Time 1.703 (1.703)	Data 1.326 (1.326)	Loss 3.3191 (3.3191)	Loss@kd 1.9014 (1.9014)	Acc@1 56.250 (56.250)	Acc@5 100.000 (100.000)
Epoch: [36][100/875]	Time 0.357 (0.369)	Data 0.007 (0.020)	Loss 3.3893 (3.3452)	Loss@kd 1.9963 (1.9304)	Acc@1 64.062 (61.618)	Acc@5 98.438 (97.324)
Epoch: [36][200/875]	Time 0.355 (0.363)	Data 0.008 (0.014)	Loss 3.2726 (3.3664)	Loss@kd 1.9552 (1.9406)	Acc@1 70.312 (61.357)	Acc@5 96.875 (97.489)
Epoch: [36][300/875]	Time 0.306 (0.348)	Data 0.007 (0.011)	Loss 3.1723 (3.3678)	Loss@kd 1.8848 (1.9403)	Acc@1 65.625 (61.509)	Acc@5 98.438 (97.415)
Epoch: [36][400/875]	Time 0.336 (0.349)	Data 0.008 (0.010)	Loss 3.5013 (3.3771)	Loss@kd 1.9531 (1.9432)	Acc@1 57.812 (61.245)	Acc@5 93.750 (97.339)
Epoch: [36][500/875]	Time 0.353 (0.350)	Data 0.007 (0.010)	Loss 3.2808 (3.3753)	Loss@kd 1.8687 (1.9415)	Acc@1 57.812 (61.146)	Acc@5 95.312 (97.368)
Epoch: [36][600/875]	Time 0.347 (0.351)	Data 0.009 (0.009)	Loss 3.3910 (3.3793)	Loss@kd 1.9055 (1.9408)	Acc@1 56.250 (60.979)	Acc@5 95.312 (97.304)
Epoch: [36][700/875]	Time 0.351 (0.352)	Data 0.007 (0.009)	Loss 3.3606 (3.3732)	Loss@kd 1.9289 (1.9392)	Acc@1 60.938 (61.138)	Acc@5 98.438 (97.330)
Epoch: [36][800/875]	Time 0.359 (0.352)	Data 0.007 (0.009)	Loss 3.5982 (3.3726)	Loss@kd 2.0149 (1.9374)	Acc@1 60.938 (61.056)	Acc@5 96.875 (97.308)
 * Acc@1 61.100 Acc@5 97.336
epoch 36, total time 309.06
Test: [0/750]	Time 0.715 (0.715)	Loss 0.8043 (0.8043)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.038 (0.040)	Loss 0.6512 (0.5999)	Acc@1 78.125 (82.024)	Acc@5 96.875 (88.119)
Test: [200/750]	Time 0.033 (0.037)	Loss 1.5673 (0.6910)	Acc@1 37.500 (76.104)	Acc@5 90.625 (91.045)
Test: [300/750]	Time 0.045 (0.037)	Loss 1.3118 (0.9052)	Acc@1 37.500 (65.500)	Acc@5 100.000 (91.456)
Test: [400/750]	Time 0.035 (0.037)	Loss 0.6816 (0.9899)	Acc@1 87.500 (60.287)	Acc@5 90.625 (91.623)
Test: [500/750]	Time 0.030 (0.036)	Loss 0.8199 (0.9584)	Acc@1 65.625 (63.292)	Acc@5 93.750 (91.087)
Test: [600/750]	Time 0.036 (0.036)	Loss 0.9819 (0.9642)	Acc@1 62.500 (63.998)	Acc@5 87.500 (90.791)
Test: [700/750]	Time 0.028 (0.035)	Loss 1.4668 (0.9853)	Acc@1 46.875 (63.374)	Acc@5 78.125 (90.563)
 * Acc@1 63.042 Acc@5 90.188
saving the best model!
==> training...
Epoch: [37][0/875]	Time 1.818 (1.818)	Data 1.449 (1.449)	Loss 3.3987 (3.3987)	Loss@kd 1.9634 (1.9634)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [37][100/875]	Time 0.354 (0.370)	Data 0.007 (0.021)	Loss 3.2769 (3.3474)	Loss@kd 1.8599 (1.9304)	Acc@1 64.062 (62.082)	Acc@5 96.875 (97.509)
Epoch: [37][200/875]	Time 0.355 (0.364)	Data 0.008 (0.014)	Loss 3.2590 (3.3427)	Loss@kd 1.9420 (1.9288)	Acc@1 62.500 (62.282)	Acc@5 98.438 (97.404)
Epoch: [37][300/875]	Time 0.292 (0.349)	Data 0.005 (0.012)	Loss 3.2651 (3.3465)	Loss@kd 1.8944 (1.9291)	Acc@1 67.188 (61.996)	Acc@5 95.312 (97.337)
Epoch: [37][400/875]	Time 0.348 (0.351)	Data 0.008 (0.011)	Loss 3.4591 (3.3485)	Loss@kd 1.9489 (1.9285)	Acc@1 64.062 (61.880)	Acc@5 95.312 (97.311)
Epoch: [37][500/875]	Time 0.355 (0.352)	Data 0.006 (0.010)	Loss 3.2765 (3.3589)	Loss@kd 1.8903 (1.9331)	Acc@1 64.062 (61.465)	Acc@5 96.875 (97.315)
Epoch: [37][600/875]	Time 0.352 (0.353)	Data 0.007 (0.010)	Loss 3.2535 (3.3574)	Loss@kd 1.9097 (1.9318)	Acc@1 60.938 (61.455)	Acc@5 100.000 (97.333)
Epoch: [37][700/875]	Time 0.357 (0.353)	Data 0.007 (0.009)	Loss 3.5354 (3.3573)	Loss@kd 1.9392 (1.9316)	Acc@1 51.562 (61.443)	Acc@5 96.875 (97.372)
Epoch: [37][800/875]	Time 0.352 (0.354)	Data 0.008 (0.009)	Loss 3.5345 (3.3602)	Loss@kd 1.9744 (1.9317)	Acc@1 45.312 (61.277)	Acc@5 98.438 (97.382)
 * Acc@1 61.373 Acc@5 97.384
epoch 37, total time 309.86
Test: [0/750]	Time 0.780 (0.780)	Loss 0.8344 (0.8344)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.036 (0.041)	Loss 0.9911 (0.6189)	Acc@1 59.375 (80.415)	Acc@5 93.750 (89.202)
Test: [200/750]	Time 0.029 (0.038)	Loss 1.3459 (0.8143)	Acc@1 34.375 (71.082)	Acc@5 93.750 (89.894)
Test: [300/750]	Time 0.043 (0.037)	Loss 1.2277 (0.9508)	Acc@1 34.375 (63.953)	Acc@5 96.875 (91.663)
Test: [400/750]	Time 0.028 (0.035)	Loss 0.9095 (1.0343)	Acc@1 81.250 (58.962)	Acc@5 90.625 (91.412)
Test: [500/750]	Time 0.033 (0.034)	Loss 0.5812 (1.0099)	Acc@1 81.250 (61.190)	Acc@5 96.875 (91.161)
Test: [600/750]	Time 0.022 (0.033)	Loss 1.4166 (1.0041)	Acc@1 46.875 (62.334)	Acc@5 78.125 (90.526)
Test: [700/750]	Time 0.024 (0.032)	Loss 1.4405 (1.0470)	Acc@1 43.750 (60.922)	Acc@5 81.250 (89.426)
 * Acc@1 60.596 Acc@5 89.104
==> training...
Epoch: [38][0/875]	Time 1.633 (1.633)	Data 1.263 (1.263)	Loss 3.2828 (3.2828)	Loss@kd 1.8894 (1.8894)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [38][100/875]	Time 0.362 (0.369)	Data 0.009 (0.019)	Loss 3.2368 (3.3468)	Loss@kd 1.8912 (1.9254)	Acc@1 64.062 (61.541)	Acc@5 96.875 (97.324)
Epoch: [38][200/875]	Time 0.352 (0.362)	Data 0.008 (0.013)	Loss 3.4296 (3.3519)	Loss@kd 1.9390 (1.9244)	Acc@1 54.688 (61.202)	Acc@5 96.875 (97.287)
Epoch: [38][300/875]	Time 0.338 (0.348)	Data 0.005 (0.011)	Loss 3.3634 (3.3522)	Loss@kd 1.9607 (1.9232)	Acc@1 64.062 (61.233)	Acc@5 95.312 (97.270)
Epoch: [38][400/875]	Time 0.350 (0.350)	Data 0.006 (0.010)	Loss 3.4559 (3.3440)	Loss@kd 1.9419 (1.9209)	Acc@1 57.812 (61.491)	Acc@5 92.188 (97.319)
Epoch: [38][500/875]	Time 0.351 (0.351)	Data 0.007 (0.010)	Loss 3.6555 (3.3514)	Loss@kd 1.9515 (1.9236)	Acc@1 50.000 (61.343)	Acc@5 92.188 (97.321)
Epoch: [38][600/875]	Time 0.356 (0.352)	Data 0.008 (0.009)	Loss 3.3812 (3.3540)	Loss@kd 1.9290 (1.9252)	Acc@1 65.625 (61.242)	Acc@5 96.875 (97.343)
Epoch: [38][700/875]	Time 0.441 (0.353)	Data 0.005 (0.009)	Loss 3.1992 (3.3525)	Loss@kd 1.9061 (1.9254)	Acc@1 62.500 (61.312)	Acc@5 96.875 (97.372)
Epoch: [38][800/875]	Time 0.352 (0.353)	Data 0.009 (0.009)	Loss 3.5956 (3.3519)	Loss@kd 1.9877 (1.9241)	Acc@1 54.688 (61.265)	Acc@5 95.312 (97.369)
 * Acc@1 61.311 Acc@5 97.393
epoch 38, total time 309.99
Test: [0/750]	Time 0.784 (0.784)	Loss 0.8278 (0.8278)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.034 (0.041)	Loss 0.5955 (0.5948)	Acc@1 75.000 (82.859)	Acc@5 100.000 (89.325)
Test: [200/750]	Time 0.021 (0.037)	Loss 2.0054 (0.6567)	Acc@1 15.625 (76.928)	Acc@5 71.875 (92.257)
Test: [300/750]	Time 0.032 (0.037)	Loss 1.2772 (0.9712)	Acc@1 43.750 (61.784)	Acc@5 96.875 (89.836)
Test: [400/750]	Time 0.028 (0.037)	Loss 0.8143 (1.0138)	Acc@1 75.000 (60.341)	Acc@5 90.625 (90.726)
Test: [500/750]	Time 0.038 (0.036)	Loss 0.8900 (1.0008)	Acc@1 71.875 (62.556)	Acc@5 93.750 (90.145)
Test: [600/750]	Time 0.027 (0.036)	Loss 0.6472 (0.9998)	Acc@1 81.250 (63.509)	Acc@5 96.875 (90.199)
Test: [700/750]	Time 0.039 (0.035)	Loss 1.7616 (1.0080)	Acc@1 34.375 (63.057)	Acc@5 71.875 (90.277)
 * Acc@1 61.996 Acc@5 89.596
==> training...
Epoch: [39][0/875]	Time 1.666 (1.666)	Data 1.260 (1.260)	Loss 3.3404 (3.3404)	Loss@kd 1.9694 (1.9694)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [39][100/875]	Time 0.354 (0.371)	Data 0.007 (0.020)	Loss 3.6609 (3.3547)	Loss@kd 1.9115 (1.9181)	Acc@1 45.312 (60.721)	Acc@5 93.750 (97.447)
Epoch: [39][200/875]	Time 0.358 (0.364)	Data 0.007 (0.013)	Loss 3.2274 (3.3681)	Loss@kd 1.9617 (1.9246)	Acc@1 62.500 (60.580)	Acc@5 100.000 (97.303)
Epoch: [39][300/875]	Time 0.355 (0.349)	Data 0.008 (0.011)	Loss 3.2008 (3.3602)	Loss@kd 1.8518 (1.9224)	Acc@1 65.625 (60.917)	Acc@5 100.000 (97.285)
Epoch: [39][400/875]	Time 0.353 (0.351)	Data 0.008 (0.010)	Loss 3.3730 (3.3562)	Loss@kd 1.9250 (1.9215)	Acc@1 64.062 (61.035)	Acc@5 98.438 (97.296)
Epoch: [39][500/875]	Time 0.365 (0.353)	Data 0.007 (0.010)	Loss 3.3560 (3.3606)	Loss@kd 1.8441 (1.9242)	Acc@1 54.688 (61.068)	Acc@5 98.438 (97.243)
Epoch: [39][600/875]	Time 0.358 (0.354)	Data 0.008 (0.009)	Loss 3.3081 (3.3589)	Loss@kd 1.8693 (1.9249)	Acc@1 65.625 (61.231)	Acc@5 96.875 (97.247)
Epoch: [39][700/875]	Time 0.354 (0.355)	Data 0.008 (0.009)	Loss 3.3502 (3.3508)	Loss@kd 1.9858 (1.9225)	Acc@1 65.625 (61.406)	Acc@5 96.875 (97.312)
Epoch: [39][800/875]	Time 0.350 (0.355)	Data 0.007 (0.009)	Loss 3.4215 (3.3459)	Loss@kd 1.8431 (1.9206)	Acc@1 59.375 (61.468)	Acc@5 96.875 (97.330)
 * Acc@1 61.580 Acc@5 97.336
epoch 39, total time 311.18
Test: [0/750]	Time 0.635 (0.635)	Loss 0.9485 (0.9485)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.021 (0.034)	Loss 0.5123 (0.7193)	Acc@1 84.375 (79.889)	Acc@5 96.875 (88.057)
Test: [200/750]	Time 0.037 (0.031)	Loss 1.4627 (0.6633)	Acc@1 40.625 (79.338)	Acc@5 93.750 (91.993)
Test: [300/750]	Time 0.021 (0.030)	Loss 1.6870 (0.9049)	Acc@1 12.500 (67.297)	Acc@5 71.875 (91.352)
Test: [400/750]	Time 0.023 (0.030)	Loss 0.6748 (1.0641)	Acc@1 87.500 (58.565)	Acc@5 90.625 (89.269)
Test: [500/750]	Time 0.032 (0.030)	Loss 0.6563 (1.0045)	Acc@1 75.000 (61.989)	Acc@5 96.875 (89.789)
Test: [600/750]	Time 0.030 (0.030)	Loss 1.1636 (0.9997)	Acc@1 62.500 (62.781)	Acc@5 87.500 (89.939)
Test: [700/750]	Time 0.047 (0.030)	Loss 1.2870 (1.0249)	Acc@1 62.500 (61.818)	Acc@5 81.250 (90.063)
 * Acc@1 61.912 Acc@5 90.058
==> training...
Epoch: [40][0/875]	Time 1.591 (1.591)	Data 1.248 (1.248)	Loss 3.2631 (3.2631)	Loss@kd 1.9774 (1.9774)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [40][100/875]	Time 0.349 (0.370)	Data 0.008 (0.019)	Loss 3.3348 (3.3222)	Loss@kd 1.9427 (1.9098)	Acc@1 65.625 (62.268)	Acc@5 98.438 (97.246)
Epoch: [40][200/875]	Time 0.349 (0.362)	Data 0.006 (0.013)	Loss 3.3835 (3.3230)	Loss@kd 1.9798 (1.9154)	Acc@1 64.062 (62.368)	Acc@5 98.438 (97.357)
Epoch: [40][300/875]	Time 0.346 (0.344)	Data 0.005 (0.011)	Loss 3.1039 (3.3391)	Loss@kd 1.8561 (1.9197)	Acc@1 65.625 (61.965)	Acc@5 98.438 (97.270)
Epoch: [40][400/875]	Time 0.356 (0.347)	Data 0.005 (0.010)	Loss 3.4738 (3.3391)	Loss@kd 1.9627 (1.9193)	Acc@1 56.250 (61.849)	Acc@5 100.000 (97.374)
Epoch: [40][500/875]	Time 0.347 (0.348)	Data 0.007 (0.009)	Loss 3.3459 (3.3390)	Loss@kd 1.9908 (1.9179)	Acc@1 64.062 (61.689)	Acc@5 100.000 (97.383)
Epoch: [40][600/875]	Time 0.350 (0.349)	Data 0.007 (0.009)	Loss 3.3526 (3.3379)	Loss@kd 1.8530 (1.9181)	Acc@1 56.250 (61.793)	Acc@5 98.438 (97.395)
Epoch: [40][700/875]	Time 0.350 (0.350)	Data 0.006 (0.009)	Loss 3.4210 (3.3357)	Loss@kd 1.8843 (1.9178)	Acc@1 54.688 (61.876)	Acc@5 95.312 (97.408)
Epoch: [40][800/875]	Time 0.361 (0.351)	Data 0.005 (0.009)	Loss 3.2815 (3.3350)	Loss@kd 1.9711 (1.9160)	Acc@1 59.375 (61.829)	Acc@5 100.000 (97.392)
 * Acc@1 61.809 Acc@5 97.423
epoch 40, total time 307.79
Test: [0/750]	Time 0.708 (0.708)	Loss 0.8347 (0.8347)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.020 (0.035)	Loss 0.6449 (0.6737)	Acc@1 78.125 (81.590)	Acc@5 93.750 (87.902)
Test: [200/750]	Time 0.024 (0.031)	Loss 1.7746 (0.6932)	Acc@1 34.375 (78.856)	Acc@5 84.375 (91.387)
Test: [300/750]	Time 0.041 (0.030)	Loss 1.3182 (0.9516)	Acc@1 34.375 (66.092)	Acc@5 96.875 (90.542)
Test: [400/750]	Time 0.019 (0.029)	Loss 0.5251 (1.0284)	Acc@1 84.375 (60.793)	Acc@5 96.875 (90.734)
Test: [500/750]	Time 0.021 (0.028)	Loss 0.8558 (0.9623)	Acc@1 71.875 (64.340)	Acc@5 93.750 (91.062)
Test: [600/750]	Time 0.022 (0.028)	Loss 1.1723 (0.9847)	Acc@1 59.375 (64.216)	Acc@5 84.375 (90.765)
Test: [700/750]	Time 0.021 (0.028)	Loss 1.5430 (1.0208)	Acc@1 40.625 (62.732)	Acc@5 75.000 (90.197)
 * Acc@1 62.200 Acc@5 89.625
==> Saving...
==> training...
Epoch: [41][0/875]	Time 1.647 (1.647)	Data 1.283 (1.283)	Loss 3.1639 (3.1639)	Loss@kd 1.9415 (1.9415)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [41][100/875]	Time 0.351 (0.367)	Data 0.007 (0.020)	Loss 3.3502 (3.3069)	Loss@kd 1.7814 (1.9020)	Acc@1 60.938 (61.742)	Acc@5 95.312 (97.076)
Epoch: [41][200/875]	Time 0.357 (0.361)	Data 0.007 (0.013)	Loss 3.3521 (3.3073)	Loss@kd 2.0182 (1.9064)	Acc@1 68.750 (61.995)	Acc@5 98.438 (97.240)
Epoch: [41][300/875]	Time 0.286 (0.347)	Data 0.007 (0.011)	Loss 3.5697 (3.3127)	Loss@kd 2.0683 (1.9102)	Acc@1 53.125 (62.017)	Acc@5 100.000 (97.327)
Epoch: [41][400/875]	Time 0.352 (0.349)	Data 0.006 (0.010)	Loss 3.2359 (3.3179)	Loss@kd 1.8464 (1.9071)	Acc@1 56.250 (61.690)	Acc@5 95.312 (97.296)
Epoch: [41][500/875]	Time 0.351 (0.351)	Data 0.005 (0.009)	Loss 3.1692 (3.3207)	Loss@kd 1.9258 (1.9089)	Acc@1 67.188 (61.617)	Acc@5 100.000 (97.374)
Epoch: [41][600/875]	Time 0.357 (0.351)	Data 0.007 (0.009)	Loss 3.3321 (3.3220)	Loss@kd 1.9289 (1.9082)	Acc@1 57.812 (61.483)	Acc@5 100.000 (97.385)
Epoch: [41][700/875]	Time 0.355 (0.352)	Data 0.008 (0.009)	Loss 3.5616 (3.3243)	Loss@kd 2.0468 (1.9080)	Acc@1 67.188 (61.443)	Acc@5 96.875 (97.397)
Epoch: [41][800/875]	Time 0.351 (0.353)	Data 0.007 (0.009)	Loss 3.2045 (3.3240)	Loss@kd 1.8710 (1.9076)	Acc@1 67.188 (61.503)	Acc@5 96.875 (97.406)
 * Acc@1 61.573 Acc@5 97.386
epoch 41, total time 309.23
Test: [0/750]	Time 0.720 (0.720)	Loss 0.7035 (0.7035)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.029 (0.035)	Loss 0.6829 (0.6346)	Acc@1 68.750 (80.941)	Acc@5 100.000 (88.707)
Test: [200/750]	Time 0.020 (0.032)	Loss 2.1762 (0.7469)	Acc@1 12.500 (73.523)	Acc@5 65.625 (90.718)
Test: [300/750]	Time 0.036 (0.031)	Loss 1.4983 (1.1104)	Acc@1 37.500 (56.312)	Acc@5 84.375 (86.669)
Test: [400/750]	Time 0.021 (0.030)	Loss 0.5253 (1.1664)	Acc@1 84.375 (53.078)	Acc@5 90.625 (86.869)
Test: [500/750]	Time 0.021 (0.030)	Loss 0.6330 (1.0599)	Acc@1 75.000 (58.726)	Acc@5 96.875 (88.273)
Test: [600/750]	Time 0.020 (0.029)	Loss 0.8709 (1.0292)	Acc@1 71.875 (61.101)	Acc@5 90.625 (88.930)
Test: [700/750]	Time 0.023 (0.029)	Loss 1.2306 (1.0238)	Acc@1 59.375 (61.675)	Acc@5 81.250 (89.618)
 * Acc@1 61.925 Acc@5 89.821
==> training...
Epoch: [42][0/875]	Time 1.718 (1.718)	Data 1.303 (1.303)	Loss 3.0964 (3.0964)	Loss@kd 1.9062 (1.9062)	Acc@1 65.625 (65.625)	Acc@5 95.312 (95.312)
Epoch: [42][100/875]	Time 0.347 (0.368)	Data 0.008 (0.020)	Loss 3.1577 (3.3055)	Loss@kd 1.9110 (1.9034)	Acc@1 71.875 (62.949)	Acc@5 98.438 (97.463)
Epoch: [42][200/875]	Time 0.353 (0.361)	Data 0.006 (0.014)	Loss 3.1309 (3.3193)	Loss@kd 1.8921 (1.9075)	Acc@1 70.312 (62.072)	Acc@5 98.438 (97.528)
Epoch: [42][300/875]	Time 0.289 (0.347)	Data 0.006 (0.011)	Loss 3.0940 (3.3201)	Loss@kd 1.8536 (1.9065)	Acc@1 73.438 (62.157)	Acc@5 100.000 (97.394)
Epoch: [42][400/875]	Time 0.346 (0.348)	Data 0.006 (0.010)	Loss 3.4736 (3.3200)	Loss@kd 1.9580 (1.9044)	Acc@1 59.375 (62.048)	Acc@5 96.875 (97.389)
Epoch: [42][500/875]	Time 0.345 (0.350)	Data 0.007 (0.010)	Loss 3.2382 (3.3208)	Loss@kd 1.8798 (1.9057)	Acc@1 64.062 (61.864)	Acc@5 95.312 (97.439)
Epoch: [42][600/875]	Time 0.358 (0.351)	Data 0.010 (0.009)	Loss 3.5105 (3.3206)	Loss@kd 1.9598 (1.9052)	Acc@1 62.500 (61.790)	Acc@5 93.750 (97.390)
Epoch: [42][700/875]	Time 0.449 (0.352)	Data 0.010 (0.009)	Loss 3.1578 (3.3223)	Loss@kd 1.8703 (1.9061)	Acc@1 70.312 (61.693)	Acc@5 100.000 (97.388)
Epoch: [42][800/875]	Time 0.355 (0.352)	Data 0.007 (0.009)	Loss 3.1835 (3.3207)	Loss@kd 1.8443 (1.9057)	Acc@1 71.875 (61.788)	Acc@5 98.438 (97.406)
 * Acc@1 61.816 Acc@5 97.421
epoch 42, total time 309.07
Test: [0/750]	Time 0.760 (0.760)	Loss 0.8186 (0.8186)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.028 (0.039)	Loss 0.5165 (0.6588)	Acc@1 84.375 (80.910)	Acc@5 96.875 (87.902)
Test: [200/750]	Time 0.043 (0.036)	Loss 1.7329 (0.6664)	Acc@1 34.375 (77.596)	Acc@5 81.250 (91.402)
Test: [300/750]	Time 0.040 (0.036)	Loss 1.3366 (0.9465)	Acc@1 50.000 (63.185)	Acc@5 100.000 (90.272)
Test: [400/750]	Time 0.039 (0.036)	Loss 0.6485 (1.0211)	Acc@1 84.375 (59.266)	Acc@5 93.750 (90.609)
Test: [500/750]	Time 0.047 (0.035)	Loss 0.7996 (0.9819)	Acc@1 68.750 (62.587)	Acc@5 87.500 (90.407)
Test: [600/750]	Time 0.028 (0.035)	Loss 0.7785 (0.9803)	Acc@1 75.000 (63.680)	Acc@5 93.750 (90.329)
Test: [700/750]	Time 0.033 (0.034)	Loss 1.3506 (0.9939)	Acc@1 53.125 (63.236)	Acc@5 71.875 (90.580)
 * Acc@1 62.808 Acc@5 90.371
==> training...
Epoch: [43][0/875]	Time 1.563 (1.563)	Data 1.217 (1.217)	Loss 3.2228 (3.2228)	Loss@kd 1.9498 (1.9498)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [43][100/875]	Time 0.344 (0.370)	Data 0.007 (0.019)	Loss 3.4063 (3.3120)	Loss@kd 1.9437 (1.9003)	Acc@1 54.688 (61.866)	Acc@5 100.000 (97.741)
Epoch: [43][200/875]	Time 0.347 (0.361)	Data 0.007 (0.013)	Loss 3.4994 (3.3089)	Loss@kd 2.0408 (1.8971)	Acc@1 64.062 (61.940)	Acc@5 95.312 (97.497)
Epoch: [43][300/875]	Time 0.345 (0.346)	Data 0.007 (0.011)	Loss 3.4393 (3.3042)	Loss@kd 1.9761 (1.9004)	Acc@1 60.938 (62.246)	Acc@5 93.750 (97.529)
Epoch: [43][400/875]	Time 0.350 (0.348)	Data 0.007 (0.010)	Loss 3.2654 (3.3086)	Loss@kd 1.9068 (1.9008)	Acc@1 65.625 (62.029)	Acc@5 98.438 (97.491)
Epoch: [43][500/875]	Time 0.358 (0.350)	Data 0.007 (0.009)	Loss 3.3654 (3.3158)	Loss@kd 1.8578 (1.9008)	Acc@1 57.812 (61.574)	Acc@5 98.438 (97.546)
Epoch: [43][600/875]	Time 0.366 (0.351)	Data 0.008 (0.009)	Loss 3.0637 (3.3132)	Loss@kd 1.8657 (1.8998)	Acc@1 71.875 (61.645)	Acc@5 96.875 (97.483)
Epoch: [43][700/875]	Time 0.355 (0.351)	Data 0.009 (0.009)	Loss 3.3451 (3.3121)	Loss@kd 1.9104 (1.8996)	Acc@1 60.938 (61.584)	Acc@5 98.438 (97.495)
Epoch: [43][800/875]	Time 0.349 (0.352)	Data 0.007 (0.009)	Loss 3.0476 (3.3088)	Loss@kd 1.7986 (1.8983)	Acc@1 67.188 (61.702)	Acc@5 98.438 (97.505)
 * Acc@1 61.777 Acc@5 97.486
epoch 43, total time 307.29
