==> loading teacher model
==> done
Test: [0/750]	Time 25.853 (25.853)	Loss 0.5613 (0.5613)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.065 (0.316)	Loss 0.6912 (0.4886)	Acc@1 75.000 (87.098)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.065 (0.187)	Loss 1.2877 (0.4868)	Acc@1 50.000 (85.106)	Acc@5 93.750 (96.253)
Test: [300/750]	Time 0.050 (0.144)	Loss 1.1032 (0.6946)	Acc@1 56.250 (76.412)	Acc@5 93.750 (95.515)
Test: [400/750]	Time 0.054 (0.124)	Loss 0.5579 (0.7766)	Acc@1 84.375 (73.208)	Acc@5 93.750 (94.966)
Test: [500/750]	Time 0.048 (0.111)	Loss 0.4078 (0.7378)	Acc@1 84.375 (75.087)	Acc@5 100.000 (94.966)
Test: [600/750]	Time 0.051 (0.102)	Loss 0.5665 (0.7392)	Acc@1 71.875 (75.151)	Acc@5 96.875 (94.982)
Test: [700/750]	Time 0.041 (0.096)	Loss 1.0252 (0.7310)	Acc@1 68.750 (75.334)	Acc@5 81.250 (95.136)
 * Acc@1 75.533 Acc@5 95.092
teacher accuracy:  tensor(75.5333, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 3.696 (3.696)	Data 1.565 (1.565)	Loss 28.1084 (28.1084)	Loss@kd 36.5042 (36.5042)	Acc@1 10.938 (10.938)	Acc@5 65.625 (65.625)
