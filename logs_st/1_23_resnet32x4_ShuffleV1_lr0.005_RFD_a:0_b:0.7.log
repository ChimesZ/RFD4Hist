==> loading teacher model
==> done
Test: [0/750]	Time 24.862 (24.862)	Loss 0.4924 (0.4924)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.082 (0.340)	Loss 0.4931 (0.7024)	Acc@1 78.125 (84.097)	Acc@5 93.750 (93.998)
Test: [200/750]	Time 0.089 (0.216)	Loss 1.3251 (0.6071)	Acc@1 46.875 (82.789)	Acc@5 90.625 (95.631)
Test: [300/750]	Time 0.088 (0.175)	Loss 1.1155 (0.7770)	Acc@1 71.875 (74.055)	Acc@5 93.750 (95.141)
Test: [400/750]	Time 0.088 (0.153)	Loss 0.5847 (0.8215)	Acc@1 84.375 (71.891)	Acc@5 93.750 (94.701)
Test: [500/750]	Time 0.085 (0.141)	Loss 0.4380 (0.7850)	Acc@1 84.375 (73.696)	Acc@5 100.000 (94.698)
Test: [600/750]	Time 0.087 (0.133)	Loss 0.8076 (0.7933)	Acc@1 75.000 (73.487)	Acc@5 90.625 (94.530)
Test: [700/750]	Time 0.097 (0.127)	Loss 0.9263 (0.7904)	Acc@1 56.250 (73.226)	Acc@5 96.875 (94.651)
 * Acc@1 73.362 Acc@5 94.612
teacher accuracy:  tensor(73.3625, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 3.695 (3.695)	Data 1.533 (1.533)	Loss 22.1812 (22.1812)	Loss@kd 27.3364 (27.3364)	Acc@1 12.500 (12.500)	Acc@5 65.625 (65.625)
Epoch: [1][100/875]	Time 0.685 (0.721)	Data 0.008 (0.022)	Loss 6.7825 (31.1579)	Loss@kd 7.5226 (10.9745)	Acc@1 34.375 (28.852)	Acc@5 96.875 (78.929)
Epoch: [1][200/875]	Time 0.687 (0.705)	Data 0.008 (0.015)	Loss 5.4333 (18.7393)	Loss@kd 5.6590 (8.7757)	Acc@1 50.000 (34.188)	Acc@5 92.188 (84.787)
Epoch: [1][300/875]	Time 0.686 (0.699)	Data 0.008 (0.012)	Loss 5.0228 (14.3621)	Loss@kd 5.3510 (7.7469)	Acc@1 53.125 (36.555)	Acc@5 90.625 (87.002)
Epoch: [1][400/875]	Time 0.694 (0.697)	Data 0.008 (0.011)	Loss 6.6148 (12.0961)	Loss@kd 7.4040 (7.1397)	Acc@1 46.875 (37.792)	Acc@5 93.750 (88.283)
Epoch: [1][500/875]	Time 0.681 (0.695)	Data 0.008 (0.010)	Loss 4.8706 (10.7170)	Loss@kd 5.0103 (6.7515)	Acc@1 54.688 (38.776)	Acc@5 92.188 (88.975)
Epoch: [1][600/875]	Time 0.694 (0.694)	Data 0.007 (0.010)	Loss 5.0997 (9.7808)	Loss@kd 5.3021 (6.4925)	Acc@1 53.125 (39.699)	Acc@5 93.750 (89.728)
Epoch: [1][700/875]	Time 0.760 (0.693)	Data 0.007 (0.010)	Loss 5.3775 (9.0966)	Loss@kd 5.2111 (6.2895)	Acc@1 37.500 (40.609)	Acc@5 93.750 (90.268)
Epoch: [1][800/875]	Time 0.681 (0.692)	Data 0.007 (0.009)	Loss 5.1012 (8.5836)	Loss@kd 4.9987 (6.1338)	Acc@1 37.500 (41.197)	Acc@5 92.188 (90.674)
 * Acc@1 41.580 Acc@5 90.889
epoch 1, total time 606.39
Test: [0/750]	Time 1.733 (1.733)	Loss 2.9109 (2.9109)	Acc@1 15.625 (15.625)	Acc@5 78.125 (78.125)
Test: [100/750]	Time 0.127 (0.149)	Loss 0.7668 (2.6712)	Acc@1 59.375 (20.111)	Acc@5 100.000 (82.550)
Test: [200/750]	Time 0.126 (0.138)	Loss 1.3578 (1.7984)	Acc@1 56.250 (42.289)	Acc@5 90.625 (88.604)
Test: [300/750]	Time 0.126 (0.134)	Loss 2.2036 (1.6656)	Acc@1 18.750 (44.196)	Acc@5 65.625 (88.154)
Test: [400/750]	Time 0.127 (0.131)	Loss 1.8195 (1.7124)	Acc@1 21.875 (38.474)	Acc@5 75.000 (84.320)
Test: [500/750]	Time 0.123 (0.130)	Loss 1.4279 (1.6967)	Acc@1 50.000 (38.205)	Acc@5 87.500 (82.816)
Test: [600/750]	Time 0.115 (0.129)	Loss 0.9099 (1.6446)	Acc@1 62.500 (40.635)	Acc@5 100.000 (83.881)
Test: [700/750]	Time 0.102 (0.129)	Loss 3.1356 (1.6689)	Acc@1 0.000 (39.831)	Acc@5 21.875 (81.665)
 * Acc@1 37.388 Acc@5 78.329
saving the best model!
==> training...
Epoch: [2][0/875]	Time 2.420 (2.420)	Data 1.596 (1.596)	Loss 5.1298 (5.1298)	Loss@kd 4.5556 (4.5556)	Acc@1 34.375 (34.375)	Acc@5 84.375 (84.375)
Epoch: [2][100/875]	Time 0.657 (0.709)	Data 0.006 (0.023)	Loss 4.5794 (4.8514)	Loss@kd 4.6154 (4.8754)	Acc@1 51.562 (46.566)	Acc@5 96.875 (93.936)
Epoch: [2][200/875]	Time 0.680 (0.700)	Data 0.007 (0.015)	Loss 4.5332 (4.8560)	Loss@kd 4.6718 (4.8722)	Acc@1 53.125 (46.238)	Acc@5 93.750 (93.750)
Epoch: [2][300/875]	Time 0.678 (0.696)	Data 0.007 (0.013)	Loss 4.6951 (4.8297)	Loss@kd 4.4559 (4.8348)	Acc@1 42.188 (46.423)	Acc@5 93.750 (93.864)
Epoch: [2][400/875]	Time 0.675 (0.695)	Data 0.007 (0.011)	Loss 5.3165 (4.8042)	Loss@kd 4.6020 (4.7794)	Acc@1 37.500 (46.478)	Acc@5 89.062 (93.734)
Epoch: [2][500/875]	Time 0.679 (0.694)	Data 0.007 (0.011)	Loss 4.5330 (4.7675)	Loss@kd 4.4337 (4.7100)	Acc@1 48.438 (46.526)	Acc@5 93.750 (93.610)
Epoch: [2][600/875]	Time 0.673 (0.694)	Data 0.007 (0.010)	Loss 4.0036 (4.7307)	Loss@kd 4.2116 (4.6485)	Acc@1 64.062 (46.560)	Acc@5 98.438 (93.688)
Epoch: [2][700/875]	Time 0.670 (0.693)	Data 0.007 (0.010)	Loss 4.8158 (4.6883)	Loss@kd 4.2692 (4.5809)	Acc@1 48.438 (46.485)	Acc@5 90.625 (93.714)
Epoch: [2][800/875]	Time 0.688 (0.692)	Data 0.007 (0.009)	Loss 4.5205 (4.6406)	Loss@kd 4.5510 (4.5127)	Acc@1 50.000 (46.502)	Acc@5 95.312 (93.723)
 * Acc@1 46.473 Acc@5 93.745
epoch 2, total time 606.40
Test: [0/750]	Time 1.107 (1.107)	Loss 0.7399 (0.7399)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.115 (0.144)	Loss 0.6143 (0.6432)	Acc@1 84.375 (82.178)	Acc@5 96.875 (87.809)
Test: [200/750]	Time 0.130 (0.135)	Loss 1.9141 (0.6671)	Acc@1 18.750 (78.374)	Acc@5 81.250 (91.309)
Test: [300/750]	Time 0.122 (0.132)	Loss 1.4437 (0.9594)	Acc@1 34.375 (63.154)	Acc@5 87.500 (89.815)
Test: [400/750]	Time 0.094 (0.131)	Loss 1.4396 (1.0884)	Acc@1 37.500 (56.024)	Acc@5 78.125 (89.043)
Test: [500/750]	Time 0.125 (0.130)	Loss 2.0928 (1.1950)	Acc@1 31.250 (53.761)	Acc@5 68.750 (85.710)
Test: [600/750]	Time 0.106 (0.130)	Loss 1.1945 (1.2957)	Acc@1 53.125 (51.835)	Acc@5 90.625 (84.235)
Test: [700/750]	Time 0.117 (0.130)	Loss 1.3274 (1.2794)	Acc@1 50.000 (51.997)	Acc@5 84.375 (85.164)
 * Acc@1 52.558 Acc@5 85.421
saving the best model!
==> training...
Epoch: [3][0/875]	Time 2.290 (2.290)	Data 1.619 (1.619)	Loss 4.0051 (4.0051)	Loss@kd 3.9730 (3.9730)	Acc@1 57.812 (57.812)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.678 (0.702)	Data 0.008 (0.023)	Loss 3.9435 (4.1710)	Loss@kd 3.6771 (3.9843)	Acc@1 50.000 (50.356)	Acc@5 96.875 (94.230)
Epoch: [3][200/875]	Time 0.761 (0.693)	Data 0.007 (0.015)	Loss 4.0900 (4.1355)	Loss@kd 3.6971 (3.9233)	Acc@1 48.438 (49.712)	Acc@5 95.312 (94.325)
Epoch: [3][300/875]	Time 0.679 (0.690)	Data 0.008 (0.013)	Loss 4.0958 (4.1394)	Loss@kd 3.8334 (3.9262)	Acc@1 46.875 (49.621)	Acc@5 92.188 (94.311)
Epoch: [3][400/875]	Time 0.676 (0.689)	Data 0.007 (0.011)	Loss 3.5844 (4.0861)	Loss@kd 3.6888 (3.8773)	Acc@1 64.062 (49.942)	Acc@5 98.438 (94.584)
Epoch: [3][500/875]	Time 0.677 (0.688)	Data 0.007 (0.011)	Loss 4.0084 (4.0528)	Loss@kd 3.5317 (3.8409)	Acc@1 46.875 (50.131)	Acc@5 93.750 (94.629)
Epoch: [3][600/875]	Time 0.672 (0.688)	Data 0.007 (0.010)	Loss 3.7162 (4.0506)	Loss@kd 3.8203 (3.8376)	Acc@1 59.375 (50.146)	Acc@5 98.438 (94.660)
Epoch: [3][700/875]	Time 0.681 (0.688)	Data 0.008 (0.010)	Loss 4.0318 (4.0280)	Loss@kd 3.5547 (3.8204)	Acc@1 40.625 (50.321)	Acc@5 95.312 (94.802)
Epoch: [3][800/875]	Time 0.679 (0.687)	Data 0.007 (0.009)	Loss 4.0614 (4.0092)	Loss@kd 3.7801 (3.8051)	Acc@1 50.000 (50.515)	Acc@5 92.188 (94.920)
 * Acc@1 50.700 Acc@5 95.004
epoch 3, total time 602.28
Test: [0/750]	Time 1.000 (1.000)	Loss 0.9129 (0.9129)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.130 (0.145)	Loss 4.2794 (0.9557)	Acc@1 21.875 (77.630)	Acc@5 37.500 (84.468)
Test: [200/750]	Time 0.119 (0.137)	Loss 1.4111 (2.5975)	Acc@1 25.000 (48.165)	Acc@5 96.875 (60.572)
Test: [300/750]	Time 0.125 (0.133)	Loss 3.0919 (2.3048)	Acc@1 3.125 (40.365)	Acc@5 43.750 (69.643)
Test: [400/750]	Time 0.130 (0.132)	Loss 3.0573 (2.5405)	Acc@1 15.625 (31.881)	Acc@5 50.000 (64.487)
Test: [500/750]	Time 0.126 (0.130)	Loss 0.9762 (2.5097)	Acc@1 65.625 (32.441)	Acc@5 93.750 (64.066)
Test: [600/750]	Time 0.116 (0.129)	Loss 2.8247 (2.4267)	Acc@1 21.875 (34.172)	Acc@5 43.750 (64.798)
Test: [700/750]	Time 0.128 (0.128)	Loss 0.5667 (2.3783)	Acc@1 81.250 (35.913)	Acc@5 96.875 (64.430)
 * Acc@1 39.200 Acc@5 66.692
==> training...
Epoch: [4][0/875]	Time 2.314 (2.314)	Data 1.635 (1.635)	Loss 4.3490 (4.3490)	Loss@kd 4.5436 (4.5436)	Acc@1 64.062 (64.062)	Acc@5 93.750 (93.750)
Epoch: [4][100/875]	Time 0.689 (0.698)	Data 0.007 (0.023)	Loss 3.9173 (3.8172)	Loss@kd 3.4863 (3.6627)	Acc@1 54.688 (52.893)	Acc@5 93.750 (96.040)
Epoch: [4][200/875]	Time 0.676 (0.694)	Data 0.007 (0.015)	Loss 3.8916 (3.8214)	Loss@kd 3.6966 (3.6858)	Acc@1 59.375 (53.397)	Acc@5 95.312 (96.245)
Epoch: [4][300/875]	Time 0.676 (0.692)	Data 0.007 (0.013)	Loss 3.5770 (3.8091)	Loss@kd 3.3312 (3.6789)	Acc@1 45.312 (53.867)	Acc@5 95.312 (96.086)
Epoch: [4][400/875]	Time 0.681 (0.690)	Data 0.007 (0.011)	Loss 3.4929 (3.7947)	Loss@kd 3.4575 (3.6578)	Acc@1 64.062 (53.799)	Acc@5 95.312 (96.076)
Epoch: [4][500/875]	Time 0.682 (0.689)	Data 0.008 (0.011)	Loss 3.5373 (3.7823)	Loss@kd 3.3838 (3.6402)	Acc@1 57.812 (53.777)	Acc@5 92.188 (96.108)
Epoch: [4][600/875]	Time 0.672 (0.689)	Data 0.007 (0.010)	Loss 3.5252 (3.7661)	Loss@kd 3.4028 (3.6219)	Acc@1 56.250 (53.661)	Acc@5 96.875 (96.165)
Epoch: [4][700/875]	Time 0.688 (0.689)	Data 0.007 (0.010)	Loss 3.6144 (3.7521)	Loss@kd 3.5016 (3.6062)	Acc@1 51.562 (53.823)	Acc@5 98.438 (96.137)
Epoch: [4][800/875]	Time 0.664 (0.689)	Data 0.005 (0.009)	Loss 4.2176 (3.7484)	Loss@kd 3.9288 (3.6045)	Acc@1 50.000 (53.843)	Acc@5 92.188 (96.157)
 * Acc@1 53.843 Acc@5 96.205
epoch 4, total time 603.51
Test: [0/750]	Time 0.997 (0.997)	Loss 0.7067 (0.7067)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.180 (0.136)	Loss 0.6223 (0.5392)	Acc@1 87.500 (84.189)	Acc@5 93.750 (89.387)
Test: [200/750]	Time 0.116 (0.131)	Loss 1.5835 (0.6204)	Acc@1 25.000 (80.457)	Acc@5 81.250 (91.091)
Test: [300/750]	Time 0.122 (0.130)	Loss 1.0832 (0.8681)	Acc@1 62.500 (66.487)	Acc@5 100.000 (91.435)
Test: [400/750]	Time 0.122 (0.129)	Loss 1.2993 (0.9545)	Acc@1 65.625 (63.396)	Acc@5 84.375 (91.560)
Test: [500/750]	Time 0.111 (0.128)	Loss 1.0332 (1.0188)	Acc@1 65.625 (62.244)	Acc@5 87.500 (89.502)
Test: [600/750]	Time 0.106 (0.128)	Loss 1.5234 (1.0751)	Acc@1 40.625 (60.399)	Acc@5 78.125 (88.478)
Test: [700/750]	Time 0.133 (0.128)	Loss 1.4364 (1.1336)	Acc@1 31.250 (57.293)	Acc@5 87.500 (87.839)
 * Acc@1 56.646 Acc@5 87.804
saving the best model!
==> training...
Epoch: [5][0/875]	Time 2.331 (2.331)	Data 1.655 (1.655)	Loss 3.3151 (3.3151)	Loss@kd 3.3184 (3.3184)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [5][100/875]	Time 0.682 (0.706)	Data 0.007 (0.024)	Loss 3.5100 (3.6788)	Loss@kd 3.5046 (3.5829)	Acc@1 70.312 (56.033)	Acc@5 100.000 (96.751)
Epoch: [5][200/875]	Time 0.668 (0.698)	Data 0.007 (0.016)	Loss 3.6791 (3.6401)	Loss@kd 3.6708 (3.5183)	Acc@1 62.500 (56.328)	Acc@5 98.438 (96.626)
Epoch: [5][300/875]	Time 0.676 (0.695)	Data 0.008 (0.013)	Loss 3.4988 (3.6216)	Loss@kd 3.4470 (3.4954)	Acc@1 57.812 (56.219)	Acc@5 98.438 (96.647)
Epoch: [5][400/875]	Time 0.665 (0.694)	Data 0.007 (0.012)	Loss 3.6037 (3.6140)	Loss@kd 3.2220 (3.4819)	Acc@1 48.438 (56.118)	Acc@5 93.750 (96.649)
Epoch: [5][500/875]	Time 0.676 (0.693)	Data 0.007 (0.011)	Loss 4.9520 (3.6150)	Loss@kd 5.1527 (3.4826)	Acc@1 57.812 (55.963)	Acc@5 96.875 (96.563)
Epoch: [5][600/875]	Time 0.682 (0.692)	Data 0.007 (0.010)	Loss 3.3695 (3.6182)	Loss@kd 3.2041 (3.4935)	Acc@1 53.125 (56.130)	Acc@5 96.875 (96.612)
Epoch: [5][700/875]	Time 0.673 (0.692)	Data 0.007 (0.010)	Loss 3.5037 (3.6148)	Loss@kd 3.2918 (3.4854)	Acc@1 60.938 (55.985)	Acc@5 93.750 (96.587)
Epoch: [5][800/875]	Time 0.656 (0.692)	Data 0.007 (0.009)	Loss 3.4201 (3.6091)	Loss@kd 3.2529 (3.4804)	Acc@1 56.250 (56.129)	Acc@5 100.000 (96.627)
 * Acc@1 56.120 Acc@5 96.637
epoch 5, total time 605.73
Test: [0/750]	Time 0.989 (0.989)	Loss 0.7299 (0.7299)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.126 (0.143)	Loss 0.4412 (0.5563)	Acc@1 87.500 (82.859)	Acc@5 96.875 (89.666)
Test: [200/750]	Time 0.117 (0.136)	Loss 1.6000 (0.5304)	Acc@1 40.625 (83.551)	Acc@5 87.500 (93.237)
Test: [300/750]	Time 0.116 (0.133)	Loss 2.0216 (0.8480)	Acc@1 6.250 (69.850)	Acc@5 65.625 (91.352)
Test: [400/750]	Time 0.133 (0.133)	Loss 0.5340 (1.0430)	Acc@1 87.500 (60.380)	Acc@5 93.750 (88.186)
Test: [500/750]	Time 0.142 (0.133)	Loss 0.8583 (0.9639)	Acc@1 68.750 (64.652)	Acc@5 93.750 (89.502)
Test: [600/750]	Time 0.123 (0.132)	Loss 1.6600 (1.0092)	Acc@1 25.000 (62.760)	Acc@5 84.375 (89.471)
Test: [700/750]	Time 0.131 (0.132)	Loss 2.0586 (1.1219)	Acc@1 15.625 (57.360)	Acc@5 65.625 (88.075)
 * Acc@1 55.188 Acc@5 86.867
==> training...
Epoch: [6][0/875]	Time 2.310 (2.310)	Data 1.631 (1.631)	Loss 3.7444 (3.7444)	Loss@kd 3.5471 (3.5471)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [6][100/875]	Time 0.715 (0.704)	Data 0.007 (0.023)	Loss 3.6649 (3.5111)	Loss@kd 3.2897 (3.3997)	Acc@1 46.875 (57.178)	Acc@5 95.312 (97.308)
Epoch: [6][200/875]	Time 0.675 (0.694)	Data 0.007 (0.015)	Loss 3.3083 (3.4821)	Loss@kd 3.2105 (3.3635)	Acc@1 65.625 (57.844)	Acc@5 98.438 (97.233)
Epoch: [6][300/875]	Time 0.672 (0.691)	Data 0.008 (0.013)	Loss 3.5598 (3.4779)	Loss@kd 3.3760 (3.3541)	Acc@1 56.250 (57.750)	Acc@5 96.875 (97.026)
Epoch: [6][400/875]	Time 0.668 (0.690)	Data 0.007 (0.011)	Loss 3.2847 (3.4869)	Loss@kd 3.2720 (3.3590)	Acc@1 62.500 (57.567)	Acc@5 98.438 (96.902)
Epoch: [6][500/875]	Time 0.760 (0.690)	Data 0.010 (0.011)	Loss 3.4272 (3.4952)	Loss@kd 3.2266 (3.3716)	Acc@1 60.938 (57.678)	Acc@5 95.312 (96.900)
Epoch: [6][600/875]	Time 0.687 (0.690)	Data 0.008 (0.010)	Loss 3.4385 (3.4971)	Loss@kd 3.5520 (3.3787)	Acc@1 67.188 (57.870)	Acc@5 100.000 (96.883)
Epoch: [6][700/875]	Time 0.687 (0.689)	Data 0.007 (0.010)	Loss 3.4447 (3.5056)	Loss@kd 3.3385 (3.3821)	Acc@1 60.938 (57.529)	Acc@5 96.875 (96.875)
Epoch: [6][800/875]	Time 0.686 (0.689)	Data 0.007 (0.009)	Loss 3.1821 (3.5018)	Loss@kd 3.2359 (3.3758)	Acc@1 60.938 (57.496)	Acc@5 100.000 (96.863)
 * Acc@1 57.686 Acc@5 96.886
epoch 6, total time 603.21
Test: [0/750]	Time 0.930 (0.930)	Loss 0.6444 (0.6444)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.130 (0.139)	Loss 0.5932 (0.6108)	Acc@1 81.250 (79.641)	Acc@5 96.875 (91.244)
Test: [200/750]	Time 0.120 (0.132)	Loss 2.3709 (0.6782)	Acc@1 6.250 (76.632)	Acc@5 59.375 (92.366)
Test: [300/750]	Time 0.123 (0.129)	Loss 1.0316 (1.0477)	Acc@1 71.875 (59.479)	Acc@5 96.875 (88.933)
Test: [400/750]	Time 0.111 (0.128)	Loss 1.1084 (1.0698)	Acc@1 65.625 (59.710)	Acc@5 87.500 (89.830)
Test: [500/750]	Time 0.123 (0.127)	Loss 0.7935 (1.0555)	Acc@1 75.000 (61.440)	Acc@5 93.750 (89.159)
Test: [600/750]	Time 0.113 (0.127)	Loss 1.0648 (1.0541)	Acc@1 59.375 (61.912)	Acc@5 87.500 (89.283)
Test: [700/750]	Time 0.118 (0.127)	Loss 1.3695 (1.0829)	Acc@1 56.250 (59.972)	Acc@5 81.250 (89.261)
 * Acc@1 59.358 Acc@5 89.033
saving the best model!
==> training...
Epoch: [7][0/875]	Time 2.290 (2.290)	Data 1.609 (1.609)	Loss 3.4504 (3.4504)	Loss@kd 3.1930 (3.1930)	Acc@1 51.562 (51.562)	Acc@5 96.875 (96.875)
Epoch: [7][100/875]	Time 0.773 (0.703)	Data 0.007 (0.023)	Loss 3.4658 (3.4095)	Loss@kd 3.6820 (3.3006)	Acc@1 68.750 (58.555)	Acc@5 96.875 (97.308)
Epoch: [7][200/875]	Time 0.680 (0.695)	Data 0.007 (0.016)	Loss 3.3586 (3.4300)	Loss@kd 3.1968 (3.3121)	Acc@1 51.562 (58.341)	Acc@5 96.875 (97.209)
Epoch: [7][300/875]	Time 0.678 (0.692)	Data 0.006 (0.013)	Loss 3.6134 (3.4438)	Loss@kd 3.5281 (3.3322)	Acc@1 57.812 (58.529)	Acc@5 96.875 (97.218)
Epoch: [7][400/875]	Time 0.674 (0.690)	Data 0.008 (0.011)	Loss 3.0601 (3.4412)	Loss@kd 3.0177 (3.3178)	Acc@1 68.750 (58.229)	Acc@5 98.438 (97.105)
Epoch: [7][500/875]	Time 0.671 (0.689)	Data 0.010 (0.011)	Loss 3.2153 (3.4343)	Loss@kd 3.2323 (3.3075)	Acc@1 68.750 (58.087)	Acc@5 96.875 (97.118)
Epoch: [7][600/875]	Time 0.672 (0.689)	Data 0.007 (0.010)	Loss 4.2284 (3.4262)	Loss@kd 3.9453 (3.3016)	Acc@1 48.438 (58.109)	Acc@5 92.188 (97.138)
Epoch: [7][700/875]	Time 0.678 (0.688)	Data 0.007 (0.010)	Loss 3.6384 (3.4258)	Loss@kd 3.3911 (3.2984)	Acc@1 54.688 (58.096)	Acc@5 92.188 (97.087)
Epoch: [7][800/875]	Time 0.671 (0.688)	Data 0.007 (0.009)	Loss 3.4497 (3.4245)	Loss@kd 3.3964 (3.2959)	Acc@1 67.188 (58.166)	Acc@5 100.000 (97.068)
 * Acc@1 58.271 Acc@5 97.068
epoch 7, total time 602.42
Test: [0/750]	Time 0.928 (0.928)	Loss 0.7974 (0.7974)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.123 (0.141)	Loss 0.4658 (0.6827)	Acc@1 81.250 (80.538)	Acc@5 100.000 (88.645)
Test: [200/750]	Time 0.123 (0.135)	Loss 1.6343 (0.6228)	Acc@1 28.125 (80.877)	Acc@5 90.625 (92.724)
Test: [300/750]	Time 0.117 (0.134)	Loss 1.2158 (0.8697)	Acc@1 40.625 (68.750)	Acc@5 93.750 (91.923)
Test: [400/750]	Time 0.130 (0.133)	Loss 0.9200 (0.9652)	Acc@1 75.000 (63.568)	Acc@5 87.500 (91.506)
Test: [500/750]	Time 0.201 (0.132)	Loss 0.9087 (0.9545)	Acc@1 68.750 (64.808)	Acc@5 87.500 (90.506)
Test: [600/750]	Time 0.128 (0.132)	Loss 1.1133 (0.9831)	Acc@1 62.500 (64.091)	Acc@5 90.625 (90.261)
Test: [700/750]	Time 0.123 (0.132)	Loss 1.3263 (1.0261)	Acc@1 40.625 (62.023)	Acc@5 84.375 (90.041)
 * Acc@1 61.617 Acc@5 89.796
saving the best model!
==> training...
Epoch: [8][0/875]	Time 2.279 (2.279)	Data 1.591 (1.591)	Loss 3.4902 (3.4902)	Loss@kd 3.6893 (3.6893)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [8][100/875]	Time 0.759 (0.706)	Data 0.007 (0.023)	Loss 3.1897 (3.3692)	Loss@kd 2.9635 (3.2290)	Acc@1 62.500 (58.168)	Acc@5 93.750 (97.014)
Epoch: [8][200/875]	Time 0.756 (0.698)	Data 0.007 (0.015)	Loss 3.3749 (3.3671)	Loss@kd 3.0390 (3.2384)	Acc@1 53.125 (58.551)	Acc@5 95.312 (97.054)
Epoch: [8][300/875]	Time 0.756 (0.695)	Data 0.007 (0.013)	Loss 3.3917 (3.3682)	Loss@kd 3.2180 (3.2346)	Acc@1 59.375 (58.477)	Acc@5 98.438 (97.062)
Epoch: [8][400/875]	Time 0.783 (0.693)	Data 0.008 (0.011)	Loss 3.2045 (3.3583)	Loss@kd 3.1181 (3.2294)	Acc@1 59.375 (58.802)	Acc@5 95.312 (97.035)
Epoch: [8][500/875]	Time 0.730 (0.692)	Data 0.007 (0.011)	Loss 3.3357 (3.3578)	Loss@kd 3.2172 (3.2334)	Acc@1 57.812 (58.888)	Acc@5 95.312 (97.047)
Epoch: [8][600/875]	Time 0.738 (0.691)	Data 0.007 (0.010)	Loss 3.2448 (3.3559)	Loss@kd 3.1614 (3.2326)	Acc@1 54.688 (58.988)	Acc@5 98.438 (97.140)
Epoch: [8][700/875]	Time 0.774 (0.691)	Data 0.007 (0.010)	Loss 3.2252 (3.3518)	Loss@kd 3.1368 (3.2289)	Acc@1 64.062 (58.994)	Acc@5 98.438 (97.163)
Epoch: [8][800/875]	Time 0.775 (0.691)	Data 0.008 (0.009)	Loss 3.0638 (3.3562)	Loss@kd 3.1473 (3.2337)	Acc@1 65.625 (59.069)	Acc@5 100.000 (97.146)
 * Acc@1 59.111 Acc@5 97.155
epoch 8, total time 604.91
Test: [0/750]	Time 1.002 (1.002)	Loss 0.5551 (0.5551)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.123 (0.138)	Loss 0.7342 (0.5081)	Acc@1 78.125 (83.571)	Acc@5 96.875 (91.739)
Test: [200/750]	Time 0.119 (0.132)	Loss 1.9528 (0.6263)	Acc@1 18.750 (76.959)	Acc@5 78.125 (93.548)
Test: [300/750]	Time 0.114 (0.130)	Loss 1.0316 (0.9221)	Acc@1 65.625 (62.801)	Acc@5 100.000 (91.580)
Test: [400/750]	Time 0.138 (0.129)	Loss 0.9822 (0.9605)	Acc@1 68.750 (61.822)	Acc@5 87.500 (92.098)
Test: [500/750]	Time 0.114 (0.128)	Loss 0.7308 (0.9551)	Acc@1 78.125 (63.716)	Acc@5 90.625 (91.224)
Test: [600/750]	Time 0.114 (0.127)	Loss 0.8128 (0.9495)	Acc@1 71.875 (64.751)	Acc@5 93.750 (91.369)
Test: [700/750]	Time 0.113 (0.127)	Loss 2.0373 (0.9960)	Acc@1 28.125 (63.022)	Acc@5 68.750 (90.589)
 * Acc@1 61.296 Acc@5 89.375
==> training...
Epoch: [9][0/875]	Time 2.304 (2.304)	Data 1.614 (1.614)	Loss 3.7331 (3.7331)	Loss@kd 3.7783 (3.7783)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [9][100/875]	Time 0.674 (0.704)	Data 0.009 (0.023)	Loss 3.3690 (3.3041)	Loss@kd 3.2447 (3.1935)	Acc@1 59.375 (59.886)	Acc@5 96.875 (97.324)
Epoch: [9][200/875]	Time 0.665 (0.695)	Data 0.007 (0.015)	Loss 3.0908 (3.3095)	Loss@kd 3.1151 (3.1929)	Acc@1 64.062 (59.756)	Acc@5 100.000 (97.139)
Epoch: [9][300/875]	Time 0.680 (0.692)	Data 0.007 (0.013)	Loss 3.4322 (3.3033)	Loss@kd 3.3025 (3.1857)	Acc@1 57.812 (59.858)	Acc@5 100.000 (97.212)
Epoch: [9][400/875]	Time 0.669 (0.691)	Data 0.007 (0.011)	Loss 3.3605 (3.3143)	Loss@kd 3.0202 (3.1923)	Acc@1 50.000 (59.554)	Acc@5 100.000 (97.167)
Epoch: [9][500/875]	Time 0.682 (0.690)	Data 0.007 (0.011)	Loss 3.2665 (3.3123)	Loss@kd 3.2366 (3.1889)	Acc@1 68.750 (59.568)	Acc@5 98.438 (97.224)
Epoch: [9][600/875]	Time 0.676 (0.689)	Data 0.008 (0.010)	Loss 3.2392 (3.3123)	Loss@kd 3.1614 (3.1905)	Acc@1 59.375 (59.531)	Acc@5 96.875 (97.296)
Epoch: [9][700/875]	Time 0.674 (0.689)	Data 0.008 (0.010)	Loss 3.4088 (3.3067)	Loss@kd 3.1647 (3.1840)	Acc@1 54.688 (59.571)	Acc@5 95.312 (97.319)
Epoch: [9][800/875]	Time 0.680 (0.687)	Data 0.008 (0.009)	Loss 3.2373 (3.3011)	Loss@kd 3.1967 (3.1775)	Acc@1 64.062 (59.666)	Acc@5 98.438 (97.302)
 * Acc@1 59.648 Acc@5 97.330
epoch 9, total time 602.09
Test: [0/750]	Time 1.010 (1.010)	Loss 0.7337 (0.7337)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.133 (0.146)	Loss 0.6016 (0.6668)	Acc@1 84.375 (81.590)	Acc@5 96.875 (88.243)
Test: [200/750]	Time 0.123 (0.136)	Loss 1.6123 (0.7050)	Acc@1 37.500 (76.912)	Acc@5 84.375 (91.107)
Test: [300/750]	Time 0.116 (0.132)	Loss 1.4472 (0.9195)	Acc@1 34.375 (66.040)	Acc@5 87.500 (91.196)
Test: [400/750]	Time 0.115 (0.131)	Loss 0.8992 (1.0272)	Acc@1 71.875 (59.928)	Acc@5 90.625 (90.430)
Test: [500/750]	Time 0.182 (0.130)	Loss 0.7144 (1.0050)	Acc@1 78.125 (61.970)	Acc@5 90.625 (89.852)
Test: [600/750]	Time 0.102 (0.129)	Loss 0.8687 (0.9995)	Acc@1 68.750 (62.984)	Acc@5 87.500 (89.881)
Test: [700/750]	Time 0.092 (0.128)	Loss 1.1663 (0.9962)	Acc@1 50.000 (62.928)	Acc@5 87.500 (90.389)
 * Acc@1 63.104 Acc@5 90.479
saving the best model!
==> training...
Epoch: [10][0/875]	Time 2.438 (2.438)	Data 1.606 (1.606)	Loss 3.0685 (3.0685)	Loss@kd 3.0097 (3.0097)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [10][100/875]	Time 0.794 (0.709)	Data 0.007 (0.023)	Loss 3.4254 (3.2792)	Loss@kd 3.3842 (3.1522)	Acc@1 62.500 (59.669)	Acc@5 100.000 (97.602)
Epoch: [10][200/875]	Time 0.766 (0.698)	Data 0.008 (0.015)	Loss 2.9928 (3.2623)	Loss@kd 2.9720 (3.1350)	Acc@1 65.625 (59.849)	Acc@5 100.000 (97.404)
Epoch: [10][300/875]	Time 0.735 (0.694)	Data 0.007 (0.013)	Loss 3.1713 (3.2608)	Loss@kd 2.9749 (3.1378)	Acc@1 54.688 (59.879)	Acc@5 98.438 (97.420)
Epoch: [10][400/875]	Time 0.757 (0.693)	Data 0.007 (0.011)	Loss 3.0491 (3.2564)	Loss@kd 2.9297 (3.1274)	Acc@1 60.938 (59.862)	Acc@5 95.312 (97.378)
Epoch: [10][500/875]	Time 0.768 (0.692)	Data 0.007 (0.010)	Loss 3.3317 (3.2545)	Loss@kd 3.1487 (3.1236)	Acc@1 62.500 (59.827)	Acc@5 96.875 (97.446)
Epoch: [10][600/875]	Time 0.728 (0.691)	Data 0.007 (0.010)	Loss 3.3349 (3.2497)	Loss@kd 3.1758 (3.1186)	Acc@1 57.812 (59.994)	Acc@5 95.312 (97.416)
Epoch: [10][700/875]	Time 0.787 (0.691)	Data 0.007 (0.010)	Loss 3.1481 (3.2464)	Loss@kd 3.0793 (3.1159)	Acc@1 70.312 (60.137)	Acc@5 93.750 (97.457)
Epoch: [10][800/875]	Time 0.765 (0.690)	Data 0.006 (0.009)	Loss 3.3255 (3.2442)	Loss@kd 3.0951 (3.1156)	Acc@1 56.250 (60.093)	Acc@5 98.438 (97.493)
 * Acc@1 60.177 Acc@5 97.493
epoch 10, total time 604.32
Test: [0/750]	Time 0.977 (0.977)	Loss 0.6518 (0.6518)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.101 (0.141)	Loss 0.5434 (0.5771)	Acc@1 84.375 (82.147)	Acc@5 96.875 (89.449)
Test: [200/750]	Time 0.187 (0.133)	Loss 1.5111 (0.5787)	Acc@1 40.625 (80.271)	Acc@5 84.375 (93.284)
Test: [300/750]	Time 0.127 (0.130)	Loss 1.3120 (0.7997)	Acc@1 37.500 (70.629)	Acc@5 96.875 (93.262)
Test: [400/750]	Time 0.125 (0.128)	Loss 0.6863 (0.9111)	Acc@1 81.250 (64.931)	Acc@5 93.750 (92.636)
Test: [500/750]	Time 0.117 (0.127)	Loss 1.0288 (0.8992)	Acc@1 68.750 (66.848)	Acc@5 90.625 (91.816)
Test: [600/750]	Time 0.122 (0.127)	Loss 0.7146 (0.9370)	Acc@1 81.250 (66.275)	Acc@5 96.875 (91.249)
Test: [700/750]	Time 0.116 (0.126)	Loss 1.6391 (0.9794)	Acc@1 28.125 (63.949)	Acc@5 84.375 (91.089)
 * Acc@1 62.008 Acc@5 90.554
==> training...
Epoch: [11][0/875]	Time 2.257 (2.257)	Data 1.609 (1.609)	Loss 3.1360 (3.1360)	Loss@kd 3.1002 (3.1002)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [11][100/875]	Time 0.659 (0.702)	Data 0.006 (0.023)	Loss 3.2506 (3.2058)	Loss@kd 3.1204 (3.0639)	Acc@1 60.938 (60.427)	Acc@5 100.000 (97.014)
Epoch: [11][200/875]	Time 0.672 (0.688)	Data 0.007 (0.015)	Loss 3.0399 (3.2138)	Loss@kd 2.9029 (3.0713)	Acc@1 60.938 (60.362)	Acc@5 98.438 (97.225)
Epoch: [11][300/875]	Time 0.664 (0.685)	Data 0.007 (0.012)	Loss 2.9605 (3.2024)	Loss@kd 2.9226 (3.0666)	Acc@1 64.062 (60.771)	Acc@5 98.438 (97.327)
Epoch: [11][400/875]	Time 0.665 (0.683)	Data 0.007 (0.011)	Loss 3.1245 (3.1971)	Loss@kd 3.0076 (3.0687)	Acc@1 60.938 (60.739)	Acc@5 100.000 (97.401)
Epoch: [11][500/875]	Time 0.660 (0.682)	Data 0.007 (0.010)	Loss 3.2345 (3.1991)	Loss@kd 3.1262 (3.0716)	Acc@1 56.250 (60.716)	Acc@5 100.000 (97.436)
Epoch: [11][600/875]	Time 0.680 (0.683)	Data 0.007 (0.010)	Loss 3.3966 (3.2082)	Loss@kd 3.4295 (3.0793)	Acc@1 64.062 (60.610)	Acc@5 96.875 (97.452)
Epoch: [11][700/875]	Time 0.690 (0.685)	Data 0.007 (0.010)	Loss 2.9585 (3.2071)	Loss@kd 2.7785 (3.0799)	Acc@1 67.188 (60.708)	Acc@5 98.438 (97.479)
Epoch: [11][800/875]	Time 0.677 (0.686)	Data 0.008 (0.009)	Loss 3.0366 (3.1968)	Loss@kd 2.9348 (3.0708)	Acc@1 65.625 (60.797)	Acc@5 100.000 (97.544)
 * Acc@1 60.848 Acc@5 97.532
epoch 11, total time 601.01
Test: [0/750]	Time 1.004 (1.004)	Loss 0.5813 (0.5813)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.118 (0.138)	Loss 0.5570 (0.5912)	Acc@1 78.125 (82.054)	Acc@5 100.000 (90.470)
Test: [200/750]	Time 0.128 (0.132)	Loss 2.0023 (0.6393)	Acc@1 28.125 (77.596)	Acc@5 68.750 (93.128)
Test: [300/750]	Time 0.092 (0.130)	Loss 1.6085 (0.9380)	Acc@1 37.500 (64.753)	Acc@5 87.500 (91.580)
Test: [400/750]	Time 0.191 (0.129)	Loss 0.8610 (1.0783)	Acc@1 68.750 (57.933)	Acc@5 87.500 (90.773)
Test: [500/750]	Time 0.106 (0.129)	Loss 1.0310 (1.0675)	Acc@1 62.500 (59.631)	Acc@5 87.500 (89.808)
Test: [600/750]	Time 0.117 (0.129)	Loss 0.5331 (1.0641)	Acc@1 84.375 (60.821)	Acc@5 96.875 (89.653)
Test: [700/750]	Time 0.126 (0.129)	Loss 1.1998 (1.0286)	Acc@1 53.125 (62.175)	Acc@5 81.250 (90.277)
 * Acc@1 62.650 Acc@5 90.258
==> training...
Epoch: [12][0/875]	Time 2.276 (2.276)	Data 1.606 (1.606)	Loss 3.2635 (3.2635)	Loss@kd 2.8584 (2.8584)	Acc@1 51.562 (51.562)	Acc@5 98.438 (98.438)
Epoch: [12][100/875]	Time 0.685 (0.709)	Data 0.008 (0.023)	Loss 3.2755 (3.1367)	Loss@kd 3.1327 (3.0153)	Acc@1 57.812 (61.417)	Acc@5 96.875 (97.509)
Epoch: [12][200/875]	Time 0.671 (0.701)	Data 0.006 (0.015)	Loss 3.1420 (3.1572)	Loss@kd 3.0327 (3.0368)	Acc@1 60.938 (61.280)	Acc@5 98.438 (97.613)
Epoch: [12][300/875]	Time 0.670 (0.698)	Data 0.007 (0.013)	Loss 3.0563 (3.1547)	Loss@kd 2.8848 (3.0359)	Acc@1 64.062 (61.415)	Acc@5 92.188 (97.602)
Epoch: [12][400/875]	Time 0.686 (0.696)	Data 0.007 (0.011)	Loss 3.1985 (3.1571)	Loss@kd 3.0621 (3.0343)	Acc@1 57.812 (61.280)	Acc@5 100.000 (97.565)
Epoch: [12][500/875]	Time 0.684 (0.695)	Data 0.008 (0.011)	Loss 2.9002 (3.1552)	Loss@kd 2.9293 (3.0343)	Acc@1 70.312 (61.324)	Acc@5 98.438 (97.608)
Epoch: [12][600/875]	Time 0.671 (0.694)	Data 0.007 (0.010)	Loss 3.2656 (3.1550)	Loss@kd 2.9565 (3.0284)	Acc@1 57.812 (61.221)	Acc@5 98.438 (97.647)
Epoch: [12][700/875]	Time 0.687 (0.694)	Data 0.007 (0.010)	Loss 3.1087 (3.1480)	Loss@kd 2.8886 (3.0202)	Acc@1 57.812 (61.316)	Acc@5 100.000 (97.628)
Epoch: [12][800/875]	Time 0.684 (0.694)	Data 0.007 (0.009)	Loss 3.3839 (3.1459)	Loss@kd 3.0273 (3.0172)	Acc@1 57.812 (61.359)	Acc@5 96.875 (97.589)
 * Acc@1 61.321 Acc@5 97.591
epoch 12, total time 607.39
Test: [0/750]	Time 1.006 (1.006)	Loss 0.7633 (0.7633)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.129 (0.140)	Loss 0.4934 (0.7367)	Acc@1 81.250 (80.167)	Acc@5 100.000 (89.047)
Test: [200/750]	Time 0.114 (0.134)	Loss 1.9151 (0.6940)	Acc@1 25.000 (77.612)	Acc@5 81.250 (92.646)
Test: [300/750]	Time 0.135 (0.130)	Loss 1.8971 (1.0120)	Acc@1 12.500 (62.760)	Acc@5 78.125 (90.345)
Test: [400/750]	Time 0.187 (0.128)	Loss 0.9556 (1.1929)	Acc@1 65.625 (54.387)	Acc@5 90.625 (87.570)
Test: [500/750]	Time 0.127 (0.128)	Loss 0.6318 (1.1335)	Acc@1 78.125 (57.410)	Acc@5 96.875 (87.980)
Test: [600/750]	Time 0.134 (0.127)	Loss 0.7116 (1.0822)	Acc@1 81.250 (60.108)	Acc@5 96.875 (88.914)
Test: [700/750]	Time 0.133 (0.127)	Loss 0.9324 (1.0414)	Acc@1 78.125 (61.791)	Acc@5 87.500 (89.836)
 * Acc@1 62.642 Acc@5 90.037
==> training...
Epoch: [13][0/875]	Time 2.262 (2.262)	Data 1.588 (1.588)	Loss 3.1798 (3.1798)	Loss@kd 2.8914 (2.8914)	Acc@1 56.250 (56.250)	Acc@5 100.000 (100.000)
Epoch: [13][100/875]	Time 0.683 (0.708)	Data 0.008 (0.023)	Loss 3.1219 (3.0867)	Loss@kd 2.9748 (2.9605)	Acc@1 57.812 (62.299)	Acc@5 98.438 (97.834)
Epoch: [13][200/875]	Time 0.678 (0.700)	Data 0.007 (0.015)	Loss 3.2715 (3.0955)	Loss@kd 3.1602 (2.9728)	Acc@1 57.812 (62.096)	Acc@5 98.438 (97.707)
Epoch: [13][300/875]	Time 0.689 (0.697)	Data 0.008 (0.013)	Loss 3.3029 (3.1026)	Loss@kd 3.4623 (2.9824)	Acc@1 65.625 (61.919)	Acc@5 98.438 (97.747)
Epoch: [13][400/875]	Time 0.671 (0.696)	Data 0.007 (0.011)	Loss 3.4807 (3.1200)	Loss@kd 3.2726 (2.9946)	Acc@1 54.688 (61.647)	Acc@5 95.312 (97.666)
Epoch: [13][500/875]	Time 0.662 (0.695)	Data 0.007 (0.011)	Loss 3.1580 (3.1148)	Loss@kd 2.8908 (2.9906)	Acc@1 59.375 (61.730)	Acc@5 98.438 (97.705)
Epoch: [13][600/875]	Time 0.675 (0.694)	Data 0.007 (0.010)	Loss 3.3703 (3.1135)	Loss@kd 3.0642 (2.9884)	Acc@1 56.250 (61.697)	Acc@5 96.875 (97.717)
Epoch: [13][700/875]	Time 0.677 (0.693)	Data 0.008 (0.010)	Loss 2.8997 (3.1086)	Loss@kd 2.8805 (2.9842)	Acc@1 68.750 (61.718)	Acc@5 100.000 (97.729)
Epoch: [13][800/875]	Time 0.682 (0.693)	Data 0.007 (0.009)	Loss 2.8312 (3.1055)	Loss@kd 2.8296 (2.9776)	Acc@1 65.625 (61.636)	Acc@5 98.438 (97.675)
 * Acc@1 61.575 Acc@5 97.695
epoch 13, total time 606.65
Test: [0/750]	Time 1.012 (1.012)	Loss 0.6182 (0.6182)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.123 (0.144)	Loss 0.6769 (0.5275)	Acc@1 78.125 (84.004)	Acc@5 100.000 (91.522)
Test: [200/750]	Time 0.116 (0.138)	Loss 1.8020 (0.6631)	Acc@1 37.500 (76.539)	Acc@5 75.000 (93.206)
Test: [300/750]	Time 0.119 (0.134)	Loss 1.4924 (0.9419)	Acc@1 31.250 (64.556)	Acc@5 93.750 (91.030)
Test: [400/750]	Time 0.104 (0.133)	Loss 0.8964 (1.0652)	Acc@1 62.500 (57.489)	Acc@5 84.375 (90.391)
Test: [500/750]	Time 0.137 (0.132)	Loss 0.8836 (1.0400)	Acc@1 75.000 (59.799)	Acc@5 87.500 (89.777)
Test: [600/750]	Time 0.122 (0.132)	Loss 0.6409 (1.0244)	Acc@1 84.375 (61.247)	Acc@5 93.750 (90.017)
Test: [700/750]	Time 0.131 (0.132)	Loss 0.9786 (0.9932)	Acc@1 65.625 (62.794)	Acc@5 87.500 (90.589)
 * Acc@1 63.438 Acc@5 90.787
saving the best model!
==> training...
Epoch: [14][0/875]	Time 2.267 (2.267)	Data 1.597 (1.597)	Loss 3.1522 (3.1522)	Loss@kd 2.9468 (2.9468)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
Epoch: [14][100/875]	Time 0.679 (0.702)	Data 0.007 (0.023)	Loss 2.9242 (3.0913)	Loss@kd 2.8715 (2.9714)	Acc@1 65.625 (62.299)	Acc@5 96.875 (97.772)
Epoch: [14][200/875]	Time 0.711 (0.695)	Data 0.008 (0.015)	Loss 3.1118 (3.0722)	Loss@kd 2.9859 (2.9533)	Acc@1 59.375 (62.135)	Acc@5 100.000 (97.878)
Epoch: [14][300/875]	Time 0.679 (0.692)	Data 0.007 (0.013)	Loss 2.9695 (3.0675)	Loss@kd 2.8534 (2.9447)	Acc@1 64.062 (62.080)	Acc@5 96.875 (97.861)
Epoch: [14][400/875]	Time 0.681 (0.691)	Data 0.007 (0.011)	Loss 3.1990 (3.0706)	Loss@kd 2.9743 (2.9421)	Acc@1 59.375 (62.009)	Acc@5 96.875 (97.814)
Epoch: [14][500/875]	Time 0.681 (0.689)	Data 0.007 (0.011)	Loss 3.2395 (3.0701)	Loss@kd 2.8791 (2.9413)	Acc@1 57.812 (62.066)	Acc@5 100.000 (97.808)
Epoch: [14][600/875]	Time 0.652 (0.689)	Data 0.005 (0.010)	Loss 3.0292 (3.0686)	Loss@kd 2.8959 (2.9380)	Acc@1 60.938 (61.988)	Acc@5 96.875 (97.803)
Epoch: [14][700/875]	Time 0.758 (0.688)	Data 0.007 (0.010)	Loss 3.0127 (3.0685)	Loss@kd 2.9839 (2.9404)	Acc@1 64.062 (62.072)	Acc@5 100.000 (97.811)
Epoch: [14][800/875]	Time 0.667 (0.687)	Data 0.007 (0.009)	Loss 3.1181 (3.0665)	Loss@kd 2.8866 (2.9380)	Acc@1 56.250 (62.034)	Acc@5 96.875 (97.796)
 * Acc@1 62.046 Acc@5 97.812
epoch 14, total time 602.10
Test: [0/750]	Time 1.030 (1.030)	Loss 0.7011 (0.7011)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.122 (0.139)	Loss 0.6302 (0.6729)	Acc@1 71.875 (81.621)	Acc@5 100.000 (90.656)
Test: [200/750]	Time 0.134 (0.136)	Loss 2.2176 (0.7511)	Acc@1 15.625 (73.865)	Acc@5 75.000 (92.149)
Test: [300/750]	Time 0.115 (0.134)	Loss 1.1465 (1.0935)	Acc@1 59.375 (57.922)	Acc@5 96.875 (88.061)
Test: [400/750]	Time 0.132 (0.134)	Loss 1.0019 (1.0995)	Acc@1 59.375 (57.255)	Acc@5 87.500 (89.542)
Test: [500/750]	Time 0.127 (0.134)	Loss 0.8633 (1.0679)	Acc@1 71.875 (59.512)	Acc@5 90.625 (89.159)
Test: [600/750]	Time 0.117 (0.133)	Loss 0.6014 (1.0456)	Acc@1 78.125 (61.304)	Acc@5 93.750 (89.320)
Test: [700/750]	Time 0.134 (0.133)	Loss 0.9972 (1.0149)	Acc@1 56.250 (62.562)	Acc@5 81.250 (89.974)
 * Acc@1 63.008 Acc@5 90.046
==> training...
Epoch: [15][0/875]	Time 2.276 (2.276)	Data 1.604 (1.604)	Loss 3.0930 (3.0930)	Loss@kd 2.9815 (2.9815)	Acc@1 56.250 (56.250)	Acc@5 95.312 (95.312)
Epoch: [15][100/875]	Time 0.685 (0.699)	Data 0.007 (0.023)	Loss 3.0017 (3.0381)	Loss@kd 2.9528 (2.9065)	Acc@1 62.500 (62.252)	Acc@5 98.438 (97.865)
Epoch: [15][200/875]	Time 0.688 (0.692)	Data 0.007 (0.015)	Loss 3.1264 (3.0464)	Loss@kd 2.8661 (2.9126)	Acc@1 59.375 (62.127)	Acc@5 100.000 (97.831)
Epoch: [15][300/875]	Time 0.672 (0.690)	Data 0.007 (0.013)	Loss 2.8803 (3.0490)	Loss@kd 2.8737 (2.9156)	Acc@1 67.188 (62.324)	Acc@5 100.000 (97.799)
Epoch: [15][400/875]	Time 0.671 (0.688)	Data 0.007 (0.011)	Loss 3.1336 (3.0403)	Loss@kd 2.9594 (2.9071)	Acc@1 54.688 (62.527)	Acc@5 98.438 (97.767)
Epoch: [15][500/875]	Time 0.783 (0.688)	Data 0.008 (0.011)	Loss 3.3365 (3.0391)	Loss@kd 3.3566 (2.9117)	Acc@1 59.375 (62.634)	Acc@5 100.000 (97.789)
Epoch: [15][600/875]	Time 0.671 (0.687)	Data 0.007 (0.010)	Loss 2.9510 (3.0414)	Loss@kd 2.7732 (2.9071)	Acc@1 59.375 (62.477)	Acc@5 96.875 (97.801)
Epoch: [15][700/875]	Time 0.677 (0.687)	Data 0.007 (0.010)	Loss 3.0453 (3.0370)	Loss@kd 2.8343 (2.9060)	Acc@1 62.500 (62.647)	Acc@5 95.312 (97.836)
Epoch: [15][800/875]	Time 0.707 (0.686)	Data 0.007 (0.009)	Loss 3.0472 (3.0330)	Loss@kd 2.8457 (2.9012)	Acc@1 54.688 (62.627)	Acc@5 96.875 (97.829)
 * Acc@1 62.686 Acc@5 97.857
epoch 15, total time 600.82
Test: [0/750]	Time 1.010 (1.010)	Loss 0.8124 (0.8124)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.123 (0.141)	Loss 0.5180 (0.8019)	Acc@1 84.375 (80.972)	Acc@5 96.875 (89.078)
Test: [200/750]	Time 0.112 (0.135)	Loss 1.4651 (0.6850)	Acc@1 34.375 (80.426)	Acc@5 90.625 (92.600)
Test: [300/750]	Time 0.126 (0.132)	Loss 1.0833 (0.8838)	Acc@1 65.625 (68.200)	Acc@5 93.750 (92.878)
Test: [400/750]	Time 0.121 (0.130)	Loss 0.9307 (0.9427)	Acc@1 65.625 (65.228)	Acc@5 90.625 (92.737)
Test: [500/750]	Time 0.113 (0.130)	Loss 1.0760 (0.9597)	Acc@1 56.250 (65.301)	Acc@5 81.250 (91.124)
Test: [600/750]	Time 0.117 (0.128)	Loss 1.0230 (0.9943)	Acc@1 62.500 (64.502)	Acc@5 84.375 (90.240)
Test: [700/750]	Time 0.119 (0.128)	Loss 1.0869 (1.0134)	Acc@1 56.250 (63.280)	Acc@5 84.375 (90.358)
 * Acc@1 63.400 Acc@5 90.704
==> training...
Epoch: [16][0/875]	Time 2.275 (2.275)	Data 1.613 (1.613)	Loss 2.9949 (2.9949)	Loss@kd 2.9399 (2.9399)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [16][100/875]	Time 0.676 (0.703)	Data 0.007 (0.023)	Loss 3.2740 (3.0522)	Loss@kd 2.8946 (2.9319)	Acc@1 59.375 (62.392)	Acc@5 93.750 (97.803)
Epoch: [16][200/875]	Time 0.681 (0.692)	Data 0.007 (0.015)	Loss 2.8918 (3.0334)	Loss@kd 2.7090 (2.8998)	Acc@1 64.062 (62.422)	Acc@5 100.000 (97.854)
Epoch: [16][300/875]	Time 0.665 (0.690)	Data 0.008 (0.013)	Loss 3.1307 (3.0151)	Loss@kd 2.8781 (2.8827)	Acc@1 60.938 (62.687)	Acc@5 96.875 (97.841)
Epoch: [16][400/875]	Time 0.690 (0.688)	Data 0.007 (0.011)	Loss 3.2744 (3.0098)	Loss@kd 2.9753 (2.8770)	Acc@1 64.062 (62.707)	Acc@5 96.875 (97.869)
Epoch: [16][500/875]	Time 0.686 (0.687)	Data 0.008 (0.011)	Loss 2.8154 (3.0005)	Loss@kd 2.8044 (2.8696)	Acc@1 62.500 (62.874)	Acc@5 100.000 (97.914)
Epoch: [16][600/875]	Time 0.682 (0.687)	Data 0.007 (0.010)	Loss 2.9001 (2.9986)	Loss@kd 2.8319 (2.8691)	Acc@1 60.938 (62.971)	Acc@5 98.438 (97.951)
Epoch: [16][700/875]	Time 0.683 (0.687)	Data 0.007 (0.010)	Loss 3.0624 (2.9941)	Loss@kd 2.9334 (2.8626)	Acc@1 65.625 (62.926)	Acc@5 100.000 (97.936)
Epoch: [16][800/875]	Time 0.676 (0.687)	Data 0.007 (0.009)	Loss 2.9126 (2.9952)	Loss@kd 2.6964 (2.8637)	Acc@1 62.500 (62.888)	Acc@5 95.312 (97.936)
 * Acc@1 62.902 Acc@5 97.911
epoch 16, total time 601.36
Test: [0/750]	Time 1.110 (1.110)	Loss 0.7145 (0.7145)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.136 (0.141)	Loss 0.4910 (0.6102)	Acc@1 75.000 (82.550)	Acc@5 100.000 (92.450)
Test: [200/750]	Time 0.114 (0.136)	Loss 1.8003 (0.6601)	Acc@1 34.375 (77.799)	Acc@5 75.000 (93.781)
Test: [300/750]	Time 0.136 (0.133)	Loss 1.8084 (0.9926)	Acc@1 15.625 (63.382)	Acc@5 78.125 (90.054)
Test: [400/750]	Time 0.119 (0.131)	Loss 0.5942 (1.1329)	Acc@1 84.375 (57.863)	Acc@5 93.750 (87.219)
Test: [500/750]	Time 0.123 (0.130)	Loss 0.5062 (1.0319)	Acc@1 87.500 (62.537)	Acc@5 100.000 (88.448)
Test: [600/750]	Time 0.111 (0.129)	Loss 0.8347 (0.9862)	Acc@1 71.875 (64.569)	Acc@5 90.625 (89.434)
Test: [700/750]	Time 0.093 (0.129)	Loss 1.2839 (1.0016)	Acc@1 59.375 (63.485)	Acc@5 84.375 (89.863)
 * Acc@1 62.696 Acc@5 89.892
==> training...
Epoch: [17][0/875]	Time 2.293 (2.293)	Data 1.595 (1.595)	Loss 3.0917 (3.0917)	Loss@kd 2.9369 (2.9369)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)
Epoch: [17][100/875]	Time 0.671 (0.700)	Data 0.007 (0.023)	Loss 2.8708 (2.9828)	Loss@kd 2.7773 (2.8528)	Acc@1 64.062 (63.057)	Acc@5 98.438 (97.803)
Epoch: [17][200/875]	Time 0.763 (0.694)	Data 0.007 (0.015)	Loss 3.1206 (2.9688)	Loss@kd 3.1107 (2.8355)	Acc@1 60.938 (63.005)	Acc@5 96.875 (97.831)
Epoch: [17][300/875]	Time 0.690 (0.690)	Data 0.007 (0.013)	Loss 3.0545 (2.9644)	Loss@kd 3.0129 (2.8387)	Acc@1 62.500 (63.429)	Acc@5 96.875 (97.861)
Epoch: [17][400/875]	Time 0.668 (0.685)	Data 0.005 (0.011)	Loss 2.9520 (2.9577)	Loss@kd 2.7871 (2.8305)	Acc@1 65.625 (63.447)	Acc@5 95.312 (97.908)
Epoch: [17][500/875]	Time 0.655 (0.683)	Data 0.007 (0.010)	Loss 3.0831 (2.9558)	Loss@kd 2.8831 (2.8305)	Acc@1 60.938 (63.570)	Acc@5 96.875 (97.942)
Epoch: [17][600/875]	Time 0.682 (0.682)	Data 0.005 (0.010)	Loss 3.0444 (2.9574)	Loss@kd 2.8811 (2.8299)	Acc@1 62.500 (63.415)	Acc@5 96.875 (97.920)
Epoch: [17][700/875]	Time 0.667 (0.680)	Data 0.007 (0.009)	Loss 2.9193 (2.9557)	Loss@kd 2.6636 (2.8280)	Acc@1 60.938 (63.456)	Acc@5 100.000 (97.889)
Epoch: [17][800/875]	Time 0.642 (0.679)	Data 0.004 (0.009)	Loss 3.0194 (2.9640)	Loss@kd 2.8577 (2.8364)	Acc@1 71.875 (63.333)	Acc@5 93.750 (97.893)
 * Acc@1 63.409 Acc@5 97.886
epoch 17, total time 594.66
Test: [0/750]	Time 1.024 (1.024)	Loss 0.6781 (0.6781)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.137 (0.145)	Loss 0.3011 (0.5940)	Acc@1 90.625 (83.199)	Acc@5 100.000 (90.285)
Test: [200/750]	Time 0.123 (0.137)	Loss 1.7456 (0.5535)	Acc@1 18.750 (81.763)	Acc@5 78.125 (93.470)
Test: [300/750]	Time 0.144 (0.133)	Loss 1.3235 (0.8860)	Acc@1 56.250 (65.064)	Acc@5 100.000 (92.027)
Test: [400/750]	Time 0.197 (0.131)	Loss 1.0232 (0.9649)	Acc@1 75.000 (61.783)	Acc@5 84.375 (92.075)
Test: [500/750]	Time 0.123 (0.129)	Loss 0.9840 (0.9969)	Acc@1 71.875 (62.132)	Acc@5 87.500 (90.107)
Test: [600/750]	Time 0.111 (0.128)	Loss 0.8649 (1.0218)	Acc@1 68.750 (61.954)	Acc@5 93.750 (89.564)
Test: [700/750]	Time 0.191 (0.128)	Loss 0.8933 (1.0039)	Acc@1 62.500 (62.326)	Acc@5 87.500 (90.389)
 * Acc@1 63.300 Acc@5 90.787
==> training...
Epoch: [18][0/875]	Time 2.292 (2.292)	Data 1.603 (1.603)	Loss 2.9688 (2.9688)	Loss@kd 2.7586 (2.7586)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [18][100/875]	Time 0.665 (0.693)	Data 0.005 (0.023)	Loss 2.5566 (2.9340)	Loss@kd 2.6934 (2.7946)	Acc@1 78.125 (63.258)	Acc@5 100.000 (97.819)
Epoch: [18][200/875]	Time 0.772 (0.684)	Data 0.007 (0.015)	Loss 2.7707 (2.9259)	Loss@kd 2.7294 (2.8008)	Acc@1 68.750 (63.612)	Acc@5 98.438 (98.103)
Epoch: [18][300/875]	Time 0.684 (0.682)	Data 0.007 (0.012)	Loss 3.0849 (2.9419)	Loss@kd 2.8770 (2.8114)	Acc@1 60.938 (63.393)	Acc@5 98.438 (98.064)
Epoch: [18][400/875]	Time 0.659 (0.681)	Data 0.005 (0.011)	Loss 3.3429 (2.9430)	Loss@kd 3.4927 (2.8171)	Acc@1 57.812 (63.494)	Acc@5 96.875 (98.075)
Epoch: [18][500/875]	Time 0.677 (0.680)	Data 0.007 (0.010)	Loss 2.6166 (2.9388)	Loss@kd 2.6805 (2.8130)	Acc@1 75.000 (63.588)	Acc@5 100.000 (98.091)
Epoch: [18][600/875]	Time 0.660 (0.680)	Data 0.006 (0.009)	Loss 2.6826 (2.9367)	Loss@kd 2.7411 (2.8097)	Acc@1 73.438 (63.678)	Acc@5 100.000 (98.081)
Epoch: [18][700/875]	Time 0.674 (0.679)	Data 0.006 (0.009)	Loss 2.9801 (2.9394)	Loss@kd 2.7359 (2.8113)	Acc@1 62.500 (63.646)	Acc@5 100.000 (98.085)
Epoch: [18][800/875]	Time 0.676 (0.679)	Data 0.007 (0.009)	Loss 2.8006 (2.9387)	Loss@kd 2.8623 (2.8097)	Acc@1 70.312 (63.655)	Acc@5 100.000 (98.061)
 * Acc@1 63.698 Acc@5 98.062
epoch 18, total time 594.66
Test: [0/750]	Time 1.007 (1.007)	Loss 0.6938 (0.6938)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.141 (0.136)	Loss 0.4098 (0.5674)	Acc@1 90.625 (83.509)	Acc@5 100.000 (91.368)
Test: [200/750]	Time 0.126 (0.131)	Loss 1.6154 (0.5007)	Acc@1 31.250 (84.297)	Acc@5 87.500 (94.496)
Test: [300/750]	Time 0.132 (0.129)	Loss 1.5924 (0.8228)	Acc@1 43.750 (70.245)	Acc@5 90.625 (92.307)
Test: [400/750]	Time 0.184 (0.127)	Loss 0.8351 (0.9758)	Acc@1 78.125 (63.474)	Acc@5 87.500 (90.874)
Test: [500/750]	Time 0.121 (0.127)	Loss 0.5063 (0.9539)	Acc@1 81.250 (64.951)	Acc@5 100.000 (90.606)
Test: [600/750]	Time 0.116 (0.126)	Loss 0.9338 (0.9455)	Acc@1 65.625 (65.360)	Acc@5 90.625 (91.181)
Test: [700/750]	Time 0.132 (0.126)	Loss 1.0832 (0.9649)	Acc@1 62.500 (64.395)	Acc@5 78.125 (91.396)
 * Acc@1 64.846 Acc@5 91.308
saving the best model!
==> training...
Epoch: [19][0/875]	Time 2.346 (2.346)	Data 1.602 (1.602)	Loss 2.9124 (2.9124)	Loss@kd 2.8209 (2.8209)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [19][100/875]	Time 0.669 (0.699)	Data 0.005 (0.023)	Loss 2.9875 (2.9234)	Loss@kd 2.8038 (2.7714)	Acc@1 57.812 (63.521)	Acc@5 100.000 (97.896)
Epoch: [19][200/875]	Time 0.676 (0.689)	Data 0.007 (0.015)	Loss 2.8839 (2.9334)	Loss@kd 2.8691 (2.7975)	Acc@1 59.375 (63.868)	Acc@5 98.438 (97.948)
Epoch: [19][300/875]	Time 0.668 (0.686)	Data 0.005 (0.012)	Loss 2.8892 (2.9205)	Loss@kd 2.6653 (2.7880)	Acc@1 62.500 (64.005)	Acc@5 98.438 (97.924)
Epoch: [19][400/875]	Time 0.667 (0.685)	Data 0.005 (0.011)	Loss 3.5896 (2.9229)	Loss@kd 3.5442 (2.7912)	Acc@1 59.375 (64.047)	Acc@5 96.875 (97.943)
Epoch: [19][500/875]	Time 0.662 (0.684)	Data 0.011 (0.010)	Loss 3.0295 (2.9193)	Loss@kd 2.7874 (2.7864)	Acc@1 62.500 (64.147)	Acc@5 96.875 (97.898)
Epoch: [19][600/875]	Time 0.676 (0.683)	Data 0.007 (0.009)	Loss 2.7922 (2.9192)	Loss@kd 2.6911 (2.7887)	Acc@1 62.500 (64.086)	Acc@5 98.438 (97.920)
Epoch: [19][700/875]	Time 0.661 (0.683)	Data 0.006 (0.009)	Loss 2.7124 (2.9262)	Loss@kd 2.7670 (2.7984)	Acc@1 76.562 (64.009)	Acc@5 96.875 (97.952)
Epoch: [19][800/875]	Time 0.668 (0.682)	Data 0.005 (0.009)	Loss 2.5859 (2.9273)	Loss@kd 2.6552 (2.8028)	Acc@1 71.875 (64.119)	Acc@5 100.000 (98.002)
 * Acc@1 64.121 Acc@5 98.016
epoch 19, total time 597.87
Test: [0/750]	Time 1.024 (1.024)	Loss 0.6733 (0.6733)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.115 (0.138)	Loss 0.4368 (0.6498)	Acc@1 90.625 (81.807)	Acc@5 100.000 (90.377)
Test: [200/750]	Time 0.189 (0.131)	Loss 1.8208 (0.6233)	Acc@1 15.625 (80.100)	Acc@5 81.250 (92.879)
Test: [300/750]	Time 0.128 (0.129)	Loss 1.2071 (0.9603)	Acc@1 56.250 (64.109)	Acc@5 96.875 (89.711)
Test: [400/750]	Time 0.127 (0.128)	Loss 0.7557 (1.0001)	Acc@1 78.125 (62.329)	Acc@5 87.500 (90.750)
Test: [500/750]	Time 0.123 (0.127)	Loss 0.6513 (0.9661)	Acc@1 81.250 (64.359)	Acc@5 96.875 (90.687)
Test: [600/750]	Time 0.124 (0.126)	Loss 0.8726 (0.9557)	Acc@1 65.625 (65.245)	Acc@5 87.500 (90.911)
Test: [700/750]	Time 0.128 (0.126)	Loss 1.0144 (0.9510)	Acc@1 68.750 (65.099)	Acc@5 87.500 (91.419)
 * Acc@1 65.600 Acc@5 91.508
saving the best model!
==> training...
Epoch: [20][0/875]	Time 2.177 (2.177)	Data 1.499 (1.499)	Loss 2.8945 (2.8945)	Loss@kd 2.5527 (2.5527)	Acc@1 64.062 (64.062)	Acc@5 93.750 (93.750)
Epoch: [20][100/875]	Time 0.668 (0.679)	Data 0.007 (0.021)	Loss 3.0236 (2.9064)	Loss@kd 2.6881 (2.7733)	Acc@1 57.812 (64.140)	Acc@5 98.438 (97.865)
Epoch: [20][200/875]	Time 0.679 (0.669)	Data 0.007 (0.014)	Loss 2.8472 (2.8844)	Loss@kd 2.6137 (2.7583)	Acc@1 67.188 (64.265)	Acc@5 100.000 (97.971)
Epoch: [20][300/875]	Time 0.643 (0.667)	Data 0.005 (0.011)	Loss 3.0115 (2.8952)	Loss@kd 2.7103 (2.7712)	Acc@1 60.938 (64.338)	Acc@5 95.312 (97.965)
Epoch: [20][400/875]	Time 0.660 (0.665)	Data 0.007 (0.010)	Loss 2.9706 (2.8966)	Loss@kd 2.7761 (2.7686)	Acc@1 62.500 (64.327)	Acc@5 96.875 (97.966)
Epoch: [20][500/875]	Time 0.655 (0.664)	Data 0.007 (0.009)	Loss 3.0391 (2.8941)	Loss@kd 2.7392 (2.7649)	Acc@1 62.500 (64.278)	Acc@5 95.312 (98.020)
Epoch: [20][600/875]	Time 0.645 (0.664)	Data 0.005 (0.009)	Loss 2.5348 (2.8975)	Loss@kd 2.5693 (2.7696)	Acc@1 75.000 (64.320)	Acc@5 98.438 (98.014)
Epoch: [20][700/875]	Time 0.656 (0.664)	Data 0.007 (0.008)	Loss 2.6345 (2.9013)	Loss@kd 2.6593 (2.7722)	Acc@1 68.750 (64.288)	Acc@5 98.438 (98.003)
Epoch: [20][800/875]	Time 0.646 (0.664)	Data 0.008 (0.008)	Loss 2.8913 (2.8945)	Loss@kd 2.8097 (2.7649)	Acc@1 65.625 (64.299)	Acc@5 98.438 (98.049)
 * Acc@1 64.248 Acc@5 98.061
epoch 20, total time 581.27
Test: [0/750]	Time 0.945 (0.945)	Loss 0.9487 (0.9487)	Acc@1 62.500 (62.500)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.111 (0.141)	Loss 0.3064 (0.8522)	Acc@1 87.500 (77.321)	Acc@5 100.000 (89.511)
Test: [200/750]	Time 0.119 (0.133)	Loss 1.6144 (0.6752)	Acc@1 34.375 (79.493)	Acc@5 90.625 (93.221)
Test: [300/750]	Time 0.106 (0.130)	Loss 1.1416 (0.9019)	Acc@1 56.250 (67.473)	Acc@5 96.875 (92.442)
Test: [400/750]	Time 0.134 (0.130)	Loss 0.7498 (0.9505)	Acc@1 75.000 (65.079)	Acc@5 87.500 (92.449)
Test: [500/750]	Time 0.119 (0.129)	Loss 0.7775 (0.9222)	Acc@1 78.125 (66.791)	Acc@5 96.875 (91.611)
Test: [600/750]	Time 0.122 (0.128)	Loss 0.9055 (0.9341)	Acc@1 75.000 (66.727)	Acc@5 93.750 (91.462)
Test: [700/750]	Time 0.092 (0.128)	Loss 1.2319 (0.9483)	Acc@1 59.375 (65.549)	Acc@5 84.375 (91.708)
 * Acc@1 65.371 Acc@5 91.650
==> training...
Epoch: [21][0/875]	Time 2.318 (2.318)	Data 1.641 (1.641)	Loss 2.7556 (2.7556)	Loss@kd 2.6299 (2.6299)	Acc@1 59.375 (59.375)	Acc@5 95.312 (95.312)
Epoch: [21][100/875]	Time 0.710 (0.678)	Data 0.005 (0.022)	Loss 2.7023 (2.8791)	Loss@kd 2.7834 (2.7820)	Acc@1 73.438 (65.238)	Acc@5 100.000 (98.190)
Epoch: [21][200/875]	Time 0.668 (0.670)	Data 0.007 (0.014)	Loss 2.9251 (2.8678)	Loss@kd 2.6195 (2.7588)	Acc@1 64.062 (65.166)	Acc@5 98.438 (98.088)
Epoch: [21][300/875]	Time 0.650 (0.667)	Data 0.007 (0.012)	Loss 2.8476 (2.8651)	Loss@kd 2.7403 (2.7476)	Acc@1 65.625 (64.992)	Acc@5 96.875 (98.043)
Epoch: [21][400/875]	Time 0.639 (0.665)	Data 0.004 (0.010)	Loss 3.0452 (2.8648)	Loss@kd 2.6447 (2.7348)	Acc@1 51.562 (64.631)	Acc@5 98.438 (97.997)
Epoch: [21][500/875]	Time 0.660 (0.664)	Data 0.005 (0.010)	Loss 2.8050 (2.8649)	Loss@kd 2.5162 (2.7340)	Acc@1 60.938 (64.455)	Acc@5 100.000 (98.029)
Epoch: [21][600/875]	Time 0.660 (0.663)	Data 0.007 (0.009)	Loss 2.8395 (2.8626)	Loss@kd 2.5616 (2.7323)	Acc@1 60.938 (64.538)	Acc@5 98.438 (98.097)
Epoch: [21][700/875]	Time 0.643 (0.662)	Data 0.005 (0.009)	Loss 2.8086 (2.8601)	Loss@kd 2.6613 (2.7294)	Acc@1 65.625 (64.546)	Acc@5 100.000 (98.128)
Epoch: [21][800/875]	Time 0.631 (0.661)	Data 0.005 (0.008)	Loss 3.0762 (2.8623)	Loss@kd 2.7951 (2.7297)	Acc@1 56.250 (64.441)	Acc@5 98.438 (98.104)
 * Acc@1 64.529 Acc@5 98.123
epoch 21, total time 579.02
Test: [0/750]	Time 0.949 (0.949)	Loss 0.5850 (0.5850)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.108 (0.130)	Loss 0.4107 (0.5983)	Acc@1 87.500 (82.364)	Acc@5 100.000 (91.089)
Test: [200/750]	Time 0.100 (0.127)	Loss 1.6260 (0.6026)	Acc@1 28.125 (79.369)	Acc@5 90.625 (93.828)
Test: [300/750]	Time 0.129 (0.127)	Loss 1.1636 (0.8574)	Acc@1 50.000 (66.923)	Acc@5 100.000 (92.411)
Test: [400/750]	Time 0.115 (0.126)	Loss 0.9635 (0.9343)	Acc@1 68.750 (63.420)	Acc@5 87.500 (92.269)
Test: [500/750]	Time 0.115 (0.125)	Loss 0.6179 (0.9312)	Acc@1 84.375 (64.546)	Acc@5 100.000 (91.367)
Test: [600/750]	Time 0.130 (0.126)	Loss 0.8152 (0.9290)	Acc@1 71.875 (65.318)	Acc@5 90.625 (91.327)
Test: [700/750]	Time 0.121 (0.126)	Loss 0.8075 (0.9196)	Acc@1 68.750 (65.625)	Acc@5 93.750 (91.878)
 * Acc@1 66.229 Acc@5 92.108
saving the best model!
==> training...
Epoch: [22][0/875]	Time 2.312 (2.312)	Data 1.610 (1.610)	Loss 2.7012 (2.7012)	Loss@kd 2.6521 (2.6521)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [22][100/875]	Time 0.646 (0.678)	Data 0.006 (0.022)	Loss 2.7310 (2.8477)	Loss@kd 2.5590 (2.7474)	Acc@1 68.750 (65.811)	Acc@5 100.000 (98.468)
Epoch: [22][200/875]	Time 0.658 (0.670)	Data 0.005 (0.014)	Loss 2.8681 (2.8476)	Loss@kd 2.5817 (2.7274)	Acc@1 62.500 (65.205)	Acc@5 95.312 (98.321)
Epoch: [22][300/875]	Time 0.645 (0.666)	Data 0.005 (0.011)	Loss 2.9775 (2.8347)	Loss@kd 2.7818 (2.7088)	Acc@1 65.625 (65.345)	Acc@5 100.000 (98.277)
Epoch: [22][400/875]	Time 0.659 (0.665)	Data 0.007 (0.010)	Loss 2.6985 (2.8327)	Loss@kd 2.7187 (2.7055)	Acc@1 70.312 (65.122)	Acc@5 100.000 (98.270)
Epoch: [22][500/875]	Time 0.665 (0.663)	Data 0.007 (0.009)	Loss 2.8481 (2.8302)	Loss@kd 2.6660 (2.7078)	Acc@1 64.062 (65.266)	Acc@5 96.875 (98.241)
Epoch: [22][600/875]	Time 0.636 (0.662)	Data 0.007 (0.009)	Loss 2.9906 (2.8356)	Loss@kd 2.6847 (2.7095)	Acc@1 62.500 (65.048)	Acc@5 96.875 (98.248)
Epoch: [22][700/875]	Time 0.677 (0.662)	Data 0.007 (0.008)	Loss 2.7635 (2.8311)	Loss@kd 2.7944 (2.7065)	Acc@1 73.438 (65.164)	Acc@5 95.312 (98.159)
Epoch: [22][800/875]	Time 0.655 (0.661)	Data 0.005 (0.008)	Loss 2.8776 (2.8313)	Loss@kd 2.6386 (2.7038)	Acc@1 54.688 (65.048)	Acc@5 98.438 (98.180)
 * Acc@1 65.045 Acc@5 98.195
epoch 22, total time 579.16
Test: [0/750]	Time 0.888 (0.888)	Loss 2.3079 (2.3079)	Acc@1 53.125 (53.125)	Acc@5 59.375 (59.375)
Test: [100/750]	Time 0.199 (0.140)	Loss 0.3531 (1.4596)	Acc@1 90.625 (59.313)	Acc@5 100.000 (76.176)
Test: [200/750]	Time 0.135 (0.135)	Loss 1.3294 (0.9738)	Acc@1 46.875 (71.284)	Acc@5 90.625 (86.909)
Test: [300/750]	Time 0.126 (0.134)	Loss 1.3257 (1.0511)	Acc@1 43.750 (65.220)	Acc@5 90.625 (88.953)
Test: [400/750]	Time 0.136 (0.134)	Loss 0.5516 (1.0979)	Acc@1 84.375 (61.113)	Acc@5 90.625 (89.511)
Test: [500/750]	Time 0.124 (0.133)	Loss 0.9745 (1.0286)	Acc@1 62.500 (64.047)	Acc@5 90.625 (89.758)
Test: [600/750]	Time 0.137 (0.133)	Loss 0.9733 (1.0370)	Acc@1 62.500 (63.930)	Acc@5 90.625 (89.887)
Test: [700/750]	Time 0.137 (0.133)	Loss 1.0812 (1.0362)	Acc@1 62.500 (63.401)	Acc@5 84.375 (90.308)
 * Acc@1 63.500 Acc@5 90.375
==> training...
Epoch: [23][0/875]	Time 2.288 (2.288)	Data 1.606 (1.606)	Loss 2.9082 (2.9082)	Loss@kd 2.6064 (2.6064)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [23][100/875]	Time 0.684 (0.697)	Data 0.007 (0.023)	Loss 2.8785 (2.8080)	Loss@kd 2.6416 (2.6996)	Acc@1 56.250 (66.584)	Acc@5 100.000 (98.128)
Epoch: [23][200/875]	Time 0.688 (0.695)	Data 0.008 (0.015)	Loss 3.0629 (2.8256)	Loss@kd 3.0032 (2.7134)	Acc@1 71.875 (66.084)	Acc@5 96.875 (98.197)
Epoch: [23][300/875]	Time 0.681 (0.695)	Data 0.007 (0.012)	Loss 2.7164 (2.8151)	Loss@kd 2.7319 (2.6962)	Acc@1 68.750 (65.687)	Acc@5 98.438 (98.308)
Epoch: [23][400/875]	Time 0.670 (0.694)	Data 0.007 (0.011)	Loss 2.7988 (2.8159)	Loss@kd 2.8023 (2.6931)	Acc@1 65.625 (65.422)	Acc@5 100.000 (98.196)
Epoch: [23][500/875]	Time 0.678 (0.694)	Data 0.007 (0.010)	Loss 2.7130 (2.8187)	Loss@kd 2.5945 (2.6909)	Acc@1 57.812 (65.310)	Acc@5 100.000 (98.154)
Epoch: [23][600/875]	Time 0.678 (0.694)	Data 0.010 (0.010)	Loss 2.6698 (2.8192)	Loss@kd 2.6310 (2.6901)	Acc@1 71.875 (65.256)	Acc@5 98.438 (98.146)
Epoch: [23][700/875]	Time 0.690 (0.693)	Data 0.007 (0.010)	Loss 2.7320 (2.8139)	Loss@kd 2.6607 (2.6872)	Acc@1 68.750 (65.286)	Acc@5 98.438 (98.152)
Epoch: [23][800/875]	Time 0.669 (0.693)	Data 0.007 (0.009)	Loss 2.7902 (2.8106)	Loss@kd 2.6879 (2.6854)	Acc@1 68.750 (65.313)	Acc@5 96.875 (98.174)
 * Acc@1 65.354 Acc@5 98.182
epoch 23, total time 607.14
Test: [0/750]	Time 1.012 (1.012)	Loss 0.4354 (0.4354)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.122 (0.142)	Loss 0.5434 (0.4632)	Acc@1 78.125 (85.179)	Acc@5 100.000 (93.657)
Test: [200/750]	Time 0.122 (0.137)	Loss 1.6419 (0.5230)	Acc@1 40.625 (81.499)	Acc@5 81.250 (95.056)
Test: [300/750]	Time 0.213 (0.135)	Loss 1.5373 (0.8445)	Acc@1 46.875 (68.563)	Acc@5 93.750 (91.892)
Test: [400/750]	Time 0.137 (0.134)	Loss 0.7038 (0.9738)	Acc@1 75.000 (63.825)	Acc@5 90.625 (90.750)
Test: [500/750]	Time 0.127 (0.132)	Loss 0.5526 (0.9296)	Acc@1 81.250 (66.112)	Acc@5 100.000 (90.831)
Test: [600/750]	Time 0.206 (0.132)	Loss 0.5921 (0.8990)	Acc@1 71.875 (67.544)	Acc@5 100.000 (91.525)
Test: [700/750]	Time 0.131 (0.132)	Loss 1.5283 (0.9046)	Acc@1 46.875 (66.878)	Acc@5 81.250 (91.628)
 * Acc@1 66.242 Acc@5 91.237
saving the best model!
==> training...
Epoch: [24][0/875]	Time 2.326 (2.326)	Data 1.663 (1.663)	Loss 2.7857 (2.7857)	Loss@kd 2.5355 (2.5355)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [24][100/875]	Time 0.682 (0.706)	Data 0.007 (0.024)	Loss 2.9014 (2.7710)	Loss@kd 2.7562 (2.6449)	Acc@1 64.062 (65.857)	Acc@5 98.438 (98.267)
Epoch: [24][200/875]	Time 0.681 (0.697)	Data 0.007 (0.016)	Loss 2.9797 (2.8014)	Loss@kd 3.0196 (2.6867)	Acc@1 62.500 (65.819)	Acc@5 100.000 (98.321)
Epoch: [24][300/875]	Time 0.679 (0.694)	Data 0.007 (0.013)	Loss 2.7435 (2.8071)	Loss@kd 2.6193 (2.6918)	Acc@1 65.625 (65.796)	Acc@5 100.000 (98.277)
Epoch: [24][400/875]	Time 0.677 (0.693)	Data 0.007 (0.012)	Loss 2.8309 (2.8041)	Loss@kd 2.7361 (2.6913)	Acc@1 62.500 (65.956)	Acc@5 98.438 (98.301)
Epoch: [24][500/875]	Time 0.682 (0.692)	Data 0.007 (0.011)	Loss 2.7054 (2.8045)	Loss@kd 2.6362 (2.6879)	Acc@1 64.062 (65.784)	Acc@5 96.875 (98.303)
Epoch: [24][600/875]	Time 0.672 (0.691)	Data 0.007 (0.010)	Loss 2.7742 (2.8020)	Loss@kd 2.5839 (2.6822)	Acc@1 64.062 (65.802)	Acc@5 93.750 (98.256)
Epoch: [24][700/875]	Time 0.745 (0.691)	Data 0.007 (0.010)	Loss 2.9071 (2.7969)	Loss@kd 2.6809 (2.6781)	Acc@1 64.062 (65.837)	Acc@5 96.875 (98.308)
Epoch: [24][800/875]	Time 0.683 (0.691)	Data 0.007 (0.010)	Loss 2.6904 (2.7941)	Loss@kd 2.4523 (2.6715)	Acc@1 60.938 (65.691)	Acc@5 95.312 (98.315)
 * Acc@1 65.714 Acc@5 98.309
epoch 24, total time 604.95
Test: [0/750]	Time 1.017 (1.017)	Loss 0.5021 (0.5021)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.126 (0.140)	Loss 0.5995 (0.5914)	Acc@1 84.375 (83.199)	Acc@5 93.750 (91.368)
Test: [200/750]	Time 0.110 (0.134)	Loss 1.9411 (0.6274)	Acc@1 18.750 (79.835)	Acc@5 81.250 (92.662)
Test: [300/750]	Time 0.130 (0.132)	Loss 0.9089 (0.9927)	Acc@1 71.875 (62.510)	Acc@5 100.000 (89.161)
Test: [400/750]	Time 0.137 (0.132)	Loss 0.4721 (0.9586)	Acc@1 84.375 (64.386)	Acc@5 96.875 (90.719)
Test: [500/750]	Time 0.128 (0.132)	Loss 0.7451 (0.8903)	Acc@1 78.125 (67.609)	Acc@5 93.750 (91.349)
Test: [600/750]	Time 0.126 (0.131)	Loss 0.9867 (0.9103)	Acc@1 65.625 (67.424)	Acc@5 84.375 (91.135)
Test: [700/750]	Time 0.134 (0.131)	Loss 1.1482 (0.9347)	Acc@1 56.250 (65.892)	Acc@5 87.500 (91.512)
 * Acc@1 65.617 Acc@5 91.625
==> training...
Epoch: [25][0/875]	Time 2.333 (2.333)	Data 1.641 (1.641)	Loss 3.0272 (3.0272)	Loss@kd 2.7157 (2.7157)	Acc@1 64.062 (64.062)	Acc@5 93.750 (93.750)
Epoch: [25][100/875]	Time 0.681 (0.709)	Data 0.007 (0.023)	Loss 2.8630 (2.7619)	Loss@kd 2.7006 (2.6518)	Acc@1 60.938 (66.244)	Acc@5 100.000 (98.345)
Epoch: [25][200/875]	Time 0.679 (0.700)	Data 0.007 (0.015)	Loss 2.7547 (2.7636)	Loss@kd 2.4913 (2.6387)	Acc@1 67.188 (65.975)	Acc@5 96.875 (98.352)
Epoch: [25][300/875]	Time 0.681 (0.697)	Data 0.007 (0.013)	Loss 2.5959 (2.7721)	Loss@kd 2.4803 (2.6580)	Acc@1 70.312 (66.009)	Acc@5 96.875 (98.344)
Epoch: [25][400/875]	Time 0.671 (0.696)	Data 0.008 (0.011)	Loss 2.9171 (2.7696)	Loss@kd 2.7421 (2.6494)	Acc@1 60.938 (65.683)	Acc@5 100.000 (98.328)
Epoch: [25][500/875]	Time 0.684 (0.695)	Data 0.007 (0.011)	Loss 2.3327 (2.7763)	Loss@kd 2.5333 (2.6517)	Acc@1 82.812 (65.578)	Acc@5 100.000 (98.303)
Epoch: [25][600/875]	Time 0.674 (0.695)	Data 0.010 (0.010)	Loss 2.8788 (2.7856)	Loss@kd 2.6757 (2.6614)	Acc@1 62.500 (65.586)	Acc@5 100.000 (98.279)
Epoch: [25][700/875]	Time 0.673 (0.694)	Data 0.007 (0.010)	Loss 2.5645 (2.7786)	Loss@kd 2.5276 (2.6536)	Acc@1 67.188 (65.580)	Acc@5 96.875 (98.322)
Epoch: [25][800/875]	Time 0.685 (0.694)	Data 0.008 (0.010)	Loss 2.7268 (2.7762)	Loss@kd 2.6096 (2.6505)	Acc@1 68.750 (65.615)	Acc@5 98.438 (98.285)
 * Acc@1 65.613 Acc@5 98.287
epoch 25, total time 607.57
Test: [0/750]	Time 1.008 (1.008)	Loss 0.5686 (0.5686)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.199 (0.138)	Loss 0.6008 (0.5948)	Acc@1 75.000 (83.416)	Acc@5 100.000 (92.358)
Test: [200/750]	Time 0.136 (0.130)	Loss 1.6091 (0.6435)	Acc@1 31.250 (77.317)	Acc@5 84.375 (94.123)
Test: [300/750]	Time 0.139 (0.129)	Loss 0.7863 (0.8908)	Acc@1 78.125 (64.680)	Acc@5 96.875 (92.836)
Test: [400/750]	Time 0.107 (0.127)	Loss 0.8588 (0.8996)	Acc@1 75.000 (65.368)	Acc@5 90.625 (93.033)
Test: [500/750]	Time 0.117 (0.126)	Loss 0.7701 (0.9067)	Acc@1 75.000 (66.136)	Acc@5 90.625 (91.879)
Test: [600/750]	Time 0.207 (0.126)	Loss 0.8760 (0.9061)	Acc@1 68.750 (66.873)	Acc@5 87.500 (91.707)
Test: [700/750]	Time 0.115 (0.126)	Loss 1.2146 (0.9060)	Acc@1 53.125 (66.570)	Acc@5 81.250 (91.980)
 * Acc@1 66.404 Acc@5 91.971
saving the best model!
==> training...
Epoch: [26][0/875]	Time 2.299 (2.299)	Data 1.616 (1.616)	Loss 2.8211 (2.8211)	Loss@kd 2.7444 (2.7444)	Acc@1 64.062 (64.062)	Acc@5 98.438 (98.438)
Epoch: [26][100/875]	Time 0.745 (0.702)	Data 0.008 (0.023)	Loss 3.0088 (2.7201)	Loss@kd 2.8099 (2.6149)	Acc@1 67.188 (66.615)	Acc@5 96.875 (98.283)
Epoch: [26][200/875]	Time 0.680 (0.694)	Data 0.008 (0.015)	Loss 2.8419 (2.7212)	Loss@kd 2.7889 (2.6038)	Acc@1 67.188 (66.402)	Acc@5 100.000 (98.266)
Epoch: [26][300/875]	Time 0.674 (0.690)	Data 0.007 (0.013)	Loss 2.5639 (2.7272)	Loss@kd 2.5254 (2.6057)	Acc@1 71.875 (66.165)	Acc@5 100.000 (98.297)
Epoch: [26][400/875]	Time 0.713 (0.688)	Data 0.007 (0.011)	Loss 2.7092 (2.7375)	Loss@kd 2.6257 (2.6117)	Acc@1 65.625 (66.038)	Acc@5 98.438 (98.286)
Epoch: [26][500/875]	Time 0.684 (0.687)	Data 0.008 (0.011)	Loss 2.8850 (2.7407)	Loss@kd 2.6296 (2.6121)	Acc@1 56.250 (65.940)	Acc@5 98.438 (98.353)
Epoch: [26][600/875]	Time 0.679 (0.686)	Data 0.007 (0.010)	Loss 2.7177 (2.7413)	Loss@kd 2.6651 (2.6107)	Acc@1 67.188 (65.815)	Acc@5 96.875 (98.336)
Epoch: [26][700/875]	Time 0.681 (0.686)	Data 0.007 (0.010)	Loss 2.5740 (2.7437)	Loss@kd 2.5768 (2.6155)	Acc@1 70.312 (65.884)	Acc@5 98.438 (98.353)
Epoch: [26][800/875]	Time 0.759 (0.686)	Data 0.010 (0.009)	Loss 2.5157 (2.7442)	Loss@kd 2.5673 (2.6170)	Acc@1 76.562 (65.912)	Acc@5 98.438 (98.354)
 * Acc@1 66.005 Acc@5 98.348
epoch 26, total time 600.57
Test: [0/750]	Time 1.019 (1.019)	Loss 1.1370 (1.1370)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.125 (0.142)	Loss 0.3295 (0.7018)	Acc@1 84.375 (78.589)	Acc@5 100.000 (91.925)
Test: [200/750]	Time 0.121 (0.138)	Loss 1.3854 (0.5919)	Acc@1 50.000 (80.830)	Acc@5 90.625 (94.652)
Test: [300/750]	Time 0.137 (0.136)	Loss 1.6567 (0.8382)	Acc@1 34.375 (69.965)	Acc@5 81.250 (92.618)
Test: [400/750]	Time 0.119 (0.135)	Loss 0.4929 (1.0126)	Acc@1 84.375 (63.131)	Acc@5 87.500 (90.048)
Test: [500/750]	Time 0.112 (0.134)	Loss 0.6449 (0.9389)	Acc@1 78.125 (66.480)	Acc@5 96.875 (90.706)
Test: [600/750]	Time 0.177 (0.132)	Loss 0.7799 (0.9301)	Acc@1 75.000 (66.946)	Acc@5 90.625 (91.197)
Test: [700/750]	Time 0.129 (0.132)	Loss 1.4387 (0.9494)	Acc@1 53.125 (65.888)	Acc@5 78.125 (91.258)
 * Acc@1 65.279 Acc@5 90.817
==> training...
Epoch: [27][0/875]	Time 2.427 (2.427)	Data 1.728 (1.728)	Loss 2.5636 (2.5636)	Loss@kd 2.6128 (2.6128)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [27][100/875]	Time 0.679 (0.700)	Data 0.007 (0.024)	Loss 2.5569 (2.7357)	Loss@kd 2.5870 (2.6109)	Acc@1 68.750 (65.733)	Acc@5 100.000 (98.314)
Epoch: [27][200/875]	Time 0.689 (0.692)	Data 0.007 (0.016)	Loss 2.8024 (2.7366)	Loss@kd 2.4028 (2.6149)	Acc@1 57.812 (66.068)	Acc@5 95.312 (98.406)
Epoch: [27][300/875]	Time 0.685 (0.689)	Data 0.007 (0.013)	Loss 2.5679 (2.7329)	Loss@kd 2.5836 (2.6138)	Acc@1 70.312 (66.097)	Acc@5 100.000 (98.417)
Epoch: [27][400/875]	Time 0.671 (0.687)	Data 0.007 (0.012)	Loss 2.9110 (2.7286)	Loss@kd 2.5501 (2.6012)	Acc@1 54.688 (66.069)	Acc@5 96.875 (98.395)
Epoch: [27][500/875]	Time 0.675 (0.686)	Data 0.005 (0.011)	Loss 2.9010 (2.7262)	Loss@kd 2.7349 (2.5977)	Acc@1 57.812 (66.165)	Acc@5 100.000 (98.416)
Epoch: [27][600/875]	Time 0.681 (0.686)	Data 0.007 (0.010)	Loss 2.9183 (2.7217)	Loss@kd 2.6046 (2.5916)	Acc@1 64.062 (66.291)	Acc@5 95.312 (98.391)
Epoch: [27][700/875]	Time 0.753 (0.685)	Data 0.007 (0.010)	Loss 3.2046 (2.7269)	Loss@kd 3.2049 (2.5929)	Acc@1 70.312 (66.122)	Acc@5 100.000 (98.395)
Epoch: [27][800/875]	Time 0.660 (0.685)	Data 0.007 (0.010)	Loss 2.9785 (2.7256)	Loss@kd 2.6956 (2.5940)	Acc@1 59.375 (66.191)	Acc@5 98.438 (98.391)
 * Acc@1 66.236 Acc@5 98.348
epoch 27, total time 600.14
Test: [0/750]	Time 0.979 (0.979)	Loss 0.5661 (0.5661)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.115 (0.135)	Loss 0.6449 (0.5875)	Acc@1 78.125 (82.797)	Acc@5 93.750 (90.965)
Test: [200/750]	Time 0.114 (0.131)	Loss 1.3847 (0.6829)	Acc@1 34.375 (76.539)	Acc@5 100.000 (92.755)
Test: [300/750]	Time 0.120 (0.128)	Loss 0.8665 (0.8782)	Acc@1 71.875 (66.622)	Acc@5 100.000 (92.587)
Test: [400/750]	Time 0.125 (0.127)	Loss 0.5679 (0.9002)	Acc@1 81.250 (65.742)	Acc@5 84.375 (93.056)
Test: [500/750]	Time 0.131 (0.126)	Loss 0.6500 (0.8623)	Acc@1 78.125 (67.883)	Acc@5 96.875 (92.883)
Test: [600/750]	Time 0.121 (0.126)	Loss 0.9060 (0.8649)	Acc@1 65.625 (68.381)	Acc@5 87.500 (92.726)
Test: [700/750]	Time 0.114 (0.126)	Loss 1.2200 (0.8867)	Acc@1 53.125 (67.426)	Acc@5 81.250 (92.569)
 * Acc@1 66.992 Acc@5 92.442
saving the best model!
==> training...
Epoch: [28][0/875]	Time 2.426 (2.426)	Data 1.611 (1.611)	Loss 2.5766 (2.5766)	Loss@kd 2.5171 (2.5171)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [28][100/875]	Time 0.764 (0.702)	Data 0.007 (0.023)	Loss 2.8978 (2.7183)	Loss@kd 2.5949 (2.5799)	Acc@1 65.625 (65.563)	Acc@5 95.312 (98.360)
Epoch: [28][200/875]	Time 0.764 (0.697)	Data 0.008 (0.015)	Loss 2.5580 (2.7177)	Loss@kd 2.6104 (2.5814)	Acc@1 70.312 (66.169)	Acc@5 100.000 (98.422)
Epoch: [28][300/875]	Time 0.779 (0.696)	Data 0.007 (0.013)	Loss 2.9116 (2.7099)	Loss@kd 2.7754 (2.5769)	Acc@1 59.375 (66.347)	Acc@5 98.438 (98.354)
Epoch: [28][400/875]	Time 0.780 (0.695)	Data 0.009 (0.011)	Loss 2.7101 (2.7083)	Loss@kd 2.8215 (2.5771)	Acc@1 75.000 (66.537)	Acc@5 100.000 (98.480)
Epoch: [28][500/875]	Time 0.785 (0.695)	Data 0.007 (0.011)	Loss 2.4730 (2.7067)	Loss@kd 2.5646 (2.5839)	Acc@1 76.562 (66.735)	Acc@5 100.000 (98.453)
Epoch: [28][600/875]	Time 0.797 (0.694)	Data 0.008 (0.010)	Loss 2.5810 (2.7095)	Loss@kd 2.4413 (2.5859)	Acc@1 67.188 (66.577)	Acc@5 98.438 (98.471)
Epoch: [28][700/875]	Time 0.786 (0.694)	Data 0.008 (0.010)	Loss 2.6969 (2.7054)	Loss@kd 2.4812 (2.5828)	Acc@1 67.188 (66.635)	Acc@5 96.875 (98.453)
Epoch: [28][800/875]	Time 0.767 (0.694)	Data 0.008 (0.009)	Loss 2.5075 (2.7032)	Loss@kd 2.5805 (2.5810)	Acc@1 71.875 (66.618)	Acc@5 100.000 (98.453)
 * Acc@1 66.580 Acc@5 98.445
epoch 28, total time 607.90
Test: [0/750]	Time 0.998 (0.998)	Loss 0.7357 (0.7357)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.109 (0.141)	Loss 0.6302 (0.7012)	Acc@1 68.750 (80.910)	Acc@5 100.000 (89.790)
Test: [200/750]	Time 0.192 (0.130)	Loss 1.6743 (0.7184)	Acc@1 31.250 (74.596)	Acc@5 90.625 (93.268)
Test: [300/750]	Time 0.109 (0.127)	Loss 0.9826 (0.9589)	Acc@1 71.875 (62.874)	Acc@5 96.875 (91.767)
Test: [400/750]	Time 0.111 (0.126)	Loss 0.7151 (0.9666)	Acc@1 75.000 (62.812)	Acc@5 96.875 (92.698)
Test: [500/750]	Time 0.130 (0.126)	Loss 0.7240 (0.9352)	Acc@1 71.875 (64.901)	Acc@5 93.750 (92.209)
Test: [600/750]	Time 0.115 (0.127)	Loss 0.5430 (0.9108)	Acc@1 84.375 (66.660)	Acc@5 96.875 (92.180)
Test: [700/750]	Time 0.113 (0.126)	Loss 1.3312 (0.8987)	Acc@1 62.500 (67.043)	Acc@5 81.250 (92.323)
 * Acc@1 66.562 Acc@5 92.058
==> training...
Epoch: [29][0/875]	Time 2.394 (2.394)	Data 1.571 (1.571)	Loss 2.4901 (2.4901)	Loss@kd 2.4135 (2.4135)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [29][100/875]	Time 0.772 (0.706)	Data 0.007 (0.023)	Loss 2.5016 (2.6785)	Loss@kd 2.5990 (2.5381)	Acc@1 75.000 (65.842)	Acc@5 98.438 (98.422)
Epoch: [29][200/875]	Time 0.768 (0.698)	Data 0.008 (0.015)	Loss 2.7218 (2.6729)	Loss@kd 2.4422 (2.5445)	Acc@1 64.062 (66.449)	Acc@5 98.438 (98.445)
Epoch: [29][300/875]	Time 0.778 (0.695)	Data 0.007 (0.012)	Loss 2.6920 (2.6725)	Loss@kd 2.6970 (2.5522)	Acc@1 68.750 (66.684)	Acc@5 98.438 (98.547)
Epoch: [29][400/875]	Time 0.761 (0.693)	Data 0.007 (0.011)	Loss 2.7753 (2.6862)	Loss@kd 2.5832 (2.5580)	Acc@1 67.188 (66.591)	Acc@5 98.438 (98.492)
Epoch: [29][500/875]	Time 0.751 (0.693)	Data 0.007 (0.010)	Loss 2.7860 (2.6895)	Loss@kd 2.5755 (2.5627)	Acc@1 68.750 (66.679)	Acc@5 100.000 (98.497)
Epoch: [29][600/875]	Time 0.766 (0.692)	Data 0.007 (0.010)	Loss 2.9490 (2.6916)	Loss@kd 2.5777 (2.5621)	Acc@1 54.688 (66.493)	Acc@5 98.438 (98.476)
Epoch: [29][700/875]	Time 0.758 (0.692)	Data 0.007 (0.010)	Loss 2.6379 (2.6848)	Loss@kd 2.5429 (2.5559)	Acc@1 70.312 (66.510)	Acc@5 100.000 (98.453)
Epoch: [29][800/875]	Time 0.760 (0.692)	Data 0.007 (0.009)	Loss 2.5709 (2.6852)	Loss@kd 2.6433 (2.5558)	Acc@1 70.312 (66.559)	Acc@5 98.438 (98.436)
 * Acc@1 66.657 Acc@5 98.418
epoch 29, total time 605.95
Test: [0/750]	Time 1.009 (1.009)	Loss 0.4886 (0.4886)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.121 (0.141)	Loss 0.5780 (0.5388)	Acc@1 75.000 (84.313)	Acc@5 96.875 (93.472)
Test: [200/750]	Time 0.082 (0.135)	Loss 1.4610 (0.5614)	Acc@1 40.625 (81.483)	Acc@5 90.625 (95.243)
Test: [300/750]	Time 0.124 (0.129)	Loss 1.1905 (0.7904)	Acc@1 53.125 (70.671)	Acc@5 87.500 (94.134)
Test: [400/750]	Time 0.128 (0.128)	Loss 0.6558 (0.8689)	Acc@1 84.375 (67.456)	Acc@5 90.625 (93.602)
Test: [500/750]	Time 0.208 (0.128)	Loss 0.7278 (0.8475)	Acc@1 78.125 (69.237)	Acc@5 96.875 (92.833)
Test: [600/750]	Time 0.096 (0.127)	Loss 0.8186 (0.8546)	Acc@1 75.000 (69.514)	Acc@5 93.750 (92.715)
Test: [700/750]	Time 0.122 (0.126)	Loss 1.3870 (0.8727)	Acc@1 53.125 (68.545)	Acc@5 78.125 (92.662)
 * Acc@1 67.846 Acc@5 92.379
saving the best model!
==> training...
Epoch: [30][0/875]	Time 2.306 (2.306)	Data 1.617 (1.617)	Loss 2.7403 (2.7403)	Loss@kd 2.7285 (2.7285)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [30][100/875]	Time 0.779 (0.704)	Data 0.007 (0.023)	Loss 2.9239 (2.6892)	Loss@kd 2.6895 (2.5919)	Acc@1 59.375 (67.512)	Acc@5 98.438 (98.639)
Epoch: [30][200/875]	Time 0.682 (0.696)	Data 0.007 (0.015)	Loss 2.7732 (2.6791)	Loss@kd 2.4730 (2.5766)	Acc@1 70.312 (67.428)	Acc@5 100.000 (98.546)
Epoch: [30][300/875]	Time 0.689 (0.693)	Data 0.007 (0.013)	Loss 2.8782 (2.6849)	Loss@kd 2.6369 (2.5724)	Acc@1 64.062 (67.198)	Acc@5 95.312 (98.505)
Epoch: [30][400/875]	Time 0.665 (0.691)	Data 0.007 (0.011)	Loss 2.6296 (2.6806)	Loss@kd 2.4232 (2.5617)	Acc@1 59.375 (67.028)	Acc@5 98.438 (98.469)
Epoch: [30][500/875]	Time 0.681 (0.690)	Data 0.007 (0.011)	Loss 2.6092 (2.6789)	Loss@kd 2.6084 (2.5594)	Acc@1 78.125 (67.106)	Acc@5 98.438 (98.447)
Epoch: [30][600/875]	Time 0.677 (0.689)	Data 0.007 (0.010)	Loss 2.5666 (2.6761)	Loss@kd 2.6429 (2.5535)	Acc@1 76.562 (67.045)	Acc@5 96.875 (98.411)
Epoch: [30][700/875]	Time 0.690 (0.689)	Data 0.007 (0.010)	Loss 2.6372 (2.6745)	Loss@kd 2.4007 (2.5521)	Acc@1 65.625 (67.063)	Acc@5 100.000 (98.411)
Epoch: [30][800/875]	Time 0.742 (0.689)	Data 0.007 (0.009)	Loss 2.7508 (2.6734)	Loss@kd 2.4400 (2.5502)	Acc@1 65.625 (67.084)	Acc@5 95.312 (98.404)
 * Acc@1 67.034 Acc@5 98.432
epoch 30, total time 603.21
Test: [0/750]	Time 1.013 (1.013)	Loss 0.3631 (0.3631)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.189 (0.143)	Loss 0.8807 (0.4732)	Acc@1 62.500 (85.520)	Acc@5 93.750 (94.585)
Test: [200/750]	Time 0.136 (0.138)	Loss 1.5874 (0.5995)	Acc@1 31.250 (78.218)	Acc@5 84.375 (95.087)
Test: [300/750]	Time 0.116 (0.136)	Loss 1.5605 (0.8824)	Acc@1 34.375 (65.968)	Acc@5 87.500 (92.452)
Test: [400/750]	Time 0.129 (0.135)	Loss 0.5263 (1.0124)	Acc@1 84.375 (60.887)	Acc@5 87.500 (91.389)
Test: [500/750]	Time 0.140 (0.134)	Loss 0.5534 (0.9506)	Acc@1 84.375 (64.353)	Acc@5 96.875 (91.542)
Test: [600/750]	Time 0.189 (0.133)	Loss 0.6590 (0.9282)	Acc@1 78.125 (65.880)	Acc@5 93.750 (91.655)
Test: [700/750]	Time 0.123 (0.133)	Loss 0.8819 (0.9066)	Acc@1 71.875 (66.784)	Acc@5 90.625 (92.145)
 * Acc@1 67.054 Acc@5 92.296
==> training...
Epoch: [31][0/875]	Time 2.332 (2.332)	Data 1.619 (1.619)	Loss 2.5968 (2.5968)	Loss@kd 2.4951 (2.4951)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [31][100/875]	Time 0.671 (0.706)	Data 0.007 (0.024)	Loss 2.6891 (2.6660)	Loss@kd 2.6712 (2.5854)	Acc@1 62.500 (68.332)	Acc@5 98.438 (98.639)
Epoch: [31][200/875]	Time 0.672 (0.697)	Data 0.007 (0.016)	Loss 2.5605 (2.6935)	Loss@kd 2.4362 (2.5925)	Acc@1 68.750 (67.351)	Acc@5 98.438 (98.391)
Epoch: [31][300/875]	Time 0.682 (0.694)	Data 0.007 (0.013)	Loss 2.5335 (2.6852)	Loss@kd 2.3942 (2.5805)	Acc@1 67.188 (67.374)	Acc@5 96.875 (98.354)
Epoch: [31][400/875]	Time 0.683 (0.692)	Data 0.007 (0.012)	Loss 2.7385 (2.6871)	Loss@kd 2.5948 (2.5867)	Acc@1 64.062 (67.472)	Acc@5 96.875 (98.402)
Epoch: [31][500/875]	Time 0.680 (0.691)	Data 0.007 (0.011)	Loss 2.4609 (2.6877)	Loss@kd 2.4612 (2.5792)	Acc@1 73.438 (67.440)	Acc@5 98.438 (98.413)
Epoch: [31][600/875]	Time 0.682 (0.691)	Data 0.007 (0.010)	Loss 2.4927 (2.6806)	Loss@kd 2.4401 (2.5684)	Acc@1 75.000 (67.333)	Acc@5 100.000 (98.422)
Epoch: [31][700/875]	Time 0.760 (0.691)	Data 0.007 (0.010)	Loss 2.4549 (2.6751)	Loss@kd 2.5082 (2.5591)	Acc@1 76.562 (67.321)	Acc@5 100.000 (98.442)
Epoch: [31][800/875]	Time 0.682 (0.690)	Data 0.007 (0.010)	Loss 2.8097 (2.6660)	Loss@kd 2.5304 (2.5503)	Acc@1 57.812 (67.383)	Acc@5 98.438 (98.461)
 * Acc@1 67.395 Acc@5 98.409
epoch 31, total time 604.38
Test: [0/750]	Time 1.047 (1.047)	Loss 0.5401 (0.5401)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.117 (0.136)	Loss 0.6286 (0.5153)	Acc@1 78.125 (84.097)	Acc@5 100.000 (93.007)
Test: [200/750]	Time 0.111 (0.131)	Loss 1.2903 (0.5758)	Acc@1 46.875 (80.892)	Acc@5 93.750 (94.403)
Test: [300/750]	Time 0.128 (0.128)	Loss 1.0067 (0.7880)	Acc@1 65.625 (70.505)	Acc@5 96.875 (93.999)
Test: [400/750]	Time 0.100 (0.126)	Loss 0.6581 (0.8506)	Acc@1 84.375 (67.799)	Acc@5 90.625 (93.781)
Test: [500/750]	Time 0.117 (0.126)	Loss 0.6211 (0.8328)	Acc@1 78.125 (69.374)	Acc@5 96.875 (92.945)
Test: [600/750]	Time 0.096 (0.125)	Loss 0.8687 (0.8468)	Acc@1 71.875 (69.468)	Acc@5 87.500 (92.471)
Test: [700/750]	Time 0.100 (0.125)	Loss 0.9362 (0.8570)	Acc@1 56.250 (68.777)	Acc@5 90.625 (92.600)
 * Acc@1 68.829 Acc@5 92.717
saving the best model!
==> training...
Epoch: [32][0/875]	Time 2.306 (2.306)	Data 1.501 (1.501)	Loss 2.3265 (2.3265)	Loss@kd 2.3995 (2.3995)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [32][100/875]	Time 0.773 (0.708)	Data 0.007 (0.022)	Loss 2.8160 (2.6774)	Loss@kd 2.6685 (2.5496)	Acc@1 67.188 (66.692)	Acc@5 95.312 (98.314)
Epoch: [32][200/875]	Time 0.773 (0.702)	Data 0.007 (0.015)	Loss 2.9526 (2.6689)	Loss@kd 2.5691 (2.5392)	Acc@1 70.312 (66.877)	Acc@5 95.312 (98.469)
Epoch: [32][300/875]	Time 0.750 (0.699)	Data 0.007 (0.012)	Loss 2.5121 (2.6596)	Loss@kd 2.4786 (2.5372)	Acc@1 73.438 (67.172)	Acc@5 98.438 (98.474)
Epoch: [32][400/875]	Time 0.777 (0.697)	Data 0.007 (0.011)	Loss 2.4774 (2.6539)	Loss@kd 2.4031 (2.5263)	Acc@1 70.312 (67.075)	Acc@5 98.438 (98.480)
Epoch: [32][500/875]	Time 0.771 (0.696)	Data 0.008 (0.010)	Loss 2.6657 (2.6460)	Loss@kd 2.3446 (2.5181)	Acc@1 65.625 (67.318)	Acc@5 96.875 (98.441)
Epoch: [32][600/875]	Time 0.757 (0.696)	Data 0.008 (0.010)	Loss 2.6415 (2.6425)	Loss@kd 2.5361 (2.5162)	Acc@1 65.625 (67.294)	Acc@5 96.875 (98.466)
Epoch: [32][700/875]	Time 0.764 (0.695)	Data 0.010 (0.010)	Loss 2.5444 (2.6387)	Loss@kd 2.4362 (2.5124)	Acc@1 70.312 (67.344)	Acc@5 95.312 (98.466)
Epoch: [32][800/875]	Time 0.757 (0.695)	Data 0.008 (0.009)	Loss 2.4035 (2.6326)	Loss@kd 2.4710 (2.5084)	Acc@1 73.438 (67.480)	Acc@5 100.000 (98.475)
 * Acc@1 67.525 Acc@5 98.480
epoch 32, total time 608.59
Test: [0/750]	Time 0.941 (0.941)	Loss 0.4768 (0.4768)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.116 (0.136)	Loss 0.6537 (0.5222)	Acc@1 78.125 (84.932)	Acc@5 93.750 (93.441)
Test: [200/750]	Time 0.201 (0.131)	Loss 1.8279 (0.5490)	Acc@1 31.250 (81.608)	Acc@5 75.000 (94.807)
Test: [300/750]	Time 0.132 (0.129)	Loss 1.3453 (0.8771)	Acc@1 50.000 (67.691)	Acc@5 84.375 (91.850)
Test: [400/750]	Time 0.117 (0.127)	Loss 0.6321 (0.9761)	Acc@1 75.000 (63.786)	Acc@5 84.375 (91.365)
Test: [500/750]	Time 0.124 (0.126)	Loss 0.6409 (0.9185)	Acc@1 81.250 (66.392)	Acc@5 93.750 (91.467)
Test: [600/750]	Time 0.122 (0.126)	Loss 0.6217 (0.8940)	Acc@1 75.000 (67.653)	Acc@5 93.750 (91.909)
Test: [700/750]	Time 0.109 (0.125)	Loss 1.1441 (0.8873)	Acc@1 62.500 (67.707)	Acc@5 87.500 (92.279)
 * Acc@1 67.858 Acc@5 92.233
==> training...
Epoch: [33][0/875]	Time 2.354 (2.354)	Data 1.621 (1.621)	Loss 2.6178 (2.6178)	Loss@kd 2.5267 (2.5267)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [33][100/875]	Time 0.671 (0.704)	Data 0.007 (0.023)	Loss 2.5875 (2.6036)	Loss@kd 2.5093 (2.4927)	Acc@1 64.062 (68.363)	Acc@5 100.000 (98.376)
Epoch: [33][200/875]	Time 0.668 (0.692)	Data 0.007 (0.015)	Loss 2.5509 (2.6113)	Loss@kd 2.6076 (2.5057)	Acc@1 71.875 (68.276)	Acc@5 100.000 (98.546)
Epoch: [33][300/875]	Time 0.657 (0.690)	Data 0.007 (0.013)	Loss 2.7152 (2.6076)	Loss@kd 2.5520 (2.5001)	Acc@1 67.188 (68.200)	Acc@5 98.438 (98.609)
Epoch: [33][400/875]	Time 0.790 (0.689)	Data 0.008 (0.011)	Loss 2.9591 (2.6212)	Loss@kd 2.4933 (2.5110)	Acc@1 57.812 (67.873)	Acc@5 98.438 (98.613)
Epoch: [33][500/875]	Time 0.673 (0.689)	Data 0.007 (0.011)	Loss 2.7717 (2.6229)	Loss@kd 2.5356 (2.5104)	Acc@1 56.250 (67.811)	Acc@5 100.000 (98.622)
Epoch: [33][600/875]	Time 0.674 (0.688)	Data 0.007 (0.010)	Loss 2.6306 (2.6319)	Loss@kd 2.5333 (2.5201)	Acc@1 67.188 (67.637)	Acc@5 100.000 (98.640)
Epoch: [33][700/875]	Time 0.693 (0.688)	Data 0.007 (0.010)	Loss 2.3501 (2.6308)	Loss@kd 2.3631 (2.5183)	Acc@1 73.438 (67.580)	Acc@5 100.000 (98.623)
Epoch: [33][800/875]	Time 0.685 (0.688)	Data 0.008 (0.009)	Loss 2.4018 (2.6291)	Loss@kd 2.3168 (2.5157)	Acc@1 68.750 (67.689)	Acc@5 98.438 (98.582)
 * Acc@1 67.618 Acc@5 98.584
epoch 33, total time 602.82
Test: [0/750]	Time 0.988 (0.988)	Loss 0.5955 (0.5955)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.124 (0.143)	Loss 0.6457 (0.5914)	Acc@1 75.000 (83.045)	Acc@5 93.750 (92.450)
Test: [200/750]	Time 0.124 (0.139)	Loss 1.0789 (0.5412)	Acc@1 53.125 (83.629)	Acc@5 96.875 (94.605)
Test: [300/750]	Time 0.185 (0.138)	Loss 1.3378 (0.7346)	Acc@1 43.750 (74.512)	Acc@5 93.750 (94.529)
Test: [400/750]	Time 0.130 (0.138)	Loss 0.6530 (0.8562)	Acc@1 84.375 (68.688)	Acc@5 90.625 (93.508)
Test: [500/750]	Time 0.130 (0.137)	Loss 0.8038 (0.8329)	Acc@1 65.625 (70.135)	Acc@5 100.000 (93.083)
Test: [600/750]	Time 0.130 (0.137)	Loss 1.0427 (0.8630)	Acc@1 65.625 (69.104)	Acc@5 84.375 (92.606)
Test: [700/750]	Time 0.117 (0.137)	Loss 0.8784 (0.8796)	Acc@1 62.500 (68.215)	Acc@5 87.500 (92.524)
 * Acc@1 68.417 Acc@5 92.608
==> training...
Epoch: [34][0/875]	Time 2.308 (2.308)	Data 1.592 (1.592)	Loss 2.4691 (2.4691)	Loss@kd 2.3551 (2.3551)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [34][100/875]	Time 0.673 (0.704)	Data 0.007 (0.023)	Loss 2.5796 (2.5938)	Loss@kd 2.3990 (2.4813)	Acc@1 68.750 (67.822)	Acc@5 98.438 (98.778)
Epoch: [34][200/875]	Time 0.802 (0.696)	Data 0.008 (0.015)	Loss 2.7063 (2.5925)	Loss@kd 2.4280 (2.4732)	Acc@1 70.312 (67.934)	Acc@5 98.438 (98.756)
Epoch: [34][300/875]	Time 0.683 (0.692)	Data 0.007 (0.013)	Loss 2.3768 (2.5887)	Loss@kd 2.4137 (2.4744)	Acc@1 73.438 (68.023)	Acc@5 100.000 (98.733)
Epoch: [34][400/875]	Time 0.681 (0.691)	Data 0.007 (0.011)	Loss 2.6643 (2.5896)	Loss@kd 2.4037 (2.4730)	Acc@1 71.875 (67.990)	Acc@5 100.000 (98.687)
Epoch: [34][500/875]	Time 0.674 (0.690)	Data 0.007 (0.011)	Loss 2.4926 (2.6000)	Loss@kd 2.3512 (2.4800)	Acc@1 70.312 (67.749)	Acc@5 100.000 (98.637)
Epoch: [34][600/875]	Time 0.689 (0.690)	Data 0.007 (0.010)	Loss 2.7707 (2.6046)	Loss@kd 2.5228 (2.4863)	Acc@1 60.938 (67.796)	Acc@5 98.438 (98.640)
Epoch: [34][700/875]	Time 0.680 (0.690)	Data 0.008 (0.010)	Loss 2.6027 (2.6014)	Loss@kd 2.4299 (2.4812)	Acc@1 60.938 (67.814)	Acc@5 96.875 (98.660)
Epoch: [34][800/875]	Time 0.673 (0.690)	Data 0.007 (0.009)	Loss 2.4009 (2.6003)	Loss@kd 2.4502 (2.4839)	Acc@1 70.312 (67.884)	Acc@5 100.000 (98.636)
 * Acc@1 67.804 Acc@5 98.620
epoch 34, total time 604.04
Test: [0/750]	Time 1.010 (1.010)	Loss 0.4939 (0.4939)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.133 (0.144)	Loss 0.5670 (0.5809)	Acc@1 84.375 (85.458)	Acc@5 96.875 (92.791)
Test: [200/750]	Time 0.104 (0.135)	Loss 1.4022 (0.5369)	Acc@1 40.625 (84.173)	Acc@5 87.500 (94.729)
Test: [300/750]	Time 0.117 (0.131)	Loss 1.1640 (0.7789)	Acc@1 50.000 (72.716)	Acc@5 93.750 (93.781)
Test: [400/750]	Time 0.122 (0.129)	Loss 0.5487 (0.8478)	Acc@1 81.250 (69.576)	Acc@5 93.750 (93.438)
Test: [500/750]	Time 0.131 (0.128)	Loss 0.5589 (0.8049)	Acc@1 81.250 (71.438)	Acc@5 96.875 (93.370)
Test: [600/750]	Time 0.115 (0.128)	Loss 1.2417 (0.8390)	Acc@1 56.250 (70.242)	Acc@5 81.250 (92.965)
Test: [700/750]	Time 0.199 (0.127)	Loss 1.3394 (0.9026)	Acc@1 56.250 (67.377)	Acc@5 84.375 (92.413)
 * Acc@1 66.675 Acc@5 92.183
==> training...
Epoch: [35][0/875]	Time 2.264 (2.264)	Data 1.585 (1.585)	Loss 2.5143 (2.5143)	Loss@kd 2.2871 (2.2871)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [35][100/875]	Time 0.676 (0.706)	Data 0.007 (0.023)	Loss 2.4190 (2.5744)	Loss@kd 2.2719 (2.4536)	Acc@1 73.438 (68.085)	Acc@5 98.438 (98.298)
Epoch: [35][200/875]	Time 0.686 (0.700)	Data 0.008 (0.015)	Loss 2.5274 (2.5762)	Loss@kd 2.3490 (2.4614)	Acc@1 68.750 (68.330)	Acc@5 95.312 (98.492)
Epoch: [35][300/875]	Time 0.687 (0.698)	Data 0.007 (0.013)	Loss 2.5875 (2.5856)	Loss@kd 2.4638 (2.4697)	Acc@1 67.188 (68.091)	Acc@5 100.000 (98.484)
Epoch: [35][400/875]	Time 0.674 (0.696)	Data 0.007 (0.011)	Loss 2.7415 (2.5994)	Loss@kd 2.3938 (2.4837)	Acc@1 59.375 (67.885)	Acc@5 96.875 (98.512)
Epoch: [35][500/875]	Time 0.682 (0.696)	Data 0.007 (0.010)	Loss 2.5912 (2.5945)	Loss@kd 2.4226 (2.4806)	Acc@1 64.062 (68.104)	Acc@5 100.000 (98.559)
Epoch: [35][600/875]	Time 0.682 (0.695)	Data 0.008 (0.010)	Loss 2.5781 (2.5968)	Loss@kd 2.3689 (2.4786)	Acc@1 76.562 (67.993)	Acc@5 100.000 (98.562)
Epoch: [35][700/875]	Time 0.675 (0.695)	Data 0.007 (0.010)	Loss 2.5862 (2.5949)	Loss@kd 2.4946 (2.4757)	Acc@1 73.438 (67.992)	Acc@5 93.750 (98.569)
Epoch: [35][800/875]	Time 0.692 (0.695)	Data 0.007 (0.009)	Loss 2.5375 (2.5937)	Loss@kd 2.3336 (2.4730)	Acc@1 62.500 (68.001)	Acc@5 100.000 (98.566)
 * Acc@1 68.009 Acc@5 98.580
epoch 35, total time 608.31
Test: [0/750]	Time 1.019 (1.019)	Loss 0.5579 (0.5579)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.181 (0.147)	Loss 0.5454 (0.5230)	Acc@1 81.250 (83.942)	Acc@5 96.875 (93.441)
Test: [200/750]	Time 0.111 (0.136)	Loss 1.3004 (0.5422)	Acc@1 46.875 (82.074)	Acc@5 93.750 (95.009)
Test: [300/750]	Time 0.125 (0.131)	Loss 1.5938 (0.8027)	Acc@1 37.500 (71.055)	Acc@5 87.500 (93.480)
Test: [400/750]	Time 0.124 (0.130)	Loss 0.4638 (0.9456)	Acc@1 87.500 (65.181)	Acc@5 93.750 (91.817)
Test: [500/750]	Time 0.109 (0.129)	Loss 0.5850 (0.8699)	Acc@1 84.375 (68.550)	Acc@5 96.875 (92.372)
Test: [600/750]	Time 0.204 (0.128)	Loss 0.8375 (0.8546)	Acc@1 68.750 (69.338)	Acc@5 90.625 (92.622)
Test: [700/750]	Time 0.129 (0.128)	Loss 1.1007 (0.8585)	Acc@1 56.250 (68.906)	Acc@5 87.500 (92.841)
 * Acc@1 68.762 Acc@5 92.846
==> training...
Epoch: [36][0/875]	Time 2.309 (2.309)	Data 1.610 (1.610)	Loss 2.4851 (2.4851)	Loss@kd 2.3403 (2.3403)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [36][100/875]	Time 0.665 (0.706)	Data 0.006 (0.023)	Loss 2.4511 (2.5598)	Loss@kd 2.5821 (2.4265)	Acc@1 79.688 (68.286)	Acc@5 96.875 (98.530)
Epoch: [36][200/875]	Time 0.675 (0.697)	Data 0.007 (0.015)	Loss 2.5651 (2.5550)	Loss@kd 2.3779 (2.4244)	Acc@1 65.625 (68.019)	Acc@5 98.438 (98.492)
Epoch: [36][300/875]	Time 0.670 (0.695)	Data 0.008 (0.013)	Loss 2.4460 (2.5607)	Loss@kd 2.4609 (2.4417)	Acc@1 70.312 (68.246)	Acc@5 98.438 (98.505)
Epoch: [36][400/875]	Time 0.682 (0.695)	Data 0.006 (0.011)	Loss 2.6072 (2.5604)	Loss@kd 2.3965 (2.4426)	Acc@1 64.062 (68.333)	Acc@5 96.875 (98.519)
Epoch: [36][500/875]	Time 0.674 (0.694)	Data 0.008 (0.011)	Loss 2.6120 (2.5655)	Loss@kd 2.3728 (2.4446)	Acc@1 62.500 (68.204)	Acc@5 96.875 (98.525)
Epoch: [36][600/875]	Time 0.687 (0.694)	Data 0.008 (0.010)	Loss 2.3400 (2.5638)	Loss@kd 2.3520 (2.4421)	Acc@1 75.000 (68.105)	Acc@5 100.000 (98.526)
Epoch: [36][700/875]	Time 0.683 (0.693)	Data 0.007 (0.010)	Loss 3.0103 (2.5792)	Loss@kd 2.6550 (2.4571)	Acc@1 51.562 (67.890)	Acc@5 98.438 (98.495)
Epoch: [36][800/875]	Time 0.675 (0.693)	Data 0.007 (0.009)	Loss 2.4433 (2.5838)	Loss@kd 2.4118 (2.4622)	Acc@1 67.188 (67.890)	Acc@5 100.000 (98.535)
 * Acc@1 68.029 Acc@5 98.557
epoch 36, total time 606.96
Test: [0/750]	Time 1.069 (1.069)	Loss 0.4532 (0.4532)	Acc@1 90.625 (90.625)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.129 (0.145)	Loss 0.6031 (0.5447)	Acc@1 71.875 (83.818)	Acc@5 100.000 (93.100)
Test: [200/750]	Time 0.125 (0.139)	Loss 1.5520 (0.5549)	Acc@1 34.375 (81.297)	Acc@5 87.500 (95.025)
Test: [300/750]	Time 0.135 (0.137)	Loss 1.2353 (0.8457)	Acc@1 56.250 (68.044)	Acc@5 90.625 (92.961)
Test: [400/750]	Time 0.130 (0.136)	Loss 0.5063 (0.9185)	Acc@1 87.500 (65.157)	Acc@5 90.625 (92.511)
Test: [500/750]	Time 0.118 (0.135)	Loss 0.4146 (0.8450)	Acc@1 90.625 (68.688)	Acc@5 100.000 (92.977)
Test: [600/750]	Time 0.132 (0.135)	Loss 0.9659 (0.8306)	Acc@1 68.750 (69.702)	Acc@5 87.500 (93.121)
Test: [700/750]	Time 0.087 (0.134)	Loss 1.0087 (0.8392)	Acc@1 65.625 (69.280)	Acc@5 87.500 (93.148)
 * Acc@1 69.300 Acc@5 93.050
saving the best model!
==> training...
Epoch: [37][0/875]	Time 2.276 (2.276)	Data 1.578 (1.578)	Loss 2.6924 (2.6924)	Loss@kd 2.4210 (2.4210)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [37][100/875]	Time 0.669 (0.695)	Data 0.007 (0.023)	Loss 2.3602 (2.5480)	Loss@kd 2.4962 (2.4420)	Acc@1 76.562 (69.353)	Acc@5 100.000 (98.685)
Epoch: [37][200/875]	Time 0.678 (0.688)	Data 0.007 (0.015)	Loss 2.7009 (2.5657)	Loss@kd 2.5512 (2.4571)	Acc@1 76.562 (69.045)	Acc@5 96.875 (98.624)
Epoch: [37][300/875]	Time 0.659 (0.685)	Data 0.009 (0.013)	Loss 2.4676 (2.5600)	Loss@kd 2.3691 (2.4509)	Acc@1 67.188 (68.973)	Acc@5 100.000 (98.645)
Epoch: [37][400/875]	Time 0.677 (0.684)	Data 0.007 (0.011)	Loss 2.7583 (2.5619)	Loss@kd 2.3657 (2.4465)	Acc@1 59.375 (68.762)	Acc@5 98.438 (98.593)
Epoch: [37][500/875]	Time 0.665 (0.683)	Data 0.007 (0.011)	Loss 2.3734 (2.5578)	Loss@kd 2.3145 (2.4388)	Acc@1 78.125 (68.638)	Acc@5 98.438 (98.556)
Epoch: [37][600/875]	Time 0.686 (0.682)	Data 0.007 (0.010)	Loss 2.4063 (2.5610)	Loss@kd 2.4209 (2.4411)	Acc@1 73.438 (68.649)	Acc@5 96.875 (98.544)
Epoch: [37][700/875]	Time 0.663 (0.682)	Data 0.006 (0.010)	Loss 2.6289 (2.5618)	Loss@kd 2.4358 (2.4430)	Acc@1 68.750 (68.754)	Acc@5 100.000 (98.558)
Epoch: [37][800/875]	Time 0.677 (0.681)	Data 0.008 (0.009)	Loss 2.3980 (2.5618)	Loss@kd 2.3378 (2.4436)	Acc@1 64.062 (68.828)	Acc@5 100.000 (98.576)
 * Acc@1 68.779 Acc@5 98.589
epoch 37, total time 596.26
Test: [0/750]	Time 1.001 (1.001)	Loss 1.0538 (1.0538)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.127 (0.144)	Loss 0.5270 (0.6351)	Acc@1 75.000 (82.797)	Acc@5 96.875 (91.863)
Test: [200/750]	Time 0.110 (0.138)	Loss 1.7122 (0.6041)	Acc@1 25.000 (80.846)	Acc@5 81.250 (94.170)
Test: [300/750]	Time 0.134 (0.134)	Loss 0.9938 (0.8867)	Acc@1 71.875 (67.307)	Acc@5 93.750 (91.964)
Test: [400/750]	Time 0.137 (0.134)	Loss 0.7612 (0.9111)	Acc@1 75.000 (65.945)	Acc@5 87.500 (92.449)
Test: [500/750]	Time 0.138 (0.133)	Loss 0.7315 (0.8921)	Acc@1 78.125 (67.484)	Acc@5 93.750 (92.134)
Test: [600/750]	Time 0.122 (0.132)	Loss 0.7443 (0.8911)	Acc@1 68.750 (67.882)	Acc@5 93.750 (92.294)
Test: [700/750]	Time 0.136 (0.132)	Loss 1.0177 (0.8892)	Acc@1 62.500 (67.618)	Acc@5 87.500 (92.618)
 * Acc@1 67.637 Acc@5 92.558
==> training...
Epoch: [38][0/875]	Time 2.315 (2.315)	Data 1.617 (1.617)	Loss 4.1186 (4.1186)	Loss@kd 4.1551 (4.1551)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [38][100/875]	Time 0.752 (0.698)	Data 0.008 (0.023)	Loss 2.5102 (2.5963)	Loss@kd 2.2505 (2.4982)	Acc@1 68.750 (68.843)	Acc@5 96.875 (98.793)
Epoch: [38][200/875]	Time 0.677 (0.690)	Data 0.007 (0.015)	Loss 2.4773 (2.5706)	Loss@kd 2.3542 (2.4633)	Acc@1 67.188 (68.937)	Acc@5 100.000 (98.733)
Epoch: [38][300/875]	Time 0.693 (0.687)	Data 0.010 (0.013)	Loss 2.6734 (2.5633)	Loss@kd 2.3556 (2.4526)	Acc@1 59.375 (69.098)	Acc@5 100.000 (98.697)
Epoch: [38][400/875]	Time 0.704 (0.687)	Data 0.007 (0.011)	Loss 2.6898 (2.5587)	Loss@kd 2.5245 (2.4519)	Acc@1 59.375 (69.108)	Acc@5 98.438 (98.656)
Epoch: [38][500/875]	Time 0.695 (0.687)	Data 0.007 (0.011)	Loss 2.5224 (2.5595)	Loss@kd 2.3668 (2.4480)	Acc@1 67.188 (68.787)	Acc@5 96.875 (98.612)
Epoch: [38][600/875]	Time 0.684 (0.687)	Data 0.007 (0.010)	Loss 2.5404 (2.5606)	Loss@kd 2.5489 (2.4467)	Acc@1 76.562 (68.659)	Acc@5 100.000 (98.645)
Epoch: [38][700/875]	Time 0.656 (0.687)	Data 0.005 (0.010)	Loss 2.4669 (2.5565)	Loss@kd 2.2608 (2.4434)	Acc@1 70.312 (68.721)	Acc@5 98.438 (98.631)
Epoch: [38][800/875]	Time 0.782 (0.687)	Data 0.007 (0.009)	Loss 2.5653 (2.5559)	Loss@kd 2.3931 (2.4405)	Acc@1 65.625 (68.615)	Acc@5 96.875 (98.613)
 * Acc@1 68.741 Acc@5 98.643
epoch 38, total time 601.34
Test: [0/750]	Time 1.012 (1.012)	Loss 0.5885 (0.5885)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.179 (0.142)	Loss 0.8233 (0.7196)	Acc@1 75.000 (82.024)	Acc@5 90.625 (91.027)
Test: [200/750]	Time 0.111 (0.133)	Loss 1.2962 (0.7390)	Acc@1 34.375 (77.596)	Acc@5 93.750 (92.848)
Test: [300/750]	Time 0.100 (0.130)	Loss 1.5861 (0.9215)	Acc@1 34.375 (68.335)	Acc@5 84.375 (92.130)
Test: [400/750]	Time 0.133 (0.129)	Loss 0.3440 (1.0513)	Acc@1 84.375 (62.484)	Acc@5 100.000 (90.368)
Test: [500/750]	Time 0.107 (0.129)	Loss 0.6331 (0.9598)	Acc@1 75.000 (66.136)	Acc@5 100.000 (91.330)
Test: [600/750]	Time 0.095 (0.129)	Loss 1.0894 (0.9615)	Acc@1 62.500 (66.213)	Acc@5 78.125 (91.317)
Test: [700/750]	Time 0.112 (0.128)	Loss 1.0152 (0.9746)	Acc@1 65.625 (65.625)	Acc@5 90.625 (91.236)
 * Acc@1 65.592 Acc@5 91.267
==> training...
Epoch: [39][0/875]	Time 2.340 (2.340)	Data 1.619 (1.619)	Loss 2.8839 (2.8839)	Loss@kd 2.6320 (2.6320)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [39][100/875]	Time 0.687 (0.706)	Data 0.007 (0.023)	Loss 2.4031 (2.6152)	Loss@kd 2.2809 (2.5111)	Acc@1 68.750 (68.394)	Acc@5 98.438 (98.670)
Epoch: [39][200/875]	Time 0.688 (0.697)	Data 0.006 (0.015)	Loss 2.3763 (2.5645)	Loss@kd 2.3302 (2.4556)	Acc@1 71.875 (68.750)	Acc@5 100.000 (98.741)
Epoch: [39][300/875]	Time 0.676 (0.694)	Data 0.007 (0.013)	Loss 2.6320 (2.5540)	Loss@kd 2.3097 (2.4371)	Acc@1 60.938 (68.625)	Acc@5 100.000 (98.640)
Epoch: [39][400/875]	Time 0.681 (0.693)	Data 0.007 (0.011)	Loss 2.7625 (2.5498)	Loss@kd 2.4000 (2.4330)	Acc@1 65.625 (68.625)	Acc@5 92.188 (98.656)
Epoch: [39][500/875]	Time 0.690 (0.692)	Data 0.008 (0.011)	Loss 2.4160 (2.5483)	Loss@kd 2.3970 (2.4304)	Acc@1 71.875 (68.578)	Acc@5 96.875 (98.684)
Epoch: [39][600/875]	Time 0.783 (0.692)	Data 0.007 (0.010)	Loss 2.6108 (2.5480)	Loss@kd 2.3741 (2.4313)	Acc@1 62.500 (68.630)	Acc@5 98.438 (98.690)
Epoch: [39][700/875]	Time 0.675 (0.692)	Data 0.007 (0.010)	Loss 2.4799 (2.5467)	Loss@kd 2.4092 (2.4311)	Acc@1 68.750 (68.781)	Acc@5 100.000 (98.649)
Epoch: [39][800/875]	Time 0.696 (0.691)	Data 0.007 (0.010)	Loss 2.4277 (2.5492)	Loss@kd 2.3385 (2.4355)	Acc@1 65.625 (68.754)	Acc@5 100.000 (98.635)
 * Acc@1 68.629 Acc@5 98.625
epoch 39, total time 605.41
Test: [0/750]	Time 1.140 (1.140)	Loss 0.5356 (0.5356)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.132 (0.142)	Loss 0.6134 (0.6069)	Acc@1 78.125 (84.623)	Acc@5 93.750 (91.925)
Test: [200/750]	Time 0.115 (0.137)	Loss 1.5308 (0.5875)	Acc@1 31.250 (82.416)	Acc@5 87.500 (94.123)
Test: [300/750]	Time 0.134 (0.135)	Loss 1.5364 (0.8663)	Acc@1 53.125 (69.300)	Acc@5 84.375 (92.130)
Test: [400/750]	Time 0.110 (0.134)	Loss 0.6033 (0.9298)	Acc@1 78.125 (66.038)	Acc@5 96.875 (92.238)
Test: [500/750]	Time 0.119 (0.133)	Loss 0.7118 (0.8865)	Acc@1 71.875 (67.958)	Acc@5 96.875 (92.184)
Test: [600/750]	Time 0.127 (0.133)	Loss 0.8170 (0.8946)	Acc@1 65.625 (68.006)	Acc@5 93.750 (92.117)
Test: [700/750]	Time 0.130 (0.133)	Loss 0.9399 (0.9006)	Acc@1 65.625 (67.582)	Acc@5 93.750 (92.435)
 * Acc@1 67.838 Acc@5 92.554
==> training...
Epoch: [40][0/875]	Time 2.319 (2.319)	Data 1.614 (1.614)	Loss 2.4618 (2.4618)	Loss@kd 2.4508 (2.4508)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [40][100/875]	Time 0.679 (0.702)	Data 0.006 (0.023)	Loss 2.6410 (2.5534)	Loss@kd 2.4229 (2.4655)	Acc@1 64.062 (69.895)	Acc@5 98.438 (98.871)
Epoch: [40][200/875]	Time 0.684 (0.693)	Data 0.007 (0.015)	Loss 2.5376 (2.5266)	Loss@kd 2.3422 (2.4340)	Acc@1 65.625 (69.636)	Acc@5 98.438 (98.780)
Epoch: [40][300/875]	Time 0.688 (0.692)	Data 0.008 (0.013)	Loss 2.3234 (2.5179)	Loss@kd 2.2969 (2.4227)	Acc@1 68.750 (69.523)	Acc@5 98.438 (98.702)
Epoch: [40][400/875]	Time 0.693 (0.692)	Data 0.008 (0.011)	Loss 2.6182 (2.5181)	Loss@kd 2.2957 (2.4176)	Acc@1 56.250 (69.428)	Acc@5 95.312 (98.660)
Epoch: [40][500/875]	Time 0.669 (0.691)	Data 0.007 (0.011)	Loss 2.4661 (2.5182)	Loss@kd 2.2759 (2.4150)	Acc@1 68.750 (69.258)	Acc@5 93.750 (98.675)
Epoch: [40][600/875]	Time 0.678 (0.689)	Data 0.007 (0.010)	Loss 2.3125 (2.5223)	Loss@kd 2.2817 (2.4158)	Acc@1 73.438 (69.218)	Acc@5 100.000 (98.653)
Epoch: [40][700/875]	Time 0.670 (0.688)	Data 0.007 (0.010)	Loss 2.2650 (2.5199)	Loss@kd 2.4164 (2.4116)	Acc@1 78.125 (69.111)	Acc@5 100.000 (98.672)
Epoch: [40][800/875]	Time 0.691 (0.687)	Data 0.008 (0.009)	Loss 2.3842 (2.5194)	Loss@kd 2.3040 (2.4090)	Acc@1 70.312 (69.099)	Acc@5 98.438 (98.689)
 * Acc@1 69.055 Acc@5 98.664
epoch 40, total time 600.77
Test: [0/750]	Time 0.931 (0.931)	Loss 0.9302 (0.9302)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.125 (0.129)	Loss 0.3912 (0.6567)	Acc@1 84.375 (79.950)	Acc@5 96.875 (92.884)
Test: [200/750]	Time 0.116 (0.126)	Loss 1.6859 (0.5678)	Acc@1 18.750 (81.421)	Acc@5 81.250 (94.698)
Test: [300/750]	Time 0.094 (0.126)	Loss 0.8585 (0.8640)	Acc@1 81.250 (67.930)	Acc@5 96.875 (92.442)
Test: [400/750]	Time 0.113 (0.125)	Loss 0.7340 (0.8755)	Acc@1 71.875 (67.838)	Acc@5 93.750 (93.197)
Test: [500/750]	Time 0.116 (0.125)	Loss 0.7337 (0.8644)	Acc@1 78.125 (68.968)	Acc@5 90.625 (92.758)
Test: [600/750]	Time 0.123 (0.124)	Loss 0.9075 (0.8876)	Acc@1 65.625 (68.438)	Acc@5 90.625 (92.486)
Test: [700/750]	Time 0.187 (0.124)	Loss 1.2654 (0.9143)	Acc@1 53.125 (66.994)	Acc@5 84.375 (92.640)
 * Acc@1 66.675 Acc@5 92.533
==> Saving...
==> training...
Epoch: [41][0/875]	Time 2.244 (2.244)	Data 1.580 (1.580)	Loss 2.5544 (2.5544)	Loss@kd 2.2618 (2.2618)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)
Epoch: [41][100/875]	Time 0.674 (0.701)	Data 0.007 (0.023)	Loss 2.9042 (2.5211)	Loss@kd 2.3848 (2.4058)	Acc@1 54.688 (68.580)	Acc@5 93.750 (98.654)
Epoch: [41][200/875]	Time 0.672 (0.692)	Data 0.008 (0.015)	Loss 2.5093 (2.5221)	Loss@kd 2.3323 (2.4194)	Acc@1 62.500 (68.983)	Acc@5 96.875 (98.702)
Epoch: [41][300/875]	Time 0.682 (0.688)	Data 0.007 (0.013)	Loss 2.6450 (2.5075)	Loss@kd 2.3435 (2.4061)	Acc@1 62.500 (69.165)	Acc@5 98.438 (98.718)
Epoch: [41][400/875]	Time 0.663 (0.686)	Data 0.007 (0.011)	Loss 2.6074 (2.5126)	Loss@kd 2.4277 (2.4050)	Acc@1 65.625 (68.894)	Acc@5 98.438 (98.702)
Epoch: [41][500/875]	Time 0.682 (0.687)	Data 0.007 (0.011)	Loss 2.5337 (2.5048)	Loss@kd 2.2984 (2.3964)	Acc@1 64.062 (69.049)	Acc@5 100.000 (98.665)
Epoch: [41][600/875]	Time 0.684 (0.688)	Data 0.007 (0.010)	Loss 2.5276 (2.5063)	Loss@kd 2.4497 (2.3956)	Acc@1 68.750 (69.036)	Acc@5 98.438 (98.690)
Epoch: [41][700/875]	Time 0.665 (0.689)	Data 0.007 (0.010)	Loss 2.2215 (2.5025)	Loss@kd 2.3930 (2.3927)	Acc@1 82.812 (69.133)	Acc@5 98.438 (98.721)
Epoch: [41][800/875]	Time 0.684 (0.690)	Data 0.007 (0.009)	Loss 2.5257 (2.5034)	Loss@kd 2.3629 (2.3926)	Acc@1 73.438 (69.091)	Acc@5 98.438 (98.732)
 * Acc@1 69.082 Acc@5 98.714
epoch 41, total time 604.35
Test: [0/750]	Time 1.006 (1.006)	Loss 0.5092 (0.5092)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.208 (0.145)	Loss 0.6469 (0.5667)	Acc@1 68.750 (83.849)	Acc@5 100.000 (92.822)
Test: [200/750]	Time 0.128 (0.137)	Loss 1.1749 (0.5825)	Acc@1 53.125 (81.328)	Acc@5 93.750 (95.056)
Test: [300/750]	Time 0.137 (0.135)	Loss 2.0225 (0.8029)	Acc@1 31.250 (71.719)	Acc@5 81.250 (93.999)
Test: [400/750]	Time 0.124 (0.133)	Loss 0.3719 (0.9795)	Acc@1 84.375 (64.783)	Acc@5 96.875 (91.202)
Test: [500/750]	Time 0.130 (0.133)	Loss 0.6581 (0.8964)	Acc@1 78.125 (68.270)	Acc@5 93.750 (91.966)
Test: [600/750]	Time 0.140 (0.133)	Loss 0.8239 (0.8869)	Acc@1 75.000 (68.786)	Acc@5 93.750 (92.123)
Test: [700/750]	Time 0.131 (0.133)	Loss 0.9420 (0.8867)	Acc@1 62.500 (68.567)	Acc@5 90.625 (92.368)
 * Acc@1 68.483 Acc@5 92.362
==> training...
Epoch: [42][0/875]	Time 2.417 (2.417)	Data 1.698 (1.698)	Loss 2.3403 (2.3403)	Loss@kd 2.2589 (2.2589)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [42][100/875]	Time 0.670 (0.703)	Data 0.006 (0.024)	Loss 2.5755 (2.4696)	Loss@kd 2.3954 (2.3923)	Acc@1 70.312 (69.957)	Acc@5 100.000 (98.917)
Epoch: [42][200/875]	Time 0.674 (0.695)	Data 0.007 (0.016)	Loss 2.6268 (2.4943)	Loss@kd 2.6298 (2.4055)	Acc@1 70.312 (69.970)	Acc@5 98.438 (98.803)
Epoch: [42][300/875]	Time 0.688 (0.693)	Data 0.007 (0.013)	Loss 2.4242 (2.5037)	Loss@kd 2.2320 (2.4050)	Acc@1 64.062 (69.549)	Acc@5 100.000 (98.728)
Epoch: [42][400/875]	Time 0.680 (0.691)	Data 0.008 (0.012)	Loss 2.3756 (2.4951)	Loss@kd 2.2487 (2.3916)	Acc@1 59.375 (69.393)	Acc@5 98.438 (98.761)
Epoch: [42][500/875]	Time 0.724 (0.691)	Data 0.007 (0.011)	Loss 2.2755 (2.5024)	Loss@kd 2.2086 (2.3926)	Acc@1 71.875 (69.143)	Acc@5 100.000 (98.784)
Epoch: [42][600/875]	Time 0.670 (0.690)	Data 0.008 (0.010)	Loss 2.5009 (2.5035)	Loss@kd 2.4394 (2.3919)	Acc@1 73.438 (68.984)	Acc@5 100.000 (98.775)
Epoch: [42][700/875]	Time 0.670 (0.690)	Data 0.007 (0.010)	Loss 2.3493 (2.5084)	Loss@kd 2.3636 (2.3937)	Acc@1 75.000 (68.788)	Acc@5 100.000 (98.787)
Epoch: [42][800/875]	Time 0.679 (0.690)	Data 0.008 (0.010)	Loss 2.4346 (2.5073)	Loss@kd 2.4809 (2.3966)	Acc@1 70.312 (68.865)	Acc@5 100.000 (98.773)
 * Acc@1 69.059 Acc@5 98.745
epoch 42, total time 604.35
Test: [0/750]	Time 0.946 (0.946)	Loss 3.4936 (3.4936)	Acc@1 21.875 (21.875)	Acc@5 50.000 (50.000)
Test: [100/750]	Time 0.121 (0.141)	Loss 0.9048 (2.2387)	Acc@1 62.500 (34.715)	Acc@5 96.875 (72.958)
Test: [200/750]	Time 0.117 (0.134)	Loss 1.3906 (1.4998)	Acc@1 43.750 (52.270)	Acc@5 84.375 (84.795)
Test: [300/750]	Time 0.110 (0.131)	Loss 1.1650 (1.4187)	Acc@1 59.375 (51.485)	Acc@5 93.750 (87.324)
Test: [400/750]	Time 0.092 (0.129)	Loss 0.6391 (1.3427)	Acc@1 81.250 (52.907)	Acc@5 90.625 (88.677)
Test: [500/750]	Time 0.121 (0.129)	Loss 0.5722 (1.2191)	Acc@1 81.250 (57.522)	Acc@5 93.750 (89.465)
Test: [600/750]	Time 0.106 (0.128)	Loss 0.6837 (1.1403)	Acc@1 71.875 (60.519)	Acc@5 90.625 (90.225)
Test: [700/750]	Time 0.175 (0.127)	Loss 1.0042 (1.0876)	Acc@1 65.625 (62.090)	Acc@5 81.250 (90.866)
 * Acc@1 62.325 Acc@5 90.992
==> training...
Epoch: [43][0/875]	Time 2.321 (2.321)	Data 1.620 (1.620)	Loss 2.5010 (2.5010)	Loss@kd 2.3626 (2.3626)	Acc@1 70.312 (70.312)	Acc@5 95.312 (95.312)
Epoch: [43][100/875]	Time 0.674 (0.706)	Data 0.007 (0.023)	Loss 2.2901 (2.4922)	Loss@kd 2.2017 (2.3867)	Acc@1 71.875 (69.539)	Acc@5 98.438 (98.809)
Epoch: [43][200/875]	Time 0.683 (0.698)	Data 0.008 (0.016)	Loss 2.3820 (2.4815)	Loss@kd 2.4464 (2.3792)	Acc@1 78.125 (69.675)	Acc@5 100.000 (98.919)
Epoch: [43][300/875]	Time 0.666 (0.695)	Data 0.008 (0.013)	Loss 2.4479 (2.4779)	Loss@kd 2.3668 (2.3853)	Acc@1 73.438 (69.871)	Acc@5 98.438 (98.905)
Epoch: [43][400/875]	Time 0.677 (0.693)	Data 0.007 (0.012)	Loss 2.5989 (2.4793)	Loss@kd 2.6399 (2.3867)	Acc@1 76.562 (69.938)	Acc@5 100.000 (98.889)
Epoch: [43][500/875]	Time 0.678 (0.692)	Data 0.007 (0.011)	Loss 2.6454 (2.4847)	Loss@kd 2.4982 (2.3861)	Acc@1 67.188 (69.795)	Acc@5 98.438 (98.855)
Epoch: [43][600/875]	Time 0.680 (0.691)	Data 0.007 (0.010)	Loss 2.3843 (2.4866)	Loss@kd 2.2920 (2.3832)	Acc@1 68.750 (69.624)	Acc@5 98.438 (98.817)
Epoch: [43][700/875]	Time 0.683 (0.691)	Data 0.007 (0.010)	Loss 2.4838 (2.4841)	Loss@kd 2.2891 (2.3796)	Acc@1 70.312 (69.615)	Acc@5 96.875 (98.792)
Epoch: [43][800/875]	Time 0.679 (0.691)	Data 0.010 (0.010)	Loss 2.3853 (2.4849)	Loss@kd 2.3692 (2.3799)	Acc@1 76.562 (69.700)	Acc@5 100.000 (98.755)
 * Acc@1 69.630 Acc@5 98.746
epoch 43, total time 605.05
Test: [0/750]	Time 0.993 (0.993)	Loss 0.4887 (0.4887)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.117 (0.143)	Loss 0.7276 (0.5300)	Acc@1 71.875 (84.994)	Acc@5 90.625 (93.905)
Test: [200/750]	Time 0.120 (0.137)	Loss 1.3043 (0.5887)	Acc@1 53.125 (80.675)	Acc@5 87.500 (95.134)
Test: [300/750]	Time 0.175 (0.135)	Loss 1.1765 (0.8109)	Acc@1 65.625 (70.702)	Acc@5 90.625 (94.134)
Test: [400/750]	Time 0.118 (0.134)	Loss 0.7827 (0.9047)	Acc@1 71.875 (66.365)	Acc@5 93.750 (93.306)
Test: [500/750]	Time 0.130 (0.134)	Loss 0.5802 (0.8888)	Acc@1 75.000 (67.821)	Acc@5 93.750 (92.727)
Test: [600/750]	Time 0.114 (0.134)	Loss 0.9270 (0.8821)	Acc@1 65.625 (68.402)	Acc@5 87.500 (92.746)
Test: [700/750]	Time 0.136 (0.134)	Loss 0.8395 (0.8774)	Acc@1 68.750 (68.487)	Acc@5 93.750 (92.974)
 * Acc@1 69.062 Acc@5 93.088
==> training...
Epoch: [44][0/875]	Time 2.408 (2.408)	Data 1.701 (1.701)	Loss 2.2972 (2.2972)	Loss@kd 2.3453 (2.3453)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Epoch: [44][100/875]	Time 0.677 (0.706)	Data 0.007 (0.024)	Loss 2.5127 (2.5724)	Loss@kd 2.3781 (2.4786)	Acc@1 71.875 (69.183)	Acc@5 98.438 (98.422)
Epoch: [44][200/875]	Time 0.692 (0.697)	Data 0.008 (0.016)	Loss 2.4932 (2.5188)	Loss@kd 2.3845 (2.4369)	Acc@1 70.312 (69.535)	Acc@5 100.000 (98.756)
Epoch: [44][300/875]	Time 0.687 (0.694)	Data 0.007 (0.013)	Loss 2.3228 (2.5128)	Loss@kd 2.2362 (2.4227)	Acc@1 73.438 (69.337)	Acc@5 100.000 (98.796)
Epoch: [44][400/875]	Time 0.687 (0.693)	Data 0.007 (0.012)	Loss 2.2833 (2.4940)	Loss@kd 2.2162 (2.4008)	Acc@1 68.750 (69.592)	Acc@5 100.000 (98.878)
Epoch: [44][500/875]	Time 0.797 (0.693)	Data 0.007 (0.011)	Loss 2.6827 (2.4902)	Loss@kd 2.4387 (2.3953)	Acc@1 64.062 (69.720)	Acc@5 100.000 (98.837)
Epoch: [44][600/875]	Time 0.685 (0.692)	Data 0.007 (0.010)	Loss 2.5522 (2.4860)	Loss@kd 2.2682 (2.3840)	Acc@1 65.625 (69.655)	Acc@5 95.312 (98.812)
Epoch: [44][700/875]	Time 0.674 (0.692)	Data 0.008 (0.010)	Loss 2.4797 (2.4842)	Loss@kd 2.3919 (2.3816)	Acc@1 68.750 (69.679)	Acc@5 100.000 (98.783)
Epoch: [44][800/875]	Time 0.698 (0.692)	Data 0.007 (0.010)	Loss 2.4416 (2.4804)	Loss@kd 2.3520 (2.3762)	Acc@1 71.875 (69.719)	Acc@5 100.000 (98.785)
 * Acc@1 69.645 Acc@5 98.800
epoch 44, total time 605.35
Test: [0/750]	Time 0.954 (0.954)	Loss 0.7066 (0.7066)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.132 (0.142)	Loss 0.5417 (0.5726)	Acc@1 78.125 (84.375)	Acc@5 96.875 (93.348)
Test: [200/750]	Time 0.114 (0.138)	Loss 1.4907 (0.6023)	Acc@1 37.500 (80.239)	Acc@5 87.500 (94.838)
Test: [300/750]	Time 0.131 (0.136)	Loss 1.4810 (0.8902)	Acc@1 50.000 (67.660)	Acc@5 93.750 (92.816)
Test: [400/750]	Time 0.135 (0.134)	Loss 0.5789 (0.9864)	Acc@1 81.250 (63.459)	Acc@5 90.625 (92.534)
Test: [500/750]	Time 0.134 (0.134)	Loss 0.6738 (0.9285)	Acc@1 78.125 (66.249)	Acc@5 96.875 (92.459)
Test: [600/750]	Time 0.137 (0.133)	Loss 0.7714 (0.9110)	Acc@1 68.750 (67.294)	Acc@5 90.625 (92.419)
Test: [700/750]	Time 0.121 (0.133)	Loss 0.8325 (0.8803)	Acc@1 75.000 (68.398)	Acc@5 93.750 (92.925)
 * Acc@1 69.075 Acc@5 93.129
==> training...
Epoch: [45][0/875]	Time 2.335 (2.335)	Data 1.622 (1.622)	Loss 2.4019 (2.4019)	Loss@kd 2.3218 (2.3218)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [45][100/875]	Time 0.685 (0.695)	Data 0.007 (0.023)	Loss 3.0482 (2.4675)	Loss@kd 3.3565 (2.3825)	Acc@1 71.875 (70.668)	Acc@5 100.000 (98.731)
Epoch: [45][200/875]	Time 0.677 (0.691)	Data 0.008 (0.015)	Loss 2.1283 (2.4692)	Loss@kd 2.3258 (2.3840)	Acc@1 78.125 (70.390)	Acc@5 100.000 (98.756)
Epoch: [45][300/875]	Time 0.687 (0.688)	Data 0.007 (0.013)	Loss 2.4922 (2.4661)	Loss@kd 2.2439 (2.3711)	Acc@1 64.062 (70.344)	Acc@5 96.875 (98.749)
Epoch: [45][400/875]	Time 0.664 (0.686)	Data 0.010 (0.011)	Loss 2.6733 (2.4633)	Loss@kd 2.4351 (2.3622)	Acc@1 62.500 (70.102)	Acc@5 98.438 (98.796)
Epoch: [45][500/875]	Time 0.750 (0.685)	Data 0.007 (0.011)	Loss 2.4112 (2.4683)	Loss@kd 2.2340 (2.3704)	Acc@1 67.188 (70.035)	Acc@5 95.312 (98.781)
Epoch: [45][600/875]	Time 0.674 (0.684)	Data 0.007 (0.010)	Loss 2.4208 (2.4671)	Loss@kd 2.4577 (2.3648)	Acc@1 75.000 (69.990)	Acc@5 100.000 (98.799)
Epoch: [45][700/875]	Time 0.665 (0.684)	Data 0.007 (0.010)	Loss 2.2873 (2.4720)	Loss@kd 2.2132 (2.3698)	Acc@1 71.875 (69.876)	Acc@5 100.000 (98.799)
Epoch: [45][800/875]	Time 0.660 (0.684)	Data 0.007 (0.009)	Loss 2.4053 (2.4656)	Loss@kd 2.2671 (2.3617)	Acc@1 68.750 (69.911)	Acc@5 96.875 (98.775)
 * Acc@1 69.827 Acc@5 98.762
epoch 45, total time 598.63
Test: [0/750]	Time 1.039 (1.039)	Loss 4.9517 (4.9517)	Acc@1 31.250 (31.250)	Acc@5 43.750 (43.750)
Test: [100/750]	Time 0.133 (0.139)	Loss 0.8158 (3.0639)	Acc@1 68.750 (45.792)	Acc@5 96.875 (62.717)
Test: [200/750]	Time 0.108 (0.131)	Loss 1.4895 (1.9192)	Acc@1 40.625 (58.364)	Acc@5 87.500 (78.918)
Test: [300/750]	Time 0.103 (0.128)	Loss 1.0637 (1.7492)	Acc@1 62.500 (53.634)	Acc@5 93.750 (81.987)
Test: [400/750]	Time 0.128 (0.127)	Loss 0.9304 (1.5863)	Acc@1 68.750 (54.629)	Acc@5 87.500 (84.796)
Test: [500/750]	Time 0.119 (0.126)	Loss 0.7026 (1.4355)	Acc@1 78.125 (58.408)	Acc@5 96.875 (85.891)
Test: [600/750]	Time 0.096 (0.125)	Loss 0.6970 (1.3491)	Acc@1 75.000 (60.467)	Acc@5 90.625 (86.840)
Test: [700/750]	Time 0.128 (0.125)	Loss 1.0338 (1.2637)	Acc@1 59.375 (62.299)	Acc@5 84.375 (88.035)
 * Acc@1 63.071 Acc@5 88.487
==> training...
Epoch: [46][0/875]	Time 2.343 (2.343)	Data 1.626 (1.626)	Loss 2.4184 (2.4184)	Loss@kd 2.3215 (2.3215)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [46][100/875]	Time 0.665 (0.699)	Data 0.005 (0.023)	Loss 2.3999 (2.4446)	Loss@kd 2.3161 (2.3585)	Acc@1 76.562 (70.390)	Acc@5 100.000 (98.824)
Epoch: [46][200/875]	Time 0.661 (0.689)	Data 0.008 (0.015)	Loss 2.3883 (2.4601)	Loss@kd 2.2061 (2.3615)	Acc@1 75.000 (70.009)	Acc@5 96.875 (98.896)
Epoch: [46][300/875]	Time 0.684 (0.685)	Data 0.008 (0.013)	Loss 2.6949 (2.4502)	Loss@kd 2.3140 (2.3542)	Acc@1 62.500 (70.058)	Acc@5 98.438 (98.868)
Epoch: [46][400/875]	Time 0.746 (0.684)	Data 0.007 (0.011)	Loss 2.9452 (2.4474)	Loss@kd 2.9651 (2.3554)	Acc@1 70.312 (70.344)	Acc@5 100.000 (98.882)
Epoch: [46][500/875]	Time 0.684 (0.683)	Data 0.007 (0.010)	Loss 2.3230 (2.4500)	Loss@kd 2.1898 (2.3579)	Acc@1 76.562 (70.350)	Acc@5 98.438 (98.896)
Epoch: [46][600/875]	Time 0.652 (0.682)	Data 0.007 (0.010)	Loss 2.3294 (2.4493)	Loss@kd 2.2710 (2.3525)	Acc@1 71.875 (70.242)	Acc@5 98.438 (98.879)
Epoch: [46][700/875]	Time 0.671 (0.682)	Data 0.007 (0.010)	Loss 2.4463 (2.4510)	Loss@kd 2.3094 (2.3514)	Acc@1 70.312 (70.156)	Acc@5 98.438 (98.848)
Epoch: [46][800/875]	Time 0.669 (0.682)	Data 0.007 (0.009)	Loss 2.1331 (2.4531)	Loss@kd 2.2800 (2.3511)	Acc@1 85.938 (70.055)	Acc@5 98.438 (98.816)
 * Acc@1 70.066 Acc@5 98.827
epoch 46, total time 596.69
Test: [0/750]	Time 1.007 (1.007)	Loss 0.5806 (0.5806)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.117 (0.143)	Loss 0.8256 (0.5286)	Acc@1 71.875 (84.684)	Acc@5 96.875 (94.833)
Test: [200/750]	Time 0.116 (0.136)	Loss 1.7225 (0.5856)	Acc@1 28.125 (79.726)	Acc@5 84.375 (95.725)
Test: [300/750]	Time 0.090 (0.132)	Loss 0.7216 (0.8702)	Acc@1 81.250 (67.058)	Acc@5 100.000 (93.480)
Test: [400/750]	Time 0.096 (0.130)	Loss 0.7629 (0.8637)	Acc@1 75.000 (67.760)	Acc@5 90.625 (93.828)
Test: [500/750]	Time 0.117 (0.129)	Loss 0.8458 (0.8718)	Acc@1 68.750 (68.706)	Acc@5 96.875 (93.045)
Test: [600/750]	Time 0.106 (0.128)	Loss 0.5674 (0.8798)	Acc@1 84.375 (68.911)	Acc@5 93.750 (92.830)
Test: [700/750]	Time 0.121 (0.127)	Loss 1.4373 (0.8882)	Acc@1 40.625 (68.242)	Acc@5 84.375 (92.881)
 * Acc@1 67.396 Acc@5 92.679
==> training...
Epoch: [47][0/875]	Time 2.236 (2.236)	Data 1.544 (1.544)	Loss 2.5534 (2.5534)	Loss@kd 2.3029 (2.3029)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [47][100/875]	Time 0.684 (0.704)	Data 0.007 (0.022)	Loss 2.7159 (2.4283)	Loss@kd 2.3611 (2.3248)	Acc@1 64.062 (70.777)	Acc@5 100.000 (98.824)
Epoch: [47][200/875]	Time 0.661 (0.693)	Data 0.007 (0.015)	Loss 2.6204 (2.4404)	Loss@kd 2.2397 (2.3360)	Acc@1 60.938 (70.274)	Acc@5 95.312 (98.873)
Epoch: [47][300/875]	Time 0.683 (0.691)	Data 0.007 (0.012)	Loss 2.4358 (2.4428)	Loss@kd 2.4154 (2.3439)	Acc@1 71.875 (70.640)	Acc@5 98.438 (98.868)
Epoch: [47][400/875]	Time 0.682 (0.690)	Data 0.007 (0.011)	Loss 2.2592 (2.4476)	Loss@kd 2.3505 (2.3462)	Acc@1 76.562 (70.414)	Acc@5 98.438 (98.812)
Epoch: [47][500/875]	Time 0.673 (0.690)	Data 0.007 (0.010)	Loss 2.4860 (2.4479)	Loss@kd 2.3084 (2.3400)	Acc@1 62.500 (70.163)	Acc@5 98.438 (98.834)
Epoch: [47][600/875]	Time 0.678 (0.688)	Data 0.007 (0.010)	Loss 2.5953 (2.4480)	Loss@kd 2.3895 (2.3355)	Acc@1 64.062 (69.962)	Acc@5 98.438 (98.791)
Epoch: [47][700/875]	Time 0.687 (0.688)	Data 0.007 (0.010)	Loss 2.3494 (2.4454)	Loss@kd 2.2292 (2.3369)	Acc@1 76.562 (70.056)	Acc@5 100.000 (98.823)
Epoch: [47][800/875]	Time 0.679 (0.687)	Data 0.007 (0.009)	Loss 2.2992 (2.4409)	Loss@kd 2.2056 (2.3335)	Acc@1 70.312 (70.149)	Acc@5 100.000 (98.812)
 * Acc@1 70.195 Acc@5 98.816
epoch 47, total time 601.39
Test: [0/750]	Time 0.885 (0.885)	Loss 8.8781 (8.8781)	Acc@1 21.875 (21.875)	Acc@5 28.125 (28.125)
Test: [100/750]	Time 0.168 (0.142)	Loss 0.4645 (7.2706)	Acc@1 75.000 (27.692)	Acc@5 100.000 (37.160)
Test: [200/750]	Time 0.107 (0.136)	Loss 1.5092 (3.9427)	Acc@1 40.625 (52.596)	Acc@5 84.375 (66.729)
Test: [300/750]	Time 0.118 (0.132)	Loss 1.4269 (3.1255)	Acc@1 65.625 (49.211)	Acc@5 90.625 (73.422)
Test: [400/750]	Time 0.119 (0.130)	Loss 0.7007 (2.6066)	Acc@1 78.125 (52.346)	Acc@5 90.625 (78.164)
Test: [500/750]	Time 0.126 (0.128)	Loss 0.5267 (2.2403)	Acc@1 81.250 (56.649)	Acc@5 100.000 (80.926)
Test: [600/750]	Time 0.106 (0.127)	Loss 0.6429 (2.0024)	Acc@1 78.125 (59.396)	Acc@5 96.875 (83.070)
Test: [700/750]	Time 0.117 (0.126)	Loss 1.2759 (1.8519)	Acc@1 56.250 (60.146)	Acc@5 81.250 (84.509)
 * Acc@1 59.871 Acc@5 84.721
==> training...
Epoch: [48][0/875]	Time 2.299 (2.299)	Data 1.591 (1.591)	Loss 2.2556 (2.2556)	Loss@kd 2.3799 (2.3799)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [48][100/875]	Time 0.685 (0.702)	Data 0.007 (0.023)	Loss 2.2448 (2.4355)	Loss@kd 2.2454 (2.3238)	Acc@1 79.688 (70.312)	Acc@5 100.000 (98.762)
Epoch: [48][200/875]	Time 0.676 (0.692)	Data 0.007 (0.015)	Loss 2.3629 (2.4420)	Loss@kd 2.2373 (2.3304)	Acc@1 68.750 (70.250)	Acc@5 98.438 (98.857)
Epoch: [48][300/875]	Time 0.673 (0.688)	Data 0.008 (0.013)	Loss 2.5270 (2.4342)	Loss@kd 2.3042 (2.3279)	Acc@1 65.625 (70.375)	Acc@5 100.000 (98.915)
Epoch: [48][400/875]	Time 0.690 (0.686)	Data 0.007 (0.011)	Loss 2.5027 (2.4305)	Loss@kd 2.3062 (2.3224)	Acc@1 71.875 (70.406)	Acc@5 100.000 (98.878)
Epoch: [48][500/875]	Time 0.650 (0.684)	Data 0.004 (0.011)	Loss 2.6781 (2.4387)	Loss@kd 2.6523 (2.3350)	Acc@1 70.312 (70.459)	Acc@5 96.875 (98.871)
Epoch: [48][600/875]	Time 0.657 (0.684)	Data 0.005 (0.010)	Loss 2.1503 (2.4324)	Loss@kd 2.2105 (2.3291)	Acc@1 79.688 (70.494)	Acc@5 100.000 (98.812)
Epoch: [48][700/875]	Time 0.673 (0.683)	Data 0.007 (0.010)	Loss 2.3609 (2.4300)	Loss@kd 2.2543 (2.3280)	Acc@1 73.438 (70.511)	Acc@5 100.000 (98.832)
Epoch: [48][800/875]	Time 0.672 (0.683)	Data 0.007 (0.009)	Loss 2.5433 (2.4290)	Loss@kd 2.3357 (2.3260)	Acc@1 59.375 (70.465)	Acc@5 100.000 (98.845)
 * Acc@1 70.425 Acc@5 98.834
epoch 48, total time 598.24
Test: [0/750]	Time 1.028 (1.028)	Loss 1.9672 (1.9672)	Acc@1 53.125 (53.125)	Acc@5 68.750 (68.750)
Test: [100/750]	Time 0.126 (0.146)	Loss 0.3822 (1.0754)	Acc@1 90.625 (70.637)	Acc@5 100.000 (85.551)
Test: [200/750]	Time 0.111 (0.140)	Loss 1.2628 (0.8195)	Acc@1 56.250 (75.078)	Acc@5 93.750 (91.138)
Test: [300/750]	Time 0.130 (0.137)	Loss 1.7445 (1.0072)	Acc@1 37.500 (65.220)	Acc@5 78.125 (90.750)
Test: [400/750]	Time 0.132 (0.137)	Loss 0.5066 (1.1393)	Acc@1 87.500 (59.944)	Acc@5 93.750 (88.474)
Test: [500/750]	Time 0.128 (0.136)	Loss 0.3650 (1.0222)	Acc@1 87.500 (64.521)	Acc@5 100.000 (89.864)
Test: [600/750]	Time 0.119 (0.135)	Loss 0.9965 (0.9770)	Acc@1 62.500 (66.363)	Acc@5 90.625 (90.599)
Test: [700/750]	Time 0.114 (0.134)	Loss 0.7795 (0.9636)	Acc@1 65.625 (66.552)	Acc@5 93.750 (91.147)
 * Acc@1 67.067 Acc@5 91.404
==> training...
Epoch: [49][0/875]	Time 2.328 (2.328)	Data 1.616 (1.616)	Loss 2.3001 (2.3001)	Loss@kd 2.3146 (2.3146)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [49][100/875]	Time 0.686 (0.700)	Data 0.007 (0.023)	Loss 2.4743 (2.4268)	Loss@kd 2.2915 (2.3103)	Acc@1 64.062 (69.694)	Acc@5 96.875 (98.592)
Epoch: [49][200/875]	Time 0.685 (0.691)	Data 0.008 (0.015)	Loss 2.3249 (2.4318)	Loss@kd 2.2341 (2.3194)	Acc@1 70.312 (69.885)	Acc@5 98.438 (98.741)
Epoch: [49][300/875]	Time 0.669 (0.689)	Data 0.007 (0.013)	Loss 2.4154 (2.4276)	Loss@kd 2.2482 (2.3184)	Acc@1 67.188 (69.975)	Acc@5 98.438 (98.848)
Epoch: [49][400/875]	Time 0.734 (0.688)	Data 0.006 (0.011)	Loss 2.5416 (2.4189)	Loss@kd 2.4339 (2.3126)	Acc@1 73.438 (70.094)	Acc@5 100.000 (98.874)
Epoch: [49][500/875]	Time 0.680 (0.686)	Data 0.007 (0.011)	Loss 2.4217 (2.4159)	Loss@kd 2.3159 (2.3098)	Acc@1 75.000 (70.110)	Acc@5 100.000 (98.915)
Epoch: [49][600/875]	Time 0.678 (0.686)	Data 0.008 (0.010)	Loss 2.6296 (2.4153)	Loss@kd 2.3410 (2.3113)	Acc@1 65.625 (70.253)	Acc@5 96.875 (98.895)
Epoch: [49][700/875]	Time 0.687 (0.685)	Data 0.010 (0.010)	Loss 2.6697 (2.4177)	Loss@kd 2.4282 (2.3155)	Acc@1 62.500 (70.272)	Acc@5 96.875 (98.883)
Epoch: [49][800/875]	Time 0.682 (0.685)	Data 0.008 (0.009)	Loss 2.7617 (2.4160)	Loss@kd 2.4092 (2.3165)	Acc@1 56.250 (70.338)	Acc@5 92.188 (98.874)
 * Acc@1 70.411 Acc@5 98.887
epoch 49, total time 599.71
Test: [0/750]	Time 1.009 (1.009)	Loss 0.6114 (0.6114)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.141 (0.142)	Loss 0.6850 (0.7029)	Acc@1 68.750 (82.302)	Acc@5 96.875 (91.089)
Test: [200/750]	Time 0.132 (0.139)	Loss 1.2918 (0.6528)	Acc@1 53.125 (80.006)	Acc@5 84.375 (93.874)
Test: [300/750]	Time 0.132 (0.134)	Loss 1.2870 (0.8097)	Acc@1 56.250 (71.242)	Acc@5 96.875 (94.010)
Test: [400/750]	Time 0.125 (0.132)	Loss 0.6567 (0.8494)	Acc@1 84.375 (69.264)	Acc@5 100.000 (94.218)
Test: [500/750]	Time 0.099 (0.130)	Loss 0.6971 (0.8450)	Acc@1 71.875 (70.022)	Acc@5 96.875 (93.600)
Test: [600/750]	Time 0.122 (0.129)	Loss 0.7384 (0.8689)	Acc@1 75.000 (69.566)	Acc@5 93.750 (92.975)
Test: [700/750]	Time 0.211 (0.128)	Loss 0.8993 (0.8697)	Acc@1 62.500 (69.196)	Acc@5 93.750 (93.068)
 * Acc@1 69.312 Acc@5 93.088
saving the best model!
==> training...
Epoch: [50][0/875]	Time 2.302 (2.302)	Data 1.615 (1.615)	Loss 2.2122 (2.2122)	Loss@kd 2.3658 (2.3658)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [50][100/875]	Time 0.675 (0.700)	Data 0.007 (0.023)	Loss 2.1189 (2.3758)	Loss@kd 2.2450 (2.2978)	Acc@1 81.250 (71.627)	Acc@5 100.000 (99.056)
Epoch: [50][200/875]	Time 0.801 (0.691)	Data 0.007 (0.015)	Loss 2.2757 (2.3807)	Loss@kd 2.3268 (2.2984)	Acc@1 75.000 (71.385)	Acc@5 100.000 (99.036)
Epoch: [50][300/875]	Time 0.695 (0.688)	Data 0.008 (0.013)	Loss 2.3070 (2.3914)	Loss@kd 2.1994 (2.3070)	Acc@1 71.875 (71.273)	Acc@5 100.000 (98.998)
Epoch: [50][400/875]	Time 0.674 (0.685)	Data 0.007 (0.011)	Loss 2.4018 (2.4060)	Loss@kd 2.3003 (2.3195)	Acc@1 71.875 (71.142)	Acc@5 98.438 (98.932)
Epoch: [50][500/875]	Time 0.684 (0.685)	Data 0.007 (0.010)	Loss 2.7047 (2.4169)	Loss@kd 2.6993 (2.3336)	Acc@1 75.000 (71.120)	Acc@5 98.438 (98.918)
Epoch: [50][600/875]	Time 0.674 (0.685)	Data 0.007 (0.010)	Loss 2.3682 (2.4346)	Loss@kd 2.2982 (2.3448)	Acc@1 70.312 (70.741)	Acc@5 98.438 (98.916)
Epoch: [50][700/875]	Time 0.672 (0.684)	Data 0.007 (0.010)	Loss 2.6738 (2.4368)	Loss@kd 2.4184 (2.3428)	Acc@1 59.375 (70.638)	Acc@5 98.438 (98.910)
Epoch: [50][800/875]	Time 0.677 (0.683)	Data 0.007 (0.009)	Loss 2.4273 (2.4348)	Loss@kd 2.3157 (2.3379)	Acc@1 70.312 (70.519)	Acc@5 100.000 (98.892)
 * Acc@1 70.409 Acc@5 98.896
epoch 50, total time 598.16
Test: [0/750]	Time 1.032 (1.032)	Loss 0.7770 (0.7770)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.130 (0.145)	Loss 0.4580 (0.7223)	Acc@1 84.375 (82.673)	Acc@5 100.000 (92.481)
Test: [200/750]	Time 0.187 (0.135)	Loss 0.9907 (0.5878)	Acc@1 65.625 (83.504)	Acc@5 93.750 (94.994)
Test: [300/750]	Time 0.118 (0.131)	Loss 1.4086 (0.7231)	Acc@1 40.625 (76.370)	Acc@5 90.625 (95.318)
Test: [400/750]	Time 0.118 (0.129)	Loss 0.6159 (0.8083)	Acc@1 84.375 (71.852)	Acc@5 84.375 (94.506)
Test: [500/750]	Time 0.190 (0.129)	Loss 0.5301 (0.7695)	Acc@1 81.250 (73.303)	Acc@5 96.875 (94.318)
Test: [600/750]	Time 0.114 (0.128)	Loss 1.2499 (0.8046)	Acc@1 53.125 (72.015)	Acc@5 87.500 (93.849)
Test: [700/750]	Time 0.098 (0.127)	Loss 1.3769 (0.8623)	Acc@1 46.875 (69.561)	Acc@5 84.375 (93.246)
 * Acc@1 68.817 Acc@5 93.008
==> training...
Epoch: [51][0/875]	Time 2.360 (2.360)	Data 1.600 (1.600)	Loss 2.4746 (2.4746)	Loss@kd 2.2340 (2.2340)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [51][100/875]	Time 0.685 (0.707)	Data 0.008 (0.023)	Loss 2.7231 (2.3726)	Loss@kd 2.1736 (2.2701)	Acc@1 59.375 (70.421)	Acc@5 95.312 (98.902)
Epoch: [51][200/875]	Time 0.691 (0.694)	Data 0.008 (0.015)	Loss 2.3002 (2.3962)	Loss@kd 2.2668 (2.2969)	Acc@1 76.562 (70.530)	Acc@5 100.000 (98.912)
Epoch: [51][300/875]	Time 0.662 (0.690)	Data 0.007 (0.013)	Loss 2.3356 (2.3992)	Loss@kd 2.2715 (2.3045)	Acc@1 75.000 (70.629)	Acc@5 100.000 (98.889)
Epoch: [51][400/875]	Time 0.751 (0.688)	Data 0.007 (0.011)	Loss 2.3148 (2.3998)	Loss@kd 2.1857 (2.3051)	Acc@1 68.750 (70.714)	Acc@5 100.000 (98.913)
Epoch: [51][500/875]	Time 0.665 (0.687)	Data 0.007 (0.011)	Loss 2.5650 (2.4035)	Loss@kd 2.4166 (2.3085)	Acc@1 65.625 (70.790)	Acc@5 100.000 (98.908)
Epoch: [51][600/875]	Time 0.679 (0.686)	Data 0.007 (0.010)	Loss 2.4252 (2.3981)	Loss@kd 2.3121 (2.3023)	Acc@1 64.062 (70.757)	Acc@5 98.438 (98.895)
Epoch: [51][700/875]	Time 0.668 (0.685)	Data 0.007 (0.010)	Loss 2.4063 (2.3923)	Loss@kd 2.5548 (2.2990)	Acc@1 79.688 (70.937)	Acc@5 100.000 (98.919)
Epoch: [51][800/875]	Time 0.693 (0.685)	Data 0.008 (0.009)	Loss 2.4549 (2.3974)	Loss@kd 2.1904 (2.3020)	Acc@1 68.750 (70.802)	Acc@5 98.438 (98.902)
 * Acc@1 70.700 Acc@5 98.859
epoch 51, total time 599.61
Test: [0/750]	Time 1.020 (1.020)	Loss 0.6817 (0.6817)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.138 (0.146)	Loss 0.5181 (0.6415)	Acc@1 84.375 (84.499)	Acc@5 96.875 (95.019)
Test: [200/750]	Time 0.132 (0.140)	Loss 1.5010 (0.5993)	Acc@1 28.125 (81.701)	Acc@5 78.125 (95.740)
Test: [300/750]	Time 0.124 (0.139)	Loss 0.9621 (0.8667)	Acc@1 68.750 (69.061)	Acc@5 90.625 (93.449)
Test: [400/750]	Time 0.132 (0.138)	Loss 0.7926 (0.8704)	Acc@1 75.000 (68.851)	Acc@5 90.625 (93.625)
Test: [500/750]	Time 0.143 (0.138)	Loss 0.5933 (0.8742)	Acc@1 78.125 (69.661)	Acc@5 96.875 (93.095)
Test: [600/750]	Time 0.137 (0.138)	Loss 0.7048 (0.8709)	Acc@1 65.625 (69.811)	Acc@5 96.875 (93.235)
Test: [700/750]	Time 0.124 (0.138)	Loss 1.5490 (0.8921)	Acc@1 53.125 (68.705)	Acc@5 81.250 (93.006)
 * Acc@1 68.129 Acc@5 92.579
==> training...
Epoch: [52][0/875]	Time 2.403 (2.403)	Data 1.711 (1.711)	Loss 2.5758 (2.5758)	Loss@kd 2.3520 (2.3520)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [52][100/875]	Time 0.720 (0.703)	Data 0.007 (0.024)	Loss 2.1604 (2.3628)	Loss@kd 2.3146 (2.2902)	Acc@1 76.562 (71.364)	Acc@5 100.000 (98.902)
Epoch: [52][200/875]	Time 0.743 (0.696)	Data 0.007 (0.016)	Loss 2.2920 (2.3773)	Loss@kd 2.2491 (2.3151)	Acc@1 70.312 (71.362)	Acc@5 98.438 (99.052)
Epoch: [52][300/875]	Time 0.781 (0.693)	Data 0.008 (0.013)	Loss 2.4827 (2.3943)	Loss@kd 2.2231 (2.3287)	Acc@1 62.500 (71.242)	Acc@5 95.312 (99.024)
Epoch: [52][400/875]	Time 0.766 (0.691)	Data 0.007 (0.012)	Loss 2.5006 (2.3865)	Loss@kd 2.2809 (2.3152)	Acc@1 67.188 (71.107)	Acc@5 100.000 (98.999)
Epoch: [52][500/875]	Time 0.754 (0.689)	Data 0.007 (0.011)	Loss 2.2353 (2.3878)	Loss@kd 2.1338 (2.3088)	Acc@1 81.250 (71.080)	Acc@5 98.438 (98.955)
Epoch: [52][600/875]	Time 0.773 (0.689)	Data 0.007 (0.010)	Loss 2.5027 (2.3871)	Loss@kd 2.3564 (2.3057)	Acc@1 70.312 (71.126)	Acc@5 96.875 (98.944)
Epoch: [52][700/875]	Time 0.759 (0.689)	Data 0.008 (0.010)	Loss 2.2301 (2.3859)	Loss@kd 2.2591 (2.3038)	Acc@1 75.000 (71.160)	Acc@5 100.000 (98.950)
Epoch: [52][800/875]	Time 0.760 (0.688)	Data 0.007 (0.009)	Loss 2.2619 (2.3895)	Loss@kd 2.2646 (2.3040)	Acc@1 70.312 (71.046)	Acc@5 98.438 (98.962)
 * Acc@1 70.964 Acc@5 98.950
epoch 52, total time 602.38
Test: [0/750]	Time 0.882 (0.882)	Loss 1.0954 (1.0954)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.124 (0.138)	Loss 0.6523 (0.8262)	Acc@1 65.625 (73.546)	Acc@5 93.750 (93.781)
Test: [200/750]	Time 0.199 (0.131)	Loss 1.7842 (0.7741)	Acc@1 28.125 (73.445)	Acc@5 84.375 (94.356)
Test: [300/750]	Time 0.113 (0.127)	Loss 1.1829 (1.0397)	Acc@1 65.625 (61.628)	Acc@5 96.875 (91.736)
Test: [400/750]	Time 0.121 (0.126)	Loss 0.7070 (1.0379)	Acc@1 78.125 (61.861)	Acc@5 93.750 (92.145)
Test: [500/750]	Time 0.121 (0.126)	Loss 0.7531 (0.9881)	Acc@1 68.750 (64.390)	Acc@5 90.625 (91.954)
Test: [600/750]	Time 0.126 (0.126)	Loss 0.6978 (0.9760)	Acc@1 68.750 (65.459)	Acc@5 93.750 (91.722)
Test: [700/750]	Time 0.114 (0.125)	Loss 0.7017 (0.9553)	Acc@1 71.875 (65.968)	Acc@5 93.750 (92.167)
 * Acc@1 66.454 Acc@5 92.383
==> training...
Epoch: [53][0/875]	Time 2.325 (2.325)	Data 1.598 (1.598)	Loss 2.5093 (2.5093)	Loss@kd 2.2197 (2.2197)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [53][100/875]	Time 0.676 (0.706)	Data 0.007 (0.023)	Loss 2.5590 (2.3759)	Loss@kd 2.3837 (2.2797)	Acc@1 67.188 (71.581)	Acc@5 95.312 (98.933)
Epoch: [53][200/875]	Time 0.675 (0.696)	Data 0.007 (0.015)	Loss 2.3595 (2.3702)	Loss@kd 2.3320 (2.2779)	Acc@1 75.000 (71.657)	Acc@5 98.438 (99.021)
Epoch: [53][300/875]	Time 0.679 (0.693)	Data 0.007 (0.013)	Loss 2.2783 (2.3737)	Loss@kd 2.2575 (2.2803)	Acc@1 82.812 (71.434)	Acc@5 98.438 (98.962)
Epoch: [53][400/875]	Time 0.679 (0.691)	Data 0.007 (0.011)	Loss 2.4882 (2.3771)	Loss@kd 2.2760 (2.2809)	Acc@1 65.625 (71.216)	Acc@5 100.000 (98.878)
Epoch: [53][500/875]	Time 0.687 (0.691)	Data 0.007 (0.011)	Loss 2.2997 (2.3742)	Loss@kd 2.1753 (2.2765)	Acc@1 71.875 (71.108)	Acc@5 100.000 (98.912)
Epoch: [53][600/875]	Time 0.675 (0.690)	Data 0.007 (0.010)	Loss 2.4498 (2.3719)	Loss@kd 2.2876 (2.2751)	Acc@1 65.625 (71.087)	Acc@5 98.438 (98.931)
Epoch: [53][700/875]	Time 0.670 (0.689)	Data 0.006 (0.010)	Loss 2.2483 (2.3734)	Loss@kd 2.3053 (2.2787)	Acc@1 75.000 (71.053)	Acc@5 100.000 (98.939)
Epoch: [53][800/875]	Time 0.669 (0.689)	Data 0.007 (0.009)	Loss 2.5179 (2.3803)	Loss@kd 2.4000 (2.2841)	Acc@1 75.000 (70.919)	Acc@5 96.875 (98.908)
 * Acc@1 70.939 Acc@5 98.916
epoch 53, total time 602.77
Test: [0/750]	Time 0.959 (0.959)	Loss 0.4288 (0.4288)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.104 (0.137)	Loss 0.5621 (0.6033)	Acc@1 78.125 (84.715)	Acc@5 93.750 (93.472)
Test: [200/750]	Time 0.128 (0.131)	Loss 1.1230 (0.5827)	Acc@1 59.375 (82.307)	Acc@5 90.625 (95.460)
Test: [300/750]	Time 0.125 (0.128)	Loss 1.4672 (0.7713)	Acc@1 53.125 (73.557)	Acc@5 87.500 (94.591)
Test: [400/750]	Time 0.121 (0.127)	Loss 0.3733 (0.8832)	Acc@1 84.375 (68.836)	Acc@5 100.000 (93.438)
Test: [500/750]	Time 0.125 (0.127)	Loss 0.7255 (0.8296)	Acc@1 68.750 (71.388)	Acc@5 96.875 (93.762)
Test: [600/750]	Time 0.119 (0.127)	Loss 0.6249 (0.8535)	Acc@1 78.125 (70.648)	Acc@5 100.000 (93.610)
Test: [700/750]	Time 0.118 (0.127)	Loss 1.8299 (0.9065)	Acc@1 40.625 (68.643)	Acc@5 75.000 (92.800)
 * Acc@1 67.321 Acc@5 92.067
==> training...
Epoch: [54][0/875]	Time 2.269 (2.269)	Data 1.547 (1.547)	Loss 2.3091 (2.3091)	Loss@kd 2.2047 (2.2047)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [54][100/875]	Time 0.678 (0.702)	Data 0.007 (0.023)	Loss 2.4328 (2.4131)	Loss@kd 2.2491 (2.3335)	Acc@1 68.750 (71.535)	Acc@5 98.438 (98.979)
Epoch: [54][200/875]	Time 0.657 (0.692)	Data 0.007 (0.015)	Loss 2.3390 (2.4004)	Loss@kd 2.4133 (2.3135)	Acc@1 79.688 (71.323)	Acc@5 100.000 (98.912)
Epoch: [54][300/875]	Time 0.686 (0.691)	Data 0.007 (0.012)	Loss 2.5462 (2.3873)	Loss@kd 2.4438 (2.3036)	Acc@1 70.312 (71.397)	Acc@5 95.312 (98.951)
Epoch: [54][400/875]	Time 0.664 (0.690)	Data 0.008 (0.011)	Loss 2.3853 (2.3906)	Loss@kd 2.3945 (2.2940)	Acc@1 71.875 (71.002)	Acc@5 98.438 (98.956)
Epoch: [54][500/875]	Time 0.667 (0.689)	Data 0.007 (0.010)	Loss 2.1725 (2.3861)	Loss@kd 2.2568 (2.2926)	Acc@1 78.125 (71.058)	Acc@5 100.000 (98.968)
Epoch: [54][600/875]	Time 0.666 (0.688)	Data 0.007 (0.010)	Loss 2.3342 (2.3845)	Loss@kd 2.2317 (2.2894)	Acc@1 73.438 (70.921)	Acc@5 98.438 (98.942)
Epoch: [54][700/875]	Time 0.670 (0.688)	Data 0.006 (0.010)	Loss 2.3713 (2.3818)	Loss@kd 2.5168 (2.2889)	Acc@1 79.688 (70.988)	Acc@5 100.000 (98.961)
Epoch: [54][800/875]	Time 0.683 (0.688)	Data 0.007 (0.009)	Loss 2.4050 (2.3843)	Loss@kd 2.2640 (2.2893)	Acc@1 68.750 (70.970)	Acc@5 100.000 (98.943)
 * Acc@1 70.973 Acc@5 98.946
epoch 54, total time 602.01
Test: [0/750]	Time 0.917 (0.917)	Loss 0.8223 (0.8223)	Acc@1 68.750 (68.750)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.132 (0.137)	Loss 0.8192 (0.9973)	Acc@1 68.750 (79.084)	Acc@5 96.875 (91.986)
Test: [200/750]	Time 0.130 (0.134)	Loss 1.8086 (0.9572)	Acc@1 37.500 (71.067)	Acc@5 81.250 (93.455)
Test: [300/750]	Time 0.128 (0.133)	Loss 1.1542 (1.1268)	Acc@1 71.875 (62.012)	Acc@5 96.875 (91.777)
Test: [400/750]	Time 0.143 (0.133)	Loss 0.9784 (1.0878)	Acc@1 71.875 (62.687)	Acc@5 84.375 (92.246)
Test: [500/750]	Time 0.129 (0.133)	Loss 0.6118 (1.0543)	Acc@1 71.875 (64.870)	Acc@5 96.875 (91.754)
Test: [600/750]	Time 0.129 (0.132)	Loss 0.8001 (1.0258)	Acc@1 68.750 (66.020)	Acc@5 93.750 (91.670)
Test: [700/750]	Time 0.122 (0.131)	Loss 0.9353 (1.0055)	Acc@1 59.375 (66.298)	Acc@5 93.750 (92.047)
 * Acc@1 66.158 Acc@5 92.146
==> training...
Epoch: [55][0/875]	Time 2.296 (2.296)	Data 1.590 (1.590)	Loss 2.6366 (2.6366)	Loss@kd 2.4396 (2.4396)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [55][100/875]	Time 0.756 (0.697)	Data 0.008 (0.023)	Loss 2.1481 (2.3723)	Loss@kd 2.2754 (2.2897)	Acc@1 85.938 (71.705)	Acc@5 100.000 (99.165)
Epoch: [55][200/875]	Time 0.664 (0.688)	Data 0.006 (0.015)	Loss 2.4499 (2.3714)	Loss@kd 2.1994 (2.2923)	Acc@1 70.312 (71.572)	Acc@5 100.000 (99.114)
Epoch: [55][300/875]	Time 0.676 (0.685)	Data 0.007 (0.013)	Loss 2.3230 (2.3623)	Loss@kd 2.3350 (2.2798)	Acc@1 73.438 (71.688)	Acc@5 100.000 (99.066)
Epoch: [55][400/875]	Time 0.677 (0.684)	Data 0.008 (0.011)	Loss 2.2319 (2.3623)	Loss@kd 2.2012 (2.2801)	Acc@1 71.875 (71.591)	Acc@5 100.000 (99.018)
Epoch: [55][500/875]	Time 0.665 (0.684)	Data 0.007 (0.010)	Loss 2.3256 (2.3707)	Loss@kd 2.4575 (2.2834)	Acc@1 76.562 (71.432)	Acc@5 100.000 (98.977)
Epoch: [55][600/875]	Time 0.665 (0.683)	Data 0.008 (0.010)	Loss 2.4835 (2.3718)	Loss@kd 2.4604 (2.2843)	Acc@1 70.312 (71.404)	Acc@5 100.000 (98.942)
Epoch: [55][700/875]	Time 0.676 (0.682)	Data 0.007 (0.010)	Loss 2.2539 (2.3696)	Loss@kd 2.2124 (2.2814)	Acc@1 73.438 (71.427)	Acc@5 100.000 (98.908)
Epoch: [55][800/875]	Time 0.674 (0.682)	Data 0.008 (0.009)	Loss 2.2458 (2.3717)	Loss@kd 2.1445 (2.2814)	Acc@1 78.125 (71.303)	Acc@5 98.438 (98.888)
 * Acc@1 71.213 Acc@5 98.912
epoch 55, total time 597.39
Test: [0/750]	Time 0.898 (0.898)	Loss 0.6573 (0.6573)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.103 (0.134)	Loss 0.4707 (0.6494)	Acc@1 84.375 (82.921)	Acc@5 100.000 (93.038)
Test: [200/750]	Time 0.106 (0.130)	Loss 1.5513 (0.5891)	Acc@1 31.250 (81.716)	Acc@5 81.250 (95.087)
Test: [300/750]	Time 0.112 (0.128)	Loss 1.0827 (0.8525)	Acc@1 65.625 (69.560)	Acc@5 96.875 (93.065)
Test: [400/750]	Time 0.125 (0.127)	Loss 0.6237 (0.8809)	Acc@1 81.250 (68.197)	Acc@5 87.500 (93.243)
Test: [500/750]	Time 0.108 (0.126)	Loss 0.6311 (0.8400)	Acc@1 71.875 (70.191)	Acc@5 96.875 (93.089)
Test: [600/750]	Time 0.122 (0.125)	Loss 0.8410 (0.8567)	Acc@1 62.500 (69.925)	Acc@5 93.750 (92.804)
Test: [700/750]	Time 0.124 (0.125)	Loss 0.9047 (0.8612)	Acc@1 68.750 (69.419)	Acc@5 90.625 (93.130)
 * Acc@1 69.542 Acc@5 93.287
saving the best model!
==> training...
Epoch: [56][0/875]	Time 2.461 (2.461)	Data 1.631 (1.631)	Loss 2.2132 (2.2132)	Loss@kd 2.2790 (2.2790)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [56][100/875]	Time 0.762 (0.706)	Data 0.007 (0.023)	Loss 2.1341 (2.3581)	Loss@kd 2.2245 (2.2824)	Acc@1 78.125 (71.349)	Acc@5 100.000 (99.134)
Epoch: [56][200/875]	Time 0.735 (0.694)	Data 0.007 (0.015)	Loss 2.3187 (2.3544)	Loss@kd 2.2047 (2.2834)	Acc@1 79.688 (71.751)	Acc@5 100.000 (99.176)
Epoch: [56][300/875]	Time 0.778 (0.691)	Data 0.007 (0.013)	Loss 2.4108 (2.3471)	Loss@kd 2.1364 (2.2708)	Acc@1 56.250 (71.802)	Acc@5 98.438 (99.029)
Epoch: [56][400/875]	Time 0.780 (0.690)	Data 0.007 (0.011)	Loss 2.2182 (2.3444)	Loss@kd 2.0945 (2.2647)	Acc@1 71.875 (71.817)	Acc@5 100.000 (99.049)
Epoch: [56][500/875]	Time 0.735 (0.689)	Data 0.007 (0.011)	Loss 2.3011 (2.3466)	Loss@kd 2.1983 (2.2640)	Acc@1 71.875 (71.797)	Acc@5 98.438 (99.021)
Epoch: [56][600/875]	Time 0.774 (0.688)	Data 0.007 (0.010)	Loss 2.2457 (2.3480)	Loss@kd 2.2683 (2.2613)	Acc@1 75.000 (71.620)	Acc@5 100.000 (99.007)
Epoch: [56][700/875]	Time 0.746 (0.687)	Data 0.007 (0.010)	Loss 2.3177 (2.3517)	Loss@kd 2.2814 (2.2663)	Acc@1 73.438 (71.556)	Acc@5 98.438 (99.010)
Epoch: [56][800/875]	Time 0.764 (0.687)	Data 0.007 (0.009)	Loss 2.2175 (2.3539)	Loss@kd 2.1750 (2.2684)	Acc@1 70.312 (71.573)	Acc@5 98.438 (99.013)
 * Acc@1 71.525 Acc@5 99.005
epoch 56, total time 600.79
Test: [0/750]	Time 1.045 (1.045)	Loss 0.7718 (0.7718)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.136 (0.145)	Loss 0.4746 (0.6978)	Acc@1 87.500 (82.766)	Acc@5 96.875 (92.698)
Test: [200/750]	Time 0.196 (0.139)	Loss 1.3040 (0.6222)	Acc@1 43.750 (81.763)	Acc@5 90.625 (94.714)
Test: [300/750]	Time 0.125 (0.137)	Loss 1.1772 (0.8165)	Acc@1 53.125 (72.301)	Acc@5 87.500 (93.760)
Test: [400/750]	Time 0.122 (0.136)	Loss 0.6539 (0.8666)	Acc@1 78.125 (69.592)	Acc@5 87.500 (93.781)
Test: [500/750]	Time 0.206 (0.136)	Loss 0.4519 (0.8331)	Acc@1 84.375 (71.176)	Acc@5 96.875 (93.407)
Test: [600/750]	Time 0.117 (0.136)	Loss 0.7596 (0.8298)	Acc@1 75.000 (71.360)	Acc@5 96.875 (93.391)
Test: [700/750]	Time 0.117 (0.135)	Loss 1.1247 (0.8363)	Acc@1 59.375 (70.725)	Acc@5 90.625 (93.491)
 * Acc@1 70.392 Acc@5 93.400
saving the best model!
==> training...
Epoch: [57][0/875]	Time 2.419 (2.419)	Data 1.611 (1.611)	Loss 2.5632 (2.5632)	Loss@kd 2.4027 (2.4027)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [57][100/875]	Time 0.682 (0.702)	Data 0.007 (0.023)	Loss 2.3144 (2.3644)	Loss@kd 2.3737 (2.3010)	Acc@1 78.125 (72.618)	Acc@5 96.875 (98.871)
Epoch: [57][200/875]	Time 0.666 (0.693)	Data 0.007 (0.015)	Loss 2.4723 (2.3507)	Loss@kd 2.2693 (2.2793)	Acc@1 70.312 (72.575)	Acc@5 100.000 (98.912)
Epoch: [57][300/875]	Time 0.679 (0.689)	Data 0.007 (0.013)	Loss 2.4193 (2.3486)	Loss@kd 2.3390 (2.2692)	Acc@1 76.562 (72.306)	Acc@5 98.438 (98.936)
Epoch: [57][400/875]	Time 0.660 (0.688)	Data 0.007 (0.011)	Loss 2.3915 (2.3558)	Loss@kd 2.2296 (2.2738)	Acc@1 70.312 (72.101)	Acc@5 95.312 (98.952)
Epoch: [57][500/875]	Time 0.680 (0.686)	Data 0.007 (0.010)	Loss 2.2624 (2.3465)	Loss@kd 2.2549 (2.2651)	Acc@1 73.438 (72.093)	Acc@5 98.438 (98.958)
Epoch: [57][600/875]	Time 0.683 (0.686)	Data 0.008 (0.010)	Loss 2.4545 (2.3480)	Loss@kd 2.2503 (2.2626)	Acc@1 68.750 (71.896)	Acc@5 98.438 (98.991)
Epoch: [57][700/875]	Time 0.660 (0.686)	Data 0.007 (0.010)	Loss 2.2487 (2.3473)	Loss@kd 2.1541 (2.2619)	Acc@1 73.438 (71.873)	Acc@5 98.438 (99.008)
Epoch: [57][800/875]	Time 0.658 (0.685)	Data 0.011 (0.009)	Loss 2.3500 (2.3474)	Loss@kd 2.2634 (2.2599)	Acc@1 68.750 (71.797)	Acc@5 98.438 (99.003)
 * Acc@1 71.736 Acc@5 99.004
epoch 57, total time 599.74
Test: [0/750]	Time 0.876 (0.876)	Loss 1.5137 (1.5137)	Acc@1 53.125 (53.125)	Acc@5 75.000 (75.000)
Test: [100/750]	Time 0.116 (0.141)	Loss 0.4133 (0.9594)	Acc@1 81.250 (73.917)	Acc@5 96.875 (88.150)
Test: [200/750]	Time 0.125 (0.133)	Loss 1.4250 (0.7272)	Acc@1 43.750 (77.705)	Acc@5 93.750 (93.113)
Test: [300/750]	Time 0.102 (0.130)	Loss 1.4119 (0.8635)	Acc@1 50.000 (70.266)	Acc@5 87.500 (93.574)
Test: [400/750]	Time 0.136 (0.129)	Loss 0.7612 (0.9469)	Acc@1 75.000 (66.482)	Acc@5 87.500 (92.784)
Test: [500/750]	Time 0.122 (0.128)	Loss 0.4673 (0.9152)	Acc@1 87.500 (68.214)	Acc@5 96.875 (92.471)
Test: [600/750]	Time 0.137 (0.128)	Loss 0.7901 (0.8927)	Acc@1 78.125 (68.984)	Acc@5 90.625 (92.804)
Test: [700/750]	Time 0.120 (0.127)	Loss 0.9459 (0.8840)	Acc@1 65.625 (68.777)	Acc@5 87.500 (92.983)
 * Acc@1 68.871 Acc@5 92.996
==> training...
Epoch: [58][0/875]	Time 2.322 (2.322)	Data 1.625 (1.625)	Loss 2.3020 (2.3020)	Loss@kd 2.2345 (2.2345)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [58][100/875]	Time 0.666 (0.700)	Data 0.007 (0.023)	Loss 2.4681 (2.3310)	Loss@kd 2.2599 (2.2659)	Acc@1 65.625 (72.277)	Acc@5 98.438 (99.010)
Epoch: [58][200/875]	Time 0.668 (0.691)	Data 0.007 (0.016)	Loss 2.2186 (2.3181)	Loss@kd 2.2583 (2.2481)	Acc@1 79.688 (72.551)	Acc@5 100.000 (99.044)
Epoch: [58][300/875]	Time 0.676 (0.688)	Data 0.007 (0.013)	Loss 2.2285 (2.3296)	Loss@kd 2.3809 (2.2554)	Acc@1 79.688 (72.384)	Acc@5 100.000 (99.050)
Epoch: [58][400/875]	Time 0.680 (0.687)	Data 0.007 (0.012)	Loss 2.5720 (2.3298)	Loss@kd 2.1927 (2.2470)	Acc@1 64.062 (72.230)	Acc@5 100.000 (99.022)
Epoch: [58][500/875]	Time 0.749 (0.687)	Data 0.007 (0.011)	Loss 2.3476 (2.3326)	Loss@kd 2.2511 (2.2517)	Acc@1 68.750 (72.165)	Acc@5 96.875 (99.011)
Epoch: [58][600/875]	Time 0.679 (0.686)	Data 0.007 (0.010)	Loss 2.4266 (2.3355)	Loss@kd 2.1315 (2.2499)	Acc@1 65.625 (72.005)	Acc@5 96.875 (98.996)
Epoch: [58][700/875]	Time 0.684 (0.685)	Data 0.007 (0.010)	Loss 2.3155 (2.3415)	Loss@kd 2.3152 (2.2567)	Acc@1 68.750 (71.915)	Acc@5 100.000 (99.001)
Epoch: [58][800/875]	Time 0.673 (0.685)	Data 0.007 (0.010)	Loss 2.1596 (2.3467)	Loss@kd 2.2666 (2.2639)	Acc@1 78.125 (71.824)	Acc@5 100.000 (99.025)
 * Acc@1 71.857 Acc@5 99.007
epoch 58, total time 600.00
Test: [0/750]	Time 0.897 (0.897)	Loss 3.2588 (3.2588)	Acc@1 28.125 (28.125)	Acc@5 43.750 (43.750)
Test: [100/750]	Time 0.112 (0.136)	Loss 0.4501 (2.7114)	Acc@1 84.375 (29.146)	Acc@5 100.000 (56.157)
Test: [200/750]	Time 0.111 (0.131)	Loss 1.6682 (1.6448)	Acc@1 34.375 (53.747)	Acc@5 84.375 (76.322)
Test: [300/750]	Time 0.106 (0.128)	Loss 1.2647 (1.6183)	Acc@1 59.375 (49.304)	Acc@5 93.750 (79.547)
Test: [400/750]	Time 0.109 (0.127)	Loss 0.6760 (1.4979)	Acc@1 78.125 (51.925)	Acc@5 90.625 (82.497)
Test: [500/750]	Time 0.113 (0.126)	Loss 0.4763 (1.3353)	Acc@1 93.750 (57.017)	Acc@5 96.875 (84.593)
Test: [600/750]	Time 0.116 (0.126)	Loss 0.6315 (1.2491)	Acc@1 68.750 (59.573)	Acc@5 96.875 (86.179)
Test: [700/750]	Time 0.124 (0.125)	Loss 1.0067 (1.1962)	Acc@1 59.375 (60.650)	Acc@5 90.625 (87.384)
 * Acc@1 61.312 Acc@5 87.717
==> training...
Epoch: [59][0/875]	Time 2.244 (2.244)	Data 1.558 (1.558)	Loss 2.4584 (2.4584)	Loss@kd 2.2899 (2.2899)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [59][100/875]	Time 0.673 (0.698)	Data 0.007 (0.022)	Loss 2.2780 (2.3653)	Loss@kd 2.2903 (2.3258)	Acc@1 73.438 (73.113)	Acc@5 98.438 (99.180)
Epoch: [59][200/875]	Time 0.795 (0.692)	Data 0.007 (0.015)	Loss 2.4132 (2.3502)	Loss@kd 2.3928 (2.2912)	Acc@1 68.750 (72.567)	Acc@5 98.438 (99.176)
Epoch: [59][300/875]	Time 0.669 (0.689)	Data 0.009 (0.012)	Loss 2.3354 (2.3418)	Loss@kd 2.1181 (2.2798)	Acc@1 73.438 (72.436)	Acc@5 95.312 (99.138)
Epoch: [59][400/875]	Time 0.681 (0.688)	Data 0.007 (0.011)	Loss 2.3159 (2.3346)	Loss@kd 2.0984 (2.2644)	Acc@1 62.500 (72.300)	Acc@5 98.438 (99.084)
Epoch: [59][500/875]	Time 0.678 (0.687)	Data 0.007 (0.010)	Loss 2.3806 (2.3412)	Loss@kd 2.2026 (2.2650)	Acc@1 75.000 (71.981)	Acc@5 100.000 (99.099)
Epoch: [59][600/875]	Time 0.677 (0.686)	Data 0.008 (0.010)	Loss 2.3242 (2.3449)	Loss@kd 2.0277 (2.2625)	Acc@1 68.750 (71.784)	Acc@5 96.875 (99.072)
Epoch: [59][700/875]	Time 0.670 (0.685)	Data 0.007 (0.010)	Loss 2.6019 (2.3422)	Loss@kd 2.2617 (2.2594)	Acc@1 67.188 (71.828)	Acc@5 98.438 (99.046)
Epoch: [59][800/875]	Time 0.684 (0.684)	Data 0.008 (0.009)	Loss 2.2077 (2.3435)	Loss@kd 2.3169 (2.2575)	Acc@1 82.812 (71.721)	Acc@5 100.000 (99.038)
 * Acc@1 71.800 Acc@5 99.011
epoch 59, total time 599.56
Test: [0/750]	Time 1.011 (1.011)	Loss 5.5979 (5.5979)	Acc@1 21.875 (21.875)	Acc@5 34.375 (34.375)
Test: [100/750]	Time 0.103 (0.146)	Loss 0.4620 (4.0142)	Acc@1 78.125 (39.078)	Acc@5 100.000 (55.043)
Test: [200/750]	Time 0.124 (0.135)	Loss 1.2938 (2.2633)	Acc@1 50.000 (60.681)	Acc@5 93.750 (76.290)
Test: [300/750]	Time 0.112 (0.131)	Loss 1.5774 (1.9354)	Acc@1 43.750 (57.776)	Acc@5 87.500 (81.105)
Test: [400/750]	Time 0.110 (0.129)	Loss 0.6479 (1.8116)	Acc@1 81.250 (55.619)	Acc@5 90.625 (81.772)
Test: [500/750]	Time 0.124 (0.128)	Loss 0.5190 (1.5864)	Acc@1 87.500 (60.317)	Acc@5 96.875 (84.069)
Test: [600/750]	Time 0.098 (0.128)	Loss 0.8271 (1.4456)	Acc@1 62.500 (62.791)	Acc@5 100.000 (85.898)
Test: [700/750]	Time 0.171 (0.127)	Loss 1.2740 (1.3656)	Acc@1 56.250 (63.574)	Acc@5 84.375 (87.063)
 * Acc@1 63.792 Acc@5 87.346
==> training...
Epoch: [60][0/875]	Time 2.323 (2.323)	Data 1.600 (1.600)	Loss 2.1406 (2.1406)	Loss@kd 2.4405 (2.4405)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [60][100/875]	Time 0.684 (0.700)	Data 0.007 (0.023)	Loss 2.2493 (2.3395)	Loss@kd 2.1567 (2.2616)	Acc@1 65.625 (72.123)	Acc@5 100.000 (99.072)
Epoch: [60][200/875]	Time 0.658 (0.691)	Data 0.007 (0.015)	Loss 2.2901 (2.3345)	Loss@kd 2.3129 (2.2575)	Acc@1 73.438 (71.929)	Acc@5 100.000 (99.059)
Epoch: [60][300/875]	Time 0.677 (0.686)	Data 0.008 (0.013)	Loss 2.4317 (2.3292)	Loss@kd 2.2295 (2.2506)	Acc@1 65.625 (72.155)	Acc@5 98.438 (99.050)
Epoch: [60][400/875]	Time 0.687 (0.684)	Data 0.007 (0.011)	Loss 2.7146 (2.3304)	Loss@kd 2.4481 (2.2524)	Acc@1 59.375 (72.046)	Acc@5 98.438 (99.080)
Epoch: [60][500/875]	Time 0.695 (0.683)	Data 0.007 (0.010)	Loss 2.3755 (2.3301)	Loss@kd 2.3306 (2.2514)	Acc@1 71.875 (71.972)	Acc@5 96.875 (99.058)
Epoch: [60][600/875]	Time 0.736 (0.683)	Data 0.007 (0.010)	Loss 2.4035 (2.3455)	Loss@kd 2.3075 (2.2661)	Acc@1 76.562 (71.849)	Acc@5 98.438 (99.033)
Epoch: [60][700/875]	Time 0.703 (0.683)	Data 0.008 (0.010)	Loss 2.3365 (2.3552)	Loss@kd 2.2988 (2.2777)	Acc@1 76.562 (71.721)	Acc@5 98.438 (99.024)
Epoch: [60][800/875]	Time 0.684 (0.683)	Data 0.007 (0.009)	Loss 2.1286 (2.3540)	Loss@kd 2.0718 (2.2745)	Acc@1 67.188 (71.742)	Acc@5 100.000 (98.995)
 * Acc@1 71.730 Acc@5 99.009
epoch 60, total time 597.50
Test: [0/750]	Time 0.936 (0.936)	Loss 3.2483 (3.2483)	Acc@1 50.000 (50.000)	Acc@5 62.500 (62.500)
Test: [100/750]	Time 0.122 (0.140)	Loss 0.4543 (1.7659)	Acc@1 81.250 (62.840)	Acc@5 96.875 (81.714)
Test: [200/750]	Time 0.130 (0.131)	Loss 1.1353 (1.1342)	Acc@1 53.125 (72.839)	Acc@5 90.625 (89.366)
Test: [300/750]	Time 0.168 (0.128)	Loss 1.2886 (1.1619)	Acc@1 50.000 (65.926)	Acc@5 90.625 (90.687)
Test: [400/750]	Time 0.126 (0.127)	Loss 0.4462 (1.1605)	Acc@1 87.500 (63.544)	Acc@5 96.875 (90.711)
Test: [500/750]	Time 0.116 (0.128)	Loss 0.4508 (1.0381)	Acc@1 84.375 (67.652)	Acc@5 100.000 (91.554)
Test: [600/750]	Time 0.099 (0.128)	Loss 0.7744 (1.0023)	Acc@1 75.000 (68.636)	Acc@5 93.750 (92.086)
Test: [700/750]	Time 0.125 (0.127)	Loss 1.4763 (1.0231)	Acc@1 46.875 (67.141)	Acc@5 78.125 (92.025)
 * Acc@1 66.008 Acc@5 91.704
==> training...
Epoch: [61][0/875]	Time 2.435 (2.435)	Data 1.705 (1.705)	Loss 2.3447 (2.3447)	Loss@kd 2.3109 (2.3109)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [61][100/875]	Time 0.676 (0.700)	Data 0.007 (0.024)	Loss 2.1310 (2.3718)	Loss@kd 2.1825 (2.2737)	Acc@1 73.438 (71.055)	Acc@5 100.000 (99.149)
Epoch: [61][200/875]	Time 0.675 (0.689)	Data 0.008 (0.016)	Loss 2.1919 (2.3146)	Loss@kd 2.2242 (2.2512)	Acc@1 79.688 (72.800)	Acc@5 98.438 (99.215)
Epoch: [61][300/875]	Time 0.667 (0.687)	Data 0.007 (0.013)	Loss 2.3635 (2.3192)	Loss@kd 2.4569 (2.2585)	Acc@1 73.438 (72.913)	Acc@5 100.000 (99.133)
Epoch: [61][400/875]	Time 0.683 (0.687)	Data 0.007 (0.011)	Loss 2.4173 (2.3264)	Loss@kd 2.3239 (2.2578)	Acc@1 70.312 (72.456)	Acc@5 100.000 (99.127)
Epoch: [61][500/875]	Time 0.682 (0.688)	Data 0.007 (0.011)	Loss 2.2142 (2.3270)	Loss@kd 2.1986 (2.2547)	Acc@1 76.562 (72.315)	Acc@5 100.000 (99.096)
Epoch: [61][600/875]	Time 0.657 (0.687)	Data 0.007 (0.010)	Loss 2.3061 (2.3271)	Loss@kd 2.1789 (2.2533)	Acc@1 73.438 (72.200)	Acc@5 100.000 (99.064)
Epoch: [61][700/875]	Time 0.672 (0.687)	Data 0.007 (0.010)	Loss 2.2972 (2.3248)	Loss@kd 2.1291 (2.2503)	Acc@1 67.188 (72.196)	Acc@5 100.000 (99.091)
Epoch: [61][800/875]	Time 0.678 (0.687)	Data 0.007 (0.009)	Loss 2.2622 (2.3250)	Loss@kd 2.0695 (2.2474)	Acc@1 71.875 (72.193)	Acc@5 100.000 (99.087)
 * Acc@1 72.127 Acc@5 99.064
epoch 61, total time 601.98
Test: [0/750]	Time 1.065 (1.065)	Loss 0.4554 (0.4554)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.136 (0.141)	Loss 0.4095 (0.5550)	Acc@1 84.375 (85.644)	Acc@5 96.875 (93.193)
Test: [200/750]	Time 0.138 (0.136)	Loss 1.2459 (0.4865)	Acc@1 46.875 (86.272)	Acc@5 90.625 (95.522)
Test: [300/750]	Time 0.135 (0.135)	Loss 1.4367 (0.6946)	Acc@1 53.125 (76.900)	Acc@5 84.375 (94.840)
Test: [400/750]	Time 0.134 (0.134)	Loss 0.7188 (0.8319)	Acc@1 81.250 (70.831)	Acc@5 87.500 (93.812)
Test: [500/750]	Time 0.140 (0.134)	Loss 0.8273 (0.8283)	Acc@1 65.625 (71.289)	Acc@5 96.875 (93.607)
Test: [600/750]	Time 0.117 (0.134)	Loss 1.0965 (0.8728)	Acc@1 68.750 (69.847)	Acc@5 90.625 (93.256)
Test: [700/750]	Time 0.130 (0.133)	Loss 0.9420 (0.8804)	Acc@1 62.500 (69.410)	Acc@5 87.500 (93.380)
 * Acc@1 69.679 Acc@5 93.479
==> training...
Epoch: [62][0/875]	Time 2.335 (2.335)	Data 1.615 (1.615)	Loss 2.1375 (2.1375)	Loss@kd 2.1644 (2.1644)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [62][100/875]	Time 0.694 (0.702)	Data 0.008 (0.023)	Loss 2.2438 (2.3122)	Loss@kd 2.3314 (2.2486)	Acc@1 75.000 (71.983)	Acc@5 100.000 (99.196)
Epoch: [62][200/875]	Time 0.656 (0.692)	Data 0.007 (0.015)	Loss 2.3151 (2.3155)	Loss@kd 2.2368 (2.2497)	Acc@1 73.438 (72.318)	Acc@5 100.000 (99.114)
Epoch: [62][300/875]	Time 0.665 (0.689)	Data 0.007 (0.013)	Loss 2.5298 (2.3166)	Loss@kd 2.0650 (2.2443)	Acc@1 64.062 (72.197)	Acc@5 96.875 (99.112)
Epoch: [62][400/875]	Time 0.721 (0.687)	Data 0.007 (0.011)	Loss 2.3219 (2.3173)	Loss@kd 2.2187 (2.2408)	Acc@1 67.188 (72.043)	Acc@5 98.438 (99.108)
Epoch: [62][500/875]	Time 0.657 (0.686)	Data 0.007 (0.011)	Loss 2.2726 (2.3197)	Loss@kd 2.1753 (2.2475)	Acc@1 75.000 (72.131)	Acc@5 98.438 (99.139)
Epoch: [62][600/875]	Time 0.678 (0.685)	Data 0.007 (0.010)	Loss 2.1848 (2.3212)	Loss@kd 2.2096 (2.2473)	Acc@1 76.562 (72.148)	Acc@5 100.000 (99.103)
Epoch: [62][700/875]	Time 0.666 (0.685)	Data 0.010 (0.010)	Loss 2.1500 (2.3171)	Loss@kd 2.1595 (2.2427)	Acc@1 79.688 (72.160)	Acc@5 96.875 (99.102)
Epoch: [62][800/875]	Time 0.676 (0.685)	Data 0.007 (0.009)	Loss 2.0933 (2.3161)	Loss@kd 2.1283 (2.2414)	Acc@1 75.000 (72.158)	Acc@5 100.000 (99.064)
 * Acc@1 72.198 Acc@5 99.055
epoch 62, total time 599.24
Test: [0/750]	Time 0.992 (0.992)	Loss 0.9494 (0.9494)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.122 (0.134)	Loss 0.5665 (0.6723)	Acc@1 81.250 (82.704)	Acc@5 100.000 (93.193)
Test: [200/750]	Time 0.133 (0.129)	Loss 1.4757 (0.6178)	Acc@1 50.000 (80.986)	Acc@5 84.375 (95.118)
Test: [300/750]	Time 0.135 (0.127)	Loss 1.7155 (0.8802)	Acc@1 40.625 (69.996)	Acc@5 87.500 (93.034)
Test: [400/750]	Time 0.117 (0.126)	Loss 0.8154 (1.0138)	Acc@1 81.250 (64.409)	Acc@5 90.625 (92.207)
Test: [500/750]	Time 0.119 (0.125)	Loss 0.6096 (0.9659)	Acc@1 78.125 (66.667)	Acc@5 100.000 (92.197)
Test: [600/750]	Time 0.187 (0.125)	Loss 0.5808 (0.9322)	Acc@1 81.250 (67.923)	Acc@5 96.875 (92.611)
Test: [700/750]	Time 0.119 (0.125)	Loss 0.7868 (0.8986)	Acc@1 78.125 (69.067)	Acc@5 93.750 (93.041)
 * Acc@1 69.567 Acc@5 93.100
==> training...
Epoch: [63][0/875]	Time 2.318 (2.318)	Data 1.625 (1.625)	Loss 2.5282 (2.5282)	Loss@kd 2.5436 (2.5436)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [63][100/875]	Time 0.690 (0.699)	Data 0.007 (0.023)	Loss 2.4787 (2.3287)	Loss@kd 2.3981 (2.2382)	Acc@1 62.500 (71.566)	Acc@5 100.000 (99.103)
Epoch: [63][200/875]	Time 0.666 (0.691)	Data 0.007 (0.015)	Loss 2.2556 (2.4306)	Loss@kd 2.1896 (2.3675)	Acc@1 68.750 (71.191)	Acc@5 100.000 (99.044)
Epoch: [63][300/875]	Time 0.636 (0.688)	Data 0.007 (0.013)	Loss 2.2420 (2.4129)	Loss@kd 2.1198 (2.3532)	Acc@1 78.125 (71.745)	Acc@5 100.000 (98.972)
Epoch: [63][400/875]	Time 0.669 (0.686)	Data 0.007 (0.011)	Loss 2.6177 (2.3960)	Loss@kd 2.2161 (2.3316)	Acc@1 56.250 (71.665)	Acc@5 100.000 (98.975)
Epoch: [63][500/875]	Time 0.690 (0.686)	Data 0.008 (0.011)	Loss 2.3674 (2.3934)	Loss@kd 2.0937 (2.3295)	Acc@1 67.188 (71.691)	Acc@5 100.000 (98.980)
Epoch: [63][600/875]	Time 0.692 (0.685)	Data 0.011 (0.010)	Loss 2.3876 (2.3857)	Loss@kd 2.3214 (2.3190)	Acc@1 71.875 (71.802)	Acc@5 100.000 (98.976)
Epoch: [63][700/875]	Time 0.690 (0.684)	Data 0.008 (0.010)	Loss 2.3111 (2.3791)	Loss@kd 2.3662 (2.3140)	Acc@1 75.000 (71.868)	Acc@5 100.000 (98.999)
Epoch: [63][800/875]	Time 0.648 (0.684)	Data 0.007 (0.009)	Loss 2.3574 (2.3737)	Loss@kd 2.2059 (2.3035)	Acc@1 71.875 (71.742)	Acc@5 100.000 (98.990)
 * Acc@1 71.770 Acc@5 99.011
epoch 63, total time 598.79
Test: [0/750]	Time 0.963 (0.963)	Loss 0.5492 (0.5492)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.117 (0.134)	Loss 0.4552 (0.6237)	Acc@1 84.375 (84.777)	Acc@5 100.000 (93.348)
Test: [200/750]	Time 0.112 (0.130)	Loss 1.6038 (0.5752)	Acc@1 40.625 (82.540)	Acc@5 87.500 (95.336)
Test: [300/750]	Time 0.101 (0.130)	Loss 0.8767 (0.8117)	Acc@1 75.000 (70.390)	Acc@5 96.875 (94.549)
Test: [400/750]	Time 0.113 (0.129)	Loss 0.9176 (0.8249)	Acc@1 71.875 (70.090)	Acc@5 87.500 (94.654)
Test: [500/750]	Time 0.126 (0.128)	Loss 0.5681 (0.8727)	Acc@1 81.250 (69.580)	Acc@5 100.000 (93.444)
Test: [600/750]	Time 0.120 (0.128)	Loss 0.9954 (0.8934)	Acc@1 62.500 (69.239)	Acc@5 87.500 (93.017)
Test: [700/750]	Time 0.122 (0.127)	Loss 1.1083 (0.8953)	Acc@1 62.500 (68.763)	Acc@5 84.375 (93.211)
 * Acc@1 68.658 Acc@5 93.200
==> training...
Epoch: [64][0/875]	Time 2.338 (2.338)	Data 1.630 (1.630)	Loss 2.7951 (2.7951)	Loss@kd 2.6391 (2.6391)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [64][100/875]	Time 0.682 (0.702)	Data 0.006 (0.023)	Loss 2.3790 (2.3037)	Loss@kd 2.3109 (2.2282)	Acc@1 71.875 (72.463)	Acc@5 100.000 (99.335)
Epoch: [64][200/875]	Time 0.697 (0.694)	Data 0.007 (0.015)	Loss 2.1029 (2.2881)	Loss@kd 2.2024 (2.2191)	Acc@1 76.562 (72.730)	Acc@5 100.000 (99.238)
Epoch: [64][300/875]	Time 0.676 (0.689)	Data 0.008 (0.013)	Loss 2.0226 (2.2812)	Loss@kd 2.1682 (2.2147)	Acc@1 81.250 (72.721)	Acc@5 100.000 (99.237)
Epoch: [64][400/875]	Time 0.685 (0.688)	Data 0.007 (0.011)	Loss 2.2467 (2.2800)	Loss@kd 2.2116 (2.2109)	Acc@1 73.438 (72.724)	Acc@5 100.000 (99.197)
Epoch: [64][500/875]	Time 0.661 (0.687)	Data 0.007 (0.011)	Loss 2.4096 (2.3005)	Loss@kd 2.2950 (2.2276)	Acc@1 67.188 (72.418)	Acc@5 100.000 (99.127)
Epoch: [64][600/875]	Time 0.781 (0.686)	Data 0.007 (0.010)	Loss 3.2008 (2.3117)	Loss@kd 3.6422 (2.2388)	Acc@1 73.438 (72.255)	Acc@5 98.438 (99.100)
Epoch: [64][700/875]	Time 0.676 (0.685)	Data 0.007 (0.010)	Loss 2.5297 (2.3131)	Loss@kd 2.2264 (2.2401)	Acc@1 59.375 (72.249)	Acc@5 96.875 (99.066)
Epoch: [64][800/875]	Time 0.670 (0.685)	Data 0.010 (0.009)	Loss 2.3343 (2.3146)	Loss@kd 2.2136 (2.2395)	Acc@1 71.875 (72.222)	Acc@5 100.000 (99.079)
 * Acc@1 72.216 Acc@5 99.062
epoch 64, total time 600.00
Test: [0/750]	Time 1.015 (1.015)	Loss 0.7132 (0.7132)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.136 (0.147)	Loss 0.4239 (0.6151)	Acc@1 78.125 (83.632)	Acc@5 100.000 (92.946)
Test: [200/750]	Time 0.126 (0.139)	Loss 1.3735 (0.5475)	Acc@1 46.875 (82.945)	Acc@5 84.375 (95.134)
Test: [300/750]	Time 0.118 (0.138)	Loss 1.1095 (0.7904)	Acc@1 68.750 (72.020)	Acc@5 93.750 (93.843)
Test: [400/750]	Time 0.112 (0.137)	Loss 0.4756 (0.8401)	Acc@1 84.375 (69.740)	Acc@5 93.750 (93.820)
Test: [500/750]	Time 0.208 (0.137)	Loss 0.6599 (0.8107)	Acc@1 81.250 (71.800)	Acc@5 93.750 (93.787)
Test: [600/750]	Time 0.137 (0.137)	Loss 0.8570 (0.8280)	Acc@1 62.500 (71.449)	Acc@5 93.750 (93.620)
Test: [700/750]	Time 0.133 (0.136)	Loss 1.3898 (0.8528)	Acc@1 53.125 (70.194)	Acc@5 87.500 (93.563)
 * Acc@1 69.512 Acc@5 93.383
==> training...
Epoch: [65][0/875]	Time 2.453 (2.453)	Data 1.642 (1.642)	Loss 2.4226 (2.4226)	Loss@kd 2.2194 (2.2194)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [65][100/875]	Time 0.665 (0.704)	Data 0.007 (0.023)	Loss 2.7953 (2.2973)	Loss@kd 2.9983 (2.2094)	Acc@1 75.000 (72.215)	Acc@5 100.000 (99.118)
Epoch: [65][200/875]	Time 0.687 (0.695)	Data 0.007 (0.015)	Loss 2.1523 (2.3451)	Loss@kd 2.2198 (2.2834)	Acc@1 81.250 (72.295)	Acc@5 100.000 (99.021)
Epoch: [65][300/875]	Time 0.663 (0.692)	Data 0.007 (0.013)	Loss 1.9555 (2.3285)	Loss@kd 2.2254 (2.2673)	Acc@1 87.500 (72.586)	Acc@5 100.000 (99.102)
Epoch: [65][400/875]	Time 0.648 (0.689)	Data 0.008 (0.011)	Loss 2.2595 (2.3181)	Loss@kd 2.2660 (2.2584)	Acc@1 73.438 (72.740)	Acc@5 100.000 (99.119)
Epoch: [65][500/875]	Time 0.660 (0.688)	Data 0.007 (0.011)	Loss 2.2692 (2.3176)	Loss@kd 2.2368 (2.2502)	Acc@1 75.000 (72.570)	Acc@5 100.000 (99.111)
Epoch: [65][600/875]	Time 0.669 (0.687)	Data 0.007 (0.010)	Loss 2.1910 (2.3101)	Loss@kd 2.2811 (2.2431)	Acc@1 81.250 (72.723)	Acc@5 100.000 (99.093)
Epoch: [65][700/875]	Time 0.656 (0.688)	Data 0.007 (0.010)	Loss 2.4150 (2.3066)	Loss@kd 2.1389 (2.2353)	Acc@1 65.625 (72.644)	Acc@5 98.438 (99.084)
Epoch: [65][800/875]	Time 0.687 (0.687)	Data 0.007 (0.009)	Loss 2.2098 (2.3044)	Loss@kd 2.1443 (2.2302)	Acc@1 75.000 (72.558)	Acc@5 100.000 (99.068)
 * Acc@1 72.575 Acc@5 99.073
epoch 65, total time 601.57
Test: [0/750]	Time 0.956 (0.956)	Loss 0.4118 (0.4118)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.114 (0.137)	Loss 0.5078 (0.5548)	Acc@1 78.125 (85.644)	Acc@5 93.750 (95.390)
Test: [200/750]	Time 0.120 (0.130)	Loss 1.6579 (0.6145)	Acc@1 37.500 (80.053)	Acc@5 78.125 (95.351)
Test: [300/750]	Time 0.108 (0.129)	Loss 1.1512 (0.9282)	Acc@1 65.625 (66.424)	Acc@5 90.625 (92.317)
Test: [400/750]	Time 0.122 (0.128)	Loss 0.5612 (0.9311)	Acc@1 81.250 (66.233)	Acc@5 90.625 (92.526)
Test: [500/750]	Time 0.214 (0.127)	Loss 0.4558 (0.8765)	Acc@1 78.125 (68.862)	Acc@5 100.000 (92.652)
Test: [600/750]	Time 0.131 (0.127)	Loss 0.9602 (0.8662)	Acc@1 65.625 (69.613)	Acc@5 84.375 (92.752)
Test: [700/750]	Time 0.128 (0.127)	Loss 0.7989 (0.8635)	Acc@1 65.625 (69.468)	Acc@5 93.750 (93.006)
 * Acc@1 69.733 Acc@5 93.079
==> training...
Epoch: [66][0/875]	Time 2.418 (2.418)	Data 1.641 (1.641)	Loss 2.2245 (2.2245)	Loss@kd 2.2861 (2.2861)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [66][100/875]	Time 0.668 (0.699)	Data 0.006 (0.023)	Loss 2.1246 (2.2846)	Loss@kd 2.0513 (2.2319)	Acc@1 73.438 (73.360)	Acc@5 98.438 (99.288)
Epoch: [66][200/875]	Time 0.677 (0.690)	Data 0.010 (0.015)	Loss 2.1447 (2.2704)	Loss@kd 2.0926 (2.2177)	Acc@1 75.000 (73.577)	Acc@5 100.000 (99.199)
Epoch: [66][300/875]	Time 0.675 (0.689)	Data 0.007 (0.013)	Loss 2.1774 (2.2824)	Loss@kd 2.1760 (2.2269)	Acc@1 71.875 (73.313)	Acc@5 96.875 (99.128)
Epoch: [66][400/875]	Time 0.758 (0.687)	Data 0.008 (0.011)	Loss 2.4022 (2.2934)	Loss@kd 2.2769 (2.2255)	Acc@1 67.188 (72.935)	Acc@5 100.000 (99.077)
Epoch: [66][500/875]	Time 0.677 (0.686)	Data 0.007 (0.011)	Loss 2.3584 (2.2976)	Loss@kd 2.0952 (2.2310)	Acc@1 67.188 (72.945)	Acc@5 100.000 (99.080)
Epoch: [66][600/875]	Time 0.663 (0.686)	Data 0.007 (0.010)	Loss 4.0365 (2.3008)	Loss@kd 4.1019 (2.2360)	Acc@1 65.625 (72.980)	Acc@5 100.000 (99.095)
Epoch: [66][700/875]	Time 0.706 (0.685)	Data 0.007 (0.010)	Loss 2.2164 (2.3044)	Loss@kd 2.1647 (2.2388)	Acc@1 71.875 (72.916)	Acc@5 96.875 (99.102)
Epoch: [66][800/875]	Time 0.677 (0.685)	Data 0.008 (0.009)	Loss 2.0249 (2.3062)	Loss@kd 2.2181 (2.2409)	Acc@1 82.812 (72.932)	Acc@5 100.000 (99.093)
 * Acc@1 72.773 Acc@5 99.057
epoch 66, total time 599.75
Test: [0/750]	Time 0.909 (0.909)	Loss 0.6355 (0.6355)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.127 (0.133)	Loss 0.7667 (0.6788)	Acc@1 78.125 (83.911)	Acc@5 90.625 (92.853)
Test: [200/750]	Time 0.109 (0.127)	Loss 1.4406 (0.7302)	Acc@1 43.750 (77.254)	Acc@5 96.875 (94.372)
Test: [300/750]	Time 0.089 (0.126)	Loss 0.8891 (0.9061)	Acc@1 68.750 (68.148)	Acc@5 96.875 (93.719)
Test: [400/750]	Time 0.095 (0.125)	Loss 0.6824 (0.9044)	Acc@1 78.125 (67.612)	Acc@5 90.625 (93.851)
Test: [500/750]	Time 0.102 (0.124)	Loss 0.4960 (0.8770)	Acc@1 78.125 (69.343)	Acc@5 96.875 (93.500)
Test: [600/750]	Time 0.106 (0.124)	Loss 0.6756 (0.8664)	Acc@1 71.875 (70.029)	Acc@5 90.625 (93.485)
Test: [700/750]	Time 0.132 (0.124)	Loss 1.0892 (0.8702)	Acc@1 59.375 (69.677)	Acc@5 84.375 (93.465)
 * Acc@1 69.550 Acc@5 93.458
==> training...
Epoch: [67][0/875]	Time 2.327 (2.327)	Data 1.604 (1.604)	Loss 2.2076 (2.2076)	Loss@kd 2.1183 (2.1183)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [67][100/875]	Time 0.680 (0.699)	Data 0.007 (0.023)	Loss 2.2926 (2.2713)	Loss@kd 2.1282 (2.2055)	Acc@1 62.500 (72.927)	Acc@5 100.000 (99.242)
Epoch: [67][200/875]	Time 0.684 (0.693)	Data 0.008 (0.015)	Loss 2.3656 (2.2761)	Loss@kd 2.2655 (2.2153)	Acc@1 75.000 (72.994)	Acc@5 98.438 (99.254)
Epoch: [67][300/875]	Time 0.673 (0.689)	Data 0.007 (0.013)	Loss 2.1469 (2.2811)	Loss@kd 2.1391 (2.2200)	Acc@1 76.562 (72.944)	Acc@5 96.875 (99.216)
Epoch: [67][400/875]	Time 0.679 (0.687)	Data 0.007 (0.011)	Loss 2.1968 (2.2741)	Loss@kd 2.3026 (2.2123)	Acc@1 79.688 (72.978)	Acc@5 100.000 (99.193)
Epoch: [67][500/875]	Time 0.755 (0.687)	Data 0.007 (0.011)	Loss 2.3214 (2.2768)	Loss@kd 2.2460 (2.2134)	Acc@1 71.875 (72.970)	Acc@5 100.000 (99.152)
Epoch: [67][600/875]	Time 0.668 (0.685)	Data 0.007 (0.010)	Loss 2.0579 (2.2804)	Loss@kd 2.1549 (2.2125)	Acc@1 81.250 (72.920)	Acc@5 100.000 (99.145)
Epoch: [67][700/875]	Time 0.665 (0.685)	Data 0.008 (0.010)	Loss 2.2715 (2.2879)	Loss@kd 2.0681 (2.2204)	Acc@1 65.625 (72.836)	Acc@5 100.000 (99.124)
Epoch: [67][800/875]	Time 0.665 (0.685)	Data 0.007 (0.009)	Loss 2.3115 (2.2925)	Loss@kd 2.2947 (2.2263)	Acc@1 73.438 (72.841)	Acc@5 98.438 (99.099)
 * Acc@1 72.727 Acc@5 99.095
epoch 67, total time 599.16
Test: [0/750]	Time 1.020 (1.020)	Loss 1.7459 (1.7459)	Acc@1 65.625 (65.625)	Acc@5 75.000 (75.000)
Test: [100/750]	Time 0.115 (0.141)	Loss 0.5548 (0.8814)	Acc@1 75.000 (76.949)	Acc@5 96.875 (89.573)
Test: [200/750]	Time 0.135 (0.136)	Loss 1.1018 (0.7035)	Acc@1 56.250 (79.027)	Acc@5 96.875 (93.501)
Test: [300/750]	Time 0.123 (0.135)	Loss 1.3237 (0.8474)	Acc@1 56.250 (71.522)	Acc@5 93.750 (93.449)
Test: [400/750]	Time 0.119 (0.134)	Loss 0.4111 (0.8826)	Acc@1 90.625 (69.202)	Acc@5 96.875 (93.485)
Test: [500/750]	Time 0.125 (0.134)	Loss 0.7463 (0.8356)	Acc@1 68.750 (71.164)	Acc@5 93.750 (93.607)
Test: [600/750]	Time 0.118 (0.133)	Loss 0.6709 (0.8574)	Acc@1 78.125 (70.549)	Acc@5 93.750 (93.396)
Test: [700/750]	Time 0.118 (0.132)	Loss 1.3425 (0.8761)	Acc@1 53.125 (69.441)	Acc@5 81.250 (93.184)
 * Acc@1 68.942 Acc@5 92.887
==> training...
Epoch: [68][0/875]	Time 2.366 (2.366)	Data 1.644 (1.644)	Loss 2.1959 (2.1959)	Loss@kd 2.0493 (2.0493)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [68][100/875]	Time 0.670 (0.698)	Data 0.007 (0.023)	Loss 2.4961 (2.2644)	Loss@kd 2.1547 (2.1972)	Acc@1 62.500 (73.113)	Acc@5 95.312 (99.165)
Epoch: [68][200/875]	Time 0.664 (0.689)	Data 0.007 (0.015)	Loss 2.3198 (2.2694)	Loss@kd 2.1172 (2.2048)	Acc@1 71.875 (72.769)	Acc@5 98.438 (99.184)
Epoch: [68][300/875]	Time 0.777 (0.686)	Data 0.007 (0.013)	Loss 2.2700 (2.2695)	Loss@kd 2.1582 (2.2076)	Acc@1 71.875 (73.136)	Acc@5 100.000 (99.216)
Epoch: [68][400/875]	Time 0.667 (0.684)	Data 0.007 (0.011)	Loss 2.2073 (2.2690)	Loss@kd 2.0806 (2.2042)	Acc@1 68.750 (73.126)	Acc@5 100.000 (99.244)
Epoch: [68][500/875]	Time 0.683 (0.684)	Data 0.007 (0.011)	Loss 2.3204 (2.2634)	Loss@kd 2.1519 (2.2000)	Acc@1 64.062 (73.238)	Acc@5 100.000 (99.248)
Epoch: [68][600/875]	Time 0.689 (0.684)	Data 0.007 (0.010)	Loss 2.1911 (2.2664)	Loss@kd 2.1036 (2.2035)	Acc@1 75.000 (73.178)	Acc@5 100.000 (99.223)
Epoch: [68][700/875]	Time 0.658 (0.684)	Data 0.007 (0.010)	Loss 2.1644 (2.2688)	Loss@kd 2.1102 (2.2053)	Acc@1 75.000 (73.083)	Acc@5 100.000 (99.218)
Epoch: [68][800/875]	Time 0.690 (0.684)	Data 0.008 (0.009)	Loss 2.3456 (2.2790)	Loss@kd 2.1705 (2.2138)	Acc@1 65.625 (72.946)	Acc@5 100.000 (99.200)
 * Acc@1 72.977 Acc@5 99.207
epoch 68, total time 598.69
Test: [0/750]	Time 0.950 (0.950)	Loss 1.3791 (1.3791)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.140 (0.139)	Loss 0.2110 (0.6839)	Acc@1 90.625 (84.499)	Acc@5 100.000 (92.915)
Test: [200/750]	Time 0.128 (0.132)	Loss 1.0242 (0.5130)	Acc@1 59.375 (86.567)	Acc@5 93.750 (95.569)
Test: [300/750]	Time 0.208 (0.131)	Loss 1.3199 (0.6964)	Acc@1 59.375 (77.024)	Acc@5 87.500 (95.027)
Test: [400/750]	Time 0.101 (0.130)	Loss 0.7575 (0.7753)	Acc@1 75.000 (73.363)	Acc@5 90.625 (94.545)
Test: [500/750]	Time 0.131 (0.129)	Loss 0.6736 (0.7917)	Acc@1 78.125 (73.216)	Acc@5 96.875 (93.775)
Test: [600/750]	Time 0.090 (0.128)	Loss 1.1043 (0.8517)	Acc@1 56.250 (71.152)	Acc@5 96.875 (93.350)
Test: [700/750]	Time 0.115 (0.127)	Loss 0.8507 (0.8883)	Acc@1 68.750 (69.419)	Acc@5 93.750 (93.358)
 * Acc@1 69.567 Acc@5 93.400
==> training...
Epoch: [69][0/875]	Time 2.329 (2.329)	Data 1.610 (1.610)	Loss 2.3688 (2.3688)	Loss@kd 2.1134 (2.1134)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [69][100/875]	Time 0.670 (0.706)	Data 0.007 (0.023)	Loss 2.2652 (2.2377)	Loss@kd 2.1659 (2.1839)	Acc@1 75.000 (73.855)	Acc@5 98.438 (99.165)
Epoch: [69][200/875]	Time 0.677 (0.696)	Data 0.007 (0.015)	Loss 1.9350 (2.2514)	Loss@kd 2.0905 (2.1896)	Acc@1 85.938 (73.601)	Acc@5 100.000 (99.137)
Epoch: [69][300/875]	Time 0.680 (0.693)	Data 0.007 (0.013)	Loss 2.2217 (2.2507)	Loss@kd 2.1845 (2.1948)	Acc@1 70.312 (73.500)	Acc@5 100.000 (99.123)
Epoch: [69][400/875]	Time 0.689 (0.692)	Data 0.007 (0.011)	Loss 2.1084 (2.2583)	Loss@kd 2.1544 (2.1970)	Acc@1 76.562 (73.332)	Acc@5 98.438 (99.112)
Epoch: [69][500/875]	Time 0.682 (0.690)	Data 0.007 (0.011)	Loss 2.2650 (2.2669)	Loss@kd 2.2057 (2.2085)	Acc@1 73.438 (73.238)	Acc@5 100.000 (99.158)
Epoch: [69][600/875]	Time 0.684 (0.689)	Data 0.007 (0.010)	Loss 2.4740 (2.2705)	Loss@kd 2.0784 (2.2078)	Acc@1 65.625 (73.094)	Acc@5 96.875 (99.168)
Epoch: [69][700/875]	Time 0.666 (0.689)	Data 0.007 (0.010)	Loss 2.2640 (2.2714)	Loss@kd 2.2292 (2.2044)	Acc@1 78.125 (73.003)	Acc@5 100.000 (99.142)
Epoch: [69][800/875]	Time 0.669 (0.689)	Data 0.008 (0.009)	Loss 2.0887 (2.2695)	Loss@kd 2.2533 (2.2037)	Acc@1 78.125 (73.016)	Acc@5 100.000 (99.161)
 * Acc@1 72.927 Acc@5 99.146
epoch 69, total time 602.79
Test: [0/750]	Time 1.061 (1.061)	Loss 0.9291 (0.9291)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.129 (0.133)	Loss 0.3585 (0.8957)	Acc@1 81.250 (79.827)	Acc@5 100.000 (90.192)
Test: [200/750]	Time 0.111 (0.129)	Loss 1.6229 (0.6828)	Acc@1 43.750 (81.157)	Acc@5 84.375 (93.905)
Test: [300/750]	Time 0.106 (0.128)	Loss 1.3574 (0.8628)	Acc@1 62.500 (71.501)	Acc@5 87.500 (93.449)
Test: [400/750]	Time 0.106 (0.127)	Loss 0.6935 (0.9044)	Acc@1 81.250 (69.147)	Acc@5 84.375 (93.243)
Test: [500/750]	Time 0.173 (0.127)	Loss 0.5889 (0.8715)	Acc@1 68.750 (70.465)	Acc@5 96.875 (93.151)
Test: [600/750]	Time 0.116 (0.126)	Loss 0.8607 (0.8749)	Acc@1 68.750 (70.476)	Acc@5 96.875 (93.157)
Test: [700/750]	Time 0.111 (0.126)	Loss 0.8931 (0.8715)	Acc@1 62.500 (70.221)	Acc@5 90.625 (93.509)
 * Acc@1 70.233 Acc@5 93.517
==> training...
Epoch: [70][0/875]	Time 2.423 (2.423)	Data 1.608 (1.608)	Loss 2.2583 (2.2583)	Loss@kd 2.1982 (2.1982)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [70][100/875]	Time 0.774 (0.706)	Data 0.007 (0.023)	Loss 2.2902 (2.2499)	Loss@kd 2.3483 (2.1881)	Acc@1 75.000 (73.963)	Acc@5 98.438 (99.103)
Epoch: [70][200/875]	Time 0.782 (0.697)	Data 0.007 (0.015)	Loss 2.3335 (2.2638)	Loss@kd 2.2387 (2.2001)	Acc@1 71.875 (73.671)	Acc@5 96.875 (99.114)
Epoch: [70][300/875]	Time 0.765 (0.693)	Data 0.007 (0.013)	Loss 2.3032 (2.2636)	Loss@kd 2.2888 (2.2003)	Acc@1 75.000 (73.438)	Acc@5 100.000 (99.133)
Epoch: [70][400/875]	Time 0.774 (0.691)	Data 0.007 (0.011)	Loss 2.0718 (2.2694)	Loss@kd 2.0472 (2.2126)	Acc@1 79.688 (73.492)	Acc@5 98.438 (99.139)
Epoch: [70][500/875]	Time 0.729 (0.689)	Data 0.007 (0.010)	Loss 2.2916 (2.2689)	Loss@kd 2.2500 (2.2122)	Acc@1 73.438 (73.360)	Acc@5 100.000 (99.086)
Epoch: [70][600/875]	Time 0.748 (0.689)	Data 0.008 (0.010)	Loss 2.1167 (2.2632)	Loss@kd 2.1621 (2.2062)	Acc@1 75.000 (73.336)	Acc@5 98.438 (99.093)
Epoch: [70][700/875]	Time 0.755 (0.689)	Data 0.007 (0.010)	Loss 2.2787 (2.2626)	Loss@kd 2.2079 (2.2037)	Acc@1 70.312 (73.342)	Acc@5 100.000 (99.097)
Epoch: [70][800/875]	Time 0.731 (0.688)	Data 0.006 (0.009)	Loss 2.2085 (2.2625)	Loss@kd 2.1960 (2.2020)	Acc@1 76.562 (73.332)	Acc@5 100.000 (99.091)
 * Acc@1 73.300 Acc@5 99.100
epoch 70, total time 602.63
Test: [0/750]	Time 0.921 (0.921)	Loss 2.5976 (2.5976)	Acc@1 56.250 (56.250)	Acc@5 75.000 (75.000)
Test: [100/750]	Time 0.121 (0.134)	Loss 0.4000 (1.2089)	Acc@1 81.250 (73.546)	Acc@5 100.000 (87.407)
Test: [200/750]	Time 0.122 (0.129)	Loss 1.3177 (0.8217)	Acc@1 50.000 (79.089)	Acc@5 90.625 (92.537)
Test: [300/750]	Time 0.122 (0.127)	Loss 1.2180 (0.9238)	Acc@1 53.125 (71.740)	Acc@5 90.625 (92.452)
Test: [400/750]	Time 0.121 (0.126)	Loss 0.6341 (0.9571)	Acc@1 84.375 (68.719)	Acc@5 90.625 (92.488)
Test: [500/750]	Time 0.102 (0.125)	Loss 0.6773 (0.9111)	Acc@1 75.000 (70.259)	Acc@5 100.000 (92.396)
Test: [600/750]	Time 0.127 (0.125)	Loss 0.6807 (0.9239)	Acc@1 75.000 (69.660)	Acc@5 100.000 (92.460)
Test: [700/750]	Time 0.124 (0.125)	Loss 1.3158 (0.9281)	Acc@1 56.250 (69.165)	Acc@5 84.375 (92.613)
 * Acc@1 68.762 Acc@5 92.396
==> training...
Epoch: [71][0/875]	Time 2.324 (2.324)	Data 1.611 (1.611)	Loss 2.2419 (2.2419)	Loss@kd 2.0441 (2.0441)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Epoch: [71][100/875]	Time 0.670 (0.701)	Data 0.007 (0.023)	Loss 2.2981 (2.2231)	Loss@kd 2.3043 (2.1819)	Acc@1 73.438 (73.979)	Acc@5 100.000 (99.397)
Epoch: [71][200/875]	Time 0.690 (0.693)	Data 0.007 (0.015)	Loss 2.2617 (2.2326)	Loss@kd 2.2157 (2.1819)	Acc@1 71.875 (73.609)	Acc@5 96.875 (99.246)
Epoch: [71][300/875]	Time 0.672 (0.691)	Data 0.008 (0.013)	Loss 2.3178 (2.2564)	Loss@kd 2.1926 (2.1978)	Acc@1 71.875 (73.349)	Acc@5 98.438 (99.175)
Epoch: [71][400/875]	Time 0.690 (0.689)	Data 0.008 (0.011)	Loss 2.2008 (2.2737)	Loss@kd 2.2142 (2.2108)	Acc@1 78.125 (73.219)	Acc@5 100.000 (99.092)
Epoch: [71][500/875]	Time 0.665 (0.688)	Data 0.007 (0.011)	Loss 2.2843 (2.2698)	Loss@kd 2.2361 (2.2059)	Acc@1 78.125 (73.288)	Acc@5 100.000 (99.074)
Epoch: [71][600/875]	Time 0.680 (0.688)	Data 0.007 (0.010)	Loss 2.3003 (2.2780)	Loss@kd 2.2749 (2.2106)	Acc@1 76.562 (73.042)	Acc@5 100.000 (99.061)
Epoch: [71][700/875]	Time 0.676 (0.688)	Data 0.007 (0.010)	Loss 2.3427 (2.2730)	Loss@kd 2.1689 (2.2059)	Acc@1 68.750 (73.012)	Acc@5 98.438 (99.075)
Epoch: [71][800/875]	Time 0.670 (0.688)	Data 0.007 (0.009)	Loss 2.2772 (2.2770)	Loss@kd 2.0923 (2.2126)	Acc@1 67.188 (73.043)	Acc@5 98.438 (99.091)
 * Acc@1 72.921 Acc@5 99.096
epoch 71, total time 602.35
Test: [0/750]	Time 1.071 (1.071)	Loss 1.3112 (1.3112)	Acc@1 50.000 (50.000)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.115 (0.134)	Loss 0.4001 (1.0674)	Acc@1 87.500 (64.851)	Acc@5 96.875 (91.986)
Test: [200/750]	Time 0.129 (0.128)	Loss 1.5021 (0.8001)	Acc@1 37.500 (73.181)	Acc@5 87.500 (94.558)
Test: [300/750]	Time 0.105 (0.126)	Loss 1.4650 (0.9284)	Acc@1 56.250 (65.926)	Acc@5 84.375 (94.373)
Test: [400/750]	Time 0.160 (0.124)	Loss 0.8673 (0.9519)	Acc@1 75.000 (65.095)	Acc@5 87.500 (94.046)
Test: [500/750]	Time 0.123 (0.123)	Loss 0.4307 (0.9132)	Acc@1 78.125 (67.153)	Acc@5 96.875 (93.388)
Test: [600/750]	Time 0.119 (0.123)	Loss 1.1184 (0.9139)	Acc@1 53.125 (67.351)	Acc@5 84.375 (93.246)
Test: [700/750]	Time 0.102 (0.123)	Loss 0.5697 (0.9134)	Acc@1 75.000 (67.078)	Acc@5 96.875 (93.389)
 * Acc@1 67.688 Acc@5 93.525
==> training...
Epoch: [72][0/875]	Time 2.238 (2.238)	Data 1.509 (1.509)	Loss 2.3818 (2.3818)	Loss@kd 2.2783 (2.2783)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [72][100/875]	Time 0.688 (0.704)	Data 0.007 (0.022)	Loss 2.3002 (2.2263)	Loss@kd 2.2031 (2.1945)	Acc@1 78.125 (74.660)	Acc@5 98.438 (99.180)
Epoch: [72][200/875]	Time 0.670 (0.697)	Data 0.006 (0.015)	Loss 2.1972 (2.2448)	Loss@kd 2.3351 (2.1945)	Acc@1 76.562 (73.406)	Acc@5 100.000 (99.137)
Epoch: [72][300/875]	Time 0.682 (0.696)	Data 0.007 (0.012)	Loss 2.3517 (2.2482)	Loss@kd 2.2011 (2.1940)	Acc@1 71.875 (73.412)	Acc@5 98.438 (99.086)
Epoch: [72][400/875]	Time 0.679 (0.695)	Data 0.008 (0.011)	Loss 2.1167 (2.2480)	Loss@kd 2.1466 (2.1934)	Acc@1 79.688 (73.434)	Acc@5 96.875 (99.061)
Epoch: [72][500/875]	Time 0.680 (0.695)	Data 0.007 (0.010)	Loss 2.2095 (2.2416)	Loss@kd 2.0718 (2.1902)	Acc@1 68.750 (73.593)	Acc@5 98.438 (99.111)
Epoch: [72][600/875]	Time 0.679 (0.694)	Data 0.007 (0.010)	Loss 3.3511 (2.2525)	Loss@kd 3.5394 (2.2016)	Acc@1 67.188 (73.500)	Acc@5 98.438 (99.129)
Epoch: [72][700/875]	Time 0.682 (0.695)	Data 0.007 (0.010)	Loss 2.3245 (2.2562)	Loss@kd 2.1928 (2.2038)	Acc@1 75.000 (73.451)	Acc@5 100.000 (99.137)
Epoch: [72][800/875]	Time 0.680 (0.694)	Data 0.007 (0.009)	Loss 2.2317 (2.2624)	Loss@kd 2.1520 (2.2088)	Acc@1 73.438 (73.336)	Acc@5 98.438 (99.142)
 * Acc@1 73.277 Acc@5 99.145
epoch 72, total time 607.80
Test: [0/750]	Time 1.039 (1.039)	Loss 1.0337 (1.0337)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.114 (0.144)	Loss 0.4945 (0.6722)	Acc@1 81.250 (82.704)	Acc@5 96.875 (94.214)
Test: [200/750]	Time 0.128 (0.137)	Loss 1.7832 (0.6483)	Acc@1 31.250 (79.804)	Acc@5 84.375 (95.476)
Test: [300/750]	Time 0.110 (0.134)	Loss 0.9923 (0.9326)	Acc@1 56.250 (67.265)	Acc@5 93.750 (92.649)
Test: [400/750]	Time 0.138 (0.131)	Loss 0.6358 (0.9067)	Acc@1 78.125 (67.986)	Acc@5 96.875 (93.337)
Test: [500/750]	Time 0.086 (0.130)	Loss 0.6920 (0.8800)	Acc@1 75.000 (69.773)	Acc@5 93.750 (93.108)
Test: [600/750]	Time 0.170 (0.128)	Loss 0.5558 (0.8915)	Acc@1 81.250 (69.592)	Acc@5 96.875 (92.835)
Test: [700/750]	Time 0.128 (0.127)	Loss 1.3016 (0.8921)	Acc@1 53.125 (69.272)	Acc@5 87.500 (93.023)
 * Acc@1 68.992 Acc@5 92.942
==> training...
Epoch: [73][0/875]	Time 2.357 (2.357)	Data 1.611 (1.611)	Loss 2.2078 (2.2078)	Loss@kd 2.1685 (2.1685)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [73][100/875]	Time 0.686 (0.708)	Data 0.007 (0.023)	Loss 2.2300 (2.2342)	Loss@kd 2.2760 (2.1890)	Acc@1 78.125 (74.180)	Acc@5 98.438 (99.319)
Epoch: [73][200/875]	Time 0.678 (0.701)	Data 0.007 (0.015)	Loss 2.1351 (2.2504)	Loss@kd 2.0930 (2.1924)	Acc@1 75.000 (73.406)	Acc@5 100.000 (99.207)
Epoch: [73][300/875]	Time 0.678 (0.698)	Data 0.007 (0.013)	Loss 2.4204 (2.2738)	Loss@kd 2.1815 (2.2197)	Acc@1 65.625 (73.334)	Acc@5 98.438 (99.185)
Epoch: [73][400/875]	Time 0.683 (0.696)	Data 0.007 (0.011)	Loss 2.1732 (2.2662)	Loss@kd 2.1028 (2.2110)	Acc@1 70.312 (73.363)	Acc@5 100.000 (99.162)
Epoch: [73][500/875]	Time 0.668 (0.695)	Data 0.007 (0.011)	Loss 2.4055 (2.2605)	Loss@kd 2.1529 (2.2118)	Acc@1 67.188 (73.559)	Acc@5 100.000 (99.186)
Epoch: [73][600/875]	Time 0.681 (0.695)	Data 0.007 (0.010)	Loss 2.1400 (2.2661)	Loss@kd 2.1483 (2.2133)	Acc@1 75.000 (73.451)	Acc@5 98.438 (99.145)
Epoch: [73][700/875]	Time 0.685 (0.694)	Data 0.008 (0.010)	Loss 2.2194 (2.2635)	Loss@kd 2.1752 (2.2059)	Acc@1 75.000 (73.384)	Acc@5 98.438 (99.122)
Epoch: [73][800/875]	Time 0.677 (0.693)	Data 0.008 (0.009)	Loss 2.3177 (2.2638)	Loss@kd 2.1995 (2.2047)	Acc@1 68.750 (73.332)	Acc@5 98.438 (99.132)
 * Acc@1 73.296 Acc@5 99.145
epoch 73, total time 607.20
Test: [0/750]	Time 1.027 (1.027)	Loss 0.3826 (0.3826)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.129 (0.147)	Loss 0.4976 (0.4755)	Acc@1 81.250 (86.665)	Acc@5 100.000 (95.545)
Test: [200/750]	Time 0.105 (0.139)	Loss 1.3054 (0.4870)	Acc@1 37.500 (84.562)	Acc@5 93.750 (96.331)
Test: [300/750]	Time 0.136 (0.137)	Loss 1.9198 (0.7527)	Acc@1 40.625 (73.983)	Acc@5 87.500 (94.518)
Test: [400/750]	Time 0.122 (0.136)	Loss 0.6867 (0.9085)	Acc@1 81.250 (68.236)	Acc@5 90.625 (92.675)
Test: [500/750]	Time 0.144 (0.135)	Loss 0.3134 (0.8547)	Acc@1 90.625 (70.528)	Acc@5 100.000 (92.808)
Test: [600/750]	Time 0.130 (0.134)	Loss 0.7766 (0.8385)	Acc@1 68.750 (71.033)	Acc@5 96.875 (93.230)
Test: [700/750]	Time 0.131 (0.134)	Loss 0.9590 (0.8502)	Acc@1 65.625 (70.529)	Acc@5 87.500 (93.398)
 * Acc@1 70.512 Acc@5 93.279
saving the best model!
==> training...
Epoch: [74][0/875]	Time 2.358 (2.358)	Data 1.623 (1.623)	Loss 2.7850 (2.7850)	Loss@kd 3.0554 (3.0554)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [74][100/875]	Time 0.672 (0.707)	Data 0.007 (0.023)	Loss 2.2531 (2.2610)	Loss@kd 2.2650 (2.2259)	Acc@1 79.688 (73.994)	Acc@5 100.000 (99.103)
Epoch: [74][200/875]	Time 0.670 (0.697)	Data 0.007 (0.015)	Loss 2.4185 (2.2367)	Loss@kd 2.2491 (2.1972)	Acc@1 71.875 (74.137)	Acc@5 98.438 (99.207)
Epoch: [74][300/875]	Time 0.665 (0.695)	Data 0.007 (0.013)	Loss 2.2245 (2.2349)	Loss@kd 2.3107 (2.1954)	Acc@1 76.562 (74.278)	Acc@5 100.000 (99.143)
Epoch: [74][400/875]	Time 0.674 (0.693)	Data 0.007 (0.011)	Loss 2.0692 (2.2346)	Loss@kd 2.1171 (2.1892)	Acc@1 75.000 (74.026)	Acc@5 98.438 (99.112)
Epoch: [74][500/875]	Time 0.686 (0.693)	Data 0.006 (0.011)	Loss 2.1602 (2.2358)	Loss@kd 2.0900 (2.1857)	Acc@1 76.562 (74.011)	Acc@5 98.438 (99.142)
Epoch: [74][600/875]	Time 0.677 (0.693)	Data 0.008 (0.010)	Loss 2.1697 (2.2342)	Loss@kd 2.1220 (2.1832)	Acc@1 71.875 (73.965)	Acc@5 100.000 (99.152)
Epoch: [74][700/875]	Time 0.690 (0.693)	Data 0.007 (0.010)	Loss 2.0628 (2.2429)	Loss@kd 2.0813 (2.1855)	Acc@1 76.562 (73.656)	Acc@5 100.000 (99.131)
Epoch: [74][800/875]	Time 0.689 (0.693)	Data 0.008 (0.010)	Loss 2.3472 (2.2440)	Loss@kd 2.0941 (2.1849)	Acc@1 68.750 (73.619)	Acc@5 95.312 (99.130)
 * Acc@1 73.591 Acc@5 99.134
epoch 74, total time 606.87
Test: [0/750]	Time 1.049 (1.049)	Loss 1.0409 (1.0409)	Acc@1 59.375 (59.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.124 (0.139)	Loss 0.4716 (1.0703)	Acc@1 78.125 (73.886)	Acc@5 100.000 (93.967)
Test: [200/750]	Time 0.101 (0.134)	Loss 1.7375 (0.8114)	Acc@1 31.250 (77.021)	Acc@5 81.250 (95.165)
Test: [300/750]	Time 0.191 (0.133)	Loss 1.1574 (0.9883)	Acc@1 68.750 (66.777)	Acc@5 93.750 (93.459)
Test: [400/750]	Time 0.123 (0.130)	Loss 0.7022 (0.9769)	Acc@1 75.000 (66.178)	Acc@5 90.625 (93.898)
Test: [500/750]	Time 0.126 (0.130)	Loss 0.8058 (0.9591)	Acc@1 65.625 (67.265)	Acc@5 96.875 (93.182)
Test: [600/750]	Time 0.124 (0.129)	Loss 0.9132 (0.9733)	Acc@1 71.875 (67.216)	Acc@5 90.625 (92.694)
Test: [700/750]	Time 0.134 (0.129)	Loss 0.8544 (0.9446)	Acc@1 65.625 (67.948)	Acc@5 93.750 (93.126)
 * Acc@1 68.363 Acc@5 93.217
==> training...
Epoch: [75][0/875]	Time 2.350 (2.350)	Data 1.606 (1.606)	Loss 2.3655 (2.3655)	Loss@kd 2.1120 (2.1120)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [75][100/875]	Time 0.667 (0.699)	Data 0.007 (0.023)	Loss 2.2880 (2.2419)	Loss@kd 2.1938 (2.1766)	Acc@1 68.750 (73.670)	Acc@5 100.000 (99.025)
Epoch: [75][200/875]	Time 0.696 (0.692)	Data 0.007 (0.015)	Loss 1.9492 (2.2341)	Loss@kd 2.0724 (2.1714)	Acc@1 76.562 (73.896)	Acc@5 100.000 (99.137)
Epoch: [75][300/875]	Time 0.675 (0.690)	Data 0.007 (0.013)	Loss 2.1678 (2.2277)	Loss@kd 2.1532 (2.1798)	Acc@1 73.438 (74.216)	Acc@5 100.000 (99.237)
Epoch: [75][400/875]	Time 0.676 (0.689)	Data 0.007 (0.011)	Loss 2.1322 (2.2240)	Loss@kd 2.1691 (2.1782)	Acc@1 78.125 (74.318)	Acc@5 100.000 (99.232)
Epoch: [75][500/875]	Time 0.682 (0.688)	Data 0.007 (0.011)	Loss 2.1823 (2.2288)	Loss@kd 2.2000 (2.1779)	Acc@1 78.125 (74.033)	Acc@5 100.000 (99.220)
Epoch: [75][600/875]	Time 0.688 (0.688)	Data 0.008 (0.010)	Loss 2.1296 (2.2249)	Loss@kd 2.0556 (2.1734)	Acc@1 71.875 (74.020)	Acc@5 98.438 (99.210)
Epoch: [75][700/875]	Time 0.753 (0.687)	Data 0.008 (0.010)	Loss 2.2498 (2.2347)	Loss@kd 2.1864 (2.1826)	Acc@1 68.750 (73.932)	Acc@5 100.000 (99.213)
Epoch: [75][800/875]	Time 0.686 (0.687)	Data 0.008 (0.009)	Loss 2.2213 (2.2333)	Loss@kd 2.0574 (2.1798)	Acc@1 68.750 (73.896)	Acc@5 100.000 (99.210)
 * Acc@1 73.864 Acc@5 99.221
epoch 75, total time 601.80
Test: [0/750]	Time 1.066 (1.066)	Loss 0.6204 (0.6204)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.124 (0.139)	Loss 0.7033 (0.7202)	Acc@1 75.000 (84.375)	Acc@5 93.750 (92.574)
Test: [200/750]	Time 0.092 (0.132)	Loss 1.3949 (0.6288)	Acc@1 46.875 (82.307)	Acc@5 81.250 (94.947)
Test: [300/750]	Time 0.121 (0.128)	Loss 1.6039 (0.8331)	Acc@1 46.875 (72.591)	Acc@5 84.375 (94.103)
Test: [400/750]	Time 0.109 (0.127)	Loss 0.6458 (0.9577)	Acc@1 78.125 (67.137)	Acc@5 90.625 (93.064)
Test: [500/750]	Time 0.120 (0.126)	Loss 0.8098 (0.9232)	Acc@1 65.625 (68.869)	Acc@5 96.875 (92.783)
Test: [600/750]	Time 0.116 (0.126)	Loss 0.7523 (0.9400)	Acc@1 78.125 (68.490)	Acc@5 96.875 (92.492)
Test: [700/750]	Time 0.186 (0.125)	Loss 0.6673 (0.9046)	Acc@1 75.000 (69.535)	Acc@5 93.750 (92.961)
 * Acc@1 70.171 Acc@5 93.158
==> training...
Epoch: [76][0/875]	Time 2.364 (2.364)	Data 1.633 (1.633)	Loss 2.0332 (2.0332)	Loss@kd 2.0273 (2.0273)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [76][100/875]	Time 0.669 (0.704)	Data 0.005 (0.023)	Loss 2.3586 (2.1193)	Loss@kd 2.1432 (2.0952)	Acc@1 70.312 (75.959)	Acc@5 96.875 (99.072)
Epoch: [76][200/875]	Time 0.751 (0.696)	Data 0.007 (0.015)	Loss 2.3515 (2.0962)	Loss@kd 2.1047 (2.0874)	Acc@1 64.062 (76.493)	Acc@5 98.438 (99.238)
Epoch: [76][300/875]	Time 0.672 (0.693)	Data 0.007 (0.013)	Loss 1.8599 (2.0715)	Loss@kd 1.8760 (2.0731)	Acc@1 82.812 (77.102)	Acc@5 100.000 (99.336)
Epoch: [76][400/875]	Time 0.678 (0.691)	Data 0.007 (0.011)	Loss 2.0507 (2.0661)	Loss@kd 2.1416 (2.0696)	Acc@1 76.562 (77.264)	Acc@5 100.000 (99.380)
Epoch: [76][500/875]	Time 0.668 (0.691)	Data 0.007 (0.011)	Loss 1.9212 (2.0616)	Loss@kd 1.9547 (2.0644)	Acc@1 76.562 (77.311)	Acc@5 100.000 (99.361)
Epoch: [76][600/875]	Time 0.678 (0.691)	Data 0.008 (0.010)	Loss 2.8040 (2.0571)	Loss@kd 3.0272 (2.0641)	Acc@1 78.125 (77.545)	Acc@5 100.000 (99.366)
Epoch: [76][700/875]	Time 0.690 (0.690)	Data 0.014 (0.010)	Loss 2.0113 (2.0530)	Loss@kd 1.9018 (2.0627)	Acc@1 79.688 (77.755)	Acc@5 96.875 (99.378)
Epoch: [76][800/875]	Time 0.680 (0.690)	Data 0.007 (0.009)	Loss 2.1181 (2.0485)	Loss@kd 2.0224 (2.0607)	Acc@1 73.438 (77.834)	Acc@5 100.000 (99.403)
 * Acc@1 77.900 Acc@5 99.393
epoch 76, total time 604.67
Test: [0/750]	Time 1.045 (1.045)	Loss 1.1855 (1.1855)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.118 (0.141)	Loss 0.4737 (0.8658)	Acc@1 78.125 (80.662)	Acc@5 96.875 (93.379)
Test: [200/750]	Time 0.123 (0.133)	Loss 1.4168 (0.6914)	Acc@1 40.625 (80.815)	Acc@5 87.500 (95.320)
Test: [300/750]	Time 0.133 (0.130)	Loss 1.1599 (0.8583)	Acc@1 65.625 (71.833)	Acc@5 90.625 (93.968)
Test: [400/750]	Time 0.107 (0.128)	Loss 0.5462 (0.8823)	Acc@1 81.250 (70.145)	Acc@5 93.750 (93.968)
Test: [500/750]	Time 0.117 (0.127)	Loss 0.4696 (0.8290)	Acc@1 84.375 (72.386)	Acc@5 100.000 (94.074)
Test: [600/750]	Time 0.124 (0.127)	Loss 0.7692 (0.8268)	Acc@1 75.000 (72.525)	Acc@5 93.750 (94.057)
Test: [700/750]	Time 0.135 (0.127)	Loss 0.7598 (0.8141)	Acc@1 62.500 (72.633)	Acc@5 90.625 (94.285)
 * Acc@1 72.842 Acc@5 94.321
saving the best model!
==> training...
Epoch: [77][0/875]	Time 2.377 (2.377)	Data 1.635 (1.635)	Loss 2.0337 (2.0337)	Loss@kd 1.9810 (1.9810)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [77][100/875]	Time 0.684 (0.708)	Data 0.007 (0.023)	Loss 1.9136 (2.0195)	Loss@kd 2.0005 (2.0580)	Acc@1 81.250 (78.976)	Acc@5 100.000 (99.567)
Epoch: [77][200/875]	Time 0.673 (0.698)	Data 0.007 (0.015)	Loss 1.8492 (2.0145)	Loss@kd 1.9818 (2.0509)	Acc@1 89.062 (79.089)	Acc@5 98.438 (99.502)
Epoch: [77][300/875]	Time 0.680 (0.695)	Data 0.008 (0.013)	Loss 2.0516 (2.0265)	Loss@kd 2.0214 (2.0630)	Acc@1 76.562 (78.883)	Acc@5 100.000 (99.476)
Epoch: [77][400/875]	Time 0.674 (0.691)	Data 0.006 (0.011)	Loss 1.9962 (2.0212)	Loss@kd 2.0190 (2.0516)	Acc@1 76.562 (78.912)	Acc@5 100.000 (99.454)
Epoch: [77][500/875]	Time 0.670 (0.687)	Data 0.007 (0.011)	Loss 1.9863 (2.0143)	Loss@kd 2.0356 (2.0458)	Acc@1 81.250 (78.961)	Acc@5 100.000 (99.489)
Epoch: [77][600/875]	Time 0.755 (0.686)	Data 0.007 (0.010)	Loss 1.9705 (2.0123)	Loss@kd 1.9502 (2.0403)	Acc@1 75.000 (78.837)	Acc@5 98.438 (99.496)
Epoch: [77][700/875]	Time 0.689 (0.684)	Data 0.007 (0.010)	Loss 2.2153 (2.0091)	Loss@kd 2.0554 (2.0350)	Acc@1 71.875 (78.776)	Acc@5 100.000 (99.476)
Epoch: [77][800/875]	Time 0.685 (0.683)	Data 0.012 (0.009)	Loss 1.9544 (2.0071)	Loss@kd 1.9608 (2.0334)	Acc@1 81.250 (78.773)	Acc@5 98.438 (99.466)
 * Acc@1 78.761 Acc@5 99.461
epoch 77, total time 597.95
Test: [0/750]	Time 1.026 (1.026)	Loss 0.5858 (0.5858)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.120 (0.136)	Loss 0.4796 (0.7182)	Acc@1 78.125 (84.189)	Acc@5 96.875 (94.152)
Test: [200/750]	Time 0.123 (0.131)	Loss 1.3663 (0.6277)	Acc@1 50.000 (82.276)	Acc@5 87.500 (95.709)
Test: [300/750]	Time 0.135 (0.130)	Loss 1.3828 (0.8069)	Acc@1 62.500 (73.204)	Acc@5 90.625 (94.581)
Test: [400/750]	Time 0.118 (0.129)	Loss 0.5533 (0.8662)	Acc@1 84.375 (70.277)	Acc@5 90.625 (94.218)
Test: [500/750]	Time 0.111 (0.129)	Loss 0.4978 (0.8198)	Acc@1 75.000 (72.287)	Acc@5 100.000 (94.155)
Test: [600/750]	Time 0.128 (0.128)	Loss 0.6643 (0.8156)	Acc@1 75.000 (72.499)	Acc@5 96.875 (94.119)
Test: [700/750]	Time 0.188 (0.127)	Loss 0.6449 (0.7967)	Acc@1 65.625 (72.914)	Acc@5 96.875 (94.401)
 * Acc@1 73.325 Acc@5 94.483
saving the best model!
==> training...
Epoch: [78][0/875]	Time 2.325 (2.325)	Data 1.601 (1.601)	Loss 1.9796 (1.9796)	Loss@kd 2.0481 (2.0481)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [78][100/875]	Time 0.666 (0.701)	Data 0.006 (0.023)	Loss 2.2047 (1.9853)	Loss@kd 2.0125 (2.0271)	Acc@1 78.125 (79.301)	Acc@5 100.000 (99.582)
Epoch: [78][200/875]	Time 0.670 (0.693)	Data 0.007 (0.015)	Loss 1.9645 (1.9911)	Loss@kd 1.9593 (2.0191)	Acc@1 82.812 (78.887)	Acc@5 100.000 (99.495)
Epoch: [78][300/875]	Time 0.671 (0.690)	Data 0.007 (0.013)	Loss 1.9884 (1.9953)	Loss@kd 2.0284 (2.0239)	Acc@1 81.250 (79.049)	Acc@5 98.438 (99.471)
Epoch: [78][400/875]	Time 0.670 (0.687)	Data 0.007 (0.011)	Loss 2.0453 (1.9960)	Loss@kd 1.9198 (2.0248)	Acc@1 78.125 (79.087)	Acc@5 98.438 (99.454)
Epoch: [78][500/875]	Time 0.672 (0.685)	Data 0.008 (0.010)	Loss 1.9221 (1.9938)	Loss@kd 2.0090 (2.0259)	Acc@1 78.125 (79.207)	Acc@5 100.000 (99.439)
Epoch: [78][600/875]	Time 0.737 (0.684)	Data 0.007 (0.010)	Loss 2.1592 (1.9911)	Loss@kd 2.1374 (2.0247)	Acc@1 75.000 (79.222)	Acc@5 96.875 (99.464)
Epoch: [78][700/875]	Time 0.680 (0.683)	Data 0.007 (0.010)	Loss 1.8439 (1.9924)	Loss@kd 1.9190 (2.0230)	Acc@1 85.938 (79.115)	Acc@5 100.000 (99.447)
Epoch: [78][800/875]	Time 0.653 (0.682)	Data 0.010 (0.009)	Loss 2.1957 (1.9917)	Loss@kd 2.1775 (2.0239)	Acc@1 73.438 (79.122)	Acc@5 100.000 (99.477)
 * Acc@1 79.148 Acc@5 99.493
epoch 78, total time 597.66
Test: [0/750]	Time 1.043 (1.043)	Loss 0.8739 (0.8739)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.142 (0.133)	Loss 0.4032 (0.7604)	Acc@1 81.250 (83.416)	Acc@5 96.875 (94.183)
Test: [200/750]	Time 0.123 (0.129)	Loss 1.3918 (0.6242)	Acc@1 53.125 (83.147)	Acc@5 84.375 (95.678)
Test: [300/750]	Time 0.118 (0.126)	Loss 1.1982 (0.8105)	Acc@1 56.250 (73.692)	Acc@5 90.625 (94.248)
Test: [400/750]	Time 0.187 (0.126)	Loss 0.5492 (0.8611)	Acc@1 84.375 (70.979)	Acc@5 93.750 (94.093)
Test: [500/750]	Time 0.118 (0.125)	Loss 0.5203 (0.8221)	Acc@1 78.125 (72.730)	Acc@5 96.875 (93.993)
Test: [600/750]	Time 0.101 (0.125)	Loss 0.7170 (0.8284)	Acc@1 75.000 (72.499)	Acc@5 90.625 (93.901)
Test: [700/750]	Time 0.105 (0.124)	Loss 0.7336 (0.8139)	Acc@1 65.625 (72.619)	Acc@5 96.875 (94.191)
 * Acc@1 73.037 Acc@5 94.283
==> training...
Epoch: [79][0/875]	Time 2.323 (2.323)	Data 1.615 (1.615)	Loss 2.0185 (2.0185)	Loss@kd 2.1593 (2.1593)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [79][100/875]	Time 0.687 (0.705)	Data 0.007 (0.023)	Loss 1.8814 (1.9494)	Loss@kd 1.9272 (2.0180)	Acc@1 78.125 (81.312)	Acc@5 100.000 (99.551)
Epoch: [79][200/875]	Time 0.679 (0.696)	Data 0.008 (0.015)	Loss 1.8590 (1.9591)	Loss@kd 1.8815 (2.0200)	Acc@1 78.125 (80.589)	Acc@5 100.000 (99.534)
Epoch: [79][300/875]	Time 0.669 (0.693)	Data 0.007 (0.013)	Loss 1.9185 (1.9657)	Loss@kd 2.0218 (2.0209)	Acc@1 84.375 (80.279)	Acc@5 100.000 (99.595)
Epoch: [79][400/875]	Time 0.701 (0.692)	Data 0.008 (0.011)	Loss 1.7757 (1.9673)	Loss@kd 1.9793 (2.0193)	Acc@1 89.062 (80.128)	Acc@5 100.000 (99.583)
Epoch: [79][500/875]	Time 0.683 (0.692)	Data 0.007 (0.011)	Loss 2.0538 (1.9762)	Loss@kd 1.9839 (2.0241)	Acc@1 76.562 (79.840)	Acc@5 100.000 (99.551)
Epoch: [79][600/875]	Time 0.661 (0.691)	Data 0.007 (0.010)	Loss 1.9470 (1.9764)	Loss@kd 1.9713 (2.0214)	Acc@1 81.250 (79.768)	Acc@5 100.000 (99.540)
Epoch: [79][700/875]	Time 0.695 (0.691)	Data 0.008 (0.010)	Loss 2.1042 (1.9743)	Loss@kd 2.1698 (2.0179)	Acc@1 81.250 (79.766)	Acc@5 100.000 (99.530)
Epoch: [79][800/875]	Time 0.688 (0.691)	Data 0.007 (0.009)	Loss 1.7963 (1.9750)	Loss@kd 2.0499 (2.0168)	Acc@1 87.500 (79.715)	Acc@5 100.000 (99.526)
 * Acc@1 79.679 Acc@5 99.523
epoch 79, total time 605.28
Test: [0/750]	Time 1.027 (1.027)	Loss 1.5525 (1.5525)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.131 (0.148)	Loss 0.4687 (0.9729)	Acc@1 78.125 (77.259)	Acc@5 93.750 (92.017)
Test: [200/750]	Time 0.122 (0.143)	Loss 1.3903 (0.7606)	Acc@1 53.125 (79.120)	Acc@5 87.500 (94.450)
Test: [300/750]	Time 0.139 (0.139)	Loss 1.1369 (0.9046)	Acc@1 65.625 (70.691)	Acc@5 93.750 (93.594)
Test: [400/750]	Time 0.135 (0.137)	Loss 0.5847 (0.9098)	Acc@1 81.250 (69.615)	Acc@5 90.625 (93.906)
Test: [500/750]	Time 0.133 (0.135)	Loss 0.5265 (0.8669)	Acc@1 75.000 (71.526)	Acc@5 96.875 (93.900)
Test: [600/750]	Time 0.136 (0.135)	Loss 0.6658 (0.8671)	Acc@1 75.000 (71.547)	Acc@5 96.875 (93.812)
Test: [700/750]	Time 0.123 (0.134)	Loss 0.6602 (0.8477)	Acc@1 65.625 (71.759)	Acc@5 93.750 (94.102)
 * Acc@1 72.083 Acc@5 94.158
==> training...
Epoch: [80][0/875]	Time 2.341 (2.341)	Data 1.621 (1.621)	Loss 1.8851 (1.8851)	Loss@kd 1.9550 (1.9550)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [80][100/875]	Time 0.684 (0.705)	Data 0.007 (0.023)	Loss 2.0441 (1.9649)	Loss@kd 1.9314 (2.0077)	Acc@1 71.875 (79.780)	Acc@5 100.000 (99.474)
Epoch: [80][200/875]	Time 0.681 (0.697)	Data 0.008 (0.016)	Loss 1.9995 (1.9561)	Loss@kd 2.0896 (2.0098)	Acc@1 82.812 (80.294)	Acc@5 100.000 (99.549)
Epoch: [80][300/875]	Time 0.668 (0.694)	Data 0.007 (0.013)	Loss 2.3089 (1.9621)	Loss@kd 2.4728 (2.0168)	Acc@1 76.562 (80.082)	Acc@5 100.000 (99.559)
Epoch: [80][400/875]	Time 0.686 (0.693)	Data 0.007 (0.012)	Loss 2.1082 (1.9749)	Loss@kd 2.0513 (2.0282)	Acc@1 75.000 (79.855)	Acc@5 98.438 (99.536)
Epoch: [80][500/875]	Time 0.789 (0.693)	Data 0.008 (0.011)	Loss 1.8733 (1.9732)	Loss@kd 1.9373 (2.0237)	Acc@1 81.250 (79.946)	Acc@5 100.000 (99.532)
Epoch: [80][600/875]	Time 0.681 (0.692)	Data 0.007 (0.010)	Loss 1.9666 (1.9698)	Loss@kd 1.9241 (2.0186)	Acc@1 76.562 (79.940)	Acc@5 98.438 (99.524)
Epoch: [80][700/875]	Time 0.691 (0.692)	Data 0.007 (0.010)	Loss 2.0086 (1.9717)	Loss@kd 1.9699 (2.0190)	Acc@1 81.250 (79.873)	Acc@5 98.438 (99.530)
Epoch: [80][800/875]	Time 0.689 (0.691)	Data 0.008 (0.010)	Loss 1.8965 (1.9711)	Loss@kd 1.8931 (2.0167)	Acc@1 78.125 (79.766)	Acc@5 100.000 (99.547)
 * Acc@1 79.657 Acc@5 99.548
epoch 80, total time 605.49
Test: [0/750]	Time 1.052 (1.052)	Loss 0.5373 (0.5373)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.113 (0.148)	Loss 0.3573 (0.7199)	Acc@1 84.375 (84.901)	Acc@5 100.000 (94.400)
Test: [200/750]	Time 0.114 (0.135)	Loss 1.4030 (0.5881)	Acc@1 43.750 (84.437)	Acc@5 87.500 (95.927)
Test: [300/750]	Time 0.114 (0.130)	Loss 1.1225 (0.7753)	Acc@1 68.750 (74.367)	Acc@5 90.625 (94.913)
Test: [400/750]	Time 0.201 (0.128)	Loss 0.5585 (0.7931)	Acc@1 84.375 (73.067)	Acc@5 90.625 (95.036)
Test: [500/750]	Time 0.123 (0.128)	Loss 0.5493 (0.7681)	Acc@1 78.125 (74.339)	Acc@5 96.875 (94.829)
Test: [600/750]	Time 0.106 (0.127)	Loss 0.8077 (0.7877)	Acc@1 75.000 (73.799)	Acc@5 93.750 (94.592)
Test: [700/750]	Time 0.193 (0.126)	Loss 0.9868 (0.7957)	Acc@1 59.375 (73.003)	Acc@5 87.500 (94.646)
 * Acc@1 72.883 Acc@5 94.583
==> Saving...
==> training...
Epoch: [81][0/875]	Time 2.326 (2.326)	Data 1.606 (1.606)	Loss 1.8433 (1.8433)	Loss@kd 1.8839 (1.8839)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [81][100/875]	Time 0.679 (0.708)	Data 0.007 (0.023)	Loss 1.8976 (1.9816)	Loss@kd 1.8786 (2.0288)	Acc@1 73.438 (79.641)	Acc@5 100.000 (99.443)
Epoch: [81][200/875]	Time 0.681 (0.698)	Data 0.007 (0.015)	Loss 2.1383 (1.9732)	Loss@kd 2.0636 (2.0067)	Acc@1 81.250 (79.540)	Acc@5 98.438 (99.448)
Epoch: [81][300/875]	Time 0.676 (0.695)	Data 0.007 (0.013)	Loss 1.9017 (1.9670)	Loss@kd 1.9924 (2.0088)	Acc@1 85.938 (79.760)	Acc@5 100.000 (99.450)
Epoch: [81][400/875]	Time 0.675 (0.693)	Data 0.007 (0.011)	Loss 1.9030 (1.9692)	Loss@kd 2.0742 (2.0118)	Acc@1 85.938 (79.832)	Acc@5 98.438 (99.458)
Epoch: [81][500/875]	Time 0.689 (0.692)	Data 0.007 (0.011)	Loss 2.0031 (1.9713)	Loss@kd 1.9963 (2.0152)	Acc@1 79.688 (79.868)	Acc@5 98.438 (99.454)
Epoch: [81][600/875]	Time 0.774 (0.691)	Data 0.008 (0.010)	Loss 1.9780 (1.9680)	Loss@kd 2.0154 (2.0125)	Acc@1 76.562 (79.856)	Acc@5 100.000 (99.459)
Epoch: [81][700/875]	Time 0.680 (0.691)	Data 0.007 (0.010)	Loss 1.9375 (1.9666)	Loss@kd 1.9071 (2.0124)	Acc@1 75.000 (79.926)	Acc@5 98.438 (99.481)
Epoch: [81][800/875]	Time 0.674 (0.691)	Data 0.008 (0.010)	Loss 1.7689 (1.9637)	Loss@kd 1.9998 (2.0097)	Acc@1 89.062 (79.900)	Acc@5 100.000 (99.483)
 * Acc@1 79.796 Acc@5 99.486
epoch 81, total time 604.58
Test: [0/750]	Time 1.027 (1.027)	Loss 0.7621 (0.7621)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.121 (0.136)	Loss 0.4614 (0.8127)	Acc@1 78.125 (80.538)	Acc@5 96.875 (94.245)
Test: [200/750]	Time 0.179 (0.129)	Loss 1.4671 (0.6493)	Acc@1 40.625 (81.483)	Acc@5 84.375 (95.833)
Test: [300/750]	Time 0.116 (0.130)	Loss 1.1368 (0.8086)	Acc@1 62.500 (73.630)	Acc@5 90.625 (94.736)
Test: [400/750]	Time 0.118 (0.130)	Loss 0.5871 (0.8494)	Acc@1 81.250 (71.275)	Acc@5 93.750 (94.560)
Test: [500/750]	Time 0.136 (0.130)	Loss 0.6122 (0.8249)	Acc@1 71.875 (72.530)	Acc@5 93.750 (94.349)
Test: [600/750]	Time 0.114 (0.130)	Loss 0.7194 (0.8361)	Acc@1 75.000 (72.156)	Acc@5 96.875 (94.124)
Test: [700/750]	Time 0.102 (0.130)	Loss 0.8034 (0.8228)	Acc@1 65.625 (72.285)	Acc@5 87.500 (94.272)
 * Acc@1 72.467 Acc@5 94.262
==> training...
Epoch: [82][0/875]	Time 2.404 (2.404)	Data 1.723 (1.723)	Loss 1.9486 (1.9486)	Loss@kd 1.9877 (1.9877)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [82][100/875]	Time 0.674 (0.704)	Data 0.007 (0.024)	Loss 1.9186 (1.9534)	Loss@kd 1.9872 (2.0047)	Acc@1 78.125 (79.471)	Acc@5 100.000 (99.443)
Epoch: [82][200/875]	Time 0.683 (0.697)	Data 0.008 (0.016)	Loss 2.0601 (1.9588)	Loss@kd 2.0210 (2.0069)	Acc@1 76.562 (79.703)	Acc@5 98.438 (99.534)
Epoch: [82][300/875]	Time 0.775 (0.694)	Data 0.007 (0.013)	Loss 1.6872 (1.9568)	Loss@kd 2.0011 (2.0089)	Acc@1 92.188 (79.890)	Acc@5 100.000 (99.528)
Epoch: [82][400/875]	Time 0.670 (0.693)	Data 0.007 (0.012)	Loss 1.8479 (1.9524)	Loss@kd 1.9958 (2.0062)	Acc@1 85.938 (79.945)	Acc@5 100.000 (99.552)
Epoch: [82][500/875]	Time 0.670 (0.692)	Data 0.008 (0.011)	Loss 1.8111 (1.9492)	Loss@kd 1.9950 (2.0053)	Acc@1 82.812 (80.177)	Acc@5 100.000 (99.542)
Epoch: [82][600/875]	Time 0.699 (0.691)	Data 0.007 (0.010)	Loss 1.8632 (1.9492)	Loss@kd 1.9257 (2.0033)	Acc@1 81.250 (80.103)	Acc@5 100.000 (99.532)
Epoch: [82][700/875]	Time 0.683 (0.691)	Data 0.008 (0.010)	Loss 2.1316 (1.9549)	Loss@kd 2.1666 (2.0071)	Acc@1 78.125 (80.031)	Acc@5 98.438 (99.516)
Epoch: [82][800/875]	Time 0.686 (0.690)	Data 0.007 (0.010)	Loss 1.8706 (1.9553)	Loss@kd 2.0876 (2.0049)	Acc@1 89.062 (79.974)	Acc@5 100.000 (99.508)
 * Acc@1 79.891 Acc@5 99.493
epoch 82, total time 604.56
Test: [0/750]	Time 1.067 (1.067)	Loss 0.9700 (0.9700)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.130 (0.137)	Loss 0.3972 (0.7279)	Acc@1 81.250 (83.663)	Acc@5 96.875 (93.812)
Test: [200/750]	Time 0.130 (0.130)	Loss 1.3155 (0.5981)	Acc@1 50.000 (83.458)	Acc@5 87.500 (95.756)
Test: [300/750]	Time 0.106 (0.127)	Loss 1.2105 (0.7638)	Acc@1 59.375 (74.533)	Acc@5 90.625 (95.141)
Test: [400/750]	Time 0.114 (0.125)	Loss 0.5706 (0.8106)	Acc@1 78.125 (72.132)	Acc@5 87.500 (94.981)
Test: [500/750]	Time 0.108 (0.124)	Loss 0.4837 (0.7833)	Acc@1 78.125 (73.603)	Acc@5 93.750 (94.736)
Test: [600/750]	Time 0.094 (0.124)	Loss 0.7127 (0.7916)	Acc@1 75.000 (73.336)	Acc@5 96.875 (94.639)
Test: [700/750]	Time 0.189 (0.124)	Loss 0.7976 (0.7882)	Acc@1 62.500 (73.123)	Acc@5 93.750 (94.766)
 * Acc@1 73.350 Acc@5 94.737
saving the best model!
==> training...
Epoch: [83][0/875]	Time 2.407 (2.407)	Data 1.710 (1.710)	Loss 1.9443 (1.9443)	Loss@kd 1.9285 (1.9285)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [83][100/875]	Time 0.671 (0.707)	Data 0.007 (0.024)	Loss 1.9589 (1.9433)	Loss@kd 2.0055 (2.0102)	Acc@1 84.375 (81.033)	Acc@5 100.000 (99.459)
Epoch: [83][200/875]	Time 0.682 (0.696)	Data 0.010 (0.016)	Loss 1.7921 (1.9385)	Loss@kd 1.9057 (2.0052)	Acc@1 76.562 (80.885)	Acc@5 100.000 (99.487)
Epoch: [83][300/875]	Time 0.668 (0.695)	Data 0.007 (0.013)	Loss 1.9281 (1.9385)	Loss@kd 2.0464 (2.0045)	Acc@1 82.812 (80.944)	Acc@5 100.000 (99.528)
Epoch: [83][400/875]	Time 0.671 (0.694)	Data 0.007 (0.012)	Loss 1.8298 (1.9416)	Loss@kd 1.9530 (2.0022)	Acc@1 84.375 (80.666)	Acc@5 100.000 (99.536)
Epoch: [83][500/875]	Time 0.685 (0.694)	Data 0.007 (0.011)	Loss 1.8609 (1.9442)	Loss@kd 1.9032 (2.0036)	Acc@1 81.250 (80.576)	Acc@5 100.000 (99.532)
Epoch: [83][600/875]	Time 0.674 (0.694)	Data 0.007 (0.010)	Loss 2.0344 (1.9435)	Loss@kd 2.1415 (2.0015)	Acc@1 76.562 (80.506)	Acc@5 100.000 (99.511)
Epoch: [83][700/875]	Time 0.689 (0.694)	Data 0.007 (0.010)	Loss 2.0744 (1.9461)	Loss@kd 1.9697 (2.0020)	Acc@1 67.188 (80.387)	Acc@5 98.438 (99.503)
Epoch: [83][800/875]	Time 0.686 (0.694)	Data 0.007 (0.010)	Loss 1.8716 (1.9502)	Loss@kd 1.9430 (2.0041)	Acc@1 82.812 (80.275)	Acc@5 100.000 (99.503)
 * Acc@1 80.273 Acc@5 99.489
epoch 83, total time 607.67
Test: [0/750]	Time 1.033 (1.033)	Loss 0.5686 (0.5686)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.192 (0.137)	Loss 0.3591 (0.7652)	Acc@1 84.375 (83.880)	Acc@5 100.000 (94.585)
Test: [200/750]	Time 0.101 (0.130)	Loss 1.3312 (0.6223)	Acc@1 46.875 (83.504)	Acc@5 90.625 (96.004)
Test: [300/750]	Time 0.108 (0.127)	Loss 1.2284 (0.7951)	Acc@1 56.250 (74.252)	Acc@5 90.625 (94.965)
Test: [400/750]	Time 0.130 (0.127)	Loss 0.5931 (0.8299)	Acc@1 81.250 (72.397)	Acc@5 93.750 (94.802)
Test: [500/750]	Time 0.132 (0.127)	Loss 0.4486 (0.7976)	Acc@1 75.000 (73.790)	Acc@5 96.875 (94.580)
Test: [600/750]	Time 0.123 (0.126)	Loss 0.8145 (0.8006)	Acc@1 71.875 (73.560)	Acc@5 90.625 (94.488)
Test: [700/750]	Time 0.114 (0.126)	Loss 0.8298 (0.8008)	Acc@1 62.500 (73.101)	Acc@5 93.750 (94.570)
 * Acc@1 73.192 Acc@5 94.512
==> training...
Epoch: [84][0/875]	Time 2.346 (2.346)	Data 1.611 (1.611)	Loss 1.9645 (1.9645)	Loss@kd 2.2099 (2.2099)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [84][100/875]	Time 0.683 (0.700)	Data 0.007 (0.023)	Loss 1.8113 (1.9290)	Loss@kd 1.9843 (1.9921)	Acc@1 82.812 (80.430)	Acc@5 100.000 (99.536)
Epoch: [84][200/875]	Time 0.661 (0.689)	Data 0.007 (0.015)	Loss 1.7934 (1.9306)	Loss@kd 1.9361 (1.9978)	Acc@1 84.375 (80.737)	Acc@5 98.438 (99.596)
Epoch: [84][300/875]	Time 0.657 (0.686)	Data 0.007 (0.013)	Loss 1.7609 (1.9268)	Loss@kd 1.9473 (1.9963)	Acc@1 84.375 (80.913)	Acc@5 100.000 (99.574)
Epoch: [84][400/875]	Time 0.653 (0.683)	Data 0.007 (0.011)	Loss 2.0761 (1.9328)	Loss@kd 2.0568 (2.0007)	Acc@1 82.812 (80.806)	Acc@5 100.000 (99.583)
Epoch: [84][500/875]	Time 0.656 (0.682)	Data 0.007 (0.011)	Loss 2.1861 (1.9371)	Loss@kd 2.0762 (2.0024)	Acc@1 73.438 (80.642)	Acc@5 100.000 (99.542)
Epoch: [84][600/875]	Time 0.759 (0.681)	Data 0.007 (0.010)	Loss 2.0675 (1.9395)	Loss@kd 2.1454 (2.0000)	Acc@1 81.250 (80.421)	Acc@5 100.000 (99.527)
Epoch: [84][700/875]	Time 0.679 (0.680)	Data 0.007 (0.010)	Loss 2.0125 (1.9402)	Loss@kd 2.0783 (1.9992)	Acc@1 73.438 (80.336)	Acc@5 100.000 (99.541)
Epoch: [84][800/875]	Time 0.671 (0.679)	Data 0.007 (0.009)	Loss 1.9378 (1.9402)	Loss@kd 1.8621 (1.9985)	Acc@1 76.562 (80.308)	Acc@5 100.000 (99.538)
 * Acc@1 80.254 Acc@5 99.532
epoch 84, total time 595.08
Test: [0/750]	Time 1.069 (1.069)	Loss 0.6630 (0.6630)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.138 (0.141)	Loss 0.4289 (0.7561)	Acc@1 78.125 (83.601)	Acc@5 100.000 (94.678)
Test: [200/750]	Time 0.132 (0.136)	Loss 1.4506 (0.6369)	Acc@1 43.750 (82.525)	Acc@5 87.500 (96.004)
Test: [300/750]	Time 0.097 (0.132)	Loss 1.1791 (0.8236)	Acc@1 65.625 (73.152)	Acc@5 90.625 (94.643)
Test: [400/750]	Time 0.133 (0.131)	Loss 0.5166 (0.8619)	Acc@1 81.250 (71.228)	Acc@5 96.875 (94.373)
Test: [500/750]	Time 0.120 (0.129)	Loss 0.4402 (0.8162)	Acc@1 81.250 (73.253)	Acc@5 96.875 (94.324)
Test: [600/750]	Time 0.176 (0.128)	Loss 0.6904 (0.8127)	Acc@1 78.125 (73.378)	Acc@5 93.750 (94.265)
Test: [700/750]	Time 0.101 (0.128)	Loss 0.8411 (0.8081)	Acc@1 65.625 (73.226)	Acc@5 87.500 (94.405)
 * Acc@1 73.308 Acc@5 94.362
==> training...
Epoch: [85][0/875]	Time 2.362 (2.362)	Data 1.618 (1.618)	Loss 1.9774 (1.9774)	Loss@kd 2.1163 (2.1163)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [85][100/875]	Time 0.673 (0.703)	Data 0.007 (0.023)	Loss 2.0613 (1.9060)	Loss@kd 2.0882 (1.9834)	Acc@1 76.562 (80.987)	Acc@5 100.000 (99.567)
Epoch: [85][200/875]	Time 0.668 (0.693)	Data 0.007 (0.015)	Loss 1.9968 (1.9258)	Loss@kd 2.0473 (1.9934)	Acc@1 76.562 (80.854)	Acc@5 100.000 (99.650)
Epoch: [85][300/875]	Time 0.659 (0.689)	Data 0.007 (0.013)	Loss 1.7782 (1.9324)	Loss@kd 1.9674 (1.9959)	Acc@1 85.938 (80.689)	Acc@5 100.000 (99.611)
Epoch: [85][400/875]	Time 0.678 (0.688)	Data 0.007 (0.011)	Loss 1.9162 (1.9330)	Loss@kd 2.1643 (1.9947)	Acc@1 87.500 (80.751)	Acc@5 100.000 (99.595)
Epoch: [85][500/875]	Time 0.675 (0.689)	Data 0.007 (0.011)	Loss 1.8233 (1.9350)	Loss@kd 1.9802 (1.9948)	Acc@1 78.125 (80.704)	Acc@5 100.000 (99.591)
Epoch: [85][600/875]	Time 0.672 (0.689)	Data 0.007 (0.010)	Loss 1.8534 (1.9364)	Loss@kd 1.9736 (1.9939)	Acc@1 85.938 (80.636)	Acc@5 100.000 (99.563)
Epoch: [85][700/875]	Time 0.679 (0.690)	Data 0.007 (0.010)	Loss 2.1890 (1.9380)	Loss@kd 1.9256 (1.9934)	Acc@1 71.875 (80.535)	Acc@5 96.875 (99.565)
Epoch: [85][800/875]	Time 0.673 (0.690)	Data 0.007 (0.009)	Loss 1.9811 (1.9372)	Loss@kd 1.9787 (1.9922)	Acc@1 75.000 (80.505)	Acc@5 100.000 (99.577)
 * Acc@1 80.473 Acc@5 99.589
epoch 85, total time 604.78
Test: [0/750]	Time 1.054 (1.054)	Loss 0.7651 (0.7651)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.131 (0.140)	Loss 0.4164 (0.7972)	Acc@1 84.375 (83.354)	Acc@5 100.000 (93.905)
Test: [200/750]	Time 0.131 (0.135)	Loss 1.2589 (0.6520)	Acc@1 46.875 (82.416)	Acc@5 90.625 (95.756)
Test: [300/750]	Time 0.181 (0.134)	Loss 1.2322 (0.7966)	Acc@1 59.375 (74.481)	Acc@5 90.625 (95.006)
Test: [400/750]	Time 0.129 (0.133)	Loss 0.5679 (0.8509)	Acc@1 81.250 (71.618)	Acc@5 93.750 (94.685)
Test: [500/750]	Time 0.123 (0.133)	Loss 0.4420 (0.8106)	Acc@1 78.125 (73.372)	Acc@5 96.875 (94.573)
Test: [600/750]	Time 0.124 (0.132)	Loss 0.6554 (0.8069)	Acc@1 75.000 (73.451)	Acc@5 100.000 (94.546)
Test: [700/750]	Time 0.117 (0.132)	Loss 0.9668 (0.7992)	Acc@1 65.625 (73.328)	Acc@5 87.500 (94.677)
 * Acc@1 73.417 Acc@5 94.671
saving the best model!
==> training...
Epoch: [86][0/875]	Time 2.425 (2.425)	Data 1.714 (1.714)	Loss 2.2069 (2.2069)	Loss@kd 2.3232 (2.3232)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [86][100/875]	Time 0.678 (0.704)	Data 0.007 (0.024)	Loss 1.9586 (1.9342)	Loss@kd 1.8928 (2.0050)	Acc@1 70.312 (81.033)	Acc@5 100.000 (99.644)
Epoch: [86][200/875]	Time 0.751 (0.695)	Data 0.007 (0.016)	Loss 2.1990 (1.9406)	Loss@kd 1.8790 (2.0104)	Acc@1 70.312 (80.962)	Acc@5 100.000 (99.619)
Epoch: [86][300/875]	Time 0.687 (0.691)	Data 0.008 (0.013)	Loss 1.9117 (1.9363)	Loss@kd 1.9331 (2.0030)	Acc@1 78.125 (80.866)	Acc@5 100.000 (99.574)
Epoch: [86][400/875]	Time 0.684 (0.689)	Data 0.008 (0.012)	Loss 1.8289 (1.9354)	Loss@kd 1.9711 (1.9984)	Acc@1 87.500 (80.747)	Acc@5 100.000 (99.591)
Epoch: [86][500/875]	Time 0.678 (0.689)	Data 0.007 (0.011)	Loss 1.7962 (1.9324)	Loss@kd 1.9226 (1.9941)	Acc@1 82.812 (80.785)	Acc@5 100.000 (99.588)
Epoch: [86][600/875]	Time 0.673 (0.689)	Data 0.007 (0.010)	Loss 1.7301 (1.9342)	Loss@kd 1.8890 (1.9953)	Acc@1 84.375 (80.727)	Acc@5 100.000 (99.592)
Epoch: [86][700/875]	Time 0.676 (0.688)	Data 0.007 (0.010)	Loss 1.9217 (1.9365)	Loss@kd 1.9663 (1.9954)	Acc@1 82.812 (80.626)	Acc@5 100.000 (99.588)
Epoch: [86][800/875]	Time 0.669 (0.688)	Data 0.007 (0.010)	Loss 1.8999 (1.9357)	Loss@kd 1.8897 (1.9946)	Acc@1 79.688 (80.575)	Acc@5 98.438 (99.585)
 * Acc@1 80.688 Acc@5 99.580
epoch 86, total time 602.58
Test: [0/750]	Time 1.025 (1.025)	Loss 0.8033 (0.8033)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.111 (0.140)	Loss 0.3591 (0.7609)	Acc@1 81.250 (83.756)	Acc@5 100.000 (94.554)
Test: [200/750]	Time 0.127 (0.132)	Loss 1.4095 (0.6143)	Acc@1 43.750 (83.535)	Acc@5 84.375 (95.989)
Test: [300/750]	Time 0.115 (0.129)	Loss 1.1877 (0.8127)	Acc@1 65.625 (74.097)	Acc@5 90.625 (94.518)
Test: [400/750]	Time 0.193 (0.127)	Loss 0.6067 (0.8669)	Acc@1 81.250 (71.267)	Acc@5 93.750 (94.194)
Test: [500/750]	Time 0.105 (0.127)	Loss 0.4794 (0.8256)	Acc@1 84.375 (73.091)	Acc@5 96.875 (94.199)
Test: [600/750]	Time 0.120 (0.127)	Loss 0.7486 (0.8296)	Acc@1 75.000 (72.910)	Acc@5 96.875 (94.182)
Test: [700/750]	Time 0.113 (0.126)	Loss 0.7193 (0.8181)	Acc@1 75.000 (72.905)	Acc@5 93.750 (94.432)
 * Acc@1 73.267 Acc@5 94.500
==> training...
Epoch: [87][0/875]	Time 2.641 (2.641)	Data 1.914 (1.914)	Loss 2.0177 (2.0177)	Loss@kd 1.9321 (1.9321)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [87][100/875]	Time 0.675 (0.714)	Data 0.007 (0.026)	Loss 1.8830 (1.9137)	Loss@kd 1.9052 (1.9893)	Acc@1 76.562 (81.327)	Acc@5 100.000 (99.613)
Epoch: [87][200/875]	Time 0.683 (0.703)	Data 0.007 (0.017)	Loss 1.8504 (1.9112)	Loss@kd 1.8977 (1.9847)	Acc@1 81.250 (81.242)	Acc@5 98.438 (99.596)
Epoch: [87][300/875]	Time 0.683 (0.699)	Data 0.007 (0.014)	Loss 1.8587 (1.9138)	Loss@kd 2.0362 (1.9832)	Acc@1 85.938 (81.292)	Acc@5 100.000 (99.569)
Epoch: [87][400/875]	Time 0.669 (0.697)	Data 0.008 (0.012)	Loss 1.9094 (1.9225)	Loss@kd 1.8915 (1.9896)	Acc@1 79.688 (80.993)	Acc@5 100.000 (99.583)
Epoch: [87][500/875]	Time 0.689 (0.696)	Data 0.007 (0.011)	Loss 2.4654 (1.9317)	Loss@kd 2.4962 (1.9929)	Acc@1 78.125 (80.748)	Acc@5 100.000 (99.570)
Epoch: [87][600/875]	Time 0.681 (0.695)	Data 0.007 (0.011)	Loss 2.0515 (1.9302)	Loss@kd 1.9027 (1.9895)	Acc@1 71.875 (80.642)	Acc@5 100.000 (99.550)
Epoch: [87][700/875]	Time 0.644 (0.692)	Data 0.011 (0.010)	Loss 1.8912 (1.9291)	Loss@kd 1.8738 (1.9928)	Acc@1 78.125 (80.757)	Acc@5 100.000 (99.570)
Epoch: [87][800/875]	Time 0.641 (0.691)	Data 0.006 (0.010)	Loss 1.9088 (1.9323)	Loss@kd 1.9677 (1.9965)	Acc@1 81.250 (80.733)	Acc@5 98.438 (99.577)
 * Acc@1 80.654 Acc@5 99.561
epoch 87, total time 603.75
Test: [0/750]	Time 0.924 (0.924)	Loss 0.7655 (0.7655)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.190 (0.129)	Loss 0.3592 (0.7411)	Acc@1 81.250 (84.097)	Acc@5 100.000 (94.152)
Test: [200/750]	Time 0.129 (0.125)	Loss 1.3597 (0.6085)	Acc@1 50.000 (83.427)	Acc@5 87.500 (95.849)
Test: [300/750]	Time 0.119 (0.126)	Loss 1.2131 (0.7828)	Acc@1 62.500 (74.481)	Acc@5 90.625 (94.882)
Test: [400/750]	Time 0.125 (0.126)	Loss 0.6652 (0.8215)	Acc@1 78.125 (72.475)	Acc@5 87.500 (94.810)
Test: [500/750]	Time 0.130 (0.125)	Loss 0.4175 (0.7923)	Acc@1 84.375 (73.971)	Acc@5 100.000 (94.648)
Test: [600/750]	Time 0.119 (0.125)	Loss 0.7386 (0.7942)	Acc@1 68.750 (73.851)	Acc@5 93.750 (94.566)
Test: [700/750]	Time 0.121 (0.125)	Loss 0.9337 (0.7938)	Acc@1 62.500 (73.502)	Acc@5 87.500 (94.597)
 * Acc@1 73.617 Acc@5 94.542
saving the best model!
==> training...
Epoch: [88][0/875]	Time 2.349 (2.349)	Data 1.634 (1.634)	Loss 1.9311 (1.9311)	Loss@kd 1.9248 (1.9248)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [88][100/875]	Time 0.664 (0.697)	Data 0.007 (0.023)	Loss 1.7444 (1.9150)	Loss@kd 1.9172 (1.9835)	Acc@1 85.938 (81.513)	Acc@5 100.000 (99.567)
Epoch: [88][200/875]	Time 0.762 (0.688)	Data 0.007 (0.015)	Loss 1.7503 (1.9066)	Loss@kd 2.0026 (1.9823)	Acc@1 90.625 (81.452)	Acc@5 100.000 (99.596)
Epoch: [88][300/875]	Time 0.686 (0.684)	Data 0.007 (0.012)	Loss 1.9342 (1.9058)	Loss@kd 1.8708 (1.9819)	Acc@1 78.125 (81.676)	Acc@5 100.000 (99.605)
Epoch: [88][400/875]	Time 0.665 (0.685)	Data 0.007 (0.011)	Loss 2.0585 (1.9125)	Loss@kd 1.8837 (1.9858)	Acc@1 73.438 (81.484)	Acc@5 100.000 (99.583)
Epoch: [88][500/875]	Time 0.669 (0.684)	Data 0.007 (0.010)	Loss 2.0596 (1.9117)	Loss@kd 2.0164 (1.9832)	Acc@1 73.438 (81.337)	Acc@5 100.000 (99.563)
Epoch: [88][600/875]	Time 0.671 (0.684)	Data 0.007 (0.010)	Loss 1.8767 (1.9138)	Loss@kd 1.8356 (1.9855)	Acc@1 78.125 (81.273)	Acc@5 98.438 (99.537)
Epoch: [88][700/875]	Time 0.681 (0.684)	Data 0.007 (0.009)	Loss 2.0401 (1.9195)	Loss@kd 1.9361 (1.9894)	Acc@1 84.375 (81.132)	Acc@5 98.438 (99.539)
Epoch: [88][800/875]	Time 0.689 (0.685)	Data 0.008 (0.009)	Loss 1.8426 (1.9198)	Loss@kd 1.8684 (1.9867)	Acc@1 82.812 (81.012)	Acc@5 98.438 (99.549)
 * Acc@1 80.989 Acc@5 99.557
epoch 88, total time 599.97
Test: [0/750]	Time 1.023 (1.023)	Loss 0.9105 (0.9105)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.133 (0.139)	Loss 0.3947 (0.7818)	Acc@1 81.250 (82.116)	Acc@5 96.875 (93.905)
Test: [200/750]	Time 0.106 (0.132)	Loss 1.2454 (0.6061)	Acc@1 43.750 (83.644)	Acc@5 90.625 (95.927)
Test: [300/750]	Time 0.095 (0.128)	Loss 1.2242 (0.7579)	Acc@1 56.250 (75.509)	Acc@5 93.750 (95.297)
Test: [400/750]	Time 0.183 (0.127)	Loss 0.6066 (0.8161)	Acc@1 81.250 (72.553)	Acc@5 87.500 (95.036)
Test: [500/750]	Time 0.115 (0.126)	Loss 0.5209 (0.7915)	Acc@1 75.000 (73.784)	Acc@5 96.875 (94.711)
Test: [600/750]	Time 0.113 (0.125)	Loss 0.8196 (0.8063)	Acc@1 75.000 (73.326)	Acc@5 96.875 (94.525)
Test: [700/750]	Time 0.125 (0.124)	Loss 0.9648 (0.8040)	Acc@1 65.625 (73.039)	Acc@5 87.500 (94.637)
 * Acc@1 73.158 Acc@5 94.579
==> training...
Epoch: [89][0/875]	Time 2.258 (2.258)	Data 1.551 (1.551)	Loss 1.7002 (1.7002)	Loss@kd 1.8701 (1.8701)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [89][100/875]	Time 0.658 (0.700)	Data 0.007 (0.023)	Loss 1.6903 (1.9105)	Loss@kd 1.9104 (1.9781)	Acc@1 87.500 (80.817)	Acc@5 100.000 (99.613)
Epoch: [89][200/875]	Time 0.734 (0.692)	Data 0.007 (0.015)	Loss 1.9083 (1.9161)	Loss@kd 1.8912 (1.9863)	Acc@1 76.562 (81.102)	Acc@5 100.000 (99.572)
Epoch: [89][300/875]	Time 0.669 (0.688)	Data 0.007 (0.012)	Loss 1.7154 (1.9179)	Loss@kd 1.9415 (1.9841)	Acc@1 87.500 (80.949)	Acc@5 100.000 (99.590)
Epoch: [89][400/875]	Time 0.670 (0.686)	Data 0.007 (0.011)	Loss 1.8110 (1.9210)	Loss@kd 1.9355 (1.9856)	Acc@1 85.938 (80.911)	Acc@5 100.000 (99.532)
Epoch: [89][500/875]	Time 0.672 (0.684)	Data 0.007 (0.010)	Loss 2.0581 (1.9231)	Loss@kd 2.0893 (1.9882)	Acc@1 78.125 (80.835)	Acc@5 98.438 (99.557)
Epoch: [89][600/875]	Time 0.667 (0.683)	Data 0.007 (0.010)	Loss 1.9224 (1.9206)	Loss@kd 1.9362 (1.9867)	Acc@1 75.000 (80.860)	Acc@5 100.000 (99.563)
Epoch: [89][700/875]	Time 0.690 (0.683)	Data 0.007 (0.009)	Loss 2.0165 (1.9194)	Loss@kd 2.0763 (1.9879)	Acc@1 78.125 (80.983)	Acc@5 100.000 (99.574)
Epoch: [89][800/875]	Time 0.665 (0.683)	Data 0.007 (0.009)	Loss 1.8822 (1.9181)	Loss@kd 2.1020 (1.9875)	Acc@1 85.938 (81.108)	Acc@5 100.000 (99.573)
 * Acc@1 81.093 Acc@5 99.562
epoch 89, total time 597.97
Test: [0/750]	Time 1.000 (1.000)	Loss 0.4540 (0.4540)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.138 (0.146)	Loss 0.4440 (0.7279)	Acc@1 78.125 (85.334)	Acc@5 96.875 (94.988)
Test: [200/750]	Time 0.135 (0.138)	Loss 1.3291 (0.6148)	Acc@1 50.000 (83.784)	Acc@5 90.625 (96.206)
Test: [300/750]	Time 0.130 (0.135)	Loss 1.3222 (0.7864)	Acc@1 65.625 (74.751)	Acc@5 90.625 (95.183)
Test: [400/750]	Time 0.109 (0.134)	Loss 0.6094 (0.8336)	Acc@1 78.125 (72.202)	Acc@5 90.625 (94.989)
Test: [500/750]	Time 0.127 (0.134)	Loss 0.4846 (0.7996)	Acc@1 75.000 (73.815)	Acc@5 100.000 (94.798)
Test: [600/750]	Time 0.110 (0.132)	Loss 0.7343 (0.8081)	Acc@1 75.000 (73.502)	Acc@5 90.625 (94.577)
Test: [700/750]	Time 0.134 (0.132)	Loss 0.7774 (0.8008)	Acc@1 65.625 (73.435)	Acc@5 90.625 (94.673)
 * Acc@1 73.704 Acc@5 94.683
saving the best model!
==> training...
Epoch: [90][0/875]	Time 2.333 (2.333)	Data 1.601 (1.601)	Loss 1.8372 (1.8372)	Loss@kd 1.9541 (1.9541)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [90][100/875]	Time 0.681 (0.706)	Data 0.007 (0.023)	Loss 2.5914 (1.8998)	Loss@kd 2.9514 (1.9876)	Acc@1 79.688 (82.116)	Acc@5 100.000 (99.691)
Epoch: [90][200/875]	Time 0.669 (0.696)	Data 0.007 (0.015)	Loss 1.8847 (1.9036)	Loss@kd 2.0914 (1.9869)	Acc@1 85.938 (81.786)	Acc@5 100.000 (99.697)
Epoch: [90][300/875]	Time 0.681 (0.692)	Data 0.007 (0.013)	Loss 1.9662 (1.9028)	Loss@kd 1.8881 (1.9812)	Acc@1 73.438 (81.416)	Acc@5 98.438 (99.580)
Epoch: [90][400/875]	Time 0.674 (0.690)	Data 0.008 (0.011)	Loss 1.8363 (1.9020)	Loss@kd 2.0212 (1.9797)	Acc@1 84.375 (81.289)	Acc@5 100.000 (99.583)
Epoch: [90][500/875]	Time 0.672 (0.690)	Data 0.007 (0.011)	Loss 1.9284 (1.9039)	Loss@kd 1.9646 (1.9796)	Acc@1 78.125 (81.156)	Acc@5 100.000 (99.620)
Epoch: [90][600/875]	Time 0.677 (0.690)	Data 0.007 (0.010)	Loss 1.7284 (1.9054)	Loss@kd 1.9240 (1.9818)	Acc@1 87.500 (81.208)	Acc@5 100.000 (99.626)
Epoch: [90][700/875]	Time 0.683 (0.689)	Data 0.007 (0.010)	Loss 2.0635 (1.9086)	Loss@kd 2.0631 (1.9825)	Acc@1 75.000 (81.081)	Acc@5 98.438 (99.617)
Epoch: [90][800/875]	Time 0.671 (0.689)	Data 0.007 (0.009)	Loss 1.7995 (1.9096)	Loss@kd 1.9468 (1.9816)	Acc@1 84.375 (81.104)	Acc@5 100.000 (99.624)
 * Acc@1 81.046 Acc@5 99.616
epoch 90, total time 603.44
Test: [0/750]	Time 1.011 (1.011)	Loss 0.7744 (0.7744)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.243 (0.140)	Loss 0.4577 (0.7714)	Acc@1 78.125 (84.623)	Acc@5 96.875 (93.812)
Test: [200/750]	Time 0.131 (0.133)	Loss 1.2064 (0.6277)	Acc@1 53.125 (83.800)	Acc@5 90.625 (95.662)
Test: [300/750]	Time 0.128 (0.130)	Loss 1.3992 (0.7603)	Acc@1 56.250 (75.924)	Acc@5 93.750 (95.162)
Test: [400/750]	Time 0.198 (0.128)	Loss 0.6139 (0.8199)	Acc@1 81.250 (72.896)	Acc@5 93.750 (94.794)
Test: [500/750]	Time 0.121 (0.127)	Loss 0.5207 (0.7913)	Acc@1 78.125 (74.158)	Acc@5 96.875 (94.629)
Test: [600/750]	Time 0.116 (0.126)	Loss 0.7725 (0.8008)	Acc@1 71.875 (73.742)	Acc@5 90.625 (94.499)
Test: [700/750]	Time 0.132 (0.126)	Loss 0.8109 (0.7978)	Acc@1 68.750 (73.409)	Acc@5 90.625 (94.642)
 * Acc@1 73.608 Acc@5 94.637
==> training...
Epoch: [91][0/875]	Time 2.362 (2.362)	Data 1.628 (1.628)	Loss 1.8939 (1.8939)	Loss@kd 1.8919 (1.8919)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [91][100/875]	Time 0.675 (0.708)	Data 0.007 (0.023)	Loss 1.7982 (1.8860)	Loss@kd 1.9463 (1.9752)	Acc@1 82.812 (81.962)	Acc@5 100.000 (99.613)
Epoch: [91][200/875]	Time 0.676 (0.698)	Data 0.008 (0.015)	Loss 1.7626 (1.8860)	Loss@kd 1.9007 (1.9701)	Acc@1 81.250 (81.732)	Acc@5 100.000 (99.619)
Epoch: [91][300/875]	Time 0.675 (0.695)	Data 0.007 (0.013)	Loss 1.7532 (1.8863)	Loss@kd 1.7924 (1.9720)	Acc@1 79.688 (81.795)	Acc@5 100.000 (99.616)
Epoch: [91][400/875]	Time 0.678 (0.692)	Data 0.007 (0.011)	Loss 1.8512 (1.8865)	Loss@kd 1.8625 (1.9714)	Acc@1 76.562 (81.784)	Acc@5 100.000 (99.603)
Epoch: [91][500/875]	Time 0.679 (0.692)	Data 0.008 (0.011)	Loss 1.9202 (1.8840)	Loss@kd 1.9688 (1.9702)	Acc@1 81.250 (81.902)	Acc@5 98.438 (99.623)
Epoch: [91][600/875]	Time 0.672 (0.690)	Data 0.007 (0.010)	Loss 1.8354 (1.8865)	Loss@kd 1.9974 (1.9723)	Acc@1 84.375 (81.851)	Acc@5 100.000 (99.615)
Epoch: [91][700/875]	Time 0.677 (0.690)	Data 0.007 (0.010)	Loss 2.0235 (1.8880)	Loss@kd 2.0107 (1.9730)	Acc@1 82.812 (81.767)	Acc@5 100.000 (99.628)
Epoch: [91][800/875]	Time 0.661 (0.689)	Data 0.008 (0.009)	Loss 1.9553 (1.8863)	Loss@kd 2.0160 (1.9714)	Acc@1 79.688 (81.841)	Acc@5 100.000 (99.616)
 * Acc@1 81.875 Acc@5 99.614
epoch 91, total time 602.78
Test: [0/750]	Time 0.952 (0.952)	Loss 0.6914 (0.6914)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.133 (0.134)	Loss 0.4007 (0.7791)	Acc@1 81.250 (84.097)	Acc@5 96.875 (93.874)
Test: [200/750]	Time 0.124 (0.130)	Loss 1.3012 (0.6370)	Acc@1 50.000 (83.318)	Acc@5 90.625 (95.662)
Test: [300/750]	Time 0.117 (0.128)	Loss 1.3536 (0.7889)	Acc@1 59.375 (75.052)	Acc@5 90.625 (94.954)
Test: [400/750]	Time 0.169 (0.126)	Loss 0.5433 (0.8323)	Acc@1 84.375 (72.662)	Acc@5 93.750 (94.732)
Test: [500/750]	Time 0.114 (0.125)	Loss 0.5784 (0.7897)	Acc@1 62.500 (74.358)	Acc@5 93.750 (94.673)
Test: [600/750]	Time 0.118 (0.125)	Loss 0.7347 (0.8004)	Acc@1 71.875 (73.944)	Acc@5 93.750 (94.494)
Test: [700/750]	Time 0.101 (0.125)	Loss 0.7459 (0.7954)	Acc@1 62.500 (73.734)	Acc@5 87.500 (94.633)
 * Acc@1 73.929 Acc@5 94.658
saving the best model!
==> training...
Epoch: [92][0/875]	Time 2.360 (2.360)	Data 1.636 (1.636)	Loss 1.7867 (1.7867)	Loss@kd 1.8299 (1.8299)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [92][100/875]	Time 0.683 (0.693)	Data 0.007 (0.023)	Loss 1.7380 (1.8918)	Loss@kd 1.8491 (1.9591)	Acc@1 84.375 (81.080)	Acc@5 100.000 (99.644)
Epoch: [92][200/875]	Time 0.663 (0.685)	Data 0.007 (0.015)	Loss 1.9031 (1.8814)	Loss@kd 1.9692 (1.9579)	Acc@1 82.812 (81.802)	Acc@5 100.000 (99.611)
Epoch: [92][300/875]	Time 0.717 (0.682)	Data 0.007 (0.013)	Loss 1.8656 (1.8748)	Loss@kd 2.0797 (1.9551)	Acc@1 82.812 (81.972)	Acc@5 100.000 (99.605)
Epoch: [92][400/875]	Time 0.673 (0.680)	Data 0.007 (0.011)	Loss 1.9815 (1.8813)	Loss@kd 1.7916 (1.9608)	Acc@1 79.688 (81.850)	Acc@5 100.000 (99.595)
Epoch: [92][500/875]	Time 0.673 (0.680)	Data 0.008 (0.011)	Loss 1.9162 (1.8805)	Loss@kd 1.8730 (1.9609)	Acc@1 75.000 (81.924)	Acc@5 100.000 (99.604)
Epoch: [92][600/875]	Time 0.683 (0.680)	Data 0.007 (0.010)	Loss 1.6827 (1.8833)	Loss@kd 1.8354 (1.9629)	Acc@1 90.625 (81.809)	Acc@5 100.000 (99.602)
Epoch: [92][700/875]	Time 0.681 (0.679)	Data 0.008 (0.010)	Loss 1.8751 (1.8820)	Loss@kd 1.8587 (1.9645)	Acc@1 75.000 (81.919)	Acc@5 100.000 (99.614)
Epoch: [92][800/875]	Time 0.658 (0.678)	Data 0.007 (0.009)	Loss 1.7410 (1.8815)	Loss@kd 1.9338 (1.9660)	Acc@1 87.500 (81.985)	Acc@5 100.000 (99.622)
 * Acc@1 82.046 Acc@5 99.623
epoch 92, total time 594.19
Test: [0/750]	Time 1.027 (1.027)	Loss 0.8297 (0.8297)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.121 (0.139)	Loss 0.4021 (0.8096)	Acc@1 84.375 (83.354)	Acc@5 96.875 (94.214)
Test: [200/750]	Time 0.139 (0.135)	Loss 1.3780 (0.6499)	Acc@1 43.750 (83.053)	Acc@5 90.625 (95.833)
Test: [300/750]	Time 0.141 (0.134)	Loss 1.2527 (0.8122)	Acc@1 62.500 (74.325)	Acc@5 90.625 (94.902)
Test: [400/750]	Time 0.113 (0.133)	Loss 0.5887 (0.8379)	Acc@1 81.250 (72.631)	Acc@5 93.750 (94.872)
Test: [500/750]	Time 0.123 (0.133)	Loss 0.5537 (0.8008)	Acc@1 71.875 (74.189)	Acc@5 93.750 (94.723)
Test: [600/750]	Time 0.132 (0.133)	Loss 0.7320 (0.8083)	Acc@1 75.000 (73.861)	Acc@5 93.750 (94.561)
Test: [700/750]	Time 0.120 (0.132)	Loss 0.7368 (0.7999)	Acc@1 65.625 (73.703)	Acc@5 87.500 (94.731)
 * Acc@1 73.933 Acc@5 94.771
saving the best model!
==> training...
Epoch: [93][0/875]	Time 2.400 (2.400)	Data 1.662 (1.662)	Loss 1.8530 (1.8530)	Loss@kd 1.9278 (1.9278)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [93][100/875]	Time 0.667 (0.697)	Data 0.007 (0.023)	Loss 1.9281 (1.8993)	Loss@kd 1.9445 (1.9923)	Acc@1 78.125 (81.993)	Acc@5 98.438 (99.722)
Epoch: [93][200/875]	Time 0.644 (0.686)	Data 0.005 (0.015)	Loss 1.8844 (1.8883)	Loss@kd 1.9418 (1.9714)	Acc@1 76.562 (81.538)	Acc@5 100.000 (99.712)
Epoch: [93][300/875]	Time 0.669 (0.684)	Data 0.007 (0.013)	Loss 1.9101 (1.8807)	Loss@kd 1.9968 (1.9694)	Acc@1 79.688 (81.909)	Acc@5 100.000 (99.689)
Epoch: [93][400/875]	Time 0.757 (0.682)	Data 0.007 (0.011)	Loss 1.7648 (1.8801)	Loss@kd 1.8741 (1.9687)	Acc@1 85.938 (82.064)	Acc@5 100.000 (99.665)
Epoch: [93][500/875]	Time 0.665 (0.681)	Data 0.007 (0.011)	Loss 1.8349 (1.8851)	Loss@kd 1.8391 (1.9726)	Acc@1 82.812 (82.042)	Acc@5 100.000 (99.632)
Epoch: [93][600/875]	Time 0.675 (0.680)	Data 0.007 (0.010)	Loss 1.7051 (1.8863)	Loss@kd 1.8887 (1.9722)	Acc@1 89.062 (82.053)	Acc@5 100.000 (99.613)
Epoch: [93][700/875]	Time 0.673 (0.679)	Data 0.007 (0.010)	Loss 1.9834 (1.8845)	Loss@kd 1.9694 (1.9724)	Acc@1 85.938 (82.095)	Acc@5 100.000 (99.617)
Epoch: [93][800/875]	Time 0.665 (0.679)	Data 0.007 (0.009)	Loss 1.6306 (1.8820)	Loss@kd 1.8817 (1.9689)	Acc@1 90.625 (82.087)	Acc@5 100.000 (99.612)
 * Acc@1 82.079 Acc@5 99.611
epoch 93, total time 594.64
Test: [0/750]	Time 0.954 (0.954)	Loss 0.6465 (0.6465)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.115 (0.136)	Loss 0.4217 (0.7200)	Acc@1 81.250 (84.313)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.118 (0.130)	Loss 1.3216 (0.5983)	Acc@1 43.750 (83.722)	Acc@5 90.625 (96.098)
Test: [300/750]	Time 0.201 (0.128)	Loss 1.2759 (0.7612)	Acc@1 62.500 (75.228)	Acc@5 90.625 (95.297)
Test: [400/750]	Time 0.113 (0.127)	Loss 0.5916 (0.8084)	Acc@1 81.250 (72.717)	Acc@5 93.750 (95.005)
Test: [500/750]	Time 0.111 (0.126)	Loss 0.5312 (0.7846)	Acc@1 71.875 (74.102)	Acc@5 93.750 (94.748)
Test: [600/750]	Time 0.150 (0.125)	Loss 0.7600 (0.7904)	Acc@1 75.000 (73.903)	Acc@5 93.750 (94.670)
Test: [700/750]	Time 0.121 (0.125)	Loss 0.8800 (0.7859)	Acc@1 65.625 (73.680)	Acc@5 87.500 (94.731)
 * Acc@1 73.854 Acc@5 94.746
==> training...
Epoch: [94][0/875]	Time 2.326 (2.326)	Data 1.616 (1.616)	Loss 1.8433 (1.8433)	Loss@kd 1.8412 (1.8412)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [94][100/875]	Time 0.675 (0.699)	Data 0.007 (0.023)	Loss 1.9782 (1.8703)	Loss@kd 1.9213 (1.9645)	Acc@1 75.000 (82.379)	Acc@5 100.000 (99.737)
Epoch: [94][200/875]	Time 0.685 (0.690)	Data 0.007 (0.015)	Loss 1.7890 (1.8763)	Loss@kd 1.9476 (1.9655)	Acc@1 85.938 (82.245)	Acc@5 96.875 (99.674)
Epoch: [94][300/875]	Time 0.685 (0.688)	Data 0.007 (0.013)	Loss 1.9533 (1.8760)	Loss@kd 1.9884 (1.9638)	Acc@1 78.125 (82.304)	Acc@5 100.000 (99.663)
Epoch: [94][400/875]	Time 0.659 (0.686)	Data 0.011 (0.011)	Loss 1.9082 (1.8827)	Loss@kd 1.9771 (1.9706)	Acc@1 78.125 (82.271)	Acc@5 100.000 (99.665)
Epoch: [94][500/875]	Time 0.661 (0.684)	Data 0.008 (0.010)	Loss 2.0204 (1.8826)	Loss@kd 2.0068 (1.9672)	Acc@1 76.562 (82.070)	Acc@5 100.000 (99.679)
Epoch: [94][600/875]	Time 0.654 (0.684)	Data 0.007 (0.010)	Loss 1.6526 (1.8793)	Loss@kd 1.9241 (1.9673)	Acc@1 87.500 (82.129)	Acc@5 100.000 (99.646)
Epoch: [94][700/875]	Time 0.659 (0.683)	Data 0.007 (0.010)	Loss 2.3796 (1.8776)	Loss@kd 2.8187 (1.9668)	Acc@1 90.625 (82.179)	Acc@5 100.000 (99.619)
Epoch: [94][800/875]	Time 0.670 (0.682)	Data 0.007 (0.009)	Loss 1.7753 (1.8773)	Loss@kd 1.9412 (1.9657)	Acc@1 84.375 (82.118)	Acc@5 98.438 (99.625)
 * Acc@1 82.125 Acc@5 99.623
epoch 94, total time 597.71
Test: [0/750]	Time 1.038 (1.038)	Loss 0.6412 (0.6412)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.112 (0.129)	Loss 0.3836 (0.7526)	Acc@1 78.125 (84.251)	Acc@5 96.875 (94.245)
Test: [200/750]	Time 0.084 (0.123)	Loss 1.2536 (0.6177)	Acc@1 46.875 (83.691)	Acc@5 90.625 (95.880)
Test: [300/750]	Time 0.120 (0.122)	Loss 1.3058 (0.7663)	Acc@1 65.625 (75.446)	Acc@5 90.625 (95.120)
Test: [400/750]	Time 0.190 (0.122)	Loss 0.6054 (0.8171)	Acc@1 78.125 (72.865)	Acc@5 96.875 (94.919)
Test: [500/750]	Time 0.131 (0.121)	Loss 0.5319 (0.7902)	Acc@1 68.750 (74.139)	Acc@5 96.875 (94.729)
Test: [600/750]	Time 0.096 (0.121)	Loss 0.7021 (0.8024)	Acc@1 75.000 (73.700)	Acc@5 93.750 (94.556)
Test: [700/750]	Time 0.133 (0.121)	Loss 0.8003 (0.7967)	Acc@1 65.625 (73.560)	Acc@5 87.500 (94.677)
 * Acc@1 73.737 Acc@5 94.683
==> training...
Epoch: [95][0/875]	Time 2.351 (2.351)	Data 1.630 (1.630)	Loss 1.7775 (1.7775)	Loss@kd 1.9754 (1.9754)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [95][100/875]	Time 0.674 (0.704)	Data 0.007 (0.023)	Loss 1.7543 (1.8679)	Loss@kd 1.9062 (1.9631)	Acc@1 84.375 (82.317)	Acc@5 100.000 (99.613)
Epoch: [95][200/875]	Time 0.667 (0.692)	Data 0.007 (0.015)	Loss 2.3711 (1.8785)	Loss@kd 2.8070 (1.9684)	Acc@1 82.812 (82.090)	Acc@5 100.000 (99.604)
Epoch: [95][300/875]	Time 0.678 (0.690)	Data 0.007 (0.013)	Loss 1.7821 (1.8764)	Loss@kd 1.9535 (1.9602)	Acc@1 85.938 (82.117)	Acc@5 100.000 (99.590)
Epoch: [95][400/875]	Time 0.662 (0.688)	Data 0.007 (0.011)	Loss 1.7388 (1.8752)	Loss@kd 1.9614 (1.9607)	Acc@1 89.062 (82.127)	Acc@5 100.000 (99.599)
Epoch: [95][500/875]	Time 0.671 (0.688)	Data 0.007 (0.010)	Loss 1.8270 (1.8767)	Loss@kd 1.9253 (1.9637)	Acc@1 81.250 (82.111)	Acc@5 98.438 (99.607)
Epoch: [95][600/875]	Time 0.666 (0.686)	Data 0.007 (0.010)	Loss 1.8528 (1.8755)	Loss@kd 2.0539 (1.9651)	Acc@1 85.938 (82.204)	Acc@5 98.438 (99.618)
Epoch: [95][700/875]	Time 0.682 (0.686)	Data 0.006 (0.010)	Loss 1.9338 (1.8806)	Loss@kd 1.9655 (1.9694)	Acc@1 75.000 (82.066)	Acc@5 100.000 (99.628)
Epoch: [95][800/875]	Time 0.667 (0.686)	Data 0.007 (0.009)	Loss 1.9130 (1.8788)	Loss@kd 2.0998 (1.9673)	Acc@1 84.375 (82.040)	Acc@5 100.000 (99.625)
 * Acc@1 82.066 Acc@5 99.618
epoch 95, total time 600.43
Test: [0/750]	Time 1.112 (1.112)	Loss 1.1788 (1.1788)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.131 (0.147)	Loss 0.4571 (0.8675)	Acc@1 84.375 (81.157)	Acc@5 96.875 (93.533)
Test: [200/750]	Time 0.112 (0.137)	Loss 1.3399 (0.6890)	Acc@1 43.750 (81.608)	Acc@5 90.625 (95.476)
Test: [300/750]	Time 0.114 (0.134)	Loss 1.2889 (0.8308)	Acc@1 62.500 (73.671)	Acc@5 93.750 (94.726)
Test: [400/750]	Time 0.115 (0.133)	Loss 0.5742 (0.8744)	Acc@1 84.375 (71.220)	Acc@5 93.750 (94.514)
Test: [500/750]	Time 0.195 (0.132)	Loss 0.5360 (0.8299)	Acc@1 71.875 (73.091)	Acc@5 96.875 (94.467)
Test: [600/750]	Time 0.121 (0.131)	Loss 0.7120 (0.8287)	Acc@1 75.000 (73.097)	Acc@5 93.750 (94.405)
Test: [700/750]	Time 0.127 (0.131)	Loss 0.8335 (0.8158)	Acc@1 65.625 (73.119)	Acc@5 87.500 (94.530)
 * Acc@1 73.321 Acc@5 94.550
==> training...
Epoch: [96][0/875]	Time 2.385 (2.385)	Data 1.560 (1.560)	Loss 1.9621 (1.9621)	Loss@kd 1.8335 (1.8335)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [96][100/875]	Time 0.662 (0.701)	Data 0.007 (0.023)	Loss 1.7010 (1.8752)	Loss@kd 1.9820 (1.9589)	Acc@1 87.500 (82.194)	Acc@5 100.000 (99.397)
Epoch: [96][200/875]	Time 0.679 (0.693)	Data 0.007 (0.015)	Loss 1.7737 (1.8676)	Loss@kd 1.8769 (1.9565)	Acc@1 79.688 (82.385)	Acc@5 100.000 (99.534)
Epoch: [96][300/875]	Time 0.684 (0.691)	Data 0.007 (0.013)	Loss 1.9275 (1.8731)	Loss@kd 1.8736 (1.9588)	Acc@1 76.562 (82.283)	Acc@5 100.000 (99.543)
Epoch: [96][400/875]	Time 0.679 (0.691)	Data 0.007 (0.011)	Loss 1.7584 (1.8733)	Loss@kd 1.9731 (1.9633)	Acc@1 85.938 (82.322)	Acc@5 100.000 (99.564)
Epoch: [96][500/875]	Time 0.679 (0.691)	Data 0.007 (0.011)	Loss 1.8655 (1.8725)	Loss@kd 2.0289 (1.9618)	Acc@1 85.938 (82.267)	Acc@5 100.000 (99.591)
Epoch: [96][600/875]	Time 0.693 (0.690)	Data 0.007 (0.010)	Loss 2.1168 (1.8749)	Loss@kd 2.0058 (1.9651)	Acc@1 81.250 (82.274)	Acc@5 95.312 (99.600)
Epoch: [96][700/875]	Time 0.670 (0.690)	Data 0.007 (0.010)	Loss 1.7495 (1.8822)	Loss@kd 1.9041 (1.9739)	Acc@1 85.938 (82.110)	Acc@5 100.000 (99.610)
Epoch: [96][800/875]	Time 0.687 (0.690)	Data 0.007 (0.009)	Loss 1.8418 (1.8792)	Loss@kd 2.0693 (1.9713)	Acc@1 84.375 (82.147)	Acc@5 100.000 (99.620)
 * Acc@1 82.091 Acc@5 99.620
epoch 96, total time 604.29
Test: [0/750]	Time 1.040 (1.040)	Loss 1.4079 (1.4079)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.129 (0.138)	Loss 0.3631 (0.8844)	Acc@1 84.375 (81.095)	Acc@5 100.000 (93.472)
Test: [200/750]	Time 0.118 (0.130)	Loss 1.2739 (0.6795)	Acc@1 53.125 (82.323)	Acc@5 87.500 (95.522)
Test: [300/750]	Time 0.118 (0.130)	Loss 1.2722 (0.8258)	Acc@1 59.375 (74.003)	Acc@5 93.750 (94.747)
Test: [400/750]	Time 0.123 (0.128)	Loss 0.5347 (0.8648)	Acc@1 87.500 (71.719)	Acc@5 96.875 (94.584)
Test: [500/750]	Time 0.122 (0.127)	Loss 0.5036 (0.8179)	Acc@1 71.875 (73.615)	Acc@5 96.875 (94.505)
Test: [600/750]	Time 0.126 (0.127)	Loss 0.7890 (0.8198)	Acc@1 75.000 (73.435)	Acc@5 90.625 (94.452)
Test: [700/750]	Time 0.124 (0.127)	Loss 0.8186 (0.8169)	Acc@1 65.625 (73.105)	Acc@5 90.625 (94.548)
 * Acc@1 73.275 Acc@5 94.550
==> training...
Epoch: [97][0/875]	Time 2.396 (2.396)	Data 1.662 (1.662)	Loss 2.2257 (2.2257)	Loss@kd 2.2957 (2.2957)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [97][100/875]	Time 0.658 (0.703)	Data 0.007 (0.024)	Loss 2.0884 (1.8759)	Loss@kd 1.8816 (1.9616)	Acc@1 76.562 (82.410)	Acc@5 100.000 (99.675)
Epoch: [97][200/875]	Time 0.671 (0.694)	Data 0.007 (0.016)	Loss 1.8752 (1.8672)	Loss@kd 1.8941 (1.9607)	Acc@1 82.812 (82.540)	Acc@5 100.000 (99.674)
Epoch: [97][300/875]	Time 0.680 (0.691)	Data 0.007 (0.013)	Loss 1.9637 (1.8715)	Loss@kd 1.8875 (1.9632)	Acc@1 70.312 (82.330)	Acc@5 100.000 (99.657)
Epoch: [97][400/875]	Time 0.685 (0.690)	Data 0.007 (0.012)	Loss 1.9259 (1.8690)	Loss@kd 2.0225 (1.9599)	Acc@1 81.250 (82.372)	Acc@5 98.438 (99.638)
Epoch: [97][500/875]	Time 0.679 (0.689)	Data 0.007 (0.011)	Loss 1.8443 (1.8742)	Loss@kd 1.9975 (1.9653)	Acc@1 85.938 (82.236)	Acc@5 98.438 (99.629)
Epoch: [97][600/875]	Time 0.700 (0.689)	Data 0.007 (0.010)	Loss 1.9495 (1.8719)	Loss@kd 1.9696 (1.9642)	Acc@1 82.812 (82.264)	Acc@5 98.438 (99.641)
Epoch: [97][700/875]	Time 0.742 (0.688)	Data 0.007 (0.010)	Loss 1.7648 (1.8740)	Loss@kd 1.8380 (1.9638)	Acc@1 84.375 (82.162)	Acc@5 100.000 (99.637)
Epoch: [97][800/875]	Time 0.682 (0.688)	Data 0.007 (0.010)	Loss 1.6987 (1.8756)	Loss@kd 1.8554 (1.9649)	Acc@1 90.625 (82.147)	Acc@5 100.000 (99.635)
 * Acc@1 82.095 Acc@5 99.632
epoch 97, total time 602.61
Test: [0/750]	Time 1.033 (1.033)	Loss 0.6199 (0.6199)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.089 (0.136)	Loss 0.3811 (0.7618)	Acc@1 81.250 (84.437)	Acc@5 100.000 (94.369)
Test: [200/750]	Time 0.121 (0.130)	Loss 1.2859 (0.6152)	Acc@1 40.625 (83.800)	Acc@5 90.625 (95.989)
Test: [300/750]	Time 0.108 (0.129)	Loss 1.2551 (0.7705)	Acc@1 59.375 (75.384)	Acc@5 90.625 (95.141)
Test: [400/750]	Time 0.129 (0.128)	Loss 0.5844 (0.8140)	Acc@1 81.250 (72.974)	Acc@5 93.750 (94.958)
Test: [500/750]	Time 0.121 (0.128)	Loss 0.5327 (0.7854)	Acc@1 65.625 (74.389)	Acc@5 100.000 (94.742)
Test: [600/750]	Time 0.116 (0.127)	Loss 0.7061 (0.7941)	Acc@1 75.000 (74.012)	Acc@5 96.875 (94.603)
Test: [700/750]	Time 0.196 (0.127)	Loss 0.8640 (0.7895)	Acc@1 62.500 (73.752)	Acc@5 87.500 (94.708)
 * Acc@1 73.871 Acc@5 94.700
==> training...
Epoch: [98][0/875]	Time 2.356 (2.356)	Data 1.615 (1.615)	Loss 1.8884 (1.8884)	Loss@kd 1.8573 (1.8573)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [98][100/875]	Time 0.668 (0.706)	Data 0.006 (0.023)	Loss 2.0053 (1.8864)	Loss@kd 1.9459 (1.9688)	Acc@1 81.250 (82.333)	Acc@5 98.438 (99.598)
Epoch: [98][200/875]	Time 0.680 (0.698)	Data 0.007 (0.015)	Loss 1.8840 (1.8860)	Loss@kd 1.9969 (1.9766)	Acc@1 76.562 (82.206)	Acc@5 100.000 (99.658)
Epoch: [98][300/875]	Time 0.677 (0.695)	Data 0.007 (0.013)	Loss 1.8790 (1.8760)	Loss@kd 1.9471 (1.9683)	Acc@1 81.250 (82.283)	Acc@5 98.438 (99.626)
Epoch: [98][400/875]	Time 0.677 (0.694)	Data 0.007 (0.011)	Loss 2.3164 (1.8733)	Loss@kd 2.8924 (1.9696)	Acc@1 89.062 (82.489)	Acc@5 100.000 (99.622)
Epoch: [98][500/875]	Time 0.675 (0.693)	Data 0.007 (0.011)	Loss 2.0376 (1.8755)	Loss@kd 1.9574 (1.9691)	Acc@1 73.438 (82.401)	Acc@5 100.000 (99.598)
Epoch: [98][600/875]	Time 0.687 (0.693)	Data 0.007 (0.010)	Loss 1.7222 (1.8745)	Loss@kd 1.9182 (1.9654)	Acc@1 84.375 (82.334)	Acc@5 100.000 (99.607)
Epoch: [98][700/875]	Time 0.668 (0.692)	Data 0.007 (0.010)	Loss 1.8806 (1.8728)	Loss@kd 1.9487 (1.9640)	Acc@1 82.812 (82.295)	Acc@5 100.000 (99.617)
Epoch: [98][800/875]	Time 0.678 (0.692)	Data 0.007 (0.009)	Loss 1.8242 (1.8761)	Loss@kd 1.9483 (1.9662)	Acc@1 82.812 (82.200)	Acc@5 100.000 (99.639)
 * Acc@1 82.180 Acc@5 99.654
epoch 98, total time 606.40
Test: [0/750]	Time 1.036 (1.036)	Loss 0.4771 (0.4771)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.116 (0.142)	Loss 0.3830 (0.7219)	Acc@1 84.375 (84.870)	Acc@5 100.000 (94.864)
Test: [200/750]	Time 0.135 (0.137)	Loss 1.3132 (0.5950)	Acc@1 43.750 (84.188)	Acc@5 90.625 (96.269)
Test: [300/750]	Time 0.140 (0.135)	Loss 1.2988 (0.7587)	Acc@1 65.625 (75.789)	Acc@5 90.625 (95.390)
Test: [400/750]	Time 0.129 (0.134)	Loss 0.5793 (0.8124)	Acc@1 78.125 (72.950)	Acc@5 96.875 (95.114)
Test: [500/750]	Time 0.128 (0.133)	Loss 0.5275 (0.7839)	Acc@1 75.000 (74.295)	Acc@5 96.875 (94.891)
Test: [600/750]	Time 0.146 (0.133)	Loss 0.8071 (0.7933)	Acc@1 75.000 (73.918)	Acc@5 96.875 (94.748)
Test: [700/750]	Time 0.125 (0.132)	Loss 0.7694 (0.7893)	Acc@1 65.625 (73.573)	Acc@5 87.500 (94.842)
 * Acc@1 73.758 Acc@5 94.875
==> training...
Epoch: [99][0/875]	Time 2.355 (2.355)	Data 1.658 (1.658)	Loss 1.7200 (1.7200)	Loss@kd 1.9018 (1.9018)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [99][100/875]	Time 0.663 (0.705)	Data 0.006 (0.024)	Loss 2.0806 (1.8754)	Loss@kd 2.0813 (1.9727)	Acc@1 85.938 (82.225)	Acc@5 98.438 (99.691)
Epoch: [99][200/875]	Time 0.688 (0.697)	Data 0.008 (0.016)	Loss 1.8314 (1.8699)	Loss@kd 2.0549 (1.9709)	Acc@1 85.938 (82.517)	Acc@5 100.000 (99.681)
Epoch: [99][300/875]	Time 0.666 (0.694)	Data 0.008 (0.013)	Loss 1.8592 (1.8716)	Loss@kd 1.9102 (1.9677)	Acc@1 73.438 (82.537)	Acc@5 100.000 (99.631)
Epoch: [99][400/875]	Time 0.675 (0.693)	Data 0.008 (0.011)	Loss 1.7762 (1.8783)	Loss@kd 1.8937 (1.9688)	Acc@1 81.250 (82.251)	Acc@5 100.000 (99.642)
Epoch: [99][500/875]	Time 0.671 (0.692)	Data 0.007 (0.011)	Loss 1.8468 (1.8778)	Loss@kd 1.9068 (1.9665)	Acc@1 79.688 (82.226)	Acc@5 98.438 (99.623)
Epoch: [99][600/875]	Time 0.681 (0.693)	Data 0.007 (0.010)	Loss 1.7848 (1.8786)	Loss@kd 2.0475 (1.9667)	Acc@1 87.500 (82.178)	Acc@5 98.438 (99.623)
Epoch: [99][700/875]	Time 0.678 (0.693)	Data 0.007 (0.010)	Loss 1.8634 (1.8731)	Loss@kd 1.8553 (1.9632)	Acc@1 78.125 (82.166)	Acc@5 100.000 (99.639)
Epoch: [99][800/875]	Time 0.669 (0.693)	Data 0.007 (0.009)	Loss 1.9207 (1.8748)	Loss@kd 2.0359 (1.9650)	Acc@1 84.375 (82.177)	Acc@5 100.000 (99.629)
 * Acc@1 82.111 Acc@5 99.630
epoch 99, total time 606.99
Test: [0/750]	Time 1.031 (1.031)	Loss 0.8993 (0.8993)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.103 (0.146)	Loss 0.4120 (0.8537)	Acc@1 81.250 (81.219)	Acc@5 100.000 (94.276)
Test: [200/750]	Time 0.130 (0.139)	Loss 1.2960 (0.6633)	Acc@1 50.000 (82.276)	Acc@5 90.625 (95.896)
Test: [300/750]	Time 0.086 (0.135)	Loss 1.2891 (0.8177)	Acc@1 59.375 (74.180)	Acc@5 93.750 (94.882)
Test: [400/750]	Time 0.197 (0.132)	Loss 0.6250 (0.8614)	Acc@1 84.375 (71.781)	Acc@5 93.750 (94.584)
Test: [500/750]	Time 0.126 (0.130)	Loss 0.5333 (0.8261)	Acc@1 75.000 (73.322)	Acc@5 93.750 (94.424)
Test: [600/750]	Time 0.122 (0.130)	Loss 0.7238 (0.8276)	Acc@1 75.000 (73.222)	Acc@5 96.875 (94.379)
Test: [700/750]	Time 0.103 (0.129)	Loss 0.8722 (0.8208)	Acc@1 62.500 (73.007)	Acc@5 87.500 (94.481)
 * Acc@1 73.121 Acc@5 94.442
==> training...
Epoch: [100][0/875]	Time 2.413 (2.413)	Data 1.644 (1.644)	Loss 1.7538 (1.7538)	Loss@kd 1.8841 (1.8841)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [100][100/875]	Time 0.687 (0.706)	Data 0.007 (0.024)	Loss 1.9712 (1.8829)	Loss@kd 1.9546 (1.9720)	Acc@1 75.000 (81.637)	Acc@5 100.000 (99.613)
Epoch: [100][200/875]	Time 0.738 (0.698)	Data 0.007 (0.016)	Loss 2.0435 (1.8850)	Loss@kd 2.2182 (1.9708)	Acc@1 84.375 (81.662)	Acc@5 100.000 (99.650)
Epoch: [100][300/875]	Time 0.672 (0.691)	Data 0.008 (0.013)	Loss 1.7646 (1.8806)	Loss@kd 1.9586 (1.9696)	Acc@1 85.938 (82.034)	Acc@5 100.000 (99.605)
Epoch: [100][400/875]	Time 0.668 (0.690)	Data 0.007 (0.011)	Loss 1.9406 (1.8737)	Loss@kd 1.9988 (1.9669)	Acc@1 76.562 (82.244)	Acc@5 100.000 (99.606)
Epoch: [100][500/875]	Time 0.668 (0.689)	Data 0.007 (0.011)	Loss 1.9369 (1.8781)	Loss@kd 1.9804 (1.9687)	Acc@1 79.688 (82.048)	Acc@5 100.000 (99.629)
Epoch: [100][600/875]	Time 0.678 (0.689)	Data 0.008 (0.010)	Loss 1.8996 (1.8788)	Loss@kd 1.9574 (1.9688)	Acc@1 79.688 (82.007)	Acc@5 98.438 (99.639)
Epoch: [100][700/875]	Time 0.685 (0.689)	Data 0.007 (0.010)	Loss 1.8913 (1.8787)	Loss@kd 1.9822 (1.9669)	Acc@1 81.250 (81.943)	Acc@5 100.000 (99.639)
Epoch: [100][800/875]	Time 0.681 (0.689)	Data 0.007 (0.010)	Loss 1.9376 (1.8764)	Loss@kd 2.0271 (1.9659)	Acc@1 79.688 (82.017)	Acc@5 98.438 (99.637)
 * Acc@1 82.105 Acc@5 99.652
epoch 100, total time 603.85
Test: [0/750]	Time 1.041 (1.041)	Loss 1.3519 (1.3519)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.136 (0.141)	Loss 0.3677 (0.8775)	Acc@1 81.250 (81.281)	Acc@5 96.875 (93.595)
Test: [200/750]	Time 0.142 (0.138)	Loss 1.2661 (0.6715)	Acc@1 50.000 (82.463)	Acc@5 90.625 (95.647)
Test: [300/750]	Time 0.136 (0.137)	Loss 1.2664 (0.8143)	Acc@1 62.500 (74.294)	Acc@5 90.625 (94.996)
Test: [400/750]	Time 0.140 (0.136)	Loss 0.5935 (0.8489)	Acc@1 84.375 (72.233)	Acc@5 90.625 (94.818)
Test: [500/750]	Time 0.144 (0.136)	Loss 0.5203 (0.8143)	Acc@1 78.125 (73.802)	Acc@5 93.750 (94.642)
Test: [600/750]	Time 0.135 (0.135)	Loss 0.7812 (0.8177)	Acc@1 75.000 (73.502)	Acc@5 96.875 (94.572)
Test: [700/750]	Time 0.210 (0.134)	Loss 0.8405 (0.8119)	Acc@1 65.625 (73.279)	Acc@5 87.500 (94.686)
 * Acc@1 73.504 Acc@5 94.692
==> training...
Epoch: [101][0/875]	Time 2.360 (2.360)	Data 1.622 (1.622)	Loss 2.1080 (2.1080)	Loss@kd 1.9720 (1.9720)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [101][100/875]	Time 0.691 (0.706)	Data 0.007 (0.023)	Loss 1.5703 (1.8705)	Loss@kd 1.7958 (1.9659)	Acc@1 90.625 (82.410)	Acc@5 98.438 (99.598)
Epoch: [101][200/875]	Time 0.667 (0.696)	Data 0.007 (0.015)	Loss 1.7804 (1.8710)	Loss@kd 1.9220 (1.9565)	Acc@1 85.938 (81.942)	Acc@5 100.000 (99.619)
Epoch: [101][300/875]	Time 0.741 (0.693)	Data 0.007 (0.013)	Loss 1.9977 (1.8714)	Loss@kd 2.1080 (1.9553)	Acc@1 84.375 (82.086)	Acc@5 100.000 (99.631)
Epoch: [101][400/875]	Time 0.678 (0.691)	Data 0.006 (0.011)	Loss 1.6027 (1.8707)	Loss@kd 1.8404 (1.9592)	Acc@1 87.500 (82.209)	Acc@5 100.000 (99.657)
Epoch: [101][500/875]	Time 0.667 (0.691)	Data 0.007 (0.011)	Loss 1.8268 (1.8699)	Loss@kd 1.9414 (1.9607)	Acc@1 87.500 (82.254)	Acc@5 100.000 (99.666)
Epoch: [101][600/875]	Time 0.714 (0.691)	Data 0.007 (0.010)	Loss 1.8325 (1.8687)	Loss@kd 1.9786 (1.9602)	Acc@1 81.250 (82.300)	Acc@5 100.000 (99.672)
Epoch: [101][700/875]	Time 0.670 (0.691)	Data 0.007 (0.010)	Loss 1.6548 (1.8684)	Loss@kd 1.8096 (1.9620)	Acc@1 85.938 (82.293)	Acc@5 100.000 (99.688)
Epoch: [101][800/875]	Time 0.679 (0.690)	Data 0.007 (0.009)	Loss 1.9112 (1.8703)	Loss@kd 2.0172 (1.9642)	Acc@1 81.250 (82.180)	Acc@5 98.438 (99.680)
 * Acc@1 82.218 Acc@5 99.677
epoch 101, total time 604.55
Test: [0/750]	Time 1.032 (1.032)	Loss 0.6561 (0.6561)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.132 (0.144)	Loss 0.4254 (0.7512)	Acc@1 81.250 (83.632)	Acc@5 100.000 (94.369)
Test: [200/750]	Time 0.121 (0.138)	Loss 1.3356 (0.6237)	Acc@1 46.875 (82.914)	Acc@5 90.625 (95.911)
Test: [300/750]	Time 0.122 (0.136)	Loss 1.2259 (0.7832)	Acc@1 59.375 (74.543)	Acc@5 93.750 (95.172)
Test: [400/750]	Time 0.127 (0.134)	Loss 0.5861 (0.8175)	Acc@1 81.250 (72.615)	Acc@5 93.750 (95.114)
Test: [500/750]	Time 0.200 (0.134)	Loss 0.5742 (0.7953)	Acc@1 65.625 (73.883)	Acc@5 96.875 (94.792)
Test: [600/750]	Time 0.130 (0.133)	Loss 0.6880 (0.8067)	Acc@1 75.000 (73.424)	Acc@5 93.750 (94.587)
Test: [700/750]	Time 0.128 (0.133)	Loss 0.7627 (0.7989)	Acc@1 65.625 (73.346)	Acc@5 87.500 (94.722)
 * Acc@1 73.467 Acc@5 94.746
==> training...
Epoch: [102][0/875]	Time 2.440 (2.440)	Data 1.599 (1.599)	Loss 1.8128 (1.8128)	Loss@kd 1.8459 (1.8459)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [102][100/875]	Time 0.691 (0.708)	Data 0.007 (0.023)	Loss 2.0339 (1.8808)	Loss@kd 1.8816 (1.9595)	Acc@1 70.312 (81.993)	Acc@5 98.438 (99.536)
Epoch: [102][200/875]	Time 0.675 (0.699)	Data 0.007 (0.015)	Loss 1.8443 (1.8782)	Loss@kd 1.9547 (1.9601)	Acc@1 84.375 (82.058)	Acc@5 100.000 (99.534)
Epoch: [102][300/875]	Time 0.673 (0.696)	Data 0.007 (0.013)	Loss 1.9819 (1.8873)	Loss@kd 1.8903 (1.9797)	Acc@1 76.562 (82.231)	Acc@5 98.438 (99.590)
Epoch: [102][400/875]	Time 0.680 (0.695)	Data 0.008 (0.012)	Loss 1.9096 (1.8815)	Loss@kd 1.9266 (1.9774)	Acc@1 79.688 (82.442)	Acc@5 100.000 (99.599)
Epoch: [102][500/875]	Time 0.675 (0.694)	Data 0.007 (0.011)	Loss 2.0612 (1.8740)	Loss@kd 2.4766 (1.9703)	Acc@1 92.188 (82.413)	Acc@5 100.000 (99.613)
Epoch: [102][600/875]	Time 0.670 (0.693)	Data 0.007 (0.010)	Loss 1.7611 (1.8759)	Loss@kd 1.8673 (1.9719)	Acc@1 82.812 (82.352)	Acc@5 100.000 (99.618)
Epoch: [102][700/875]	Time 0.767 (0.692)	Data 0.007 (0.010)	Loss 2.0514 (1.8781)	Loss@kd 1.8015 (1.9725)	Acc@1 60.938 (82.286)	Acc@5 100.000 (99.619)
Epoch: [102][800/875]	Time 0.673 (0.691)	Data 0.007 (0.009)	Loss 1.8818 (1.8767)	Loss@kd 1.9610 (1.9703)	Acc@1 79.688 (82.247)	Acc@5 100.000 (99.620)
 * Acc@1 82.264 Acc@5 99.625
epoch 102, total time 605.15
Test: [0/750]	Time 1.149 (1.149)	Loss 0.7482 (0.7482)	Acc@1 68.750 (68.750)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.138 (0.143)	Loss 0.4059 (0.7831)	Acc@1 81.250 (83.849)	Acc@5 100.000 (94.276)
Test: [200/750]	Time 0.103 (0.137)	Loss 1.2470 (0.6357)	Acc@1 50.000 (83.333)	Acc@5 90.625 (95.833)
Test: [300/750]	Time 0.108 (0.135)	Loss 1.2438 (0.7798)	Acc@1 62.500 (75.332)	Acc@5 93.750 (95.193)
Test: [400/750]	Time 0.134 (0.134)	Loss 0.6080 (0.8266)	Acc@1 81.250 (72.865)	Acc@5 93.750 (94.950)
Test: [500/750]	Time 0.178 (0.132)	Loss 0.5551 (0.8013)	Acc@1 71.875 (74.127)	Acc@5 93.750 (94.717)
Test: [600/750]	Time 0.110 (0.132)	Loss 0.7538 (0.8127)	Acc@1 75.000 (73.653)	Acc@5 93.750 (94.540)
Test: [700/750]	Time 0.136 (0.132)	Loss 0.7965 (0.8052)	Acc@1 65.625 (73.502)	Acc@5 87.500 (94.655)
 * Acc@1 73.696 Acc@5 94.700
==> training...
Epoch: [103][0/875]	Time 2.326 (2.326)	Data 1.597 (1.597)	Loss 1.9270 (1.9270)	Loss@kd 1.9116 (1.9116)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [103][100/875]	Time 0.809 (0.701)	Data 0.007 (0.023)	Loss 1.9118 (1.8707)	Loss@kd 1.9434 (1.9705)	Acc@1 78.125 (82.379)	Acc@5 100.000 (99.752)
Epoch: [103][200/875]	Time 0.681 (0.693)	Data 0.007 (0.015)	Loss 2.2561 (1.8597)	Loss@kd 2.4583 (1.9634)	Acc@1 82.812 (82.486)	Acc@5 100.000 (99.712)
Epoch: [103][300/875]	Time 0.668 (0.690)	Data 0.007 (0.013)	Loss 1.6597 (1.8659)	Loss@kd 1.8668 (1.9652)	Acc@1 85.938 (82.480)	Acc@5 98.438 (99.668)
Epoch: [103][400/875]	Time 0.694 (0.689)	Data 0.007 (0.011)	Loss 1.9131 (1.8692)	Loss@kd 1.9548 (1.9638)	Acc@1 73.438 (82.325)	Acc@5 100.000 (99.677)
Epoch: [103][500/875]	Time 0.672 (0.689)	Data 0.008 (0.011)	Loss 1.8943 (1.8638)	Loss@kd 2.0853 (1.9599)	Acc@1 84.375 (82.323)	Acc@5 100.000 (99.669)
Epoch: [103][600/875]	Time 0.666 (0.689)	Data 0.007 (0.010)	Loss 1.7162 (1.8682)	Loss@kd 1.8225 (1.9615)	Acc@1 90.625 (82.225)	Acc@5 100.000 (99.644)
Epoch: [103][700/875]	Time 0.673 (0.689)	Data 0.007 (0.010)	Loss 1.8698 (1.8709)	Loss@kd 2.0378 (1.9640)	Acc@1 85.938 (82.122)	Acc@5 100.000 (99.639)
Epoch: [103][800/875]	Time 0.775 (0.689)	Data 0.008 (0.009)	Loss 1.7590 (1.8699)	Loss@kd 1.9202 (1.9625)	Acc@1 87.500 (82.171)	Acc@5 100.000 (99.645)
 * Acc@1 82.273 Acc@5 99.646
epoch 103, total time 603.93
Test: [0/750]	Time 1.029 (1.029)	Loss 0.6039 (0.6039)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.117 (0.144)	Loss 0.3699 (0.7414)	Acc@1 81.250 (84.561)	Acc@5 100.000 (94.493)
Test: [200/750]	Time 0.121 (0.138)	Loss 1.3323 (0.6076)	Acc@1 43.750 (83.862)	Acc@5 90.625 (96.020)
Test: [300/750]	Time 0.117 (0.134)	Loss 1.3235 (0.7772)	Acc@1 62.500 (75.208)	Acc@5 90.625 (95.079)
Test: [400/750]	Time 0.135 (0.134)	Loss 0.5360 (0.8175)	Acc@1 84.375 (73.169)	Acc@5 96.875 (94.942)
Test: [500/750]	Time 0.132 (0.133)	Loss 0.5363 (0.7810)	Acc@1 68.750 (74.763)	Acc@5 96.875 (94.860)
Test: [600/750]	Time 0.113 (0.133)	Loss 0.7705 (0.7933)	Acc@1 75.000 (74.256)	Acc@5 93.750 (94.686)
Test: [700/750]	Time 0.128 (0.132)	Loss 0.7580 (0.7895)	Acc@1 65.625 (73.939)	Acc@5 90.625 (94.802)
 * Acc@1 74.071 Acc@5 94.800
saving the best model!
==> training...
Epoch: [104][0/875]	Time 2.353 (2.353)	Data 1.632 (1.632)	Loss 1.8277 (1.8277)	Loss@kd 1.9956 (1.9956)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [104][100/875]	Time 0.673 (0.710)	Data 0.007 (0.024)	Loss 1.7392 (1.8925)	Loss@kd 1.8128 (1.9861)	Acc@1 84.375 (82.008)	Acc@5 100.000 (99.582)
Epoch: [104][200/875]	Time 0.681 (0.700)	Data 0.008 (0.016)	Loss 2.0550 (1.8731)	Loss@kd 2.1810 (1.9717)	Acc@1 82.812 (82.206)	Acc@5 100.000 (99.642)
Epoch: [104][300/875]	Time 0.689 (0.698)	Data 0.007 (0.013)	Loss 1.8652 (1.8657)	Loss@kd 1.9477 (1.9664)	Acc@1 87.500 (82.330)	Acc@5 100.000 (99.683)
Epoch: [104][400/875]	Time 0.681 (0.697)	Data 0.008 (0.012)	Loss 1.8945 (1.8678)	Loss@kd 1.9353 (1.9658)	Acc@1 79.688 (82.224)	Acc@5 98.438 (99.677)
Epoch: [104][500/875]	Time 0.676 (0.696)	Data 0.007 (0.011)	Loss 1.8467 (1.8695)	Loss@kd 1.9406 (1.9650)	Acc@1 82.812 (82.170)	Acc@5 100.000 (99.663)
Epoch: [104][600/875]	Time 0.677 (0.695)	Data 0.007 (0.010)	Loss 2.0634 (1.8699)	Loss@kd 2.0678 (1.9634)	Acc@1 78.125 (82.267)	Acc@5 100.000 (99.659)
Epoch: [104][700/875]	Time 0.689 (0.695)	Data 0.007 (0.010)	Loss 1.7025 (1.8682)	Loss@kd 1.8255 (1.9661)	Acc@1 84.375 (82.382)	Acc@5 100.000 (99.668)
Epoch: [104][800/875]	Time 0.666 (0.695)	Data 0.007 (0.010)	Loss 1.8949 (1.8649)	Loss@kd 1.9642 (1.9615)	Acc@1 81.250 (82.422)	Acc@5 100.000 (99.659)
 * Acc@1 82.311 Acc@5 99.652
epoch 104, total time 608.58
Test: [0/750]	Time 1.037 (1.037)	Loss 0.9286 (0.9286)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.107 (0.142)	Loss 0.3946 (0.8138)	Acc@1 84.375 (83.478)	Acc@5 100.000 (93.750)
Test: [200/750]	Time 0.112 (0.137)	Loss 1.3169 (0.6432)	Acc@1 56.250 (83.489)	Acc@5 87.500 (95.693)
Test: [300/750]	Time 0.127 (0.134)	Loss 1.2892 (0.7943)	Acc@1 62.500 (74.958)	Acc@5 90.625 (94.975)
Test: [400/750]	Time 0.119 (0.134)	Loss 0.6319 (0.8327)	Acc@1 81.250 (72.748)	Acc@5 96.875 (94.896)
Test: [500/750]	Time 0.131 (0.133)	Loss 0.5628 (0.8058)	Acc@1 65.625 (73.965)	Acc@5 93.750 (94.673)
Test: [600/750]	Time 0.133 (0.133)	Loss 0.7626 (0.8177)	Acc@1 75.000 (73.502)	Acc@5 90.625 (94.499)
Test: [700/750]	Time 0.093 (0.133)	Loss 0.7580 (0.8099)	Acc@1 65.625 (73.368)	Acc@5 87.500 (94.659)
 * Acc@1 73.642 Acc@5 94.696
==> training...
Epoch: [105][0/875]	Time 2.384 (2.384)	Data 1.633 (1.633)	Loss 2.0488 (2.0488)	Loss@kd 2.1137 (2.1137)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [105][100/875]	Time 0.769 (0.708)	Data 0.008 (0.024)	Loss 1.9382 (1.8674)	Loss@kd 1.9154 (1.9595)	Acc@1 75.000 (82.008)	Acc@5 100.000 (99.722)
Epoch: [105][200/875]	Time 0.684 (0.696)	Data 0.007 (0.016)	Loss 1.8459 (1.8624)	Loss@kd 1.8995 (1.9556)	Acc@1 81.250 (82.377)	Acc@5 100.000 (99.658)
Epoch: [105][300/875]	Time 0.691 (0.694)	Data 0.007 (0.013)	Loss 2.1688 (1.8699)	Loss@kd 2.2660 (1.9582)	Acc@1 82.812 (82.044)	Acc@5 100.000 (99.663)
Epoch: [105][400/875]	Time 0.675 (0.693)	Data 0.008 (0.012)	Loss 1.9710 (1.8656)	Loss@kd 1.9957 (1.9544)	Acc@1 78.125 (82.193)	Acc@5 98.438 (99.653)
Epoch: [105][500/875]	Time 0.673 (0.692)	Data 0.007 (0.011)	Loss 1.9425 (1.8657)	Loss@kd 2.0032 (1.9576)	Acc@1 81.250 (82.373)	Acc@5 100.000 (99.635)
Epoch: [105][600/875]	Time 0.679 (0.691)	Data 0.007 (0.010)	Loss 1.8352 (1.8652)	Loss@kd 1.9639 (1.9570)	Acc@1 82.812 (82.404)	Acc@5 100.000 (99.652)
Epoch: [105][700/875]	Time 0.688 (0.690)	Data 0.008 (0.010)	Loss 1.6661 (1.8638)	Loss@kd 1.9740 (1.9557)	Acc@1 93.750 (82.494)	Acc@5 100.000 (99.650)
Epoch: [105][800/875]	Time 0.771 (0.690)	Data 0.007 (0.010)	Loss 1.8233 (1.8656)	Loss@kd 1.9162 (1.9592)	Acc@1 82.812 (82.580)	Acc@5 98.438 (99.641)
 * Acc@1 82.495 Acc@5 99.639
epoch 105, total time 603.94
Test: [0/750]	Time 1.035 (1.035)	Loss 0.9103 (0.9103)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.207 (0.143)	Loss 0.4063 (0.7565)	Acc@1 81.250 (82.952)	Acc@5 96.875 (94.338)
Test: [200/750]	Time 0.097 (0.133)	Loss 1.2539 (0.6174)	Acc@1 50.000 (83.007)	Acc@5 90.625 (95.896)
Test: [300/750]	Time 0.109 (0.131)	Loss 1.3283 (0.7746)	Acc@1 59.375 (74.886)	Acc@5 90.625 (95.183)
Test: [400/750]	Time 0.122 (0.129)	Loss 0.5399 (0.8265)	Acc@1 81.250 (72.265)	Acc@5 93.750 (94.966)
Test: [500/750]	Time 0.119 (0.127)	Loss 0.5756 (0.7987)	Acc@1 68.750 (73.628)	Acc@5 93.750 (94.767)
Test: [600/750]	Time 0.198 (0.127)	Loss 0.7020 (0.8109)	Acc@1 75.000 (73.165)	Acc@5 96.875 (94.608)
Test: [700/750]	Time 0.135 (0.127)	Loss 0.7469 (0.8007)	Acc@1 65.625 (73.168)	Acc@5 90.625 (94.757)
 * Acc@1 73.400 Acc@5 94.779
==> training...
Epoch: [106][0/875]	Time 2.330 (2.330)	Data 1.595 (1.595)	Loss 1.8461 (1.8461)	Loss@kd 1.9839 (1.9839)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [106][100/875]	Time 0.682 (0.700)	Data 0.007 (0.023)	Loss 1.7203 (1.8807)	Loss@kd 1.9670 (1.9593)	Acc@1 90.625 (81.621)	Acc@5 100.000 (99.520)
Epoch: [106][200/875]	Time 0.681 (0.690)	Data 0.011 (0.015)	Loss 1.7937 (1.8678)	Loss@kd 1.9377 (1.9568)	Acc@1 85.938 (81.973)	Acc@5 100.000 (99.627)
Epoch: [106][300/875]	Time 0.685 (0.688)	Data 0.007 (0.013)	Loss 2.2248 (1.8668)	Loss@kd 2.4830 (1.9566)	Acc@1 84.375 (82.091)	Acc@5 100.000 (99.595)
Epoch: [106][400/875]	Time 0.787 (0.687)	Data 0.007 (0.011)	Loss 1.9007 (1.8658)	Loss@kd 1.9722 (1.9576)	Acc@1 82.812 (82.240)	Acc@5 98.438 (99.591)
Epoch: [106][500/875]	Time 0.678 (0.687)	Data 0.007 (0.011)	Loss 1.7365 (1.8623)	Loss@kd 1.8301 (1.9541)	Acc@1 82.812 (82.407)	Acc@5 100.000 (99.607)
Epoch: [106][600/875]	Time 0.678 (0.686)	Data 0.007 (0.010)	Loss 1.8369 (1.8633)	Loss@kd 1.9451 (1.9576)	Acc@1 79.688 (82.462)	Acc@5 100.000 (99.615)
Epoch: [106][700/875]	Time 0.703 (0.686)	Data 0.007 (0.010)	Loss 2.0874 (1.8680)	Loss@kd 1.8773 (1.9669)	Acc@1 75.000 (82.527)	Acc@5 98.438 (99.621)
Epoch: [106][800/875]	Time 0.676 (0.685)	Data 0.007 (0.009)	Loss 1.9556 (1.8658)	Loss@kd 2.0321 (1.9658)	Acc@1 78.125 (82.602)	Acc@5 100.000 (99.625)
 * Acc@1 82.493 Acc@5 99.636
epoch 106, total time 599.43
Test: [0/750]	Time 1.024 (1.024)	Loss 0.8963 (0.8963)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.116 (0.133)	Loss 0.4109 (0.7799)	Acc@1 78.125 (82.797)	Acc@5 100.000 (94.307)
Test: [200/750]	Time 0.130 (0.130)	Loss 1.2088 (0.6192)	Acc@1 53.125 (83.287)	Acc@5 87.500 (95.989)
Test: [300/750]	Time 0.125 (0.129)	Loss 1.3783 (0.7750)	Acc@1 56.250 (75.093)	Acc@5 90.625 (95.120)
Test: [400/750]	Time 0.098 (0.128)	Loss 0.5311 (0.8308)	Acc@1 84.375 (72.343)	Acc@5 96.875 (94.810)
Test: [500/750]	Time 0.101 (0.127)	Loss 0.5427 (0.7932)	Acc@1 65.625 (74.033)	Acc@5 93.750 (94.760)
Test: [600/750]	Time 0.109 (0.126)	Loss 0.7302 (0.8005)	Acc@1 75.000 (73.721)	Acc@5 93.750 (94.665)
Test: [700/750]	Time 0.126 (0.126)	Loss 0.7982 (0.7941)	Acc@1 65.625 (73.605)	Acc@5 87.500 (94.784)
 * Acc@1 73.779 Acc@5 94.787
==> training...
Epoch: [107][0/875]	Time 2.362 (2.362)	Data 1.621 (1.621)	Loss 1.8971 (1.8971)	Loss@kd 1.8665 (1.8665)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [107][100/875]	Time 0.669 (0.700)	Data 0.007 (0.023)	Loss 1.8996 (1.8681)	Loss@kd 1.9396 (1.9597)	Acc@1 82.812 (82.426)	Acc@5 96.875 (99.675)
Epoch: [107][200/875]	Time 0.678 (0.690)	Data 0.007 (0.015)	Loss 1.7248 (1.8691)	Loss@kd 1.9024 (1.9612)	Acc@1 85.938 (82.385)	Acc@5 100.000 (99.658)
Epoch: [107][300/875]	Time 0.677 (0.688)	Data 0.008 (0.013)	Loss 2.2015 (1.8670)	Loss@kd 2.2581 (1.9685)	Acc@1 71.875 (82.532)	Acc@5 100.000 (99.699)
Epoch: [107][400/875]	Time 0.662 (0.687)	Data 0.009 (0.011)	Loss 1.9151 (1.8652)	Loss@kd 1.9852 (1.9626)	Acc@1 81.250 (82.458)	Acc@5 100.000 (99.700)
Epoch: [107][500/875]	Time 0.650 (0.687)	Data 0.007 (0.011)	Loss 1.8669 (1.8664)	Loss@kd 1.8822 (1.9596)	Acc@1 85.938 (82.485)	Acc@5 98.438 (99.679)
Epoch: [107][600/875]	Time 0.676 (0.687)	Data 0.007 (0.010)	Loss 1.7984 (1.8673)	Loss@kd 1.8953 (1.9639)	Acc@1 87.500 (82.428)	Acc@5 98.438 (99.670)
Epoch: [107][700/875]	Time 0.657 (0.686)	Data 0.007 (0.010)	Loss 1.9324 (1.8697)	Loss@kd 2.0641 (1.9650)	Acc@1 76.562 (82.351)	Acc@5 100.000 (99.650)
Epoch: [107][800/875]	Time 0.663 (0.684)	Data 0.007 (0.009)	Loss 1.9998 (1.8681)	Loss@kd 1.8939 (1.9628)	Acc@1 73.438 (82.321)	Acc@5 98.438 (99.655)
 * Acc@1 82.355 Acc@5 99.659
epoch 107, total time 599.03
Test: [0/750]	Time 0.925 (0.925)	Loss 1.0252 (1.0252)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.122 (0.133)	Loss 0.3813 (0.8178)	Acc@1 84.375 (83.168)	Acc@5 96.875 (93.688)
Test: [200/750]	Time 0.128 (0.129)	Loss 1.3298 (0.6491)	Acc@1 46.875 (83.069)	Acc@5 87.500 (95.631)
Test: [300/750]	Time 0.121 (0.127)	Loss 1.3523 (0.8166)	Acc@1 56.250 (74.211)	Acc@5 90.625 (94.653)
Test: [400/750]	Time 0.123 (0.127)	Loss 0.5608 (0.8570)	Acc@1 81.250 (71.914)	Acc@5 96.875 (94.514)
Test: [500/750]	Time 0.130 (0.126)	Loss 0.4736 (0.8129)	Acc@1 78.125 (73.765)	Acc@5 96.875 (94.511)
Test: [600/750]	Time 0.097 (0.125)	Loss 0.7225 (0.8113)	Acc@1 75.000 (73.674)	Acc@5 96.875 (94.462)
Test: [700/750]	Time 0.119 (0.125)	Loss 0.6965 (0.8011)	Acc@1 68.750 (73.658)	Acc@5 90.625 (94.637)
 * Acc@1 73.900 Acc@5 94.667
==> training...
Epoch: [108][0/875]	Time 2.358 (2.358)	Data 1.621 (1.621)	Loss 1.7886 (1.7886)	Loss@kd 1.8472 (1.8472)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [108][100/875]	Time 0.725 (0.697)	Data 0.007 (0.023)	Loss 1.9392 (1.8466)	Loss@kd 1.9301 (1.9440)	Acc@1 76.562 (83.029)	Acc@5 100.000 (99.722)
Epoch: [108][200/875]	Time 0.674 (0.688)	Data 0.007 (0.015)	Loss 1.9254 (1.8450)	Loss@kd 1.9788 (1.9435)	Acc@1 76.562 (82.766)	Acc@5 98.438 (99.759)
Epoch: [108][300/875]	Time 0.664 (0.685)	Data 0.007 (0.013)	Loss 1.5985 (1.8570)	Loss@kd 1.9177 (1.9537)	Acc@1 96.875 (82.667)	Acc@5 100.000 (99.720)
Epoch: [108][400/875]	Time 0.688 (0.683)	Data 0.007 (0.011)	Loss 1.6650 (1.8636)	Loss@kd 1.8540 (1.9611)	Acc@1 89.062 (82.509)	Acc@5 100.000 (99.708)
Epoch: [108][500/875]	Time 0.667 (0.682)	Data 0.007 (0.011)	Loss 1.9327 (1.8666)	Loss@kd 1.8650 (1.9609)	Acc@1 75.000 (82.342)	Acc@5 98.438 (99.682)
Epoch: [108][600/875]	Time 0.674 (0.681)	Data 0.007 (0.010)	Loss 2.0330 (1.8651)	Loss@kd 1.9408 (1.9590)	Acc@1 71.875 (82.358)	Acc@5 100.000 (99.667)
Epoch: [108][700/875]	Time 0.657 (0.681)	Data 0.007 (0.010)	Loss 1.6509 (1.8669)	Loss@kd 1.8471 (1.9606)	Acc@1 85.938 (82.307)	Acc@5 100.000 (99.657)
Epoch: [108][800/875]	Time 0.655 (0.680)	Data 0.007 (0.009)	Loss 2.0686 (1.8667)	Loss@kd 2.1048 (1.9605)	Acc@1 75.000 (82.329)	Acc@5 100.000 (99.651)
 * Acc@1 82.352 Acc@5 99.639
epoch 108, total time 595.45
Test: [0/750]	Time 1.035 (1.035)	Loss 0.8237 (0.8237)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.101 (0.147)	Loss 0.4113 (0.8063)	Acc@1 81.250 (82.921)	Acc@5 96.875 (94.183)
Test: [200/750]	Time 0.126 (0.140)	Loss 1.3285 (0.6466)	Acc@1 40.625 (82.836)	Acc@5 90.625 (95.864)
Test: [300/750]	Time 0.122 (0.138)	Loss 1.2732 (0.8039)	Acc@1 68.750 (74.564)	Acc@5 90.625 (95.048)
Test: [400/750]	Time 0.136 (0.136)	Loss 0.6023 (0.8437)	Acc@1 81.250 (72.335)	Acc@5 96.875 (94.896)
Test: [500/750]	Time 0.201 (0.135)	Loss 0.4796 (0.8059)	Acc@1 75.000 (73.908)	Acc@5 96.875 (94.742)
Test: [600/750]	Time 0.133 (0.135)	Loss 0.7814 (0.8066)	Acc@1 75.000 (73.794)	Acc@5 93.750 (94.707)
Test: [700/750]	Time 0.128 (0.134)	Loss 0.7862 (0.8002)	Acc@1 65.625 (73.596)	Acc@5 87.500 (94.802)
 * Acc@1 73.796 Acc@5 94.796
==> training...
Epoch: [109][0/875]	Time 2.388 (2.388)	Data 1.624 (1.624)	Loss 1.6746 (1.6746)	Loss@kd 1.9025 (1.9025)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [109][100/875]	Time 0.680 (0.704)	Data 0.007 (0.023)	Loss 1.9901 (1.8497)	Loss@kd 1.9537 (1.9598)	Acc@1 78.125 (83.369)	Acc@5 98.438 (99.722)
Epoch: [109][200/875]	Time 0.681 (0.695)	Data 0.007 (0.015)	Loss 1.9460 (1.8586)	Loss@kd 2.0113 (1.9629)	Acc@1 79.688 (82.719)	Acc@5 100.000 (99.674)
Epoch: [109][300/875]	Time 0.684 (0.692)	Data 0.006 (0.013)	Loss 1.9799 (1.8642)	Loss@kd 1.9983 (1.9629)	Acc@1 78.125 (82.231)	Acc@5 100.000 (99.689)
Epoch: [109][400/875]	Time 0.679 (0.691)	Data 0.007 (0.011)	Loss 1.9299 (1.8644)	Loss@kd 2.1007 (1.9638)	Acc@1 82.812 (82.345)	Acc@5 100.000 (99.708)
Epoch: [109][500/875]	Time 0.683 (0.691)	Data 0.005 (0.011)	Loss 1.7919 (1.8683)	Loss@kd 1.9675 (1.9646)	Acc@1 85.938 (82.170)	Acc@5 100.000 (99.710)
Epoch: [109][600/875]	Time 0.671 (0.690)	Data 0.007 (0.010)	Loss 1.6917 (1.8661)	Loss@kd 1.8659 (1.9641)	Acc@1 84.375 (82.264)	Acc@5 100.000 (99.688)
Epoch: [109][700/875]	Time 0.673 (0.690)	Data 0.007 (0.010)	Loss 1.6810 (1.8680)	Loss@kd 1.9260 (1.9629)	Acc@1 89.062 (82.186)	Acc@5 100.000 (99.677)
Epoch: [109][800/875]	Time 0.753 (0.689)	Data 0.008 (0.009)	Loss 1.8239 (1.8695)	Loss@kd 1.9035 (1.9640)	Acc@1 82.812 (82.218)	Acc@5 100.000 (99.668)
 * Acc@1 82.318 Acc@5 99.670
epoch 109, total time 603.77
Test: [0/750]	Time 1.063 (1.063)	Loss 0.6308 (0.6308)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.110 (0.136)	Loss 0.3868 (0.7159)	Acc@1 81.250 (84.158)	Acc@5 100.000 (94.895)
Test: [200/750]	Time 0.097 (0.130)	Loss 1.3531 (0.5944)	Acc@1 43.750 (83.458)	Acc@5 90.625 (96.253)
Test: [300/750]	Time 0.122 (0.128)	Loss 1.2653 (0.7690)	Acc@1 62.500 (74.709)	Acc@5 90.625 (95.255)
Test: [400/750]	Time 0.114 (0.127)	Loss 0.5706 (0.8104)	Acc@1 81.250 (72.732)	Acc@5 93.750 (95.067)
Test: [500/750]	Time 0.114 (0.126)	Loss 0.5269 (0.7825)	Acc@1 68.750 (74.170)	Acc@5 96.875 (94.810)
Test: [600/750]	Time 0.135 (0.126)	Loss 0.7644 (0.7936)	Acc@1 71.875 (73.804)	Acc@5 93.750 (94.629)
Test: [700/750]	Time 0.127 (0.125)	Loss 0.7194 (0.7875)	Acc@1 65.625 (73.689)	Acc@5 87.500 (94.762)
 * Acc@1 73.900 Acc@5 94.812
==> training...
Epoch: [110][0/875]	Time 2.355 (2.355)	Data 1.613 (1.613)	Loss 1.8839 (1.8839)	Loss@kd 1.9160 (1.9160)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [110][100/875]	Time 0.672 (0.711)	Data 0.007 (0.023)	Loss 1.6910 (1.8729)	Loss@kd 1.8610 (1.9687)	Acc@1 89.062 (82.472)	Acc@5 100.000 (99.613)
Epoch: [110][200/875]	Time 0.678 (0.702)	Data 0.007 (0.015)	Loss 1.9147 (1.8719)	Loss@kd 1.9101 (1.9626)	Acc@1 73.438 (82.144)	Acc@5 100.000 (99.611)
Epoch: [110][300/875]	Time 0.685 (0.698)	Data 0.007 (0.013)	Loss 1.8556 (1.8833)	Loss@kd 1.9144 (1.9798)	Acc@1 81.250 (82.138)	Acc@5 98.438 (99.605)
Epoch: [110][400/875]	Time 0.673 (0.697)	Data 0.007 (0.011)	Loss 1.8527 (1.8739)	Loss@kd 1.9584 (1.9735)	Acc@1 84.375 (82.431)	Acc@5 100.000 (99.587)
Epoch: [110][500/875]	Time 0.674 (0.696)	Data 0.008 (0.011)	Loss 2.0231 (1.8730)	Loss@kd 1.8252 (1.9708)	Acc@1 73.438 (82.404)	Acc@5 100.000 (99.616)
Epoch: [110][600/875]	Time 0.689 (0.695)	Data 0.007 (0.010)	Loss 1.7974 (1.8723)	Loss@kd 2.0096 (1.9689)	Acc@1 89.062 (82.417)	Acc@5 100.000 (99.631)
Epoch: [110][700/875]	Time 0.679 (0.695)	Data 0.008 (0.010)	Loss 1.7547 (1.8679)	Loss@kd 1.8505 (1.9654)	Acc@1 79.688 (82.480)	Acc@5 100.000 (99.632)
Epoch: [110][800/875]	Time 0.673 (0.695)	Data 0.010 (0.010)	Loss 1.9442 (1.8661)	Loss@kd 2.0607 (1.9636)	Acc@1 82.812 (82.477)	Acc@5 98.438 (99.627)
 * Acc@1 82.530 Acc@5 99.627
epoch 110, total time 608.60
Test: [0/750]	Time 1.046 (1.046)	Loss 0.9799 (0.9799)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.110 (0.138)	Loss 0.3752 (0.7984)	Acc@1 81.250 (82.550)	Acc@5 100.000 (93.719)
Test: [200/750]	Time 0.124 (0.131)	Loss 1.2389 (0.6300)	Acc@1 53.125 (83.209)	Acc@5 90.625 (95.725)
Test: [300/750]	Time 0.118 (0.128)	Loss 1.4239 (0.7821)	Acc@1 59.375 (75.093)	Acc@5 90.625 (95.017)
Test: [400/750]	Time 0.124 (0.127)	Loss 0.5653 (0.8363)	Acc@1 81.250 (72.459)	Acc@5 93.750 (94.748)
Test: [500/750]	Time 0.123 (0.127)	Loss 0.4924 (0.7991)	Acc@1 71.875 (73.990)	Acc@5 100.000 (94.673)
Test: [600/750]	Time 0.103 (0.126)	Loss 0.7689 (0.8043)	Acc@1 71.875 (73.710)	Acc@5 93.750 (94.598)
Test: [700/750]	Time 0.121 (0.126)	Loss 0.7180 (0.7986)	Acc@1 65.625 (73.507)	Acc@5 90.625 (94.753)
 * Acc@1 73.708 Acc@5 94.779
==> training...
Epoch: [111][0/875]	Time 2.361 (2.361)	Data 1.629 (1.629)	Loss 1.8362 (1.8362)	Loss@kd 2.0263 (2.0263)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [111][100/875]	Time 0.667 (0.704)	Data 0.007 (0.023)	Loss 1.8215 (1.8710)	Loss@kd 2.0112 (1.9854)	Acc@1 85.938 (82.457)	Acc@5 100.000 (99.737)
Epoch: [111][200/875]	Time 0.672 (0.696)	Data 0.007 (0.015)	Loss 1.7764 (1.8637)	Loss@kd 1.8527 (1.9669)	Acc@1 82.812 (82.758)	Acc@5 98.438 (99.635)
Epoch: [111][300/875]	Time 0.673 (0.693)	Data 0.007 (0.013)	Loss 1.7715 (1.8638)	Loss@kd 1.8485 (1.9648)	Acc@1 87.500 (82.584)	Acc@5 98.438 (99.626)
Epoch: [111][400/875]	Time 0.675 (0.691)	Data 0.007 (0.011)	Loss 1.9548 (1.8603)	Loss@kd 2.0151 (1.9591)	Acc@1 76.562 (82.583)	Acc@5 100.000 (99.665)
Epoch: [111][500/875]	Time 0.779 (0.691)	Data 0.008 (0.011)	Loss 1.8575 (1.8605)	Loss@kd 1.8020 (1.9594)	Acc@1 81.250 (82.544)	Acc@5 98.438 (99.660)
Epoch: [111][600/875]	Time 0.677 (0.690)	Data 0.007 (0.010)	Loss 1.9035 (1.8556)	Loss@kd 1.9824 (1.9561)	Acc@1 82.812 (82.703)	Acc@5 98.438 (99.649)
Epoch: [111][700/875]	Time 0.682 (0.689)	Data 0.010 (0.010)	Loss 2.1065 (1.8582)	Loss@kd 1.9828 (1.9566)	Acc@1 75.000 (82.616)	Acc@5 100.000 (99.643)
Epoch: [111][800/875]	Time 0.689 (0.689)	Data 0.007 (0.009)	Loss 1.9528 (1.8636)	Loss@kd 2.0114 (1.9605)	Acc@1 78.125 (82.454)	Acc@5 100.000 (99.633)
 * Acc@1 82.491 Acc@5 99.629
epoch 111, total time 603.24
Test: [0/750]	Time 1.043 (1.043)	Loss 0.7385 (0.7385)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.108 (0.141)	Loss 0.4000 (0.7877)	Acc@1 81.250 (83.199)	Acc@5 100.000 (94.090)
Test: [200/750]	Time 0.137 (0.134)	Loss 1.3170 (0.6362)	Acc@1 46.875 (82.945)	Acc@5 90.625 (95.849)
Test: [300/750]	Time 0.123 (0.131)	Loss 1.2444 (0.8020)	Acc@1 65.625 (74.242)	Acc@5 90.625 (94.996)
Test: [400/750]	Time 0.124 (0.130)	Loss 0.5490 (0.8328)	Acc@1 81.250 (72.374)	Acc@5 93.750 (94.919)
Test: [500/750]	Time 0.132 (0.129)	Loss 0.5155 (0.8005)	Acc@1 65.625 (73.958)	Acc@5 100.000 (94.779)
Test: [600/750]	Time 0.113 (0.129)	Loss 0.7308 (0.8091)	Acc@1 75.000 (73.653)	Acc@5 96.875 (94.603)
Test: [700/750]	Time 0.197 (0.129)	Loss 0.7439 (0.7987)	Acc@1 65.625 (73.578)	Acc@5 90.625 (94.771)
 * Acc@1 73.787 Acc@5 94.800
==> training...
Epoch: [112][0/875]	Time 2.378 (2.378)	Data 1.630 (1.630)	Loss 1.9493 (1.9493)	Loss@kd 2.0016 (2.0016)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [112][100/875]	Time 0.684 (0.709)	Data 0.007 (0.024)	Loss 1.9130 (1.8724)	Loss@kd 2.0143 (1.9648)	Acc@1 85.938 (82.008)	Acc@5 100.000 (99.582)
Epoch: [112][200/875]	Time 0.676 (0.698)	Data 0.007 (0.016)	Loss 1.8963 (1.8701)	Loss@kd 1.9810 (1.9627)	Acc@1 82.812 (82.012)	Acc@5 100.000 (99.604)
Epoch: [112][300/875]	Time 0.774 (0.696)	Data 0.007 (0.013)	Loss 1.8148 (1.8751)	Loss@kd 1.9269 (1.9725)	Acc@1 75.000 (82.153)	Acc@5 100.000 (99.595)
Epoch: [112][400/875]	Time 0.681 (0.693)	Data 0.007 (0.012)	Loss 1.8148 (1.8710)	Loss@kd 1.9834 (1.9700)	Acc@1 82.812 (82.322)	Acc@5 100.000 (99.603)
Epoch: [112][500/875]	Time 0.674 (0.692)	Data 0.007 (0.011)	Loss 1.9030 (1.8697)	Loss@kd 1.9206 (1.9680)	Acc@1 78.125 (82.401)	Acc@5 100.000 (99.607)
Epoch: [112][600/875]	Time 0.687 (0.691)	Data 0.007 (0.010)	Loss 1.7118 (1.8701)	Loss@kd 1.8907 (1.9647)	Acc@1 85.938 (82.248)	Acc@5 100.000 (99.605)
Epoch: [112][700/875]	Time 0.692 (0.691)	Data 0.007 (0.010)	Loss 1.9178 (1.8683)	Loss@kd 2.0102 (1.9642)	Acc@1 71.875 (82.336)	Acc@5 100.000 (99.639)
Epoch: [112][800/875]	Time 0.685 (0.690)	Data 0.007 (0.010)	Loss 1.8296 (1.8679)	Loss@kd 1.9219 (1.9642)	Acc@1 82.812 (82.393)	Acc@5 98.438 (99.633)
 * Acc@1 82.400 Acc@5 99.643
epoch 112, total time 604.26
Test: [0/750]	Time 1.011 (1.011)	Loss 0.5918 (0.5918)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.127 (0.146)	Loss 0.4181 (0.6919)	Acc@1 81.250 (84.127)	Acc@5 100.000 (94.864)
Test: [200/750]	Time 0.138 (0.139)	Loss 1.4449 (0.5886)	Acc@1 43.750 (83.302)	Acc@5 87.500 (96.129)
Test: [300/750]	Time 0.179 (0.137)	Loss 1.1848 (0.7815)	Acc@1 65.625 (74.003)	Acc@5 90.625 (95.037)
Test: [400/750]	Time 0.140 (0.135)	Loss 0.6193 (0.8132)	Acc@1 81.250 (72.140)	Acc@5 96.875 (95.059)
Test: [500/750]	Time 0.112 (0.135)	Loss 0.5964 (0.7934)	Acc@1 71.875 (73.534)	Acc@5 93.750 (94.704)
Test: [600/750]	Time 0.138 (0.134)	Loss 0.7389 (0.8046)	Acc@1 75.000 (73.144)	Acc@5 93.750 (94.520)
Test: [700/750]	Time 0.134 (0.134)	Loss 0.7675 (0.7962)	Acc@1 68.750 (73.021)	Acc@5 87.500 (94.659)
 * Acc@1 73.213 Acc@5 94.683
==> training...
Epoch: [113][0/875]	Time 2.375 (2.375)	Data 1.651 (1.651)	Loss 1.7383 (1.7383)	Loss@kd 1.9059 (1.9059)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [113][100/875]	Time 0.681 (0.711)	Data 0.007 (0.024)	Loss 1.8923 (1.8916)	Loss@kd 1.8613 (2.0050)	Acc@1 81.250 (81.993)	Acc@5 98.438 (99.706)
Epoch: [113][200/875]	Time 0.684 (0.701)	Data 0.007 (0.016)	Loss 1.8615 (1.8837)	Loss@kd 2.0835 (1.9839)	Acc@1 87.500 (81.864)	Acc@5 100.000 (99.666)
Epoch: [113][300/875]	Time 0.676 (0.697)	Data 0.007 (0.013)	Loss 1.6909 (1.8698)	Loss@kd 1.9530 (1.9707)	Acc@1 90.625 (82.231)	Acc@5 100.000 (99.642)
Epoch: [113][400/875]	Time 0.679 (0.694)	Data 0.007 (0.012)	Loss 1.8443 (1.8666)	Loss@kd 1.9388 (1.9673)	Acc@1 81.250 (82.372)	Acc@5 100.000 (99.645)
Epoch: [113][500/875]	Time 0.671 (0.693)	Data 0.007 (0.011)	Loss 1.7622 (1.8651)	Loss@kd 1.9067 (1.9631)	Acc@1 82.812 (82.292)	Acc@5 100.000 (99.613)
Epoch: [113][600/875]	Time 0.671 (0.691)	Data 0.007 (0.010)	Loss 1.8874 (1.8657)	Loss@kd 2.0126 (1.9631)	Acc@1 85.938 (82.339)	Acc@5 100.000 (99.620)
Epoch: [113][700/875]	Time 0.675 (0.690)	Data 0.007 (0.010)	Loss 1.9092 (1.8664)	Loss@kd 1.9480 (1.9624)	Acc@1 81.250 (82.286)	Acc@5 96.875 (99.603)
Epoch: [113][800/875]	Time 0.680 (0.690)	Data 0.008 (0.010)	Loss 2.0102 (1.8650)	Loss@kd 2.0932 (1.9626)	Acc@1 79.688 (82.344)	Acc@5 100.000 (99.614)
 * Acc@1 82.434 Acc@5 99.605
epoch 113, total time 604.62
Test: [0/750]	Time 1.031 (1.031)	Loss 0.7316 (0.7316)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.137 (0.142)	Loss 0.3678 (0.7667)	Acc@1 81.250 (84.313)	Acc@5 100.000 (93.874)
Test: [200/750]	Time 0.110 (0.134)	Loss 1.2941 (0.6170)	Acc@1 46.875 (83.924)	Acc@5 90.625 (95.756)
Test: [300/750]	Time 0.118 (0.130)	Loss 1.3641 (0.7824)	Acc@1 62.500 (75.249)	Acc@5 90.625 (94.882)
Test: [400/750]	Time 0.120 (0.129)	Loss 0.5919 (0.8255)	Acc@1 81.250 (72.950)	Acc@5 90.625 (94.794)
Test: [500/750]	Time 0.098 (0.127)	Loss 0.5048 (0.7920)	Acc@1 75.000 (74.457)	Acc@5 96.875 (94.648)
Test: [600/750]	Time 0.100 (0.127)	Loss 0.7322 (0.7974)	Acc@1 75.000 (74.178)	Acc@5 96.875 (94.613)
Test: [700/750]	Time 0.135 (0.126)	Loss 0.8372 (0.7948)	Acc@1 65.625 (73.877)	Acc@5 87.500 (94.691)
 * Acc@1 73.967 Acc@5 94.637
==> training...
Epoch: [114][0/875]	Time 2.289 (2.289)	Data 1.563 (1.563)	Loss 1.8404 (1.8404)	Loss@kd 1.8333 (1.8333)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [114][100/875]	Time 0.673 (0.707)	Data 0.007 (0.023)	Loss 1.8395 (1.8646)	Loss@kd 1.9311 (1.9731)	Acc@1 78.125 (82.395)	Acc@5 100.000 (99.783)
Epoch: [114][200/875]	Time 0.673 (0.698)	Data 0.007 (0.015)	Loss 1.7709 (1.8718)	Loss@kd 1.8780 (1.9808)	Acc@1 82.812 (82.540)	Acc@5 100.000 (99.712)
Epoch: [114][300/875]	Time 0.677 (0.695)	Data 0.008 (0.013)	Loss 1.9274 (1.8736)	Loss@kd 1.9831 (1.9788)	Acc@1 84.375 (82.636)	Acc@5 100.000 (99.689)
Epoch: [114][400/875]	Time 0.660 (0.693)	Data 0.007 (0.011)	Loss 1.7639 (1.8739)	Loss@kd 1.9947 (1.9738)	Acc@1 90.625 (82.512)	Acc@5 100.000 (99.649)
Epoch: [114][500/875]	Time 0.664 (0.693)	Data 0.007 (0.011)	Loss 1.7658 (1.8739)	Loss@kd 1.9690 (1.9731)	Acc@1 82.812 (82.426)	Acc@5 100.000 (99.632)
Epoch: [114][600/875]	Time 0.694 (0.693)	Data 0.008 (0.010)	Loss 1.6432 (1.8739)	Loss@kd 1.9454 (1.9712)	Acc@1 85.938 (82.391)	Acc@5 100.000 (99.644)
Epoch: [114][700/875]	Time 0.680 (0.693)	Data 0.008 (0.010)	Loss 1.7744 (1.8725)	Loss@kd 1.9255 (1.9695)	Acc@1 84.375 (82.364)	Acc@5 100.000 (99.646)
Epoch: [114][800/875]	Time 0.676 (0.693)	Data 0.007 (0.009)	Loss 1.8812 (1.8713)	Loss@kd 1.9240 (1.9680)	Acc@1 87.500 (82.379)	Acc@5 100.000 (99.649)
 * Acc@1 82.384 Acc@5 99.655
epoch 114, total time 606.75
Test: [0/750]	Time 1.055 (1.055)	Loss 0.7548 (0.7548)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.127 (0.143)	Loss 0.4439 (0.7455)	Acc@1 84.375 (84.035)	Acc@5 96.875 (94.647)
Test: [200/750]	Time 0.134 (0.137)	Loss 1.3279 (0.6257)	Acc@1 46.875 (83.022)	Acc@5 90.625 (96.098)
Test: [300/750]	Time 0.188 (0.135)	Loss 1.2674 (0.7958)	Acc@1 65.625 (74.336)	Acc@5 90.625 (95.141)
Test: [400/750]	Time 0.117 (0.132)	Loss 0.6096 (0.8376)	Acc@1 81.250 (72.000)	Acc@5 93.750 (94.958)
Test: [500/750]	Time 0.129 (0.132)	Loss 0.5626 (0.8118)	Acc@1 65.625 (73.441)	Acc@5 93.750 (94.704)
Test: [600/750]	Time 0.122 (0.132)	Loss 0.6808 (0.8162)	Acc@1 75.000 (73.227)	Acc@5 93.750 (94.592)
Test: [700/750]	Time 0.136 (0.132)	Loss 0.7918 (0.8039)	Acc@1 65.625 (73.270)	Acc@5 87.500 (94.708)
 * Acc@1 73.521 Acc@5 94.704
==> training...
Epoch: [115][0/875]	Time 2.447 (2.447)	Data 1.708 (1.708)	Loss 1.9597 (1.9597)	Loss@kd 2.1387 (2.1387)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [115][100/875]	Time 0.756 (0.707)	Data 0.007 (0.024)	Loss 1.7134 (1.8675)	Loss@kd 1.9697 (1.9630)	Acc@1 90.625 (82.317)	Acc@5 100.000 (99.814)
Epoch: [115][200/875]	Time 0.681 (0.698)	Data 0.008 (0.016)	Loss 1.8458 (1.8692)	Loss@kd 1.9963 (1.9582)	Acc@1 84.375 (82.307)	Acc@5 100.000 (99.697)
Epoch: [115][300/875]	Time 0.680 (0.694)	Data 0.007 (0.013)	Loss 1.9516 (1.8595)	Loss@kd 2.0711 (1.9564)	Acc@1 84.375 (82.662)	Acc@5 98.438 (99.709)
Epoch: [115][400/875]	Time 0.676 (0.693)	Data 0.007 (0.012)	Loss 1.8819 (1.8631)	Loss@kd 1.9393 (1.9596)	Acc@1 82.812 (82.629)	Acc@5 100.000 (99.708)
Epoch: [115][500/875]	Time 0.677 (0.693)	Data 0.007 (0.011)	Loss 1.7238 (1.8625)	Loss@kd 1.8976 (1.9580)	Acc@1 87.500 (82.541)	Acc@5 100.000 (99.694)
Epoch: [115][600/875]	Time 0.682 (0.692)	Data 0.008 (0.010)	Loss 2.0053 (1.8644)	Loss@kd 1.9507 (1.9603)	Acc@1 76.562 (82.514)	Acc@5 100.000 (99.683)
Epoch: [115][700/875]	Time 0.680 (0.691)	Data 0.007 (0.010)	Loss 1.7936 (1.8667)	Loss@kd 1.9022 (1.9623)	Acc@1 87.500 (82.523)	Acc@5 100.000 (99.655)
Epoch: [115][800/875]	Time 0.760 (0.691)	Data 0.007 (0.010)	Loss 2.0951 (1.8657)	Loss@kd 1.9691 (1.9606)	Acc@1 75.000 (82.434)	Acc@5 98.438 (99.647)
 * Acc@1 82.468 Acc@5 99.646
epoch 115, total time 604.97
Test: [0/750]	Time 1.030 (1.030)	Loss 0.8510 (0.8510)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.171 (0.137)	Loss 0.4313 (0.8007)	Acc@1 84.375 (81.931)	Acc@5 100.000 (94.028)
Test: [200/750]	Time 0.124 (0.130)	Loss 1.3234 (0.6457)	Acc@1 46.875 (82.229)	Acc@5 90.625 (95.864)
Test: [300/750]	Time 0.130 (0.131)	Loss 1.1950 (0.7976)	Acc@1 65.625 (74.169)	Acc@5 93.750 (95.037)
Test: [400/750]	Time 0.126 (0.131)	Loss 0.6047 (0.8323)	Acc@1 81.250 (72.031)	Acc@5 93.750 (94.872)
Test: [500/750]	Time 0.129 (0.131)	Loss 0.5035 (0.8047)	Acc@1 75.000 (73.441)	Acc@5 100.000 (94.642)
Test: [600/750]	Time 0.099 (0.131)	Loss 0.7618 (0.8088)	Acc@1 75.000 (73.237)	Acc@5 93.750 (94.535)
Test: [700/750]	Time 0.128 (0.131)	Loss 0.7625 (0.7991)	Acc@1 65.625 (73.146)	Acc@5 87.500 (94.691)
 * Acc@1 73.417 Acc@5 94.725
==> training...
Epoch: [116][0/875]	Time 2.375 (2.375)	Data 1.639 (1.639)	Loss 1.7828 (1.7828)	Loss@kd 2.1446 (2.1446)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [116][100/875]	Time 0.702 (0.703)	Data 0.008 (0.024)	Loss 1.8464 (1.8611)	Loss@kd 1.9299 (1.9507)	Acc@1 81.250 (82.271)	Acc@5 100.000 (99.629)
Epoch: [116][200/875]	Time 0.665 (0.694)	Data 0.007 (0.016)	Loss 1.7171 (1.8551)	Loss@kd 1.8905 (1.9495)	Acc@1 87.500 (82.478)	Acc@5 100.000 (99.635)
Epoch: [116][300/875]	Time 0.682 (0.690)	Data 0.007 (0.013)	Loss 2.0161 (1.8641)	Loss@kd 2.0698 (1.9550)	Acc@1 79.688 (82.148)	Acc@5 100.000 (99.652)
Epoch: [116][400/875]	Time 0.680 (0.689)	Data 0.007 (0.011)	Loss 1.6572 (1.8625)	Loss@kd 1.8635 (1.9553)	Acc@1 85.938 (82.224)	Acc@5 100.000 (99.634)
Epoch: [116][500/875]	Time 0.778 (0.689)	Data 0.008 (0.011)	Loss 1.7269 (1.8613)	Loss@kd 1.8986 (1.9554)	Acc@1 84.375 (82.232)	Acc@5 100.000 (99.626)
Epoch: [116][600/875]	Time 0.686 (0.688)	Data 0.007 (0.010)	Loss 1.8964 (1.8631)	Loss@kd 1.9526 (1.9600)	Acc@1 84.375 (82.381)	Acc@5 100.000 (99.618)
Epoch: [116][700/875]	Time 0.687 (0.688)	Data 0.007 (0.010)	Loss 1.9458 (1.8620)	Loss@kd 2.0135 (1.9595)	Acc@1 81.250 (82.418)	Acc@5 100.000 (99.619)
Epoch: [116][800/875]	Time 0.683 (0.688)	Data 0.007 (0.009)	Loss 1.9122 (1.8630)	Loss@kd 1.9476 (1.9592)	Acc@1 81.250 (82.374)	Acc@5 100.000 (99.627)
 * Acc@1 82.384 Acc@5 99.627
epoch 116, total time 602.89
Test: [0/750]	Time 1.034 (1.034)	Loss 0.4923 (0.4923)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.127 (0.138)	Loss 0.3752 (0.7122)	Acc@1 81.250 (85.118)	Acc@5 100.000 (94.802)
Test: [200/750]	Time 0.120 (0.134)	Loss 1.3024 (0.5938)	Acc@1 50.000 (84.095)	Acc@5 90.625 (96.191)
Test: [300/750]	Time 0.141 (0.131)	Loss 1.2998 (0.7628)	Acc@1 62.500 (75.467)	Acc@5 93.750 (95.349)
Test: [400/750]	Time 0.131 (0.129)	Loss 0.6054 (0.8091)	Acc@1 78.125 (73.192)	Acc@5 96.875 (95.137)
Test: [500/750]	Time 0.088 (0.128)	Loss 0.5246 (0.7850)	Acc@1 65.625 (74.476)	Acc@5 96.875 (94.860)
Test: [600/750]	Time 0.099 (0.128)	Loss 0.8051 (0.7974)	Acc@1 75.000 (73.970)	Acc@5 93.750 (94.707)
Test: [700/750]	Time 0.097 (0.127)	Loss 0.7298 (0.7936)	Acc@1 65.625 (73.725)	Acc@5 87.500 (94.780)
 * Acc@1 73.963 Acc@5 94.829
==> training...
Epoch: [117][0/875]	Time 2.272 (2.272)	Data 1.565 (1.565)	Loss 1.8128 (1.8128)	Loss@kd 1.9752 (1.9752)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [117][100/875]	Time 0.680 (0.702)	Data 0.007 (0.023)	Loss 1.9565 (1.8710)	Loss@kd 1.9466 (1.9704)	Acc@1 71.875 (82.178)	Acc@5 100.000 (99.582)
Epoch: [117][200/875]	Time 0.680 (0.694)	Data 0.007 (0.015)	Loss 2.0535 (1.8626)	Loss@kd 2.2772 (1.9661)	Acc@1 82.812 (82.307)	Acc@5 100.000 (99.658)
Epoch: [117][300/875]	Time 0.683 (0.691)	Data 0.007 (0.013)	Loss 1.7208 (1.8620)	Loss@kd 1.9410 (1.9596)	Acc@1 85.938 (82.008)	Acc@5 100.000 (99.668)
Epoch: [117][400/875]	Time 0.686 (0.691)	Data 0.007 (0.011)	Loss 1.7613 (1.8650)	Loss@kd 1.8956 (1.9572)	Acc@1 85.938 (82.072)	Acc@5 100.000 (99.661)
Epoch: [117][500/875]	Time 0.667 (0.690)	Data 0.007 (0.011)	Loss 1.6760 (1.8653)	Loss@kd 1.8861 (1.9566)	Acc@1 85.938 (82.198)	Acc@5 100.000 (99.660)
Epoch: [117][600/875]	Time 0.679 (0.689)	Data 0.007 (0.010)	Loss 1.9224 (1.8631)	Loss@kd 2.0563 (1.9568)	Acc@1 79.688 (82.371)	Acc@5 100.000 (99.662)
Epoch: [117][700/875]	Time 0.677 (0.689)	Data 0.007 (0.010)	Loss 1.9320 (1.8646)	Loss@kd 1.9849 (1.9611)	Acc@1 78.125 (82.396)	Acc@5 100.000 (99.675)
Epoch: [117][800/875]	Time 0.664 (0.689)	Data 0.007 (0.009)	Loss 1.8376 (1.8640)	Loss@kd 1.9848 (1.9601)	Acc@1 79.688 (82.376)	Acc@5 100.000 (99.670)
 * Acc@1 82.350 Acc@5 99.673
epoch 117, total time 603.25
Test: [0/750]	Time 1.154 (1.154)	Loss 1.1260 (1.1260)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.124 (0.143)	Loss 0.3911 (0.8565)	Acc@1 81.250 (81.343)	Acc@5 100.000 (93.688)
Test: [200/750]	Time 0.125 (0.132)	Loss 1.2612 (0.6685)	Acc@1 50.000 (82.307)	Acc@5 90.625 (95.600)
Test: [300/750]	Time 0.120 (0.128)	Loss 1.2977 (0.8125)	Acc@1 62.500 (74.408)	Acc@5 93.750 (94.799)
Test: [400/750]	Time 0.105 (0.126)	Loss 0.5993 (0.8573)	Acc@1 78.125 (71.984)	Acc@5 90.625 (94.560)
Test: [500/750]	Time 0.182 (0.125)	Loss 0.4953 (0.8157)	Acc@1 75.000 (73.728)	Acc@5 96.875 (94.505)
Test: [600/750]	Time 0.117 (0.124)	Loss 0.7801 (0.8175)	Acc@1 75.000 (73.575)	Acc@5 93.750 (94.457)
Test: [700/750]	Time 0.120 (0.124)	Loss 0.7852 (0.8093)	Acc@1 68.750 (73.431)	Acc@5 87.500 (94.584)
 * Acc@1 73.679 Acc@5 94.567
==> training...
Epoch: [118][0/875]	Time 2.331 (2.331)	Data 1.553 (1.553)	Loss 1.9953 (1.9953)	Loss@kd 1.9700 (1.9700)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [118][100/875]	Time 0.751 (0.711)	Data 0.007 (0.023)	Loss 1.6952 (1.8587)	Loss@kd 1.8937 (1.9463)	Acc@1 89.062 (82.457)	Acc@5 100.000 (99.551)
Epoch: [118][200/875]	Time 0.798 (0.701)	Data 0.007 (0.015)	Loss 2.1516 (1.8722)	Loss@kd 2.3727 (1.9662)	Acc@1 81.250 (82.362)	Acc@5 100.000 (99.510)
Epoch: [118][300/875]	Time 0.757 (0.698)	Data 0.007 (0.013)	Loss 1.8836 (1.8643)	Loss@kd 2.0221 (1.9599)	Acc@1 82.812 (82.480)	Acc@5 100.000 (99.533)
Epoch: [118][400/875]	Time 0.768 (0.696)	Data 0.007 (0.011)	Loss 1.8054 (1.8707)	Loss@kd 1.9176 (1.9653)	Acc@1 84.375 (82.399)	Acc@5 100.000 (99.571)
Epoch: [118][500/875]	Time 0.737 (0.694)	Data 0.007 (0.010)	Loss 1.9159 (1.8669)	Loss@kd 2.0131 (1.9617)	Acc@1 79.688 (82.420)	Acc@5 100.000 (99.591)
Epoch: [118][600/875]	Time 0.728 (0.693)	Data 0.005 (0.010)	Loss 1.7239 (1.8673)	Loss@kd 1.8438 (1.9639)	Acc@1 82.812 (82.384)	Acc@5 100.000 (99.610)
Epoch: [118][700/875]	Time 0.777 (0.692)	Data 0.007 (0.010)	Loss 1.7847 (1.8668)	Loss@kd 1.9847 (1.9624)	Acc@1 84.375 (82.349)	Acc@5 100.000 (99.641)
Epoch: [118][800/875]	Time 0.780 (0.692)	Data 0.008 (0.009)	Loss 2.0703 (1.8681)	Loss@kd 2.2024 (1.9635)	Acc@1 81.250 (82.313)	Acc@5 100.000 (99.627)
 * Acc@1 82.346 Acc@5 99.630
epoch 118, total time 605.29
Test: [0/750]	Time 1.029 (1.029)	Loss 0.5589 (0.5589)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.120 (0.137)	Loss 0.4241 (0.7221)	Acc@1 81.250 (84.994)	Acc@5 100.000 (95.142)
Test: [200/750]	Time 0.119 (0.129)	Loss 1.3142 (0.6093)	Acc@1 40.625 (83.504)	Acc@5 90.625 (96.331)
Test: [300/750]	Time 0.105 (0.127)	Loss 1.2832 (0.7823)	Acc@1 62.500 (74.709)	Acc@5 90.625 (95.297)
Test: [400/750]	Time 0.113 (0.125)	Loss 0.5950 (0.8265)	Acc@1 81.250 (72.498)	Acc@5 93.750 (95.051)
Test: [500/750]	Time 0.116 (0.125)	Loss 0.5545 (0.7955)	Acc@1 65.625 (74.014)	Acc@5 93.750 (94.867)
Test: [600/750]	Time 0.128 (0.124)	Loss 0.7389 (0.8044)	Acc@1 75.000 (73.580)	Acc@5 93.750 (94.717)
Test: [700/750]	Time 0.125 (0.124)	Loss 0.7383 (0.7962)	Acc@1 65.625 (73.582)	Acc@5 90.625 (94.856)
 * Acc@1 73.808 Acc@5 94.875
==> training...
Epoch: [119][0/875]	Time 2.373 (2.373)	Data 1.643 (1.643)	Loss 1.7659 (1.7659)	Loss@kd 2.0196 (2.0196)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [119][100/875]	Time 0.681 (0.705)	Data 0.007 (0.024)	Loss 1.8190 (1.8589)	Loss@kd 2.0523 (1.9592)	Acc@1 89.062 (82.302)	Acc@5 100.000 (99.675)
Epoch: [119][200/875]	Time 0.750 (0.694)	Data 0.008 (0.015)	Loss 1.7798 (1.8484)	Loss@kd 1.8811 (1.9570)	Acc@1 85.938 (82.688)	Acc@5 100.000 (99.689)
Epoch: [119][300/875]	Time 0.652 (0.690)	Data 0.007 (0.013)	Loss 2.0184 (1.8588)	Loss@kd 2.4534 (1.9625)	Acc@1 89.062 (82.631)	Acc@5 100.000 (99.699)
Epoch: [119][400/875]	Time 0.675 (0.689)	Data 0.007 (0.011)	Loss 1.8245 (1.8643)	Loss@kd 1.9131 (1.9659)	Acc@1 78.125 (82.532)	Acc@5 100.000 (99.684)
Epoch: [119][500/875]	Time 0.676 (0.687)	Data 0.007 (0.011)	Loss 1.9987 (1.8641)	Loss@kd 1.9630 (1.9638)	Acc@1 78.125 (82.441)	Acc@5 100.000 (99.673)
Epoch: [119][600/875]	Time 0.679 (0.686)	Data 0.008 (0.010)	Loss 1.9888 (1.8681)	Loss@kd 1.9602 (1.9688)	Acc@1 81.250 (82.490)	Acc@5 95.312 (99.652)
Epoch: [119][700/875]	Time 0.675 (0.686)	Data 0.007 (0.010)	Loss 2.0317 (1.8657)	Loss@kd 1.9251 (1.9646)	Acc@1 76.562 (82.438)	Acc@5 98.438 (99.646)
Epoch: [119][800/875]	Time 0.678 (0.686)	Data 0.007 (0.009)	Loss 1.8732 (1.8674)	Loss@kd 1.9517 (1.9634)	Acc@1 78.125 (82.358)	Acc@5 100.000 (99.639)
 * Acc@1 82.430 Acc@5 99.648
epoch 119, total time 600.64
Test: [0/750]	Time 0.933 (0.933)	Loss 0.7307 (0.7307)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.133 (0.144)	Loss 0.4003 (0.7459)	Acc@1 84.375 (84.406)	Acc@5 96.875 (94.369)
Test: [200/750]	Time 0.125 (0.136)	Loss 1.3460 (0.6159)	Acc@1 46.875 (83.582)	Acc@5 87.500 (95.927)
Test: [300/750]	Time 0.124 (0.132)	Loss 1.3122 (0.7910)	Acc@1 65.625 (74.574)	Acc@5 90.625 (94.819)
Test: [400/750]	Time 0.121 (0.129)	Loss 0.5425 (0.8276)	Acc@1 87.500 (72.608)	Acc@5 96.875 (94.755)
Test: [500/750]	Time 0.082 (0.128)	Loss 0.5778 (0.7922)	Acc@1 68.750 (74.227)	Acc@5 96.875 (94.648)
Test: [600/750]	Time 0.118 (0.126)	Loss 0.6969 (0.8022)	Acc@1 75.000 (73.851)	Acc@5 93.750 (94.551)
Test: [700/750]	Time 0.194 (0.125)	Loss 0.7997 (0.7969)	Acc@1 65.625 (73.743)	Acc@5 87.500 (94.655)
 * Acc@1 73.892 Acc@5 94.662
==> training...
Epoch: [120][0/875]	Time 2.304 (2.304)	Data 1.542 (1.542)	Loss 1.8121 (1.8121)	Loss@kd 1.8826 (1.8826)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [120][100/875]	Time 0.674 (0.702)	Data 0.007 (0.022)	Loss 1.6977 (1.8592)	Loss@kd 1.9037 (1.9439)	Acc@1 89.062 (82.642)	Acc@5 100.000 (99.613)
Epoch: [120][200/875]	Time 0.753 (0.693)	Data 0.007 (0.015)	Loss 1.7641 (1.8592)	Loss@kd 1.8804 (1.9510)	Acc@1 87.500 (82.929)	Acc@5 98.438 (99.635)
Epoch: [120][300/875]	Time 0.683 (0.690)	Data 0.007 (0.012)	Loss 1.8704 (1.8663)	Loss@kd 2.0129 (1.9591)	Acc@1 87.500 (82.709)	Acc@5 98.438 (99.647)
Epoch: [120][400/875]	Time 0.668 (0.688)	Data 0.007 (0.011)	Loss 1.9231 (1.8689)	Loss@kd 1.9643 (1.9583)	Acc@1 79.688 (82.493)	Acc@5 100.000 (99.669)
Epoch: [120][500/875]	Time 0.686 (0.687)	Data 0.007 (0.010)	Loss 1.8408 (1.8667)	Loss@kd 2.0113 (1.9616)	Acc@1 84.375 (82.663)	Acc@5 100.000 (99.669)
Epoch: [120][600/875]	Time 0.675 (0.686)	Data 0.008 (0.010)	Loss 1.7196 (1.8649)	Loss@kd 1.9103 (1.9613)	Acc@1 82.812 (82.662)	Acc@5 100.000 (99.659)
Epoch: [120][700/875]	Time 0.678 (0.686)	Data 0.007 (0.009)	Loss 1.6370 (1.8641)	Loss@kd 1.7592 (1.9598)	Acc@1 84.375 (82.681)	Acc@5 100.000 (99.643)
Epoch: [120][800/875]	Time 0.683 (0.686)	Data 0.007 (0.009)	Loss 1.7490 (1.8665)	Loss@kd 1.8766 (1.9650)	Acc@1 81.250 (82.664)	Acc@5 100.000 (99.639)
 * Acc@1 82.588 Acc@5 99.637
epoch 120, total time 600.16
Test: [0/750]	Time 1.014 (1.014)	Loss 0.7361 (0.7361)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.095 (0.135)	Loss 0.3959 (0.7814)	Acc@1 81.250 (83.292)	Acc@5 100.000 (94.338)
Test: [200/750]	Time 0.110 (0.130)	Loss 1.2550 (0.6239)	Acc@1 43.750 (83.489)	Acc@5 90.625 (95.973)
Test: [300/750]	Time 0.115 (0.127)	Loss 1.2521 (0.7743)	Acc@1 59.375 (75.311)	Acc@5 93.750 (95.193)
Test: [400/750]	Time 0.164 (0.126)	Loss 0.5463 (0.8221)	Acc@1 84.375 (72.740)	Acc@5 90.625 (94.911)
Test: [500/750]	Time 0.124 (0.125)	Loss 0.5030 (0.7871)	Acc@1 78.125 (74.301)	Acc@5 96.875 (94.810)
Test: [600/750]	Time 0.107 (0.125)	Loss 0.7796 (0.7942)	Acc@1 75.000 (74.033)	Acc@5 93.750 (94.707)
Test: [700/750]	Time 0.115 (0.125)	Loss 0.8622 (0.7944)	Acc@1 65.625 (73.689)	Acc@5 87.500 (94.735)
 * Acc@1 73.767 Acc@5 94.692
==> Saving...
best accuracy: tensor(74.0708, device='cuda:0')
