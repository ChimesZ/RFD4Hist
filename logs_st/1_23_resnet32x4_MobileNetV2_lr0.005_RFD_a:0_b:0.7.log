==> loading teacher model
==> done
6 0.5
Test: [0/750]	Time 23.835 (23.835)	Loss 0.4924 (0.4924)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.162 (0.321)	Loss 0.4931 (0.7024)	Acc@1 78.125 (84.097)	Acc@5 93.750 (93.998)
Test: [200/750]	Time 0.068 (0.202)	Loss 1.3251 (0.6071)	Acc@1 46.875 (82.789)	Acc@5 90.625 (95.631)
Test: [300/750]	Time 0.076 (0.162)	Loss 1.1155 (0.7770)	Acc@1 71.875 (74.055)	Acc@5 93.750 (95.141)
Test: [400/750]	Time 0.124 (0.143)	Loss 0.5847 (0.8215)	Acc@1 84.375 (71.891)	Acc@5 93.750 (94.701)
Test: [500/750]	Time 0.079 (0.130)	Loss 0.4380 (0.7850)	Acc@1 84.375 (73.696)	Acc@5 100.000 (94.698)
Test: [600/750]	Time 0.187 (0.123)	Loss 0.8076 (0.7933)	Acc@1 75.000 (73.487)	Acc@5 90.625 (94.530)
Test: [700/750]	Time 0.081 (0.117)	Loss 0.9263 (0.7904)	Acc@1 56.250 (73.226)	Acc@5 96.875 (94.651)
 * Acc@1 73.362 Acc@5 94.612
teacher accuracy:  tensor(73.3625, device='cuda:1')
==> training...
Epoch: [1][0/875]	Time 2.728 (2.728)	Data 1.332 (1.332)	Loss 17.5387 (17.5387)	Loss@kd 21.6097 (21.6097)	Acc@1 6.250 (6.250)	Acc@5 64.062 (64.062)
Epoch: [1][100/875]	Time 0.413 (0.473)	Data 0.005 (0.020)	Loss 8.7650 (15.5277)	Loss@kd 6.3800 (13.2516)	Acc@1 23.438 (22.803)	Acc@5 71.875 (72.772)
Epoch: [1][200/875]	Time 0.412 (0.463)	Data 0.007 (0.013)	Loss 5.3174 (11.2238)	Loss@kd 4.6722 (9.4541)	Acc@1 28.125 (25.536)	Acc@5 87.500 (75.972)
Epoch: [1][300/875]	Time 0.432 (0.460)	Data 0.007 (0.011)	Loss 4.7668 (9.2077)	Loss@kd 4.5339 (7.9210)	Acc@1 37.500 (28.753)	Acc@5 92.188 (79.812)
Epoch: [1][400/875]	Time 0.551 (0.458)	Data 0.006 (0.010)	Loss 5.0390 (8.1439)	Loss@kd 4.5586 (7.1248)	Acc@1 29.688 (30.884)	Acc@5 81.250 (82.489)
Epoch: [1][500/875]	Time 0.466 (0.457)	Data 0.007 (0.009)	Loss 4.9614 (7.4868)	Loss@kd 4.7475 (6.6382)	Acc@1 35.938 (32.728)	Acc@5 89.062 (84.334)
Epoch: [1][600/875]	Time 0.439 (0.457)	Data 0.007 (0.009)	Loss 4.4264 (7.0181)	Loss@kd 4.3441 (6.2804)	Acc@1 45.312 (34.014)	Acc@5 92.188 (85.756)
Epoch: [1][700/875]	Time 0.448 (0.456)	Data 0.010 (0.009)	Loss 4.7558 (6.6781)	Loss@kd 4.4798 (6.0257)	Acc@1 45.312 (35.200)	Acc@5 89.062 (86.834)
Epoch: [1][800/875]	Time 0.410 (0.455)	Data 0.007 (0.008)	Loss 4.4230 (6.4207)	Loss@kd 4.3967 (5.8354)	Acc@1 46.875 (36.189)	Acc@5 96.875 (87.730)
 * Acc@1 36.859 Acc@5 88.259
epoch 1, total time 396.31
Test: [0/750]	Time 1.212 (1.212)	Loss 1.8921 (1.8921)	Acc@1 15.625 (15.625)	Acc@5 78.125 (78.125)
Test: [100/750]	Time 0.104 (0.118)	Loss 0.5994 (1.8667)	Acc@1 78.125 (16.770)	Acc@5 100.000 (78.682)
Test: [200/750]	Time 0.109 (0.112)	Loss 1.9547 (1.3184)	Acc@1 15.625 (44.621)	Acc@5 81.250 (87.018)
Test: [300/750]	Time 0.101 (0.110)	Loss 1.8585 (1.4525)	Acc@1 15.625 (39.794)	Acc@5 71.875 (84.292)
Test: [400/750]	Time 0.090 (0.109)	Loss 1.7706 (1.5353)	Acc@1 25.000 (34.913)	Acc@5 46.875 (80.946)
Test: [500/750]	Time 0.160 (0.108)	Loss 1.3203 (1.5140)	Acc@1 50.000 (37.812)	Acc@5 87.500 (78.780)
Test: [600/750]	Time 0.088 (0.107)	Loss 1.3075 (1.4744)	Acc@1 34.375 (40.074)	Acc@5 87.500 (80.044)
Test: [700/750]	Time 0.105 (0.107)	Loss 1.5912 (1.4630)	Acc@1 43.750 (40.322)	Acc@5 68.750 (80.978)
 * Acc@1 40.537 Acc@5 80.725
saving the best model!
==> training...
Epoch: [2][0/875]	Time 1.828 (1.828)	Data 1.262 (1.262)	Loss 4.6567 (4.6567)	Loss@kd 4.6337 (4.6337)	Acc@1 45.312 (45.312)	Acc@5 92.188 (92.188)
Epoch: [2][100/875]	Time 0.408 (0.461)	Data 0.007 (0.019)	Loss 4.5155 (4.5895)	Loss@kd 4.4099 (4.4886)	Acc@1 51.562 (43.657)	Acc@5 95.312 (94.384)
Epoch: [2][200/875]	Time 0.470 (0.456)	Data 0.007 (0.013)	Loss 4.1328 (4.5279)	Loss@kd 4.0455 (4.4303)	Acc@1 54.688 (44.644)	Acc@5 90.625 (94.325)
Epoch: [2][300/875]	Time 0.482 (0.454)	Data 0.006 (0.011)	Loss 4.6293 (4.5109)	Loss@kd 4.4287 (4.4113)	Acc@1 32.812 (44.487)	Acc@5 96.875 (94.342)
Epoch: [2][400/875]	Time 0.450 (0.453)	Data 0.007 (0.010)	Loss 4.9720 (4.5032)	Loss@kd 5.0779 (4.4098)	Acc@1 42.188 (44.798)	Acc@5 93.750 (94.529)
Epoch: [2][500/875]	Time 0.438 (0.452)	Data 0.007 (0.010)	Loss 4.4163 (4.4925)	Loss@kd 4.2680 (4.4026)	Acc@1 50.000 (45.263)	Acc@5 93.750 (94.567)
Epoch: [2][600/875]	Time 0.419 (0.451)	Data 0.007 (0.009)	Loss 4.2597 (4.4758)	Loss@kd 4.2668 (4.3857)	Acc@1 46.875 (45.437)	Acc@5 98.438 (94.582)
Epoch: [2][700/875]	Time 0.425 (0.451)	Data 0.008 (0.009)	Loss 3.9775 (4.4724)	Loss@kd 4.0672 (4.3914)	Acc@1 50.000 (45.685)	Acc@5 95.312 (94.675)
Epoch: [2][800/875]	Time 0.442 (0.450)	Data 0.005 (0.009)	Loss 5.0448 (4.4573)	Loss@kd 5.0630 (4.3788)	Acc@1 37.500 (46.030)	Acc@5 93.750 (94.735)
 * Acc@1 46.243 Acc@5 94.816
epoch 2, total time 394.40
Test: [0/750]	Time 0.721 (0.721)	Loss 0.6761 (0.6761)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.103 (0.114)	Loss 0.4624 (0.5364)	Acc@1 90.625 (84.406)	Acc@5 96.875 (89.295)
Test: [200/750]	Time 0.103 (0.109)	Loss 2.2442 (0.5629)	Acc@1 15.625 (82.603)	Acc@5 68.750 (91.822)
Test: [300/750]	Time 0.112 (0.109)	Loss 1.9501 (1.0293)	Acc@1 12.500 (62.542)	Acc@5 71.875 (84.365)
Test: [400/750]	Time 0.112 (0.108)	Loss 1.7082 (1.2555)	Acc@1 21.875 (51.551)	Acc@5 62.500 (81.336)
Test: [500/750]	Time 0.104 (0.107)	Loss 1.3063 (1.3152)	Acc@1 46.875 (49.033)	Acc@5 87.500 (79.996)
Test: [600/750]	Time 0.095 (0.107)	Loss 1.4367 (1.3297)	Acc@1 25.000 (48.430)	Acc@5 96.875 (81.266)
Test: [700/750]	Time 0.115 (0.107)	Loss 1.5844 (1.3489)	Acc@1 50.000 (47.557)	Acc@5 75.000 (82.275)
 * Acc@1 47.800 Acc@5 82.242
saving the best model!
==> training...
Epoch: [3][0/875]	Time 1.860 (1.860)	Data 1.275 (1.275)	Loss 7.2597 (7.2597)	Loss@kd 8.5314 (8.5314)	Acc@1 53.125 (53.125)	Acc@5 95.312 (95.312)
Epoch: [3][100/875]	Time 0.419 (0.442)	Data 0.007 (0.019)	Loss 4.4692 (4.3646)	Loss@kd 4.2825 (4.3481)	Acc@1 51.562 (48.685)	Acc@5 90.625 (95.498)
Epoch: [3][200/875]	Time 0.426 (0.436)	Data 0.006 (0.013)	Loss 4.3390 (4.3360)	Loss@kd 4.2792 (4.2972)	Acc@1 48.438 (48.414)	Acc@5 95.312 (95.546)
Epoch: [3][300/875]	Time 0.421 (0.437)	Data 0.008 (0.011)	Loss 4.0684 (4.3434)	Loss@kd 3.8976 (4.3005)	Acc@1 42.188 (48.199)	Acc@5 92.188 (95.437)
Epoch: [3][400/875]	Time 0.410 (0.441)	Data 0.007 (0.010)	Loss 4.1319 (4.3301)	Loss@kd 4.2192 (4.2878)	Acc@1 45.312 (48.465)	Acc@5 100.000 (95.566)
Epoch: [3][500/875]	Time 0.416 (0.443)	Data 0.007 (0.009)	Loss 4.2103 (4.3179)	Loss@kd 4.0199 (4.2713)	Acc@1 45.312 (48.512)	Acc@5 92.188 (95.518)
Epoch: [3][600/875]	Time 0.424 (0.446)	Data 0.007 (0.009)	Loss 4.4856 (4.3230)	Loss@kd 4.0886 (4.2778)	Acc@1 43.750 (48.521)	Acc@5 87.500 (95.500)
Epoch: [3][700/875]	Time 0.451 (0.447)	Data 0.005 (0.009)	Loss 4.7798 (4.3176)	Loss@kd 4.8971 (4.2703)	Acc@1 50.000 (48.594)	Acc@5 96.875 (95.506)
Epoch: [3][800/875]	Time 0.556 (0.448)	Data 0.007 (0.008)	Loss 4.3413 (4.3153)	Loss@kd 4.3256 (4.2706)	Acc@1 53.125 (48.636)	Acc@5 96.875 (95.506)
 * Acc@1 48.638 Acc@5 95.521
epoch 3, total time 392.38
Test: [0/750]	Time 0.862 (0.862)	Loss 0.5642 (0.5642)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.110 (0.112)	Loss 0.5549 (0.5281)	Acc@1 84.375 (83.385)	Acc@5 96.875 (89.202)
Test: [200/750]	Time 0.097 (0.108)	Loss 1.9104 (0.6171)	Acc@1 28.125 (79.478)	Acc@5 68.750 (91.418)
Test: [300/750]	Time 0.159 (0.107)	Loss 1.7940 (1.0074)	Acc@1 18.750 (61.005)	Acc@5 81.250 (86.026)
Test: [400/750]	Time 0.107 (0.106)	Loss 1.5845 (1.1927)	Acc@1 18.750 (51.185)	Acc@5 81.250 (85.162)
Test: [500/750]	Time 0.104 (0.105)	Loss 1.1439 (1.2355)	Acc@1 68.750 (49.401)	Acc@5 78.125 (84.169)
Test: [600/750]	Time 0.115 (0.105)	Loss 1.3421 (1.2398)	Acc@1 37.500 (50.229)	Acc@5 87.500 (84.619)
Test: [700/750]	Time 0.076 (0.105)	Loss 1.4390 (1.2493)	Acc@1 53.125 (50.160)	Acc@5 75.000 (85.102)
 * Acc@1 51.138 Acc@5 84.925
saving the best model!
==> training...
Epoch: [4][0/875]	Time 1.866 (1.866)	Data 1.367 (1.367)	Loss 4.3567 (4.3567)	Loss@kd 4.1015 (4.1015)	Acc@1 39.062 (39.062)	Acc@5 93.750 (93.750)
Epoch: [4][100/875]	Time 0.478 (0.468)	Data 0.007 (0.020)	Loss 4.0567 (4.2997)	Loss@kd 3.9318 (4.2667)	Acc@1 48.438 (49.056)	Acc@5 96.875 (95.931)
Epoch: [4][200/875]	Time 0.411 (0.460)	Data 0.006 (0.014)	Loss 4.2646 (4.2581)	Loss@kd 4.1186 (4.2290)	Acc@1 40.625 (49.876)	Acc@5 93.750 (95.826)
Epoch: [4][300/875]	Time 0.437 (0.457)	Data 0.006 (0.012)	Loss 4.2618 (4.2429)	Loss@kd 4.2142 (4.2163)	Acc@1 45.312 (49.948)	Acc@5 95.312 (96.003)
Epoch: [4][400/875]	Time 0.403 (0.451)	Data 0.007 (0.010)	Loss 4.1487 (4.2398)	Loss@kd 3.9646 (4.2117)	Acc@1 45.312 (50.031)	Acc@5 96.875 (95.975)
Epoch: [4][500/875]	Time 0.424 (0.446)	Data 0.010 (0.010)	Loss 4.9256 (4.2290)	Loss@kd 5.2093 (4.1979)	Acc@1 60.938 (50.056)	Acc@5 90.625 (95.936)
Epoch: [4][600/875]	Time 0.423 (0.445)	Data 0.007 (0.009)	Loss 3.9898 (4.2192)	Loss@kd 4.0637 (4.1896)	Acc@1 56.250 (50.130)	Acc@5 96.875 (95.955)
Epoch: [4][700/875]	Time 0.425 (0.445)	Data 0.007 (0.009)	Loss 4.2977 (4.2160)	Loss@kd 4.1952 (4.1873)	Acc@1 45.312 (50.292)	Acc@5 95.312 (95.946)
Epoch: [4][800/875]	Time 0.450 (0.446)	Data 0.007 (0.009)	Loss 4.3326 (4.2146)	Loss@kd 4.3015 (4.1886)	Acc@1 40.625 (50.371)	Acc@5 98.438 (95.954)
 * Acc@1 50.402 Acc@5 95.948
epoch 4, total time 391.11
Test: [0/750]	Time 0.816 (0.816)	Loss 0.7359 (0.7359)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.108 (0.113)	Loss 0.3936 (0.7392)	Acc@1 90.625 (79.394)	Acc@5 96.875 (86.448)
Test: [200/750]	Time 0.106 (0.109)	Loss 1.8367 (0.6591)	Acc@1 28.125 (79.509)	Acc@5 78.125 (90.718)
Test: [300/750]	Time 0.094 (0.106)	Loss 1.7230 (0.9975)	Acc@1 25.000 (62.770)	Acc@5 81.250 (87.583)
Test: [400/750]	Time 0.098 (0.106)	Loss 1.3699 (1.1535)	Acc@1 34.375 (53.624)	Acc@5 81.250 (86.814)
Test: [500/750]	Time 0.098 (0.105)	Loss 1.2847 (1.1763)	Acc@1 62.500 (52.957)	Acc@5 78.125 (85.560)
Test: [600/750]	Time 0.093 (0.106)	Loss 1.3119 (1.1966)	Acc@1 43.750 (52.839)	Acc@5 90.625 (85.602)
Test: [700/750]	Time 0.091 (0.105)	Loss 1.3963 (1.2181)	Acc@1 46.875 (52.118)	Acc@5 81.250 (86.065)
 * Acc@1 52.717 Acc@5 85.846
saving the best model!
==> training...
Epoch: [5][0/875]	Time 1.822 (1.822)	Data 1.403 (1.403)	Loss 4.0205 (4.0205)	Loss@kd 3.9998 (3.9998)	Acc@1 53.125 (53.125)	Acc@5 93.750 (93.750)
Epoch: [5][100/875]	Time 0.435 (0.467)	Data 0.007 (0.021)	Loss 3.9419 (4.1399)	Loss@kd 4.1239 (4.1009)	Acc@1 60.938 (50.959)	Acc@5 100.000 (95.746)
Epoch: [5][200/875]	Time 0.426 (0.460)	Data 0.007 (0.014)	Loss 3.9630 (4.1736)	Loss@kd 3.8919 (4.1532)	Acc@1 48.438 (50.878)	Acc@5 96.875 (96.067)
Epoch: [5][300/875]	Time 0.413 (0.457)	Data 0.005 (0.012)	Loss 3.7820 (4.1634)	Loss@kd 3.8843 (4.1395)	Acc@1 59.375 (51.428)	Acc@5 95.312 (96.013)
Epoch: [5][400/875]	Time 0.491 (0.456)	Data 0.006 (0.010)	Loss 3.8278 (4.1712)	Loss@kd 3.8070 (4.1570)	Acc@1 54.688 (51.594)	Acc@5 100.000 (96.092)
Epoch: [5][500/875]	Time 0.463 (0.455)	Data 0.006 (0.010)	Loss 4.2862 (4.1697)	Loss@kd 4.3719 (4.1482)	Acc@1 54.688 (51.354)	Acc@5 95.312 (96.073)
Epoch: [5][600/875]	Time 0.449 (0.454)	Data 0.007 (0.009)	Loss 3.8414 (4.1543)	Loss@kd 3.8809 (4.1326)	Acc@1 57.812 (51.529)	Acc@5 98.438 (96.113)
Epoch: [5][700/875]	Time 0.408 (0.451)	Data 0.007 (0.009)	Loss 3.8164 (4.1427)	Loss@kd 3.9499 (4.1158)	Acc@1 62.500 (51.473)	Acc@5 96.875 (96.057)
Epoch: [5][800/875]	Time 0.416 (0.448)	Data 0.005 (0.009)	Loss 4.3859 (4.1436)	Loss@kd 4.4641 (4.1174)	Acc@1 51.562 (51.447)	Acc@5 96.875 (96.103)
 * Acc@1 51.448 Acc@5 96.130
epoch 5, total time 391.18
Test: [0/750]	Time 0.830 (0.830)	Loss 0.8078 (0.8078)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.152 (0.115)	Loss 0.8462 (0.6910)	Acc@1 62.500 (78.558)	Acc@5 93.750 (86.634)
Test: [200/750]	Time 0.114 (0.109)	Loss 1.7504 (0.7774)	Acc@1 25.000 (71.440)	Acc@5 87.500 (90.485)
Test: [300/750]	Time 0.110 (0.107)	Loss 1.6159 (1.0324)	Acc@1 18.750 (60.195)	Acc@5 90.625 (89.005)
Test: [400/750]	Time 0.093 (0.106)	Loss 1.5023 (1.1821)	Acc@1 31.250 (50.499)	Acc@5 78.125 (87.866)
Test: [500/750]	Time 0.090 (0.106)	Loss 1.3113 (1.2330)	Acc@1 56.250 (48.752)	Acc@5 75.000 (85.485)
Test: [600/750]	Time 0.077 (0.106)	Loss 0.9230 (1.2189)	Acc@1 71.875 (50.879)	Acc@5 93.750 (85.550)
Test: [700/750]	Time 0.093 (0.105)	Loss 1.4485 (1.1999)	Acc@1 53.125 (52.679)	Acc@5 78.125 (86.047)
 * Acc@1 53.325 Acc@5 85.904
saving the best model!
==> training...
Epoch: [6][0/875]	Time 1.802 (1.802)	Data 1.344 (1.344)	Loss 3.9487 (3.9487)	Loss@kd 3.9100 (3.9100)	Acc@1 48.438 (48.438)	Acc@5 95.312 (95.312)
Epoch: [6][100/875]	Time 0.429 (0.460)	Data 0.007 (0.020)	Loss 4.2091 (4.0618)	Loss@kd 4.2420 (4.0108)	Acc@1 42.188 (52.305)	Acc@5 96.875 (96.380)
Epoch: [6][200/875]	Time 0.457 (0.455)	Data 0.007 (0.013)	Loss 4.0154 (4.0821)	Loss@kd 3.9435 (4.0482)	Acc@1 59.375 (52.519)	Acc@5 95.312 (96.183)
Epoch: [6][300/875]	Time 0.403 (0.453)	Data 0.007 (0.011)	Loss 4.9496 (4.0876)	Loss@kd 5.0566 (4.0525)	Acc@1 45.312 (52.165)	Acc@5 96.875 (96.237)
Epoch: [6][400/875]	Time 0.472 (0.453)	Data 0.007 (0.010)	Loss 4.3402 (4.1087)	Loss@kd 4.0934 (4.0840)	Acc@1 42.188 (52.120)	Acc@5 93.750 (96.205)
Epoch: [6][500/875]	Time 0.407 (0.452)	Data 0.005 (0.009)	Loss 3.8927 (4.1114)	Loss@kd 3.6790 (4.0942)	Acc@1 43.750 (52.286)	Acc@5 100.000 (96.292)
Epoch: [6][600/875]	Time 0.517 (0.452)	Data 0.006 (0.009)	Loss 4.2515 (4.1070)	Loss@kd 4.0907 (4.0914)	Acc@1 45.312 (52.285)	Acc@5 96.875 (96.332)
Epoch: [6][700/875]	Time 0.409 (0.452)	Data 0.006 (0.009)	Loss 4.2878 (4.0997)	Loss@kd 4.4781 (4.0799)	Acc@1 56.250 (52.222)	Acc@5 98.438 (96.293)
Epoch: [6][800/875]	Time 0.412 (0.452)	Data 0.005 (0.009)	Loss 4.0860 (4.0912)	Loss@kd 4.1025 (4.0707)	Acc@1 51.562 (52.261)	Acc@5 98.438 (96.327)
 * Acc@1 52.248 Acc@5 96.295
epoch 6, total time 395.26
Test: [0/750]	Time 0.803 (0.803)	Loss 0.7339 (0.7339)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.106 (0.115)	Loss 0.6782 (0.6712)	Acc@1 71.875 (80.043)	Acc@5 96.875 (87.067)
Test: [200/750]	Time 0.144 (0.106)	Loss 1.6114 (0.7195)	Acc@1 31.250 (75.669)	Acc@5 93.750 (90.920)
Test: [300/750]	Time 0.109 (0.105)	Loss 1.6490 (0.9849)	Acc@1 18.750 (63.860)	Acc@5 87.500 (89.691)
Test: [400/750]	Time 0.107 (0.104)	Loss 1.5430 (1.1476)	Acc@1 31.250 (52.930)	Acc@5 81.250 (88.529)
Test: [500/750]	Time 0.109 (0.104)	Loss 1.3947 (1.2066)	Acc@1 53.125 (51.460)	Acc@5 75.000 (85.872)
Test: [600/750]	Time 0.102 (0.103)	Loss 1.0389 (1.2035)	Acc@1 59.375 (52.860)	Acc@5 96.875 (85.888)
Test: [700/750]	Time 0.085 (0.103)	Loss 1.3762 (1.1996)	Acc@1 53.125 (53.575)	Acc@5 78.125 (86.252)
 * Acc@1 53.692 Acc@5 85.812
saving the best model!
==> training...
Epoch: [7][0/875]	Time 1.815 (1.815)	Data 1.295 (1.295)	Loss 3.8964 (3.8964)	Loss@kd 3.8163 (3.8163)	Acc@1 53.125 (53.125)	Acc@5 95.312 (95.312)
Epoch: [7][100/875]	Time 0.405 (0.444)	Data 0.006 (0.020)	Loss 4.2266 (4.0305)	Loss@kd 4.3419 (4.0040)	Acc@1 48.438 (52.553)	Acc@5 100.000 (96.318)
Epoch: [7][200/875]	Time 0.413 (0.447)	Data 0.009 (0.013)	Loss 4.1695 (4.0497)	Loss@kd 4.2190 (4.0192)	Acc@1 48.438 (52.387)	Acc@5 100.000 (96.549)
Epoch: [7][300/875]	Time 0.439 (0.447)	Data 0.007 (0.011)	Loss 3.8730 (4.0772)	Loss@kd 3.7368 (4.0531)	Acc@1 54.688 (52.289)	Acc@5 98.438 (96.512)
Epoch: [7][400/875]	Time 0.436 (0.448)	Data 0.010 (0.010)	Loss 4.8555 (4.0676)	Loss@kd 5.0249 (4.0461)	Acc@1 48.438 (52.385)	Acc@5 93.750 (96.470)
Epoch: [7][500/875]	Time 0.434 (0.450)	Data 0.007 (0.009)	Loss 3.9474 (4.0604)	Loss@kd 3.8690 (4.0356)	Acc@1 56.250 (52.448)	Acc@5 92.188 (96.445)
Epoch: [7][600/875]	Time 0.423 (0.451)	Data 0.007 (0.009)	Loss 4.0433 (4.0525)	Loss@kd 3.9585 (4.0234)	Acc@1 50.000 (52.517)	Acc@5 96.875 (96.467)
Epoch: [7][700/875]	Time 0.433 (0.451)	Data 0.007 (0.009)	Loss 4.2346 (4.0414)	Loss@kd 3.8849 (4.0159)	Acc@1 53.125 (52.846)	Acc@5 90.625 (96.460)
Epoch: [7][800/875]	Time 0.570 (0.451)	Data 0.007 (0.009)	Loss 3.8836 (4.0424)	Loss@kd 3.8664 (4.0180)	Acc@1 56.250 (52.920)	Acc@5 100.000 (96.479)
 * Acc@1 52.929 Acc@5 96.493
epoch 7, total time 394.92
Test: [0/750]	Time 0.828 (0.828)	Loss 0.6923 (0.6923)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.098 (0.112)	Loss 0.9701 (0.5376)	Acc@1 56.250 (83.045)	Acc@5 93.750 (89.666)
Test: [200/750]	Time 0.096 (0.108)	Loss 1.7421 (0.7437)	Acc@1 25.000 (71.968)	Acc@5 78.125 (91.294)
Test: [300/750]	Time 0.200 (0.107)	Loss 1.7728 (1.0266)	Acc@1 21.875 (59.759)	Acc@5 75.000 (89.213)
Test: [400/750]	Time 0.100 (0.106)	Loss 1.4030 (1.2032)	Acc@1 46.875 (50.748)	Acc@5 78.125 (85.949)
Test: [500/750]	Time 0.110 (0.105)	Loss 1.0566 (1.2176)	Acc@1 56.250 (52.314)	Acc@5 87.500 (84.880)
Test: [600/750]	Time 0.100 (0.105)	Loss 1.2139 (1.1967)	Acc@1 65.625 (54.357)	Acc@5 90.625 (85.420)
Test: [700/750]	Time 0.088 (0.105)	Loss 1.6072 (1.2150)	Acc@1 37.500 (54.012)	Acc@5 78.125 (85.632)
 * Acc@1 53.454 Acc@5 85.458
==> training...
Epoch: [8][0/875]	Time 1.775 (1.775)	Data 1.309 (1.309)	Loss 4.4724 (4.4724)	Loss@kd 4.1973 (4.1973)	Acc@1 46.875 (46.875)	Acc@5 89.062 (89.062)
Epoch: [8][100/875]	Time 0.537 (0.467)	Data 0.007 (0.020)	Loss 4.0675 (3.9614)	Loss@kd 4.0884 (3.9194)	Acc@1 50.000 (52.908)	Acc@5 96.875 (96.798)
Epoch: [8][200/875]	Time 0.438 (0.455)	Data 0.007 (0.013)	Loss 3.9658 (3.9691)	Loss@kd 3.8957 (3.9277)	Acc@1 57.812 (53.319)	Acc@5 98.438 (96.634)
Epoch: [8][300/875]	Time 0.414 (0.447)	Data 0.008 (0.011)	Loss 4.6380 (4.0046)	Loss@kd 4.7044 (3.9898)	Acc@1 53.125 (53.540)	Acc@5 96.875 (96.647)
Epoch: [8][400/875]	Time 0.421 (0.443)	Data 0.007 (0.010)	Loss 4.1553 (4.0063)	Loss@kd 3.7865 (3.9935)	Acc@1 40.625 (53.499)	Acc@5 95.312 (96.622)
Epoch: [8][500/875]	Time 0.463 (0.445)	Data 0.007 (0.009)	Loss 4.2767 (3.9985)	Loss@kd 4.2826 (3.9837)	Acc@1 45.312 (53.452)	Acc@5 96.875 (96.654)
Epoch: [8][600/875]	Time 0.426 (0.446)	Data 0.007 (0.009)	Loss 3.9110 (3.9928)	Loss@kd 3.8057 (3.9751)	Acc@1 46.875 (53.427)	Acc@5 95.312 (96.612)
Epoch: [8][700/875]	Time 0.420 (0.447)	Data 0.007 (0.009)	Loss 3.9104 (3.9884)	Loss@kd 4.0127 (3.9684)	Acc@1 57.812 (53.428)	Acc@5 96.875 (96.594)
Epoch: [8][800/875]	Time 0.400 (0.447)	Data 0.007 (0.008)	Loss 3.9874 (3.9863)	Loss@kd 3.9591 (3.9681)	Acc@1 53.125 (53.560)	Acc@5 95.312 (96.582)
 * Acc@1 53.571 Acc@5 96.566
epoch 8, total time 392.38
Test: [0/750]	Time 0.840 (0.840)	Loss 0.6681 (0.6681)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.128 (0.116)	Loss 0.7686 (0.6185)	Acc@1 75.000 (80.229)	Acc@5 96.875 (89.016)
Test: [200/750]	Time 0.101 (0.110)	Loss 1.7626 (0.7286)	Acc@1 25.000 (73.352)	Acc@5 87.500 (91.418)
Test: [300/750]	Time 0.108 (0.109)	Loss 1.4477 (1.0070)	Acc@1 43.750 (61.078)	Acc@5 93.750 (89.265)
Test: [400/750]	Time 0.102 (0.108)	Loss 1.3129 (1.1188)	Acc@1 56.250 (54.949)	Acc@5 87.500 (89.238)
Test: [500/750]	Time 0.101 (0.108)	Loss 1.1395 (1.1554)	Acc@1 62.500 (54.953)	Acc@5 78.125 (87.375)
Test: [600/750]	Time 0.108 (0.107)	Loss 0.9582 (1.1393)	Acc@1 68.750 (56.531)	Acc@5 96.875 (87.656)
Test: [700/750]	Time 0.111 (0.107)	Loss 1.6000 (1.1506)	Acc@1 43.750 (56.054)	Acc@5 71.875 (87.447)
 * Acc@1 55.342 Acc@5 86.767
saving the best model!
==> training...
Epoch: [9][0/875]	Time 1.882 (1.882)	Data 1.359 (1.359)	Loss 4.6883 (4.6883)	Loss@kd 5.0219 (5.0219)	Acc@1 51.562 (51.562)	Acc@5 98.438 (98.438)
Epoch: [9][100/875]	Time 0.428 (0.465)	Data 0.007 (0.020)	Loss 4.4555 (3.9748)	Loss@kd 4.6833 (3.9623)	Acc@1 56.250 (53.697)	Acc@5 98.438 (96.720)
Epoch: [9][200/875]	Time 0.449 (0.458)	Data 0.007 (0.014)	Loss 3.7974 (3.9882)	Loss@kd 3.9009 (3.9741)	Acc@1 57.812 (53.677)	Acc@5 96.875 (96.813)
Epoch: [9][300/875]	Time 0.440 (0.457)	Data 0.007 (0.011)	Loss 3.6454 (3.9709)	Loss@kd 3.6445 (3.9481)	Acc@1 53.125 (53.784)	Acc@5 96.875 (96.678)
Epoch: [9][400/875]	Time 0.455 (0.456)	Data 0.007 (0.010)	Loss 3.8286 (3.9572)	Loss@kd 3.8796 (3.9385)	Acc@1 67.188 (54.013)	Acc@5 98.438 (96.766)
Epoch: [9][500/875]	Time 0.436 (0.453)	Data 0.007 (0.010)	Loss 3.9670 (3.9542)	Loss@kd 4.0187 (3.9313)	Acc@1 60.938 (54.023)	Acc@5 98.438 (96.750)
Epoch: [9][600/875]	Time 0.426 (0.450)	Data 0.007 (0.009)	Loss 3.6643 (3.9530)	Loss@kd 3.6292 (3.9272)	Acc@1 59.375 (53.962)	Acc@5 96.875 (96.696)
Epoch: [9][700/875]	Time 0.428 (0.448)	Data 0.007 (0.009)	Loss 3.8918 (3.9525)	Loss@kd 3.7935 (3.9328)	Acc@1 43.750 (54.150)	Acc@5 98.438 (96.775)
Epoch: [9][800/875]	Time 0.549 (0.448)	Data 0.007 (0.009)	Loss 3.7086 (3.9496)	Loss@kd 3.6891 (3.9291)	Acc@1 56.250 (54.120)	Acc@5 100.000 (96.768)
 * Acc@1 54.198 Acc@5 96.784
epoch 9, total time 392.51
Test: [0/750]	Time 0.836 (0.836)	Loss 0.6889 (0.6889)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.109 (0.113)	Loss 0.8958 (0.7419)	Acc@1 59.375 (78.125)	Acc@5 96.875 (88.274)
Test: [200/750]	Time 0.110 (0.109)	Loss 1.8321 (0.8259)	Acc@1 28.125 (70.709)	Acc@5 87.500 (91.169)
Test: [300/750]	Time 0.177 (0.108)	Loss 1.9390 (1.1194)	Acc@1 12.500 (57.745)	Acc@5 78.125 (89.317)
Test: [400/750]	Time 0.101 (0.107)	Loss 0.8398 (1.2529)	Acc@1 78.125 (49.961)	Acc@5 93.750 (87.095)
Test: [500/750]	Time 0.094 (0.106)	Loss 0.9610 (1.1859)	Acc@1 62.500 (54.098)	Acc@5 87.500 (87.369)
Test: [600/750]	Time 0.108 (0.106)	Loss 0.8952 (1.1500)	Acc@1 59.375 (56.297)	Acc@5 93.750 (87.770)
Test: [700/750]	Time 0.102 (0.106)	Loss 1.5328 (1.1452)	Acc@1 50.000 (56.705)	Acc@5 75.000 (87.696)
 * Acc@1 56.633 Acc@5 87.242
saving the best model!
==> training...
Epoch: [10][0/875]	Time 1.845 (1.845)	Data 1.409 (1.409)	Loss 3.9656 (3.9656)	Loss@kd 3.7282 (3.7282)	Acc@1 51.562 (51.562)	Acc@5 95.312 (95.312)
Epoch: [10][100/875]	Time 0.557 (0.467)	Data 0.008 (0.021)	Loss 3.8233 (3.8887)	Loss@kd 3.7808 (3.8920)	Acc@1 56.250 (55.801)	Acc@5 98.438 (96.875)
Epoch: [10][200/875]	Time 0.420 (0.459)	Data 0.007 (0.014)	Loss 3.6310 (3.8837)	Loss@kd 3.5168 (3.8746)	Acc@1 57.812 (55.372)	Acc@5 98.438 (96.891)
Epoch: [10][300/875]	Time 0.425 (0.458)	Data 0.007 (0.012)	Loss 4.0064 (3.9168)	Loss@kd 4.0669 (3.9122)	Acc@1 50.000 (55.274)	Acc@5 98.438 (96.896)
Epoch: [10][400/875]	Time 0.417 (0.456)	Data 0.007 (0.010)	Loss 3.7362 (3.9130)	Loss@kd 3.6109 (3.9076)	Acc@1 54.688 (55.210)	Acc@5 96.875 (96.883)
Epoch: [10][500/875]	Time 0.450 (0.455)	Data 0.007 (0.010)	Loss 3.9629 (3.9108)	Loss@kd 3.7248 (3.9057)	Acc@1 43.750 (55.190)	Acc@5 93.750 (96.863)
Epoch: [10][600/875]	Time 0.453 (0.455)	Data 0.005 (0.009)	Loss 3.7534 (3.9098)	Loss@kd 3.7122 (3.8999)	Acc@1 51.562 (55.181)	Acc@5 95.312 (96.818)
Epoch: [10][700/875]	Time 0.458 (0.454)	Data 0.007 (0.009)	Loss 3.8305 (3.9059)	Loss@kd 3.9916 (3.8945)	Acc@1 67.188 (55.229)	Acc@5 95.312 (96.822)
Epoch: [10][800/875]	Time 0.437 (0.452)	Data 0.005 (0.009)	Loss 4.3119 (3.9014)	Loss@kd 4.5854 (3.8889)	Acc@1 51.562 (55.220)	Acc@5 95.312 (96.822)
 * Acc@1 55.202 Acc@5 96.795
epoch 10, total time 394.89
Test: [0/750]	Time 0.818 (0.818)	Loss 0.6266 (0.6266)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.097 (0.114)	Loss 0.7390 (0.5909)	Acc@1 75.000 (80.600)	Acc@5 93.750 (89.109)
Test: [200/750]	Time 0.097 (0.108)	Loss 1.7359 (0.6909)	Acc@1 34.375 (75.358)	Acc@5 81.250 (91.993)
Test: [300/750]	Time 0.095 (0.107)	Loss 1.5573 (0.9925)	Acc@1 28.125 (61.908)	Acc@5 87.500 (90.002)
Test: [400/750]	Time 0.084 (0.104)	Loss 1.2506 (1.1359)	Acc@1 62.500 (53.468)	Acc@5 90.625 (88.536)
Test: [500/750]	Time 0.098 (0.104)	Loss 0.8040 (1.1587)	Acc@1 71.875 (54.329)	Acc@5 93.750 (87.007)
Test: [600/750]	Time 0.096 (0.104)	Loss 0.9607 (1.1261)	Acc@1 68.750 (56.671)	Acc@5 96.875 (87.578)
Test: [700/750]	Time 0.091 (0.105)	Loss 1.4083 (1.1316)	Acc@1 43.750 (56.767)	Acc@5 81.250 (87.803)
 * Acc@1 56.800 Acc@5 87.579
saving the best model!
==> training...
Epoch: [11][0/875]	Time 2.044 (2.044)	Data 1.451 (1.451)	Loss 3.9104 (3.9104)	Loss@kd 3.6886 (3.6886)	Acc@1 53.125 (53.125)	Acc@5 98.438 (98.438)
Epoch: [11][100/875]	Time 0.425 (0.462)	Data 0.007 (0.021)	Loss 3.7836 (3.8390)	Loss@kd 3.7345 (3.8527)	Acc@1 51.562 (57.163)	Acc@5 96.875 (97.107)
Epoch: [11][200/875]	Time 0.462 (0.457)	Data 0.006 (0.014)	Loss 3.7356 (3.8574)	Loss@kd 3.6351 (3.8649)	Acc@1 51.562 (56.693)	Acc@5 96.875 (96.883)
Epoch: [11][300/875]	Time 0.427 (0.454)	Data 0.007 (0.012)	Loss 4.0675 (3.8619)	Loss@kd 3.8943 (3.8480)	Acc@1 56.250 (55.871)	Acc@5 93.750 (96.771)
Epoch: [11][400/875]	Time 0.466 (0.453)	Data 0.007 (0.011)	Loss 4.0276 (3.8593)	Loss@kd 3.9800 (3.8443)	Acc@1 50.000 (55.685)	Acc@5 96.875 (96.735)
Epoch: [11][500/875]	Time 0.454 (0.453)	Data 0.007 (0.010)	Loss 3.7166 (3.8586)	Loss@kd 3.6734 (3.8426)	Acc@1 59.375 (55.689)	Acc@5 98.438 (96.819)
Epoch: [11][600/875]	Time 0.456 (0.452)	Data 0.006 (0.009)	Loss 3.9217 (3.8661)	Loss@kd 3.7893 (3.8571)	Acc@1 51.562 (55.831)	Acc@5 93.750 (96.818)
Epoch: [11][700/875]	Time 0.443 (0.452)	Data 0.007 (0.009)	Loss 4.1057 (3.8686)	Loss@kd 3.9002 (3.8614)	Acc@1 43.750 (55.896)	Acc@5 93.750 (96.826)
Epoch: [11][800/875]	Time 0.518 (0.452)	Data 0.007 (0.009)	Loss 4.1809 (3.8668)	Loss@kd 4.0395 (3.8606)	Acc@1 40.625 (55.850)	Acc@5 98.438 (96.834)
 * Acc@1 55.818 Acc@5 96.857
epoch 11, total time 396.19
Test: [0/750]	Time 0.751 (0.751)	Loss 0.7402 (0.7402)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.092 (0.110)	Loss 0.4813 (0.6509)	Acc@1 81.250 (81.467)	Acc@5 96.875 (87.562)
Test: [200/750]	Time 0.097 (0.107)	Loss 1.8791 (0.6454)	Acc@1 25.000 (78.265)	Acc@5 84.375 (91.278)
Test: [300/750]	Time 0.178 (0.106)	Loss 1.4397 (0.9622)	Acc@1 37.500 (62.490)	Acc@5 90.625 (89.680)
Test: [400/750]	Time 0.110 (0.105)	Loss 1.1129 (1.0647)	Acc@1 62.500 (57.458)	Acc@5 84.375 (89.682)
Test: [500/750]	Time 0.108 (0.105)	Loss 1.2630 (1.0923)	Acc@1 50.000 (58.302)	Acc@5 78.125 (88.161)
Test: [600/750]	Time 0.104 (0.104)	Loss 0.9590 (1.1073)	Acc@1 59.375 (58.501)	Acc@5 96.875 (87.942)
Test: [700/750]	Time 0.099 (0.103)	Loss 1.4808 (1.1193)	Acc@1 46.875 (57.712)	Acc@5 78.125 (88.191)
 * Acc@1 57.196 Acc@5 87.800
saving the best model!
==> training...
Epoch: [12][0/875]	Time 1.755 (1.755)	Data 1.319 (1.319)	Loss 3.6957 (3.6957)	Loss@kd 3.6326 (3.6326)	Acc@1 53.125 (53.125)	Acc@5 96.875 (96.875)
Epoch: [12][100/875]	Time 0.497 (0.447)	Data 0.007 (0.020)	Loss 3.7168 (3.8308)	Loss@kd 3.8728 (3.7936)	Acc@1 57.812 (55.832)	Acc@5 93.750 (96.612)
Epoch: [12][200/875]	Time 0.402 (0.438)	Data 0.007 (0.013)	Loss 3.6582 (3.8065)	Loss@kd 3.6156 (3.7727)	Acc@1 59.375 (55.869)	Acc@5 93.750 (96.782)
Epoch: [12][300/875]	Time 0.479 (0.440)	Data 0.007 (0.011)	Loss 3.8510 (3.8250)	Loss@kd 3.7805 (3.8042)	Acc@1 50.000 (55.850)	Acc@5 100.000 (97.015)
Epoch: [12][400/875]	Time 0.419 (0.443)	Data 0.007 (0.010)	Loss 5.2438 (3.8398)	Loss@kd 5.7370 (3.8284)	Acc@1 53.125 (55.802)	Acc@5 98.438 (97.023)
Epoch: [12][500/875]	Time 0.441 (0.445)	Data 0.007 (0.010)	Loss 3.5723 (3.8325)	Loss@kd 3.5687 (3.8239)	Acc@1 57.812 (56.069)	Acc@5 98.438 (97.009)
Epoch: [12][600/875]	Time 0.492 (0.446)	Data 0.007 (0.009)	Loss 3.5722 (3.8318)	Loss@kd 3.5769 (3.8205)	Acc@1 64.062 (56.099)	Acc@5 96.875 (97.028)
Epoch: [12][700/875]	Time 0.420 (0.447)	Data 0.010 (0.009)	Loss 3.8270 (3.8321)	Loss@kd 3.8506 (3.8230)	Acc@1 56.250 (56.147)	Acc@5 98.438 (97.018)
Epoch: [12][800/875]	Time 0.428 (0.448)	Data 0.007 (0.009)	Loss 3.8752 (3.8347)	Loss@kd 3.7506 (3.8267)	Acc@1 57.812 (56.168)	Acc@5 98.438 (97.015)
 * Acc@1 56.211 Acc@5 97.027
epoch 12, total time 392.32
Test: [0/750]	Time 0.782 (0.782)	Loss 0.6791 (0.6791)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.101 (0.110)	Loss 0.6582 (0.6099)	Acc@1 78.125 (81.436)	Acc@5 93.750 (89.387)
Test: [200/750]	Time 0.076 (0.108)	Loss 1.3773 (0.6611)	Acc@1 46.875 (77.612)	Acc@5 93.750 (92.226)
Test: [300/750]	Time 0.101 (0.105)	Loss 1.8491 (0.9139)	Acc@1 15.625 (66.881)	Acc@5 78.125 (91.186)
Test: [400/750]	Time 0.085 (0.105)	Loss 1.0770 (1.1330)	Acc@1 68.750 (55.182)	Acc@5 87.500 (87.531)
Test: [500/750]	Time 0.105 (0.104)	Loss 0.9304 (1.1470)	Acc@1 59.375 (55.901)	Acc@5 90.625 (86.920)
Test: [600/750]	Time 0.119 (0.104)	Loss 0.9913 (1.1247)	Acc@1 59.375 (57.555)	Acc@5 90.625 (87.193)
Test: [700/750]	Time 0.090 (0.104)	Loss 1.2666 (1.1297)	Acc@1 62.500 (57.342)	Acc@5 81.250 (87.643)
 * Acc@1 57.258 Acc@5 87.838
saving the best model!
==> training...
Epoch: [13][0/875]	Time 1.748 (1.748)	Data 1.261 (1.261)	Loss 4.2208 (4.2208)	Loss@kd 3.8284 (3.8284)	Acc@1 42.188 (42.188)	Acc@5 93.750 (93.750)
Epoch: [13][100/875]	Time 0.468 (0.463)	Data 0.007 (0.019)	Loss 3.6598 (3.8260)	Loss@kd 3.7680 (3.8087)	Acc@1 54.688 (55.662)	Acc@5 96.875 (96.890)
Epoch: [13][200/875]	Time 0.435 (0.455)	Data 0.007 (0.013)	Loss 3.6858 (3.8142)	Loss@kd 3.6374 (3.7956)	Acc@1 53.125 (55.854)	Acc@5 96.875 (96.968)
Epoch: [13][300/875]	Time 0.429 (0.451)	Data 0.007 (0.011)	Loss 3.9197 (3.8006)	Loss@kd 3.9493 (3.7791)	Acc@1 51.562 (55.944)	Acc@5 95.312 (96.979)
Epoch: [13][400/875]	Time 0.457 (0.446)	Data 0.005 (0.010)	Loss 3.4894 (3.7840)	Loss@kd 3.6725 (3.7704)	Acc@1 60.938 (56.577)	Acc@5 98.438 (97.085)
Epoch: [13][500/875]	Time 0.414 (0.443)	Data 0.007 (0.009)	Loss 3.8347 (3.7858)	Loss@kd 3.7411 (3.7753)	Acc@1 59.375 (56.821)	Acc@5 98.438 (97.022)
Epoch: [13][600/875]	Time 0.448 (0.443)	Data 0.007 (0.009)	Loss 3.6300 (3.7955)	Loss@kd 3.5567 (3.7907)	Acc@1 62.500 (56.900)	Acc@5 95.312 (97.041)
Epoch: [13][700/875]	Time 0.422 (0.444)	Data 0.007 (0.009)	Loss 3.6913 (3.7982)	Loss@kd 3.8616 (3.7963)	Acc@1 60.938 (56.852)	Acc@5 93.750 (97.087)
Epoch: [13][800/875]	Time 0.451 (0.445)	Data 0.006 (0.008)	Loss 3.6083 (3.7961)	Loss@kd 3.7218 (3.7979)	Acc@1 65.625 (57.005)	Acc@5 96.875 (97.111)
 * Acc@1 56.998 Acc@5 97.089
epoch 13, total time 390.16
Test: [0/750]	Time 0.825 (0.825)	Loss 0.7089 (0.7089)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.181 (0.115)	Loss 0.6481 (0.6322)	Acc@1 75.000 (80.353)	Acc@5 96.875 (88.304)
Test: [200/750]	Time 0.094 (0.111)	Loss 1.7793 (0.7000)	Acc@1 28.125 (75.342)	Acc@5 84.375 (91.900)
Test: [300/750]	Time 0.095 (0.109)	Loss 1.4865 (0.9970)	Acc@1 46.875 (61.618)	Acc@5 90.625 (89.753)
Test: [400/750]	Time 0.090 (0.109)	Loss 1.1912 (1.1064)	Acc@1 75.000 (56.515)	Acc@5 81.250 (89.308)
Test: [500/750]	Time 0.091 (0.108)	Loss 1.0122 (1.1263)	Acc@1 62.500 (57.616)	Acc@5 84.375 (87.899)
Test: [600/750]	Time 0.097 (0.107)	Loss 0.8197 (1.1035)	Acc@1 78.125 (59.198)	Acc@5 96.875 (88.176)
Test: [700/750]	Time 0.105 (0.107)	Loss 1.4119 (1.1003)	Acc@1 50.000 (59.045)	Acc@5 75.000 (88.396)
 * Acc@1 58.263 Acc@5 87.963
saving the best model!
==> training...
Epoch: [14][0/875]	Time 1.868 (1.868)	Data 1.361 (1.361)	Loss 3.5914 (3.5914)	Loss@kd 3.6217 (3.6217)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [14][100/875]	Time 0.477 (0.465)	Data 0.007 (0.020)	Loss 3.6641 (3.8418)	Loss@kd 3.7858 (3.8541)	Acc@1 60.938 (57.085)	Acc@5 100.000 (97.061)
Epoch: [14][200/875]	Time 0.428 (0.458)	Data 0.007 (0.014)	Loss 3.7357 (3.7924)	Loss@kd 3.7605 (3.8038)	Acc@1 62.500 (57.657)	Acc@5 98.438 (97.124)
Epoch: [14][300/875]	Time 0.417 (0.455)	Data 0.007 (0.011)	Loss 3.3759 (3.7852)	Loss@kd 3.4756 (3.7943)	Acc@1 65.625 (57.548)	Acc@5 96.875 (97.171)
Epoch: [14][400/875]	Time 0.423 (0.454)	Data 0.007 (0.010)	Loss 3.7968 (3.7761)	Loss@kd 3.6824 (3.7821)	Acc@1 50.000 (57.575)	Acc@5 96.875 (97.101)
Epoch: [14][500/875]	Time 0.446 (0.453)	Data 0.007 (0.010)	Loss 3.7227 (3.7786)	Loss@kd 3.5282 (3.7829)	Acc@1 43.750 (57.535)	Acc@5 95.312 (97.106)
Epoch: [14][600/875]	Time 0.491 (0.451)	Data 0.007 (0.009)	Loss 3.8882 (3.7677)	Loss@kd 3.6388 (3.7730)	Acc@1 56.250 (57.693)	Acc@5 95.312 (97.135)
Epoch: [14][700/875]	Time 0.448 (0.448)	Data 0.007 (0.009)	Loss 3.6000 (3.7698)	Loss@kd 3.5366 (3.7762)	Acc@1 53.125 (57.732)	Acc@5 98.438 (97.151)
Epoch: [14][800/875]	Time 0.431 (0.447)	Data 0.007 (0.009)	Loss 3.5944 (3.7622)	Loss@kd 3.5809 (3.7662)	Acc@1 62.500 (57.772)	Acc@5 95.312 (97.131)
 * Acc@1 57.755 Acc@5 97.148
epoch 14, total time 391.51
Test: [0/750]	Time 0.787 (0.787)	Loss 0.7109 (0.7109)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.090 (0.115)	Loss 0.7533 (0.5934)	Acc@1 71.875 (81.683)	Acc@5 93.750 (88.552)
Test: [200/750]	Time 0.166 (0.109)	Loss 1.7399 (0.7257)	Acc@1 31.250 (74.145)	Acc@5 81.250 (91.154)
Test: [300/750]	Time 0.095 (0.108)	Loss 1.3969 (0.9788)	Acc@1 37.500 (61.701)	Acc@5 96.875 (90.033)
Test: [400/750]	Time 0.086 (0.106)	Loss 1.0631 (1.0652)	Acc@1 62.500 (57.138)	Acc@5 90.625 (90.415)
Test: [500/750]	Time 0.119 (0.106)	Loss 0.8346 (1.0595)	Acc@1 78.125 (59.288)	Acc@5 90.625 (89.652)
Test: [600/750]	Time 0.094 (0.106)	Loss 0.9665 (1.0448)	Acc@1 62.500 (60.878)	Acc@5 93.750 (89.621)
Test: [700/750]	Time 0.098 (0.105)	Loss 1.4076 (1.0679)	Acc@1 56.250 (60.021)	Acc@5 78.125 (89.136)
 * Acc@1 59.096 Acc@5 88.533
saving the best model!
==> training...
Epoch: [15][0/875]	Time 1.959 (1.959)	Data 1.375 (1.375)	Loss 3.7461 (3.7461)	Loss@kd 3.8922 (3.8922)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [15][100/875]	Time 0.453 (0.469)	Data 0.006 (0.020)	Loss 3.3505 (3.7905)	Loss@kd 3.5601 (3.8175)	Acc@1 62.500 (57.550)	Acc@5 100.000 (97.030)
Epoch: [15][200/875]	Time 0.416 (0.461)	Data 0.007 (0.014)	Loss 3.7251 (3.7533)	Loss@kd 3.9297 (3.7681)	Acc@1 64.062 (57.292)	Acc@5 98.438 (97.108)
Epoch: [15][300/875]	Time 0.480 (0.457)	Data 0.007 (0.011)	Loss 3.4995 (3.7423)	Loss@kd 3.4813 (3.7549)	Acc@1 56.250 (57.724)	Acc@5 98.438 (97.202)
Epoch: [15][400/875]	Time 0.434 (0.456)	Data 0.006 (0.010)	Loss 3.8882 (3.7478)	Loss@kd 3.5894 (3.7591)	Acc@1 48.438 (57.859)	Acc@5 96.875 (97.206)
Epoch: [15][500/875]	Time 0.464 (0.456)	Data 0.006 (0.010)	Loss 3.8627 (3.7396)	Loss@kd 3.6613 (3.7452)	Acc@1 54.688 (57.772)	Acc@5 93.750 (97.209)
Epoch: [15][600/875]	Time 0.455 (0.455)	Data 0.007 (0.009)	Loss 3.7543 (3.7451)	Loss@kd 3.7744 (3.7512)	Acc@1 59.375 (57.818)	Acc@5 98.438 (97.182)
Epoch: [15][700/875]	Time 0.441 (0.455)	Data 0.010 (0.009)	Loss 3.8071 (3.7435)	Loss@kd 3.8270 (3.7506)	Acc@1 60.938 (57.839)	Acc@5 95.312 (97.185)
Epoch: [15][800/875]	Time 0.513 (0.455)	Data 0.005 (0.009)	Loss 3.5192 (3.7340)	Loss@kd 3.6065 (3.7408)	Acc@1 59.375 (57.896)	Acc@5 96.875 (97.209)
 * Acc@1 57.950 Acc@5 97.220
epoch 15, total time 397.60
Test: [0/750]	Time 0.793 (0.793)	Loss 0.7422 (0.7422)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.110 (0.111)	Loss 0.5676 (0.6456)	Acc@1 71.875 (79.920)	Acc@5 100.000 (87.964)
Test: [200/750]	Time 0.086 (0.108)	Loss 1.8998 (0.6847)	Acc@1 28.125 (75.451)	Acc@5 81.250 (91.356)
Test: [300/750]	Time 0.169 (0.107)	Loss 1.2954 (1.0189)	Acc@1 50.000 (58.866)	Acc@5 90.625 (88.372)
Test: [400/750]	Time 0.097 (0.106)	Loss 1.1681 (1.0918)	Acc@1 68.750 (55.268)	Acc@5 87.500 (89.152)
Test: [500/750]	Time 0.083 (0.105)	Loss 0.9446 (1.0986)	Acc@1 71.875 (56.855)	Acc@5 90.625 (88.386)
Test: [600/750]	Time 0.095 (0.104)	Loss 1.0076 (1.0897)	Acc@1 59.375 (58.423)	Acc@5 90.625 (88.368)
Test: [700/750]	Time 0.088 (0.104)	Loss 1.0500 (1.0772)	Acc@1 68.750 (58.947)	Acc@5 87.500 (88.940)
 * Acc@1 59.296 Acc@5 89.050
saving the best model!
==> training...
Epoch: [16][0/875]	Time 1.753 (1.753)	Data 1.349 (1.349)	Loss 3.6408 (3.6408)	Loss@kd 3.7166 (3.7166)	Acc@1 56.250 (56.250)	Acc@5 96.875 (96.875)
Epoch: [16][100/875]	Time 0.520 (0.454)	Data 0.007 (0.020)	Loss 3.3780 (3.7313)	Loss@kd 3.4335 (3.7400)	Acc@1 59.375 (57.905)	Acc@5 98.438 (96.921)
Epoch: [16][200/875]	Time 0.407 (0.451)	Data 0.006 (0.013)	Loss 3.4087 (3.7273)	Loss@kd 3.5318 (3.7468)	Acc@1 70.312 (58.170)	Acc@5 98.438 (97.279)
Epoch: [16][300/875]	Time 0.415 (0.452)	Data 0.007 (0.011)	Loss 3.5466 (3.7419)	Loss@kd 3.5773 (3.7651)	Acc@1 59.375 (58.108)	Acc@5 98.438 (97.295)
Epoch: [16][400/875]	Time 0.430 (0.451)	Data 0.007 (0.010)	Loss 3.3899 (3.7264)	Loss@kd 3.6391 (3.7458)	Acc@1 70.312 (58.124)	Acc@5 98.438 (97.385)
Epoch: [16][500/875]	Time 0.448 (0.451)	Data 0.007 (0.010)	Loss 3.7548 (3.7205)	Loss@kd 3.5836 (3.7404)	Acc@1 51.562 (58.255)	Acc@5 98.438 (97.393)
Epoch: [16][600/875]	Time 0.465 (0.451)	Data 0.008 (0.009)	Loss 3.6529 (3.7182)	Loss@kd 3.5577 (3.7364)	Acc@1 56.250 (58.267)	Acc@5 98.438 (97.398)
Epoch: [16][700/875]	Time 0.423 (0.451)	Data 0.007 (0.009)	Loss 3.7439 (3.7091)	Loss@kd 3.4163 (3.7230)	Acc@1 46.875 (58.307)	Acc@5 92.188 (97.379)
Epoch: [16][800/875]	Time 0.415 (0.451)	Data 0.009 (0.009)	Loss 3.3533 (3.7037)	Loss@kd 3.5539 (3.7163)	Acc@1 71.875 (58.382)	Acc@5 95.312 (97.404)
 * Acc@1 58.480 Acc@5 97.398
epoch 16, total time 395.41
Test: [0/750]	Time 0.729 (0.729)	Loss 0.6311 (0.6311)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.107)	Loss 0.6922 (0.5420)	Acc@1 75.000 (82.952)	Acc@5 100.000 (90.037)
Test: [200/750]	Time 0.108 (0.106)	Loss 1.6444 (0.6688)	Acc@1 40.625 (76.368)	Acc@5 87.500 (92.289)
Test: [300/750]	Time 0.104 (0.104)	Loss 1.5751 (0.9651)	Acc@1 25.000 (63.850)	Acc@5 87.500 (90.677)
Test: [400/750]	Time 0.091 (0.104)	Loss 0.9581 (1.0770)	Acc@1 71.875 (56.967)	Acc@5 87.500 (90.360)
Test: [500/750]	Time 0.093 (0.103)	Loss 0.6704 (1.0410)	Acc@1 81.250 (59.874)	Acc@5 93.750 (89.608)
Test: [600/750]	Time 0.086 (0.103)	Loss 0.9184 (1.0211)	Acc@1 71.875 (61.507)	Acc@5 90.625 (89.642)
Test: [700/750]	Time 0.102 (0.103)	Loss 1.2724 (1.0361)	Acc@1 53.125 (61.198)	Acc@5 84.375 (89.609)
 * Acc@1 61.050 Acc@5 89.533
saving the best model!
==> training...
Epoch: [17][0/875]	Time 1.778 (1.778)	Data 1.323 (1.323)	Loss 3.5338 (3.5338)	Loss@kd 3.6165 (3.6165)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [17][100/875]	Time 0.444 (0.463)	Data 0.007 (0.020)	Loss 3.2407 (3.7327)	Loss@kd 3.3827 (3.7634)	Acc@1 67.188 (58.725)	Acc@5 98.438 (97.478)
Epoch: [17][200/875]	Time 0.427 (0.446)	Data 0.007 (0.013)	Loss 3.5912 (3.6763)	Loss@kd 3.4119 (3.6853)	Acc@1 54.688 (58.831)	Acc@5 95.312 (97.497)
Epoch: [17][300/875]	Time 0.418 (0.439)	Data 0.007 (0.011)	Loss 3.6556 (3.6742)	Loss@kd 3.5932 (3.6803)	Acc@1 64.062 (58.565)	Acc@5 96.875 (97.508)
Epoch: [17][400/875]	Time 0.531 (0.438)	Data 0.007 (0.010)	Loss 3.6626 (3.6747)	Loss@kd 3.6102 (3.6834)	Acc@1 56.250 (58.705)	Acc@5 96.875 (97.456)
Epoch: [17][500/875]	Time 0.430 (0.440)	Data 0.007 (0.009)	Loss 3.5678 (3.6760)	Loss@kd 3.5880 (3.6844)	Acc@1 64.062 (58.520)	Acc@5 96.875 (97.455)
Epoch: [17][600/875]	Time 0.442 (0.442)	Data 0.007 (0.009)	Loss 3.6540 (3.6759)	Loss@kd 3.5453 (3.6873)	Acc@1 50.000 (58.668)	Acc@5 100.000 (97.452)
Epoch: [17][700/875]	Time 0.418 (0.443)	Data 0.007 (0.009)	Loss 3.4611 (3.6713)	Loss@kd 3.6406 (3.6827)	Acc@1 68.750 (58.878)	Acc@5 98.438 (97.383)
Epoch: [17][800/875]	Time 0.455 (0.444)	Data 0.007 (0.009)	Loss 3.5163 (3.6721)	Loss@kd 3.4635 (3.6852)	Acc@1 60.938 (58.985)	Acc@5 95.312 (97.421)
 * Acc@1 58.968 Acc@5 97.425
epoch 17, total time 389.82
Test: [0/750]	Time 0.900 (0.900)	Loss 0.7166 (0.7166)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.168 (0.115)	Loss 0.6559 (0.5935)	Acc@1 68.750 (81.869)	Acc@5 96.875 (88.892)
Test: [200/750]	Time 0.112 (0.112)	Loss 1.7657 (0.6955)	Acc@1 34.375 (75.140)	Acc@5 81.250 (91.480)
Test: [300/750]	Time 0.109 (0.110)	Loss 1.5618 (0.9756)	Acc@1 34.375 (61.514)	Acc@5 93.750 (89.701)
Test: [400/750]	Time 0.123 (0.110)	Loss 0.6794 (1.0498)	Acc@1 78.125 (57.099)	Acc@5 90.625 (90.072)
Test: [500/750]	Time 0.107 (0.109)	Loss 0.9553 (1.0034)	Acc@1 68.750 (60.766)	Acc@5 87.500 (89.752)
Test: [600/750]	Time 0.105 (0.109)	Loss 0.9504 (1.0181)	Acc@1 59.375 (61.564)	Acc@5 90.625 (89.133)
Test: [700/750]	Time 0.110 (0.109)	Loss 1.1418 (1.0302)	Acc@1 68.750 (61.109)	Acc@5 84.375 (89.283)
 * Acc@1 60.575 Acc@5 89.333
==> training...
Epoch: [18][0/875]	Time 1.713 (1.713)	Data 1.286 (1.286)	Loss 3.7191 (3.7191)	Loss@kd 3.5431 (3.5431)	Acc@1 53.125 (53.125)	Acc@5 96.875 (96.875)
Epoch: [18][100/875]	Time 0.418 (0.463)	Data 0.006 (0.019)	Loss 3.7915 (3.6362)	Loss@kd 3.8064 (3.6316)	Acc@1 68.750 (58.509)	Acc@5 98.438 (97.416)
Epoch: [18][200/875]	Time 0.443 (0.457)	Data 0.007 (0.013)	Loss 3.6461 (3.6341)	Loss@kd 3.4974 (3.6431)	Acc@1 57.812 (58.971)	Acc@5 95.312 (97.326)
Epoch: [18][300/875]	Time 0.441 (0.455)	Data 0.007 (0.011)	Loss 3.5740 (3.6236)	Loss@kd 3.5912 (3.6228)	Acc@1 59.375 (59.027)	Acc@5 98.438 (97.311)
Epoch: [18][400/875]	Time 0.431 (0.454)	Data 0.006 (0.010)	Loss 3.7150 (3.6372)	Loss@kd 3.6677 (3.6415)	Acc@1 57.812 (59.196)	Acc@5 98.438 (97.397)
Epoch: [18][500/875]	Time 0.424 (0.450)	Data 0.007 (0.009)	Loss 3.4818 (3.6377)	Loss@kd 3.3586 (3.6481)	Acc@1 53.125 (59.285)	Acc@5 98.438 (97.483)
Epoch: [18][600/875]	Time 0.518 (0.447)	Data 0.007 (0.009)	Loss 3.7084 (3.6376)	Loss@kd 3.6213 (3.6448)	Acc@1 60.938 (59.183)	Acc@5 95.312 (97.489)
Epoch: [18][700/875]	Time 0.438 (0.446)	Data 0.007 (0.009)	Loss 3.4580 (3.6349)	Loss@kd 3.6204 (3.6425)	Acc@1 65.625 (59.239)	Acc@5 98.438 (97.501)
Epoch: [18][800/875]	Time 0.431 (0.448)	Data 0.008 (0.009)	Loss 3.3863 (3.6367)	Loss@kd 3.5639 (3.6494)	Acc@1 64.062 (59.350)	Acc@5 98.438 (97.527)
 * Acc@1 59.375 Acc@5 97.536
epoch 18, total time 392.35
Test: [0/750]	Time 0.782 (0.782)	Loss 0.8103 (0.8103)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.081 (0.114)	Loss 0.6727 (0.7180)	Acc@1 75.000 (78.558)	Acc@5 96.875 (88.800)
Test: [200/750]	Time 0.182 (0.107)	Loss 1.8725 (0.7538)	Acc@1 31.250 (73.787)	Acc@5 71.875 (91.620)
Test: [300/750]	Time 0.099 (0.106)	Loss 1.4601 (1.0452)	Acc@1 46.875 (60.102)	Acc@5 96.875 (89.172)
Test: [400/750]	Time 0.099 (0.105)	Loss 1.0678 (1.0992)	Acc@1 62.500 (56.733)	Acc@5 84.375 (89.955)
Test: [500/750]	Time 0.095 (0.105)	Loss 0.8878 (1.0717)	Acc@1 75.000 (59.125)	Acc@5 90.625 (88.878)
Test: [600/750]	Time 0.093 (0.104)	Loss 0.8221 (1.0566)	Acc@1 68.750 (60.691)	Acc@5 96.875 (88.888)
Test: [700/750]	Time 0.092 (0.104)	Loss 1.3789 (1.0606)	Acc@1 43.750 (60.436)	Acc@5 81.250 (89.172)
 * Acc@1 59.892 Acc@5 89.050
==> training...
Epoch: [19][0/875]	Time 1.863 (1.863)	Data 1.315 (1.315)	Loss 3.4329 (3.4329)	Loss@kd 3.4977 (3.4977)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
Epoch: [19][100/875]	Time 0.418 (0.463)	Data 0.007 (0.020)	Loss 3.8968 (3.6261)	Loss@kd 3.8629 (3.6531)	Acc@1 57.812 (60.288)	Acc@5 98.438 (97.741)
Epoch: [19][200/875]	Time 0.449 (0.458)	Data 0.008 (0.013)	Loss 3.8928 (3.6185)	Loss@kd 3.5784 (3.6349)	Acc@1 53.125 (59.725)	Acc@5 95.312 (97.613)
Epoch: [19][300/875]	Time 0.436 (0.456)	Data 0.007 (0.011)	Loss 4.1238 (3.6344)	Loss@kd 4.4885 (3.6488)	Acc@1 59.375 (59.515)	Acc@5 96.875 (97.493)
Epoch: [19][400/875]	Time 0.438 (0.455)	Data 0.007 (0.010)	Loss 3.3938 (3.6264)	Loss@kd 3.5477 (3.6441)	Acc@1 70.312 (59.640)	Acc@5 96.875 (97.530)
Epoch: [19][500/875]	Time 0.426 (0.454)	Data 0.007 (0.010)	Loss 3.3523 (3.6242)	Loss@kd 3.3459 (3.6363)	Acc@1 59.375 (59.550)	Acc@5 96.875 (97.527)
Epoch: [19][600/875]	Time 0.477 (0.454)	Data 0.007 (0.009)	Loss 3.7077 (3.6295)	Loss@kd 3.5278 (3.6408)	Acc@1 59.375 (59.534)	Acc@5 98.438 (97.499)
Epoch: [19][700/875]	Time 0.399 (0.454)	Data 0.007 (0.009)	Loss 3.6688 (3.6383)	Loss@kd 3.6229 (3.6537)	Acc@1 57.812 (59.422)	Acc@5 96.875 (97.501)
Epoch: [19][800/875]	Time 0.422 (0.451)	Data 0.008 (0.009)	Loss 3.4276 (3.6329)	Loss@kd 3.5503 (3.6417)	Acc@1 57.812 (59.196)	Acc@5 100.000 (97.497)
 * Acc@1 59.298 Acc@5 97.505
epoch 19, total time 393.39
Test: [0/750]	Time 0.839 (0.839)	Loss 0.7270 (0.7270)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.105 (0.109)	Loss 0.6410 (0.5616)	Acc@1 75.000 (82.859)	Acc@5 96.875 (89.604)
Test: [200/750]	Time 0.097 (0.105)	Loss 1.8677 (0.6483)	Acc@1 31.250 (77.752)	Acc@5 87.500 (92.677)
Test: [300/750]	Time 0.098 (0.100)	Loss 1.5518 (0.9839)	Acc@1 34.375 (62.874)	Acc@5 93.750 (89.961)
Test: [400/750]	Time 0.101 (0.101)	Loss 0.7922 (1.0669)	Acc@1 81.250 (58.448)	Acc@5 90.625 (89.861)
Test: [500/750]	Time 0.097 (0.101)	Loss 0.8198 (1.0253)	Acc@1 78.125 (61.284)	Acc@5 90.625 (89.527)
Test: [600/750]	Time 0.090 (0.102)	Loss 0.9004 (1.0299)	Acc@1 71.875 (61.840)	Acc@5 96.875 (89.512)
Test: [700/750]	Time 0.177 (0.101)	Loss 1.3144 (1.0360)	Acc@1 56.250 (61.510)	Acc@5 81.250 (89.805)
 * Acc@1 61.275 Acc@5 89.579
saving the best model!
==> training...
Epoch: [20][0/875]	Time 1.809 (1.809)	Data 1.344 (1.344)	Loss 3.7537 (3.7537)	Loss@kd 3.3959 (3.3959)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [20][100/875]	Time 0.431 (0.469)	Data 0.007 (0.020)	Loss 3.2604 (3.6522)	Loss@kd 3.3545 (3.6759)	Acc@1 68.750 (59.545)	Acc@5 100.000 (97.587)
Epoch: [20][200/875]	Time 0.419 (0.461)	Data 0.007 (0.014)	Loss 3.8532 (3.6208)	Loss@kd 4.1572 (3.6390)	Acc@1 57.812 (59.935)	Acc@5 98.438 (97.660)
Epoch: [20][300/875]	Time 0.491 (0.458)	Data 0.007 (0.011)	Loss 3.6498 (3.6128)	Loss@kd 3.6285 (3.6261)	Acc@1 59.375 (59.873)	Acc@5 96.875 (97.633)
Epoch: [20][400/875]	Time 0.420 (0.456)	Data 0.005 (0.010)	Loss 3.3954 (3.6039)	Loss@kd 3.5272 (3.6139)	Acc@1 60.938 (59.679)	Acc@5 100.000 (97.635)
Epoch: [20][500/875]	Time 0.406 (0.454)	Data 0.007 (0.010)	Loss 3.3717 (3.5976)	Loss@kd 3.4514 (3.6077)	Acc@1 60.938 (59.631)	Acc@5 96.875 (97.636)
Epoch: [20][600/875]	Time 0.547 (0.452)	Data 0.007 (0.009)	Loss 3.5432 (3.5886)	Loss@kd 3.6011 (3.6029)	Acc@1 70.312 (59.991)	Acc@5 100.000 (97.645)
Epoch: [20][700/875]	Time 0.402 (0.451)	Data 0.007 (0.009)	Loss 3.4784 (3.5936)	Loss@kd 3.5420 (3.6122)	Acc@1 62.500 (60.133)	Acc@5 96.875 (97.579)
Epoch: [20][800/875]	Time 0.445 (0.450)	Data 0.007 (0.009)	Loss 3.4522 (3.5849)	Loss@kd 3.4329 (3.6023)	Acc@1 64.062 (60.214)	Acc@5 98.438 (97.607)
 * Acc@1 60.143 Acc@5 97.577
epoch 20, total time 393.49
Test: [0/750]	Time 0.868 (0.868)	Loss 0.7563 (0.7563)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.108 (0.115)	Loss 0.6559 (0.6645)	Acc@1 78.125 (79.889)	Acc@5 100.000 (89.202)
Test: [200/750]	Time 0.180 (0.108)	Loss 1.4394 (0.7064)	Acc@1 46.875 (75.684)	Acc@5 90.625 (93.004)
Test: [300/750]	Time 0.092 (0.107)	Loss 1.8291 (0.9592)	Acc@1 15.625 (65.033)	Acc@5 75.000 (91.860)
Test: [400/750]	Time 0.097 (0.106)	Loss 0.9176 (1.1375)	Acc@1 68.750 (55.712)	Acc@5 93.750 (88.661)
Test: [500/750]	Time 0.100 (0.106)	Loss 0.4964 (1.1082)	Acc@1 84.375 (58.184)	Acc@5 100.000 (88.149)
Test: [600/750]	Time 0.081 (0.105)	Loss 0.7899 (1.0554)	Acc@1 75.000 (60.945)	Acc@5 96.875 (88.951)
Test: [700/750]	Time 0.107 (0.105)	Loss 1.3836 (1.0533)	Acc@1 43.750 (60.975)	Acc@5 75.000 (89.314)
 * Acc@1 60.408 Acc@5 89.075
==> training...
Epoch: [21][0/875]	Time 1.802 (1.802)	Data 1.297 (1.297)	Loss 3.5441 (3.5441)	Loss@kd 3.5325 (3.5325)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [21][100/875]	Time 0.429 (0.445)	Data 0.007 (0.020)	Loss 3.4176 (3.5550)	Loss@kd 3.4730 (3.5695)	Acc@1 64.062 (61.030)	Acc@5 98.438 (97.649)
Epoch: [21][200/875]	Time 0.366 (0.438)	Data 0.005 (0.013)	Loss 3.4921 (3.5509)	Loss@kd 3.3654 (3.5643)	Acc@1 51.562 (60.728)	Acc@5 98.438 (97.715)
Epoch: [21][300/875]	Time 0.428 (0.442)	Data 0.008 (0.011)	Loss 3.8025 (3.5470)	Loss@kd 3.8854 (3.5678)	Acc@1 64.062 (60.901)	Acc@5 93.750 (97.680)
Epoch: [21][400/875]	Time 0.439 (0.445)	Data 0.007 (0.010)	Loss 3.6745 (3.5599)	Loss@kd 3.5210 (3.5797)	Acc@1 60.938 (60.754)	Acc@5 95.312 (97.635)
Epoch: [21][500/875]	Time 0.437 (0.447)	Data 0.007 (0.010)	Loss 3.2988 (3.5537)	Loss@kd 3.4030 (3.5721)	Acc@1 71.875 (60.850)	Acc@5 100.000 (97.558)
Epoch: [21][600/875]	Time 0.424 (0.448)	Data 0.007 (0.009)	Loss 3.4877 (3.5516)	Loss@kd 3.6059 (3.5671)	Acc@1 62.500 (60.652)	Acc@5 100.000 (97.533)
Epoch: [21][700/875]	Time 0.456 (0.449)	Data 0.007 (0.009)	Loss 3.5958 (3.5496)	Loss@kd 3.5630 (3.5670)	Acc@1 59.375 (60.663)	Acc@5 95.312 (97.548)
Epoch: [21][800/875]	Time 0.512 (0.449)	Data 0.007 (0.009)	Loss 3.5064 (3.5492)	Loss@kd 3.2965 (3.5678)	Acc@1 56.250 (60.627)	Acc@5 92.188 (97.591)
 * Acc@1 60.612 Acc@5 97.604
epoch 21, total time 393.64
Test: [0/750]	Time 0.823 (0.823)	Loss 0.7295 (0.7295)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.105 (0.113)	Loss 0.4814 (0.6994)	Acc@1 81.250 (80.105)	Acc@5 100.000 (87.717)
Test: [200/750]	Time 0.109 (0.109)	Loss 1.4124 (0.6575)	Acc@1 53.125 (78.467)	Acc@5 93.750 (92.460)
Test: [300/750]	Time 0.172 (0.108)	Loss 1.7583 (0.8837)	Acc@1 21.875 (69.093)	Acc@5 90.625 (92.276)
Test: [400/750]	Time 0.096 (0.107)	Loss 0.9217 (1.0377)	Acc@1 75.000 (59.944)	Acc@5 84.375 (90.719)
Test: [500/750]	Time 0.094 (0.105)	Loss 0.9985 (1.0339)	Acc@1 68.750 (61.334)	Acc@5 96.875 (89.421)
Test: [600/750]	Time 0.103 (0.105)	Loss 0.6814 (1.0481)	Acc@1 81.250 (61.439)	Acc@5 96.875 (89.434)
Test: [700/750]	Time 0.087 (0.105)	Loss 1.4413 (1.0384)	Acc@1 40.625 (61.649)	Acc@5 78.125 (89.894)
 * Acc@1 61.379 Acc@5 89.783
saving the best model!
==> training...
Epoch: [22][0/875]	Time 1.758 (1.758)	Data 1.329 (1.329)	Loss 3.4650 (3.4650)	Loss@kd 3.6145 (3.6145)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [22][100/875]	Time 0.503 (0.468)	Data 0.007 (0.020)	Loss 3.2007 (3.5299)	Loss@kd 3.4424 (3.5349)	Acc@1 67.188 (59.994)	Acc@5 100.000 (97.726)
Epoch: [22][200/875]	Time 0.424 (0.461)	Data 0.007 (0.014)	Loss 3.6302 (3.5330)	Loss@kd 3.6015 (3.5425)	Acc@1 62.500 (60.378)	Acc@5 98.438 (97.582)
Epoch: [22][300/875]	Time 0.443 (0.455)	Data 0.007 (0.011)	Loss 3.2665 (3.5386)	Loss@kd 3.3088 (3.5531)	Acc@1 62.500 (60.600)	Acc@5 98.438 (97.612)
Epoch: [22][400/875]	Time 0.404 (0.449)	Data 0.005 (0.010)	Loss 3.6546 (3.5395)	Loss@kd 3.5179 (3.5555)	Acc@1 56.250 (60.673)	Acc@5 98.438 (97.643)
Epoch: [22][500/875]	Time 0.386 (0.445)	Data 0.007 (0.010)	Loss 3.3893 (3.5296)	Loss@kd 3.3752 (3.5436)	Acc@1 57.812 (60.825)	Acc@5 98.438 (97.589)
Epoch: [22][600/875]	Time 0.467 (0.447)	Data 0.007 (0.009)	Loss 3.2184 (3.5260)	Loss@kd 3.3513 (3.5435)	Acc@1 73.438 (60.969)	Acc@5 98.438 (97.611)
Epoch: [22][700/875]	Time 0.477 (0.448)	Data 0.007 (0.009)	Loss 3.3941 (3.5208)	Loss@kd 3.4100 (3.5356)	Acc@1 60.938 (60.942)	Acc@5 98.438 (97.611)
Epoch: [22][800/875]	Time 0.431 (0.448)	Data 0.007 (0.009)	Loss 3.4992 (3.5205)	Loss@kd 3.3748 (3.5380)	Acc@1 62.500 (60.986)	Acc@5 96.875 (97.636)
 * Acc@1 60.914 Acc@5 97.648
epoch 22, total time 393.05
Test: [0/750]	Time 0.828 (0.828)	Loss 0.7348 (0.7348)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.105 (0.110)	Loss 0.6158 (0.6477)	Acc@1 78.125 (80.662)	Acc@5 100.000 (88.304)
Test: [200/750]	Time 0.111 (0.109)	Loss 1.5638 (0.6722)	Acc@1 46.875 (77.425)	Acc@5 84.375 (91.775)
Test: [300/750]	Time 0.082 (0.106)	Loss 1.3499 (0.9007)	Acc@1 50.000 (66.279)	Acc@5 93.750 (91.227)
Test: [400/750]	Time 0.098 (0.106)	Loss 0.9080 (0.9815)	Acc@1 75.000 (61.066)	Acc@5 90.625 (91.443)
Test: [500/750]	Time 0.100 (0.105)	Loss 0.7503 (0.9795)	Acc@1 75.000 (62.388)	Acc@5 93.750 (90.413)
Test: [600/750]	Time 0.090 (0.105)	Loss 0.8487 (0.9865)	Acc@1 65.625 (62.994)	Acc@5 96.875 (90.313)
Test: [700/750]	Time 0.102 (0.104)	Loss 1.5053 (1.0095)	Acc@1 50.000 (62.076)	Acc@5 81.250 (90.148)
 * Acc@1 61.617 Acc@5 89.696
saving the best model!
==> training...
Epoch: [23][0/875]	Time 1.845 (1.845)	Data 1.392 (1.392)	Loss 3.3863 (3.3863)	Loss@kd 3.4356 (3.4356)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [23][100/875]	Time 0.417 (0.466)	Data 0.007 (0.021)	Loss 3.5283 (3.5059)	Loss@kd 3.5721 (3.5162)	Acc@1 65.625 (61.200)	Acc@5 92.188 (97.618)
Epoch: [23][200/875]	Time 0.425 (0.459)	Data 0.007 (0.014)	Loss 3.5039 (3.4939)	Loss@kd 3.3230 (3.4909)	Acc@1 53.125 (60.751)	Acc@5 98.438 (97.621)
Epoch: [23][300/875]	Time 0.450 (0.456)	Data 0.007 (0.012)	Loss 3.5219 (3.5059)	Loss@kd 3.7083 (3.5146)	Acc@1 67.188 (60.953)	Acc@5 100.000 (97.654)
Epoch: [23][400/875]	Time 0.534 (0.454)	Data 0.007 (0.010)	Loss 4.2430 (3.5138)	Loss@kd 4.6025 (3.5268)	Acc@1 59.375 (60.910)	Acc@5 96.875 (97.611)
Epoch: [23][500/875]	Time 0.438 (0.454)	Data 0.007 (0.010)	Loss 3.4213 (3.5027)	Loss@kd 3.2627 (3.5176)	Acc@1 51.562 (61.115)	Acc@5 98.438 (97.667)
Epoch: [23][600/875]	Time 0.418 (0.452)	Data 0.007 (0.009)	Loss 3.3246 (3.4947)	Loss@kd 3.3859 (3.5147)	Acc@1 67.188 (61.450)	Acc@5 100.000 (97.671)
Epoch: [23][700/875]	Time 0.427 (0.449)	Data 0.007 (0.009)	Loss 3.3598 (3.4968)	Loss@kd 3.2854 (3.5178)	Acc@1 60.938 (61.365)	Acc@5 98.438 (97.693)
Epoch: [23][800/875]	Time 0.454 (0.446)	Data 0.007 (0.009)	Loss 3.1997 (3.4919)	Loss@kd 3.3010 (3.5091)	Acc@1 67.188 (61.390)	Acc@5 100.000 (97.710)
 * Acc@1 61.261 Acc@5 97.716
epoch 23, total time 391.45
Test: [0/750]	Time 0.784 (0.784)	Loss 0.5780 (0.5780)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.098 (0.113)	Loss 0.4671 (0.5486)	Acc@1 84.375 (82.550)	Acc@5 100.000 (90.316)
Test: [200/750]	Time 0.103 (0.106)	Loss 1.7497 (0.5787)	Acc@1 31.250 (80.286)	Acc@5 81.250 (92.879)
Test: [300/750]	Time 0.175 (0.105)	Loss 1.5645 (0.9122)	Acc@1 34.375 (63.580)	Acc@5 93.750 (90.303)
Test: [400/750]	Time 0.122 (0.103)	Loss 0.7614 (1.0155)	Acc@1 78.125 (59.281)	Acc@5 87.500 (89.791)
Test: [500/750]	Time 0.110 (0.104)	Loss 0.5948 (0.9792)	Acc@1 78.125 (62.107)	Acc@5 96.875 (89.789)
Test: [600/750]	Time 0.078 (0.103)	Loss 0.9119 (0.9713)	Acc@1 75.000 (63.124)	Acc@5 96.875 (90.204)
Test: [700/750]	Time 0.136 (0.103)	Loss 1.2681 (0.9880)	Acc@1 46.875 (62.313)	Acc@5 81.250 (90.482)
 * Acc@1 62.121 Acc@5 90.400
saving the best model!
==> training...
Epoch: [24][0/875]	Time 1.796 (1.796)	Data 1.364 (1.364)	Loss 3.3477 (3.3477)	Loss@kd 3.3793 (3.3793)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [24][100/875]	Time 0.472 (0.464)	Data 0.007 (0.020)	Loss 3.6352 (3.4693)	Loss@kd 3.4015 (3.4877)	Acc@1 54.688 (61.324)	Acc@5 93.750 (97.788)
Epoch: [24][200/875]	Time 0.463 (0.457)	Data 0.007 (0.014)	Loss 3.3928 (3.4505)	Loss@kd 3.4361 (3.4584)	Acc@1 64.062 (61.458)	Acc@5 95.312 (97.886)
Epoch: [24][300/875]	Time 0.428 (0.455)	Data 0.007 (0.011)	Loss 3.4700 (3.4545)	Loss@kd 3.4608 (3.4650)	Acc@1 60.938 (61.400)	Acc@5 98.438 (97.913)
Epoch: [24][400/875]	Time 0.462 (0.454)	Data 0.007 (0.010)	Loss 3.4156 (3.4715)	Loss@kd 3.4535 (3.4851)	Acc@1 64.062 (61.195)	Acc@5 98.438 (97.830)
Epoch: [24][500/875]	Time 0.538 (0.454)	Data 0.007 (0.010)	Loss 3.6636 (3.4760)	Loss@kd 3.6354 (3.4910)	Acc@1 62.500 (61.078)	Acc@5 98.438 (97.795)
Epoch: [24][600/875]	Time 0.430 (0.454)	Data 0.007 (0.009)	Loss 3.2277 (3.4628)	Loss@kd 3.2327 (3.4814)	Acc@1 64.062 (61.278)	Acc@5 98.438 (97.798)
Epoch: [24][700/875]	Time 0.448 (0.453)	Data 0.007 (0.009)	Loss 3.4108 (3.4594)	Loss@kd 3.4004 (3.4787)	Acc@1 67.188 (61.497)	Acc@5 100.000 (97.747)
Epoch: [24][800/875]	Time 0.450 (0.453)	Data 0.007 (0.009)	Loss 3.1962 (3.4577)	Loss@kd 3.3894 (3.4773)	Acc@1 71.875 (61.599)	Acc@5 100.000 (97.761)
 * Acc@1 61.573 Acc@5 97.759
epoch 24, total time 396.40
Test: [0/750]	Time 0.803 (0.803)	Loss 0.6696 (0.6696)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.109)	Loss 0.7524 (0.5519)	Acc@1 65.625 (82.457)	Acc@5 100.000 (89.573)
Test: [200/750]	Time 0.079 (0.106)	Loss 1.7620 (0.6719)	Acc@1 25.000 (75.451)	Acc@5 87.500 (91.962)
Test: [300/750]	Time 0.101 (0.104)	Loss 1.5886 (0.9673)	Acc@1 40.625 (61.265)	Acc@5 90.625 (90.583)
Test: [400/750]	Time 0.095 (0.104)	Loss 0.9001 (1.0569)	Acc@1 71.875 (56.866)	Acc@5 84.375 (90.415)
Test: [500/750]	Time 0.106 (0.103)	Loss 0.9074 (1.0522)	Acc@1 71.875 (58.421)	Acc@5 90.625 (89.895)
Test: [600/750]	Time 0.098 (0.103)	Loss 0.8967 (1.0648)	Acc@1 53.125 (59.609)	Acc@5 87.500 (89.179)
Test: [700/750]	Time 0.095 (0.103)	Loss 1.0450 (1.0471)	Acc@1 65.625 (60.739)	Acc@5 90.625 (89.546)
 * Acc@1 61.583 Acc@5 89.850
==> training...
Epoch: [25][0/875]	Time 1.728 (1.728)	Data 1.324 (1.324)	Loss 3.5133 (3.5133)	Loss@kd 3.4828 (3.4828)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [25][100/875]	Time 0.439 (0.455)	Data 0.006 (0.020)	Loss 3.4614 (3.4813)	Loss@kd 3.5350 (3.4944)	Acc@1 59.375 (61.123)	Acc@5 100.000 (98.035)
Epoch: [25][200/875]	Time 0.450 (0.452)	Data 0.007 (0.014)	Loss 3.2936 (3.4683)	Loss@kd 3.3356 (3.4825)	Acc@1 62.500 (61.521)	Acc@5 100.000 (97.831)
Epoch: [25][300/875]	Time 0.430 (0.452)	Data 0.007 (0.011)	Loss 3.6300 (3.4594)	Loss@kd 3.5733 (3.4828)	Acc@1 64.062 (61.981)	Acc@5 95.312 (97.918)
Epoch: [25][400/875]	Time 0.536 (0.452)	Data 0.007 (0.010)	Loss 3.6646 (3.4444)	Loss@kd 3.7562 (3.4664)	Acc@1 65.625 (62.013)	Acc@5 95.312 (97.919)
Epoch: [25][500/875]	Time 0.443 (0.452)	Data 0.007 (0.010)	Loss 3.3355 (3.4384)	Loss@kd 3.4548 (3.4631)	Acc@1 57.812 (62.197)	Acc@5 100.000 (97.873)
Epoch: [25][600/875]	Time 0.459 (0.452)	Data 0.007 (0.009)	Loss 3.6340 (3.4406)	Loss@kd 3.4252 (3.4635)	Acc@1 51.562 (62.120)	Acc@5 98.438 (97.876)
Epoch: [25][700/875]	Time 0.455 (0.452)	Data 0.008 (0.009)	Loss 3.9136 (3.4342)	Loss@kd 3.6056 (3.4581)	Acc@1 60.938 (62.346)	Acc@5 95.312 (97.856)
Epoch: [25][800/875]	Time 0.453 (0.452)	Data 0.007 (0.009)	Loss 3.4574 (3.4310)	Loss@kd 3.3003 (3.4527)	Acc@1 57.812 (62.299)	Acc@5 98.438 (97.848)
 * Acc@1 62.329 Acc@5 97.848
epoch 25, total time 395.76
Test: [0/750]	Time 0.815 (0.815)	Loss 0.6229 (0.6229)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.166 (0.114)	Loss 0.5952 (0.5565)	Acc@1 75.000 (82.178)	Acc@5 100.000 (90.006)
Test: [200/750]	Time 0.098 (0.108)	Loss 1.8396 (0.6199)	Acc@1 31.250 (78.047)	Acc@5 81.250 (93.004)
Test: [300/750]	Time 0.095 (0.106)	Loss 0.8950 (0.9020)	Acc@1 84.375 (64.109)	Acc@5 100.000 (92.068)
Test: [400/750]	Time 0.127 (0.105)	Loss 0.8973 (0.9150)	Acc@1 75.000 (64.394)	Acc@5 90.625 (92.823)
Test: [500/750]	Time 0.093 (0.104)	Loss 1.2148 (0.9485)	Acc@1 56.250 (64.615)	Acc@5 84.375 (91.430)
Test: [600/750]	Time 0.094 (0.104)	Loss 0.9465 (1.0076)	Acc@1 59.375 (62.786)	Acc@5 93.750 (90.188)
Test: [700/750]	Time 0.105 (0.104)	Loss 1.5956 (1.0444)	Acc@1 37.500 (60.828)	Acc@5 75.000 (89.872)
 * Acc@1 60.146 Acc@5 89.567
==> training...
Epoch: [26][0/875]	Time 1.877 (1.877)	Data 1.402 (1.402)	Loss 3.5653 (3.5653)	Loss@kd 3.8801 (3.8801)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [26][100/875]	Time 0.433 (0.464)	Data 0.007 (0.021)	Loss 3.7860 (3.3911)	Loss@kd 3.9802 (3.4295)	Acc@1 56.250 (62.717)	Acc@5 100.000 (98.128)
Epoch: [26][200/875]	Time 0.423 (0.446)	Data 0.007 (0.014)	Loss 3.5589 (3.3939)	Loss@kd 3.4415 (3.4204)	Acc@1 56.250 (62.547)	Acc@5 96.875 (98.220)
Epoch: [26][300/875]	Time 0.427 (0.439)	Data 0.007 (0.011)	Loss 3.4296 (3.3859)	Loss@kd 3.2079 (3.4090)	Acc@1 62.500 (62.510)	Acc@5 98.438 (98.131)
Epoch: [26][400/875]	Time 0.502 (0.439)	Data 0.007 (0.010)	Loss 3.3501 (3.3947)	Loss@kd 3.3266 (3.4180)	Acc@1 57.812 (62.255)	Acc@5 100.000 (98.071)
Epoch: [26][500/875]	Time 0.514 (0.442)	Data 0.005 (0.010)	Loss 3.2613 (3.4017)	Loss@kd 3.1985 (3.4274)	Acc@1 62.500 (62.241)	Acc@5 96.875 (98.060)
Epoch: [26][600/875]	Time 0.459 (0.443)	Data 0.007 (0.009)	Loss 3.2684 (3.4017)	Loss@kd 3.2991 (3.4259)	Acc@1 68.750 (62.326)	Acc@5 98.438 (97.977)
Epoch: [26][700/875]	Time 0.465 (0.445)	Data 0.007 (0.009)	Loss 3.2709 (3.3951)	Loss@kd 3.2783 (3.4149)	Acc@1 57.812 (62.317)	Acc@5 98.438 (97.965)
Epoch: [26][800/875]	Time 0.453 (0.446)	Data 0.007 (0.009)	Loss 3.1392 (3.4077)	Loss@kd 3.1903 (3.4300)	Acc@1 65.625 (62.285)	Acc@5 100.000 (97.948)
 * Acc@1 62.180 Acc@5 97.895
epoch 26, total time 390.79
Test: [0/750]	Time 0.859 (0.859)	Loss 0.7555 (0.7555)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.099 (0.114)	Loss 0.5457 (0.6398)	Acc@1 68.750 (81.250)	Acc@5 100.000 (90.316)
Test: [200/750]	Time 0.099 (0.110)	Loss 1.8381 (0.6828)	Acc@1 21.875 (76.539)	Acc@5 87.500 (92.786)
Test: [300/750]	Time 0.104 (0.108)	Loss 1.4793 (0.9888)	Acc@1 46.875 (62.074)	Acc@5 90.625 (90.334)
Test: [400/750]	Time 0.111 (0.107)	Loss 0.6638 (1.0395)	Acc@1 81.250 (59.383)	Acc@5 90.625 (90.493)
Test: [500/750]	Time 0.084 (0.107)	Loss 0.6914 (0.9950)	Acc@1 87.500 (62.419)	Acc@5 96.875 (90.326)
Test: [600/750]	Time 0.083 (0.107)	Loss 0.7708 (0.9898)	Acc@1 75.000 (63.670)	Acc@5 90.625 (90.381)
Test: [700/750]	Time 0.076 (0.106)	Loss 1.4896 (0.9968)	Acc@1 40.625 (63.160)	Acc@5 78.125 (90.536)
 * Acc@1 62.521 Acc@5 90.287
saving the best model!
==> training...
Epoch: [27][0/875]	Time 1.815 (1.815)	Data 1.379 (1.379)	Loss 3.3919 (3.3919)	Loss@kd 3.3312 (3.3312)	Acc@1 54.688 (54.688)	Acc@5 95.312 (95.312)
Epoch: [27][100/875]	Time 0.420 (0.469)	Data 0.007 (0.020)	Loss 3.1820 (3.4221)	Loss@kd 3.4091 (3.4208)	Acc@1 68.750 (61.696)	Acc@5 100.000 (97.664)
Epoch: [27][200/875]	Time 0.476 (0.460)	Data 0.007 (0.014)	Loss 3.3213 (3.4211)	Loss@kd 3.3433 (3.4244)	Acc@1 62.500 (61.606)	Acc@5 98.438 (97.676)
Epoch: [27][300/875]	Time 0.414 (0.458)	Data 0.007 (0.011)	Loss 3.4640 (3.3918)	Loss@kd 3.3384 (3.3966)	Acc@1 53.125 (61.996)	Acc@5 95.312 (97.778)
Epoch: [27][400/875]	Time 0.526 (0.456)	Data 0.007 (0.010)	Loss 3.4743 (3.3913)	Loss@kd 3.3831 (3.4079)	Acc@1 62.500 (62.410)	Acc@5 96.875 (97.837)
Epoch: [27][500/875]	Time 0.413 (0.451)	Data 0.005 (0.010)	Loss 3.3104 (3.3821)	Loss@kd 3.2566 (3.4013)	Acc@1 60.938 (62.562)	Acc@5 100.000 (97.895)
Epoch: [27][600/875]	Time 0.423 (0.448)	Data 0.008 (0.009)	Loss 3.7079 (3.3777)	Loss@kd 3.8424 (3.3948)	Acc@1 62.500 (62.542)	Acc@5 100.000 (97.897)
Epoch: [27][700/875]	Time 0.448 (0.446)	Data 0.007 (0.009)	Loss 3.1645 (3.3767)	Loss@kd 3.1543 (3.3956)	Acc@1 57.812 (62.607)	Acc@5 100.000 (97.891)
Epoch: [27][800/875]	Time 0.435 (0.446)	Data 0.007 (0.009)	Loss 3.2961 (3.3759)	Loss@kd 3.3774 (3.3958)	Acc@1 67.188 (62.650)	Acc@5 95.312 (97.895)
 * Acc@1 62.641 Acc@5 97.882
epoch 27, total time 390.95
Test: [0/750]	Time 0.805 (0.805)	Loss 0.5771 (0.5771)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.177 (0.112)	Loss 0.6803 (0.5815)	Acc@1 78.125 (81.559)	Acc@5 96.875 (90.192)
Test: [200/750]	Time 0.089 (0.108)	Loss 1.4028 (0.6277)	Acc@1 46.875 (78.451)	Acc@5 93.750 (92.973)
Test: [300/750]	Time 0.093 (0.106)	Loss 1.3517 (0.8257)	Acc@1 46.875 (70.079)	Acc@5 90.625 (92.857)
Test: [400/750]	Time 0.094 (0.105)	Loss 0.6117 (0.9229)	Acc@1 84.375 (64.386)	Acc@5 90.625 (92.667)
Test: [500/750]	Time 0.111 (0.104)	Loss 0.8060 (0.8930)	Acc@1 78.125 (66.698)	Acc@5 96.875 (92.203)
Test: [600/750]	Time 0.097 (0.104)	Loss 0.8936 (0.9053)	Acc@1 75.000 (67.003)	Acc@5 90.625 (91.930)
Test: [700/750]	Time 0.088 (0.103)	Loss 1.7933 (0.9445)	Acc@1 34.375 (65.242)	Acc@5 65.625 (91.414)
 * Acc@1 63.996 Acc@5 90.767
saving the best model!
==> training...
Epoch: [28][0/875]	Time 1.865 (1.865)	Data 1.389 (1.389)	Loss 3.5602 (3.5602)	Loss@kd 3.4007 (3.4007)	Acc@1 57.812 (57.812)	Acc@5 90.625 (90.625)
Epoch: [28][100/875]	Time 0.424 (0.465)	Data 0.007 (0.021)	Loss 3.4087 (3.3659)	Loss@kd 3.4751 (3.3770)	Acc@1 60.938 (62.423)	Acc@5 98.438 (97.602)
Epoch: [28][200/875]	Time 0.428 (0.456)	Data 0.007 (0.014)	Loss 3.4105 (3.3473)	Loss@kd 3.5363 (3.3604)	Acc@1 68.750 (62.718)	Acc@5 98.438 (97.777)
Epoch: [28][300/875]	Time 0.416 (0.455)	Data 0.007 (0.011)	Loss 3.1775 (3.3376)	Loss@kd 3.2402 (3.3444)	Acc@1 65.625 (62.604)	Acc@5 98.438 (97.825)
Epoch: [28][400/875]	Time 0.477 (0.454)	Data 0.008 (0.010)	Loss 3.5348 (3.3411)	Loss@kd 3.3293 (3.3525)	Acc@1 56.250 (62.730)	Acc@5 95.312 (97.900)
Epoch: [28][500/875]	Time 0.414 (0.453)	Data 0.005 (0.010)	Loss 3.3629 (3.3445)	Loss@kd 3.3198 (3.3638)	Acc@1 57.812 (62.818)	Acc@5 98.438 (97.942)
Epoch: [28][600/875]	Time 0.552 (0.452)	Data 0.007 (0.009)	Loss 2.9997 (3.3474)	Loss@kd 3.1618 (3.3673)	Acc@1 67.188 (62.890)	Acc@5 100.000 (97.925)
Epoch: [28][700/875]	Time 0.450 (0.452)	Data 0.007 (0.009)	Loss 3.3689 (3.3456)	Loss@kd 3.2748 (3.3672)	Acc@1 54.688 (62.961)	Acc@5 98.438 (97.940)
Epoch: [28][800/875]	Time 0.391 (0.450)	Data 0.005 (0.009)	Loss 3.4643 (3.3471)	Loss@kd 3.6194 (3.3660)	Acc@1 57.812 (62.857)	Acc@5 96.875 (97.963)
 * Acc@1 62.896 Acc@5 97.975
epoch 28, total time 392.66
Test: [0/750]	Time 0.762 (0.762)	Loss 0.6859 (0.6859)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.101 (0.114)	Loss 0.5470 (0.4669)	Acc@1 81.250 (86.757)	Acc@5 96.875 (91.244)
Test: [200/750]	Time 0.154 (0.109)	Loss 1.3517 (0.5679)	Acc@1 56.250 (82.618)	Acc@5 81.250 (93.019)
Test: [300/750]	Time 0.100 (0.107)	Loss 1.4991 (0.8156)	Acc@1 34.375 (71.885)	Acc@5 84.375 (91.642)
Test: [400/750]	Time 0.083 (0.105)	Loss 0.7854 (0.9362)	Acc@1 78.125 (64.838)	Acc@5 90.625 (91.521)
Test: [500/750]	Time 0.103 (0.105)	Loss 1.0390 (0.9374)	Acc@1 59.375 (65.868)	Acc@5 90.625 (91.062)
Test: [600/750]	Time 0.102 (0.104)	Loss 1.5302 (0.9891)	Acc@1 50.000 (63.457)	Acc@5 78.125 (90.531)
Test: [700/750]	Time 0.094 (0.104)	Loss 1.9417 (1.0575)	Acc@1 46.875 (60.325)	Acc@5 68.750 (89.604)
 * Acc@1 59.254 Acc@5 88.992
==> training...
Epoch: [29][0/875]	Time 1.965 (1.965)	Data 1.352 (1.352)	Loss 3.1819 (3.1819)	Loss@kd 3.4795 (3.4795)	Acc@1 79.688 (79.688)	Acc@5 96.875 (96.875)
Epoch: [29][100/875]	Time 0.459 (0.465)	Data 0.007 (0.020)	Loss 3.2860 (3.4331)	Loss@kd 3.3183 (3.4581)	Acc@1 65.625 (61.649)	Acc@5 93.750 (97.679)
Epoch: [29][200/875]	Time 0.449 (0.458)	Data 0.006 (0.014)	Loss 3.6282 (3.3925)	Loss@kd 3.5579 (3.4238)	Acc@1 57.812 (62.842)	Acc@5 95.312 (97.792)
Epoch: [29][300/875]	Time 0.460 (0.455)	Data 0.007 (0.011)	Loss 3.2462 (3.3571)	Loss@kd 3.2766 (3.3901)	Acc@1 62.500 (63.175)	Acc@5 92.188 (97.872)
Epoch: [29][400/875]	Time 0.485 (0.455)	Data 0.007 (0.010)	Loss 3.2533 (3.3520)	Loss@kd 3.5369 (3.3844)	Acc@1 75.000 (63.322)	Acc@5 98.438 (97.935)
Epoch: [29][500/875]	Time 0.448 (0.454)	Data 0.008 (0.010)	Loss 4.3369 (3.3503)	Loss@kd 4.7937 (3.3835)	Acc@1 64.062 (63.442)	Acc@5 98.438 (97.904)
Epoch: [29][600/875]	Time 0.430 (0.453)	Data 0.008 (0.009)	Loss 3.0201 (3.3448)	Loss@kd 3.0803 (3.3725)	Acc@1 67.188 (63.342)	Acc@5 100.000 (97.907)
Epoch: [29][700/875]	Time 0.431 (0.453)	Data 0.007 (0.009)	Loss 3.4058 (3.3359)	Loss@kd 3.4136 (3.3647)	Acc@1 68.750 (63.300)	Acc@5 98.438 (97.958)
Epoch: [29][800/875]	Time 0.504 (0.454)	Data 0.008 (0.009)	Loss 3.0250 (3.3331)	Loss@kd 3.0794 (3.3608)	Acc@1 73.438 (63.302)	Acc@5 98.438 (97.971)
 * Acc@1 63.139 Acc@5 97.957
epoch 29, total time 397.50
Test: [0/750]	Time 0.815 (0.815)	Loss 0.7010 (0.7010)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.111 (0.110)	Loss 0.5906 (0.6082)	Acc@1 71.875 (81.436)	Acc@5 100.000 (90.316)
Test: [200/750]	Time 0.107 (0.108)	Loss 1.4869 (0.6282)	Acc@1 31.250 (77.923)	Acc@5 90.625 (93.595)
Test: [300/750]	Time 0.182 (0.106)	Loss 1.2526 (0.8777)	Acc@1 53.125 (66.591)	Acc@5 96.875 (92.068)
Test: [400/750]	Time 0.101 (0.106)	Loss 0.8053 (0.9560)	Acc@1 81.250 (62.749)	Acc@5 90.625 (92.184)
Test: [500/750]	Time 0.098 (0.105)	Loss 0.8658 (0.9643)	Acc@1 68.750 (63.679)	Acc@5 87.500 (91.161)
Test: [600/750]	Time 0.101 (0.104)	Loss 0.6898 (0.9726)	Acc@1 78.125 (64.143)	Acc@5 93.750 (90.713)
Test: [700/750]	Time 0.087 (0.103)	Loss 1.3811 (0.9662)	Acc@1 46.875 (64.158)	Acc@5 78.125 (91.022)
 * Acc@1 64.083 Acc@5 90.938
saving the best model!
==> training...
Epoch: [30][0/875]	Time 1.752 (1.752)	Data 1.324 (1.324)	Loss 3.3629 (3.3629)	Loss@kd 3.3845 (3.3845)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [30][100/875]	Time 0.489 (0.448)	Data 0.006 (0.020)	Loss 3.0027 (3.2961)	Loss@kd 3.3133 (3.3249)	Acc@1 79.688 (64.264)	Acc@5 100.000 (97.834)
Epoch: [30][200/875]	Time 0.409 (0.440)	Data 0.007 (0.013)	Loss 3.2438 (3.3011)	Loss@kd 3.3935 (3.3335)	Acc@1 76.562 (64.140)	Acc@5 96.875 (97.971)
Epoch: [30][300/875]	Time 0.408 (0.442)	Data 0.006 (0.011)	Loss 3.4760 (3.2850)	Loss@kd 3.4261 (3.3191)	Acc@1 57.812 (64.374)	Acc@5 100.000 (98.064)
Epoch: [30][400/875]	Time 0.443 (0.444)	Data 0.008 (0.010)	Loss 3.1263 (3.2812)	Loss@kd 3.2643 (3.3124)	Acc@1 71.875 (64.359)	Acc@5 95.312 (98.052)
Epoch: [30][500/875]	Time 0.456 (0.446)	Data 0.007 (0.009)	Loss 3.3017 (3.2834)	Loss@kd 3.2456 (3.3106)	Acc@1 56.250 (64.187)	Acc@5 96.875 (98.016)
Epoch: [30][600/875]	Time 0.464 (0.448)	Data 0.007 (0.009)	Loss 3.0703 (3.2801)	Loss@kd 3.3187 (3.3039)	Acc@1 70.312 (64.094)	Acc@5 98.438 (98.029)
Epoch: [30][700/875]	Time 0.421 (0.448)	Data 0.006 (0.009)	Loss 3.5354 (3.2861)	Loss@kd 3.5439 (3.3136)	Acc@1 60.938 (64.141)	Acc@5 98.438 (98.036)
Epoch: [30][800/875]	Time 0.452 (0.449)	Data 0.007 (0.009)	Loss 2.9514 (3.2899)	Loss@kd 3.0089 (3.3155)	Acc@1 76.562 (64.018)	Acc@5 100.000 (98.026)
 * Acc@1 64.034 Acc@5 98.036
epoch 30, total time 393.97
Test: [0/750]	Time 0.831 (0.831)	Loss 0.5721 (0.5721)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.097 (0.107)	Loss 0.7315 (0.5037)	Acc@1 78.125 (83.849)	Acc@5 100.000 (91.460)
Test: [200/750]	Time 0.106 (0.106)	Loss 1.4258 (0.6660)	Acc@1 37.500 (76.306)	Acc@5 84.375 (93.144)
Test: [300/750]	Time 0.098 (0.104)	Loss 1.4487 (0.9243)	Acc@1 37.500 (64.161)	Acc@5 96.875 (92.224)
Test: [400/750]	Time 0.107 (0.104)	Loss 1.0340 (1.0445)	Acc@1 75.000 (58.276)	Acc@5 81.250 (91.326)
Test: [500/750]	Time 0.115 (0.104)	Loss 0.6683 (1.0365)	Acc@1 78.125 (60.049)	Acc@5 90.625 (90.351)
Test: [600/750]	Time 0.093 (0.104)	Loss 0.8412 (1.0147)	Acc@1 75.000 (61.824)	Acc@5 90.625 (90.001)
Test: [700/750]	Time 0.113 (0.103)	Loss 0.8707 (0.9896)	Acc@1 71.875 (63.182)	Acc@5 90.625 (90.612)
 * Acc@1 64.071 Acc@5 90.946
==> training...
Epoch: [31][0/875]	Time 1.723 (1.723)	Data 1.271 (1.271)	Loss 3.1727 (3.1727)	Loss@kd 3.2634 (3.2634)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [31][100/875]	Time 0.483 (0.464)	Data 0.007 (0.019)	Loss 3.3055 (3.3066)	Loss@kd 3.2436 (3.3452)	Acc@1 51.562 (63.645)	Acc@5 98.438 (98.283)
Epoch: [31][200/875]	Time 0.403 (0.458)	Data 0.006 (0.013)	Loss 3.1605 (3.3049)	Loss@kd 3.1654 (3.3293)	Acc@1 67.188 (62.881)	Acc@5 100.000 (98.251)
Epoch: [31][300/875]	Time 0.443 (0.454)	Data 0.007 (0.011)	Loss 3.1576 (3.3007)	Loss@kd 3.2575 (3.3261)	Acc@1 67.188 (63.107)	Acc@5 100.000 (98.168)
Epoch: [31][400/875]	Time 0.491 (0.448)	Data 0.006 (0.010)	Loss 3.2171 (3.2919)	Loss@kd 3.2060 (3.3121)	Acc@1 62.500 (63.353)	Acc@5 98.438 (98.126)
Epoch: [31][500/875]	Time 0.413 (0.445)	Data 0.007 (0.009)	Loss 3.0328 (3.2859)	Loss@kd 3.1440 (3.3079)	Acc@1 70.312 (63.567)	Acc@5 98.438 (98.116)
Epoch: [31][600/875]	Time 0.430 (0.445)	Data 0.006 (0.009)	Loss 3.2833 (3.2879)	Loss@kd 3.2780 (3.3086)	Acc@1 60.938 (63.543)	Acc@5 100.000 (98.089)
Epoch: [31][700/875]	Time 0.440 (0.446)	Data 0.008 (0.009)	Loss 2.8589 (3.2777)	Loss@kd 2.9916 (3.2993)	Acc@1 71.875 (63.657)	Acc@5 96.875 (98.108)
Epoch: [31][800/875]	Time 0.424 (0.447)	Data 0.007 (0.009)	Loss 2.9381 (3.2705)	Loss@kd 3.1167 (3.2905)	Acc@1 65.625 (63.653)	Acc@5 100.000 (98.123)
 * Acc@1 63.712 Acc@5 98.132
epoch 31, total time 391.84
Test: [0/750]	Time 0.873 (0.873)	Loss 0.6854 (0.6854)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.170 (0.115)	Loss 0.7543 (0.6274)	Acc@1 65.625 (80.074)	Acc@5 100.000 (89.635)
Test: [200/750]	Time 0.098 (0.110)	Loss 1.4741 (0.7352)	Acc@1 43.750 (73.632)	Acc@5 87.500 (91.838)
Test: [300/750]	Time 0.098 (0.108)	Loss 1.2388 (0.9260)	Acc@1 65.625 (64.369)	Acc@5 87.500 (91.923)
Test: [400/750]	Time 0.103 (0.107)	Loss 0.6135 (0.9541)	Acc@1 81.250 (62.749)	Acc@5 90.625 (92.425)
Test: [500/750]	Time 0.116 (0.106)	Loss 0.8080 (0.9238)	Acc@1 68.750 (64.901)	Acc@5 96.875 (91.891)
Test: [600/750]	Time 0.097 (0.106)	Loss 0.8602 (0.9413)	Acc@1 68.750 (65.110)	Acc@5 90.625 (91.285)
Test: [700/750]	Time 0.086 (0.106)	Loss 1.4811 (0.9578)	Acc@1 50.000 (64.426)	Acc@5 81.250 (91.245)
 * Acc@1 63.979 Acc@5 91.142
==> training...
Epoch: [32][0/875]	Time 1.765 (1.765)	Data 1.311 (1.311)	Loss 4.8024 (4.8024)	Loss@kd 5.1535 (5.1535)	Acc@1 57.812 (57.812)	Acc@5 98.438 (98.438)
Epoch: [32][100/875]	Time 0.431 (0.464)	Data 0.007 (0.020)	Loss 3.1345 (3.2269)	Loss@kd 3.3796 (3.2475)	Acc@1 71.875 (64.666)	Acc@5 100.000 (98.066)
Epoch: [32][200/875]	Time 0.450 (0.459)	Data 0.007 (0.013)	Loss 3.5128 (3.2247)	Loss@kd 3.2498 (3.2550)	Acc@1 59.375 (64.995)	Acc@5 93.750 (98.142)
Epoch: [32][300/875]	Time 0.429 (0.457)	Data 0.007 (0.011)	Loss 3.1134 (3.2305)	Loss@kd 3.1025 (3.2522)	Acc@1 70.312 (64.317)	Acc@5 96.875 (98.183)
Epoch: [32][400/875]	Time 0.445 (0.456)	Data 0.007 (0.010)	Loss 3.5263 (3.2449)	Loss@kd 3.3879 (3.2709)	Acc@1 59.375 (64.257)	Acc@5 93.750 (98.118)
Epoch: [32][500/875]	Time 0.489 (0.455)	Data 0.007 (0.010)	Loss 3.4109 (3.2469)	Loss@kd 3.2123 (3.2751)	Acc@1 51.562 (64.324)	Acc@5 100.000 (98.107)
Epoch: [32][600/875]	Time 0.519 (0.454)	Data 0.008 (0.009)	Loss 3.1992 (3.2452)	Loss@kd 3.1254 (3.2710)	Acc@1 60.938 (64.203)	Acc@5 96.875 (98.102)
Epoch: [32][700/875]	Time 0.430 (0.451)	Data 0.007 (0.009)	Loss 3.0742 (3.2412)	Loss@kd 3.2100 (3.2664)	Acc@1 75.000 (64.232)	Acc@5 100.000 (98.085)
Epoch: [32][800/875]	Time 0.437 (0.449)	Data 0.008 (0.009)	Loss 3.4956 (3.2407)	Loss@kd 3.3210 (3.2641)	Acc@1 48.438 (64.209)	Acc@5 96.875 (98.082)
 * Acc@1 64.241 Acc@5 98.088
epoch 32, total time 391.99
Test: [0/750]	Time 0.882 (0.882)	Loss 0.6955 (0.6955)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.094 (0.115)	Loss 0.5112 (0.5427)	Acc@1 84.375 (83.973)	Acc@5 96.875 (90.687)
Test: [200/750]	Time 0.189 (0.109)	Loss 1.7771 (0.5796)	Acc@1 25.000 (80.597)	Acc@5 75.000 (92.848)
Test: [300/750]	Time 0.105 (0.107)	Loss 1.3235 (0.9468)	Acc@1 50.000 (64.223)	Acc@5 96.875 (90.355)
Test: [400/750]	Time 0.104 (0.106)	Loss 0.8269 (1.0184)	Acc@1 81.250 (61.043)	Acc@5 87.500 (90.991)
Test: [500/750]	Time 0.076 (0.106)	Loss 0.7864 (1.0093)	Acc@1 71.875 (62.537)	Acc@5 93.750 (90.438)
Test: [600/750]	Time 0.113 (0.106)	Loss 0.9038 (1.0216)	Acc@1 65.625 (62.703)	Acc@5 90.625 (89.907)
Test: [700/750]	Time 0.106 (0.106)	Loss 0.9542 (1.0071)	Acc@1 68.750 (63.044)	Acc@5 90.625 (90.629)
 * Acc@1 63.817 Acc@5 91.042
==> training...
Epoch: [33][0/875]	Time 1.925 (1.925)	Data 1.388 (1.388)	Loss 3.4034 (3.4034)	Loss@kd 3.2055 (3.2055)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
Epoch: [33][100/875]	Time 0.457 (0.466)	Data 0.006 (0.020)	Loss 3.2608 (3.2373)	Loss@kd 3.1242 (3.2739)	Acc@1 64.062 (65.022)	Acc@5 96.875 (98.298)
Epoch: [33][200/875]	Time 0.412 (0.459)	Data 0.005 (0.014)	Loss 3.1556 (3.2211)	Loss@kd 3.1347 (3.2555)	Acc@1 67.188 (65.151)	Acc@5 98.438 (98.290)
Epoch: [33][300/875]	Time 0.403 (0.457)	Data 0.007 (0.011)	Loss 3.1665 (3.2299)	Loss@kd 3.2252 (3.2672)	Acc@1 64.062 (64.903)	Acc@5 100.000 (98.225)
Epoch: [33][400/875]	Time 0.430 (0.456)	Data 0.007 (0.010)	Loss 2.8509 (3.2285)	Loss@kd 3.1193 (3.2641)	Acc@1 73.438 (64.877)	Acc@5 100.000 (98.192)
Epoch: [33][500/875]	Time 0.418 (0.455)	Data 0.007 (0.010)	Loss 3.1820 (3.2238)	Loss@kd 3.1628 (3.2506)	Acc@1 62.500 (64.596)	Acc@5 100.000 (98.235)
Epoch: [33][600/875]	Time 0.466 (0.455)	Data 0.005 (0.009)	Loss 3.3047 (3.2207)	Loss@kd 3.3414 (3.2433)	Acc@1 64.062 (64.556)	Acc@5 93.750 (98.188)
Epoch: [33][700/875]	Time 0.550 (0.455)	Data 0.007 (0.009)	Loss 3.1218 (3.2205)	Loss@kd 3.0704 (3.2422)	Acc@1 70.312 (64.519)	Acc@5 98.438 (98.174)
Epoch: [33][800/875]	Time 0.464 (0.454)	Data 0.007 (0.009)	Loss 3.0374 (3.2217)	Loss@kd 2.9359 (3.2438)	Acc@1 60.938 (64.472)	Acc@5 100.000 (98.180)
 * Acc@1 64.505 Acc@5 98.177
epoch 33, total time 397.59
Test: [0/750]	Time 0.775 (0.775)	Loss 0.6601 (0.6601)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.116 (0.110)	Loss 0.4143 (0.5962)	Acc@1 87.500 (83.014)	Acc@5 96.875 (89.759)
Test: [200/750]	Time 0.088 (0.109)	Loss 1.3806 (0.5661)	Acc@1 43.750 (82.074)	Acc@5 84.375 (93.268)
Test: [300/750]	Time 0.097 (0.107)	Loss 1.8796 (0.8357)	Acc@1 15.625 (70.743)	Acc@5 84.375 (92.421)
Test: [400/750]	Time 0.108 (0.107)	Loss 0.6208 (0.9949)	Acc@1 87.500 (62.773)	Acc@5 90.625 (90.835)
Test: [500/750]	Time 0.098 (0.106)	Loss 0.8171 (0.9435)	Acc@1 71.875 (65.388)	Acc@5 93.750 (90.918)
Test: [600/750]	Time 0.104 (0.106)	Loss 0.8044 (0.9527)	Acc@1 78.125 (65.100)	Acc@5 100.000 (91.400)
Test: [700/750]	Time 0.171 (0.106)	Loss 1.7745 (0.9897)	Acc@1 43.750 (63.356)	Acc@5 68.750 (91.222)
 * Acc@1 62.396 Acc@5 90.625
==> training...
Epoch: [34][0/875]	Time 1.711 (1.711)	Data 1.303 (1.303)	Loss 3.2310 (3.2310)	Loss@kd 3.3850 (3.3850)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [34][100/875]	Time 0.434 (0.451)	Data 0.007 (0.019)	Loss 3.4005 (3.1883)	Loss@kd 3.4021 (3.2061)	Acc@1 62.500 (64.913)	Acc@5 98.438 (98.097)
Epoch: [34][200/875]	Time 0.423 (0.451)	Data 0.007 (0.013)	Loss 3.1769 (3.2061)	Loss@kd 3.2814 (3.2319)	Acc@1 65.625 (64.809)	Acc@5 100.000 (98.189)
Epoch: [34][300/875]	Time 0.405 (0.452)	Data 0.005 (0.011)	Loss 3.3708 (3.2288)	Loss@kd 3.2526 (3.2608)	Acc@1 56.250 (64.753)	Acc@5 98.438 (98.199)
Epoch: [34][400/875]	Time 0.424 (0.451)	Data 0.007 (0.010)	Loss 3.0111 (3.2222)	Loss@kd 3.0755 (3.2539)	Acc@1 62.500 (64.924)	Acc@5 98.438 (98.227)
Epoch: [34][500/875]	Time 0.432 (0.451)	Data 0.007 (0.009)	Loss 3.1704 (3.2153)	Loss@kd 3.1250 (3.2469)	Acc@1 64.062 (64.895)	Acc@5 96.875 (98.179)
Epoch: [34][600/875]	Time 0.522 (0.451)	Data 0.007 (0.009)	Loss 3.0743 (3.2199)	Loss@kd 3.1881 (3.2495)	Acc@1 68.750 (64.749)	Acc@5 100.000 (98.092)
Epoch: [34][700/875]	Time 0.460 (0.452)	Data 0.007 (0.009)	Loss 3.4405 (3.2215)	Loss@kd 3.3906 (3.2518)	Acc@1 57.812 (64.707)	Acc@5 100.000 (98.132)
Epoch: [34][800/875]	Time 0.466 (0.452)	Data 0.007 (0.008)	Loss 3.3402 (3.2242)	Loss@kd 3.3271 (3.2529)	Acc@1 64.062 (64.654)	Acc@5 96.875 (98.106)
 * Acc@1 64.643 Acc@5 98.141
epoch 34, total time 395.90
Test: [0/750]	Time 0.830 (0.830)	Loss 0.5394 (0.5394)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.091 (0.111)	Loss 0.4747 (0.4347)	Acc@1 84.375 (85.953)	Acc@5 100.000 (93.193)
Test: [200/750]	Time 0.169 (0.106)	Loss 1.6484 (0.5277)	Acc@1 31.250 (81.794)	Acc@5 78.125 (94.543)
Test: [300/750]	Time 0.092 (0.105)	Loss 1.4063 (0.8396)	Acc@1 46.875 (68.615)	Acc@5 90.625 (92.307)
Test: [400/750]	Time 0.102 (0.104)	Loss 0.9087 (0.9376)	Acc@1 75.000 (63.918)	Acc@5 84.375 (91.778)
Test: [500/750]	Time 0.089 (0.105)	Loss 0.6669 (0.9188)	Acc@1 71.875 (65.563)	Acc@5 93.750 (91.149)
Test: [600/750]	Time 0.113 (0.104)	Loss 0.7004 (0.9209)	Acc@1 68.750 (66.010)	Acc@5 96.875 (91.223)
Test: [700/750]	Time 0.109 (0.104)	Loss 1.2213 (0.9260)	Acc@1 56.250 (65.728)	Acc@5 84.375 (91.499)
 * Acc@1 65.717 Acc@5 91.325
saving the best model!
==> training...
Epoch: [35][0/875]	Time 1.852 (1.852)	Data 1.362 (1.362)	Loss 3.1614 (3.1614)	Loss@kd 3.1187 (3.1187)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [35][100/875]	Time 0.423 (0.465)	Data 0.007 (0.020)	Loss 3.2124 (3.2203)	Loss@kd 3.0680 (3.2668)	Acc@1 59.375 (65.316)	Acc@5 98.438 (98.438)
Epoch: [35][200/875]	Time 0.408 (0.451)	Data 0.007 (0.014)	Loss 3.0845 (3.2017)	Loss@kd 2.9523 (3.2396)	Acc@1 64.062 (65.260)	Acc@5 96.875 (98.406)
Epoch: [35][300/875]	Time 0.417 (0.445)	Data 0.007 (0.011)	Loss 3.2811 (3.1932)	Loss@kd 3.0249 (3.2196)	Acc@1 64.062 (65.028)	Acc@5 93.750 (98.303)
Epoch: [35][400/875]	Time 0.470 (0.443)	Data 0.007 (0.010)	Loss 3.2839 (3.1924)	Loss@kd 3.2791 (3.2203)	Acc@1 64.062 (65.021)	Acc@5 98.438 (98.274)
Epoch: [35][500/875]	Time 0.412 (0.444)	Data 0.007 (0.010)	Loss 3.1391 (3.1797)	Loss@kd 3.0789 (3.2098)	Acc@1 64.062 (65.132)	Acc@5 98.438 (98.282)
Epoch: [35][600/875]	Time 0.461 (0.445)	Data 0.008 (0.009)	Loss 2.9364 (3.1817)	Loss@kd 2.9956 (3.2087)	Acc@1 75.000 (64.983)	Acc@5 98.438 (98.284)
Epoch: [35][700/875]	Time 0.516 (0.446)	Data 0.007 (0.009)	Loss 3.2477 (3.1865)	Loss@kd 2.9835 (3.2131)	Acc@1 64.062 (64.941)	Acc@5 93.750 (98.266)
Epoch: [35][800/875]	Time 0.413 (0.447)	Data 0.007 (0.009)	Loss 3.1119 (3.1810)	Loss@kd 3.0812 (3.2071)	Acc@1 70.312 (64.973)	Acc@5 98.438 (98.227)
 * Acc@1 65.043 Acc@5 98.207
epoch 35, total time 392.05
Test: [0/750]	Time 0.852 (0.852)	Loss 0.8758 (0.8758)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.105 (0.113)	Loss 0.3915 (0.7403)	Acc@1 84.375 (79.734)	Acc@5 100.000 (90.934)
Test: [200/750]	Time 0.098 (0.110)	Loss 1.5425 (0.6499)	Acc@1 37.500 (80.053)	Acc@5 84.375 (93.610)
Test: [300/750]	Time 0.120 (0.109)	Loss 1.3507 (0.9155)	Acc@1 59.375 (66.819)	Acc@5 90.625 (91.580)
Test: [400/750]	Time 0.105 (0.108)	Loss 1.1977 (1.0031)	Acc@1 71.875 (62.858)	Acc@5 78.125 (90.976)
Test: [500/750]	Time 0.118 (0.108)	Loss 0.4854 (1.0033)	Acc@1 81.250 (63.330)	Acc@5 100.000 (90.326)
Test: [600/750]	Time 0.098 (0.107)	Loss 0.8758 (0.9907)	Acc@1 68.750 (64.034)	Acc@5 93.750 (90.422)
Test: [700/750]	Time 0.189 (0.107)	Loss 0.9516 (0.9857)	Acc@1 62.500 (63.708)	Acc@5 84.375 (91.004)
 * Acc@1 64.154 Acc@5 91.217
==> training...
Epoch: [36][0/875]	Time 1.936 (1.936)	Data 1.408 (1.408)	Loss 3.1873 (3.1873)	Loss@kd 3.1273 (3.1273)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [36][100/875]	Time 0.442 (0.469)	Data 0.007 (0.021)	Loss 3.2106 (3.1868)	Loss@kd 3.1297 (3.2160)	Acc@1 67.188 (65.192)	Acc@5 96.875 (98.190)
Epoch: [36][200/875]	Time 0.435 (0.461)	Data 0.007 (0.014)	Loss 3.1013 (3.1631)	Loss@kd 3.0822 (3.1879)	Acc@1 60.938 (65.330)	Acc@5 98.438 (98.243)
Epoch: [36][300/875]	Time 0.485 (0.458)	Data 0.007 (0.012)	Loss 3.1345 (3.1564)	Loss@kd 3.0888 (3.1814)	Acc@1 64.062 (65.526)	Acc@5 96.875 (98.245)
Epoch: [36][400/875]	Time 0.449 (0.456)	Data 0.010 (0.010)	Loss 3.2494 (3.1628)	Loss@kd 3.2904 (3.1873)	Acc@1 62.500 (65.578)	Acc@5 100.000 (98.231)
Epoch: [36][500/875]	Time 0.408 (0.452)	Data 0.007 (0.010)	Loss 3.1498 (3.1669)	Loss@kd 3.0557 (3.1892)	Acc@1 62.500 (65.388)	Acc@5 100.000 (98.216)
Epoch: [36][600/875]	Time 0.482 (0.448)	Data 0.007 (0.009)	Loss 3.2197 (3.1618)	Loss@kd 3.0963 (3.1862)	Acc@1 67.188 (65.347)	Acc@5 96.875 (98.271)
Epoch: [36][700/875]	Time 0.461 (0.446)	Data 0.007 (0.009)	Loss 2.8341 (3.1563)	Loss@kd 2.9788 (3.1790)	Acc@1 70.312 (65.329)	Acc@5 100.000 (98.270)
Epoch: [36][800/875]	Time 0.432 (0.447)	Data 0.007 (0.009)	Loss 4.3949 (3.1609)	Loss@kd 5.0117 (3.1814)	Acc@1 65.625 (65.325)	Acc@5 98.438 (98.248)
 * Acc@1 65.479 Acc@5 98.245
epoch 36, total time 391.45
Test: [0/750]	Time 0.881 (0.881)	Loss 0.8712 (0.8712)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.100 (0.116)	Loss 0.3097 (0.7155)	Acc@1 90.625 (82.178)	Acc@5 96.875 (89.790)
Test: [200/750]	Time 0.149 (0.110)	Loss 1.7506 (0.5988)	Acc@1 31.250 (82.945)	Acc@5 78.125 (93.330)
Test: [300/750]	Time 0.101 (0.108)	Loss 1.7913 (0.9119)	Acc@1 25.000 (69.549)	Acc@5 71.875 (91.217)
Test: [400/750]	Time 0.101 (0.107)	Loss 0.7561 (1.0732)	Acc@1 84.375 (61.931)	Acc@5 90.625 (89.137)
Test: [500/750]	Time 0.090 (0.107)	Loss 0.6301 (1.0278)	Acc@1 84.375 (63.991)	Acc@5 100.000 (89.340)
Test: [600/750]	Time 0.098 (0.106)	Loss 0.7646 (1.0176)	Acc@1 75.000 (64.013)	Acc@5 93.750 (90.043)
Test: [700/750]	Time 0.098 (0.106)	Loss 1.7387 (1.0408)	Acc@1 50.000 (62.718)	Acc@5 71.875 (90.161)
 * Acc@1 62.025 Acc@5 89.696
==> training...
Epoch: [37][0/875]	Time 1.982 (1.982)	Data 1.368 (1.368)	Loss 3.3061 (3.3061)	Loss@kd 3.2087 (3.2087)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
Epoch: [37][100/875]	Time 0.476 (0.471)	Data 0.007 (0.020)	Loss 3.4190 (3.1623)	Loss@kd 3.5233 (3.1921)	Acc@1 70.312 (65.347)	Acc@5 98.438 (98.205)
Epoch: [37][200/875]	Time 0.432 (0.462)	Data 0.007 (0.014)	Loss 3.0876 (3.1508)	Loss@kd 3.2790 (3.1889)	Acc@1 70.312 (65.586)	Acc@5 100.000 (98.305)
Epoch: [37][300/875]	Time 0.439 (0.458)	Data 0.007 (0.011)	Loss 3.1139 (3.1571)	Loss@kd 3.0761 (3.1942)	Acc@1 62.500 (65.391)	Acc@5 98.438 (98.344)
Epoch: [37][400/875]	Time 0.444 (0.457)	Data 0.007 (0.010)	Loss 3.5295 (3.1455)	Loss@kd 3.4862 (3.1785)	Acc@1 57.812 (65.383)	Acc@5 96.875 (98.340)
Epoch: [37][500/875]	Time 0.437 (0.456)	Data 0.007 (0.010)	Loss 3.0044 (3.1426)	Loss@kd 3.1057 (3.1730)	Acc@1 71.875 (65.425)	Acc@5 98.438 (98.313)
Epoch: [37][600/875]	Time 0.467 (0.455)	Data 0.008 (0.009)	Loss 4.1208 (3.1490)	Loss@kd 4.3787 (3.1765)	Acc@1 64.062 (65.264)	Acc@5 96.875 (98.282)
Epoch: [37][700/875]	Time 0.426 (0.455)	Data 0.007 (0.009)	Loss 3.1221 (3.1413)	Loss@kd 3.1374 (3.1694)	Acc@1 60.938 (65.442)	Acc@5 98.438 (98.313)
Epoch: [37][800/875]	Time 0.483 (0.452)	Data 0.007 (0.009)	Loss 3.0086 (3.1408)	Loss@kd 3.1055 (3.1665)	Acc@1 68.750 (65.471)	Acc@5 100.000 (98.309)
 * Acc@1 65.605 Acc@5 98.298
epoch 37, total time 394.18
Test: [0/750]	Time 0.831 (0.831)	Loss 0.7119 (0.7119)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.098 (0.112)	Loss 0.3093 (0.4960)	Acc@1 87.500 (85.520)	Acc@5 100.000 (92.048)
Test: [200/750]	Time 0.099 (0.109)	Loss 1.8242 (0.4928)	Acc@1 40.625 (84.297)	Acc@5 75.000 (94.434)
Test: [300/750]	Time 0.190 (0.106)	Loss 1.7138 (0.8615)	Acc@1 37.500 (69.674)	Acc@5 81.250 (91.881)
Test: [400/750]	Time 0.090 (0.106)	Loss 1.1141 (1.0347)	Acc@1 65.625 (62.625)	Acc@5 81.250 (89.643)
Test: [500/750]	Time 0.111 (0.105)	Loss 0.6635 (1.0442)	Acc@1 78.125 (62.999)	Acc@5 90.625 (88.573)
Test: [600/750]	Time 0.090 (0.105)	Loss 0.9084 (1.0384)	Acc@1 53.125 (63.160)	Acc@5 100.000 (89.060)
Test: [700/750]	Time 0.109 (0.105)	Loss 1.7114 (1.0908)	Acc@1 46.875 (60.975)	Acc@5 78.125 (88.900)
 * Acc@1 59.629 Acc@5 88.017
==> training...
Epoch: [38][0/875]	Time 1.814 (1.814)	Data 1.345 (1.345)	Loss 3.2902 (3.2902)	Loss@kd 3.5493 (3.5493)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [38][100/875]	Time 0.561 (0.471)	Data 0.008 (0.020)	Loss 2.8556 (3.1981)	Loss@kd 2.9665 (3.2408)	Acc@1 67.188 (65.470)	Acc@5 100.000 (98.329)
Epoch: [38][200/875]	Time 0.420 (0.461)	Data 0.007 (0.014)	Loss 2.9931 (3.1688)	Loss@kd 3.0206 (3.1989)	Acc@1 68.750 (65.446)	Acc@5 98.438 (98.235)
Epoch: [38][300/875]	Time 0.471 (0.458)	Data 0.007 (0.011)	Loss 3.3399 (3.1695)	Loss@kd 3.1711 (3.1987)	Acc@1 60.938 (65.500)	Acc@5 95.312 (98.235)
Epoch: [38][400/875]	Time 0.442 (0.456)	Data 0.007 (0.010)	Loss 3.2336 (3.1511)	Loss@kd 3.4229 (3.1803)	Acc@1 71.875 (65.563)	Acc@5 98.438 (98.231)
Epoch: [38][500/875]	Time 0.432 (0.455)	Data 0.007 (0.010)	Loss 2.8654 (3.1456)	Loss@kd 2.9556 (3.1778)	Acc@1 76.562 (65.672)	Acc@5 98.438 (98.229)
Epoch: [38][600/875]	Time 0.447 (0.456)	Data 0.007 (0.009)	Loss 3.2622 (3.1337)	Loss@kd 3.0588 (3.1662)	Acc@1 68.750 (65.820)	Acc@5 93.750 (98.279)
Epoch: [38][700/875]	Time 0.457 (0.456)	Data 0.007 (0.009)	Loss 3.1781 (3.1361)	Loss@kd 3.1035 (3.1644)	Acc@1 65.625 (65.661)	Acc@5 98.438 (98.248)
Epoch: [38][800/875]	Time 0.455 (0.456)	Data 0.007 (0.009)	Loss 3.0505 (3.1303)	Loss@kd 3.0276 (3.1570)	Acc@1 64.062 (65.680)	Acc@5 95.312 (98.248)
 * Acc@1 65.700 Acc@5 98.266
epoch 38, total time 398.58
Test: [0/750]	Time 0.815 (0.815)	Loss 0.7993 (0.7993)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.106 (0.112)	Loss 0.2906 (0.7398)	Acc@1 87.500 (80.724)	Acc@5 100.000 (91.089)
Test: [200/750]	Time 0.088 (0.107)	Loss 1.7509 (0.6123)	Acc@1 31.250 (82.058)	Acc@5 84.375 (93.688)
Test: [300/750]	Time 0.102 (0.107)	Loss 1.4222 (0.9250)	Acc@1 40.625 (67.971)	Acc@5 90.625 (90.750)
Test: [400/750]	Time 0.096 (0.106)	Loss 0.6660 (1.0229)	Acc@1 81.250 (62.952)	Acc@5 93.750 (90.079)
Test: [500/750]	Time 0.077 (0.106)	Loss 0.6069 (0.9761)	Acc@1 81.250 (65.351)	Acc@5 96.875 (89.876)
Test: [600/750]	Time 0.093 (0.105)	Loss 0.9087 (0.9658)	Acc@1 71.875 (65.963)	Acc@5 96.875 (90.479)
Test: [700/750]	Time 0.099 (0.105)	Loss 1.3643 (0.9901)	Acc@1 53.125 (64.466)	Acc@5 81.250 (90.852)
 * Acc@1 63.875 Acc@5 90.667
==> training...
Epoch: [39][0/875]	Time 1.907 (1.907)	Data 1.378 (1.378)	Loss 2.6603 (2.6603)	Loss@kd 2.8640 (2.8640)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [39][100/875]	Time 0.420 (0.445)	Data 0.005 (0.020)	Loss 2.9327 (3.0845)	Loss@kd 3.0246 (3.1121)	Acc@1 71.875 (66.476)	Acc@5 100.000 (98.391)
Epoch: [39][200/875]	Time 0.452 (0.441)	Data 0.007 (0.014)	Loss 3.0119 (3.0930)	Loss@kd 2.9946 (3.1233)	Acc@1 64.062 (66.348)	Acc@5 98.438 (98.507)
Epoch: [39][300/875]	Time 0.432 (0.444)	Data 0.007 (0.011)	Loss 3.3466 (3.0888)	Loss@kd 2.9428 (3.1229)	Acc@1 45.312 (66.487)	Acc@5 95.312 (98.427)
Epoch: [39][400/875]	Time 0.468 (0.447)	Data 0.007 (0.010)	Loss 2.8365 (3.0978)	Loss@kd 2.9280 (3.1287)	Acc@1 71.875 (66.307)	Acc@5 100.000 (98.375)
Epoch: [39][500/875]	Time 0.431 (0.448)	Data 0.007 (0.010)	Loss 2.8810 (3.1029)	Loss@kd 3.0069 (3.1331)	Acc@1 73.438 (66.124)	Acc@5 96.875 (98.381)
Epoch: [39][600/875]	Time 0.481 (0.449)	Data 0.007 (0.009)	Loss 3.1322 (3.1082)	Loss@kd 3.0789 (3.1373)	Acc@1 67.188 (66.023)	Acc@5 98.438 (98.393)
Epoch: [39][700/875]	Time 0.424 (0.450)	Data 0.007 (0.009)	Loss 2.9580 (3.1031)	Loss@kd 2.9039 (3.1292)	Acc@1 70.312 (65.962)	Acc@5 96.875 (98.375)
Epoch: [39][800/875]	Time 0.531 (0.450)	Data 0.007 (0.009)	Loss 3.4829 (3.0997)	Loss@kd 3.1379 (3.1240)	Acc@1 57.812 (65.974)	Acc@5 95.312 (98.340)
 * Acc@1 66.046 Acc@5 98.339
epoch 39, total time 394.36
Test: [0/750]	Time 0.842 (0.842)	Loss 0.5549 (0.5549)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.096 (0.111)	Loss 0.3901 (0.5201)	Acc@1 78.125 (83.292)	Acc@5 100.000 (93.100)
Test: [200/750]	Time 0.115 (0.108)	Loss 1.3920 (0.5230)	Acc@1 46.875 (82.198)	Acc@5 84.375 (94.916)
Test: [300/750]	Time 0.191 (0.106)	Loss 1.3261 (0.8185)	Acc@1 50.000 (69.632)	Acc@5 96.875 (93.086)
Test: [400/750]	Time 0.091 (0.105)	Loss 1.4062 (0.9635)	Acc@1 56.250 (63.443)	Acc@5 78.125 (91.334)
Test: [500/750]	Time 0.109 (0.104)	Loss 0.4615 (0.9879)	Acc@1 84.375 (63.386)	Acc@5 100.000 (90.020)
Test: [600/750]	Time 0.094 (0.104)	Loss 1.0679 (0.9666)	Acc@1 59.375 (64.393)	Acc@5 96.875 (90.651)
Test: [700/750]	Time 0.098 (0.104)	Loss 1.5023 (0.9979)	Acc@1 50.000 (62.879)	Acc@5 75.000 (90.670)
 * Acc@1 62.450 Acc@5 90.454
==> training...
Epoch: [40][0/875]	Time 1.709 (1.709)	Data 1.278 (1.278)	Loss 2.7382 (2.7382)	Loss@kd 2.9561 (2.9561)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [40][100/875]	Time 0.508 (0.465)	Data 0.007 (0.019)	Loss 2.9191 (3.1432)	Loss@kd 2.9379 (3.1807)	Acc@1 70.312 (65.965)	Acc@5 100.000 (98.252)
Epoch: [40][200/875]	Time 0.436 (0.458)	Data 0.007 (0.013)	Loss 3.2948 (3.1166)	Loss@kd 3.2495 (3.1553)	Acc@1 62.500 (66.433)	Acc@5 96.875 (98.259)
Epoch: [40][300/875]	Time 0.431 (0.452)	Data 0.007 (0.011)	Loss 3.9387 (3.1018)	Loss@kd 4.3794 (3.1401)	Acc@1 70.312 (66.523)	Acc@5 98.438 (98.318)
Epoch: [40][400/875]	Time 0.433 (0.447)	Data 0.007 (0.010)	Loss 2.9519 (3.1001)	Loss@kd 2.8676 (3.1398)	Acc@1 59.375 (66.482)	Acc@5 100.000 (98.453)
Epoch: [40][500/875]	Time 0.442 (0.444)	Data 0.007 (0.010)	Loss 3.1938 (3.0922)	Loss@kd 3.1598 (3.1255)	Acc@1 67.188 (66.470)	Acc@5 98.438 (98.444)
Epoch: [40][600/875]	Time 0.411 (0.446)	Data 0.005 (0.009)	Loss 3.6196 (3.0962)	Loss@kd 3.7429 (3.1318)	Acc@1 60.938 (66.402)	Acc@5 98.438 (98.458)
Epoch: [40][700/875]	Time 0.447 (0.447)	Data 0.005 (0.009)	Loss 3.0833 (3.0867)	Loss@kd 3.0446 (3.1183)	Acc@1 60.938 (66.369)	Acc@5 100.000 (98.453)
Epoch: [40][800/875]	Time 0.429 (0.447)	Data 0.007 (0.009)	Loss 2.8955 (3.0833)	Loss@kd 2.8395 (3.1112)	Acc@1 70.312 (66.249)	Acc@5 100.000 (98.477)
 * Acc@1 66.198 Acc@5 98.479
epoch 40, total time 392.28
Test: [0/750]	Time 0.869 (0.869)	Loss 0.6878 (0.6878)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.105 (0.106)	Loss 0.4792 (0.5479)	Acc@1 84.375 (84.004)	Acc@5 100.000 (91.058)
Test: [200/750]	Time 0.103 (0.107)	Loss 1.5404 (0.5546)	Acc@1 40.625 (81.996)	Acc@5 84.375 (93.610)
Test: [300/750]	Time 0.098 (0.106)	Loss 1.4323 (0.8298)	Acc@1 43.750 (68.895)	Acc@5 93.750 (92.151)
Test: [400/750]	Time 0.087 (0.106)	Loss 0.9260 (0.9155)	Acc@1 75.000 (65.415)	Acc@5 84.375 (92.020)
Test: [500/750]	Time 0.120 (0.106)	Loss 0.5878 (0.9253)	Acc@1 84.375 (65.887)	Acc@5 100.000 (90.981)
Test: [600/750]	Time 0.109 (0.107)	Loss 0.7271 (0.9230)	Acc@1 81.250 (66.135)	Acc@5 93.750 (91.181)
Test: [700/750]	Time 0.104 (0.106)	Loss 1.0137 (0.9223)	Acc@1 71.875 (65.919)	Acc@5 75.000 (91.579)
 * Acc@1 66.196 Acc@5 91.671
saving the best model!
==> Saving...
==> training...
Epoch: [41][0/875]	Time 1.774 (1.774)	Data 1.311 (1.311)	Loss 2.9742 (2.9742)	Loss@kd 3.0392 (3.0392)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [41][100/875]	Time 0.472 (0.467)	Data 0.007 (0.020)	Loss 3.0674 (3.0871)	Loss@kd 3.0966 (3.1302)	Acc@1 60.938 (66.739)	Acc@5 96.875 (98.515)
Epoch: [41][200/875]	Time 0.442 (0.461)	Data 0.007 (0.013)	Loss 3.2946 (3.0801)	Loss@kd 3.1530 (3.1085)	Acc@1 59.375 (66.317)	Acc@5 98.438 (98.492)
Epoch: [41][300/875]	Time 0.429 (0.458)	Data 0.007 (0.011)	Loss 2.8976 (3.0724)	Loss@kd 2.9619 (3.0982)	Acc@1 68.750 (66.362)	Acc@5 100.000 (98.396)
Epoch: [41][400/875]	Time 0.451 (0.457)	Data 0.007 (0.010)	Loss 3.1239 (3.0675)	Loss@kd 2.9941 (3.0944)	Acc@1 60.938 (66.307)	Acc@5 98.438 (98.418)
Epoch: [41][500/875]	Time 0.409 (0.456)	Data 0.007 (0.010)	Loss 3.6559 (3.0711)	Loss@kd 3.6433 (3.0937)	Acc@1 60.938 (66.155)	Acc@5 98.438 (98.388)
Epoch: [41][600/875]	Time 0.410 (0.453)	Data 0.005 (0.009)	Loss 3.4873 (3.0721)	Loss@kd 3.4642 (3.0948)	Acc@1 59.375 (66.150)	Acc@5 100.000 (98.391)
Epoch: [41][700/875]	Time 0.511 (0.450)	Data 0.007 (0.009)	Loss 2.8273 (3.0655)	Loss@kd 3.1013 (3.0903)	Acc@1 78.125 (66.352)	Acc@5 100.000 (98.400)
Epoch: [41][800/875]	Time 0.492 (0.449)	Data 0.007 (0.009)	Loss 3.1831 (3.0622)	Loss@kd 3.1278 (3.0896)	Acc@1 59.375 (66.481)	Acc@5 96.875 (98.397)
 * Acc@1 66.461 Acc@5 98.395
epoch 41, total time 393.01
Test: [0/750]	Time 0.836 (0.836)	Loss 1.1502 (1.1502)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.099 (0.109)	Loss 0.3676 (0.7868)	Acc@1 81.250 (77.475)	Acc@5 100.000 (89.480)
Test: [200/750]	Time 0.103 (0.108)	Loss 1.4248 (0.6399)	Acc@1 46.875 (80.271)	Acc@5 81.250 (93.035)
Test: [300/750]	Time 0.107 (0.105)	Loss 1.2852 (0.8418)	Acc@1 53.125 (70.691)	Acc@5 93.750 (92.618)
Test: [400/750]	Time 0.096 (0.105)	Loss 0.8536 (0.9396)	Acc@1 68.750 (65.368)	Acc@5 84.375 (92.503)
Test: [500/750]	Time 0.106 (0.105)	Loss 1.0035 (0.9442)	Acc@1 65.625 (65.918)	Acc@5 93.750 (91.436)
Test: [600/750]	Time 0.104 (0.104)	Loss 0.9786 (0.9746)	Acc@1 62.500 (65.266)	Acc@5 90.625 (91.176)
Test: [700/750]	Time 0.159 (0.104)	Loss 1.5195 (0.9897)	Acc@1 50.000 (64.444)	Acc@5 68.750 (91.289)
 * Acc@1 64.488 Acc@5 91.237
==> training...
Epoch: [42][0/875]	Time 1.758 (1.758)	Data 1.287 (1.287)	Loss 3.1139 (3.1139)	Loss@kd 3.1664 (3.1664)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [42][100/875]	Time 0.454 (0.468)	Data 0.007 (0.019)	Loss 2.9347 (3.0242)	Loss@kd 3.0135 (3.0635)	Acc@1 67.188 (67.327)	Acc@5 100.000 (98.453)
Epoch: [42][200/875]	Time 0.429 (0.461)	Data 0.007 (0.013)	Loss 3.2081 (3.0266)	Loss@kd 3.0687 (3.0680)	Acc@1 59.375 (67.561)	Acc@5 96.875 (98.391)
Epoch: [42][300/875]	Time 0.447 (0.459)	Data 0.008 (0.011)	Loss 3.2728 (3.0215)	Loss@kd 3.5655 (3.0671)	Acc@1 68.750 (67.759)	Acc@5 96.875 (98.422)
Epoch: [42][400/875]	Time 0.430 (0.457)	Data 0.008 (0.010)	Loss 3.0315 (3.0249)	Loss@kd 2.9902 (3.0632)	Acc@1 73.438 (67.523)	Acc@5 98.438 (98.387)
Epoch: [42][500/875]	Time 0.431 (0.456)	Data 0.007 (0.009)	Loss 3.0326 (3.0338)	Loss@kd 2.8925 (3.0684)	Acc@1 53.125 (67.212)	Acc@5 98.438 (98.384)
Epoch: [42][600/875]	Time 0.531 (0.456)	Data 0.007 (0.009)	Loss 2.9780 (3.0354)	Loss@kd 3.0037 (3.0678)	Acc@1 65.625 (67.143)	Acc@5 100.000 (98.357)
Epoch: [42][700/875]	Time 0.448 (0.456)	Data 0.007 (0.009)	Loss 3.0374 (3.0364)	Loss@kd 3.0653 (3.0678)	Acc@1 68.750 (67.058)	Acc@5 98.438 (98.371)
Epoch: [42][800/875]	Time 0.443 (0.456)	Data 0.007 (0.008)	Loss 2.9703 (3.0419)	Loss@kd 3.0903 (3.0701)	Acc@1 70.312 (66.940)	Acc@5 96.875 (98.348)
 * Acc@1 66.841 Acc@5 98.359
epoch 42, total time 398.10
Test: [0/750]	Time 0.856 (0.856)	Loss 0.6570 (0.6570)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.076 (0.113)	Loss 0.5925 (0.5601)	Acc@1 71.875 (81.807)	Acc@5 96.875 (91.677)
Test: [200/750]	Time 0.167 (0.107)	Loss 1.4624 (0.6175)	Acc@1 43.750 (77.488)	Acc@5 90.625 (94.076)
Test: [300/750]	Time 0.093 (0.106)	Loss 1.4769 (0.8447)	Acc@1 40.625 (67.795)	Acc@5 90.625 (92.971)
Test: [400/750]	Time 0.099 (0.105)	Loss 0.8362 (0.9607)	Acc@1 75.000 (62.679)	Acc@5 87.500 (91.926)
Test: [500/750]	Time 0.078 (0.105)	Loss 0.6567 (0.9645)	Acc@1 75.000 (63.517)	Acc@5 96.875 (90.768)
Test: [600/750]	Time 0.098 (0.103)	Loss 0.5605 (0.9362)	Acc@1 81.250 (65.235)	Acc@5 96.875 (90.989)
Test: [700/750]	Time 0.106 (0.104)	Loss 0.9544 (0.9202)	Acc@1 65.625 (65.794)	Acc@5 84.375 (91.472)
 * Acc@1 65.992 Acc@5 91.658
==> training...
Epoch: [43][0/875]	Time 1.818 (1.818)	Data 1.288 (1.288)	Loss 2.8756 (2.8756)	Loss@kd 2.9926 (2.9926)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [43][100/875]	Time 0.429 (0.465)	Data 0.007 (0.019)	Loss 2.9488 (3.0182)	Loss@kd 2.9971 (3.0693)	Acc@1 70.312 (67.543)	Acc@5 98.438 (98.298)
Epoch: [43][200/875]	Time 0.428 (0.458)	Data 0.007 (0.013)	Loss 2.7815 (3.0148)	Loss@kd 2.8177 (3.0597)	Acc@1 62.500 (67.654)	Acc@5 98.438 (98.360)
Epoch: [43][300/875]	Time 0.452 (0.457)	Data 0.007 (0.011)	Loss 3.5296 (3.0285)	Loss@kd 3.4926 (3.0605)	Acc@1 64.062 (67.322)	Acc@5 96.875 (98.328)
Epoch: [43][400/875]	Time 0.427 (0.456)	Data 0.007 (0.010)	Loss 3.1155 (3.0279)	Loss@kd 2.9313 (3.0598)	Acc@1 60.938 (67.230)	Acc@5 98.438 (98.402)
Epoch: [43][500/875]	Time 0.450 (0.456)	Data 0.007 (0.009)	Loss 2.9945 (3.0266)	Loss@kd 2.9217 (3.0617)	Acc@1 60.938 (67.340)	Acc@5 98.438 (98.462)
Epoch: [43][600/875]	Time 0.457 (0.456)	Data 0.007 (0.009)	Loss 2.6062 (3.0242)	Loss@kd 2.8813 (3.0563)	Acc@1 82.812 (67.174)	Acc@5 98.438 (98.458)
Epoch: [43][700/875]	Time 0.432 (0.455)	Data 0.007 (0.009)	Loss 2.9473 (3.0294)	Loss@kd 2.8097 (3.0609)	Acc@1 65.625 (67.134)	Acc@5 96.875 (98.449)
Epoch: [43][800/875]	Time 0.557 (0.455)	Data 0.007 (0.009)	Loss 2.9483 (3.0293)	Loss@kd 3.0372 (3.0602)	Acc@1 64.062 (67.047)	Acc@5 100.000 (98.449)
 * Acc@1 67.061 Acc@5 98.471
epoch 43, total time 398.20
Test: [0/750]	Time 0.826 (0.826)	Loss 0.7220 (0.7220)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.111 (0.111)	Loss 0.3524 (0.5908)	Acc@1 87.500 (82.921)	Acc@5 96.875 (92.512)
Test: [200/750]	Time 0.101 (0.107)	Loss 1.4444 (0.5448)	Acc@1 34.375 (82.898)	Acc@5 87.500 (94.621)
Test: [300/750]	Time 0.160 (0.106)	Loss 1.5383 (0.8385)	Acc@1 34.375 (70.048)	Acc@5 90.625 (92.255)
Test: [400/750]	Time 0.097 (0.105)	Loss 0.9403 (0.9349)	Acc@1 71.875 (65.516)	Acc@5 87.500 (91.825)
Test: [500/750]	Time 0.092 (0.105)	Loss 0.4911 (0.8981)	Acc@1 87.500 (67.615)	Acc@5 100.000 (91.511)
Test: [600/750]	Time 0.098 (0.105)	Loss 0.8870 (0.8886)	Acc@1 59.375 (68.032)	Acc@5 96.875 (91.935)
Test: [700/750]	Time 0.118 (0.105)	Loss 1.4042 (0.9129)	Acc@1 56.250 (66.543)	Acc@5 75.000 (92.047)
 * Acc@1 66.338 Acc@5 91.892
saving the best model!
==> training...
Epoch: [44][0/875]	Time 1.866 (1.866)	Data 1.360 (1.360)	Loss 3.1049 (3.1049)	Loss@kd 2.9630 (2.9630)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [44][100/875]	Time 0.489 (0.463)	Data 0.007 (0.020)	Loss 2.7616 (2.9832)	Loss@kd 2.8534 (3.0055)	Acc@1 70.312 (67.543)	Acc@5 96.875 (98.360)
Epoch: [44][200/875]	Time 0.433 (0.447)	Data 0.007 (0.014)	Loss 2.9273 (2.9920)	Loss@kd 2.9456 (3.0118)	Acc@1 70.312 (67.537)	Acc@5 96.875 (98.406)
Epoch: [44][300/875]	Time 0.421 (0.442)	Data 0.007 (0.011)	Loss 2.8334 (3.0333)	Loss@kd 2.9291 (3.0653)	Acc@1 75.000 (67.426)	Acc@5 100.000 (98.453)
Epoch: [44][400/875]	Time 0.432 (0.444)	Data 0.007 (0.010)	Loss 2.9467 (3.0361)	Loss@kd 2.9945 (3.0684)	Acc@1 68.750 (67.328)	Acc@5 100.000 (98.445)
Epoch: [44][500/875]	Time 0.420 (0.445)	Data 0.007 (0.010)	Loss 2.8622 (3.0439)	Loss@kd 2.9436 (3.0762)	Acc@1 68.750 (67.166)	Acc@5 98.438 (98.369)
Epoch: [44][600/875]	Time 0.454 (0.447)	Data 0.007 (0.009)	Loss 3.0055 (3.0474)	Loss@kd 2.9390 (3.0797)	Acc@1 64.062 (67.130)	Acc@5 98.438 (98.357)
Epoch: [44][700/875]	Time 0.456 (0.448)	Data 0.007 (0.009)	Loss 3.1367 (3.0419)	Loss@kd 3.0632 (3.0762)	Acc@1 65.625 (67.150)	Acc@5 96.875 (98.375)
Epoch: [44][800/875]	Time 0.466 (0.448)	Data 0.007 (0.009)	Loss 2.9353 (3.0353)	Loss@kd 2.8651 (3.0686)	Acc@1 57.812 (67.156)	Acc@5 100.000 (98.418)
 * Acc@1 67.207 Acc@5 98.443
epoch 44, total time 392.84
Test: [0/750]	Time 0.801 (0.801)	Loss 5.8091 (5.8091)	Acc@1 18.750 (18.750)	Acc@5 21.875 (21.875)
Test: [100/750]	Time 0.091 (0.109)	Loss 0.4395 (5.3608)	Acc@1 78.125 (24.072)	Acc@5 100.000 (31.962)
Test: [200/750]	Time 0.097 (0.105)	Loss 1.7554 (2.9510)	Acc@1 43.750 (52.627)	Acc@5 68.750 (64.288)
Test: [300/750]	Time 0.101 (0.103)	Loss 1.8963 (2.4846)	Acc@1 37.500 (49.730)	Acc@5 90.625 (71.055)
Test: [400/750]	Time 0.090 (0.103)	Loss 0.8645 (2.2602)	Acc@1 75.000 (47.382)	Acc@5 87.500 (74.306)
Test: [500/750]	Time 0.094 (0.103)	Loss 0.5121 (1.9827)	Acc@1 87.500 (51.996)	Acc@5 96.875 (77.376)
Test: [600/750]	Time 0.093 (0.103)	Loss 1.0110 (1.8036)	Acc@1 59.375 (54.628)	Acc@5 90.625 (80.148)
Test: [700/750]	Time 0.114 (0.103)	Loss 1.7232 (1.7131)	Acc@1 43.750 (54.547)	Acc@5 81.250 (81.856)
 * Acc@1 54.188 Acc@5 82.092
==> training...
Epoch: [45][0/875]	Time 1.963 (1.963)	Data 1.442 (1.442)	Loss 3.6493 (3.6493)	Loss@kd 4.1458 (4.1458)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Epoch: [45][100/875]	Time 0.440 (0.467)	Data 0.007 (0.021)	Loss 2.8985 (3.0189)	Loss@kd 2.8884 (3.0494)	Acc@1 68.750 (67.095)	Acc@5 100.000 (98.360)
Epoch: [45][200/875]	Time 0.427 (0.459)	Data 0.007 (0.014)	Loss 3.0413 (3.0002)	Loss@kd 2.9691 (3.0272)	Acc@1 62.500 (67.188)	Acc@5 100.000 (98.484)
Epoch: [45][300/875]	Time 0.406 (0.458)	Data 0.005 (0.012)	Loss 2.9555 (3.0000)	Loss@kd 2.8140 (3.0238)	Acc@1 60.938 (67.073)	Acc@5 98.438 (98.380)
Epoch: [45][400/875]	Time 0.494 (0.454)	Data 0.007 (0.011)	Loss 2.9835 (2.9962)	Loss@kd 2.9212 (3.0195)	Acc@1 65.625 (67.102)	Acc@5 98.438 (98.438)
Epoch: [45][500/875]	Time 0.402 (0.448)	Data 0.007 (0.010)	Loss 3.0716 (2.9981)	Loss@kd 2.8738 (3.0255)	Acc@1 65.625 (67.047)	Acc@5 100.000 (98.509)
Epoch: [45][600/875]	Time 0.387 (0.444)	Data 0.005 (0.009)	Loss 3.0576 (3.0010)	Loss@kd 2.9635 (3.0308)	Acc@1 67.188 (67.242)	Acc@5 98.438 (98.513)
Epoch: [45][700/875]	Time 0.436 (0.444)	Data 0.007 (0.009)	Loss 3.1728 (2.9999)	Loss@kd 2.8639 (3.0297)	Acc@1 54.688 (67.272)	Acc@5 96.875 (98.502)
Epoch: [45][800/875]	Time 0.434 (0.445)	Data 0.007 (0.009)	Loss 2.8711 (3.0021)	Loss@kd 2.9705 (3.0309)	Acc@1 68.750 (67.197)	Acc@5 96.875 (98.492)
 * Acc@1 67.173 Acc@5 98.479
epoch 45, total time 389.87
Test: [0/750]	Time 0.814 (0.814)	Loss 0.5951 (0.5951)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.172 (0.111)	Loss 0.4719 (0.4688)	Acc@1 87.500 (85.489)	Acc@5 96.875 (92.915)
Test: [200/750]	Time 0.108 (0.106)	Loss 1.3305 (0.5151)	Acc@1 31.250 (82.960)	Acc@5 90.625 (94.419)
Test: [300/750]	Time 0.094 (0.105)	Loss 1.3609 (0.7965)	Acc@1 59.375 (70.359)	Acc@5 90.625 (92.805)
Test: [400/750]	Time 0.090 (0.105)	Loss 0.6126 (0.8865)	Acc@1 81.250 (66.420)	Acc@5 90.625 (92.425)
Test: [500/750]	Time 0.096 (0.105)	Loss 0.6198 (0.8449)	Acc@1 78.125 (68.713)	Acc@5 100.000 (92.478)
Test: [600/750]	Time 0.099 (0.105)	Loss 0.8705 (0.8742)	Acc@1 78.125 (68.074)	Acc@5 87.500 (92.076)
Test: [700/750]	Time 0.094 (0.104)	Loss 1.0801 (0.8939)	Acc@1 56.250 (67.132)	Acc@5 87.500 (92.270)
 * Acc@1 67.387 Acc@5 92.387
saving the best model!
==> training...
Epoch: [46][0/875]	Time 1.780 (1.780)	Data 1.344 (1.344)	Loss 3.0845 (3.0845)	Loss@kd 3.0844 (3.0844)	Acc@1 68.750 (68.750)	Acc@5 95.312 (95.312)
Epoch: [46][100/875]	Time 0.428 (0.463)	Data 0.007 (0.020)	Loss 2.8084 (2.9865)	Loss@kd 2.9161 (3.0449)	Acc@1 67.188 (67.729)	Acc@5 100.000 (98.561)
Epoch: [46][200/875]	Time 0.443 (0.458)	Data 0.007 (0.014)	Loss 2.9503 (2.9815)	Loss@kd 2.9988 (3.0297)	Acc@1 65.625 (67.561)	Acc@5 98.438 (98.554)
Epoch: [46][300/875]	Time 0.449 (0.456)	Data 0.007 (0.011)	Loss 3.2011 (2.9793)	Loss@kd 2.9577 (3.0148)	Acc@1 59.375 (67.421)	Acc@5 100.000 (98.458)
Epoch: [46][400/875]	Time 0.440 (0.456)	Data 0.007 (0.010)	Loss 3.0663 (2.9702)	Loss@kd 2.9338 (3.0009)	Acc@1 56.250 (67.464)	Acc@5 100.000 (98.469)
Epoch: [46][500/875]	Time 0.419 (0.455)	Data 0.007 (0.010)	Loss 2.8931 (2.9680)	Loss@kd 3.0951 (2.9960)	Acc@1 78.125 (67.393)	Acc@5 98.438 (98.512)
Epoch: [46][600/875]	Time 0.534 (0.455)	Data 0.007 (0.009)	Loss 2.8834 (2.9770)	Loss@kd 2.9625 (3.0075)	Acc@1 68.750 (67.447)	Acc@5 100.000 (98.541)
Epoch: [46][700/875]	Time 0.421 (0.454)	Data 0.007 (0.009)	Loss 2.8538 (2.9943)	Loss@kd 2.9958 (3.0290)	Acc@1 70.312 (67.404)	Acc@5 98.438 (98.536)
Epoch: [46][800/875]	Time 0.413 (0.451)	Data 0.009 (0.009)	Loss 3.2670 (2.9921)	Loss@kd 3.0335 (3.0249)	Acc@1 57.812 (67.484)	Acc@5 95.312 (98.492)
 * Acc@1 67.473 Acc@5 98.495
epoch 46, total time 392.93
Test: [0/750]	Time 0.846 (0.846)	Loss 0.8389 (0.8389)	Acc@1 65.625 (65.625)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.107 (0.116)	Loss 0.3935 (0.5472)	Acc@1 81.250 (83.014)	Acc@5 100.000 (93.812)
Test: [200/750]	Time 0.136 (0.106)	Loss 1.6557 (0.5385)	Acc@1 37.500 (81.872)	Acc@5 78.125 (94.994)
Test: [300/750]	Time 0.098 (0.106)	Loss 1.2055 (0.8722)	Acc@1 59.375 (67.670)	Acc@5 93.750 (92.006)
Test: [400/750]	Time 0.117 (0.105)	Loss 0.7119 (0.9418)	Acc@1 75.000 (65.446)	Acc@5 93.750 (91.794)
Test: [500/750]	Time 0.092 (0.105)	Loss 0.6638 (0.9173)	Acc@1 81.250 (66.960)	Acc@5 96.875 (91.423)
Test: [600/750]	Time 0.103 (0.105)	Loss 0.7533 (0.9192)	Acc@1 68.750 (67.434)	Acc@5 96.875 (91.447)
Test: [700/750]	Time 0.104 (0.105)	Loss 1.2116 (0.9197)	Acc@1 46.875 (66.838)	Acc@5 78.125 (91.967)
 * Acc@1 66.700 Acc@5 92.033
==> training...
Epoch: [47][0/875]	Time 1.888 (1.888)	Data 1.340 (1.340)	Loss 2.6800 (2.6800)	Loss@kd 2.7635 (2.7635)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [47][100/875]	Time 0.453 (0.469)	Data 0.007 (0.020)	Loss 2.8461 (2.9748)	Loss@kd 3.0162 (3.0075)	Acc@1 76.562 (67.621)	Acc@5 98.438 (98.499)
Epoch: [47][200/875]	Time 0.468 (0.462)	Data 0.007 (0.013)	Loss 2.8093 (2.9518)	Loss@kd 2.9749 (2.9859)	Acc@1 71.875 (68.144)	Acc@5 100.000 (98.601)
Epoch: [47][300/875]	Time 0.444 (0.459)	Data 0.007 (0.011)	Loss 2.9433 (2.9503)	Loss@kd 3.0803 (2.9891)	Acc@1 70.312 (68.371)	Acc@5 98.438 (98.609)
Epoch: [47][400/875]	Time 0.416 (0.458)	Data 0.005 (0.010)	Loss 3.0708 (2.9660)	Loss@kd 2.8822 (2.9985)	Acc@1 59.375 (67.955)	Acc@5 95.312 (98.628)
Epoch: [47][500/875]	Time 0.424 (0.457)	Data 0.007 (0.009)	Loss 2.8617 (2.9652)	Loss@kd 2.9849 (2.9991)	Acc@1 67.188 (67.761)	Acc@5 100.000 (98.631)
Epoch: [47][600/875]	Time 0.413 (0.456)	Data 0.007 (0.009)	Loss 2.8768 (2.9642)	Loss@kd 2.7990 (2.9998)	Acc@1 68.750 (67.752)	Acc@5 96.875 (98.666)
Epoch: [47][700/875]	Time 0.400 (0.456)	Data 0.005 (0.009)	Loss 3.0292 (2.9678)	Loss@kd 2.9492 (3.0014)	Acc@1 68.750 (67.673)	Acc@5 100.000 (98.627)
Epoch: [47][800/875]	Time 0.535 (0.456)	Data 0.007 (0.008)	Loss 2.8838 (2.9669)	Loss@kd 2.9394 (2.9997)	Acc@1 67.188 (67.728)	Acc@5 100.000 (98.613)
 * Acc@1 67.680 Acc@5 98.604
epoch 47, total time 398.75
Test: [0/750]	Time 0.836 (0.836)	Loss 1.2810 (1.2810)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/750]	Time 0.102 (0.111)	Loss 0.4599 (0.8681)	Acc@1 81.250 (76.052)	Acc@5 100.000 (88.614)
Test: [200/750]	Time 0.106 (0.110)	Loss 2.1995 (0.7643)	Acc@1 25.000 (75.995)	Acc@5 71.875 (91.978)
Test: [300/750]	Time 0.161 (0.108)	Loss 1.5509 (1.1509)	Acc@1 34.375 (60.455)	Acc@5 93.750 (87.116)
Test: [400/750]	Time 0.092 (0.107)	Loss 0.5272 (1.2225)	Acc@1 84.375 (56.601)	Acc@5 93.750 (87.352)
Test: [500/750]	Time 0.100 (0.106)	Loss 0.9069 (1.1560)	Acc@1 68.750 (59.818)	Acc@5 90.625 (87.856)
Test: [600/750]	Time 0.113 (0.106)	Loss 0.5128 (1.1257)	Acc@1 87.500 (60.862)	Acc@5 96.875 (88.571)
Test: [700/750]	Time 0.090 (0.106)	Loss 1.3964 (1.0914)	Acc@1 59.375 (61.827)	Acc@5 84.375 (89.337)
 * Acc@1 61.688 Acc@5 89.192
==> training...
Epoch: [48][0/875]	Time 1.759 (1.759)	Data 1.317 (1.317)	Loss 2.7981 (2.7981)	Loss@kd 3.0821 (3.0821)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [48][100/875]	Time 0.485 (0.446)	Data 0.010 (0.020)	Loss 2.9143 (2.9650)	Loss@kd 2.9343 (2.9871)	Acc@1 71.875 (67.976)	Acc@5 96.875 (98.639)
Epoch: [48][200/875]	Time 0.463 (0.443)	Data 0.007 (0.013)	Loss 3.0106 (2.9521)	Loss@kd 2.8455 (2.9752)	Acc@1 59.375 (67.856)	Acc@5 100.000 (98.640)
Epoch: [48][300/875]	Time 0.411 (0.447)	Data 0.007 (0.011)	Loss 3.3316 (2.9458)	Loss@kd 3.0396 (2.9758)	Acc@1 57.812 (68.231)	Acc@5 93.750 (98.526)
Epoch: [48][400/875]	Time 0.429 (0.447)	Data 0.007 (0.010)	Loss 3.0795 (2.9518)	Loss@kd 2.9472 (2.9848)	Acc@1 62.500 (68.088)	Acc@5 98.438 (98.480)
Epoch: [48][500/875]	Time 0.452 (0.448)	Data 0.006 (0.010)	Loss 2.9215 (2.9529)	Loss@kd 2.9340 (2.9833)	Acc@1 62.500 (68.086)	Acc@5 96.875 (98.503)
Epoch: [48][600/875]	Time 0.431 (0.448)	Data 0.007 (0.009)	Loss 2.6393 (2.9506)	Loss@kd 2.8670 (2.9796)	Acc@1 78.125 (68.123)	Acc@5 100.000 (98.513)
Epoch: [48][700/875]	Time 0.428 (0.448)	Data 0.007 (0.009)	Loss 2.7696 (2.9569)	Loss@kd 2.8798 (2.9848)	Acc@1 78.125 (67.994)	Acc@5 98.438 (98.529)
Epoch: [48][800/875]	Time 0.444 (0.449)	Data 0.007 (0.009)	Loss 3.1797 (2.9555)	Loss@kd 2.9962 (2.9849)	Acc@1 60.938 (68.018)	Acc@5 93.750 (98.551)
 * Acc@1 68.046 Acc@5 98.543
epoch 48, total time 393.24
Test: [0/750]	Time 0.850 (0.850)	Loss 0.5102 (0.5102)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.094 (0.108)	Loss 0.5372 (0.4380)	Acc@1 87.500 (87.438)	Acc@5 93.750 (93.038)
Test: [200/750]	Time 0.092 (0.105)	Loss 1.3866 (0.4963)	Acc@1 37.500 (84.748)	Acc@5 93.750 (94.356)
Test: [300/750]	Time 0.095 (0.104)	Loss 1.7491 (0.8294)	Acc@1 34.375 (71.626)	Acc@5 81.250 (92.255)
Test: [400/750]	Time 0.094 (0.104)	Loss 0.9591 (1.0165)	Acc@1 71.875 (63.864)	Acc@5 84.375 (90.383)
Test: [500/750]	Time 0.101 (0.103)	Loss 0.7607 (1.0325)	Acc@1 75.000 (63.560)	Acc@5 96.875 (90.051)
Test: [600/750]	Time 0.097 (0.103)	Loss 1.3114 (1.0617)	Acc@1 53.125 (62.516)	Acc@5 81.250 (89.928)
Test: [700/750]	Time 0.094 (0.102)	Loss 1.5707 (1.0996)	Acc@1 56.250 (60.931)	Acc@5 71.875 (89.546)
 * Acc@1 61.004 Acc@5 89.412
==> training...
Epoch: [49][0/875]	Time 1.787 (1.787)	Data 1.345 (1.345)	Loss 2.6913 (2.6913)	Loss@kd 2.8998 (2.8998)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [49][100/875]	Time 0.430 (0.467)	Data 0.007 (0.020)	Loss 2.8537 (2.8965)	Loss@kd 2.8552 (2.9243)	Acc@1 65.625 (69.013)	Acc@5 98.438 (98.515)
Epoch: [49][200/875]	Time 0.438 (0.460)	Data 0.005 (0.014)	Loss 2.9288 (2.9133)	Loss@kd 2.9790 (2.9445)	Acc@1 67.188 (68.579)	Acc@5 96.875 (98.593)
Epoch: [49][300/875]	Time 0.405 (0.450)	Data 0.007 (0.011)	Loss 2.9435 (2.9221)	Loss@kd 2.9364 (2.9633)	Acc@1 76.562 (68.932)	Acc@5 96.875 (98.547)
Epoch: [49][400/875]	Time 0.511 (0.445)	Data 0.008 (0.010)	Loss 2.7890 (2.9292)	Loss@kd 2.7748 (2.9585)	Acc@1 62.500 (68.325)	Acc@5 98.438 (98.586)
Epoch: [49][500/875]	Time 0.425 (0.444)	Data 0.007 (0.010)	Loss 2.8335 (2.9379)	Loss@kd 2.9251 (2.9662)	Acc@1 68.750 (68.182)	Acc@5 100.000 (98.550)
Epoch: [49][600/875]	Time 0.419 (0.446)	Data 0.007 (0.009)	Loss 3.0222 (2.9485)	Loss@kd 2.8723 (2.9775)	Acc@1 67.188 (68.152)	Acc@5 95.312 (98.554)
Epoch: [49][700/875]	Time 0.420 (0.447)	Data 0.007 (0.009)	Loss 2.8667 (2.9418)	Loss@kd 2.9265 (2.9690)	Acc@1 78.125 (68.119)	Acc@5 96.875 (98.553)
Epoch: [49][800/875]	Time 0.425 (0.447)	Data 0.007 (0.009)	Loss 2.8372 (2.9434)	Loss@kd 2.9231 (2.9708)	Acc@1 70.312 (68.052)	Acc@5 98.438 (98.556)
 * Acc@1 68.043 Acc@5 98.564
epoch 49, total time 391.93
Test: [0/750]	Time 0.821 (0.821)	Loss 0.6876 (0.6876)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.193 (0.111)	Loss 0.7160 (0.6589)	Acc@1 75.000 (80.600)	Acc@5 93.750 (90.811)
Test: [200/750]	Time 0.077 (0.107)	Loss 1.3263 (0.6644)	Acc@1 37.500 (77.192)	Acc@5 100.000 (93.905)
Test: [300/750]	Time 0.084 (0.105)	Loss 0.8878 (0.8592)	Acc@1 78.125 (67.338)	Acc@5 96.875 (93.480)
Test: [400/750]	Time 0.097 (0.105)	Loss 0.5506 (0.8682)	Acc@1 75.000 (67.184)	Acc@5 96.875 (93.953)
Test: [500/750]	Time 0.102 (0.105)	Loss 0.8217 (0.8580)	Acc@1 68.750 (68.451)	Acc@5 96.875 (93.326)
Test: [600/750]	Time 0.100 (0.105)	Loss 0.6752 (0.8787)	Acc@1 78.125 (68.235)	Acc@5 93.750 (92.752)
Test: [700/750]	Time 0.082 (0.105)	Loss 1.4920 (0.8964)	Acc@1 40.625 (67.029)	Acc@5 81.250 (92.756)
 * Acc@1 65.758 Acc@5 92.542
==> training...
Epoch: [50][0/875]	Time 1.755 (1.755)	Data 1.294 (1.294)	Loss 2.9802 (2.9802)	Loss@kd 3.0696 (3.0696)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [50][100/875]	Time 0.463 (0.465)	Data 0.007 (0.020)	Loss 2.4984 (2.8767)	Loss@kd 2.8189 (2.9205)	Acc@1 81.250 (69.075)	Acc@5 100.000 (98.670)
Epoch: [50][200/875]	Time 0.431 (0.459)	Data 0.008 (0.013)	Loss 2.9486 (2.8937)	Loss@kd 2.8409 (2.9238)	Acc@1 67.188 (68.664)	Acc@5 98.438 (98.671)
Epoch: [50][300/875]	Time 0.425 (0.455)	Data 0.007 (0.011)	Loss 2.9914 (2.9114)	Loss@kd 3.2064 (2.9602)	Acc@1 73.438 (68.657)	Acc@5 98.438 (98.702)
Epoch: [50][400/875]	Time 0.452 (0.454)	Data 0.007 (0.010)	Loss 2.7283 (2.9220)	Loss@kd 2.7965 (2.9639)	Acc@1 75.000 (68.360)	Acc@5 98.438 (98.621)
Epoch: [50][500/875]	Time 0.441 (0.454)	Data 0.007 (0.010)	Loss 2.9589 (2.9271)	Loss@kd 2.8084 (2.9674)	Acc@1 65.625 (68.316)	Acc@5 100.000 (98.656)
Epoch: [50][600/875]	Time 0.493 (0.451)	Data 0.007 (0.009)	Loss 2.7253 (2.9250)	Loss@kd 2.8177 (2.9658)	Acc@1 73.438 (68.500)	Acc@5 100.000 (98.669)
Epoch: [50][700/875]	Time 0.430 (0.448)	Data 0.006 (0.009)	Loss 2.8044 (2.9281)	Loss@kd 2.9602 (2.9655)	Acc@1 78.125 (68.500)	Acc@5 98.438 (98.658)
Epoch: [50][800/875]	Time 0.468 (0.447)	Data 0.007 (0.009)	Loss 3.0033 (2.9263)	Loss@kd 2.9958 (2.9593)	Acc@1 67.188 (68.385)	Acc@5 100.000 (98.640)
 * Acc@1 68.395 Acc@5 98.636
epoch 50, total time 392.03
Test: [0/750]	Time 0.936 (0.936)	Loss 0.6390 (0.6390)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.103 (0.112)	Loss 0.5728 (0.5881)	Acc@1 81.250 (82.983)	Acc@5 96.875 (92.543)
Test: [200/750]	Time 0.096 (0.107)	Loss 1.1634 (0.5633)	Acc@1 56.250 (82.183)	Acc@5 96.875 (94.667)
Test: [300/750]	Time 0.102 (0.104)	Loss 1.2416 (0.7500)	Acc@1 56.250 (72.924)	Acc@5 87.500 (94.539)
Test: [400/750]	Time 0.096 (0.104)	Loss 0.9212 (0.8376)	Acc@1 75.000 (68.984)	Acc@5 90.625 (93.828)
Test: [500/750]	Time 0.072 (0.103)	Loss 0.5666 (0.8642)	Acc@1 78.125 (68.812)	Acc@5 96.875 (92.453)
Test: [600/750]	Time 0.088 (0.102)	Loss 0.8433 (0.8620)	Acc@1 65.625 (68.974)	Acc@5 90.625 (92.382)
Test: [700/750]	Time 0.082 (0.102)	Loss 1.0278 (0.8701)	Acc@1 53.125 (68.135)	Acc@5 90.625 (92.783)
 * Acc@1 68.142 Acc@5 92.829
saving the best model!
==> training...
Epoch: [51][0/875]	Time 1.893 (1.893)	Data 1.409 (1.409)	Loss 2.9130 (2.9130)	Loss@kd 2.8376 (2.8376)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [51][100/875]	Time 0.494 (0.468)	Data 0.007 (0.021)	Loss 3.1041 (2.9016)	Loss@kd 3.0746 (2.9145)	Acc@1 56.250 (67.713)	Acc@5 98.438 (98.685)
Epoch: [51][200/875]	Time 0.483 (0.460)	Data 0.006 (0.014)	Loss 2.8742 (2.9109)	Loss@kd 2.8694 (2.9410)	Acc@1 62.500 (67.903)	Acc@5 100.000 (98.593)
Epoch: [51][300/875]	Time 0.437 (0.457)	Data 0.008 (0.012)	Loss 2.6330 (2.9066)	Loss@kd 2.7673 (2.9447)	Acc@1 68.750 (68.169)	Acc@5 100.000 (98.640)
Epoch: [51][400/875]	Time 0.551 (0.456)	Data 0.006 (0.010)	Loss 3.4082 (2.9229)	Loss@kd 3.8733 (2.9621)	Acc@1 79.688 (68.185)	Acc@5 100.000 (98.586)
Epoch: [51][500/875]	Time 0.463 (0.455)	Data 0.007 (0.010)	Loss 2.9444 (2.9307)	Loss@kd 2.9466 (2.9685)	Acc@1 70.312 (68.195)	Acc@5 96.875 (98.565)
Epoch: [51][600/875]	Time 0.425 (0.455)	Data 0.007 (0.009)	Loss 2.8136 (2.9188)	Loss@kd 2.9483 (2.9546)	Acc@1 71.875 (68.329)	Acc@5 98.438 (98.560)
Epoch: [51][700/875]	Time 0.461 (0.454)	Data 0.010 (0.009)	Loss 2.7485 (2.9136)	Loss@kd 2.8387 (2.9476)	Acc@1 70.312 (68.309)	Acc@5 98.438 (98.538)
Epoch: [51][800/875]	Time 0.432 (0.454)	Data 0.006 (0.009)	Loss 2.7449 (2.9154)	Loss@kd 3.0057 (2.9488)	Acc@1 76.562 (68.344)	Acc@5 100.000 (98.545)
 * Acc@1 68.421 Acc@5 98.566
epoch 51, total time 396.51
Test: [0/750]	Time 0.796 (0.796)	Loss 1.8554 (1.8554)	Acc@1 31.250 (31.250)	Acc@5 59.375 (59.375)
Test: [100/750]	Time 0.160 (0.109)	Loss 0.4190 (1.5257)	Acc@1 81.250 (36.448)	Acc@5 100.000 (80.755)
Test: [200/750]	Time 0.120 (0.104)	Loss 1.4781 (1.0589)	Acc@1 50.000 (57.354)	Acc@5 84.375 (88.759)
Test: [300/750]	Time 0.098 (0.102)	Loss 1.5347 (1.2034)	Acc@1 46.875 (52.564)	Acc@5 93.750 (88.113)
Test: [400/750]	Time 0.087 (0.101)	Loss 0.8352 (1.2493)	Acc@1 78.125 (51.153)	Acc@5 87.500 (88.007)
Test: [500/750]	Time 0.090 (0.101)	Loss 0.6176 (1.1721)	Acc@1 78.125 (55.059)	Acc@5 100.000 (88.716)
Test: [600/750]	Time 0.090 (0.100)	Loss 0.6082 (1.1148)	Acc@1 84.375 (57.862)	Acc@5 93.750 (89.439)
Test: [700/750]	Time 0.107 (0.100)	Loss 1.0988 (1.0722)	Acc@1 59.375 (59.504)	Acc@5 84.375 (90.259)
 * Acc@1 60.179 Acc@5 90.325
==> training...
Epoch: [52][0/875]	Time 1.735 (1.735)	Data 1.322 (1.322)	Loss 2.8909 (2.8909)	Loss@kd 2.9617 (2.9617)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [52][100/875]	Time 0.438 (0.465)	Data 0.006 (0.020)	Loss 3.2841 (2.9293)	Loss@kd 3.1594 (2.9878)	Acc@1 59.375 (68.317)	Acc@5 98.438 (98.747)
Epoch: [52][200/875]	Time 0.405 (0.460)	Data 0.007 (0.013)	Loss 2.7495 (2.9214)	Loss@kd 2.7772 (2.9607)	Acc@1 70.312 (68.159)	Acc@5 100.000 (98.803)
Epoch: [52][300/875]	Time 0.447 (0.458)	Data 0.008 (0.011)	Loss 2.7110 (2.9406)	Loss@kd 2.9011 (2.9753)	Acc@1 75.000 (67.857)	Acc@5 100.000 (98.713)
Epoch: [52][400/875]	Time 0.420 (0.457)	Data 0.007 (0.010)	Loss 3.3552 (2.9374)	Loss@kd 3.2146 (2.9679)	Acc@1 67.188 (67.928)	Acc@5 96.875 (98.652)
Epoch: [52][500/875]	Time 0.441 (0.457)	Data 0.005 (0.009)	Loss 2.9694 (2.9291)	Loss@kd 2.8088 (2.9624)	Acc@1 62.500 (68.120)	Acc@5 98.438 (98.675)
Epoch: [52][600/875]	Time 0.483 (0.456)	Data 0.005 (0.009)	Loss 2.9994 (2.9200)	Loss@kd 2.8218 (2.9507)	Acc@1 64.062 (68.209)	Acc@5 100.000 (98.627)
Epoch: [52][700/875]	Time 0.408 (0.456)	Data 0.005 (0.009)	Loss 2.6482 (2.9126)	Loss@kd 2.6725 (2.9454)	Acc@1 67.188 (68.384)	Acc@5 98.438 (98.676)
Epoch: [52][800/875]	Time 0.419 (0.456)	Data 0.007 (0.008)	Loss 2.8288 (2.9135)	Loss@kd 2.8882 (2.9455)	Acc@1 64.062 (68.333)	Acc@5 100.000 (98.679)
 * Acc@1 68.387 Acc@5 98.688
epoch 52, total time 399.24
Test: [0/750]	Time 0.751 (0.751)	Loss 0.7636 (0.7636)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.102 (0.111)	Loss 0.6060 (0.6406)	Acc@1 75.000 (80.476)	Acc@5 96.875 (91.894)
Test: [200/750]	Time 0.166 (0.107)	Loss 1.6635 (0.6691)	Acc@1 34.375 (76.461)	Acc@5 71.875 (93.703)
Test: [300/750]	Time 0.115 (0.106)	Loss 1.1530 (0.9359)	Acc@1 62.500 (63.953)	Acc@5 93.750 (91.466)
Test: [400/750]	Time 0.090 (0.105)	Loss 0.7611 (0.9670)	Acc@1 71.875 (62.936)	Acc@5 81.250 (91.771)
Test: [500/750]	Time 0.094 (0.105)	Loss 0.8014 (0.9400)	Acc@1 81.250 (65.014)	Acc@5 93.750 (91.386)
Test: [600/750]	Time 0.107 (0.104)	Loss 0.7187 (0.9384)	Acc@1 78.125 (65.635)	Acc@5 90.625 (91.155)
Test: [700/750]	Time 0.109 (0.104)	Loss 1.0518 (0.9256)	Acc@1 65.625 (66.160)	Acc@5 81.250 (91.641)
 * Acc@1 66.296 Acc@5 91.825
==> training...
Epoch: [53][0/875]	Time 1.969 (1.969)	Data 1.374 (1.374)	Loss 2.9820 (2.9820)	Loss@kd 3.2403 (3.2403)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [53][100/875]	Time 0.435 (0.457)	Data 0.006 (0.020)	Loss 2.9811 (2.8800)	Loss@kd 2.9250 (2.9218)	Acc@1 56.250 (68.936)	Acc@5 100.000 (98.422)
Epoch: [53][200/875]	Time 0.418 (0.444)	Data 0.006 (0.013)	Loss 2.7860 (2.8809)	Loss@kd 2.9141 (2.9247)	Acc@1 75.000 (68.905)	Acc@5 98.438 (98.616)
Epoch: [53][300/875]	Time 0.411 (0.439)	Data 0.007 (0.011)	Loss 2.9142 (2.8837)	Loss@kd 2.8273 (2.9197)	Acc@1 64.062 (68.740)	Acc@5 98.438 (98.614)
Epoch: [53][400/875]	Time 0.428 (0.441)	Data 0.006 (0.010)	Loss 2.9741 (2.8907)	Loss@kd 2.9339 (2.9282)	Acc@1 64.062 (68.836)	Acc@5 100.000 (98.613)
Epoch: [53][500/875]	Time 0.426 (0.443)	Data 0.007 (0.009)	Loss 2.7332 (2.8852)	Loss@kd 2.8128 (2.9197)	Acc@1 68.750 (68.865)	Acc@5 100.000 (98.646)
Epoch: [53][600/875]	Time 0.408 (0.446)	Data 0.005 (0.009)	Loss 2.9759 (2.8801)	Loss@kd 2.8880 (2.9152)	Acc@1 65.625 (68.877)	Acc@5 98.438 (98.648)
Epoch: [53][700/875]	Time 0.435 (0.447)	Data 0.007 (0.009)	Loss 3.1652 (2.8841)	Loss@kd 3.1721 (2.9188)	Acc@1 62.500 (68.803)	Acc@5 96.875 (98.643)
Epoch: [53][800/875]	Time 0.511 (0.448)	Data 0.007 (0.008)	Loss 2.7266 (2.8839)	Loss@kd 2.7761 (2.9164)	Acc@1 71.875 (68.732)	Acc@5 98.438 (98.623)
 * Acc@1 68.736 Acc@5 98.627
epoch 53, total time 393.06
Test: [0/750]	Time 0.750 (0.750)	Loss 0.5355 (0.5355)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.102 (0.113)	Loss 0.5789 (0.5371)	Acc@1 78.125 (83.880)	Acc@5 100.000 (92.481)
Test: [200/750]	Time 0.097 (0.110)	Loss 1.2026 (0.5505)	Acc@1 46.875 (81.981)	Acc@5 87.500 (94.761)
Test: [300/750]	Time 0.187 (0.108)	Loss 1.3277 (0.7612)	Acc@1 43.750 (72.488)	Acc@5 93.750 (93.875)
Test: [400/750]	Time 0.109 (0.108)	Loss 0.4029 (0.8546)	Acc@1 84.375 (68.204)	Acc@5 100.000 (93.103)
Test: [500/750]	Time 0.092 (0.107)	Loss 0.7406 (0.8168)	Acc@1 75.000 (70.072)	Acc@5 100.000 (93.139)
Test: [600/750]	Time 0.111 (0.107)	Loss 0.9966 (0.8430)	Acc@1 59.375 (69.228)	Acc@5 87.500 (92.632)
Test: [700/750]	Time 0.112 (0.107)	Loss 0.9840 (0.8622)	Acc@1 65.625 (68.059)	Acc@5 84.375 (92.720)
 * Acc@1 68.363 Acc@5 92.954
saving the best model!
==> training...
Epoch: [54][0/875]	Time 1.785 (1.785)	Data 1.296 (1.296)	Loss 2.6079 (2.6079)	Loss@kd 2.7840 (2.7840)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [54][100/875]	Time 0.546 (0.468)	Data 0.007 (0.020)	Loss 2.7396 (2.8920)	Loss@kd 2.8974 (2.9377)	Acc@1 70.312 (69.291)	Acc@5 100.000 (98.809)
Epoch: [54][200/875]	Time 0.451 (0.461)	Data 0.007 (0.013)	Loss 2.7323 (2.8930)	Loss@kd 2.8071 (2.9286)	Acc@1 70.312 (69.030)	Acc@5 98.438 (98.616)
Epoch: [54][300/875]	Time 0.456 (0.458)	Data 0.005 (0.011)	Loss 2.7861 (2.8904)	Loss@kd 2.8151 (2.9260)	Acc@1 67.188 (68.994)	Acc@5 100.000 (98.671)
Epoch: [54][400/875]	Time 0.443 (0.455)	Data 0.007 (0.010)	Loss 2.8604 (2.8953)	Loss@kd 2.8722 (2.9345)	Acc@1 70.312 (68.980)	Acc@5 98.438 (98.679)
Epoch: [54][500/875]	Time 0.422 (0.450)	Data 0.007 (0.010)	Loss 2.6996 (2.8905)	Loss@kd 2.8590 (2.9308)	Acc@1 71.875 (69.081)	Acc@5 100.000 (98.631)
Epoch: [54][600/875]	Time 0.419 (0.447)	Data 0.007 (0.009)	Loss 2.6842 (2.8883)	Loss@kd 2.8091 (2.9265)	Acc@1 65.625 (69.026)	Acc@5 100.000 (98.669)
Epoch: [54][700/875]	Time 0.462 (0.447)	Data 0.006 (0.009)	Loss 2.7401 (2.9200)	Loss@kd 2.7646 (2.9613)	Acc@1 62.500 (68.641)	Acc@5 100.000 (98.656)
Epoch: [54][800/875]	Time 0.496 (0.448)	Data 0.007 (0.009)	Loss 2.7592 (2.9181)	Loss@kd 2.8012 (2.9568)	Acc@1 67.188 (68.658)	Acc@5 100.000 (98.638)
 * Acc@1 68.709 Acc@5 98.662
epoch 54, total time 392.60
Test: [0/750]	Time 0.800 (0.800)	Loss 0.6287 (0.6287)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.082 (0.106)	Loss 0.7233 (0.4902)	Acc@1 75.000 (84.530)	Acc@5 96.875 (93.502)
Test: [200/750]	Time 0.097 (0.107)	Loss 1.1824 (0.5926)	Acc@1 53.125 (80.022)	Acc@5 96.875 (94.232)
Test: [300/750]	Time 0.107 (0.106)	Loss 1.5774 (0.8206)	Acc@1 37.500 (69.643)	Acc@5 87.500 (93.272)
Test: [400/750]	Time 0.100 (0.105)	Loss 0.7499 (0.9898)	Acc@1 81.250 (63.895)	Acc@5 93.750 (91.147)
Test: [500/750]	Time 0.095 (0.105)	Loss 0.7781 (0.9515)	Acc@1 71.875 (65.488)	Acc@5 96.875 (91.486)
Test: [600/750]	Time 0.104 (0.105)	Loss 1.2116 (0.9743)	Acc@1 56.250 (64.954)	Acc@5 78.125 (90.953)
Test: [700/750]	Time 0.114 (0.104)	Loss 1.0076 (0.9829)	Acc@1 65.625 (64.363)	Acc@5 90.625 (91.040)
 * Acc@1 64.867 Acc@5 91.379
==> training...
Epoch: [55][0/875]	Time 1.816 (1.816)	Data 1.334 (1.334)	Loss 4.4286 (4.4286)	Loss@kd 5.2430 (5.2430)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [55][100/875]	Time 0.421 (0.465)	Data 0.007 (0.020)	Loss 3.0202 (2.9377)	Loss@kd 2.9225 (2.9948)	Acc@1 60.938 (68.595)	Acc@5 98.438 (98.623)
Epoch: [55][200/875]	Time 0.411 (0.459)	Data 0.007 (0.014)	Loss 2.9218 (2.9169)	Loss@kd 2.7461 (2.9727)	Acc@1 59.375 (68.664)	Acc@5 100.000 (98.748)
Epoch: [55][300/875]	Time 0.466 (0.456)	Data 0.007 (0.011)	Loss 2.8774 (2.9021)	Loss@kd 3.0680 (2.9511)	Acc@1 71.875 (68.464)	Acc@5 100.000 (98.749)
Epoch: [55][400/875]	Time 0.511 (0.456)	Data 0.005 (0.010)	Loss 2.6699 (2.8923)	Loss@kd 2.8275 (2.9311)	Acc@1 70.312 (68.376)	Acc@5 100.000 (98.699)
Epoch: [55][500/875]	Time 0.411 (0.455)	Data 0.007 (0.010)	Loss 2.7690 (2.8840)	Loss@kd 2.8783 (2.9224)	Acc@1 65.625 (68.535)	Acc@5 96.875 (98.659)
Epoch: [55][600/875]	Time 0.437 (0.455)	Data 0.007 (0.009)	Loss 3.1083 (2.8821)	Loss@kd 3.0180 (2.9215)	Acc@1 67.188 (68.586)	Acc@5 98.438 (98.674)
Epoch: [55][700/875]	Time 0.435 (0.453)	Data 0.007 (0.009)	Loss 2.9875 (2.8797)	Loss@kd 2.8545 (2.9173)	Acc@1 57.812 (68.503)	Acc@5 100.000 (98.669)
Epoch: [55][800/875]	Time 0.430 (0.450)	Data 0.007 (0.009)	Loss 2.7215 (2.8774)	Loss@kd 2.7941 (2.9113)	Acc@1 68.750 (68.452)	Acc@5 98.438 (98.652)
 * Acc@1 68.454 Acc@5 98.661
epoch 55, total time 393.08
Test: [0/750]	Time 0.783 (0.783)	Loss 0.5771 (0.5771)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.168 (0.101)	Loss 0.5510 (0.5098)	Acc@1 78.125 (84.375)	Acc@5 100.000 (93.255)
Test: [200/750]	Time 0.079 (0.101)	Loss 1.5561 (0.5237)	Acc@1 37.500 (82.945)	Acc@5 78.125 (94.978)
Test: [300/750]	Time 0.104 (0.100)	Loss 1.3720 (0.8193)	Acc@1 46.875 (69.705)	Acc@5 87.500 (92.784)
Test: [400/750]	Time 0.086 (0.100)	Loss 0.8287 (0.9515)	Acc@1 78.125 (64.035)	Acc@5 90.625 (92.246)
Test: [500/750]	Time 0.111 (0.100)	Loss 0.4136 (0.9377)	Acc@1 84.375 (65.800)	Acc@5 100.000 (91.548)
Test: [600/750]	Time 0.099 (0.100)	Loss 0.8404 (0.9138)	Acc@1 65.625 (66.925)	Acc@5 93.750 (91.868)
Test: [700/750]	Time 0.083 (0.100)	Loss 1.0553 (0.9156)	Acc@1 62.500 (66.677)	Acc@5 87.500 (92.208)
 * Acc@1 66.846 Acc@5 92.221
==> training...
Epoch: [56][0/875]	Time 1.774 (1.774)	Data 1.296 (1.296)	Loss 4.2172 (4.2172)	Loss@kd 4.8748 (4.8748)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [56][100/875]	Time 0.408 (0.465)	Data 0.007 (0.020)	Loss 3.1876 (2.8836)	Loss@kd 3.2350 (2.9438)	Acc@1 65.625 (69.524)	Acc@5 100.000 (98.778)
Epoch: [56][200/875]	Time 0.436 (0.459)	Data 0.008 (0.013)	Loss 2.9214 (2.8588)	Loss@kd 2.9932 (2.9129)	Acc@1 76.562 (69.387)	Acc@5 98.438 (98.725)
Epoch: [56][300/875]	Time 0.438 (0.457)	Data 0.007 (0.011)	Loss 2.7938 (2.8677)	Loss@kd 2.9054 (2.9174)	Acc@1 68.750 (69.103)	Acc@5 100.000 (98.765)
Epoch: [56][400/875]	Time 0.440 (0.455)	Data 0.005 (0.010)	Loss 2.7989 (2.8694)	Loss@kd 2.8265 (2.9108)	Acc@1 70.312 (69.085)	Acc@5 98.438 (98.749)
Epoch: [56][500/875]	Time 0.430 (0.455)	Data 0.007 (0.010)	Loss 2.6356 (2.8626)	Loss@kd 2.8138 (2.8999)	Acc@1 75.000 (69.034)	Acc@5 100.000 (98.709)
Epoch: [56][600/875]	Time 0.547 (0.454)	Data 0.007 (0.009)	Loss 2.7431 (2.8575)	Loss@kd 2.7614 (2.8955)	Acc@1 68.750 (69.085)	Acc@5 100.000 (98.731)
Epoch: [56][700/875]	Time 0.461 (0.454)	Data 0.008 (0.009)	Loss 3.1210 (2.8642)	Loss@kd 3.1231 (2.9011)	Acc@1 65.625 (69.004)	Acc@5 96.875 (98.712)
Epoch: [56][800/875]	Time 0.420 (0.453)	Data 0.008 (0.009)	Loss 2.6244 (2.8629)	Loss@kd 2.8593 (2.8984)	Acc@1 78.125 (69.007)	Acc@5 100.000 (98.714)
 * Acc@1 68.980 Acc@5 98.745
epoch 56, total time 396.95
Test: [0/750]	Time 0.744 (0.744)	Loss 0.8729 (0.8729)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.114 (0.113)	Loss 0.4619 (0.8392)	Acc@1 81.250 (77.754)	Acc@5 100.000 (89.480)
Test: [200/750]	Time 0.161 (0.107)	Loss 1.4097 (0.6902)	Acc@1 34.375 (79.275)	Acc@5 93.750 (93.268)
Test: [300/750]	Time 0.097 (0.106)	Loss 1.1391 (0.8735)	Acc@1 62.500 (69.892)	Acc@5 96.875 (92.629)
Test: [400/750]	Time 0.097 (0.103)	Loss 0.5363 (0.9280)	Acc@1 84.375 (66.903)	Acc@5 93.750 (92.745)
Test: [500/750]	Time 0.091 (0.103)	Loss 0.6732 (0.8903)	Acc@1 71.875 (68.613)	Acc@5 100.000 (92.633)
Test: [600/750]	Time 0.110 (0.102)	Loss 0.6169 (0.8911)	Acc@1 81.250 (68.636)	Acc@5 96.875 (92.689)
Test: [700/750]	Time 0.098 (0.102)	Loss 1.3172 (0.8931)	Acc@1 59.375 (68.269)	Acc@5 84.375 (92.867)
 * Acc@1 67.854 Acc@5 92.608
==> training...
Epoch: [57][0/875]	Time 1.853 (1.853)	Data 1.290 (1.290)	Loss 2.8377 (2.8377)	Loss@kd 2.9111 (2.9111)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [57][100/875]	Time 0.429 (0.446)	Data 0.008 (0.020)	Loss 2.7891 (2.8479)	Loss@kd 2.9046 (2.8973)	Acc@1 67.188 (69.678)	Acc@5 100.000 (98.747)
Epoch: [57][200/875]	Time 0.473 (0.446)	Data 0.007 (0.013)	Loss 3.0058 (2.8459)	Loss@kd 2.9620 (2.8908)	Acc@1 71.875 (69.426)	Acc@5 100.000 (98.795)
Epoch: [57][300/875]	Time 0.447 (0.449)	Data 0.008 (0.011)	Loss 2.6989 (2.8384)	Loss@kd 2.8082 (2.8736)	Acc@1 68.750 (69.466)	Acc@5 100.000 (98.790)
Epoch: [57][400/875]	Time 0.423 (0.450)	Data 0.007 (0.010)	Loss 2.9469 (2.8294)	Loss@kd 2.8365 (2.8681)	Acc@1 65.625 (69.701)	Acc@5 98.438 (98.827)
Epoch: [57][500/875]	Time 0.385 (0.450)	Data 0.005 (0.010)	Loss 2.7996 (2.8321)	Loss@kd 2.7215 (2.8712)	Acc@1 67.188 (69.701)	Acc@5 96.875 (98.790)
Epoch: [57][600/875]	Time 0.426 (0.450)	Data 0.007 (0.009)	Loss 2.7759 (2.8422)	Loss@kd 2.8665 (2.8803)	Acc@1 73.438 (69.681)	Acc@5 96.875 (98.749)
Epoch: [57][700/875]	Time 0.435 (0.451)	Data 0.007 (0.009)	Loss 2.9853 (2.8388)	Loss@kd 2.8716 (2.8751)	Acc@1 60.938 (69.610)	Acc@5 98.438 (98.763)
Epoch: [57][800/875]	Time 0.493 (0.451)	Data 0.007 (0.009)	Loss 2.8951 (2.8429)	Loss@kd 2.8932 (2.8801)	Acc@1 78.125 (69.521)	Acc@5 100.000 (98.789)
 * Acc@1 69.496 Acc@5 98.779
epoch 57, total time 395.70
Test: [0/750]	Time 0.837 (0.837)	Loss 3.0321 (3.0321)	Acc@1 21.875 (21.875)	Acc@5 46.875 (46.875)
Test: [100/750]	Time 0.109 (0.111)	Loss 0.4944 (2.3847)	Acc@1 75.000 (30.724)	Acc@5 100.000 (58.199)
Test: [200/750]	Time 0.104 (0.107)	Loss 1.5089 (1.4893)	Acc@1 50.000 (55.084)	Acc@5 84.375 (76.928)
Test: [300/750]	Time 0.187 (0.105)	Loss 2.0297 (1.5434)	Acc@1 37.500 (50.384)	Acc@5 68.750 (78.997)
Test: [400/750]	Time 0.094 (0.104)	Loss 0.7865 (1.5914)	Acc@1 78.125 (46.976)	Acc@5 87.500 (79.130)
Test: [500/750]	Time 0.098 (0.104)	Loss 0.5867 (1.4535)	Acc@1 78.125 (51.266)	Acc@5 100.000 (81.630)
Test: [600/750]	Time 0.073 (0.103)	Loss 1.0701 (1.3625)	Acc@1 62.500 (53.848)	Acc@5 87.500 (83.845)
Test: [700/750]	Time 0.090 (0.103)	Loss 1.6105 (1.3209)	Acc@1 53.125 (54.618)	Acc@5 78.125 (84.955)
 * Acc@1 54.817 Acc@5 84.954
==> training...
Epoch: [58][0/875]	Time 1.844 (1.844)	Data 1.399 (1.399)	Loss 3.3178 (3.3178)	Loss@kd 3.3280 (3.3280)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [58][100/875]	Time 0.531 (0.468)	Data 0.007 (0.020)	Loss 2.9457 (2.8489)	Loss@kd 2.9721 (2.8772)	Acc@1 59.375 (68.410)	Acc@5 100.000 (98.530)
Epoch: [58][200/875]	Time 0.424 (0.459)	Data 0.007 (0.014)	Loss 2.9683 (2.8289)	Loss@kd 2.9913 (2.8716)	Acc@1 68.750 (69.232)	Acc@5 96.875 (98.686)
Epoch: [58][300/875]	Time 0.415 (0.450)	Data 0.007 (0.011)	Loss 2.7548 (2.8398)	Loss@kd 2.7422 (2.8745)	Acc@1 70.312 (69.191)	Acc@5 98.438 (98.671)
Epoch: [58][400/875]	Time 0.438 (0.445)	Data 0.008 (0.010)	Loss 3.0676 (2.8505)	Loss@kd 3.0111 (2.8901)	Acc@1 62.500 (69.299)	Acc@5 98.438 (98.683)
Epoch: [58][500/875]	Time 0.484 (0.445)	Data 0.007 (0.010)	Loss 2.7741 (2.8580)	Loss@kd 2.7709 (2.8986)	Acc@1 76.562 (69.311)	Acc@5 96.875 (98.709)
Epoch: [58][600/875]	Time 0.415 (0.446)	Data 0.005 (0.009)	Loss 2.7892 (2.8540)	Loss@kd 2.7944 (2.8924)	Acc@1 75.000 (69.275)	Acc@5 98.438 (98.744)
Epoch: [58][700/875]	Time 0.493 (0.446)	Data 0.007 (0.009)	Loss 2.8778 (2.8532)	Loss@kd 2.8575 (2.8942)	Acc@1 75.000 (69.323)	Acc@5 98.438 (98.758)
Epoch: [58][800/875]	Time 0.476 (0.447)	Data 0.007 (0.009)	Loss 2.6649 (2.8528)	Loss@kd 2.8358 (2.8928)	Acc@1 68.750 (69.220)	Acc@5 100.000 (98.750)
 * Acc@1 69.161 Acc@5 98.716
epoch 58, total time 392.07
Test: [0/750]	Time 0.852 (0.852)	Loss 0.5419 (0.5419)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.097 (0.111)	Loss 0.5222 (0.5444)	Acc@1 84.375 (83.014)	Acc@5 100.000 (93.410)
Test: [200/750]	Time 0.078 (0.109)	Loss 1.1198 (0.5552)	Acc@1 53.125 (81.810)	Acc@5 93.750 (94.885)
Test: [300/750]	Time 0.103 (0.105)	Loss 0.7945 (0.7460)	Acc@1 65.625 (72.674)	Acc@5 96.875 (94.529)
Test: [400/750]	Time 0.105 (0.104)	Loss 0.9012 (0.8083)	Acc@1 75.000 (69.981)	Acc@5 87.500 (94.070)
Test: [500/750]	Time 0.093 (0.104)	Loss 0.6154 (0.8093)	Acc@1 71.875 (70.559)	Acc@5 100.000 (93.363)
Test: [600/750]	Time 0.119 (0.104)	Loss 0.8092 (0.8260)	Acc@1 75.000 (70.196)	Acc@5 93.750 (92.991)
Test: [700/750]	Time 0.103 (0.104)	Loss 1.5084 (0.8576)	Acc@1 40.625 (68.790)	Acc@5 81.250 (92.921)
 * Acc@1 68.208 Acc@5 92.733
==> training...
Epoch: [59][0/875]	Time 1.880 (1.880)	Data 1.409 (1.409)	Loss 3.0118 (3.0118)	Loss@kd 3.0218 (3.0218)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [59][100/875]	Time 0.436 (0.459)	Data 0.005 (0.020)	Loss 2.7447 (2.8428)	Loss@kd 2.7299 (2.8686)	Acc@1 73.438 (68.239)	Acc@5 96.875 (98.639)
Epoch: [59][200/875]	Time 0.439 (0.455)	Data 0.010 (0.014)	Loss 2.8281 (2.8208)	Loss@kd 2.9223 (2.8577)	Acc@1 79.688 (69.628)	Acc@5 96.875 (98.717)
Epoch: [59][300/875]	Time 0.479 (0.453)	Data 0.007 (0.011)	Loss 2.7687 (2.8198)	Loss@kd 2.7955 (2.8617)	Acc@1 71.875 (69.632)	Acc@5 98.438 (98.759)
Epoch: [59][400/875]	Time 0.525 (0.453)	Data 0.006 (0.010)	Loss 2.7299 (2.8273)	Loss@kd 2.5911 (2.8659)	Acc@1 59.375 (69.436)	Acc@5 100.000 (98.780)
Epoch: [59][500/875]	Time 0.423 (0.452)	Data 0.007 (0.010)	Loss 2.8003 (2.8244)	Loss@kd 2.7370 (2.8587)	Acc@1 73.438 (69.392)	Acc@5 96.875 (98.777)
Epoch: [59][600/875]	Time 0.428 (0.448)	Data 0.007 (0.009)	Loss 2.7342 (2.8479)	Loss@kd 2.8115 (2.8874)	Acc@1 73.438 (69.330)	Acc@5 100.000 (98.752)
Epoch: [59][700/875]	Time 0.436 (0.446)	Data 0.007 (0.009)	Loss 2.9791 (2.8504)	Loss@kd 2.9945 (2.8889)	Acc@1 67.188 (69.341)	Acc@5 98.438 (98.776)
Epoch: [59][800/875]	Time 0.492 (0.446)	Data 0.007 (0.009)	Loss 2.8869 (2.8465)	Loss@kd 2.7692 (2.8851)	Acc@1 67.188 (69.310)	Acc@5 100.000 (98.783)
 * Acc@1 69.279 Acc@5 98.787
epoch 59, total time 391.52
Test: [0/750]	Time 0.852 (0.852)	Loss 0.6480 (0.6480)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.153 (0.109)	Loss 0.2853 (0.6239)	Acc@1 84.375 (80.848)	Acc@5 100.000 (93.626)
Test: [200/750]	Time 0.112 (0.107)	Loss 1.4048 (0.5403)	Acc@1 43.750 (82.587)	Acc@5 90.625 (95.538)
Test: [300/750]	Time 0.104 (0.105)	Loss 1.6373 (0.8439)	Acc@1 37.500 (69.279)	Acc@5 81.250 (93.148)
Test: [400/750]	Time 0.093 (0.104)	Loss 0.5781 (0.9473)	Acc@1 81.250 (65.376)	Acc@5 96.875 (92.012)
Test: [500/750]	Time 0.109 (0.103)	Loss 0.3610 (0.8927)	Acc@1 93.750 (67.821)	Acc@5 100.000 (92.365)
Test: [600/750]	Time 0.097 (0.104)	Loss 1.1532 (0.8817)	Acc@1 62.500 (68.459)	Acc@5 87.500 (92.679)
Test: [700/750]	Time 0.106 (0.103)	Loss 1.4573 (0.9312)	Acc@1 46.875 (66.347)	Acc@5 81.250 (92.488)
 * Acc@1 65.258 Acc@5 92.167
==> training...
Epoch: [60][0/875]	Time 1.860 (1.860)	Data 1.383 (1.383)	Loss 2.5718 (2.5718)	Loss@kd 2.7390 (2.7390)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [60][100/875]	Time 0.418 (0.468)	Data 0.011 (0.021)	Loss 2.6643 (2.7974)	Loss@kd 2.6212 (2.8212)	Acc@1 70.312 (69.028)	Acc@5 100.000 (98.933)
Epoch: [60][200/875]	Time 0.450 (0.462)	Data 0.007 (0.014)	Loss 2.6739 (2.7922)	Loss@kd 2.8489 (2.8201)	Acc@1 68.750 (69.271)	Acc@5 100.000 (98.842)
Epoch: [60][300/875]	Time 0.428 (0.460)	Data 0.007 (0.012)	Loss 2.9384 (2.8056)	Loss@kd 2.9798 (2.8430)	Acc@1 64.062 (69.414)	Acc@5 98.438 (98.899)
Epoch: [60][400/875]	Time 0.434 (0.458)	Data 0.007 (0.010)	Loss 2.8914 (2.8134)	Loss@kd 2.6291 (2.8508)	Acc@1 64.062 (69.307)	Acc@5 96.875 (98.819)
Epoch: [60][500/875]	Time 0.431 (0.457)	Data 0.005 (0.010)	Loss 2.9406 (2.8075)	Loss@kd 2.8756 (2.8456)	Acc@1 71.875 (69.670)	Acc@5 100.000 (98.830)
Epoch: [60][600/875]	Time 0.516 (0.457)	Data 0.007 (0.009)	Loss 2.8452 (2.8055)	Loss@kd 2.8727 (2.8458)	Acc@1 65.625 (69.743)	Acc@5 98.438 (98.820)
Epoch: [60][700/875]	Time 0.500 (0.456)	Data 0.007 (0.009)	Loss 2.7089 (2.8079)	Loss@kd 2.6272 (2.8499)	Acc@1 68.750 (69.700)	Acc@5 98.438 (98.823)
Epoch: [60][800/875]	Time 0.396 (0.455)	Data 0.007 (0.009)	Loss 2.9206 (2.8111)	Loss@kd 2.9505 (2.8487)	Acc@1 70.312 (69.638)	Acc@5 96.875 (98.775)
 * Acc@1 69.557 Acc@5 98.766
epoch 60, total time 397.11
Test: [0/750]	Time 0.735 (0.735)	Loss 3.1255 (3.1255)	Acc@1 21.875 (21.875)	Acc@5 40.625 (40.625)
Test: [100/750]	Time 0.092 (0.113)	Loss 0.4896 (2.1439)	Acc@1 78.125 (35.396)	Acc@5 100.000 (66.306)
Test: [200/750]	Time 0.186 (0.108)	Loss 1.1041 (1.3331)	Acc@1 59.375 (57.960)	Acc@5 90.625 (81.639)
Test: [300/750]	Time 0.076 (0.107)	Loss 1.0135 (1.2757)	Acc@1 56.250 (56.852)	Acc@5 96.875 (85.548)
Test: [400/750]	Time 0.107 (0.106)	Loss 1.1307 (1.2657)	Acc@1 68.750 (55.432)	Acc@5 81.250 (86.573)
Test: [500/750]	Time 0.102 (0.106)	Loss 0.4903 (1.2055)	Acc@1 81.250 (58.090)	Acc@5 100.000 (86.795)
Test: [600/750]	Time 0.110 (0.106)	Loss 0.7428 (1.1424)	Acc@1 68.750 (60.327)	Acc@5 96.875 (88.056)
Test: [700/750]	Time 0.101 (0.105)	Loss 1.6541 (1.1226)	Acc@1 53.125 (60.592)	Acc@5 78.125 (88.775)
 * Acc@1 60.537 Acc@5 88.742
==> training...
Epoch: [61][0/875]	Time 1.929 (1.929)	Data 1.308 (1.308)	Loss 2.7933 (2.7933)	Loss@kd 2.8822 (2.8822)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [61][100/875]	Time 0.423 (0.464)	Data 0.007 (0.020)	Loss 2.7547 (2.8117)	Loss@kd 2.6273 (2.8633)	Acc@1 64.062 (69.585)	Acc@5 96.875 (98.809)
Epoch: [61][200/875]	Time 0.405 (0.459)	Data 0.005 (0.013)	Loss 2.7116 (2.8166)	Loss@kd 2.7361 (2.8743)	Acc@1 73.438 (69.722)	Acc@5 96.875 (98.857)
Epoch: [61][300/875]	Time 0.444 (0.458)	Data 0.007 (0.011)	Loss 2.8125 (2.8103)	Loss@kd 2.7611 (2.8561)	Acc@1 65.625 (69.446)	Acc@5 98.438 (98.822)
Epoch: [61][400/875]	Time 0.432 (0.457)	Data 0.007 (0.010)	Loss 2.8360 (2.8159)	Loss@kd 2.8184 (2.8644)	Acc@1 65.625 (69.599)	Acc@5 96.875 (98.831)
Epoch: [61][500/875]	Time 0.444 (0.456)	Data 0.007 (0.009)	Loss 2.7401 (2.8130)	Loss@kd 2.8086 (2.8540)	Acc@1 62.500 (69.336)	Acc@5 100.000 (98.865)
Epoch: [61][600/875]	Time 0.468 (0.455)	Data 0.007 (0.009)	Loss 2.9508 (2.8097)	Loss@kd 2.7185 (2.8528)	Acc@1 59.375 (69.478)	Acc@5 95.312 (98.848)
Epoch: [61][700/875]	Time 0.460 (0.455)	Data 0.007 (0.009)	Loss 2.8683 (2.8118)	Loss@kd 2.8931 (2.8509)	Acc@1 70.312 (69.379)	Acc@5 100.000 (98.823)
Epoch: [61][800/875]	Time 0.519 (0.455)	Data 0.007 (0.008)	Loss 2.7265 (2.8080)	Loss@kd 2.9404 (2.8465)	Acc@1 73.438 (69.487)	Acc@5 100.000 (98.833)
 * Acc@1 69.482 Acc@5 98.816
epoch 61, total time 397.81
Test: [0/750]	Time 0.872 (0.872)	Loss 0.7468 (0.7468)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.110)	Loss 0.7607 (0.6099)	Acc@1 71.875 (82.766)	Acc@5 96.875 (92.636)
Test: [200/750]	Time 0.116 (0.107)	Loss 1.3220 (0.6657)	Acc@1 53.125 (77.177)	Acc@5 87.500 (94.356)
Test: [300/750]	Time 0.174 (0.104)	Loss 1.1015 (0.8495)	Acc@1 59.375 (68.065)	Acc@5 93.750 (94.103)
Test: [400/750]	Time 0.115 (0.103)	Loss 0.9622 (0.9047)	Acc@1 71.875 (65.594)	Acc@5 93.750 (93.719)
Test: [500/750]	Time 0.102 (0.103)	Loss 0.7925 (0.9269)	Acc@1 68.750 (65.856)	Acc@5 96.875 (92.590)
Test: [600/750]	Time 0.092 (0.102)	Loss 0.8095 (0.9511)	Acc@1 71.875 (65.682)	Acc@5 87.500 (91.769)
Test: [700/750]	Time 0.125 (0.102)	Loss 1.1663 (0.9424)	Acc@1 59.375 (65.866)	Acc@5 84.375 (91.940)
 * Acc@1 66.267 Acc@5 91.929
==> training...
Epoch: [62][0/875]	Time 1.869 (1.869)	Data 1.380 (1.380)	Loss 2.9457 (2.9457)	Loss@kd 2.9600 (2.9600)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [62][100/875]	Time 0.512 (0.455)	Data 0.007 (0.020)	Loss 3.2152 (2.8319)	Loss@kd 2.9586 (2.8686)	Acc@1 60.938 (69.817)	Acc@5 98.438 (98.700)
Epoch: [62][200/875]	Time 0.415 (0.444)	Data 0.007 (0.014)	Loss 2.6606 (2.7938)	Loss@kd 2.7763 (2.8251)	Acc@1 75.000 (69.753)	Acc@5 100.000 (98.857)
Epoch: [62][300/875]	Time 0.445 (0.442)	Data 0.007 (0.011)	Loss 2.7179 (2.8184)	Loss@kd 2.7969 (2.8580)	Acc@1 75.000 (69.607)	Acc@5 100.000 (98.853)
Epoch: [62][400/875]	Time 0.431 (0.445)	Data 0.009 (0.010)	Loss 2.9032 (2.8093)	Loss@kd 2.7615 (2.8497)	Acc@1 64.062 (69.751)	Acc@5 100.000 (98.854)
Epoch: [62][500/875]	Time 0.450 (0.447)	Data 0.008 (0.010)	Loss 2.7591 (2.8007)	Loss@kd 2.6941 (2.8394)	Acc@1 67.188 (69.898)	Acc@5 95.312 (98.806)
Epoch: [62][600/875]	Time 0.445 (0.448)	Data 0.007 (0.009)	Loss 2.6734 (2.8049)	Loss@kd 2.6946 (2.8388)	Acc@1 67.188 (69.678)	Acc@5 98.438 (98.799)
Epoch: [62][700/875]	Time 0.474 (0.448)	Data 0.007 (0.009)	Loss 2.8833 (2.8041)	Loss@kd 2.8005 (2.8400)	Acc@1 68.750 (69.726)	Acc@5 100.000 (98.805)
Epoch: [62][800/875]	Time 0.470 (0.449)	Data 0.007 (0.009)	Loss 3.1721 (2.8045)	Loss@kd 3.0790 (2.8395)	Acc@1 59.375 (69.653)	Acc@5 93.750 (98.804)
 * Acc@1 69.725 Acc@5 98.820
epoch 62, total time 393.79
Test: [0/750]	Time 0.883 (0.883)	Loss 1.0163 (1.0163)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.114 (0.108)	Loss 0.4183 (0.6250)	Acc@1 90.625 (81.095)	Acc@5 100.000 (92.605)
Test: [200/750]	Time 0.083 (0.107)	Loss 1.1671 (0.5551)	Acc@1 46.875 (82.385)	Acc@5 93.750 (95.320)
Test: [300/750]	Time 0.106 (0.106)	Loss 1.6119 (0.7794)	Acc@1 31.250 (73.079)	Acc@5 84.375 (94.010)
Test: [400/750]	Time 0.100 (0.105)	Loss 0.8105 (0.9552)	Acc@1 78.125 (65.555)	Acc@5 87.500 (91.942)
Test: [500/750]	Time 0.075 (0.104)	Loss 0.3710 (0.9170)	Acc@1 96.875 (67.627)	Acc@5 100.000 (91.885)
Test: [600/750]	Time 0.099 (0.103)	Loss 0.9068 (0.8996)	Acc@1 65.625 (68.058)	Acc@5 93.750 (92.367)
Test: [700/750]	Time 0.093 (0.103)	Loss 1.3967 (0.9230)	Acc@1 59.375 (66.548)	Acc@5 75.000 (92.404)
 * Acc@1 66.213 Acc@5 92.092
==> training...
Epoch: [63][0/875]	Time 1.833 (1.833)	Data 1.315 (1.315)	Loss 2.5628 (2.5628)	Loss@kd 2.6333 (2.6333)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [63][100/875]	Time 0.457 (0.468)	Data 0.007 (0.020)	Loss 2.7350 (2.7880)	Loss@kd 2.6897 (2.8366)	Acc@1 62.500 (70.467)	Acc@5 96.875 (98.685)
Epoch: [63][200/875]	Time 0.429 (0.461)	Data 0.007 (0.014)	Loss 2.8894 (2.7801)	Loss@kd 3.0452 (2.8240)	Acc@1 73.438 (70.522)	Acc@5 100.000 (98.834)
Epoch: [63][300/875]	Time 0.471 (0.459)	Data 0.007 (0.011)	Loss 2.6344 (2.7993)	Loss@kd 2.6365 (2.8384)	Acc@1 73.438 (70.136)	Acc@5 98.438 (98.801)
Epoch: [63][400/875]	Time 0.506 (0.454)	Data 0.007 (0.010)	Loss 2.6138 (2.8047)	Loss@kd 2.6489 (2.8496)	Acc@1 73.438 (70.024)	Acc@5 100.000 (98.874)
Epoch: [63][500/875]	Time 0.440 (0.450)	Data 0.007 (0.010)	Loss 2.8447 (2.7964)	Loss@kd 2.7544 (2.8383)	Acc@1 67.188 (69.941)	Acc@5 95.312 (98.855)
Epoch: [63][600/875]	Time 0.481 (0.448)	Data 0.007 (0.009)	Loss 2.6337 (2.7979)	Loss@kd 2.7187 (2.8360)	Acc@1 71.875 (69.860)	Acc@5 98.438 (98.796)
Epoch: [63][700/875]	Time 0.417 (0.449)	Data 0.007 (0.009)	Loss 2.9231 (2.7965)	Loss@kd 2.9873 (2.8340)	Acc@1 70.312 (69.898)	Acc@5 98.438 (98.803)
Epoch: [63][800/875]	Time 0.442 (0.450)	Data 0.008 (0.009)	Loss 2.5872 (2.7896)	Loss@kd 2.6665 (2.8273)	Acc@1 76.562 (70.018)	Acc@5 98.438 (98.802)
 * Acc@1 70.023 Acc@5 98.796
epoch 63, total time 394.05
Test: [0/750]	Time 0.821 (0.821)	Loss 0.8707 (0.8707)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.174 (0.113)	Loss 0.8846 (0.5746)	Acc@1 68.750 (83.385)	Acc@5 96.875 (93.069)
Test: [200/750]	Time 0.112 (0.109)	Loss 1.6597 (0.7099)	Acc@1 43.750 (76.446)	Acc@5 81.250 (93.579)
Test: [300/750]	Time 0.092 (0.107)	Loss 1.1715 (1.0016)	Acc@1 65.625 (65.438)	Acc@5 87.500 (90.667)
Test: [400/750]	Time 0.102 (0.106)	Loss 1.6618 (1.0529)	Acc@1 53.125 (62.648)	Acc@5 75.000 (90.921)
Test: [500/750]	Time 0.114 (0.105)	Loss 1.2718 (1.1037)	Acc@1 56.250 (61.508)	Acc@5 87.500 (89.839)
Test: [600/750]	Time 0.092 (0.106)	Loss 0.8278 (1.1225)	Acc@1 68.750 (60.826)	Acc@5 87.500 (89.335)
Test: [700/750]	Time 0.096 (0.105)	Loss 1.6629 (1.1297)	Acc@1 53.125 (60.311)	Acc@5 81.250 (89.644)
 * Acc@1 60.167 Acc@5 89.654
==> training...
Epoch: [64][0/875]	Time 1.908 (1.908)	Data 1.418 (1.418)	Loss 2.7528 (2.7528)	Loss@kd 2.9583 (2.9583)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [64][100/875]	Time 0.447 (0.465)	Data 0.007 (0.021)	Loss 3.2119 (2.7678)	Loss@kd 3.3580 (2.8157)	Acc@1 73.438 (69.570)	Acc@5 100.000 (98.933)
Epoch: [64][200/875]	Time 0.426 (0.457)	Data 0.008 (0.014)	Loss 2.7612 (2.7680)	Loss@kd 2.6086 (2.8089)	Acc@1 64.062 (69.667)	Acc@5 98.438 (98.951)
Epoch: [64][300/875]	Time 0.447 (0.457)	Data 0.007 (0.012)	Loss 2.8033 (2.7743)	Loss@kd 2.9244 (2.8205)	Acc@1 76.562 (70.069)	Acc@5 100.000 (98.884)
Epoch: [64][400/875]	Time 0.421 (0.455)	Data 0.007 (0.011)	Loss 2.6275 (2.7797)	Loss@kd 2.6386 (2.8236)	Acc@1 70.312 (70.083)	Acc@5 100.000 (98.897)
Epoch: [64][500/875]	Time 0.428 (0.455)	Data 0.007 (0.010)	Loss 2.8082 (2.7835)	Loss@kd 2.7157 (2.8268)	Acc@1 57.812 (70.138)	Acc@5 98.438 (98.859)
Epoch: [64][600/875]	Time 0.579 (0.456)	Data 0.007 (0.009)	Loss 2.7641 (2.7830)	Loss@kd 2.7844 (2.8223)	Acc@1 68.750 (69.969)	Acc@5 96.875 (98.877)
Epoch: [64][700/875]	Time 0.417 (0.452)	Data 0.007 (0.009)	Loss 2.6091 (2.7758)	Loss@kd 2.6478 (2.8134)	Acc@1 70.312 (70.114)	Acc@5 100.000 (98.841)
Epoch: [64][800/875]	Time 0.417 (0.449)	Data 0.007 (0.009)	Loss 3.1205 (2.7788)	Loss@kd 2.7849 (2.8163)	Acc@1 54.688 (70.115)	Acc@5 98.438 (98.828)
 * Acc@1 69.948 Acc@5 98.804
epoch 64, total time 390.95
Test: [0/750]	Time 0.849 (0.849)	Loss 7.9847 (7.9847)	Acc@1 18.750 (18.750)	Acc@5 25.000 (25.000)
Test: [100/750]	Time 0.096 (0.113)	Loss 0.5170 (7.1105)	Acc@1 78.125 (25.990)	Acc@5 96.875 (34.066)
Test: [200/750]	Time 0.179 (0.106)	Loss 1.6377 (3.8804)	Acc@1 50.000 (52.006)	Acc@5 81.250 (65.299)
Test: [300/750]	Time 0.083 (0.105)	Loss 1.7719 (3.1308)	Acc@1 43.750 (48.173)	Acc@5 81.250 (71.927)
Test: [400/750]	Time 0.078 (0.103)	Loss 0.9697 (2.7286)	Acc@1 75.000 (47.054)	Acc@5 84.375 (74.766)
Test: [500/750]	Time 0.077 (0.104)	Loss 0.4302 (2.3591)	Acc@1 87.500 (52.121)	Acc@5 100.000 (77.458)
Test: [600/750]	Time 0.097 (0.103)	Loss 0.8062 (2.0826)	Acc@1 68.750 (56.037)	Acc@5 96.875 (80.512)
Test: [700/750]	Time 0.100 (0.103)	Loss 1.4002 (1.9164)	Acc@1 50.000 (57.422)	Acc@5 75.000 (82.507)
 * Acc@1 58.067 Acc@5 83.071
==> training...
Epoch: [65][0/875]	Time 1.912 (1.912)	Data 1.344 (1.344)	Loss 2.6548 (2.6548)	Loss@kd 2.6915 (2.6915)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [65][100/875]	Time 0.478 (0.469)	Data 0.006 (0.020)	Loss 2.7319 (2.7785)	Loss@kd 2.8189 (2.8207)	Acc@1 70.312 (70.266)	Acc@5 100.000 (98.824)
Epoch: [65][200/875]	Time 0.421 (0.460)	Data 0.007 (0.013)	Loss 2.6575 (2.7740)	Loss@kd 2.6602 (2.8204)	Acc@1 71.875 (70.919)	Acc@5 100.000 (98.772)
Epoch: [65][300/875]	Time 0.417 (0.459)	Data 0.007 (0.011)	Loss 2.9536 (2.7771)	Loss@kd 3.2088 (2.8224)	Acc@1 75.000 (70.702)	Acc@5 98.438 (98.801)
Epoch: [65][400/875]	Time 0.451 (0.458)	Data 0.008 (0.010)	Loss 2.6305 (2.7696)	Loss@kd 2.7503 (2.8088)	Acc@1 75.000 (70.632)	Acc@5 100.000 (98.800)
Epoch: [65][500/875]	Time 0.450 (0.458)	Data 0.007 (0.010)	Loss 3.0472 (2.7762)	Loss@kd 2.9024 (2.8166)	Acc@1 64.062 (70.487)	Acc@5 100.000 (98.752)
Epoch: [65][600/875]	Time 0.447 (0.457)	Data 0.007 (0.009)	Loss 2.8207 (2.7718)	Loss@kd 2.7249 (2.8085)	Acc@1 68.750 (70.390)	Acc@5 98.438 (98.744)
Epoch: [65][700/875]	Time 0.457 (0.457)	Data 0.006 (0.009)	Loss 2.7403 (2.7722)	Loss@kd 2.9251 (2.8083)	Acc@1 68.750 (70.232)	Acc@5 100.000 (98.770)
Epoch: [65][800/875]	Time 0.541 (0.456)	Data 0.007 (0.009)	Loss 2.7759 (2.7763)	Loss@kd 2.9181 (2.8119)	Acc@1 70.312 (70.117)	Acc@5 100.000 (98.769)
 * Acc@1 70.189 Acc@5 98.779
epoch 65, total time 399.74
Test: [0/750]	Time 0.753 (0.753)	Loss 1.2392 (1.2392)	Acc@1 50.000 (50.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.096 (0.112)	Loss 0.4878 (0.8788)	Acc@1 78.125 (64.604)	Acc@5 100.000 (92.667)
Test: [200/750]	Time 0.108 (0.106)	Loss 1.0766 (0.7363)	Acc@1 59.375 (71.580)	Acc@5 90.625 (94.450)
Test: [300/750]	Time 0.188 (0.106)	Loss 1.0880 (0.8525)	Acc@1 59.375 (66.975)	Acc@5 96.875 (94.435)
Test: [400/750]	Time 0.091 (0.105)	Loss 0.7325 (0.9195)	Acc@1 75.000 (63.950)	Acc@5 87.500 (93.929)
Test: [500/750]	Time 0.095 (0.105)	Loss 0.7563 (0.9041)	Acc@1 71.875 (65.563)	Acc@5 100.000 (92.970)
Test: [600/750]	Time 0.099 (0.105)	Loss 0.9044 (0.9098)	Acc@1 65.625 (66.020)	Acc@5 96.875 (92.736)
Test: [700/750]	Time 0.093 (0.105)	Loss 1.2411 (0.9110)	Acc@1 56.250 (66.089)	Acc@5 81.250 (92.903)
 * Acc@1 66.037 Acc@5 92.808
==> training...
Epoch: [66][0/875]	Time 1.777 (1.777)	Data 1.324 (1.324)	Loss 2.9181 (2.9181)	Loss@kd 2.7753 (2.7753)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [66][100/875]	Time 0.533 (0.447)	Data 0.007 (0.020)	Loss 2.8098 (2.7452)	Loss@kd 2.7281 (2.7995)	Acc@1 68.750 (70.885)	Acc@5 98.438 (98.855)
Epoch: [66][200/875]	Time 0.449 (0.451)	Data 0.007 (0.014)	Loss 2.9373 (2.7341)	Loss@kd 2.8432 (2.7817)	Acc@1 64.062 (71.098)	Acc@5 98.438 (98.904)
Epoch: [66][300/875]	Time 0.445 (0.451)	Data 0.007 (0.011)	Loss 2.7402 (2.7527)	Loss@kd 2.7459 (2.7951)	Acc@1 68.750 (70.660)	Acc@5 98.438 (98.920)
Epoch: [66][400/875]	Time 0.458 (0.451)	Data 0.007 (0.010)	Loss 2.8809 (2.7640)	Loss@kd 2.9281 (2.8060)	Acc@1 70.312 (70.418)	Acc@5 100.000 (98.925)
Epoch: [66][500/875]	Time 0.435 (0.451)	Data 0.007 (0.010)	Loss 2.8216 (2.7700)	Loss@kd 2.6115 (2.8062)	Acc@1 65.625 (70.135)	Acc@5 98.438 (98.921)
Epoch: [66][600/875]	Time 0.490 (0.451)	Data 0.008 (0.009)	Loss 2.5491 (2.7691)	Loss@kd 2.6496 (2.8057)	Acc@1 73.438 (70.170)	Acc@5 98.438 (98.900)
Epoch: [66][700/875]	Time 0.431 (0.451)	Data 0.007 (0.009)	Loss 2.6506 (2.7661)	Loss@kd 2.6482 (2.8039)	Acc@1 71.875 (70.246)	Acc@5 95.312 (98.879)
Epoch: [66][800/875]	Time 0.429 (0.451)	Data 0.005 (0.009)	Loss 2.9830 (2.7635)	Loss@kd 2.6945 (2.7994)	Acc@1 60.938 (70.252)	Acc@5 93.750 (98.841)
 * Acc@1 70.287 Acc@5 98.854
epoch 66, total time 395.29
Test: [0/750]	Time 0.817 (0.817)	Loss 0.6741 (0.6741)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.099 (0.106)	Loss 0.5496 (0.6240)	Acc@1 78.125 (81.745)	Acc@5 96.875 (92.048)
Test: [200/750]	Time 0.102 (0.105)	Loss 1.1401 (0.6109)	Acc@1 53.125 (79.586)	Acc@5 96.875 (94.325)
Test: [300/750]	Time 0.107 (0.103)	Loss 1.0708 (0.8032)	Acc@1 62.500 (70.505)	Acc@5 93.750 (93.719)
Test: [400/750]	Time 0.086 (0.102)	Loss 0.5828 (0.8721)	Acc@1 81.250 (67.246)	Acc@5 93.750 (93.773)
Test: [500/750]	Time 0.119 (0.102)	Loss 0.9447 (0.8560)	Acc@1 75.000 (68.607)	Acc@5 96.875 (93.357)
Test: [600/750]	Time 0.117 (0.102)	Loss 0.5923 (0.8789)	Acc@1 78.125 (68.131)	Acc@5 96.875 (92.778)
Test: [700/750]	Time 0.108 (0.101)	Loss 1.3072 (0.8819)	Acc@1 50.000 (67.956)	Acc@5 81.250 (92.881)
 * Acc@1 67.767 Acc@5 92.804
==> training...
Epoch: [67][0/875]	Time 1.866 (1.866)	Data 1.347 (1.347)	Loss 2.6903 (2.6903)	Loss@kd 2.7621 (2.7621)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [67][100/875]	Time 0.446 (0.470)	Data 0.007 (0.020)	Loss 2.7655 (2.7858)	Loss@kd 2.9429 (2.8395)	Acc@1 76.562 (69.678)	Acc@5 96.875 (98.809)
Epoch: [67][200/875]	Time 0.435 (0.458)	Data 0.007 (0.013)	Loss 2.9431 (2.7537)	Loss@kd 2.9689 (2.7909)	Acc@1 70.312 (69.924)	Acc@5 96.875 (98.842)
Epoch: [67][300/875]	Time 0.425 (0.448)	Data 0.005 (0.011)	Loss 2.7029 (2.7549)	Loss@kd 2.7819 (2.7872)	Acc@1 76.562 (69.939)	Acc@5 98.438 (98.905)
Epoch: [67][400/875]	Time 0.499 (0.444)	Data 0.007 (0.010)	Loss 4.5883 (2.7623)	Loss@kd 5.0869 (2.7969)	Acc@1 67.188 (69.974)	Acc@5 96.875 (98.878)
Epoch: [67][500/875]	Time 0.472 (0.445)	Data 0.007 (0.009)	Loss 2.8042 (2.7712)	Loss@kd 2.6930 (2.8023)	Acc@1 62.500 (69.857)	Acc@5 98.438 (98.859)
Epoch: [67][600/875]	Time 0.461 (0.446)	Data 0.007 (0.009)	Loss 2.7824 (2.7643)	Loss@kd 2.7294 (2.7947)	Acc@1 71.875 (70.003)	Acc@5 100.000 (98.848)
Epoch: [67][700/875]	Time 0.478 (0.447)	Data 0.007 (0.009)	Loss 2.6036 (2.7602)	Loss@kd 2.7221 (2.7869)	Acc@1 78.125 (69.942)	Acc@5 100.000 (98.859)
Epoch: [67][800/875]	Time 0.408 (0.448)	Data 0.005 (0.008)	Loss 2.8803 (2.7598)	Loss@kd 2.8267 (2.7907)	Acc@1 64.062 (70.022)	Acc@5 96.875 (98.871)
 * Acc@1 70.096 Acc@5 98.877
epoch 67, total time 392.77
Test: [0/750]	Time 0.861 (0.861)	Loss 0.6063 (0.6063)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.173 (0.113)	Loss 0.3744 (0.5598)	Acc@1 84.375 (83.911)	Acc@5 100.000 (92.450)
Test: [200/750]	Time 0.101 (0.111)	Loss 0.9703 (0.5025)	Acc@1 62.500 (84.624)	Acc@5 100.000 (94.652)
Test: [300/750]	Time 0.101 (0.109)	Loss 1.4365 (0.6974)	Acc@1 37.500 (76.090)	Acc@5 93.750 (94.466)
Test: [400/750]	Time 0.089 (0.108)	Loss 0.8080 (0.8603)	Acc@1 78.125 (68.438)	Acc@5 90.625 (93.563)
Test: [500/750]	Time 0.097 (0.108)	Loss 0.7357 (0.8649)	Acc@1 68.750 (68.762)	Acc@5 100.000 (93.407)
Test: [600/750]	Time 0.094 (0.108)	Loss 0.9932 (0.8895)	Acc@1 59.375 (68.116)	Acc@5 87.500 (93.246)
Test: [700/750]	Time 0.108 (0.108)	Loss 1.1812 (0.9241)	Acc@1 65.625 (66.766)	Acc@5 87.500 (93.353)
 * Acc@1 66.396 Acc@5 93.267
==> training...
Epoch: [68][0/875]	Time 1.882 (1.882)	Data 1.377 (1.377)	Loss 2.6939 (2.6939)	Loss@kd 2.7677 (2.7677)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [68][100/875]	Time 0.445 (0.468)	Data 0.007 (0.020)	Loss 2.7149 (2.7509)	Loss@kd 2.6327 (2.7908)	Acc@1 60.938 (70.467)	Acc@5 100.000 (98.809)
Epoch: [68][200/875]	Time 0.456 (0.461)	Data 0.007 (0.014)	Loss 2.9968 (2.7586)	Loss@kd 2.8628 (2.7966)	Acc@1 67.188 (70.320)	Acc@5 96.875 (98.748)
Epoch: [68][300/875]	Time 0.424 (0.459)	Data 0.007 (0.011)	Loss 2.6512 (2.7430)	Loss@kd 2.6325 (2.7868)	Acc@1 78.125 (70.603)	Acc@5 96.875 (98.811)
Epoch: [68][400/875]	Time 0.472 (0.457)	Data 0.007 (0.010)	Loss 2.9045 (2.7464)	Loss@kd 2.8140 (2.7896)	Acc@1 62.500 (70.418)	Acc@5 98.438 (98.843)
Epoch: [68][500/875]	Time 0.437 (0.454)	Data 0.007 (0.009)	Loss 2.6393 (2.7483)	Loss@kd 2.4921 (2.7916)	Acc@1 60.938 (70.528)	Acc@5 96.875 (98.837)
Epoch: [68][600/875]	Time 0.514 (0.450)	Data 0.007 (0.009)	Loss 3.0635 (2.7588)	Loss@kd 2.5880 (2.8012)	Acc@1 53.125 (70.370)	Acc@5 100.000 (98.853)
Epoch: [68][700/875]	Time 0.478 (0.448)	Data 0.007 (0.009)	Loss 2.9119 (2.7543)	Loss@kd 2.8208 (2.7959)	Acc@1 73.438 (70.368)	Acc@5 98.438 (98.877)
Epoch: [68][800/875]	Time 0.472 (0.448)	Data 0.007 (0.008)	Loss 2.6909 (2.7543)	Loss@kd 2.9782 (2.7944)	Acc@1 76.562 (70.312)	Acc@5 98.438 (98.871)
 * Acc@1 70.321 Acc@5 98.868
epoch 68, total time 392.63
Test: [0/750]	Time 0.803 (0.803)	Loss 0.6130 (0.6130)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.072 (0.110)	Loss 0.4842 (0.4440)	Acc@1 81.250 (86.139)	Acc@5 96.875 (94.864)
Test: [200/750]	Time 0.164 (0.104)	Loss 1.4422 (0.4870)	Acc@1 43.750 (83.007)	Acc@5 87.500 (95.896)
Test: [300/750]	Time 0.106 (0.104)	Loss 1.1784 (0.7639)	Acc@1 53.125 (71.709)	Acc@5 90.625 (94.010)
Test: [400/750]	Time 0.114 (0.103)	Loss 0.7925 (0.8367)	Acc@1 78.125 (68.610)	Acc@5 90.625 (94.031)
Test: [500/750]	Time 0.091 (0.104)	Loss 0.5326 (0.8242)	Acc@1 81.250 (70.328)	Acc@5 100.000 (93.563)
Test: [600/750]	Time 0.092 (0.103)	Loss 0.6179 (0.8260)	Acc@1 75.000 (70.679)	Acc@5 93.750 (93.433)
Test: [700/750]	Time 0.093 (0.103)	Loss 1.4841 (0.8373)	Acc@1 56.250 (70.003)	Acc@5 81.250 (93.420)
 * Acc@1 69.542 Acc@5 93.204
saving the best model!
==> training...
Epoch: [69][0/875]	Time 1.940 (1.940)	Data 1.377 (1.377)	Loss 2.7817 (2.7817)	Loss@kd 2.9461 (2.9461)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [69][100/875]	Time 0.429 (0.467)	Data 0.007 (0.020)	Loss 2.6556 (2.6976)	Loss@kd 2.6439 (2.7450)	Acc@1 75.000 (71.287)	Acc@5 98.438 (99.118)
Epoch: [69][200/875]	Time 0.433 (0.460)	Data 0.007 (0.014)	Loss 2.6898 (2.7093)	Loss@kd 2.8095 (2.7496)	Acc@1 73.438 (70.771)	Acc@5 98.438 (98.974)
Epoch: [69][300/875]	Time 0.494 (0.458)	Data 0.007 (0.011)	Loss 2.6538 (2.7332)	Loss@kd 2.6443 (2.7792)	Acc@1 70.312 (70.743)	Acc@5 96.875 (98.936)
Epoch: [69][400/875]	Time 0.479 (0.456)	Data 0.006 (0.010)	Loss 2.6915 (2.7426)	Loss@kd 2.6716 (2.7870)	Acc@1 70.312 (70.531)	Acc@5 96.875 (98.889)
Epoch: [69][500/875]	Time 0.403 (0.456)	Data 0.007 (0.010)	Loss 3.2451 (2.7411)	Loss@kd 3.2803 (2.7820)	Acc@1 70.312 (70.571)	Acc@5 96.875 (98.890)
Epoch: [69][600/875]	Time 0.431 (0.456)	Data 0.007 (0.009)	Loss 2.6169 (2.7628)	Loss@kd 2.8437 (2.8078)	Acc@1 75.000 (70.455)	Acc@5 98.438 (98.864)
Epoch: [69][700/875]	Time 0.468 (0.455)	Data 0.007 (0.009)	Loss 2.8801 (2.7603)	Loss@kd 2.8408 (2.8008)	Acc@1 67.188 (70.375)	Acc@5 96.875 (98.836)
Epoch: [69][800/875]	Time 0.527 (0.454)	Data 0.006 (0.009)	Loss 2.7353 (2.7545)	Loss@kd 2.8542 (2.7945)	Acc@1 75.000 (70.404)	Acc@5 100.000 (98.853)
 * Acc@1 70.502 Acc@5 98.850
epoch 69, total time 396.12
Test: [0/750]	Time 0.831 (0.831)	Loss 0.9182 (0.9182)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.089 (0.111)	Loss 0.2717 (0.8940)	Acc@1 87.500 (78.403)	Acc@5 96.875 (90.408)
Test: [200/750]	Time 0.090 (0.107)	Loss 1.2826 (0.6635)	Acc@1 50.000 (81.872)	Acc@5 90.625 (93.905)
Test: [300/750]	Time 0.181 (0.105)	Loss 1.9266 (0.9273)	Acc@1 37.500 (70.588)	Acc@5 87.500 (92.151)
Test: [400/750]	Time 0.093 (0.105)	Loss 1.0940 (1.1306)	Acc@1 65.625 (62.601)	Acc@5 81.250 (89.799)
Test: [500/750]	Time 0.101 (0.103)	Loss 0.4748 (1.1064)	Acc@1 87.500 (63.492)	Acc@5 100.000 (89.365)
Test: [600/750]	Time 0.100 (0.104)	Loss 1.0452 (1.0781)	Acc@1 65.625 (64.356)	Acc@5 93.750 (90.329)
Test: [700/750]	Time 0.105 (0.104)	Loss 1.4772 (1.0807)	Acc@1 56.250 (63.980)	Acc@5 81.250 (90.594)
 * Acc@1 63.862 Acc@5 90.192
==> training...
Epoch: [70][0/875]	Time 1.905 (1.905)	Data 1.387 (1.387)	Loss 2.7513 (2.7513)	Loss@kd 2.8615 (2.8615)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [70][100/875]	Time 0.480 (0.471)	Data 0.005 (0.020)	Loss 2.7056 (2.7266)	Loss@kd 2.8084 (2.7926)	Acc@1 76.562 (71.705)	Acc@5 100.000 (99.226)
Epoch: [70][200/875]	Time 0.458 (0.461)	Data 0.007 (0.014)	Loss 2.6561 (2.7334)	Loss@kd 2.7949 (2.7786)	Acc@1 76.562 (71.035)	Acc@5 98.438 (99.036)
Epoch: [70][300/875]	Time 0.474 (0.458)	Data 0.007 (0.011)	Loss 2.6867 (2.7353)	Loss@kd 2.6369 (2.7786)	Acc@1 65.625 (70.842)	Acc@5 95.312 (98.941)
Epoch: [70][400/875]	Time 0.425 (0.458)	Data 0.007 (0.010)	Loss 2.8592 (2.7445)	Loss@kd 2.8854 (2.7903)	Acc@1 71.875 (70.811)	Acc@5 98.438 (98.886)
Epoch: [70][500/875]	Time 0.422 (0.457)	Data 0.007 (0.010)	Loss 2.6621 (2.7378)	Loss@kd 2.7437 (2.7825)	Acc@1 75.000 (70.780)	Acc@5 100.000 (98.893)
Epoch: [70][600/875]	Time 0.444 (0.457)	Data 0.007 (0.009)	Loss 2.5688 (2.7365)	Loss@kd 2.7878 (2.7796)	Acc@1 75.000 (70.767)	Acc@5 98.438 (98.879)
Epoch: [70][700/875]	Time 0.418 (0.457)	Data 0.008 (0.009)	Loss 2.7869 (2.7360)	Loss@kd 2.8684 (2.7790)	Acc@1 67.188 (70.803)	Acc@5 98.438 (98.870)
Epoch: [70][800/875]	Time 0.435 (0.456)	Data 0.005 (0.009)	Loss 2.8076 (2.7360)	Loss@kd 2.7354 (2.7790)	Acc@1 65.625 (70.798)	Acc@5 98.438 (98.892)
 * Acc@1 70.718 Acc@5 98.882
epoch 70, total time 399.60
Test: [0/750]	Time 0.873 (0.873)	Loss 1.7487 (1.7487)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.090 (0.111)	Loss 0.2823 (1.1254)	Acc@1 84.375 (64.356)	Acc@5 100.000 (88.676)
Test: [200/750]	Time 0.104 (0.108)	Loss 1.2389 (0.7641)	Acc@1 43.750 (75.513)	Acc@5 90.625 (92.957)
Test: [300/750]	Time 0.100 (0.105)	Loss 1.6096 (0.9864)	Acc@1 37.500 (65.594)	Acc@5 87.500 (91.902)
Test: [400/750]	Time 0.097 (0.105)	Loss 0.4265 (1.1056)	Acc@1 87.500 (59.882)	Acc@5 100.000 (90.617)
Test: [500/750]	Time 0.095 (0.104)	Loss 0.5019 (1.0052)	Acc@1 87.500 (63.972)	Acc@5 96.875 (91.455)
Test: [600/750]	Time 0.082 (0.103)	Loss 0.8318 (0.9895)	Acc@1 65.625 (64.658)	Acc@5 93.750 (91.753)
Test: [700/750]	Time 0.059 (0.102)	Loss 0.9244 (0.9774)	Acc@1 62.500 (64.885)	Acc@5 87.500 (92.279)
 * Acc@1 65.700 Acc@5 92.371
==> training...
Epoch: [71][0/875]	Time 1.788 (1.788)	Data 1.362 (1.362)	Loss 2.7748 (2.7748)	Loss@kd 2.6853 (2.6853)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [71][100/875]	Time 0.432 (0.449)	Data 0.007 (0.020)	Loss 2.5836 (2.7088)	Loss@kd 2.7423 (2.7812)	Acc@1 71.875 (71.860)	Acc@5 96.875 (99.056)
Epoch: [71][200/875]	Time 0.402 (0.443)	Data 0.007 (0.014)	Loss 2.6246 (2.7191)	Loss@kd 2.6673 (2.7913)	Acc@1 67.188 (71.789)	Acc@5 100.000 (98.943)
Epoch: [71][300/875]	Time 0.425 (0.444)	Data 0.007 (0.011)	Loss 2.6736 (2.7209)	Loss@kd 2.7344 (2.7836)	Acc@1 71.875 (71.486)	Acc@5 100.000 (98.931)
Epoch: [71][400/875]	Time 0.508 (0.446)	Data 0.007 (0.010)	Loss 2.7759 (2.7211)	Loss@kd 2.7346 (2.7748)	Acc@1 65.625 (71.185)	Acc@5 100.000 (98.940)
Epoch: [71][500/875]	Time 0.480 (0.448)	Data 0.008 (0.010)	Loss 2.6594 (2.7218)	Loss@kd 2.5831 (2.7728)	Acc@1 68.750 (71.070)	Acc@5 98.438 (98.958)
Epoch: [71][600/875]	Time 0.466 (0.449)	Data 0.008 (0.009)	Loss 2.4748 (2.7212)	Loss@kd 2.6366 (2.7689)	Acc@1 79.688 (70.944)	Acc@5 98.438 (98.947)
Epoch: [71][700/875]	Time 0.456 (0.449)	Data 0.007 (0.009)	Loss 2.5874 (2.7228)	Loss@kd 2.7260 (2.7698)	Acc@1 75.000 (70.988)	Acc@5 100.000 (98.932)
Epoch: [71][800/875]	Time 0.452 (0.449)	Data 0.007 (0.009)	Loss 2.8185 (2.7203)	Loss@kd 2.6870 (2.7649)	Acc@1 68.750 (70.972)	Acc@5 95.312 (98.939)
 * Acc@1 70.991 Acc@5 98.929
epoch 71, total time 393.79
Test: [0/750]	Time 0.871 (0.871)	Loss 0.5693 (0.5693)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.165 (0.110)	Loss 0.5122 (0.5764)	Acc@1 78.125 (82.085)	Acc@5 100.000 (93.595)
Test: [200/750]	Time 0.100 (0.106)	Loss 1.3850 (0.5595)	Acc@1 43.750 (80.892)	Acc@5 96.875 (95.398)
Test: [300/750]	Time 0.095 (0.104)	Loss 1.2247 (0.7907)	Acc@1 56.250 (70.899)	Acc@5 93.750 (94.041)
Test: [400/750]	Time 0.105 (0.103)	Loss 0.8941 (0.8961)	Acc@1 68.750 (66.482)	Acc@5 87.500 (93.321)
Test: [500/750]	Time 0.102 (0.102)	Loss 0.5409 (0.8971)	Acc@1 78.125 (67.372)	Acc@5 100.000 (92.428)
Test: [600/750]	Time 0.104 (0.102)	Loss 0.7345 (0.8854)	Acc@1 75.000 (68.043)	Acc@5 96.875 (92.460)
Test: [700/750]	Time 0.088 (0.102)	Loss 1.0294 (0.8827)	Acc@1 59.375 (67.925)	Acc@5 84.375 (92.841)
 * Acc@1 68.183 Acc@5 92.929
==> training...
Epoch: [72][0/875]	Time 1.842 (1.842)	Data 1.394 (1.394)	Loss 2.5792 (2.5792)	Loss@kd 2.6354 (2.6354)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [72][100/875]	Time 0.436 (0.459)	Data 0.006 (0.020)	Loss 2.7898 (2.6678)	Loss@kd 2.7727 (2.7320)	Acc@1 70.312 (71.952)	Acc@5 100.000 (99.056)
Epoch: [72][200/875]	Time 0.441 (0.455)	Data 0.007 (0.014)	Loss 2.7367 (2.6947)	Loss@kd 2.8756 (2.7481)	Acc@1 78.125 (71.269)	Acc@5 100.000 (99.013)
Epoch: [72][300/875]	Time 0.414 (0.453)	Data 0.005 (0.012)	Loss 4.7982 (2.7416)	Loss@kd 5.6579 (2.7995)	Acc@1 67.188 (70.837)	Acc@5 100.000 (99.024)
Epoch: [72][400/875]	Time 0.415 (0.448)	Data 0.007 (0.010)	Loss 2.6721 (2.7659)	Loss@kd 2.6896 (2.8218)	Acc@1 70.312 (70.472)	Acc@5 100.000 (98.917)
Epoch: [72][500/875]	Time 0.412 (0.444)	Data 0.007 (0.010)	Loss 2.5267 (2.7573)	Loss@kd 2.5037 (2.8131)	Acc@1 67.188 (70.734)	Acc@5 100.000 (98.940)
Epoch: [72][600/875]	Time 0.530 (0.445)	Data 0.007 (0.009)	Loss 2.7387 (2.7589)	Loss@kd 2.8709 (2.8108)	Acc@1 71.875 (70.630)	Acc@5 98.438 (98.931)
Epoch: [72][700/875]	Time 0.416 (0.447)	Data 0.007 (0.009)	Loss 2.6236 (2.7559)	Loss@kd 2.5850 (2.8072)	Acc@1 76.562 (70.611)	Acc@5 96.875 (98.928)
Epoch: [72][800/875]	Time 0.466 (0.447)	Data 0.007 (0.009)	Loss 2.8483 (2.7491)	Loss@kd 2.7165 (2.7980)	Acc@1 62.500 (70.632)	Acc@5 96.875 (98.929)
 * Acc@1 70.559 Acc@5 98.907
epoch 72, total time 392.21
Test: [0/750]	Time 0.827 (0.827)	Loss 0.5600 (0.5600)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.097 (0.114)	Loss 0.6799 (0.4933)	Acc@1 71.875 (83.756)	Acc@5 96.875 (94.214)
Test: [200/750]	Time 0.186 (0.109)	Loss 1.2266 (0.6577)	Acc@1 43.750 (77.488)	Acc@5 96.875 (93.517)
Test: [300/750]	Time 0.097 (0.107)	Loss 0.8675 (0.8106)	Acc@1 68.750 (70.473)	Acc@5 90.625 (93.854)
Test: [400/750]	Time 0.106 (0.106)	Loss 1.1496 (0.8991)	Acc@1 56.250 (66.521)	Acc@5 87.500 (93.243)
Test: [500/750]	Time 0.097 (0.105)	Loss 0.9063 (0.9968)	Acc@1 62.500 (63.404)	Acc@5 93.750 (91.267)
Test: [600/750]	Time 0.089 (0.105)	Loss 1.0421 (1.0422)	Acc@1 56.250 (62.271)	Acc@5 81.250 (90.334)
Test: [700/750]	Time 0.103 (0.105)	Loss 1.2218 (1.0512)	Acc@1 56.250 (61.729)	Acc@5 81.250 (90.335)
 * Acc@1 61.654 Acc@5 90.463
==> training...
Epoch: [73][0/875]	Time 1.908 (1.908)	Data 1.351 (1.351)	Loss 2.4790 (2.4790)	Loss@kd 2.6513 (2.6513)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [73][100/875]	Time 0.423 (0.466)	Data 0.006 (0.020)	Loss 2.5670 (2.7039)	Loss@kd 2.7375 (2.7725)	Acc@1 79.688 (71.674)	Acc@5 100.000 (99.226)
Epoch: [73][200/875]	Time 0.455 (0.457)	Data 0.007 (0.014)	Loss 2.6407 (2.7163)	Loss@kd 2.6488 (2.7802)	Acc@1 68.750 (71.183)	Acc@5 96.875 (99.059)
Epoch: [73][300/875]	Time 0.450 (0.456)	Data 0.007 (0.012)	Loss 2.5616 (2.7116)	Loss@kd 2.5494 (2.7688)	Acc@1 75.000 (71.480)	Acc@5 100.000 (99.029)
Epoch: [73][400/875]	Time 0.452 (0.455)	Data 0.007 (0.010)	Loss 3.1704 (2.7204)	Loss@kd 3.5471 (2.7750)	Acc@1 73.438 (71.158)	Acc@5 100.000 (99.018)
Epoch: [73][500/875]	Time 0.421 (0.454)	Data 0.007 (0.010)	Loss 2.4830 (2.7222)	Loss@kd 2.6257 (2.7725)	Acc@1 73.438 (70.980)	Acc@5 100.000 (98.999)
Epoch: [73][600/875]	Time 0.418 (0.453)	Data 0.007 (0.009)	Loss 2.6315 (2.7169)	Loss@kd 2.6733 (2.7666)	Acc@1 62.500 (70.892)	Acc@5 100.000 (98.976)
Epoch: [73][700/875]	Time 0.418 (0.450)	Data 0.007 (0.009)	Loss 2.5871 (2.7159)	Loss@kd 2.5978 (2.7609)	Acc@1 70.312 (70.694)	Acc@5 100.000 (98.990)
Epoch: [73][800/875]	Time 0.501 (0.448)	Data 0.007 (0.009)	Loss 2.7820 (2.7155)	Loss@kd 2.8958 (2.7600)	Acc@1 71.875 (70.753)	Acc@5 98.438 (98.976)
 * Acc@1 70.655 Acc@5 98.977
epoch 73, total time 391.74
Test: [0/750]	Time 0.809 (0.809)	Loss 0.6035 (0.6035)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.088 (0.112)	Loss 0.6896 (0.5248)	Acc@1 84.375 (85.179)	Acc@5 93.750 (93.719)
Test: [200/750]	Time 0.076 (0.108)	Loss 1.4024 (0.5870)	Acc@1 40.625 (81.203)	Acc@5 87.500 (94.652)
Test: [300/750]	Time 0.174 (0.106)	Loss 1.0218 (0.7975)	Acc@1 59.375 (71.179)	Acc@5 90.625 (94.352)
Test: [400/750]	Time 0.115 (0.105)	Loss 1.2128 (0.8925)	Acc@1 62.500 (66.965)	Acc@5 84.375 (93.672)
Test: [500/750]	Time 0.104 (0.104)	Loss 0.6300 (0.9441)	Acc@1 68.750 (65.419)	Acc@5 100.000 (91.997)
Test: [600/750]	Time 0.087 (0.104)	Loss 0.9076 (0.9501)	Acc@1 68.750 (65.589)	Acc@5 90.625 (91.779)
Test: [700/750]	Time 0.091 (0.103)	Loss 1.0540 (0.9403)	Acc@1 59.375 (65.835)	Acc@5 87.500 (92.185)
 * Acc@1 66.075 Acc@5 92.354
==> training...
Epoch: [74][0/875]	Time 1.870 (1.870)	Data 1.360 (1.360)	Loss 2.7651 (2.7651)	Loss@kd 2.8058 (2.8058)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [74][100/875]	Time 0.548 (0.471)	Data 0.007 (0.020)	Loss 2.5331 (2.6932)	Loss@kd 2.5772 (2.7747)	Acc@1 71.875 (72.107)	Acc@5 100.000 (99.041)
Epoch: [74][200/875]	Time 0.425 (0.460)	Data 0.007 (0.014)	Loss 2.6893 (2.6840)	Loss@kd 2.6029 (2.7463)	Acc@1 64.062 (71.362)	Acc@5 98.438 (99.044)
Epoch: [74][300/875]	Time 0.463 (0.458)	Data 0.007 (0.011)	Loss 2.7631 (2.6887)	Loss@kd 2.9177 (2.7464)	Acc@1 71.875 (71.216)	Acc@5 100.000 (98.962)
Epoch: [74][400/875]	Time 0.435 (0.457)	Data 0.007 (0.010)	Loss 2.5579 (2.6983)	Loss@kd 2.6661 (2.7621)	Acc@1 73.438 (71.302)	Acc@5 100.000 (98.999)
Epoch: [74][500/875]	Time 0.424 (0.456)	Data 0.007 (0.010)	Loss 2.4072 (2.7022)	Loss@kd 2.6177 (2.7630)	Acc@1 79.688 (71.223)	Acc@5 100.000 (98.986)
Epoch: [74][600/875]	Time 0.452 (0.455)	Data 0.007 (0.009)	Loss 2.6769 (2.7012)	Loss@kd 2.7651 (2.7557)	Acc@1 76.562 (71.077)	Acc@5 95.312 (98.978)
Epoch: [74][700/875]	Time 0.415 (0.455)	Data 0.007 (0.009)	Loss 2.6735 (2.7060)	Loss@kd 2.7262 (2.7596)	Acc@1 76.562 (71.068)	Acc@5 96.875 (98.964)
Epoch: [74][800/875]	Time 0.430 (0.455)	Data 0.007 (0.009)	Loss 2.9318 (2.7083)	Loss@kd 2.6322 (2.7554)	Acc@1 64.062 (70.904)	Acc@5 95.312 (98.931)
 * Acc@1 70.959 Acc@5 98.900
epoch 74, total time 398.15
Test: [0/750]	Time 0.920 (0.920)	Loss 1.4461 (1.4461)	Acc@1 37.500 (37.500)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.104 (0.115)	Loss 0.5711 (1.2341)	Acc@1 81.250 (39.418)	Acc@5 100.000 (91.925)
Test: [200/750]	Time 0.093 (0.107)	Loss 1.2195 (0.9327)	Acc@1 53.125 (58.815)	Acc@5 93.750 (94.045)
Test: [300/750]	Time 0.097 (0.106)	Loss 1.0385 (0.9944)	Acc@1 56.250 (57.672)	Acc@5 93.750 (94.010)
Test: [400/750]	Time 0.099 (0.104)	Loss 0.5740 (0.9965)	Acc@1 84.375 (58.315)	Acc@5 93.750 (94.015)
Test: [500/750]	Time 0.094 (0.104)	Loss 0.7326 (0.9461)	Acc@1 75.000 (61.577)	Acc@5 93.750 (93.775)
Test: [600/750]	Time 0.101 (0.103)	Loss 0.8991 (0.9532)	Acc@1 68.750 (62.401)	Acc@5 87.500 (93.152)
Test: [700/750]	Time 0.105 (0.103)	Loss 0.9644 (0.9527)	Acc@1 56.250 (62.870)	Acc@5 90.625 (93.197)
 * Acc@1 63.342 Acc@5 93.275
==> training...
Epoch: [75][0/875]	Time 1.958 (1.958)	Data 1.395 (1.395)	Loss 2.7224 (2.7224)	Loss@kd 2.5898 (2.5898)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [75][100/875]	Time 0.448 (0.444)	Data 0.008 (0.021)	Loss 2.5496 (2.6726)	Loss@kd 2.7007 (2.7252)	Acc@1 76.562 (71.318)	Acc@5 96.875 (99.025)
Epoch: [75][200/875]	Time 0.427 (0.448)	Data 0.008 (0.014)	Loss 2.6380 (2.6866)	Loss@kd 2.7771 (2.7336)	Acc@1 76.562 (71.074)	Acc@5 96.875 (99.021)
Epoch: [75][300/875]	Time 0.423 (0.449)	Data 0.007 (0.012)	Loss 2.5861 (2.6917)	Loss@kd 2.6873 (2.7473)	Acc@1 79.688 (71.506)	Acc@5 98.438 (99.055)
Epoch: [75][400/875]	Time 0.430 (0.450)	Data 0.007 (0.010)	Loss 2.7131 (2.6804)	Loss@kd 2.6815 (2.7319)	Acc@1 70.312 (71.509)	Acc@5 98.438 (99.010)
Epoch: [75][500/875]	Time 0.421 (0.451)	Data 0.007 (0.010)	Loss 4.4492 (2.6860)	Loss@kd 4.9570 (2.7337)	Acc@1 64.062 (71.248)	Acc@5 98.438 (98.980)
Epoch: [75][600/875]	Time 0.459 (0.451)	Data 0.007 (0.009)	Loss 2.5273 (2.6925)	Loss@kd 2.6458 (2.7393)	Acc@1 75.000 (71.230)	Acc@5 100.000 (98.950)
Epoch: [75][700/875]	Time 0.473 (0.452)	Data 0.007 (0.009)	Loss 2.5146 (2.6941)	Loss@kd 2.6987 (2.7465)	Acc@1 79.688 (71.376)	Acc@5 100.000 (98.950)
Epoch: [75][800/875]	Time 0.518 (0.452)	Data 0.007 (0.009)	Loss 2.6562 (2.6944)	Loss@kd 2.6962 (2.7439)	Acc@1 76.562 (71.264)	Acc@5 98.438 (98.956)
 * Acc@1 71.220 Acc@5 98.986
epoch 75, total time 395.98
Test: [0/750]	Time 0.765 (0.765)	Loss 0.8837 (0.8837)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.101 (0.111)	Loss 0.6264 (0.6617)	Acc@1 65.625 (80.043)	Acc@5 100.000 (93.131)
Test: [200/750]	Time 0.106 (0.107)	Loss 1.6319 (0.6562)	Acc@1 34.375 (77.379)	Acc@5 87.500 (95.382)
Test: [300/750]	Time 0.159 (0.105)	Loss 1.3076 (0.8998)	Acc@1 59.375 (67.297)	Acc@5 90.625 (93.418)
Test: [400/750]	Time 0.092 (0.105)	Loss 0.5972 (0.9728)	Acc@1 84.375 (63.630)	Acc@5 90.625 (93.056)
Test: [500/750]	Time 0.109 (0.104)	Loss 0.6748 (0.9307)	Acc@1 78.125 (66.161)	Acc@5 96.875 (92.633)
Test: [600/750]	Time 0.103 (0.104)	Loss 0.5656 (0.9047)	Acc@1 78.125 (67.580)	Acc@5 93.750 (92.674)
Test: [700/750]	Time 0.096 (0.104)	Loss 1.3371 (0.8853)	Acc@1 50.000 (68.237)	Acc@5 81.250 (92.885)
 * Acc@1 68.158 Acc@5 92.779
==> training...
Epoch: [76][0/875]	Time 1.839 (1.839)	Data 1.344 (1.344)	Loss 2.5417 (2.5417)	Loss@kd 2.7530 (2.7530)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [76][100/875]	Time 0.505 (0.469)	Data 0.007 (0.020)	Loss 2.5913 (2.6148)	Loss@kd 2.5859 (2.7124)	Acc@1 68.750 (73.236)	Acc@5 95.312 (99.288)
Epoch: [76][200/875]	Time 0.421 (0.451)	Data 0.007 (0.014)	Loss 2.3712 (2.5640)	Loss@kd 2.5494 (2.6723)	Acc@1 76.562 (73.896)	Acc@5 100.000 (99.230)
Epoch: [76][300/875]	Time 0.422 (0.445)	Data 0.007 (0.011)	Loss 2.5762 (2.5549)	Loss@kd 2.6171 (2.6617)	Acc@1 71.875 (74.029)	Acc@5 100.000 (99.180)
Epoch: [76][400/875]	Time 0.429 (0.442)	Data 0.007 (0.010)	Loss 2.4693 (2.5440)	Loss@kd 2.6468 (2.6526)	Acc@1 76.562 (74.178)	Acc@5 98.438 (99.205)
Epoch: [76][500/875]	Time 0.444 (0.444)	Data 0.007 (0.010)	Loss 2.4255 (2.5403)	Loss@kd 2.5805 (2.6503)	Acc@1 75.000 (74.317)	Acc@5 100.000 (99.242)
Epoch: [76][600/875]	Time 0.429 (0.445)	Data 0.007 (0.009)	Loss 2.4430 (2.5406)	Loss@kd 2.6016 (2.6542)	Acc@1 79.688 (74.394)	Acc@5 96.875 (99.241)
Epoch: [76][700/875]	Time 0.435 (0.446)	Data 0.010 (0.009)	Loss 2.4904 (2.5361)	Loss@kd 2.5726 (2.6524)	Acc@1 73.438 (74.623)	Acc@5 100.000 (99.244)
Epoch: [76][800/875]	Time 0.432 (0.447)	Data 0.008 (0.009)	Loss 2.5089 (2.5318)	Loss@kd 2.5558 (2.6484)	Acc@1 75.000 (74.690)	Acc@5 98.438 (99.247)
 * Acc@1 74.945 Acc@5 99.243
epoch 76, total time 392.67
Test: [0/750]	Time 0.874 (0.874)	Loss 0.5274 (0.5274)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.093 (0.106)	Loss 0.3596 (0.4496)	Acc@1 81.250 (86.355)	Acc@5 96.875 (95.235)
Test: [200/750]	Time 0.101 (0.106)	Loss 1.1115 (0.4492)	Acc@1 59.375 (85.137)	Acc@5 87.500 (96.377)
Test: [300/750]	Time 0.094 (0.103)	Loss 0.9948 (0.6494)	Acc@1 53.125 (76.755)	Acc@5 93.750 (95.380)
Test: [400/750]	Time 0.091 (0.103)	Loss 0.4690 (0.7502)	Acc@1 87.500 (72.218)	Acc@5 90.625 (94.841)
Test: [500/750]	Time 0.094 (0.102)	Loss 0.4898 (0.7319)	Acc@1 78.125 (73.447)	Acc@5 100.000 (94.629)
Test: [600/750]	Time 0.097 (0.103)	Loss 0.6953 (0.7461)	Acc@1 71.875 (73.357)	Acc@5 93.750 (94.457)
Test: [700/750]	Time 0.094 (0.102)	Loss 0.9327 (0.7468)	Acc@1 59.375 (73.128)	Acc@5 87.500 (94.704)
 * Acc@1 73.179 Acc@5 94.688
saving the best model!
==> training...
Epoch: [77][0/875]	Time 1.886 (1.886)	Data 1.381 (1.381)	Loss 2.6272 (2.6272)	Loss@kd 2.6388 (2.6388)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [77][100/875]	Time 0.459 (0.469)	Data 0.007 (0.021)	Loss 2.7987 (2.4867)	Loss@kd 2.7277 (2.6171)	Acc@1 70.312 (75.309)	Acc@5 98.438 (99.381)
Epoch: [77][200/875]	Time 0.450 (0.460)	Data 0.007 (0.014)	Loss 2.4276 (2.4710)	Loss@kd 2.4500 (2.6079)	Acc@1 76.562 (75.637)	Acc@5 100.000 (99.386)
Epoch: [77][300/875]	Time 0.427 (0.458)	Data 0.007 (0.012)	Loss 2.3798 (2.4886)	Loss@kd 2.5403 (2.6266)	Acc@1 68.750 (75.685)	Acc@5 98.438 (99.403)
Epoch: [77][400/875]	Time 0.558 (0.456)	Data 0.008 (0.010)	Loss 2.5539 (2.4873)	Loss@kd 2.6590 (2.6231)	Acc@1 76.562 (75.752)	Acc@5 100.000 (99.439)
Epoch: [77][500/875]	Time 0.429 (0.453)	Data 0.007 (0.010)	Loss 2.5697 (2.4881)	Loss@kd 2.5459 (2.6225)	Acc@1 68.750 (75.727)	Acc@5 100.000 (99.386)
Epoch: [77][600/875]	Time 0.421 (0.450)	Data 0.007 (0.009)	Loss 2.6537 (2.4850)	Loss@kd 2.4763 (2.6199)	Acc@1 68.750 (75.738)	Acc@5 98.438 (99.373)
Epoch: [77][700/875]	Time 0.411 (0.448)	Data 0.005 (0.009)	Loss 2.5703 (2.4875)	Loss@kd 2.6085 (2.6224)	Acc@1 76.562 (75.704)	Acc@5 100.000 (99.354)
Epoch: [77][800/875]	Time 0.454 (0.449)	Data 0.007 (0.009)	Loss 2.5087 (2.4897)	Loss@kd 2.5465 (2.6242)	Acc@1 70.312 (75.720)	Acc@5 100.000 (99.343)
 * Acc@1 75.773 Acc@5 99.341
epoch 77, total time 393.01
Test: [0/750]	Time 0.838 (0.838)	Loss 0.5695 (0.5695)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.159 (0.111)	Loss 0.3666 (0.4917)	Acc@1 81.250 (85.396)	Acc@5 96.875 (94.740)
Test: [200/750]	Time 0.096 (0.107)	Loss 1.2209 (0.4777)	Acc@1 50.000 (84.266)	Acc@5 87.500 (96.004)
Test: [300/750]	Time 0.094 (0.105)	Loss 0.9250 (0.6878)	Acc@1 56.250 (75.156)	Acc@5 90.625 (94.944)
Test: [400/750]	Time 0.093 (0.104)	Loss 0.5509 (0.7710)	Acc@1 84.375 (71.400)	Acc@5 90.625 (94.584)
Test: [500/750]	Time 0.091 (0.103)	Loss 0.4950 (0.7561)	Acc@1 81.250 (72.567)	Acc@5 100.000 (94.130)
Test: [600/750]	Time 0.096 (0.103)	Loss 0.6862 (0.7631)	Acc@1 71.875 (72.691)	Acc@5 93.750 (94.104)
Test: [700/750]	Time 0.100 (0.103)	Loss 1.0090 (0.7593)	Acc@1 65.625 (72.660)	Acc@5 87.500 (94.437)
 * Acc@1 72.846 Acc@5 94.454
==> training...
Epoch: [78][0/875]	Time 1.827 (1.827)	Data 1.391 (1.391)	Loss 2.4360 (2.4360)	Loss@kd 2.6903 (2.6903)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [78][100/875]	Time 0.446 (0.470)	Data 0.006 (0.021)	Loss 2.4982 (2.4668)	Loss@kd 2.5991 (2.6064)	Acc@1 78.125 (76.408)	Acc@5 100.000 (99.397)
Epoch: [78][200/875]	Time 0.414 (0.462)	Data 0.007 (0.014)	Loss 2.3489 (2.4760)	Loss@kd 2.6260 (2.6250)	Acc@1 76.562 (76.415)	Acc@5 100.000 (99.394)
Epoch: [78][300/875]	Time 0.469 (0.459)	Data 0.007 (0.012)	Loss 2.5042 (2.4787)	Loss@kd 2.7037 (2.6331)	Acc@1 79.688 (76.339)	Acc@5 100.000 (99.372)
Epoch: [78][400/875]	Time 0.439 (0.457)	Data 0.006 (0.010)	Loss 2.4635 (2.4742)	Loss@kd 2.4398 (2.6220)	Acc@1 71.875 (76.157)	Acc@5 100.000 (99.373)
Epoch: [78][500/875]	Time 0.443 (0.457)	Data 0.006 (0.010)	Loss 2.3301 (2.4699)	Loss@kd 2.6272 (2.6194)	Acc@1 79.688 (76.213)	Acc@5 98.438 (99.370)
Epoch: [78][600/875]	Time 0.532 (0.456)	Data 0.007 (0.009)	Loss 2.4339 (2.4706)	Loss@kd 2.5431 (2.6215)	Acc@1 76.562 (76.235)	Acc@5 100.000 (99.363)
Epoch: [78][700/875]	Time 0.442 (0.455)	Data 0.007 (0.009)	Loss 2.4247 (2.4704)	Loss@kd 2.5579 (2.6191)	Acc@1 71.875 (76.186)	Acc@5 100.000 (99.365)
Epoch: [78][800/875]	Time 0.439 (0.453)	Data 0.007 (0.009)	Loss 2.4529 (2.4694)	Loss@kd 2.5886 (2.6179)	Acc@1 75.000 (76.200)	Acc@5 98.438 (99.370)
 * Acc@1 76.180 Acc@5 99.379
epoch 78, total time 395.20
Test: [0/750]	Time 0.773 (0.773)	Loss 0.5807 (0.5807)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.108 (0.113)	Loss 0.3148 (0.4547)	Acc@1 81.250 (86.077)	Acc@5 100.000 (95.668)
Test: [200/750]	Time 0.146 (0.108)	Loss 1.2090 (0.4447)	Acc@1 56.250 (85.230)	Acc@5 90.625 (96.782)
Test: [300/750]	Time 0.080 (0.107)	Loss 1.0501 (0.6712)	Acc@1 53.125 (76.173)	Acc@5 90.625 (95.307)
Test: [400/750]	Time 0.098 (0.104)	Loss 0.5720 (0.7692)	Acc@1 87.500 (72.288)	Acc@5 93.750 (94.888)
Test: [500/750]	Time 0.120 (0.105)	Loss 0.4528 (0.7504)	Acc@1 78.125 (73.491)	Acc@5 100.000 (94.517)
Test: [600/750]	Time 0.088 (0.105)	Loss 0.6917 (0.7544)	Acc@1 71.875 (73.617)	Acc@5 96.875 (94.473)
Test: [700/750]	Time 0.102 (0.105)	Loss 1.1656 (0.7615)	Acc@1 56.250 (73.150)	Acc@5 84.375 (94.642)
 * Acc@1 72.900 Acc@5 94.537
==> training...
Epoch: [79][0/875]	Time 1.936 (1.936)	Data 1.408 (1.408)	Loss 2.4533 (2.4533)	Loss@kd 2.6181 (2.6181)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [79][100/875]	Time 0.468 (0.464)	Data 0.007 (0.021)	Loss 2.8565 (2.4601)	Loss@kd 3.0488 (2.6387)	Acc@1 75.000 (77.351)	Acc@5 98.438 (99.350)
Epoch: [79][200/875]	Time 0.497 (0.456)	Data 0.007 (0.014)	Loss 2.1714 (2.4539)	Loss@kd 2.4616 (2.6226)	Acc@1 81.250 (77.052)	Acc@5 100.000 (99.355)
Epoch: [79][300/875]	Time 0.459 (0.454)	Data 0.007 (0.012)	Loss 2.5664 (2.4530)	Loss@kd 2.5819 (2.6193)	Acc@1 76.562 (77.056)	Acc@5 96.875 (99.325)
Epoch: [79][400/875]	Time 0.503 (0.454)	Data 0.007 (0.010)	Loss 2.4184 (2.4606)	Loss@kd 2.6326 (2.6254)	Acc@1 75.000 (77.026)	Acc@5 100.000 (99.330)
Epoch: [79][500/875]	Time 0.415 (0.455)	Data 0.007 (0.010)	Loss 2.3390 (2.4583)	Loss@kd 2.4537 (2.6187)	Acc@1 78.125 (76.793)	Acc@5 100.000 (99.370)
Epoch: [79][600/875]	Time 0.469 (0.455)	Data 0.007 (0.009)	Loss 2.5866 (2.4610)	Loss@kd 2.7110 (2.6203)	Acc@1 75.000 (76.698)	Acc@5 98.438 (99.384)
Epoch: [79][700/875]	Time 0.565 (0.455)	Data 0.007 (0.009)	Loss 2.2574 (2.4622)	Loss@kd 2.4719 (2.6220)	Acc@1 75.000 (76.701)	Acc@5 98.438 (99.396)
Epoch: [79][800/875]	Time 0.457 (0.455)	Data 0.007 (0.009)	Loss 2.3967 (2.4619)	Loss@kd 2.4771 (2.6205)	Acc@1 71.875 (76.625)	Acc@5 100.000 (99.368)
 * Acc@1 76.621 Acc@5 99.375
epoch 79, total time 398.16
Test: [0/750]	Time 0.781 (0.781)	Loss 0.5626 (0.5626)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.085 (0.111)	Loss 0.3744 (0.4794)	Acc@1 84.375 (85.860)	Acc@5 100.000 (94.802)
Test: [200/750]	Time 0.092 (0.108)	Loss 1.0521 (0.4622)	Acc@1 56.250 (85.261)	Acc@5 87.500 (96.346)
Test: [300/750]	Time 0.108 (0.105)	Loss 1.0474 (0.6573)	Acc@1 50.000 (76.879)	Acc@5 93.750 (95.546)
Test: [400/750]	Time 0.101 (0.105)	Loss 0.5377 (0.7660)	Acc@1 87.500 (72.062)	Acc@5 90.625 (94.935)
Test: [500/750]	Time 0.093 (0.104)	Loss 0.4371 (0.7488)	Acc@1 81.250 (73.253)	Acc@5 100.000 (94.561)
Test: [600/750]	Time 0.099 (0.104)	Loss 0.7871 (0.7574)	Acc@1 68.750 (73.315)	Acc@5 93.750 (94.447)
Test: [700/750]	Time 0.191 (0.103)	Loss 0.9939 (0.7618)	Acc@1 65.625 (73.021)	Acc@5 87.500 (94.593)
 * Acc@1 72.925 Acc@5 94.533
==> training...
Epoch: [80][0/875]	Time 1.725 (1.725)	Data 1.277 (1.277)	Loss 2.3047 (2.3047)	Loss@kd 2.6348 (2.6348)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [80][100/875]	Time 0.421 (0.446)	Data 0.007 (0.019)	Loss 2.2955 (2.4451)	Loss@kd 2.5025 (2.6130)	Acc@1 78.125 (76.996)	Acc@5 100.000 (99.536)
Epoch: [80][200/875]	Time 0.421 (0.439)	Data 0.007 (0.013)	Loss 2.3436 (2.4502)	Loss@kd 2.5736 (2.6114)	Acc@1 84.375 (76.998)	Acc@5 100.000 (99.518)
Epoch: [80][300/875]	Time 0.455 (0.443)	Data 0.008 (0.011)	Loss 2.5880 (2.4528)	Loss@kd 2.5479 (2.6083)	Acc@1 76.562 (76.890)	Acc@5 98.438 (99.434)
Epoch: [80][400/875]	Time 0.443 (0.445)	Data 0.007 (0.010)	Loss 2.6234 (2.4555)	Loss@kd 2.6933 (2.6148)	Acc@1 73.438 (77.022)	Acc@5 98.438 (99.435)
Epoch: [80][500/875]	Time 0.416 (0.447)	Data 0.007 (0.010)	Loss 2.4181 (2.4560)	Loss@kd 2.5420 (2.6168)	Acc@1 73.438 (76.962)	Acc@5 100.000 (99.432)
Epoch: [80][600/875]	Time 0.519 (0.448)	Data 0.007 (0.009)	Loss 2.3883 (2.4503)	Loss@kd 2.5113 (2.6110)	Acc@1 76.562 (77.036)	Acc@5 100.000 (99.431)
Epoch: [80][700/875]	Time 0.477 (0.449)	Data 0.007 (0.009)	Loss 2.3506 (2.4494)	Loss@kd 2.5349 (2.6106)	Acc@1 76.562 (77.039)	Acc@5 100.000 (99.434)
Epoch: [80][800/875]	Time 0.437 (0.449)	Data 0.007 (0.009)	Loss 2.3783 (2.4497)	Loss@kd 2.5006 (2.6081)	Acc@1 76.562 (77.023)	Acc@5 100.000 (99.446)
 * Acc@1 77.018 Acc@5 99.439
epoch 80, total time 393.70
Test: [0/750]	Time 0.850 (0.850)	Loss 0.5373 (0.5373)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.090 (0.112)	Loss 0.4366 (0.4773)	Acc@1 81.250 (85.365)	Acc@5 96.875 (95.204)
Test: [200/750]	Time 0.158 (0.106)	Loss 1.1817 (0.4856)	Acc@1 46.875 (83.909)	Acc@5 90.625 (96.455)
Test: [300/750]	Time 0.089 (0.105)	Loss 1.0189 (0.6807)	Acc@1 62.500 (75.208)	Acc@5 87.500 (95.723)
Test: [400/750]	Time 0.102 (0.104)	Loss 0.5531 (0.7699)	Acc@1 81.250 (71.431)	Acc@5 93.750 (95.059)
Test: [500/750]	Time 0.091 (0.103)	Loss 0.5070 (0.7662)	Acc@1 78.125 (72.143)	Acc@5 100.000 (94.592)
Test: [600/750]	Time 0.106 (0.103)	Loss 0.6711 (0.7721)	Acc@1 71.875 (72.312)	Acc@5 90.625 (94.405)
Test: [700/750]	Time 0.101 (0.103)	Loss 0.9456 (0.7670)	Acc@1 62.500 (72.365)	Acc@5 87.500 (94.588)
 * Acc@1 72.487 Acc@5 94.592
==> Saving...
==> training...
Epoch: [81][0/875]	Time 2.034 (2.034)	Data 1.411 (1.411)	Loss 2.2708 (2.2708)	Loss@kd 2.5549 (2.5549)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [81][100/875]	Time 0.475 (0.470)	Data 0.007 (0.021)	Loss 2.3607 (2.4125)	Loss@kd 2.6837 (2.5977)	Acc@1 84.375 (78.496)	Acc@5 100.000 (99.335)
Epoch: [81][200/875]	Time 0.449 (0.463)	Data 0.007 (0.014)	Loss 2.6621 (2.4505)	Loss@kd 2.6311 (2.6231)	Acc@1 71.875 (77.472)	Acc@5 100.000 (99.370)
Epoch: [81][300/875]	Time 0.420 (0.456)	Data 0.006 (0.012)	Loss 2.3336 (2.4468)	Loss@kd 2.4895 (2.6182)	Acc@1 79.688 (77.512)	Acc@5 100.000 (99.356)
Epoch: [81][400/875]	Time 0.395 (0.450)	Data 0.005 (0.010)	Loss 2.3308 (2.4417)	Loss@kd 2.5294 (2.6098)	Acc@1 81.250 (77.439)	Acc@5 100.000 (99.404)
Epoch: [81][500/875]	Time 0.508 (0.447)	Data 0.007 (0.010)	Loss 2.4924 (2.4374)	Loss@kd 2.5649 (2.6015)	Acc@1 76.562 (77.370)	Acc@5 98.438 (99.398)
Epoch: [81][600/875]	Time 0.467 (0.446)	Data 0.007 (0.009)	Loss 2.5448 (2.4441)	Loss@kd 2.6176 (2.6088)	Acc@1 71.875 (77.160)	Acc@5 100.000 (99.397)
Epoch: [81][700/875]	Time 0.430 (0.448)	Data 0.008 (0.009)	Loss 2.2917 (2.4457)	Loss@kd 2.5300 (2.6117)	Acc@1 82.812 (77.151)	Acc@5 100.000 (99.414)
Epoch: [81][800/875]	Time 0.440 (0.448)	Data 0.007 (0.009)	Loss 2.4662 (2.4480)	Loss@kd 2.6345 (2.6140)	Acc@1 75.000 (77.046)	Acc@5 96.875 (99.423)
 * Acc@1 77.052 Acc@5 99.421
epoch 81, total time 393.12
Test: [0/750]	Time 0.872 (0.872)	Loss 1.1136 (1.1136)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.100 (0.109)	Loss 0.3339 (0.7137)	Acc@1 84.375 (77.723)	Acc@5 100.000 (93.317)
Test: [200/750]	Time 0.095 (0.107)	Loss 1.2227 (0.5797)	Acc@1 43.750 (81.063)	Acc@5 93.750 (95.522)
Test: [300/750]	Time 0.107 (0.106)	Loss 1.1191 (0.7776)	Acc@1 46.875 (72.508)	Acc@5 90.625 (94.290)
Test: [400/750]	Time 0.097 (0.105)	Loss 0.5362 (0.8664)	Acc@1 87.500 (68.524)	Acc@5 93.750 (93.711)
Test: [500/750]	Time 0.103 (0.104)	Loss 0.3839 (0.8306)	Acc@1 87.500 (70.353)	Acc@5 100.000 (93.600)
Test: [600/750]	Time 0.105 (0.104)	Loss 0.7342 (0.8144)	Acc@1 68.750 (71.199)	Acc@5 93.750 (93.823)
Test: [700/750]	Time 0.098 (0.104)	Loss 0.9161 (0.8037)	Acc@1 68.750 (71.420)	Acc@5 87.500 (94.147)
 * Acc@1 71.604 Acc@5 94.137
==> training...
Epoch: [82][0/875]	Time 1.717 (1.717)	Data 1.266 (1.266)	Loss 2.5152 (2.5152)	Loss@kd 2.5524 (2.5524)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [82][100/875]	Time 0.441 (0.462)	Data 0.007 (0.019)	Loss 2.4743 (2.4927)	Loss@kd 2.6114 (2.6580)	Acc@1 75.000 (76.315)	Acc@5 100.000 (99.335)
Epoch: [82][200/875]	Time 0.446 (0.457)	Data 0.007 (0.013)	Loss 2.5506 (2.4596)	Loss@kd 2.7130 (2.6280)	Acc@1 73.438 (77.021)	Acc@5 100.000 (99.363)
Epoch: [82][300/875]	Time 0.429 (0.456)	Data 0.007 (0.011)	Loss 2.4157 (2.4520)	Loss@kd 2.4911 (2.6163)	Acc@1 70.312 (77.009)	Acc@5 98.438 (99.377)
Epoch: [82][400/875]	Time 0.506 (0.456)	Data 0.007 (0.010)	Loss 2.7039 (2.4442)	Loss@kd 2.8368 (2.6065)	Acc@1 70.312 (76.898)	Acc@5 98.438 (99.384)
Epoch: [82][500/875]	Time 0.451 (0.456)	Data 0.007 (0.009)	Loss 2.4350 (2.4419)	Loss@kd 2.6258 (2.6053)	Acc@1 75.000 (77.015)	Acc@5 100.000 (99.386)
Epoch: [82][600/875]	Time 0.432 (0.454)	Data 0.007 (0.009)	Loss 2.2174 (2.4417)	Loss@kd 2.4927 (2.6036)	Acc@1 81.250 (77.051)	Acc@5 100.000 (99.384)
Epoch: [82][700/875]	Time 0.422 (0.450)	Data 0.007 (0.009)	Loss 2.6859 (2.4425)	Loss@kd 2.5763 (2.6020)	Acc@1 67.188 (76.970)	Acc@5 100.000 (99.405)
Epoch: [82][800/875]	Time 0.390 (0.448)	Data 0.006 (0.008)	Loss 2.6455 (2.4383)	Loss@kd 2.7443 (2.6011)	Acc@1 73.438 (77.097)	Acc@5 100.000 (99.417)
 * Acc@1 77.146 Acc@5 99.436
epoch 82, total time 391.14
Test: [0/750]	Time 0.786 (0.786)	Loss 0.5228 (0.5228)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.172 (0.110)	Loss 0.4552 (0.4282)	Acc@1 78.125 (86.943)	Acc@5 100.000 (95.142)
Test: [200/750]	Time 0.094 (0.106)	Loss 1.0863 (0.4567)	Acc@1 59.375 (85.059)	Acc@5 90.625 (96.377)
Test: [300/750]	Time 0.102 (0.105)	Loss 1.2153 (0.6722)	Acc@1 43.750 (76.267)	Acc@5 90.625 (95.494)
Test: [400/750]	Time 0.094 (0.105)	Loss 0.4688 (0.7895)	Acc@1 87.500 (71.478)	Acc@5 93.750 (94.755)
Test: [500/750]	Time 0.083 (0.105)	Loss 0.3985 (0.7572)	Acc@1 84.375 (73.066)	Acc@5 100.000 (94.642)
Test: [600/750]	Time 0.102 (0.105)	Loss 0.7708 (0.7614)	Acc@1 71.875 (73.279)	Acc@5 90.625 (94.598)
Test: [700/750]	Time 0.100 (0.105)	Loss 0.7502 (0.7543)	Acc@1 65.625 (73.359)	Acc@5 90.625 (94.824)
 * Acc@1 73.679 Acc@5 94.925
saving the best model!
==> training...
Epoch: [83][0/875]	Time 1.831 (1.831)	Data 1.322 (1.322)	Loss 2.1303 (2.1303)	Loss@kd 2.3458 (2.3458)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [83][100/875]	Time 0.472 (0.462)	Data 0.007 (0.020)	Loss 2.2629 (2.4090)	Loss@kd 2.5334 (2.5850)	Acc@1 78.125 (77.491)	Acc@5 98.438 (99.381)
Epoch: [83][200/875]	Time 0.434 (0.451)	Data 0.007 (0.013)	Loss 2.5139 (2.4342)	Loss@kd 2.5273 (2.6169)	Acc@1 75.000 (77.565)	Acc@5 96.875 (99.464)
Epoch: [83][300/875]	Time 0.407 (0.449)	Data 0.007 (0.011)	Loss 2.1821 (2.4220)	Loss@kd 2.4563 (2.6019)	Acc@1 85.938 (77.767)	Acc@5 100.000 (99.398)
Epoch: [83][400/875]	Time 0.449 (0.446)	Data 0.005 (0.010)	Loss 2.8082 (2.4287)	Loss@kd 3.2158 (2.6015)	Acc@1 81.250 (77.622)	Acc@5 100.000 (99.396)
Epoch: [83][500/875]	Time 0.463 (0.445)	Data 0.008 (0.009)	Loss 2.4680 (2.4293)	Loss@kd 2.6674 (2.6021)	Acc@1 78.125 (77.654)	Acc@5 100.000 (99.382)
Epoch: [83][600/875]	Time 0.524 (0.445)	Data 0.007 (0.009)	Loss 2.4585 (2.4277)	Loss@kd 2.6360 (2.6008)	Acc@1 75.000 (77.652)	Acc@5 100.000 (99.399)
Epoch: [83][700/875]	Time 0.455 (0.446)	Data 0.007 (0.009)	Loss 2.2916 (2.4275)	Loss@kd 2.5040 (2.5990)	Acc@1 79.688 (77.697)	Acc@5 100.000 (99.385)
Epoch: [83][800/875]	Time 0.460 (0.446)	Data 0.007 (0.008)	Loss 2.5527 (2.4316)	Loss@kd 2.9017 (2.6032)	Acc@1 81.250 (77.589)	Acc@5 100.000 (99.380)
 * Acc@1 77.605 Acc@5 99.380
epoch 83, total time 389.65
Test: [0/750]	Time 0.833 (0.833)	Loss 0.4848 (0.4848)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.094 (0.108)	Loss 0.3651 (0.4860)	Acc@1 81.250 (85.922)	Acc@5 100.000 (95.266)
Test: [200/750]	Time 0.164 (0.103)	Loss 1.0765 (0.4527)	Acc@1 53.125 (85.728)	Acc@5 90.625 (96.642)
Test: [300/750]	Time 0.107 (0.103)	Loss 1.0649 (0.6572)	Acc@1 53.125 (76.993)	Acc@5 90.625 (95.702)
Test: [400/750]	Time 0.096 (0.102)	Loss 0.5500 (0.7664)	Acc@1 84.375 (72.421)	Acc@5 90.625 (95.044)
Test: [500/750]	Time 0.109 (0.103)	Loss 0.4395 (0.7520)	Acc@1 81.250 (73.515)	Acc@5 100.000 (94.704)
Test: [600/750]	Time 0.112 (0.102)	Loss 0.7144 (0.7634)	Acc@1 75.000 (73.482)	Acc@5 96.875 (94.592)
Test: [700/750]	Time 0.098 (0.102)	Loss 0.9314 (0.7653)	Acc@1 65.625 (73.190)	Acc@5 84.375 (94.784)
 * Acc@1 73.221 Acc@5 94.783
==> training...
Epoch: [84][0/875]	Time 1.791 (1.791)	Data 1.288 (1.288)	Loss 2.3330 (2.3330)	Loss@kd 2.4776 (2.4776)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [84][100/875]	Time 0.423 (0.439)	Data 0.009 (0.019)	Loss 2.7707 (2.4069)	Loss@kd 3.1984 (2.5829)	Acc@1 79.688 (77.785)	Acc@5 100.000 (99.489)
Epoch: [84][200/875]	Time 0.387 (0.442)	Data 0.005 (0.013)	Loss 3.8800 (2.4158)	Loss@kd 4.6431 (2.5965)	Acc@1 75.000 (78.063)	Acc@5 100.000 (99.479)
Epoch: [84][300/875]	Time 0.411 (0.444)	Data 0.007 (0.011)	Loss 2.3691 (2.4188)	Loss@kd 2.6307 (2.6014)	Acc@1 79.688 (78.026)	Acc@5 100.000 (99.455)
Epoch: [84][400/875]	Time 0.469 (0.446)	Data 0.008 (0.010)	Loss 2.3857 (2.4201)	Loss@kd 2.5258 (2.6041)	Acc@1 76.562 (78.028)	Acc@5 100.000 (99.505)
Epoch: [84][500/875]	Time 0.418 (0.447)	Data 0.007 (0.009)	Loss 2.1877 (2.4198)	Loss@kd 2.5014 (2.6007)	Acc@1 87.500 (77.904)	Acc@5 100.000 (99.448)
Epoch: [84][600/875]	Time 0.473 (0.448)	Data 0.007 (0.009)	Loss 2.5382 (2.4252)	Loss@kd 2.5778 (2.6053)	Acc@1 68.750 (77.831)	Acc@5 100.000 (99.444)
Epoch: [84][700/875]	Time 0.436 (0.449)	Data 0.008 (0.009)	Loss 2.6515 (2.4228)	Loss@kd 2.5815 (2.6014)	Acc@1 65.625 (77.887)	Acc@5 100.000 (99.456)
Epoch: [84][800/875]	Time 0.518 (0.449)	Data 0.007 (0.009)	Loss 2.4900 (2.4247)	Loss@kd 2.5865 (2.6012)	Acc@1 75.000 (77.817)	Acc@5 98.438 (99.448)
 * Acc@1 77.771 Acc@5 99.425
epoch 84, total time 393.45
Test: [0/750]	Time 0.858 (0.858)	Loss 1.0378 (1.0378)	Acc@1 65.625 (65.625)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.107 (0.111)	Loss 0.4493 (0.6837)	Acc@1 81.250 (79.889)	Acc@5 100.000 (94.524)
Test: [200/750]	Time 0.103 (0.107)	Loss 1.1298 (0.5883)	Acc@1 53.125 (81.095)	Acc@5 93.750 (96.082)
Test: [300/750]	Time 0.163 (0.105)	Loss 0.9324 (0.7467)	Acc@1 65.625 (73.650)	Acc@5 93.750 (95.338)
Test: [400/750]	Time 0.111 (0.104)	Loss 0.8169 (0.8210)	Acc@1 78.125 (70.238)	Acc@5 90.625 (95.020)
Test: [500/750]	Time 0.110 (0.103)	Loss 0.5699 (0.8286)	Acc@1 81.250 (70.659)	Acc@5 100.000 (94.343)
Test: [600/750]	Time 0.107 (0.103)	Loss 0.6874 (0.8260)	Acc@1 75.000 (71.131)	Acc@5 93.750 (94.234)
Test: [700/750]	Time 0.098 (0.103)	Loss 0.8952 (0.8084)	Acc@1 68.750 (71.550)	Acc@5 87.500 (94.419)
 * Acc@1 71.812 Acc@5 94.429
==> training...
Epoch: [85][0/875]	Time 1.835 (1.835)	Data 1.348 (1.348)	Loss 2.3269 (2.3269)	Loss@kd 2.7817 (2.7817)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [85][100/875]	Time 0.484 (0.467)	Data 0.006 (0.020)	Loss 2.2851 (2.3899)	Loss@kd 2.6148 (2.5654)	Acc@1 84.375 (77.877)	Acc@5 100.000 (99.505)
Epoch: [85][200/875]	Time 0.411 (0.455)	Data 0.007 (0.014)	Loss 2.4734 (2.3924)	Loss@kd 2.6924 (2.5757)	Acc@1 76.562 (78.102)	Acc@5 100.000 (99.541)
Epoch: [85][300/875]	Time 0.414 (0.446)	Data 0.007 (0.011)	Loss 2.3439 (2.3966)	Loss@kd 2.4578 (2.5726)	Acc@1 82.812 (77.985)	Acc@5 98.438 (99.476)
Epoch: [85][400/875]	Time 0.490 (0.442)	Data 0.007 (0.010)	Loss 2.4568 (2.4036)	Loss@kd 2.6409 (2.5821)	Acc@1 76.562 (77.969)	Acc@5 98.438 (99.521)
Epoch: [85][500/875]	Time 0.418 (0.445)	Data 0.007 (0.010)	Loss 2.5179 (2.4033)	Loss@kd 2.5084 (2.5804)	Acc@1 64.062 (77.872)	Acc@5 98.438 (99.470)
Epoch: [85][600/875]	Time 0.467 (0.445)	Data 0.008 (0.009)	Loss 2.5802 (2.4100)	Loss@kd 2.6595 (2.5865)	Acc@1 73.438 (77.764)	Acc@5 100.000 (99.464)
Epoch: [85][700/875]	Time 0.415 (0.446)	Data 0.004 (0.009)	Loss 2.2008 (2.4145)	Loss@kd 2.4367 (2.5908)	Acc@1 89.062 (77.733)	Acc@5 98.438 (99.456)
Epoch: [85][800/875]	Time 0.462 (0.447)	Data 0.007 (0.009)	Loss 2.1611 (2.4156)	Loss@kd 2.4131 (2.5924)	Acc@1 84.375 (77.780)	Acc@5 100.000 (99.462)
 * Acc@1 77.812 Acc@5 99.457
epoch 85, total time 391.30
Test: [0/750]	Time 0.765 (0.765)	Loss 0.4731 (0.4731)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.097 (0.105)	Loss 0.4680 (0.4631)	Acc@1 78.125 (86.324)	Acc@5 100.000 (95.606)
Test: [200/750]	Time 0.105 (0.104)	Loss 1.1197 (0.4705)	Acc@1 53.125 (84.670)	Acc@5 93.750 (96.626)
Test: [300/750]	Time 0.098 (0.101)	Loss 1.1532 (0.6612)	Acc@1 59.375 (76.651)	Acc@5 90.625 (95.889)
Test: [400/750]	Time 0.110 (0.102)	Loss 0.4998 (0.7539)	Acc@1 84.375 (73.005)	Acc@5 96.875 (95.262)
Test: [500/750]	Time 0.106 (0.101)	Loss 0.4776 (0.7372)	Acc@1 78.125 (74.083)	Acc@5 100.000 (94.854)
Test: [600/750]	Time 0.073 (0.102)	Loss 0.5550 (0.7469)	Acc@1 78.125 (73.939)	Acc@5 96.875 (94.774)
Test: [700/750]	Time 0.093 (0.101)	Loss 0.8636 (0.7439)	Acc@1 65.625 (73.877)	Acc@5 87.500 (94.985)
 * Acc@1 73.987 Acc@5 94.954
saving the best model!
==> training...
Epoch: [86][0/875]	Time 1.814 (1.814)	Data 1.364 (1.364)	Loss 2.3537 (2.3537)	Loss@kd 2.6463 (2.6463)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [86][100/875]	Time 0.469 (0.468)	Data 0.006 (0.020)	Loss 2.6756 (2.4329)	Loss@kd 2.6846 (2.6039)	Acc@1 67.188 (78.048)	Acc@5 100.000 (99.273)
Epoch: [86][200/875]	Time 0.455 (0.461)	Data 0.007 (0.014)	Loss 2.4541 (2.4247)	Loss@kd 2.5415 (2.6088)	Acc@1 75.000 (78.444)	Acc@5 100.000 (99.347)
Epoch: [86][300/875]	Time 0.433 (0.459)	Data 0.008 (0.011)	Loss 2.3697 (2.4181)	Loss@kd 2.5786 (2.6026)	Acc@1 81.250 (78.468)	Acc@5 100.000 (99.393)
Epoch: [86][400/875]	Time 0.531 (0.458)	Data 0.007 (0.010)	Loss 2.2635 (2.4126)	Loss@kd 2.5252 (2.5941)	Acc@1 85.938 (78.425)	Acc@5 98.438 (99.392)
Epoch: [86][500/875]	Time 0.424 (0.455)	Data 0.007 (0.010)	Loss 2.3207 (2.4137)	Loss@kd 2.5405 (2.5973)	Acc@1 78.125 (78.309)	Acc@5 100.000 (99.429)
Epoch: [86][600/875]	Time 0.425 (0.451)	Data 0.007 (0.009)	Loss 2.8338 (2.4128)	Loss@kd 2.6166 (2.5929)	Acc@1 67.188 (78.206)	Acc@5 96.875 (99.444)
Epoch: [86][700/875]	Time 0.471 (0.448)	Data 0.007 (0.009)	Loss 2.5265 (2.4109)	Loss@kd 2.5697 (2.5910)	Acc@1 70.312 (78.223)	Acc@5 100.000 (99.458)
Epoch: [86][800/875]	Time 0.404 (0.449)	Data 0.005 (0.009)	Loss 2.4925 (2.4131)	Loss@kd 2.5185 (2.5912)	Acc@1 71.875 (78.029)	Acc@5 100.000 (99.452)
 * Acc@1 78.082 Acc@5 99.452
epoch 86, total time 393.07
Test: [0/750]	Time 0.873 (0.873)	Loss 0.6048 (0.6048)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.169 (0.114)	Loss 0.4433 (0.5103)	Acc@1 78.125 (85.179)	Acc@5 100.000 (94.802)
Test: [200/750]	Time 0.095 (0.112)	Loss 1.0530 (0.4768)	Acc@1 53.125 (84.733)	Acc@5 93.750 (96.502)
Test: [300/750]	Time 0.098 (0.110)	Loss 1.2297 (0.6722)	Acc@1 43.750 (76.537)	Acc@5 90.625 (95.660)
Test: [400/750]	Time 0.083 (0.109)	Loss 0.4919 (0.7857)	Acc@1 84.375 (71.852)	Acc@5 96.875 (95.028)
Test: [500/750]	Time 0.101 (0.108)	Loss 0.5384 (0.7678)	Acc@1 81.250 (72.960)	Acc@5 100.000 (94.829)
Test: [600/750]	Time 0.094 (0.108)	Loss 0.6397 (0.7770)	Acc@1 78.125 (72.925)	Acc@5 93.750 (94.681)
Test: [700/750]	Time 0.095 (0.107)	Loss 0.9884 (0.7724)	Acc@1 62.500 (72.829)	Acc@5 87.500 (94.842)
 * Acc@1 72.637 Acc@5 94.762
==> training...
Epoch: [87][0/875]	Time 1.834 (1.834)	Data 1.337 (1.337)	Loss 2.2032 (2.2032)	Loss@kd 2.5381 (2.5381)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [87][100/875]	Time 0.493 (0.468)	Data 0.007 (0.020)	Loss 2.4738 (2.3904)	Loss@kd 2.7262 (2.5733)	Acc@1 78.125 (78.527)	Acc@5 100.000 (99.397)
Epoch: [87][200/875]	Time 0.459 (0.461)	Data 0.005 (0.014)	Loss 2.3695 (2.3821)	Loss@kd 2.6637 (2.5584)	Acc@1 84.375 (78.172)	Acc@5 98.438 (99.425)
Epoch: [87][300/875]	Time 0.446 (0.457)	Data 0.008 (0.011)	Loss 2.5650 (2.3861)	Loss@kd 2.5053 (2.5664)	Acc@1 76.562 (78.130)	Acc@5 100.000 (99.403)
Epoch: [87][400/875]	Time 0.471 (0.456)	Data 0.007 (0.010)	Loss 2.9142 (2.3961)	Loss@kd 3.2108 (2.5809)	Acc@1 75.000 (78.121)	Acc@5 100.000 (99.419)
Epoch: [87][500/875]	Time 0.446 (0.456)	Data 0.007 (0.010)	Loss 2.6259 (2.3964)	Loss@kd 2.5654 (2.5775)	Acc@1 71.875 (78.081)	Acc@5 100.000 (99.442)
Epoch: [87][600/875]	Time 0.482 (0.455)	Data 0.007 (0.009)	Loss 2.5166 (2.3991)	Loss@kd 2.5515 (2.5786)	Acc@1 68.750 (77.956)	Acc@5 98.438 (99.444)
Epoch: [87][700/875]	Time 0.483 (0.455)	Data 0.007 (0.009)	Loss 2.2951 (2.4019)	Loss@kd 2.5792 (2.5835)	Acc@1 75.000 (77.944)	Acc@5 100.000 (99.441)
Epoch: [87][800/875]	Time 0.408 (0.453)	Data 0.006 (0.009)	Loss 2.3055 (2.4076)	Loss@kd 2.5947 (2.5938)	Acc@1 87.500 (78.018)	Acc@5 100.000 (99.462)
 * Acc@1 78.046 Acc@5 99.450
epoch 87, total time 394.77
Test: [0/750]	Time 0.793 (0.793)	Loss 0.5931 (0.5931)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.106 (0.113)	Loss 0.4452 (0.4926)	Acc@1 78.125 (85.458)	Acc@5 100.000 (95.390)
Test: [200/750]	Time 0.168 (0.107)	Loss 1.1676 (0.5015)	Acc@1 43.750 (83.691)	Acc@5 93.750 (96.455)
Test: [300/750]	Time 0.076 (0.105)	Loss 1.1627 (0.6890)	Acc@1 50.000 (75.779)	Acc@5 93.750 (95.411)
Test: [400/750]	Time 0.105 (0.104)	Loss 0.5439 (0.7781)	Acc@1 84.375 (71.945)	Acc@5 93.750 (95.005)
Test: [500/750]	Time 0.092 (0.103)	Loss 0.4719 (0.7613)	Acc@1 78.125 (73.110)	Acc@5 100.000 (94.698)
Test: [600/750]	Time 0.104 (0.102)	Loss 0.7065 (0.7607)	Acc@1 75.000 (73.419)	Acc@5 90.625 (94.681)
Test: [700/750]	Time 0.092 (0.102)	Loss 0.9957 (0.7570)	Acc@1 65.625 (73.516)	Acc@5 84.375 (94.762)
 * Acc@1 73.667 Acc@5 94.708
==> training...
Epoch: [88][0/875]	Time 1.972 (1.972)	Data 1.366 (1.366)	Loss 2.2764 (2.2764)	Loss@kd 2.5602 (2.5602)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [88][100/875]	Time 0.423 (0.469)	Data 0.007 (0.020)	Loss 2.6655 (2.4454)	Loss@kd 3.0679 (2.6112)	Acc@1 82.812 (76.918)	Acc@5 100.000 (99.366)
Epoch: [88][200/875]	Time 0.464 (0.462)	Data 0.007 (0.014)	Loss 2.8485 (2.4228)	Loss@kd 3.2562 (2.5945)	Acc@1 81.250 (77.791)	Acc@5 100.000 (99.401)
Epoch: [88][300/875]	Time 0.483 (0.460)	Data 0.007 (0.011)	Loss 2.2998 (2.4137)	Loss@kd 2.5619 (2.5934)	Acc@1 78.125 (78.146)	Acc@5 100.000 (99.403)
Epoch: [88][400/875]	Time 0.467 (0.458)	Data 0.007 (0.010)	Loss 2.2672 (2.4079)	Loss@kd 2.5442 (2.5918)	Acc@1 78.125 (78.199)	Acc@5 98.438 (99.388)
Epoch: [88][500/875]	Time 0.434 (0.458)	Data 0.008 (0.010)	Loss 2.3013 (2.4076)	Loss@kd 2.5621 (2.5931)	Acc@1 82.812 (78.147)	Acc@5 100.000 (99.420)
Epoch: [88][600/875]	Time 0.420 (0.457)	Data 0.007 (0.009)	Loss 2.4127 (2.4082)	Loss@kd 2.6417 (2.5930)	Acc@1 76.562 (78.107)	Acc@5 100.000 (99.441)
Epoch: [88][700/875]	Time 0.473 (0.457)	Data 0.007 (0.009)	Loss 2.4004 (2.4048)	Loss@kd 2.6257 (2.5920)	Acc@1 79.688 (78.210)	Acc@5 100.000 (99.434)
Epoch: [88][800/875]	Time 0.533 (0.457)	Data 0.007 (0.009)	Loss 2.3948 (2.4062)	Loss@kd 2.6764 (2.5912)	Acc@1 78.125 (78.146)	Acc@5 100.000 (99.411)
 * Acc@1 78.177 Acc@5 99.418
epoch 88, total time 400.09
Test: [0/750]	Time 0.790 (0.790)	Loss 0.5265 (0.5265)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.109 (0.112)	Loss 0.4433 (0.5108)	Acc@1 81.250 (85.798)	Acc@5 100.000 (95.111)
Test: [200/750]	Time 0.104 (0.106)	Loss 1.0258 (0.5101)	Acc@1 62.500 (84.017)	Acc@5 96.875 (96.471)
Test: [300/750]	Time 0.177 (0.104)	Loss 0.9474 (0.6856)	Acc@1 59.375 (76.225)	Acc@5 93.750 (95.671)
Test: [400/750]	Time 0.097 (0.103)	Loss 0.5432 (0.7779)	Acc@1 84.375 (72.187)	Acc@5 90.625 (95.168)
Test: [500/750]	Time 0.099 (0.103)	Loss 0.3922 (0.7669)	Acc@1 84.375 (73.160)	Acc@5 100.000 (94.798)
Test: [600/750]	Time 0.113 (0.102)	Loss 0.6100 (0.7651)	Acc@1 78.125 (73.466)	Acc@5 93.750 (94.774)
Test: [700/750]	Time 0.090 (0.101)	Loss 0.9550 (0.7594)	Acc@1 65.625 (73.582)	Acc@5 84.375 (94.909)
 * Acc@1 73.542 Acc@5 94.892
==> training...
Epoch: [89][0/875]	Time 1.841 (1.841)	Data 1.346 (1.346)	Loss 2.1805 (2.1805)	Loss@kd 2.5014 (2.5014)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [89][100/875]	Time 0.536 (0.447)	Data 0.007 (0.020)	Loss 2.4227 (2.4155)	Loss@kd 2.6926 (2.6180)	Acc@1 78.125 (78.373)	Acc@5 100.000 (99.428)
Epoch: [89][200/875]	Time 0.446 (0.441)	Data 0.007 (0.013)	Loss 2.3628 (2.4067)	Loss@kd 2.5950 (2.6058)	Acc@1 82.812 (78.584)	Acc@5 100.000 (99.495)
Epoch: [89][300/875]	Time 0.428 (0.442)	Data 0.007 (0.011)	Loss 2.3112 (2.4023)	Loss@kd 2.4786 (2.5961)	Acc@1 81.250 (78.509)	Acc@5 100.000 (99.491)
Epoch: [89][400/875]	Time 0.446 (0.445)	Data 0.005 (0.010)	Loss 2.1660 (2.3985)	Loss@kd 2.4237 (2.5922)	Acc@1 82.812 (78.530)	Acc@5 100.000 (99.493)
Epoch: [89][500/875]	Time 0.426 (0.447)	Data 0.007 (0.009)	Loss 2.3848 (2.4017)	Loss@kd 2.6926 (2.5933)	Acc@1 79.688 (78.418)	Acc@5 100.000 (99.482)
Epoch: [89][600/875]	Time 0.422 (0.448)	Data 0.007 (0.009)	Loss 2.2202 (2.4038)	Loss@kd 2.6775 (2.5986)	Acc@1 87.500 (78.450)	Acc@5 100.000 (99.514)
Epoch: [89][700/875]	Time 0.505 (0.450)	Data 0.007 (0.009)	Loss 2.3214 (2.4078)	Loss@kd 2.5180 (2.6001)	Acc@1 79.688 (78.297)	Acc@5 100.000 (99.505)
Epoch: [89][800/875]	Time 0.452 (0.450)	Data 0.007 (0.009)	Loss 2.2923 (2.4059)	Loss@kd 2.4051 (2.5954)	Acc@1 79.688 (78.301)	Acc@5 98.438 (99.493)
 * Acc@1 78.287 Acc@5 99.504
epoch 89, total time 394.17
Test: [0/750]	Time 0.872 (0.872)	Loss 0.7296 (0.7296)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.096 (0.107)	Loss 0.3321 (0.5841)	Acc@1 87.500 (82.921)	Acc@5 100.000 (94.988)
Test: [200/750]	Time 0.118 (0.106)	Loss 1.3701 (0.5099)	Acc@1 53.125 (84.033)	Acc@5 87.500 (96.269)
Test: [300/750]	Time 0.093 (0.103)	Loss 1.1396 (0.7286)	Acc@1 50.000 (74.720)	Acc@5 87.500 (94.934)
Test: [400/750]	Time 0.091 (0.103)	Loss 0.5661 (0.8188)	Acc@1 87.500 (70.893)	Acc@5 90.625 (94.334)
Test: [500/750]	Time 0.090 (0.102)	Loss 0.4133 (0.7980)	Acc@1 81.250 (72.056)	Acc@5 100.000 (94.112)
Test: [600/750]	Time 0.071 (0.102)	Loss 0.7261 (0.7986)	Acc@1 71.875 (72.312)	Acc@5 90.625 (94.182)
Test: [700/750]	Time 0.110 (0.101)	Loss 0.8900 (0.7937)	Acc@1 65.625 (72.254)	Acc@5 90.625 (94.512)
 * Acc@1 72.412 Acc@5 94.550
==> training...
Epoch: [90][0/875]	Time 1.855 (1.855)	Data 1.383 (1.383)	Loss 2.3732 (2.3732)	Loss@kd 2.5298 (2.5298)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [90][100/875]	Time 0.439 (0.455)	Data 0.007 (0.020)	Loss 2.4500 (2.3832)	Loss@kd 2.5781 (2.5746)	Acc@1 73.438 (78.883)	Acc@5 100.000 (99.474)
Epoch: [90][200/875]	Time 0.455 (0.451)	Data 0.007 (0.014)	Loss 2.2626 (2.3979)	Loss@kd 2.4456 (2.5904)	Acc@1 79.688 (78.521)	Acc@5 100.000 (99.565)
Epoch: [90][300/875]	Time 0.439 (0.446)	Data 0.007 (0.011)	Loss 2.3044 (2.3993)	Loss@kd 2.6465 (2.5912)	Acc@1 79.688 (78.592)	Acc@5 100.000 (99.538)
Epoch: [90][400/875]	Time 0.482 (0.440)	Data 0.007 (0.010)	Loss 2.2452 (2.4032)	Loss@kd 2.5599 (2.5945)	Acc@1 81.250 (78.429)	Acc@5 100.000 (99.552)
Epoch: [90][500/875]	Time 0.420 (0.436)	Data 0.007 (0.009)	Loss 2.3846 (2.4007)	Loss@kd 2.5558 (2.5901)	Acc@1 79.688 (78.331)	Acc@5 100.000 (99.523)
Epoch: [90][600/875]	Time 0.436 (0.436)	Data 0.004 (0.009)	Loss 2.2456 (2.3962)	Loss@kd 2.4495 (2.5882)	Acc@1 82.812 (78.424)	Acc@5 100.000 (99.529)
Epoch: [90][700/875]	Time 0.448 (0.437)	Data 0.007 (0.009)	Loss 2.5810 (2.3969)	Loss@kd 2.6866 (2.5876)	Acc@1 71.875 (78.326)	Acc@5 100.000 (99.525)
Epoch: [90][800/875]	Time 0.451 (0.438)	Data 0.007 (0.008)	Loss 2.1438 (2.4044)	Loss@kd 2.5259 (2.5983)	Acc@1 89.062 (78.439)	Acc@5 100.000 (99.503)
 * Acc@1 78.516 Acc@5 99.491
epoch 90, total time 383.92
Test: [0/750]	Time 0.809 (0.809)	Loss 1.6897 (1.6897)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.168 (0.110)	Loss 0.4317 (1.0215)	Acc@1 78.125 (71.163)	Acc@5 100.000 (90.594)
Test: [200/750]	Time 0.091 (0.107)	Loss 1.1447 (0.7434)	Acc@1 56.250 (77.565)	Acc@5 87.500 (94.201)
Test: [300/750]	Time 0.096 (0.105)	Loss 1.0874 (0.8640)	Acc@1 53.125 (71.449)	Acc@5 93.750 (93.895)
Test: [400/750]	Time 0.094 (0.105)	Loss 0.5564 (0.9289)	Acc@1 81.250 (68.166)	Acc@5 90.625 (93.415)
Test: [500/750]	Time 0.102 (0.104)	Loss 0.3781 (0.8746)	Acc@1 93.750 (70.390)	Acc@5 100.000 (93.619)
Test: [600/750]	Time 0.087 (0.104)	Loss 0.6600 (0.8551)	Acc@1 68.750 (71.079)	Acc@5 96.875 (93.859)
Test: [700/750]	Time 0.101 (0.103)	Loss 0.9667 (0.8381)	Acc@1 62.500 (71.371)	Acc@5 87.500 (94.174)
 * Acc@1 71.417 Acc@5 94.204
==> training...
Epoch: [91][0/875]	Time 1.830 (1.830)	Data 1.376 (1.376)	Loss 2.5658 (2.5658)	Loss@kd 2.6030 (2.6030)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [91][100/875]	Time 0.450 (0.459)	Data 0.008 (0.020)	Loss 2.2456 (2.3554)	Loss@kd 2.4014 (2.5718)	Acc@1 81.250 (79.564)	Acc@5 100.000 (99.613)
Epoch: [91][200/875]	Time 0.432 (0.450)	Data 0.005 (0.014)	Loss 2.3083 (2.3521)	Loss@kd 2.4820 (2.5660)	Acc@1 76.562 (79.532)	Acc@5 100.000 (99.596)
Epoch: [91][300/875]	Time 0.460 (0.450)	Data 0.007 (0.011)	Loss 2.3536 (2.3491)	Loss@kd 2.6580 (2.5699)	Acc@1 84.375 (79.786)	Acc@5 100.000 (99.611)
Epoch: [91][400/875]	Time 0.419 (0.451)	Data 0.007 (0.010)	Loss 2.4115 (2.3585)	Loss@kd 2.5347 (2.5749)	Acc@1 78.125 (79.485)	Acc@5 98.438 (99.614)
Epoch: [91][500/875]	Time 0.479 (0.451)	Data 0.007 (0.010)	Loss 2.5542 (2.3648)	Loss@kd 2.6193 (2.5809)	Acc@1 75.000 (79.407)	Acc@5 100.000 (99.604)
Epoch: [91][600/875]	Time 0.489 (0.452)	Data 0.007 (0.009)	Loss 2.3812 (2.3657)	Loss@kd 2.5583 (2.5834)	Acc@1 78.125 (79.399)	Acc@5 100.000 (99.602)
Epoch: [91][700/875]	Time 0.448 (0.447)	Data 0.007 (0.009)	Loss 2.3277 (2.3644)	Loss@kd 2.3776 (2.5821)	Acc@1 79.688 (79.471)	Acc@5 100.000 (99.592)
Epoch: [91][800/875]	Time 0.424 (0.445)	Data 0.008 (0.009)	Loss 2.4476 (2.3639)	Loss@kd 2.6036 (2.5795)	Acc@1 84.375 (79.401)	Acc@5 100.000 (99.575)
 * Acc@1 79.420 Acc@5 99.579
epoch 91, total time 388.89
Test: [0/750]	Time 0.918 (0.918)	Loss 0.4695 (0.4695)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.084 (0.112)	Loss 0.4602 (0.4675)	Acc@1 78.125 (86.231)	Acc@5 100.000 (95.514)
Test: [200/750]	Time 0.167 (0.107)	Loss 1.0740 (0.4792)	Acc@1 56.250 (84.515)	Acc@5 93.750 (96.549)
Test: [300/750]	Time 0.075 (0.105)	Loss 0.9270 (0.6627)	Acc@1 62.500 (76.609)	Acc@5 96.875 (95.681)
Test: [400/750]	Time 0.097 (0.104)	Loss 0.5806 (0.7444)	Acc@1 84.375 (73.091)	Acc@5 90.625 (95.293)
Test: [500/750]	Time 0.103 (0.103)	Loss 0.4108 (0.7288)	Acc@1 78.125 (74.233)	Acc@5 100.000 (94.998)
Test: [600/750]	Time 0.094 (0.102)	Loss 0.6936 (0.7391)	Acc@1 71.875 (74.147)	Acc@5 93.750 (94.889)
Test: [700/750]	Time 0.107 (0.102)	Loss 0.8970 (0.7352)	Acc@1 65.625 (74.108)	Acc@5 87.500 (95.034)
 * Acc@1 74.171 Acc@5 95.050
saving the best model!
==> training...
Epoch: [92][0/875]	Time 1.784 (1.784)	Data 1.280 (1.280)	Loss 2.4089 (2.4089)	Loss@kd 2.8275 (2.8275)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [92][100/875]	Time 0.402 (0.454)	Data 0.007 (0.019)	Loss 2.1457 (2.3691)	Loss@kd 2.4301 (2.5931)	Acc@1 85.938 (79.641)	Acc@5 100.000 (99.567)
Epoch: [92][200/875]	Time 0.409 (0.449)	Data 0.007 (0.013)	Loss 2.5889 (2.3607)	Loss@kd 2.5685 (2.5890)	Acc@1 67.188 (79.664)	Acc@5 98.438 (99.580)
Epoch: [92][300/875]	Time 0.458 (0.449)	Data 0.007 (0.011)	Loss 2.1968 (2.3557)	Loss@kd 2.4598 (2.5789)	Acc@1 81.250 (79.750)	Acc@5 98.438 (99.491)
Epoch: [92][400/875]	Time 0.448 (0.450)	Data 0.007 (0.010)	Loss 2.1268 (2.3571)	Loss@kd 2.4916 (2.5820)	Acc@1 89.062 (79.765)	Acc@5 98.438 (99.501)
Epoch: [92][500/875]	Time 0.419 (0.450)	Data 0.007 (0.009)	Loss 2.1588 (2.3552)	Loss@kd 2.4695 (2.5783)	Acc@1 85.938 (79.722)	Acc@5 100.000 (99.523)
Epoch: [92][600/875]	Time 0.464 (0.450)	Data 0.007 (0.009)	Loss 2.2364 (2.3511)	Loss@kd 2.5065 (2.5736)	Acc@1 81.250 (79.729)	Acc@5 100.000 (99.527)
Epoch: [92][700/875]	Time 0.421 (0.450)	Data 0.007 (0.009)	Loss 2.4504 (2.3539)	Loss@kd 2.4132 (2.5741)	Acc@1 75.000 (79.596)	Acc@5 98.438 (99.539)
Epoch: [92][800/875]	Time 0.555 (0.450)	Data 0.007 (0.008)	Loss 2.5146 (2.3583)	Loss@kd 2.4002 (2.5779)	Acc@1 73.438 (79.490)	Acc@5 96.875 (99.557)
 * Acc@1 79.532 Acc@5 99.555
epoch 92, total time 394.90
Test: [0/750]	Time 0.770 (0.770)	Loss 0.5389 (0.5389)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.107 (0.106)	Loss 0.4072 (0.5002)	Acc@1 84.375 (85.582)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.104 (0.101)	Loss 1.1169 (0.4832)	Acc@1 50.000 (84.717)	Acc@5 90.625 (96.486)
Test: [300/750]	Time 0.166 (0.099)	Loss 1.0346 (0.6801)	Acc@1 65.625 (76.121)	Acc@5 93.750 (95.473)
Test: [400/750]	Time 0.090 (0.099)	Loss 0.5699 (0.7734)	Acc@1 84.375 (72.039)	Acc@5 90.625 (94.989)
Test: [500/750]	Time 0.096 (0.098)	Loss 0.4085 (0.7547)	Acc@1 84.375 (73.347)	Acc@5 100.000 (94.804)
Test: [600/750]	Time 0.103 (0.098)	Loss 0.6651 (0.7552)	Acc@1 71.875 (73.627)	Acc@5 96.875 (94.780)
Test: [700/750]	Time 0.100 (0.098)	Loss 0.8890 (0.7480)	Acc@1 65.625 (73.747)	Acc@5 87.500 (94.958)
 * Acc@1 73.821 Acc@5 94.967
==> training...
Epoch: [93][0/875]	Time 1.786 (1.786)	Data 1.345 (1.345)	Loss 2.3593 (2.3593)	Loss@kd 2.6663 (2.6663)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [93][100/875]	Time 0.545 (0.447)	Data 0.007 (0.020)	Loss 2.5117 (2.3384)	Loss@kd 2.5413 (2.5713)	Acc@1 75.000 (80.399)	Acc@5 100.000 (99.644)
Epoch: [93][200/875]	Time 0.418 (0.448)	Data 0.007 (0.013)	Loss 2.2584 (2.3616)	Loss@kd 2.4890 (2.5855)	Acc@1 81.250 (79.742)	Acc@5 100.000 (99.604)
Epoch: [93][300/875]	Time 0.458 (0.448)	Data 0.007 (0.011)	Loss 2.5368 (2.3663)	Loss@kd 2.7331 (2.5868)	Acc@1 75.000 (79.589)	Acc@5 100.000 (99.595)
Epoch: [93][400/875]	Time 0.423 (0.449)	Data 0.005 (0.010)	Loss 2.1747 (2.3660)	Loss@kd 2.5153 (2.5862)	Acc@1 89.062 (79.539)	Acc@5 98.438 (99.575)
Epoch: [93][500/875]	Time 0.402 (0.449)	Data 0.006 (0.009)	Loss 2.1558 (2.3670)	Loss@kd 2.4141 (2.5866)	Acc@1 85.938 (79.522)	Acc@5 100.000 (99.566)
Epoch: [93][600/875]	Time 0.447 (0.449)	Data 0.007 (0.009)	Loss 2.1311 (2.3629)	Loss@kd 2.4279 (2.5808)	Acc@1 82.812 (79.500)	Acc@5 98.438 (99.566)
Epoch: [93][700/875]	Time 0.447 (0.449)	Data 0.007 (0.009)	Loss 2.4452 (2.3631)	Loss@kd 2.4861 (2.5775)	Acc@1 79.688 (79.427)	Acc@5 98.438 (99.541)
Epoch: [93][800/875]	Time 0.428 (0.449)	Data 0.007 (0.008)	Loss 2.1011 (2.3592)	Loss@kd 2.4481 (2.5762)	Acc@1 89.062 (79.606)	Acc@5 100.000 (99.544)
 * Acc@1 79.602 Acc@5 99.554
epoch 93, total time 393.17
Test: [0/750]	Time 0.767 (0.767)	Loss 0.4685 (0.4685)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.082 (0.106)	Loss 0.3983 (0.5043)	Acc@1 78.125 (85.241)	Acc@5 100.000 (95.606)
Test: [200/750]	Time 0.101 (0.107)	Loss 1.1981 (0.4913)	Acc@1 50.000 (84.204)	Acc@5 87.500 (96.517)
Test: [300/750]	Time 0.120 (0.105)	Loss 0.9487 (0.6943)	Acc@1 62.500 (75.405)	Acc@5 93.750 (95.525)
Test: [400/750]	Time 0.085 (0.105)	Loss 0.5872 (0.7717)	Acc@1 84.375 (72.272)	Acc@5 90.625 (95.161)
Test: [500/750]	Time 0.073 (0.105)	Loss 0.4642 (0.7660)	Acc@1 78.125 (73.054)	Acc@5 100.000 (94.842)
Test: [600/750]	Time 0.101 (0.104)	Loss 0.6138 (0.7748)	Acc@1 78.125 (73.170)	Acc@5 93.750 (94.707)
Test: [700/750]	Time 0.095 (0.104)	Loss 0.8708 (0.7631)	Acc@1 71.875 (73.444)	Acc@5 87.500 (94.945)
 * Acc@1 73.688 Acc@5 94.933
==> training...
Epoch: [94][0/875]	Time 1.859 (1.859)	Data 1.402 (1.402)	Loss 2.2250 (2.2250)	Loss@kd 2.5612 (2.5612)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [94][100/875]	Time 0.465 (0.467)	Data 0.007 (0.021)	Loss 2.3366 (2.3505)	Loss@kd 2.5359 (2.5791)	Acc@1 82.812 (79.425)	Acc@5 95.312 (99.443)
Epoch: [94][200/875]	Time 0.474 (0.453)	Data 0.007 (0.014)	Loss 2.1733 (2.3486)	Loss@kd 2.4513 (2.5798)	Acc@1 85.938 (79.921)	Acc@5 100.000 (99.487)
Epoch: [94][300/875]	Time 0.407 (0.447)	Data 0.006 (0.011)	Loss 2.6098 (2.3548)	Loss@kd 2.8899 (2.5786)	Acc@1 73.438 (79.521)	Acc@5 100.000 (99.507)
Epoch: [94][400/875]	Time 0.538 (0.442)	Data 0.007 (0.010)	Loss 2.1074 (2.3438)	Loss@kd 2.4175 (2.5672)	Acc@1 82.812 (79.617)	Acc@5 100.000 (99.544)
Epoch: [94][500/875]	Time 0.448 (0.443)	Data 0.007 (0.009)	Loss 2.3813 (2.3424)	Loss@kd 2.6633 (2.5668)	Acc@1 79.688 (79.706)	Acc@5 100.000 (99.566)
Epoch: [94][600/875]	Time 0.457 (0.444)	Data 0.007 (0.009)	Loss 2.3788 (2.3458)	Loss@kd 2.5994 (2.5702)	Acc@1 78.125 (79.737)	Acc@5 100.000 (99.587)
Epoch: [94][700/875]	Time 0.455 (0.444)	Data 0.006 (0.009)	Loss 2.3178 (2.3467)	Loss@kd 2.5156 (2.5685)	Acc@1 76.562 (79.708)	Acc@5 100.000 (99.590)
Epoch: [94][800/875]	Time 0.436 (0.444)	Data 0.007 (0.008)	Loss 3.4050 (2.3506)	Loss@kd 3.9938 (2.5722)	Acc@1 79.688 (79.635)	Acc@5 100.000 (99.583)
 * Acc@1 79.629 Acc@5 99.589
epoch 94, total time 388.46
Test: [0/750]	Time 0.831 (0.831)	Loss 0.5017 (0.5017)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.167 (0.111)	Loss 0.3896 (0.4800)	Acc@1 81.250 (86.231)	Acc@5 100.000 (95.730)
Test: [200/750]	Time 0.112 (0.106)	Loss 1.1764 (0.4672)	Acc@1 53.125 (85.230)	Acc@5 87.500 (96.673)
Test: [300/750]	Time 0.112 (0.104)	Loss 1.0081 (0.6769)	Acc@1 65.625 (76.391)	Acc@5 93.750 (95.525)
Test: [400/750]	Time 0.093 (0.103)	Loss 0.6188 (0.7731)	Acc@1 84.375 (72.608)	Acc@5 90.625 (94.981)
Test: [500/750]	Time 0.097 (0.103)	Loss 0.4469 (0.7680)	Acc@1 81.250 (73.123)	Acc@5 100.000 (94.673)
Test: [600/750]	Time 0.096 (0.102)	Loss 0.6627 (0.7779)	Acc@1 75.000 (73.185)	Acc@5 96.875 (94.639)
Test: [700/750]	Time 0.099 (0.102)	Loss 0.8699 (0.7689)	Acc@1 68.750 (73.355)	Acc@5 87.500 (94.869)
 * Acc@1 73.550 Acc@5 94.887
==> training...
Epoch: [95][0/875]	Time 1.861 (1.861)	Data 1.355 (1.355)	Loss 2.1417 (2.1417)	Loss@kd 2.4032 (2.4032)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [95][100/875]	Time 0.478 (0.460)	Data 0.007 (0.020)	Loss 2.3778 (2.3635)	Loss@kd 2.6549 (2.5939)	Acc@1 82.812 (79.734)	Acc@5 98.438 (99.536)
Epoch: [95][200/875]	Time 0.438 (0.451)	Data 0.007 (0.013)	Loss 2.3506 (2.3583)	Loss@kd 2.4492 (2.5781)	Acc@1 79.688 (79.493)	Acc@5 100.000 (99.565)
Epoch: [95][300/875]	Time 0.469 (0.449)	Data 0.006 (0.011)	Loss 2.6236 (2.3507)	Loss@kd 2.6512 (2.5674)	Acc@1 71.875 (79.599)	Acc@5 100.000 (99.559)
Epoch: [95][400/875]	Time 0.438 (0.448)	Data 0.007 (0.010)	Loss 2.1585 (2.3506)	Loss@kd 2.5589 (2.5694)	Acc@1 85.938 (79.691)	Acc@5 100.000 (99.595)
Epoch: [95][500/875]	Time 0.400 (0.445)	Data 0.007 (0.009)	Loss 2.4662 (2.3493)	Loss@kd 2.5148 (2.5701)	Acc@1 78.125 (79.759)	Acc@5 98.438 (99.598)
Epoch: [95][600/875]	Time 0.478 (0.442)	Data 0.007 (0.009)	Loss 2.2871 (2.3529)	Loss@kd 2.4147 (2.5716)	Acc@1 78.125 (79.708)	Acc@5 100.000 (99.589)
Epoch: [95][700/875]	Time 0.427 (0.439)	Data 0.007 (0.009)	Loss 2.6835 (2.3552)	Loss@kd 2.7753 (2.5763)	Acc@1 75.000 (79.754)	Acc@5 100.000 (99.581)
Epoch: [95][800/875]	Time 0.500 (0.440)	Data 0.006 (0.008)	Loss 2.5680 (2.3531)	Loss@kd 3.0135 (2.5748)	Acc@1 81.250 (79.783)	Acc@5 100.000 (99.583)
 * Acc@1 79.762 Acc@5 99.589
epoch 95, total time 385.85
Test: [0/750]	Time 0.885 (0.885)	Loss 0.4793 (0.4793)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.094 (0.111)	Loss 0.4029 (0.5136)	Acc@1 81.250 (85.303)	Acc@5 100.000 (95.297)
Test: [200/750]	Time 0.111 (0.108)	Loss 1.1311 (0.4944)	Acc@1 53.125 (84.282)	Acc@5 90.625 (96.455)
Test: [300/750]	Time 0.101 (0.105)	Loss 0.9815 (0.6835)	Acc@1 56.250 (76.204)	Acc@5 93.750 (95.494)
Test: [400/750]	Time 0.093 (0.104)	Loss 0.5178 (0.7633)	Acc@1 87.500 (72.662)	Acc@5 93.750 (95.161)
Test: [500/750]	Time 0.092 (0.103)	Loss 0.4175 (0.7420)	Acc@1 84.375 (73.877)	Acc@5 100.000 (94.867)
Test: [600/750]	Time 0.092 (0.103)	Loss 0.6214 (0.7471)	Acc@1 78.125 (74.038)	Acc@5 96.875 (94.842)
Test: [700/750]	Time 0.091 (0.103)	Loss 0.8703 (0.7391)	Acc@1 62.500 (74.193)	Acc@5 87.500 (95.052)
 * Acc@1 74.250 Acc@5 95.017
saving the best model!
==> training...
Epoch: [96][0/875]	Time 1.833 (1.833)	Data 1.368 (1.368)	Loss 2.2061 (2.2061)	Loss@kd 2.3194 (2.3194)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [96][100/875]	Time 0.414 (0.464)	Data 0.007 (0.020)	Loss 2.3417 (2.3514)	Loss@kd 2.6626 (2.5753)	Acc@1 84.375 (79.688)	Acc@5 100.000 (99.582)
Epoch: [96][200/875]	Time 0.414 (0.459)	Data 0.007 (0.014)	Loss 2.3893 (2.3549)	Loss@kd 2.7068 (2.5882)	Acc@1 81.250 (80.239)	Acc@5 98.438 (99.580)
Epoch: [96][300/875]	Time 0.423 (0.458)	Data 0.006 (0.012)	Loss 2.3166 (2.3519)	Loss@kd 2.5126 (2.5751)	Acc@1 79.688 (79.812)	Acc@5 98.438 (99.543)
Epoch: [96][400/875]	Time 0.547 (0.456)	Data 0.007 (0.010)	Loss 2.1945 (2.3474)	Loss@kd 2.4986 (2.5673)	Acc@1 82.812 (79.730)	Acc@5 100.000 (99.540)
Epoch: [96][500/875]	Time 0.469 (0.455)	Data 0.007 (0.010)	Loss 2.3518 (2.3522)	Loss@kd 2.5079 (2.5760)	Acc@1 78.125 (79.856)	Acc@5 98.438 (99.579)
Epoch: [96][600/875]	Time 0.498 (0.456)	Data 0.007 (0.009)	Loss 2.4613 (2.3523)	Loss@kd 2.6299 (2.5721)	Acc@1 76.562 (79.739)	Acc@5 100.000 (99.584)
Epoch: [96][700/875]	Time 0.428 (0.455)	Data 0.007 (0.009)	Loss 2.1352 (2.3486)	Loss@kd 2.4360 (2.5704)	Acc@1 84.375 (79.803)	Acc@5 100.000 (99.592)
Epoch: [96][800/875]	Time 0.394 (0.454)	Data 0.007 (0.009)	Loss 2.6750 (2.3455)	Loss@kd 2.9981 (2.5670)	Acc@1 78.125 (79.937)	Acc@5 100.000 (99.590)
 * Acc@1 79.954 Acc@5 99.582
epoch 96, total time 395.71
Test: [0/750]	Time 0.891 (0.891)	Loss 0.5265 (0.5265)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.164 (0.114)	Loss 0.4108 (0.5109)	Acc@1 84.375 (85.272)	Acc@5 100.000 (95.142)
Test: [200/750]	Time 0.092 (0.109)	Loss 1.1680 (0.4878)	Acc@1 53.125 (84.515)	Acc@5 90.625 (96.331)
Test: [300/750]	Time 0.105 (0.107)	Loss 0.9935 (0.6956)	Acc@1 56.250 (75.727)	Acc@5 93.750 (95.203)
Test: [400/750]	Time 0.106 (0.106)	Loss 0.5283 (0.7901)	Acc@1 87.500 (71.813)	Acc@5 90.625 (94.677)
Test: [500/750]	Time 0.113 (0.105)	Loss 0.3721 (0.7641)	Acc@1 90.625 (73.191)	Acc@5 100.000 (94.461)
Test: [600/750]	Time 0.125 (0.104)	Loss 0.6936 (0.7635)	Acc@1 71.875 (73.518)	Acc@5 90.625 (94.561)
Test: [700/750]	Time 0.106 (0.104)	Loss 0.8726 (0.7552)	Acc@1 65.625 (73.614)	Acc@5 93.750 (94.833)
 * Acc@1 73.683 Acc@5 94.821
==> training...
Epoch: [97][0/875]	Time 1.761 (1.761)	Data 1.283 (1.283)	Loss 2.4051 (2.4051)	Loss@kd 2.6148 (2.6148)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [97][100/875]	Time 0.425 (0.465)	Data 0.007 (0.019)	Loss 2.4837 (2.3445)	Loss@kd 2.8258 (2.5572)	Acc@1 79.688 (79.749)	Acc@5 100.000 (99.536)
Epoch: [97][200/875]	Time 0.451 (0.460)	Data 0.007 (0.013)	Loss 2.3046 (2.3458)	Loss@kd 2.6454 (2.5574)	Acc@1 84.375 (79.594)	Acc@5 100.000 (99.565)
Epoch: [97][300/875]	Time 0.418 (0.458)	Data 0.007 (0.011)	Loss 2.6843 (2.3587)	Loss@kd 2.8122 (2.5701)	Acc@1 75.000 (79.511)	Acc@5 100.000 (99.564)
Epoch: [97][400/875]	Time 0.456 (0.457)	Data 0.007 (0.010)	Loss 2.9201 (2.3585)	Loss@kd 3.3383 (2.5718)	Acc@1 79.688 (79.508)	Acc@5 100.000 (99.556)
Epoch: [97][500/875]	Time 0.484 (0.456)	Data 0.007 (0.009)	Loss 2.4388 (2.3577)	Loss@kd 2.7160 (2.5749)	Acc@1 81.250 (79.538)	Acc@5 100.000 (99.585)
Epoch: [97][600/875]	Time 0.519 (0.456)	Data 0.007 (0.009)	Loss 3.6803 (2.3618)	Loss@kd 4.2605 (2.5813)	Acc@1 68.750 (79.542)	Acc@5 100.000 (99.584)
Epoch: [97][700/875]	Time 0.466 (0.456)	Data 0.007 (0.009)	Loss 2.3477 (2.3560)	Loss@kd 2.6189 (2.5758)	Acc@1 84.375 (79.560)	Acc@5 100.000 (99.585)
Epoch: [97][800/875]	Time 0.461 (0.456)	Data 0.007 (0.008)	Loss 2.3106 (2.3574)	Loss@kd 2.5579 (2.5760)	Acc@1 82.812 (79.559)	Acc@5 100.000 (99.571)
 * Acc@1 79.586 Acc@5 99.561
epoch 97, total time 399.61
Test: [0/750]	Time 0.777 (0.777)	Loss 0.5025 (0.5025)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.109 (0.115)	Loss 0.3994 (0.5302)	Acc@1 81.250 (84.066)	Acc@5 100.000 (95.452)
Test: [200/750]	Time 0.153 (0.107)	Loss 1.0717 (0.5102)	Acc@1 56.250 (83.271)	Acc@5 93.750 (96.626)
Test: [300/750]	Time 0.094 (0.106)	Loss 0.8458 (0.6954)	Acc@1 65.625 (75.322)	Acc@5 96.875 (95.743)
Test: [400/750]	Time 0.082 (0.104)	Loss 0.4907 (0.7563)	Acc@1 87.500 (72.670)	Acc@5 90.625 (95.503)
Test: [500/750]	Time 0.091 (0.104)	Loss 0.4568 (0.7418)	Acc@1 81.250 (73.871)	Acc@5 100.000 (95.210)
Test: [600/750]	Time 0.107 (0.103)	Loss 0.6490 (0.7559)	Acc@1 75.000 (73.648)	Acc@5 96.875 (95.003)
Test: [700/750]	Time 0.097 (0.104)	Loss 1.0587 (0.7568)	Acc@1 62.500 (73.377)	Acc@5 87.500 (95.096)
 * Acc@1 73.346 Acc@5 95.025
==> training...
Epoch: [98][0/875]	Time 1.900 (1.900)	Data 1.298 (1.298)	Loss 2.2508 (2.2508)	Loss@kd 2.5159 (2.5159)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [98][100/875]	Time 0.416 (0.445)	Data 0.005 (0.020)	Loss 2.4006 (2.3422)	Loss@kd 2.5522 (2.5844)	Acc@1 78.125 (80.167)	Acc@5 100.000 (99.567)
Epoch: [98][200/875]	Time 0.411 (0.438)	Data 0.007 (0.013)	Loss 2.2131 (2.3546)	Loss@kd 2.4527 (2.5912)	Acc@1 81.250 (79.897)	Acc@5 98.438 (99.518)
Epoch: [98][300/875]	Time 0.484 (0.438)	Data 0.007 (0.011)	Loss 2.3336 (2.3530)	Loss@kd 2.5318 (2.5788)	Acc@1 84.375 (79.641)	Acc@5 100.000 (99.507)
Epoch: [98][400/875]	Time 0.449 (0.441)	Data 0.007 (0.010)	Loss 2.3314 (2.3478)	Loss@kd 2.6286 (2.5691)	Acc@1 81.250 (79.625)	Acc@5 98.438 (99.529)
Epoch: [98][500/875]	Time 0.428 (0.443)	Data 0.007 (0.010)	Loss 2.3941 (2.3511)	Loss@kd 2.6227 (2.5725)	Acc@1 79.688 (79.672)	Acc@5 100.000 (99.517)
Epoch: [98][600/875]	Time 0.428 (0.445)	Data 0.007 (0.009)	Loss 2.6486 (2.3541)	Loss@kd 2.8429 (2.5773)	Acc@1 79.688 (79.661)	Acc@5 100.000 (99.516)
Epoch: [98][700/875]	Time 0.445 (0.446)	Data 0.008 (0.009)	Loss 2.3573 (2.3550)	Loss@kd 2.4790 (2.5795)	Acc@1 71.875 (79.652)	Acc@5 100.000 (99.512)
Epoch: [98][800/875]	Time 0.422 (0.447)	Data 0.008 (0.009)	Loss 2.5225 (2.3516)	Loss@kd 2.8875 (2.5740)	Acc@1 79.688 (79.656)	Acc@5 100.000 (99.524)
 * Acc@1 79.704 Acc@5 99.523
epoch 98, total time 391.43
Test: [0/750]	Time 0.813 (0.813)	Loss 0.4352 (0.4352)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.109 (0.110)	Loss 0.3734 (0.4699)	Acc@1 81.250 (86.541)	Acc@5 100.000 (95.606)
Test: [200/750]	Time 0.084 (0.107)	Loss 1.0607 (0.4647)	Acc@1 62.500 (85.261)	Acc@5 93.750 (96.642)
Test: [300/750]	Time 0.093 (0.105)	Loss 0.9508 (0.6584)	Acc@1 65.625 (77.118)	Acc@5 96.875 (95.650)
Test: [400/750]	Time 0.079 (0.104)	Loss 0.5365 (0.7450)	Acc@1 84.375 (73.527)	Acc@5 93.750 (95.262)
Test: [500/750]	Time 0.103 (0.103)	Loss 0.4469 (0.7353)	Acc@1 81.250 (74.445)	Acc@5 100.000 (94.985)
Test: [600/750]	Time 0.123 (0.103)	Loss 0.6652 (0.7463)	Acc@1 68.750 (74.293)	Acc@5 93.750 (94.920)
Test: [700/750]	Time 0.177 (0.102)	Loss 0.9598 (0.7441)	Acc@1 65.625 (74.175)	Acc@5 87.500 (95.061)
 * Acc@1 74.171 Acc@5 95.017
==> training...
Epoch: [99][0/875]	Time 1.916 (1.916)	Data 1.359 (1.359)	Loss 2.5184 (2.5184)	Loss@kd 2.6029 (2.6029)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [99][100/875]	Time 0.434 (0.466)	Data 0.007 (0.020)	Loss 2.2282 (2.3513)	Loss@kd 2.4550 (2.5840)	Acc@1 81.250 (80.507)	Acc@5 100.000 (99.629)
Epoch: [99][200/875]	Time 0.432 (0.459)	Data 0.007 (0.014)	Loss 2.4386 (2.3551)	Loss@kd 2.4713 (2.5856)	Acc@1 71.875 (80.550)	Acc@5 98.438 (99.541)
Epoch: [99][300/875]	Time 0.418 (0.456)	Data 0.006 (0.011)	Loss 2.3538 (2.3612)	Loss@kd 2.5766 (2.5825)	Acc@1 70.312 (79.900)	Acc@5 100.000 (99.569)
Epoch: [99][400/875]	Time 0.424 (0.449)	Data 0.007 (0.010)	Loss 2.2461 (2.3574)	Loss@kd 2.5326 (2.5760)	Acc@1 79.688 (79.668)	Acc@5 100.000 (99.567)
Epoch: [99][500/875]	Time 0.416 (0.444)	Data 0.007 (0.010)	Loss 2.1419 (2.3585)	Loss@kd 2.5215 (2.5796)	Acc@1 87.500 (79.669)	Acc@5 100.000 (99.598)
Epoch: [99][600/875]	Time 0.495 (0.442)	Data 0.007 (0.009)	Loss 2.2491 (2.3495)	Loss@kd 2.4248 (2.5722)	Acc@1 71.875 (79.778)	Acc@5 98.438 (99.605)
Epoch: [99][700/875]	Time 0.424 (0.443)	Data 0.007 (0.009)	Loss 2.2562 (2.3453)	Loss@kd 2.5343 (2.5680)	Acc@1 82.812 (79.801)	Acc@5 100.000 (99.617)
Epoch: [99][800/875]	Time 0.456 (0.444)	Data 0.007 (0.009)	Loss 2.1762 (2.3504)	Loss@kd 2.4795 (2.5743)	Acc@1 84.375 (79.801)	Acc@5 100.000 (99.594)
 * Acc@1 79.730 Acc@5 99.591
epoch 99, total time 389.84
Test: [0/750]	Time 0.860 (0.860)	Loss 0.6019 (0.6019)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.096 (0.114)	Loss 0.3864 (0.5240)	Acc@1 78.125 (84.684)	Acc@5 96.875 (95.545)
Test: [200/750]	Time 0.173 (0.108)	Loss 1.0680 (0.4988)	Acc@1 56.250 (84.220)	Acc@5 90.625 (96.533)
Test: [300/750]	Time 0.105 (0.108)	Loss 0.9484 (0.6886)	Acc@1 59.375 (75.924)	Acc@5 90.625 (95.577)
Test: [400/750]	Time 0.098 (0.106)	Loss 0.4948 (0.7600)	Acc@1 87.500 (72.810)	Acc@5 93.750 (95.223)
Test: [500/750]	Time 0.092 (0.106)	Loss 0.4864 (0.7417)	Acc@1 84.375 (73.946)	Acc@5 100.000 (94.960)
Test: [600/750]	Time 0.092 (0.105)	Loss 0.6696 (0.7566)	Acc@1 75.000 (73.768)	Acc@5 90.625 (94.821)
Test: [700/750]	Time 0.123 (0.106)	Loss 1.0471 (0.7568)	Acc@1 59.375 (73.569)	Acc@5 84.375 (94.967)
 * Acc@1 73.592 Acc@5 94.925
==> training...
Epoch: [100][0/875]	Time 1.831 (1.831)	Data 1.226 (1.226)	Loss 2.4169 (2.4169)	Loss@kd 2.7716 (2.7716)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [100][100/875]	Time 0.409 (0.465)	Data 0.007 (0.019)	Loss 2.2410 (2.3451)	Loss@kd 2.4640 (2.5634)	Acc@1 82.812 (79.548)	Acc@5 100.000 (99.474)
Epoch: [100][200/875]	Time 0.471 (0.459)	Data 0.007 (0.013)	Loss 2.1900 (2.3427)	Loss@kd 2.5882 (2.5649)	Acc@1 90.625 (79.680)	Acc@5 100.000 (99.518)
Epoch: [100][300/875]	Time 0.404 (0.457)	Data 0.007 (0.011)	Loss 2.1346 (2.3428)	Loss@kd 2.5422 (2.5652)	Acc@1 85.938 (79.724)	Acc@5 100.000 (99.538)
Epoch: [100][400/875]	Time 0.437 (0.457)	Data 0.007 (0.010)	Loss 2.3375 (2.3426)	Loss@kd 2.4150 (2.5629)	Acc@1 75.000 (79.672)	Acc@5 100.000 (99.556)
Epoch: [100][500/875]	Time 0.424 (0.456)	Data 0.010 (0.009)	Loss 2.3307 (2.3399)	Loss@kd 2.4893 (2.5641)	Acc@1 75.000 (79.903)	Acc@5 100.000 (99.560)
Epoch: [100][600/875]	Time 0.465 (0.456)	Data 0.007 (0.009)	Loss 2.1863 (2.3416)	Loss@kd 2.4721 (2.5643)	Acc@1 79.688 (79.789)	Acc@5 100.000 (99.571)
Epoch: [100][700/875]	Time 0.427 (0.452)	Data 0.006 (0.009)	Loss 2.4187 (2.3420)	Loss@kd 2.4892 (2.5644)	Acc@1 76.562 (79.810)	Acc@5 100.000 (99.565)
Epoch: [100][800/875]	Time 0.461 (0.450)	Data 0.007 (0.008)	Loss 2.6538 (2.3495)	Loss@kd 2.9468 (2.5741)	Acc@1 76.562 (79.762)	Acc@5 96.875 (99.559)
 * Acc@1 79.777 Acc@5 99.557
epoch 100, total time 392.95
Test: [0/750]	Time 0.796 (0.796)	Loss 0.7732 (0.7732)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.120 (0.108)	Loss 0.3386 (0.5864)	Acc@1 81.250 (82.983)	Acc@5 100.000 (95.080)
Test: [200/750]	Time 0.093 (0.105)	Loss 1.0959 (0.5099)	Acc@1 53.125 (83.815)	Acc@5 90.625 (96.564)
Test: [300/750]	Time 0.105 (0.103)	Loss 0.9897 (0.6996)	Acc@1 59.375 (75.934)	Acc@5 93.750 (95.442)
Test: [400/750]	Time 0.116 (0.104)	Loss 0.5886 (0.8006)	Acc@1 84.375 (71.781)	Acc@5 90.625 (94.818)
Test: [500/750]	Time 0.099 (0.103)	Loss 0.3743 (0.7858)	Acc@1 87.500 (72.705)	Acc@5 100.000 (94.548)
Test: [600/750]	Time 0.094 (0.104)	Loss 0.6501 (0.7833)	Acc@1 75.000 (72.977)	Acc@5 96.875 (94.650)
Test: [700/750]	Time 0.184 (0.103)	Loss 0.9068 (0.7736)	Acc@1 68.750 (73.083)	Acc@5 87.500 (94.887)
 * Acc@1 73.229 Acc@5 94.892
==> training...
Epoch: [101][0/875]	Time 2.037 (2.037)	Data 1.554 (1.554)	Loss 2.4421 (2.4421)	Loss@kd 2.6203 (2.6203)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [101][100/875]	Time 0.412 (0.473)	Data 0.007 (0.022)	Loss 2.3721 (2.3359)	Loss@kd 2.4751 (2.5541)	Acc@1 73.438 (80.523)	Acc@5 100.000 (99.505)
Epoch: [101][200/875]	Time 0.444 (0.462)	Data 0.007 (0.014)	Loss 2.4449 (2.3383)	Loss@kd 2.5373 (2.5630)	Acc@1 78.125 (80.286)	Acc@5 100.000 (99.487)
Epoch: [101][300/875]	Time 0.434 (0.458)	Data 0.006 (0.012)	Loss 2.2246 (2.3388)	Loss@kd 2.5606 (2.5593)	Acc@1 87.500 (79.854)	Acc@5 98.438 (99.554)
Epoch: [101][400/875]	Time 0.452 (0.457)	Data 0.007 (0.011)	Loss 2.1693 (2.3381)	Loss@kd 2.3722 (2.5586)	Acc@1 81.250 (79.886)	Acc@5 100.000 (99.529)
Epoch: [101][500/875]	Time 0.442 (0.457)	Data 0.007 (0.010)	Loss 2.2828 (2.3387)	Loss@kd 2.5616 (2.5612)	Acc@1 78.125 (79.812)	Acc@5 100.000 (99.538)
Epoch: [101][600/875]	Time 0.515 (0.457)	Data 0.006 (0.009)	Loss 2.1854 (2.3409)	Loss@kd 2.5426 (2.5652)	Acc@1 87.500 (79.867)	Acc@5 100.000 (99.535)
Epoch: [101][700/875]	Time 0.442 (0.457)	Data 0.007 (0.009)	Loss 2.4030 (2.3467)	Loss@kd 2.6013 (2.5722)	Acc@1 75.000 (79.828)	Acc@5 100.000 (99.550)
Epoch: [101][800/875]	Time 0.433 (0.457)	Data 0.007 (0.009)	Loss 2.5093 (2.3485)	Loss@kd 3.0135 (2.5726)	Acc@1 87.500 (79.771)	Acc@5 100.000 (99.565)
 * Acc@1 79.811 Acc@5 99.582
epoch 101, total time 400.23
Test: [0/750]	Time 0.885 (0.885)	Loss 0.4913 (0.4913)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.110 (0.116)	Loss 0.4353 (0.5026)	Acc@1 81.250 (85.829)	Acc@5 100.000 (95.514)
Test: [200/750]	Time 0.180 (0.107)	Loss 1.1111 (0.4897)	Acc@1 56.250 (84.546)	Acc@5 90.625 (96.626)
Test: [300/750]	Time 0.099 (0.106)	Loss 0.9575 (0.6767)	Acc@1 59.375 (76.443)	Acc@5 96.875 (95.764)
Test: [400/750]	Time 0.073 (0.104)	Loss 0.6116 (0.7688)	Acc@1 84.375 (72.584)	Acc@5 90.625 (95.270)
Test: [500/750]	Time 0.101 (0.104)	Loss 0.3872 (0.7613)	Acc@1 84.375 (73.353)	Acc@5 100.000 (94.948)
Test: [600/750]	Time 0.098 (0.103)	Loss 0.6325 (0.7600)	Acc@1 75.000 (73.684)	Acc@5 96.875 (94.920)
Test: [700/750]	Time 0.096 (0.103)	Loss 0.9684 (0.7511)	Acc@1 62.500 (73.819)	Acc@5 87.500 (95.083)
 * Acc@1 73.850 Acc@5 95.037
==> training...
Epoch: [102][0/875]	Time 1.962 (1.962)	Data 1.416 (1.416)	Loss 2.4094 (2.4094)	Loss@kd 2.5921 (2.5921)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [102][100/875]	Time 0.380 (0.444)	Data 0.005 (0.021)	Loss 2.4657 (2.3227)	Loss@kd 2.5699 (2.5647)	Acc@1 76.562 (80.739)	Acc@5 98.438 (99.567)
Epoch: [102][200/875]	Time 0.446 (0.447)	Data 0.006 (0.014)	Loss 2.1689 (2.3294)	Loss@kd 2.5548 (2.5558)	Acc@1 89.062 (80.030)	Acc@5 100.000 (99.580)
Epoch: [102][300/875]	Time 0.465 (0.448)	Data 0.007 (0.012)	Loss 2.1224 (2.3349)	Loss@kd 2.5177 (2.5540)	Acc@1 89.062 (79.952)	Acc@5 100.000 (99.554)
Epoch: [102][400/875]	Time 0.419 (0.450)	Data 0.007 (0.010)	Loss 3.3576 (2.3352)	Loss@kd 4.0609 (2.5592)	Acc@1 82.812 (80.112)	Acc@5 100.000 (99.583)
Epoch: [102][500/875]	Time 0.434 (0.450)	Data 0.007 (0.010)	Loss 2.1504 (2.3326)	Loss@kd 2.5557 (2.5580)	Acc@1 87.500 (80.087)	Acc@5 100.000 (99.585)
Epoch: [102][600/875]	Time 0.431 (0.451)	Data 0.007 (0.009)	Loss 2.1051 (2.3346)	Loss@kd 2.4307 (2.5602)	Acc@1 87.500 (80.036)	Acc@5 100.000 (99.589)
Epoch: [102][700/875]	Time 0.434 (0.451)	Data 0.007 (0.009)	Loss 2.2684 (2.3417)	Loss@kd 2.4293 (2.5686)	Acc@1 79.688 (80.017)	Acc@5 100.000 (99.581)
Epoch: [102][800/875]	Time 0.482 (0.451)	Data 0.007 (0.009)	Loss 2.3867 (2.3439)	Loss@kd 2.7215 (2.5690)	Acc@1 81.250 (80.002)	Acc@5 100.000 (99.581)
 * Acc@1 79.977 Acc@5 99.589
epoch 102, total time 395.70
Test: [0/750]	Time 0.890 (0.890)	Loss 0.4340 (0.4340)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.109 (0.107)	Loss 0.4090 (0.5017)	Acc@1 81.250 (85.551)	Acc@5 96.875 (95.452)
Test: [200/750]	Time 0.086 (0.105)	Loss 1.1044 (0.4936)	Acc@1 56.250 (84.344)	Acc@5 93.750 (96.502)
Test: [300/750]	Time 0.189 (0.104)	Loss 0.8720 (0.6794)	Acc@1 59.375 (76.412)	Acc@5 96.875 (95.598)
Test: [400/750]	Time 0.098 (0.103)	Loss 0.4617 (0.7541)	Acc@1 87.500 (73.169)	Acc@5 90.625 (95.168)
Test: [500/750]	Time 0.086 (0.102)	Loss 0.4396 (0.7323)	Acc@1 81.250 (74.489)	Acc@5 100.000 (95.004)
Test: [600/750]	Time 0.099 (0.102)	Loss 0.6460 (0.7449)	Acc@1 78.125 (74.381)	Acc@5 96.875 (94.936)
Test: [700/750]	Time 0.101 (0.102)	Loss 1.0562 (0.7468)	Acc@1 56.250 (74.086)	Acc@5 81.250 (95.070)
 * Acc@1 73.892 Acc@5 95.017
==> training...
Epoch: [103][0/875]	Time 1.905 (1.905)	Data 1.356 (1.356)	Loss 2.3432 (2.3432)	Loss@kd 2.5804 (2.5804)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [103][100/875]	Time 0.538 (0.468)	Data 0.007 (0.020)	Loss 2.3195 (2.3385)	Loss@kd 2.5266 (2.5861)	Acc@1 82.812 (80.523)	Acc@5 98.438 (99.737)
Epoch: [103][200/875]	Time 0.438 (0.455)	Data 0.007 (0.014)	Loss 2.3625 (2.3423)	Loss@kd 2.4998 (2.5811)	Acc@1 78.125 (80.294)	Acc@5 100.000 (99.650)
Epoch: [103][300/875]	Time 0.420 (0.443)	Data 0.007 (0.011)	Loss 2.1161 (2.3389)	Loss@kd 2.3911 (2.5814)	Acc@1 85.938 (80.482)	Acc@5 98.438 (99.600)
Epoch: [103][400/875]	Time 0.440 (0.438)	Data 0.007 (0.010)	Loss 2.3916 (2.3340)	Loss@kd 2.6164 (2.5705)	Acc@1 78.125 (80.443)	Acc@5 96.875 (99.571)
Epoch: [103][500/875]	Time 0.470 (0.439)	Data 0.007 (0.009)	Loss 2.3914 (2.3396)	Loss@kd 2.6219 (2.5740)	Acc@1 79.688 (80.240)	Acc@5 100.000 (99.560)
Epoch: [103][600/875]	Time 0.397 (0.441)	Data 0.007 (0.009)	Loss 2.1018 (2.3415)	Loss@kd 2.3577 (2.5735)	Acc@1 82.812 (80.176)	Acc@5 100.000 (99.563)
Epoch: [103][700/875]	Time 0.433 (0.442)	Data 0.007 (0.009)	Loss 2.3586 (2.3409)	Loss@kd 2.4522 (2.5712)	Acc@1 75.000 (80.180)	Acc@5 100.000 (99.579)
Epoch: [103][800/875]	Time 0.465 (0.443)	Data 0.007 (0.008)	Loss 2.2823 (2.3411)	Loss@kd 2.5981 (2.5715)	Acc@1 79.688 (80.152)	Acc@5 100.000 (99.586)
 * Acc@1 80.198 Acc@5 99.589
epoch 103, total time 388.79
Test: [0/750]	Time 0.806 (0.806)	Loss 0.4312 (0.4312)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.088 (0.110)	Loss 0.3994 (0.4689)	Acc@1 84.375 (86.355)	Acc@5 100.000 (95.699)
Test: [200/750]	Time 0.149 (0.108)	Loss 1.0942 (0.4770)	Acc@1 53.125 (84.779)	Acc@5 93.750 (96.657)
Test: [300/750]	Time 0.091 (0.105)	Loss 0.9334 (0.6731)	Acc@1 62.500 (76.267)	Acc@5 96.875 (95.743)
Test: [400/750]	Time 0.096 (0.105)	Loss 0.5098 (0.7502)	Acc@1 87.500 (73.028)	Acc@5 90.625 (95.340)
Test: [500/750]	Time 0.089 (0.104)	Loss 0.4251 (0.7324)	Acc@1 78.125 (74.177)	Acc@5 100.000 (95.016)
Test: [600/750]	Time 0.106 (0.104)	Loss 0.6250 (0.7419)	Acc@1 75.000 (74.199)	Acc@5 96.875 (94.946)
Test: [700/750]	Time 0.100 (0.103)	Loss 0.9293 (0.7379)	Acc@1 59.375 (74.202)	Acc@5 87.500 (95.119)
 * Acc@1 74.237 Acc@5 95.079
==> training...
Epoch: [104][0/875]	Time 1.737 (1.737)	Data 1.255 (1.255)	Loss 2.1558 (2.1558)	Loss@kd 2.3960 (2.3960)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [104][100/875]	Time 0.402 (0.463)	Data 0.005 (0.019)	Loss 2.5065 (2.3492)	Loss@kd 2.5258 (2.5545)	Acc@1 73.438 (79.208)	Acc@5 100.000 (99.536)
Epoch: [104][200/875]	Time 0.406 (0.458)	Data 0.007 (0.013)	Loss 2.5503 (2.3362)	Loss@kd 2.5333 (2.5547)	Acc@1 75.000 (79.664)	Acc@5 98.438 (99.572)
Epoch: [104][300/875]	Time 0.450 (0.455)	Data 0.007 (0.011)	Loss 2.2545 (2.3357)	Loss@kd 2.5030 (2.5600)	Acc@1 81.250 (79.838)	Acc@5 98.438 (99.605)
Epoch: [104][400/875]	Time 0.528 (0.454)	Data 0.007 (0.010)	Loss 2.2160 (2.3321)	Loss@kd 2.4515 (2.5584)	Acc@1 79.688 (79.828)	Acc@5 100.000 (99.634)
Epoch: [104][500/875]	Time 0.403 (0.452)	Data 0.005 (0.009)	Loss 2.2908 (2.3303)	Loss@kd 2.5267 (2.5591)	Acc@1 82.812 (79.934)	Acc@5 100.000 (99.623)
Epoch: [104][600/875]	Time 0.421 (0.449)	Data 0.007 (0.009)	Loss 2.3119 (2.3395)	Loss@kd 2.5719 (2.5658)	Acc@1 78.125 (79.862)	Acc@5 100.000 (99.613)
Epoch: [104][700/875]	Time 0.440 (0.447)	Data 0.008 (0.009)	Loss 2.1948 (2.3414)	Loss@kd 2.4773 (2.5679)	Acc@1 84.375 (79.955)	Acc@5 100.000 (99.603)
Epoch: [104][800/875]	Time 0.439 (0.447)	Data 0.007 (0.009)	Loss 2.4560 (2.3412)	Loss@kd 2.7352 (2.5672)	Acc@1 79.688 (79.939)	Acc@5 100.000 (99.586)
 * Acc@1 79.932 Acc@5 99.591
epoch 104, total time 391.39
Test: [0/750]	Time 0.772 (0.772)	Loss 0.4754 (0.4754)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.171 (0.112)	Loss 0.4031 (0.4771)	Acc@1 81.250 (86.293)	Acc@5 96.875 (95.575)
Test: [200/750]	Time 0.079 (0.108)	Loss 1.0639 (0.4718)	Acc@1 59.375 (85.075)	Acc@5 90.625 (96.611)
Test: [300/750]	Time 0.102 (0.105)	Loss 1.0013 (0.6641)	Acc@1 62.500 (76.879)	Acc@5 96.875 (95.702)
Test: [400/750]	Time 0.092 (0.104)	Loss 0.6794 (0.7777)	Acc@1 78.125 (72.124)	Acc@5 90.625 (95.028)
Test: [500/750]	Time 0.092 (0.104)	Loss 0.4161 (0.7878)	Acc@1 87.500 (72.274)	Acc@5 100.000 (94.424)
Test: [600/750]	Time 0.102 (0.104)	Loss 0.6299 (0.7885)	Acc@1 78.125 (72.603)	Acc@5 96.875 (94.452)
Test: [700/750]	Time 0.101 (0.103)	Loss 0.9021 (0.7763)	Acc@1 65.625 (72.820)	Acc@5 87.500 (94.673)
 * Acc@1 73.083 Acc@5 94.675
==> training...
Epoch: [105][0/875]	Time 1.827 (1.827)	Data 1.340 (1.340)	Loss 2.2749 (2.2749)	Loss@kd 2.6117 (2.6117)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [105][100/875]	Time 0.447 (0.470)	Data 0.006 (0.020)	Loss 2.2589 (2.3522)	Loss@kd 2.6089 (2.5750)	Acc@1 84.375 (80.152)	Acc@5 100.000 (99.551)
Epoch: [105][200/875]	Time 0.445 (0.459)	Data 0.007 (0.013)	Loss 2.4161 (2.3603)	Loss@kd 2.4430 (2.5857)	Acc@1 73.438 (79.866)	Acc@5 98.438 (99.534)
Epoch: [105][300/875]	Time 0.474 (0.456)	Data 0.011 (0.011)	Loss 2.4502 (2.3493)	Loss@kd 2.4429 (2.5795)	Acc@1 75.000 (80.077)	Acc@5 100.000 (99.543)
Epoch: [105][400/875]	Time 0.451 (0.455)	Data 0.007 (0.010)	Loss 2.2098 (2.3458)	Loss@kd 2.4153 (2.5776)	Acc@1 85.938 (80.210)	Acc@5 100.000 (99.560)
Epoch: [105][500/875]	Time 0.437 (0.455)	Data 0.007 (0.010)	Loss 2.3420 (2.3468)	Loss@kd 2.5340 (2.5776)	Acc@1 76.562 (80.099)	Acc@5 98.438 (99.579)
Epoch: [105][600/875]	Time 0.553 (0.455)	Data 0.007 (0.009)	Loss 2.4071 (2.3494)	Loss@kd 2.5504 (2.5783)	Acc@1 78.125 (80.054)	Acc@5 100.000 (99.571)
Epoch: [105][700/875]	Time 0.472 (0.454)	Data 0.007 (0.009)	Loss 2.2615 (2.3477)	Loss@kd 2.5336 (2.5755)	Acc@1 81.250 (79.955)	Acc@5 100.000 (99.583)
Epoch: [105][800/875]	Time 0.409 (0.453)	Data 0.004 (0.009)	Loss 2.2898 (2.3469)	Loss@kd 2.5637 (2.5713)	Acc@1 79.688 (79.859)	Acc@5 100.000 (99.585)
 * Acc@1 79.954 Acc@5 99.591
epoch 105, total time 395.06
Test: [0/750]	Time 0.756 (0.756)	Loss 0.4533 (0.4533)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.106 (0.110)	Loss 0.4132 (0.4978)	Acc@1 78.125 (85.736)	Acc@5 100.000 (95.421)
Test: [200/750]	Time 0.156 (0.104)	Loss 1.1018 (0.4797)	Acc@1 59.375 (84.950)	Acc@5 93.750 (96.580)
Test: [300/750]	Time 0.100 (0.102)	Loss 0.9537 (0.6831)	Acc@1 68.750 (76.453)	Acc@5 93.750 (95.525)
Test: [400/750]	Time 0.113 (0.101)	Loss 0.5774 (0.7824)	Acc@1 81.250 (72.265)	Acc@5 90.625 (95.028)
Test: [500/750]	Time 0.093 (0.102)	Loss 0.4129 (0.7746)	Acc@1 87.500 (73.147)	Acc@5 100.000 (94.636)
Test: [600/750]	Time 0.118 (0.100)	Loss 0.6325 (0.7779)	Acc@1 78.125 (73.284)	Acc@5 93.750 (94.624)
Test: [700/750]	Time 0.097 (0.100)	Loss 0.8037 (0.7634)	Acc@1 65.625 (73.502)	Acc@5 90.625 (94.882)
 * Acc@1 73.862 Acc@5 94.933
==> training...
Epoch: [106][0/875]	Time 1.979 (1.979)	Data 1.311 (1.311)	Loss 2.2517 (2.2517)	Loss@kd 2.4322 (2.4322)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [106][100/875]	Time 0.471 (0.462)	Data 0.007 (0.020)	Loss 2.2816 (2.3379)	Loss@kd 2.5565 (2.5503)	Acc@1 79.688 (79.889)	Acc@5 100.000 (99.567)
Epoch: [106][200/875]	Time 0.454 (0.456)	Data 0.007 (0.013)	Loss 2.3209 (2.3285)	Loss@kd 2.5866 (2.5449)	Acc@1 84.375 (80.216)	Acc@5 100.000 (99.650)
Epoch: [106][300/875]	Time 0.423 (0.454)	Data 0.007 (0.011)	Loss 2.3198 (2.3350)	Loss@kd 2.5507 (2.5519)	Acc@1 82.812 (79.937)	Acc@5 98.438 (99.642)
Epoch: [106][400/875]	Time 0.412 (0.452)	Data 0.007 (0.010)	Loss 2.1170 (2.3303)	Loss@kd 2.5286 (2.5524)	Acc@1 87.500 (80.062)	Acc@5 100.000 (99.583)
Epoch: [106][500/875]	Time 0.452 (0.450)	Data 0.007 (0.009)	Loss 2.2709 (2.3270)	Loss@kd 2.4790 (2.5513)	Acc@1 79.688 (80.227)	Acc@5 100.000 (99.576)
Epoch: [106][600/875]	Time 0.460 (0.449)	Data 0.007 (0.009)	Loss 2.4469 (2.3328)	Loss@kd 2.5639 (2.5577)	Acc@1 70.312 (80.135)	Acc@5 100.000 (99.594)
Epoch: [106][700/875]	Time 0.412 (0.448)	Data 0.008 (0.009)	Loss 2.3910 (2.3387)	Loss@kd 2.5030 (2.5659)	Acc@1 73.438 (80.109)	Acc@5 98.438 (99.603)
Epoch: [106][800/875]	Time 0.515 (0.448)	Data 0.007 (0.008)	Loss 2.3836 (2.3390)	Loss@kd 2.6708 (2.5671)	Acc@1 81.250 (80.173)	Acc@5 100.000 (99.602)
 * Acc@1 80.134 Acc@5 99.605
epoch 106, total time 392.05
Test: [0/750]	Time 0.815 (0.815)	Loss 0.4240 (0.4240)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.114 (0.107)	Loss 0.4371 (0.4950)	Acc@1 81.250 (85.767)	Acc@5 100.000 (95.452)
Test: [200/750]	Time 0.108 (0.104)	Loss 1.0543 (0.4934)	Acc@1 53.125 (84.251)	Acc@5 93.750 (96.471)
Test: [300/750]	Time 0.186 (0.103)	Loss 0.9052 (0.6727)	Acc@1 62.500 (76.412)	Acc@5 96.875 (95.764)
Test: [400/750]	Time 0.096 (0.102)	Loss 0.5703 (0.7506)	Acc@1 84.375 (72.982)	Acc@5 90.625 (95.433)
Test: [500/750]	Time 0.097 (0.102)	Loss 0.4889 (0.7526)	Acc@1 81.250 (73.597)	Acc@5 100.000 (94.973)
Test: [600/750]	Time 0.076 (0.102)	Loss 0.6310 (0.7632)	Acc@1 75.000 (73.575)	Acc@5 96.875 (94.837)
Test: [700/750]	Time 0.107 (0.102)	Loss 0.9110 (0.7561)	Acc@1 65.625 (73.667)	Acc@5 87.500 (95.003)
 * Acc@1 73.746 Acc@5 95.000
==> training...
Epoch: [107][0/875]	Time 1.817 (1.817)	Data 1.327 (1.327)	Loss 2.3550 (2.3550)	Loss@kd 2.4646 (2.4646)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [107][100/875]	Time 0.447 (0.445)	Data 0.006 (0.020)	Loss 2.4058 (2.3520)	Loss@kd 2.6575 (2.5878)	Acc@1 78.125 (80.198)	Acc@5 100.000 (99.474)
Epoch: [107][200/875]	Time 0.435 (0.436)	Data 0.007 (0.013)	Loss 2.2687 (2.3481)	Loss@kd 2.6359 (2.5842)	Acc@1 79.688 (80.356)	Acc@5 100.000 (99.596)
Epoch: [107][300/875]	Time 0.405 (0.434)	Data 0.005 (0.011)	Loss 2.2177 (2.3451)	Loss@kd 2.4716 (2.5813)	Acc@1 79.688 (80.191)	Acc@5 100.000 (99.605)
Epoch: [107][400/875]	Time 0.441 (0.437)	Data 0.008 (0.010)	Loss 2.2496 (2.3424)	Loss@kd 2.4952 (2.5756)	Acc@1 78.125 (80.163)	Acc@5 100.000 (99.603)
Epoch: [107][500/875]	Time 0.430 (0.438)	Data 0.006 (0.009)	Loss 2.2280 (2.3395)	Loss@kd 2.4190 (2.5706)	Acc@1 76.562 (80.118)	Acc@5 100.000 (99.591)
Epoch: [107][600/875]	Time 0.399 (0.439)	Data 0.007 (0.009)	Loss 2.3604 (2.3425)	Loss@kd 2.5294 (2.5716)	Acc@1 76.562 (80.096)	Acc@5 100.000 (99.584)
Epoch: [107][700/875]	Time 0.397 (0.439)	Data 0.006 (0.009)	Loss 2.0705 (2.3380)	Loss@kd 2.4860 (2.5688)	Acc@1 92.188 (80.171)	Acc@5 100.000 (99.588)
Epoch: [107][800/875]	Time 0.433 (0.440)	Data 0.005 (0.008)	Loss 2.1541 (2.3350)	Loss@kd 2.5030 (2.5664)	Acc@1 81.250 (80.222)	Acc@5 100.000 (99.600)
 * Acc@1 80.198 Acc@5 99.604
epoch 107, total time 386.15
Test: [0/750]	Time 0.841 (0.841)	Loss 0.4091 (0.4091)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.095 (0.105)	Loss 0.3621 (0.4815)	Acc@1 81.250 (86.479)	Acc@5 100.000 (95.545)
Test: [200/750]	Time 0.090 (0.104)	Loss 1.0712 (0.4783)	Acc@1 53.125 (84.795)	Acc@5 93.750 (96.642)
Test: [300/750]	Time 0.081 (0.102)	Loss 0.9486 (0.6735)	Acc@1 62.500 (76.433)	Acc@5 96.875 (95.754)
Test: [400/750]	Time 0.109 (0.102)	Loss 0.5446 (0.7656)	Acc@1 84.375 (72.576)	Acc@5 90.625 (95.215)
Test: [500/750]	Time 0.079 (0.101)	Loss 0.3941 (0.7512)	Acc@1 90.625 (73.671)	Acc@5 100.000 (94.973)
Test: [600/750]	Time 0.109 (0.101)	Loss 0.6704 (0.7557)	Acc@1 71.875 (73.830)	Acc@5 96.875 (94.925)
Test: [700/750]	Time 0.091 (0.100)	Loss 1.0335 (0.7523)	Acc@1 62.500 (73.801)	Acc@5 84.375 (95.070)
 * Acc@1 73.817 Acc@5 95.033
==> training...
Epoch: [108][0/875]	Time 1.849 (1.849)	Data 1.346 (1.346)	Loss 2.3184 (2.3184)	Loss@kd 2.4927 (2.4927)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [108][100/875]	Time 0.452 (0.457)	Data 0.007 (0.020)	Loss 2.2091 (2.3184)	Loss@kd 2.5055 (2.5641)	Acc@1 82.812 (81.080)	Acc@5 100.000 (99.737)
Epoch: [108][200/875]	Time 0.436 (0.449)	Data 0.007 (0.013)	Loss 2.2433 (2.3260)	Loss@kd 2.5042 (2.5680)	Acc@1 81.250 (80.644)	Acc@5 100.000 (99.705)
Epoch: [108][300/875]	Time 0.461 (0.447)	Data 0.007 (0.011)	Loss 2.3202 (2.3272)	Loss@kd 2.6737 (2.5703)	Acc@1 85.938 (80.679)	Acc@5 100.000 (99.663)
Epoch: [108][400/875]	Time 0.501 (0.444)	Data 0.007 (0.010)	Loss 2.5478 (2.3289)	Loss@kd 2.9281 (2.5680)	Acc@1 82.812 (80.630)	Acc@5 100.000 (99.579)
Epoch: [108][500/875]	Time 0.445 (0.440)	Data 0.007 (0.009)	Loss 2.1575 (2.3311)	Loss@kd 2.3672 (2.5685)	Acc@1 79.688 (80.486)	Acc@5 98.438 (99.579)
Epoch: [108][600/875]	Time 0.425 (0.438)	Data 0.005 (0.009)	Loss 2.3486 (2.3350)	Loss@kd 2.6159 (2.5741)	Acc@1 78.125 (80.496)	Acc@5 100.000 (99.568)
Epoch: [108][700/875]	Time 0.485 (0.438)	Data 0.007 (0.009)	Loss 2.1843 (2.3314)	Loss@kd 2.3483 (2.5695)	Acc@1 84.375 (80.503)	Acc@5 100.000 (99.585)
Epoch: [108][800/875]	Time 0.416 (0.439)	Data 0.007 (0.008)	Loss 2.3094 (2.3353)	Loss@kd 2.4440 (2.5690)	Acc@1 78.125 (80.378)	Acc@5 100.000 (99.565)
 * Acc@1 80.396 Acc@5 99.582
epoch 108, total time 384.88
Test: [0/750]	Time 0.775 (0.775)	Loss 0.4175 (0.4175)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.133 (0.109)	Loss 0.4107 (0.4892)	Acc@1 78.125 (85.798)	Acc@5 100.000 (95.668)
Test: [200/750]	Time 0.111 (0.106)	Loss 1.1154 (0.4842)	Acc@1 53.125 (84.453)	Acc@5 93.750 (96.657)
Test: [300/750]	Time 0.074 (0.105)	Loss 0.8767 (0.6666)	Acc@1 59.375 (76.464)	Acc@5 96.875 (95.785)
Test: [400/750]	Time 0.092 (0.105)	Loss 0.4711 (0.7431)	Acc@1 87.500 (73.114)	Acc@5 90.625 (95.441)
Test: [500/750]	Time 0.083 (0.103)	Loss 0.4767 (0.7274)	Acc@1 78.125 (74.295)	Acc@5 100.000 (95.135)
Test: [600/750]	Time 0.087 (0.104)	Loss 0.6422 (0.7409)	Acc@1 71.875 (74.132)	Acc@5 96.875 (95.040)
Test: [700/750]	Time 0.081 (0.103)	Loss 0.9815 (0.7383)	Acc@1 59.375 (74.028)	Acc@5 84.375 (95.159)
 * Acc@1 73.983 Acc@5 95.112
==> training...
Epoch: [109][0/875]	Time 1.858 (1.858)	Data 1.362 (1.362)	Loss 2.3573 (2.3573)	Loss@kd 2.5270 (2.5270)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [109][100/875]	Time 0.507 (0.466)	Data 0.007 (0.020)	Loss 2.3267 (2.3464)	Loss@kd 2.6145 (2.5699)	Acc@1 85.938 (80.213)	Acc@5 100.000 (99.536)
Epoch: [109][200/875]	Time 0.431 (0.458)	Data 0.007 (0.014)	Loss 2.3985 (2.3386)	Loss@kd 2.4479 (2.5725)	Acc@1 73.438 (80.356)	Acc@5 98.438 (99.596)
Epoch: [109][300/875]	Time 0.463 (0.455)	Data 0.007 (0.011)	Loss 2.3034 (2.3325)	Loss@kd 2.5078 (2.5694)	Acc@1 79.688 (80.487)	Acc@5 98.438 (99.569)
Epoch: [109][400/875]	Time 0.474 (0.454)	Data 0.007 (0.010)	Loss 2.1862 (2.3371)	Loss@kd 2.4815 (2.5771)	Acc@1 87.500 (80.584)	Acc@5 98.438 (99.579)
Epoch: [109][500/875]	Time 0.478 (0.453)	Data 0.008 (0.010)	Loss 2.2451 (2.3343)	Loss@kd 2.5600 (2.5692)	Acc@1 79.688 (80.358)	Acc@5 100.000 (99.598)
Epoch: [109][600/875]	Time 0.506 (0.453)	Data 0.007 (0.009)	Loss 2.4131 (2.3354)	Loss@kd 2.5223 (2.5680)	Acc@1 76.562 (80.233)	Acc@5 100.000 (99.597)
Epoch: [109][700/875]	Time 0.425 (0.451)	Data 0.007 (0.009)	Loss 2.1771 (2.3358)	Loss@kd 2.4930 (2.5684)	Acc@1 73.438 (80.303)	Acc@5 100.000 (99.612)
Epoch: [109][800/875]	Time 0.425 (0.449)	Data 0.007 (0.009)	Loss 2.1340 (2.3387)	Loss@kd 2.4351 (2.5728)	Acc@1 90.625 (80.316)	Acc@5 98.438 (99.600)
 * Acc@1 80.261 Acc@5 99.598
epoch 109, total time 391.76
Test: [0/750]	Time 0.757 (0.757)	Loss 0.4523 (0.4523)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.097 (0.104)	Loss 0.3708 (0.5135)	Acc@1 87.500 (85.303)	Acc@5 100.000 (95.328)
Test: [200/750]	Time 0.164 (0.101)	Loss 1.0396 (0.4878)	Acc@1 56.250 (84.655)	Acc@5 93.750 (96.471)
Test: [300/750]	Time 0.089 (0.101)	Loss 0.9864 (0.6748)	Acc@1 59.375 (76.557)	Acc@5 96.875 (95.660)
Test: [400/750]	Time 0.096 (0.100)	Loss 0.4963 (0.7656)	Acc@1 87.500 (72.763)	Acc@5 93.750 (95.246)
Test: [500/750]	Time 0.095 (0.101)	Loss 0.4443 (0.7500)	Acc@1 81.250 (73.846)	Acc@5 100.000 (94.910)
Test: [600/750]	Time 0.088 (0.100)	Loss 0.6731 (0.7603)	Acc@1 75.000 (73.736)	Acc@5 96.875 (94.852)
Test: [700/750]	Time 0.075 (0.100)	Loss 0.9417 (0.7546)	Acc@1 65.625 (73.703)	Acc@5 84.375 (95.012)
 * Acc@1 73.900 Acc@5 95.004
==> training...
Epoch: [110][0/875]	Time 1.936 (1.936)	Data 1.356 (1.356)	Loss 2.4392 (2.4392)	Loss@kd 2.5958 (2.5958)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [110][100/875]	Time 0.418 (0.468)	Data 0.008 (0.020)	Loss 2.2432 (2.3128)	Loss@kd 2.4362 (2.5506)	Acc@1 79.688 (80.755)	Acc@5 100.000 (99.660)
Epoch: [110][200/875]	Time 0.448 (0.460)	Data 0.007 (0.014)	Loss 2.3653 (2.3272)	Loss@kd 2.6982 (2.5609)	Acc@1 81.250 (80.636)	Acc@5 100.000 (99.611)
Epoch: [110][300/875]	Time 0.440 (0.457)	Data 0.007 (0.011)	Loss 2.2627 (2.3364)	Loss@kd 2.5957 (2.5631)	Acc@1 82.812 (80.305)	Acc@5 100.000 (99.590)
Epoch: [110][400/875]	Time 0.429 (0.457)	Data 0.007 (0.010)	Loss 2.2704 (2.3332)	Loss@kd 2.5346 (2.5657)	Acc@1 78.125 (80.436)	Acc@5 98.438 (99.599)
Epoch: [110][500/875]	Time 0.480 (0.457)	Data 0.007 (0.010)	Loss 2.1530 (2.3307)	Loss@kd 2.4542 (2.5644)	Acc@1 85.938 (80.501)	Acc@5 100.000 (99.595)
Epoch: [110][600/875]	Time 0.424 (0.455)	Data 0.007 (0.009)	Loss 2.3951 (2.3307)	Loss@kd 2.5647 (2.5669)	Acc@1 78.125 (80.426)	Acc@5 100.000 (99.610)
Epoch: [110][700/875]	Time 0.462 (0.454)	Data 0.007 (0.009)	Loss 2.4975 (2.3342)	Loss@kd 2.7040 (2.5683)	Acc@1 75.000 (80.345)	Acc@5 100.000 (99.594)
Epoch: [110][800/875]	Time 0.487 (0.454)	Data 0.007 (0.009)	Loss 2.1481 (2.3330)	Loss@kd 2.4482 (2.5664)	Acc@1 84.375 (80.427)	Acc@5 100.000 (99.571)
 * Acc@1 80.318 Acc@5 99.573
epoch 110, total time 397.88
Test: [0/750]	Time 0.762 (0.762)	Loss 0.6924 (0.6924)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.075 (0.107)	Loss 0.3664 (0.5473)	Acc@1 81.250 (83.509)	Acc@5 100.000 (95.297)
Test: [200/750]	Time 0.117 (0.105)	Loss 1.1387 (0.4997)	Acc@1 56.250 (83.877)	Acc@5 90.625 (96.455)
Test: [300/750]	Time 0.148 (0.104)	Loss 0.9712 (0.6964)	Acc@1 62.500 (75.498)	Acc@5 96.875 (95.463)
Test: [400/750]	Time 0.072 (0.103)	Loss 0.5602 (0.7824)	Acc@1 84.375 (71.937)	Acc@5 90.625 (94.989)
Test: [500/750]	Time 0.111 (0.103)	Loss 0.4180 (0.7667)	Acc@1 84.375 (73.073)	Acc@5 100.000 (94.754)
Test: [600/750]	Time 0.102 (0.102)	Loss 0.6480 (0.7686)	Acc@1 75.000 (73.269)	Acc@5 96.875 (94.774)
Test: [700/750]	Time 0.102 (0.102)	Loss 0.9484 (0.7616)	Acc@1 62.500 (73.400)	Acc@5 87.500 (94.994)
 * Acc@1 73.425 Acc@5 94.992
==> training...
Epoch: [111][0/875]	Time 1.839 (1.839)	Data 1.390 (1.390)	Loss 2.2047 (2.2047)	Loss@kd 2.5011 (2.5011)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [111][100/875]	Time 0.496 (0.447)	Data 0.007 (0.020)	Loss 2.6319 (2.3074)	Loss@kd 2.5787 (2.5373)	Acc@1 68.750 (80.368)	Acc@5 98.438 (99.768)
Epoch: [111][200/875]	Time 0.472 (0.446)	Data 0.007 (0.014)	Loss 2.8677 (2.3247)	Loss@kd 3.3420 (2.5586)	Acc@1 75.000 (80.581)	Acc@5 100.000 (99.736)
Epoch: [111][300/875]	Time 0.420 (0.447)	Data 0.007 (0.011)	Loss 2.2085 (2.3248)	Loss@kd 2.4723 (2.5615)	Acc@1 89.062 (80.528)	Acc@5 100.000 (99.668)
Epoch: [111][400/875]	Time 0.441 (0.448)	Data 0.006 (0.010)	Loss 2.2653 (2.3295)	Loss@kd 2.4443 (2.5675)	Acc@1 81.250 (80.599)	Acc@5 100.000 (99.606)
Epoch: [111][500/875]	Time 0.424 (0.448)	Data 0.007 (0.010)	Loss 2.3556 (2.3355)	Loss@kd 2.4258 (2.5736)	Acc@1 81.250 (80.555)	Acc@5 98.438 (99.560)
Epoch: [111][600/875]	Time 0.453 (0.449)	Data 0.007 (0.009)	Loss 2.2122 (2.3357)	Loss@kd 2.4882 (2.5679)	Acc@1 76.562 (80.376)	Acc@5 100.000 (99.548)
Epoch: [111][700/875]	Time 0.408 (0.449)	Data 0.007 (0.009)	Loss 2.3318 (2.3345)	Loss@kd 2.4744 (2.5653)	Acc@1 73.438 (80.258)	Acc@5 100.000 (99.563)
Epoch: [111][800/875]	Time 0.467 (0.450)	Data 0.007 (0.009)	Loss 2.2321 (2.3340)	Loss@kd 2.5151 (2.5654)	Acc@1 79.688 (80.226)	Acc@5 100.000 (99.569)
 * Acc@1 80.193 Acc@5 99.562
epoch 111, total time 394.08
Test: [0/750]	Time 0.830 (0.830)	Loss 0.4890 (0.4890)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.091 (0.113)	Loss 0.3775 (0.5054)	Acc@1 81.250 (85.396)	Acc@5 100.000 (95.328)
Test: [200/750]	Time 0.119 (0.109)	Loss 1.1299 (0.4890)	Acc@1 53.125 (84.375)	Acc@5 93.750 (96.471)
Test: [300/750]	Time 0.100 (0.108)	Loss 1.0040 (0.6898)	Acc@1 59.375 (75.820)	Acc@5 93.750 (95.484)
Test: [400/750]	Time 0.106 (0.107)	Loss 0.5407 (0.7711)	Acc@1 84.375 (72.350)	Acc@5 90.625 (95.122)
Test: [500/750]	Time 0.093 (0.106)	Loss 0.4405 (0.7635)	Acc@1 84.375 (73.216)	Acc@5 100.000 (94.767)
Test: [600/750]	Time 0.098 (0.106)	Loss 0.6339 (0.7682)	Acc@1 75.000 (73.336)	Acc@5 96.875 (94.738)
Test: [700/750]	Time 0.108 (0.106)	Loss 0.8384 (0.7578)	Acc@1 65.625 (73.462)	Acc@5 87.500 (94.971)
 * Acc@1 73.675 Acc@5 94.983
==> training...
Epoch: [112][0/875]	Time 1.928 (1.928)	Data 1.396 (1.396)	Loss 2.3159 (2.3159)	Loss@kd 2.4106 (2.4106)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [112][100/875]	Time 0.447 (0.470)	Data 0.007 (0.020)	Loss 2.3201 (2.3130)	Loss@kd 2.4532 (2.5448)	Acc@1 71.875 (80.616)	Acc@5 98.438 (99.644)
Epoch: [112][200/875]	Time 0.437 (0.461)	Data 0.006 (0.014)	Loss 2.4202 (2.3322)	Loss@kd 2.5870 (2.5707)	Acc@1 78.125 (80.317)	Acc@5 96.875 (99.642)
Epoch: [112][300/875]	Time 0.433 (0.452)	Data 0.007 (0.011)	Loss 2.4256 (2.3342)	Loss@kd 2.6331 (2.5661)	Acc@1 81.250 (80.118)	Acc@5 98.438 (99.611)
Epoch: [112][400/875]	Time 0.441 (0.447)	Data 0.007 (0.010)	Loss 2.4162 (2.3376)	Loss@kd 2.4311 (2.5657)	Acc@1 75.000 (79.984)	Acc@5 98.438 (99.603)
Epoch: [112][500/875]	Time 0.461 (0.447)	Data 0.007 (0.010)	Loss 2.4958 (2.3330)	Loss@kd 2.5624 (2.5619)	Acc@1 70.312 (80.102)	Acc@5 98.438 (99.598)
Epoch: [112][600/875]	Time 0.435 (0.448)	Data 0.007 (0.009)	Loss 2.2955 (2.3350)	Loss@kd 2.6598 (2.5659)	Acc@1 79.688 (80.153)	Acc@5 100.000 (99.594)
Epoch: [112][700/875]	Time 0.447 (0.449)	Data 0.007 (0.009)	Loss 2.3093 (2.3363)	Loss@kd 2.4756 (2.5654)	Acc@1 81.250 (80.086)	Acc@5 100.000 (99.599)
Epoch: [112][800/875]	Time 0.531 (0.450)	Data 0.007 (0.009)	Loss 2.5216 (2.3395)	Loss@kd 2.7371 (2.5691)	Acc@1 81.250 (80.048)	Acc@5 98.438 (99.600)
 * Acc@1 80.134 Acc@5 99.609
epoch 112, total time 394.17
Test: [0/750]	Time 0.764 (0.764)	Loss 0.4342 (0.4342)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.095 (0.110)	Loss 0.3828 (0.5156)	Acc@1 81.250 (85.582)	Acc@5 100.000 (95.359)
Test: [200/750]	Time 0.081 (0.107)	Loss 1.0745 (0.4807)	Acc@1 53.125 (84.888)	Acc@5 90.625 (96.533)
Test: [300/750]	Time 0.176 (0.105)	Loss 0.8948 (0.6714)	Acc@1 65.625 (76.744)	Acc@5 93.750 (95.505)
Test: [400/750]	Time 0.094 (0.105)	Loss 0.4839 (0.7574)	Acc@1 87.500 (73.091)	Acc@5 93.750 (95.122)
Test: [500/750]	Time 0.093 (0.104)	Loss 0.4391 (0.7368)	Acc@1 81.250 (74.289)	Acc@5 100.000 (94.904)
Test: [600/750]	Time 0.104 (0.104)	Loss 0.6691 (0.7460)	Acc@1 71.875 (74.215)	Acc@5 96.875 (94.915)
Test: [700/750]	Time 0.095 (0.103)	Loss 0.9718 (0.7444)	Acc@1 59.375 (74.086)	Acc@5 84.375 (95.074)
 * Acc@1 74.012 Acc@5 95.046
==> training...
Epoch: [113][0/875]	Time 1.824 (1.824)	Data 1.325 (1.325)	Loss 2.2759 (2.2759)	Loss@kd 2.5896 (2.5896)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [113][100/875]	Time 0.519 (0.468)	Data 0.006 (0.020)	Loss 2.1826 (2.3579)	Loss@kd 2.4125 (2.5795)	Acc@1 78.125 (79.409)	Acc@5 100.000 (99.536)
Epoch: [113][200/875]	Time 0.418 (0.460)	Data 0.008 (0.013)	Loss 2.1368 (2.3480)	Loss@kd 2.3588 (2.5748)	Acc@1 79.688 (79.695)	Acc@5 100.000 (99.541)
Epoch: [113][300/875]	Time 0.466 (0.457)	Data 0.007 (0.011)	Loss 2.2543 (2.3446)	Loss@kd 2.5049 (2.5711)	Acc@1 82.812 (79.537)	Acc@5 100.000 (99.569)
Epoch: [113][400/875]	Time 0.458 (0.457)	Data 0.010 (0.010)	Loss 2.1654 (2.3359)	Loss@kd 2.5070 (2.5659)	Acc@1 84.375 (79.804)	Acc@5 100.000 (99.595)
Epoch: [113][500/875]	Time 0.412 (0.455)	Data 0.006 (0.009)	Loss 2.2172 (2.3337)	Loss@kd 2.4596 (2.5698)	Acc@1 78.125 (80.065)	Acc@5 98.438 (99.610)
Epoch: [113][600/875]	Time 0.443 (0.451)	Data 0.007 (0.009)	Loss 2.3663 (2.3334)	Loss@kd 2.4740 (2.5669)	Acc@1 71.875 (80.070)	Acc@5 100.000 (99.589)
Epoch: [113][700/875]	Time 0.410 (0.449)	Data 0.007 (0.009)	Loss 3.3248 (2.3345)	Loss@kd 3.8995 (2.5687)	Acc@1 73.438 (80.073)	Acc@5 98.438 (99.601)
Epoch: [113][800/875]	Time 0.428 (0.449)	Data 0.007 (0.008)	Loss 2.5411 (2.3352)	Loss@kd 2.5561 (2.5669)	Acc@1 65.625 (80.029)	Acc@5 100.000 (99.592)
 * Acc@1 80.048 Acc@5 99.588
epoch 113, total time 393.42
Test: [0/750]	Time 0.814 (0.814)	Loss 0.4221 (0.4221)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.097 (0.108)	Loss 0.4097 (0.4977)	Acc@1 84.375 (86.386)	Acc@5 96.875 (95.483)
Test: [200/750]	Time 0.105 (0.108)	Loss 1.1367 (0.4827)	Acc@1 56.250 (85.106)	Acc@5 90.625 (96.595)
Test: [300/750]	Time 0.095 (0.106)	Loss 0.9114 (0.6755)	Acc@1 65.625 (76.692)	Acc@5 96.875 (95.640)
Test: [400/750]	Time 0.095 (0.105)	Loss 0.5415 (0.7661)	Acc@1 84.375 (72.997)	Acc@5 90.625 (95.176)
Test: [500/750]	Time 0.113 (0.104)	Loss 0.4043 (0.7545)	Acc@1 87.500 (73.877)	Acc@5 100.000 (94.867)
Test: [600/750]	Time 0.095 (0.104)	Loss 0.6120 (0.7602)	Acc@1 81.250 (73.934)	Acc@5 96.875 (94.873)
Test: [700/750]	Time 0.094 (0.103)	Loss 0.9112 (0.7532)	Acc@1 62.500 (73.943)	Acc@5 90.625 (95.065)
 * Acc@1 74.071 Acc@5 95.062
==> training...
Epoch: [114][0/875]	Time 1.753 (1.753)	Data 1.271 (1.271)	Loss 2.2092 (2.2092)	Loss@kd 2.4363 (2.4363)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [114][100/875]	Time 0.437 (0.467)	Data 0.007 (0.019)	Loss 2.3015 (2.3304)	Loss@kd 2.5206 (2.5701)	Acc@1 79.688 (80.662)	Acc@5 100.000 (99.551)
Epoch: [114][200/875]	Time 0.442 (0.460)	Data 0.008 (0.013)	Loss 3.3587 (2.3452)	Loss@kd 4.0070 (2.5895)	Acc@1 75.000 (80.325)	Acc@5 100.000 (99.580)
Epoch: [114][300/875]	Time 0.443 (0.457)	Data 0.007 (0.011)	Loss 2.3452 (2.3442)	Loss@kd 2.5715 (2.5823)	Acc@1 85.938 (80.149)	Acc@5 100.000 (99.548)
Epoch: [114][400/875]	Time 0.498 (0.457)	Data 0.007 (0.010)	Loss 2.3553 (2.3423)	Loss@kd 2.5518 (2.5744)	Acc@1 76.562 (80.120)	Acc@5 100.000 (99.560)
Epoch: [114][500/875]	Time 0.447 (0.456)	Data 0.007 (0.009)	Loss 2.4259 (2.3418)	Loss@kd 2.4855 (2.5745)	Acc@1 73.438 (80.090)	Acc@5 100.000 (99.566)
Epoch: [114][600/875]	Time 0.421 (0.455)	Data 0.007 (0.009)	Loss 2.3727 (2.3394)	Loss@kd 2.5219 (2.5728)	Acc@1 73.438 (80.137)	Acc@5 98.438 (99.563)
Epoch: [114][700/875]	Time 0.434 (0.455)	Data 0.007 (0.009)	Loss 2.1431 (2.3362)	Loss@kd 2.5194 (2.5697)	Acc@1 87.500 (80.229)	Acc@5 100.000 (99.588)
Epoch: [114][800/875]	Time 0.433 (0.454)	Data 0.007 (0.009)	Loss 2.3633 (2.3346)	Loss@kd 2.5571 (2.5679)	Acc@1 81.250 (80.218)	Acc@5 98.438 (99.612)
 * Acc@1 80.125 Acc@5 99.618
epoch 114, total time 395.97
Test: [0/750]	Time 0.771 (0.771)	Loss 0.5507 (0.5507)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.165 (0.110)	Loss 0.3813 (0.5301)	Acc@1 81.250 (84.777)	Acc@5 100.000 (95.173)
Test: [200/750]	Time 0.086 (0.105)	Loss 1.1265 (0.4977)	Acc@1 56.250 (84.406)	Acc@5 90.625 (96.471)
Test: [300/750]	Time 0.106 (0.103)	Loss 0.9790 (0.6897)	Acc@1 65.625 (75.924)	Acc@5 93.750 (95.473)
Test: [400/750]	Time 0.077 (0.103)	Loss 0.5751 (0.7831)	Acc@1 81.250 (72.078)	Acc@5 90.625 (94.950)
Test: [500/750]	Time 0.094 (0.102)	Loss 0.4232 (0.7751)	Acc@1 84.375 (72.761)	Acc@5 100.000 (94.642)
Test: [600/750]	Time 0.074 (0.101)	Loss 0.6631 (0.7758)	Acc@1 75.000 (72.998)	Acc@5 90.625 (94.644)
Test: [700/750]	Time 0.092 (0.101)	Loss 0.8698 (0.7659)	Acc@1 65.625 (73.128)	Acc@5 90.625 (94.896)
 * Acc@1 73.342 Acc@5 94.900
==> training...
Epoch: [115][0/875]	Time 1.793 (1.793)	Data 1.290 (1.290)	Loss 2.4277 (2.4277)	Loss@kd 2.4472 (2.4472)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [115][100/875]	Time 0.426 (0.463)	Data 0.007 (0.019)	Loss 2.2662 (2.3677)	Loss@kd 2.4576 (2.5862)	Acc@1 79.688 (79.425)	Acc@5 100.000 (99.489)
Epoch: [115][200/875]	Time 0.443 (0.459)	Data 0.005 (0.013)	Loss 2.3417 (2.3465)	Loss@kd 2.5632 (2.5777)	Acc@1 75.000 (79.851)	Acc@5 100.000 (99.572)
Epoch: [115][300/875]	Time 0.481 (0.457)	Data 0.007 (0.011)	Loss 2.3980 (2.3459)	Loss@kd 2.3365 (2.5789)	Acc@1 71.875 (80.009)	Acc@5 98.438 (99.590)
Epoch: [115][400/875]	Time 0.460 (0.455)	Data 0.007 (0.010)	Loss 2.4603 (2.3424)	Loss@kd 2.6553 (2.5725)	Acc@1 79.688 (79.910)	Acc@5 100.000 (99.614)
Epoch: [115][500/875]	Time 0.428 (0.454)	Data 0.005 (0.010)	Loss 2.1801 (2.3378)	Loss@kd 2.6612 (2.5687)	Acc@1 90.625 (80.049)	Acc@5 100.000 (99.623)
Epoch: [115][600/875]	Time 0.560 (0.454)	Data 0.008 (0.009)	Loss 2.4052 (2.3359)	Loss@kd 2.5277 (2.5682)	Acc@1 79.688 (80.054)	Acc@5 98.438 (99.600)
Epoch: [115][700/875]	Time 0.461 (0.454)	Data 0.011 (0.009)	Loss 2.3473 (2.3375)	Loss@kd 2.5960 (2.5666)	Acc@1 81.250 (79.962)	Acc@5 100.000 (99.583)
Epoch: [115][800/875]	Time 0.428 (0.454)	Data 0.005 (0.009)	Loss 2.3155 (2.3402)	Loss@kd 2.7026 (2.5714)	Acc@1 84.375 (80.002)	Acc@5 100.000 (99.588)
 * Acc@1 79.948 Acc@5 99.586
epoch 115, total time 397.88
Test: [0/750]	Time 0.732 (0.732)	Loss 0.4207 (0.4207)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.100 (0.113)	Loss 0.4169 (0.5026)	Acc@1 78.125 (85.179)	Acc@5 100.000 (95.545)
Test: [200/750]	Time 0.142 (0.107)	Loss 1.0473 (0.4898)	Acc@1 53.125 (84.251)	Acc@5 93.750 (96.595)
Test: [300/750]	Time 0.068 (0.107)	Loss 0.9767 (0.6673)	Acc@1 59.375 (76.661)	Acc@5 96.875 (95.837)
Test: [400/750]	Time 0.088 (0.105)	Loss 0.6862 (0.7700)	Acc@1 75.000 (72.428)	Acc@5 90.625 (95.301)
Test: [500/750]	Time 0.097 (0.105)	Loss 0.4087 (0.7752)	Acc@1 81.250 (72.667)	Acc@5 100.000 (94.773)
Test: [600/750]	Time 0.097 (0.104)	Loss 0.6461 (0.7774)	Acc@1 78.125 (72.931)	Acc@5 93.750 (94.733)
Test: [700/750]	Time 0.100 (0.104)	Loss 0.9585 (0.7700)	Acc@1 62.500 (73.003)	Acc@5 87.500 (94.896)
 * Acc@1 73.108 Acc@5 94.887
==> training...
Epoch: [116][0/875]	Time 2.025 (2.025)	Data 1.395 (1.395)	Loss 2.1234 (2.1234)	Loss@kd 2.4159 (2.4159)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [116][100/875]	Time 0.433 (0.448)	Data 0.007 (0.020)	Loss 2.0086 (2.3461)	Loss@kd 2.4315 (2.5699)	Acc@1 95.312 (80.229)	Acc@5 100.000 (99.551)
Epoch: [116][200/875]	Time 0.423 (0.441)	Data 0.006 (0.014)	Loss 2.2187 (2.3351)	Loss@kd 2.4806 (2.5605)	Acc@1 79.688 (80.317)	Acc@5 100.000 (99.611)
Epoch: [116][300/875]	Time 0.427 (0.440)	Data 0.007 (0.011)	Loss 2.3250 (2.3318)	Loss@kd 2.5339 (2.5610)	Acc@1 79.688 (80.492)	Acc@5 96.875 (99.605)
Epoch: [116][400/875]	Time 0.428 (0.442)	Data 0.007 (0.010)	Loss 2.5469 (2.3417)	Loss@kd 2.8298 (2.5762)	Acc@1 79.688 (80.424)	Acc@5 100.000 (99.603)
Epoch: [116][500/875]	Time 0.428 (0.443)	Data 0.008 (0.010)	Loss 2.2586 (2.3415)	Loss@kd 2.5059 (2.5735)	Acc@1 82.812 (80.333)	Acc@5 100.000 (99.620)
Epoch: [116][600/875]	Time 0.476 (0.445)	Data 0.007 (0.009)	Loss 2.3458 (2.3387)	Loss@kd 2.5589 (2.5716)	Acc@1 84.375 (80.345)	Acc@5 98.438 (99.639)
Epoch: [116][700/875]	Time 0.441 (0.447)	Data 0.007 (0.009)	Loss 2.3175 (2.3362)	Loss@kd 2.5740 (2.5691)	Acc@1 82.812 (80.363)	Acc@5 100.000 (99.634)
Epoch: [116][800/875]	Time 0.426 (0.448)	Data 0.007 (0.009)	Loss 2.4823 (2.3363)	Loss@kd 2.4155 (2.5679)	Acc@1 73.438 (80.314)	Acc@5 98.438 (99.629)
 * Acc@1 80.307 Acc@5 99.629
epoch 116, total time 392.98
Test: [0/750]	Time 0.876 (0.876)	Loss 0.4609 (0.4609)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.093 (0.111)	Loss 0.3702 (0.4955)	Acc@1 78.125 (86.077)	Acc@5 100.000 (95.606)
Test: [200/750]	Time 0.101 (0.107)	Loss 1.0823 (0.4815)	Acc@1 56.250 (84.888)	Acc@5 87.500 (96.626)
Test: [300/750]	Time 0.082 (0.105)	Loss 0.8707 (0.6706)	Acc@1 62.500 (76.858)	Acc@5 96.875 (95.826)
Test: [400/750]	Time 0.096 (0.105)	Loss 0.5956 (0.7519)	Acc@1 84.375 (73.410)	Acc@5 90.625 (95.457)
Test: [500/750]	Time 0.075 (0.103)	Loss 0.4556 (0.7543)	Acc@1 84.375 (73.877)	Acc@5 100.000 (94.973)
Test: [600/750]	Time 0.098 (0.103)	Loss 0.6038 (0.7642)	Acc@1 78.125 (73.861)	Acc@5 96.875 (94.863)
Test: [700/750]	Time 0.191 (0.103)	Loss 0.9599 (0.7560)	Acc@1 62.500 (73.921)	Acc@5 87.500 (95.043)
 * Acc@1 73.975 Acc@5 95.012
==> training...
Epoch: [117][0/875]	Time 1.767 (1.767)	Data 1.307 (1.307)	Loss 2.1212 (2.1212)	Loss@kd 2.4836 (2.4836)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [117][100/875]	Time 0.451 (0.465)	Data 0.007 (0.020)	Loss 2.1062 (2.3002)	Loss@kd 2.3972 (2.5524)	Acc@1 81.250 (80.724)	Acc@5 100.000 (99.706)
Epoch: [117][200/875]	Time 0.413 (0.458)	Data 0.007 (0.013)	Loss 2.1823 (2.3212)	Loss@kd 2.5102 (2.5518)	Acc@1 81.250 (79.742)	Acc@5 100.000 (99.627)
Epoch: [117][300/875]	Time 0.459 (0.457)	Data 0.007 (0.011)	Loss 2.5509 (2.3273)	Loss@kd 2.7208 (2.5566)	Acc@1 73.438 (79.713)	Acc@5 100.000 (99.605)
Epoch: [117][400/875]	Time 0.440 (0.450)	Data 0.007 (0.010)	Loss 2.2859 (2.3436)	Loss@kd 2.5380 (2.5760)	Acc@1 78.125 (79.797)	Acc@5 100.000 (99.591)
Epoch: [117][500/875]	Time 0.431 (0.446)	Data 0.007 (0.010)	Loss 2.3272 (2.3396)	Loss@kd 2.5924 (2.5691)	Acc@1 79.688 (79.912)	Acc@5 100.000 (99.610)
Epoch: [117][600/875]	Time 0.501 (0.446)	Data 0.006 (0.009)	Loss 2.3001 (2.3371)	Loss@kd 2.6344 (2.5694)	Acc@1 85.938 (80.080)	Acc@5 100.000 (99.613)
Epoch: [117][700/875]	Time 0.413 (0.446)	Data 0.007 (0.009)	Loss 2.3504 (2.3334)	Loss@kd 2.6702 (2.5650)	Acc@1 81.250 (80.066)	Acc@5 100.000 (99.623)
Epoch: [117][800/875]	Time 0.425 (0.446)	Data 0.007 (0.009)	Loss 2.1774 (2.3359)	Loss@kd 2.5696 (2.5657)	Acc@1 84.375 (80.023)	Acc@5 100.000 (99.622)
 * Acc@1 79.998 Acc@5 99.623
epoch 117, total time 390.49
Test: [0/750]	Time 0.845 (0.845)	Loss 0.5577 (0.5577)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.106 (0.112)	Loss 0.3868 (0.5385)	Acc@1 78.125 (84.746)	Acc@5 96.875 (94.740)
Test: [200/750]	Time 0.149 (0.106)	Loss 1.2431 (0.5122)	Acc@1 46.875 (83.815)	Acc@5 93.750 (96.315)
Test: [300/750]	Time 0.072 (0.105)	Loss 0.8733 (0.6981)	Acc@1 65.625 (75.623)	Acc@5 93.750 (95.422)
Test: [400/750]	Time 0.118 (0.103)	Loss 0.5993 (0.7715)	Acc@1 81.250 (72.195)	Acc@5 90.625 (95.145)
Test: [500/750]	Time 0.096 (0.103)	Loss 0.5184 (0.7804)	Acc@1 84.375 (72.536)	Acc@5 100.000 (94.511)
Test: [600/750]	Time 0.073 (0.103)	Loss 0.5802 (0.7870)	Acc@1 78.125 (72.603)	Acc@5 96.875 (94.390)
Test: [700/750]	Time 0.069 (0.102)	Loss 1.0043 (0.7768)	Acc@1 56.250 (72.771)	Acc@5 90.625 (94.659)
 * Acc@1 72.838 Acc@5 94.675
==> training...
Epoch: [118][0/875]	Time 1.987 (1.987)	Data 1.394 (1.394)	Loss 2.3666 (2.3666)	Loss@kd 2.6180 (2.6180)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [118][100/875]	Time 0.422 (0.467)	Data 0.007 (0.020)	Loss 2.0992 (2.3290)	Loss@kd 2.5350 (2.5598)	Acc@1 92.188 (79.920)	Acc@5 100.000 (99.598)
Epoch: [118][200/875]	Time 0.470 (0.460)	Data 0.007 (0.014)	Loss 2.3728 (2.3227)	Loss@kd 2.4564 (2.5508)	Acc@1 78.125 (80.154)	Acc@5 100.000 (99.580)
Epoch: [118][300/875]	Time 0.484 (0.458)	Data 0.007 (0.012)	Loss 2.4786 (2.3258)	Loss@kd 2.5745 (2.5586)	Acc@1 70.312 (80.191)	Acc@5 100.000 (99.605)
Epoch: [118][400/875]	Time 0.438 (0.457)	Data 0.007 (0.010)	Loss 2.2835 (2.3250)	Loss@kd 2.4552 (2.5618)	Acc@1 78.125 (80.350)	Acc@5 100.000 (99.626)
Epoch: [118][500/875]	Time 0.428 (0.456)	Data 0.007 (0.010)	Loss 2.3061 (2.3360)	Loss@kd 2.6271 (2.5695)	Acc@1 89.062 (80.215)	Acc@5 98.438 (99.632)
Epoch: [118][600/875]	Time 0.416 (0.456)	Data 0.007 (0.009)	Loss 2.0931 (2.3380)	Loss@kd 2.4325 (2.5764)	Acc@1 84.375 (80.335)	Acc@5 100.000 (99.631)
Epoch: [118][700/875]	Time 0.392 (0.452)	Data 0.006 (0.009)	Loss 2.2877 (2.3384)	Loss@kd 2.4299 (2.5761)	Acc@1 79.688 (80.294)	Acc@5 100.000 (99.632)
Epoch: [118][800/875]	Time 0.502 (0.449)	Data 0.007 (0.009)	Loss 2.3909 (2.3371)	Loss@kd 2.5317 (2.5704)	Acc@1 73.438 (80.245)	Acc@5 98.438 (99.635)
 * Acc@1 80.243 Acc@5 99.627
epoch 118, total time 392.48
Test: [0/750]	Time 0.843 (0.843)	Loss 0.4100 (0.4100)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.098 (0.114)	Loss 0.4083 (0.4865)	Acc@1 81.250 (86.200)	Acc@5 100.000 (95.606)
Test: [200/750]	Time 0.108 (0.112)	Loss 1.0654 (0.4835)	Acc@1 50.000 (84.826)	Acc@5 90.625 (96.626)
Test: [300/750]	Time 0.195 (0.110)	Loss 0.9779 (0.6675)	Acc@1 62.500 (76.765)	Acc@5 96.875 (95.764)
Test: [400/750]	Time 0.079 (0.109)	Loss 0.4683 (0.7631)	Acc@1 87.500 (72.615)	Acc@5 90.625 (95.238)
Test: [500/750]	Time 0.101 (0.108)	Loss 0.3723 (0.7368)	Acc@1 84.375 (74.114)	Acc@5 100.000 (95.029)
Test: [600/750]	Time 0.100 (0.108)	Loss 0.6550 (0.7401)	Acc@1 71.875 (74.236)	Acc@5 96.875 (95.008)
Test: [700/750]	Time 0.108 (0.108)	Loss 0.8643 (0.7356)	Acc@1 68.750 (74.198)	Acc@5 87.500 (95.145)
 * Acc@1 74.275 Acc@5 95.121
saving the best model!
==> training...
Epoch: [119][0/875]	Time 1.904 (1.904)	Data 1.347 (1.347)	Loss 2.8002 (2.8002)	Loss@kd 3.1481 (3.1481)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [119][100/875]	Time 0.556 (0.467)	Data 0.005 (0.020)	Loss 2.2456 (2.3377)	Loss@kd 2.4651 (2.5870)	Acc@1 78.125 (80.739)	Acc@5 100.000 (99.613)
Epoch: [119][200/875]	Time 0.462 (0.458)	Data 0.007 (0.014)	Loss 2.1190 (2.3279)	Loss@kd 2.5191 (2.5733)	Acc@1 89.062 (80.737)	Acc@5 100.000 (99.697)
Epoch: [119][300/875]	Time 0.449 (0.456)	Data 0.007 (0.011)	Loss 2.2401 (2.3391)	Loss@kd 2.5116 (2.5711)	Acc@1 81.250 (80.139)	Acc@5 100.000 (99.611)
Epoch: [119][400/875]	Time 0.456 (0.456)	Data 0.006 (0.010)	Loss 2.5254 (2.3329)	Loss@kd 2.8758 (2.5673)	Acc@1 82.812 (80.264)	Acc@5 100.000 (99.614)
Epoch: [119][500/875]	Time 0.445 (0.455)	Data 0.005 (0.010)	Loss 2.4457 (2.3372)	Loss@kd 2.6509 (2.5671)	Acc@1 73.438 (80.049)	Acc@5 100.000 (99.604)
Epoch: [119][600/875]	Time 0.454 (0.454)	Data 0.007 (0.009)	Loss 2.3764 (2.3345)	Loss@kd 2.6259 (2.5648)	Acc@1 82.812 (80.062)	Acc@5 98.438 (99.618)
Epoch: [119][700/875]	Time 0.416 (0.454)	Data 0.007 (0.009)	Loss 2.2873 (2.3369)	Loss@kd 2.5365 (2.5678)	Acc@1 82.812 (80.066)	Acc@5 100.000 (99.603)
Epoch: [119][800/875]	Time 0.421 (0.454)	Data 0.006 (0.009)	Loss 2.3325 (2.3351)	Loss@kd 2.4271 (2.5658)	Acc@1 75.000 (80.146)	Acc@5 100.000 (99.600)
 * Acc@1 80.162 Acc@5 99.605
epoch 119, total time 397.54
Test: [0/750]	Time 0.874 (0.874)	Loss 0.4474 (0.4474)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.072 (0.106)	Loss 0.4133 (0.5019)	Acc@1 81.250 (85.520)	Acc@5 100.000 (95.514)
Test: [200/750]	Time 0.108 (0.104)	Loss 1.1676 (0.4918)	Acc@1 53.125 (84.328)	Acc@5 93.750 (96.595)
Test: [300/750]	Time 0.093 (0.103)	Loss 0.9632 (0.6884)	Acc@1 65.625 (75.997)	Acc@5 90.625 (95.515)
Test: [400/750]	Time 0.112 (0.104)	Loss 0.4751 (0.7723)	Acc@1 87.500 (72.459)	Acc@5 90.625 (95.106)
Test: [500/750]	Time 0.074 (0.104)	Loss 0.4209 (0.7516)	Acc@1 81.250 (73.703)	Acc@5 100.000 (94.829)
Test: [600/750]	Time 0.080 (0.104)	Loss 0.6432 (0.7553)	Acc@1 75.000 (73.856)	Acc@5 96.875 (94.863)
Test: [700/750]	Time 0.093 (0.104)	Loss 0.9209 (0.7482)	Acc@1 62.500 (73.948)	Acc@5 87.500 (95.047)
 * Acc@1 73.992 Acc@5 95.033
==> training...
Epoch: [120][0/875]	Time 1.776 (1.776)	Data 1.320 (1.320)	Loss 2.2709 (2.2709)	Loss@kd 2.5615 (2.5615)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [120][100/875]	Time 0.434 (0.448)	Data 0.005 (0.020)	Loss 2.3474 (2.3409)	Loss@kd 2.5676 (2.5592)	Acc@1 85.938 (79.672)	Acc@5 100.000 (99.505)
Epoch: [120][200/875]	Time 0.421 (0.451)	Data 0.007 (0.013)	Loss 2.5126 (2.3533)	Loss@kd 2.5144 (2.5794)	Acc@1 76.562 (79.944)	Acc@5 98.438 (99.580)
Epoch: [120][300/875]	Time 0.453 (0.450)	Data 0.007 (0.011)	Loss 2.2417 (2.3428)	Loss@kd 2.6005 (2.5700)	Acc@1 84.375 (80.098)	Acc@5 100.000 (99.574)
Epoch: [120][400/875]	Time 0.543 (0.451)	Data 0.007 (0.010)	Loss 2.3745 (2.3348)	Loss@kd 2.5973 (2.5632)	Acc@1 75.000 (80.015)	Acc@5 100.000 (99.599)
Epoch: [120][500/875]	Time 0.467 (0.452)	Data 0.007 (0.009)	Loss 2.2335 (2.3364)	Loss@kd 2.5275 (2.5663)	Acc@1 85.938 (80.177)	Acc@5 100.000 (99.573)
Epoch: [120][600/875]	Time 0.420 (0.452)	Data 0.007 (0.009)	Loss 2.4062 (2.3324)	Loss@kd 2.5085 (2.5645)	Acc@1 75.000 (80.213)	Acc@5 98.438 (99.587)
Epoch: [120][700/875]	Time 0.461 (0.452)	Data 0.007 (0.009)	Loss 2.4693 (2.3340)	Loss@kd 2.7879 (2.5665)	Acc@1 85.938 (80.082)	Acc@5 100.000 (99.594)
Epoch: [120][800/875]	Time 0.463 (0.452)	Data 0.007 (0.009)	Loss 2.1952 (2.3344)	Loss@kd 2.5481 (2.5658)	Acc@1 84.375 (80.078)	Acc@5 100.000 (99.606)
 * Acc@1 80.061 Acc@5 99.611
epoch 120, total time 395.98
Test: [0/750]	Time 0.799 (0.799)	Loss 0.4888 (0.4888)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.096 (0.114)	Loss 0.4155 (0.4943)	Acc@1 78.125 (85.891)	Acc@5 100.000 (95.483)
Test: [200/750]	Time 0.095 (0.107)	Loss 1.0767 (0.4922)	Acc@1 53.125 (84.391)	Acc@5 93.750 (96.517)
Test: [300/750]	Time 0.084 (0.105)	Loss 0.9314 (0.6735)	Acc@1 62.500 (76.422)	Acc@5 96.875 (95.816)
Test: [400/750]	Time 0.095 (0.103)	Loss 0.7142 (0.7685)	Acc@1 75.000 (72.428)	Acc@5 90.625 (95.246)
Test: [500/750]	Time 0.103 (0.102)	Loss 0.4314 (0.7796)	Acc@1 84.375 (72.436)	Acc@5 100.000 (94.592)
Test: [600/750]	Time 0.106 (0.101)	Loss 0.6681 (0.7795)	Acc@1 75.000 (72.801)	Acc@5 96.875 (94.598)
Test: [700/750]	Time 0.086 (0.102)	Loss 1.0020 (0.7713)	Acc@1 62.500 (72.954)	Acc@5 87.500 (94.749)
 * Acc@1 73.079 Acc@5 94.725
==> Saving...
best accuracy: tensor(74.2750, device='cuda:1')
