==> loading teacher model
==> done
Test: [0/750]	Time 25.858 (25.858)	Loss 0.4634 (0.4634)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.062 (0.323)	Loss 0.5072 (0.4629)	Acc@1 84.375 (86.912)	Acc@5 96.875 (94.957)
Test: [200/750]	Time 0.065 (0.195)	Loss 1.2823 (0.4595)	Acc@1 50.000 (85.603)	Acc@5 93.750 (96.175)
Test: [300/750]	Time 0.065 (0.152)	Loss 1.0237 (0.6758)	Acc@1 65.625 (75.872)	Acc@5 93.750 (95.442)
Test: [400/750]	Time 0.059 (0.130)	Loss 0.5271 (0.7502)	Acc@1 84.375 (72.600)	Acc@5 87.500 (94.989)
Test: [500/750]	Time 0.048 (0.117)	Loss 0.5424 (0.7175)	Acc@1 75.000 (74.339)	Acc@5 100.000 (94.885)
Test: [600/750]	Time 0.062 (0.109)	Loss 0.7790 (0.7285)	Acc@1 68.750 (74.189)	Acc@5 93.750 (94.748)
Test: [700/750]	Time 0.068 (0.102)	Loss 0.7082 (0.7212)	Acc@1 68.750 (74.269)	Acc@5 96.875 (94.954)
 * Acc@1 74.571 Acc@5 94.971
teacher accuracy:  tensor(74.5708, device='cuda:0')
==> training...
Epoch: [1][0/875]	Time 2.891 (2.891)	Data 1.204 (1.204)	Loss 15.1926 (15.1926)	Loss@kd 13.1266 (13.1266)	Acc@1 12.500 (12.500)	Acc@5 75.000 (75.000)
Epoch: [1][100/875]	Time 0.527 (0.533)	Data 0.008 (0.019)	Loss 5.7278 (6.9516)	Loss@kd 4.2176 (5.2135)	Acc@1 31.250 (33.601)	Acc@5 90.625 (86.680)
Epoch: [1][200/875]	Time 0.509 (0.522)	Data 0.007 (0.013)	Loss 5.1646 (6.1876)	Loss@kd 3.7403 (4.5819)	Acc@1 43.750 (38.013)	Acc@5 95.312 (90.135)
Epoch: [1][300/875]	Time 0.528 (0.518)	Data 0.007 (0.011)	Loss 5.2816 (5.8625)	Loss@kd 3.8137 (4.3116)	Acc@1 45.312 (39.992)	Acc@5 90.625 (91.315)
Epoch: [1][400/875]	Time 0.499 (0.516)	Data 0.008 (0.010)	Loss 5.0720 (5.6675)	Loss@kd 3.6806 (4.1489)	Acc@1 43.750 (41.112)	Acc@5 92.188 (91.989)
Epoch: [1][500/875]	Time 0.509 (0.514)	Data 0.007 (0.010)	Loss 5.0676 (5.5393)	Loss@kd 3.5285 (4.0417)	Acc@1 32.812 (42.047)	Acc@5 93.750 (92.431)
Epoch: [1][600/875]	Time 0.522 (0.514)	Data 0.007 (0.009)	Loss 5.0345 (5.4409)	Loss@kd 3.4706 (3.9632)	Acc@1 39.062 (42.910)	Acc@5 93.750 (92.746)
Epoch: [1][700/875]	Time 0.496 (0.510)	Data 0.006 (0.009)	Loss 4.7210 (5.3612)	Loss@kd 3.5236 (3.8983)	Acc@1 54.688 (43.603)	Acc@5 93.750 (92.952)
Epoch: [1][800/875]	Time 0.505 (0.510)	Data 0.008 (0.009)	Loss 4.6886 (5.2944)	Loss@kd 3.3999 (3.8475)	Acc@1 57.812 (44.361)	Acc@5 92.188 (93.216)
 * Acc@1 44.652 Acc@5 93.355
epoch 1, total time 446.59
Test: [0/750]	Time 0.806 (0.806)	Loss 0.8396 (0.8396)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.026 (0.037)	Loss 0.9463 (0.7090)	Acc@1 59.375 (80.198)	Acc@5 96.875 (86.293)
Test: [200/750]	Time 0.027 (0.033)	Loss 2.1918 (0.8540)	Acc@1 9.375 (69.807)	Acc@5 50.000 (87.904)
Test: [300/750]	Time 0.019 (0.032)	Loss 1.7372 (1.1854)	Acc@1 12.500 (52.772)	Acc@5 90.625 (81.478)
Test: [400/750]	Time 0.022 (0.031)	Loss 1.1651 (1.2676)	Acc@1 59.375 (47.054)	Acc@5 90.625 (83.432)
Test: [500/750]	Time 0.038 (0.031)	Loss 1.4944 (1.2506)	Acc@1 50.000 (49.538)	Acc@5 75.000 (84.063)
Test: [600/750]	Time 0.022 (0.030)	Loss 1.2104 (1.2694)	Acc@1 53.125 (50.525)	Acc@5 81.250 (83.923)
Test: [700/750]	Time 0.031 (0.030)	Loss 1.3026 (1.2569)	Acc@1 56.250 (51.609)	Acc@5 78.125 (84.442)
 * Acc@1 52.171 Acc@5 84.496
saving the best model!
==> training...
Epoch: [2][0/875]	Time 1.706 (1.706)	Data 1.222 (1.222)	Loss 4.6399 (4.6399)	Loss@kd 3.3647 (3.3647)	Acc@1 46.875 (46.875)	Acc@5 98.438 (98.438)
Epoch: [2][100/875]	Time 0.524 (0.522)	Data 0.008 (0.019)	Loss 4.5311 (4.7502)	Loss@kd 3.3311 (3.4212)	Acc@1 48.438 (50.062)	Acc@5 100.000 (94.663)
Epoch: [2][200/875]	Time 0.496 (0.516)	Data 0.007 (0.013)	Loss 4.6118 (4.7253)	Loss@kd 3.2996 (3.4065)	Acc@1 46.875 (50.194)	Acc@5 98.438 (94.877)
Epoch: [2][300/875]	Time 0.487 (0.514)	Data 0.007 (0.011)	Loss 4.7580 (4.7095)	Loss@kd 3.3854 (3.3906)	Acc@1 43.750 (50.457)	Acc@5 98.438 (94.897)
Epoch: [2][400/875]	Time 0.523 (0.513)	Data 0.007 (0.010)	Loss 4.5574 (4.6924)	Loss@kd 3.3369 (3.3770)	Acc@1 56.250 (50.627)	Acc@5 95.312 (94.938)
Epoch: [2][500/875]	Time 0.497 (0.505)	Data 0.007 (0.010)	Loss 4.7578 (4.6810)	Loss@kd 3.2882 (3.3695)	Acc@1 48.438 (50.661)	Acc@5 93.750 (94.991)
Epoch: [2][600/875]	Time 0.494 (0.506)	Data 0.007 (0.009)	Loss 4.6467 (4.6659)	Loss@kd 3.1720 (3.3598)	Acc@1 53.125 (50.900)	Acc@5 90.625 (95.040)
Epoch: [2][700/875]	Time 0.514 (0.507)	Data 0.007 (0.009)	Loss 4.5827 (4.6544)	Loss@kd 3.2742 (3.3496)	Acc@1 45.312 (50.961)	Acc@5 92.188 (95.070)
Epoch: [2][800/875]	Time 0.495 (0.507)	Data 0.008 (0.009)	Loss 4.6531 (4.6390)	Loss@kd 3.2550 (3.3395)	Acc@1 40.625 (51.149)	Acc@5 92.188 (95.141)
 * Acc@1 51.314 Acc@5 95.193
epoch 2, total time 444.34
Test: [0/750]	Time 0.697 (0.697)	Loss 1.0658 (1.0658)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.025 (0.035)	Loss 0.5070 (0.9230)	Acc@1 84.375 (77.908)	Acc@5 93.750 (83.323)
Test: [200/750]	Time 0.034 (0.032)	Loss 2.2088 (0.8018)	Acc@1 9.375 (77.503)	Acc@5 53.125 (88.169)
Test: [300/750]	Time 0.043 (0.031)	Loss 1.7497 (1.1387)	Acc@1 18.750 (58.306)	Acc@5 87.500 (83.015)
Test: [400/750]	Time 0.042 (0.031)	Loss 0.7684 (1.2197)	Acc@1 81.250 (51.605)	Acc@5 93.750 (84.874)
Test: [500/750]	Time 0.026 (0.030)	Loss 1.6265 (1.1818)	Acc@1 40.625 (54.878)	Acc@5 75.000 (85.516)
Test: [600/750]	Time 0.033 (0.030)	Loss 1.2484 (1.2385)	Acc@1 53.125 (53.650)	Acc@5 90.625 (84.812)
Test: [700/750]	Time 0.022 (0.030)	Loss 1.1015 (1.2271)	Acc@1 68.750 (53.963)	Acc@5 84.375 (85.623)
 * Acc@1 54.888 Acc@5 85.804
saving the best model!
==> training...
Epoch: [3][0/875]	Time 1.842 (1.842)	Data 1.326 (1.326)	Loss 4.5137 (4.5137)	Loss@kd 3.1812 (3.1812)	Acc@1 51.562 (51.562)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.527 (0.523)	Data 0.008 (0.020)	Loss 4.4530 (4.4669)	Loss@kd 3.1900 (3.2079)	Acc@1 53.125 (53.373)	Acc@5 95.312 (95.452)
Epoch: [3][200/875]	Time 0.518 (0.517)	Data 0.007 (0.013)	Loss 4.4322 (4.4578)	Loss@kd 3.1537 (3.2037)	Acc@1 42.188 (53.358)	Acc@5 98.438 (95.460)
Epoch: [3][300/875]	Time 0.527 (0.503)	Data 0.007 (0.011)	Loss 4.2438 (4.4462)	Loss@kd 3.2048 (3.1938)	Acc@1 62.500 (53.421)	Acc@5 98.438 (95.468)
Epoch: [3][400/875]	Time 0.506 (0.505)	Data 0.006 (0.010)	Loss 4.8411 (4.4347)	Loss@kd 3.3286 (3.1898)	Acc@1 51.562 (53.713)	Acc@5 90.625 (95.542)
Epoch: [3][500/875]	Time 0.509 (0.506)	Data 0.005 (0.010)	Loss 4.4260 (4.4209)	Loss@kd 3.2332 (3.1815)	Acc@1 60.938 (53.861)	Acc@5 96.875 (95.581)
Epoch: [3][600/875]	Time 0.514 (0.507)	Data 0.007 (0.009)	Loss 4.3661 (4.4116)	Loss@kd 3.1390 (3.1743)	Acc@1 53.125 (53.921)	Acc@5 96.875 (95.593)
Epoch: [3][700/875]	Time 0.534 (0.507)	Data 0.007 (0.009)	Loss 4.3633 (4.4033)	Loss@kd 3.0985 (3.1671)	Acc@1 45.312 (53.865)	Acc@5 95.312 (95.667)
Epoch: [3][800/875]	Time 0.523 (0.508)	Data 0.006 (0.009)	Loss 4.2537 (4.3929)	Loss@kd 3.0020 (3.1583)	Acc@1 51.562 (53.938)	Acc@5 96.875 (95.710)
 * Acc@1 54.123 Acc@5 95.745
epoch 3, total time 444.73
Test: [0/750]	Time 0.687 (0.687)	Loss 0.7667 (0.7667)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.026 (0.036)	Loss 1.1656 (0.6426)	Acc@1 53.125 (80.600)	Acc@5 87.500 (87.407)
Test: [200/750]	Time 0.021 (0.033)	Loss 1.4418 (0.8916)	Acc@1 46.875 (68.252)	Acc@5 81.250 (87.780)
Test: [300/750]	Time 0.042 (0.032)	Loss 1.4834 (1.0167)	Acc@1 15.625 (62.199)	Acc@5 93.750 (89.649)
Test: [400/750]	Time 0.025 (0.031)	Loss 1.1907 (1.1228)	Acc@1 56.250 (54.707)	Acc@5 81.250 (89.300)
Test: [500/750]	Time 0.040 (0.031)	Loss 1.0869 (1.1424)	Acc@1 65.625 (55.520)	Acc@5 84.375 (87.662)
Test: [600/750]	Time 0.017 (0.030)	Loss 1.3294 (1.1539)	Acc@1 53.125 (56.432)	Acc@5 84.375 (87.313)
Test: [700/750]	Time 0.019 (0.029)	Loss 1.2870 (1.1628)	Acc@1 46.875 (56.361)	Acc@5 81.250 (86.983)
 * Acc@1 56.712 Acc@5 86.938
saving the best model!
==> training...
Epoch: [4][0/875]	Time 1.756 (1.756)	Data 1.295 (1.295)	Loss 4.4509 (4.4509)	Loss@kd 3.1789 (3.1789)	Acc@1 48.438 (48.438)	Acc@5 95.312 (95.312)
Epoch: [4][100/875]	Time 0.526 (0.503)	Data 0.007 (0.020)	Loss 4.3710 (4.2597)	Loss@kd 3.1501 (3.0620)	Acc@1 59.375 (56.080)	Acc@5 95.312 (95.746)
Epoch: [4][200/875]	Time 0.504 (0.506)	Data 0.007 (0.013)	Loss 4.1409 (4.2399)	Loss@kd 2.9217 (3.0451)	Acc@1 56.250 (56.025)	Acc@5 98.438 (95.896)
Epoch: [4][300/875]	Time 0.498 (0.507)	Data 0.007 (0.011)	Loss 4.1022 (4.2321)	Loss@kd 3.0191 (3.0428)	Acc@1 56.250 (56.125)	Acc@5 96.875 (96.086)
Epoch: [4][400/875]	Time 0.499 (0.508)	Data 0.007 (0.010)	Loss 4.2345 (4.2257)	Loss@kd 2.9982 (3.0397)	Acc@1 56.250 (56.110)	Acc@5 93.750 (96.189)
Epoch: [4][500/875]	Time 0.502 (0.508)	Data 0.006 (0.010)	Loss 4.4309 (4.2136)	Loss@kd 3.0504 (3.0317)	Acc@1 50.000 (56.331)	Acc@5 92.188 (96.267)
Epoch: [4][600/875]	Time 0.525 (0.508)	Data 0.010 (0.009)	Loss 4.0699 (4.2089)	Loss@kd 2.9184 (3.0269)	Acc@1 53.125 (56.263)	Acc@5 96.875 (96.241)
Epoch: [4][700/875]	Time 0.477 (0.508)	Data 0.008 (0.009)	Loss 4.1865 (4.2022)	Loss@kd 3.0825 (3.0225)	Acc@1 57.812 (56.230)	Acc@5 95.312 (96.300)
Epoch: [4][800/875]	Time 0.524 (0.506)	Data 0.007 (0.009)	Loss 4.2022 (4.1956)	Loss@kd 2.9294 (3.0152)	Acc@1 60.938 (56.232)	Acc@5 92.188 (96.257)
 * Acc@1 56.316 Acc@5 96.252
epoch 4, total time 443.22
Test: [0/750]	Time 0.677 (0.677)	Loss 0.7282 (0.7282)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.016 (0.032)	Loss 0.7131 (0.5611)	Acc@1 68.750 (83.137)	Acc@5 100.000 (89.047)
Test: [200/750]	Time 0.025 (0.028)	Loss 1.4739 (0.6673)	Acc@1 40.625 (77.814)	Acc@5 90.625 (91.480)
Test: [300/750]	Time 0.016 (0.027)	Loss 2.7350 (0.9715)	Acc@1 0.000 (65.864)	Acc@5 34.375 (88.746)
Test: [400/750]	Time 0.022 (0.027)	Loss 0.5947 (1.2864)	Acc@1 84.375 (55.065)	Acc@5 96.875 (79.458)
Test: [500/750]	Time 0.018 (0.027)	Loss 0.6695 (1.1613)	Acc@1 75.000 (60.030)	Acc@5 100.000 (82.660)
Test: [600/750]	Time 0.028 (0.027)	Loss 1.2929 (1.1300)	Acc@1 56.250 (61.080)	Acc@5 87.500 (84.593)
Test: [700/750]	Time 0.020 (0.026)	Loss 1.8525 (1.1880)	Acc@1 21.875 (57.980)	Acc@5 71.875 (84.634)
 * Acc@1 56.471 Acc@5 83.921
==> training...
Epoch: [5][0/875]	Time 1.898 (1.898)	Data 1.364 (1.364)	Loss 4.0158 (4.0158)	Loss@kd 2.9659 (2.9659)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [5][100/875]	Time 0.502 (0.523)	Data 0.007 (0.021)	Loss 4.4051 (4.1026)	Loss@kd 3.0345 (2.9418)	Acc@1 50.000 (56.853)	Acc@5 92.188 (96.627)
Epoch: [5][200/875]	Time 0.503 (0.517)	Data 0.007 (0.014)	Loss 3.9532 (4.0914)	Loss@kd 2.8976 (2.9370)	Acc@1 60.938 (57.416)	Acc@5 95.312 (96.362)
Epoch: [5][300/875]	Time 0.513 (0.515)	Data 0.006 (0.012)	Loss 3.8680 (4.0905)	Loss@kd 2.8725 (2.9424)	Acc@1 60.938 (57.615)	Acc@5 100.000 (96.449)
Epoch: [5][400/875]	Time 0.503 (0.514)	Data 0.007 (0.011)	Loss 4.1899 (4.0840)	Loss@kd 2.8629 (2.9366)	Acc@1 45.312 (57.493)	Acc@5 95.312 (96.435)
Epoch: [5][500/875]	Time 0.461 (0.510)	Data 0.007 (0.010)	Loss 3.8878 (4.0742)	Loss@kd 2.9762 (2.9295)	Acc@1 71.875 (57.607)	Acc@5 98.438 (96.476)
Epoch: [5][600/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss 4.3135 (4.0677)	Loss@kd 2.9592 (2.9242)	Acc@1 59.375 (57.688)	Acc@5 92.188 (96.441)
Epoch: [5][700/875]	Time 0.499 (0.508)	Data 0.007 (0.009)	Loss 3.8567 (4.0616)	Loss@kd 2.8421 (2.9176)	Acc@1 59.375 (57.665)	Acc@5 100.000 (96.416)
Epoch: [5][800/875]	Time 0.532 (0.508)	Data 0.007 (0.009)	Loss 3.9870 (4.0564)	Loss@kd 2.8365 (2.9123)	Acc@1 57.812 (57.658)	Acc@5 95.312 (96.430)
 * Acc@1 57.673 Acc@5 96.438
epoch 5, total time 445.27
Test: [0/750]	Time 0.715 (0.715)	Loss 1.1651 (1.1651)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.024 (0.037)	Loss 0.8906 (1.0031)	Acc@1 68.750 (76.361)	Acc@5 93.750 (84.066)
Test: [200/750]	Time 0.035 (0.033)	Loss 1.9544 (0.9635)	Acc@1 18.750 (70.320)	Acc@5 71.875 (87.547)
Test: [300/750]	Time 0.018 (0.032)	Loss 0.9924 (1.1403)	Acc@1 62.500 (57.953)	Acc@5 100.000 (87.562)
Test: [400/750]	Time 0.041 (0.031)	Loss 0.7283 (1.1107)	Acc@1 81.250 (58.596)	Acc@5 93.750 (89.542)
Test: [500/750]	Time 0.025 (0.031)	Loss 1.2712 (1.0777)	Acc@1 53.125 (61.271)	Acc@5 78.125 (88.860)
Test: [600/750]	Time 0.034 (0.031)	Loss 1.0558 (1.1107)	Acc@1 56.250 (60.971)	Acc@5 93.750 (88.030)
Test: [700/750]	Time 0.025 (0.031)	Loss 1.2358 (1.1205)	Acc@1 50.000 (59.772)	Acc@5 87.500 (88.209)
 * Acc@1 59.200 Acc@5 88.371
saving the best model!
==> training...
Epoch: [6][0/875]	Time 1.821 (1.821)	Data 1.317 (1.317)	Loss 4.1951 (4.1951)	Loss@kd 2.8686 (2.8686)	Acc@1 53.125 (53.125)	Acc@5 95.312 (95.312)
Epoch: [6][100/875]	Time 0.525 (0.524)	Data 0.005 (0.020)	Loss 3.9338 (3.9535)	Loss@kd 2.8240 (2.8404)	Acc@1 56.250 (58.663)	Acc@5 96.875 (97.030)
Epoch: [6][200/875]	Time 0.491 (0.517)	Data 0.005 (0.013)	Loss 3.9914 (3.9569)	Loss@kd 2.8341 (2.8387)	Acc@1 56.250 (58.225)	Acc@5 96.875 (96.751)
Epoch: [6][300/875]	Time 0.504 (0.507)	Data 0.006 (0.011)	Loss 3.8929 (3.9631)	Loss@kd 2.8034 (2.8408)	Acc@1 57.812 (58.082)	Acc@5 96.875 (96.621)
Epoch: [6][400/875]	Time 0.497 (0.508)	Data 0.007 (0.010)	Loss 3.8466 (3.9534)	Loss@kd 2.8510 (2.8386)	Acc@1 60.938 (58.346)	Acc@5 96.875 (96.750)
Epoch: [6][500/875]	Time 0.524 (0.508)	Data 0.007 (0.010)	Loss 3.9766 (3.9505)	Loss@kd 2.8578 (2.8352)	Acc@1 64.062 (58.549)	Acc@5 95.312 (96.710)
Epoch: [6][600/875]	Time 0.513 (0.509)	Data 0.007 (0.009)	Loss 4.2038 (3.9491)	Loss@kd 2.9615 (2.8323)	Acc@1 56.250 (58.522)	Acc@5 95.312 (96.644)
Epoch: [6][700/875]	Time 0.494 (0.509)	Data 0.007 (0.009)	Loss 4.0006 (3.9455)	Loss@kd 2.9114 (2.8299)	Acc@1 62.500 (58.590)	Acc@5 98.438 (96.652)
Epoch: [6][800/875]	Time 0.528 (0.509)	Data 0.007 (0.009)	Loss 3.9394 (3.9409)	Loss@kd 2.7658 (2.8246)	Acc@1 62.500 (58.622)	Acc@5 95.312 (96.631)
 * Acc@1 58.700 Acc@5 96.641
epoch 6, total time 445.85
Test: [0/750]	Time 0.717 (0.717)	Loss 0.6791 (0.6791)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.025 (0.035)	Loss 0.7632 (0.6126)	Acc@1 81.250 (81.405)	Acc@5 96.875 (89.666)
Test: [200/750]	Time 0.021 (0.033)	Loss 2.2328 (0.7744)	Acc@1 18.750 (75.326)	Acc@5 78.125 (90.376)
Test: [300/750]	Time 0.024 (0.032)	Loss 2.2557 (1.2099)	Acc@1 3.125 (56.561)	Acc@5 93.750 (88.870)
Test: [400/750]	Time 0.026 (0.031)	Loss 0.1090 (1.3462)	Acc@1 100.000 (50.382)	Acc@5 100.000 (87.968)
Test: [500/750]	Time 0.032 (0.030)	Loss 1.4959 (1.1841)	Acc@1 53.125 (57.479)	Acc@5 84.375 (89.427)
Test: [600/750]	Time 0.023 (0.030)	Loss 1.6923 (1.2376)	Acc@1 43.750 (56.224)	Acc@5 78.125 (88.498)
Test: [700/750]	Time 0.033 (0.030)	Loss 2.2027 (1.3139)	Acc@1 25.000 (53.219)	Acc@5 71.875 (87.126)
 * Acc@1 51.829 Acc@5 86.362
==> training...
Epoch: [7][0/875]	Time 1.814 (1.814)	Data 1.319 (1.319)	Loss 3.6698 (3.6698)	Loss@kd 2.6850 (2.6850)	Acc@1 57.812 (57.812)	Acc@5 98.438 (98.438)
Epoch: [7][100/875]	Time 0.503 (0.499)	Data 0.008 (0.020)	Loss 3.8414 (3.8680)	Loss@kd 2.7000 (2.7757)	Acc@1 56.250 (59.638)	Acc@5 100.000 (96.921)
Epoch: [7][200/875]	Time 0.497 (0.505)	Data 0.006 (0.014)	Loss 3.8297 (3.8616)	Loss@kd 2.8887 (2.7723)	Acc@1 65.625 (59.958)	Acc@5 95.312 (96.603)
Epoch: [7][300/875]	Time 0.490 (0.507)	Data 0.008 (0.012)	Loss 4.1183 (3.8703)	Loss@kd 2.8105 (2.7735)	Acc@1 56.250 (59.873)	Acc@5 90.625 (96.652)
Epoch: [7][400/875]	Time 0.495 (0.508)	Data 0.007 (0.011)	Loss 3.8461 (3.8648)	Loss@kd 2.7566 (2.7690)	Acc@1 57.812 (59.889)	Acc@5 100.000 (96.672)
Epoch: [7][500/875]	Time 0.521 (0.508)	Data 0.007 (0.010)	Loss 4.2070 (3.8618)	Loss@kd 2.8914 (2.7657)	Acc@1 48.438 (59.774)	Acc@5 95.312 (96.707)
Epoch: [7][600/875]	Time 0.525 (0.508)	Data 0.008 (0.010)	Loss 4.0065 (3.8558)	Loss@kd 2.7558 (2.7607)	Acc@1 56.250 (59.752)	Acc@5 96.875 (96.771)
Epoch: [7][700/875]	Time 0.518 (0.509)	Data 0.007 (0.009)	Loss 3.7362 (3.8488)	Loss@kd 2.7927 (2.7552)	Acc@1 60.938 (59.665)	Acc@5 100.000 (96.828)
Epoch: [7][800/875]	Time 0.526 (0.506)	Data 0.008 (0.009)	Loss 4.0038 (3.8437)	Loss@kd 2.7092 (2.7504)	Acc@1 56.250 (59.632)	Acc@5 92.188 (96.826)
 * Acc@1 59.562 Acc@5 96.839
epoch 7, total time 442.94
Test: [0/750]	Time 0.662 (0.662)	Loss 0.6996 (0.6996)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.026 (0.031)	Loss 0.4886 (0.5342)	Acc@1 87.500 (83.849)	Acc@5 96.875 (90.347)
Test: [200/750]	Time 0.017 (0.029)	Loss 2.5103 (0.6197)	Acc@1 6.250 (78.996)	Acc@5 53.125 (91.247)
Test: [300/750]	Time 0.034 (0.029)	Loss 1.4202 (1.1124)	Acc@1 34.375 (56.977)	Acc@5 93.750 (82.537)
Test: [400/750]	Time 0.021 (0.028)	Loss 1.1695 (1.1828)	Acc@1 53.125 (52.587)	Acc@5 84.375 (84.507)
Test: [500/750]	Time 0.025 (0.027)	Loss 0.7159 (1.1749)	Acc@1 78.125 (54.691)	Acc@5 90.625 (84.444)
Test: [600/750]	Time 0.040 (0.027)	Loss 0.7959 (1.1279)	Acc@1 68.750 (57.540)	Acc@5 96.875 (85.909)
Test: [700/750]	Time 0.016 (0.027)	Loss 0.9797 (1.0958)	Acc@1 68.750 (58.969)	Acc@5 87.500 (87.397)
 * Acc@1 60.146 Acc@5 87.817
saving the best model!
==> training...
Epoch: [8][0/875]	Time 1.837 (1.837)	Data 1.337 (1.337)	Loss 3.9489 (3.9489)	Loss@kd 2.7595 (2.7595)	Acc@1 60.938 (60.938)	Acc@5 95.312 (95.312)
Epoch: [8][100/875]	Time 0.503 (0.524)	Data 0.007 (0.021)	Loss 3.4846 (3.7496)	Loss@kd 2.6855 (2.7073)	Acc@1 68.750 (61.139)	Acc@5 98.438 (97.262)
Epoch: [8][200/875]	Time 0.497 (0.517)	Data 0.007 (0.014)	Loss 4.0064 (3.7686)	Loss@kd 2.7240 (2.6977)	Acc@1 54.688 (60.238)	Acc@5 100.000 (96.836)
Epoch: [8][300/875]	Time 0.528 (0.515)	Data 0.010 (0.012)	Loss 3.7685 (3.7654)	Loss@kd 2.5887 (2.6958)	Acc@1 59.375 (60.299)	Acc@5 95.312 (96.880)
Epoch: [8][400/875]	Time 0.496 (0.514)	Data 0.007 (0.011)	Loss 3.6783 (3.7698)	Loss@kd 2.5911 (2.6952)	Acc@1 56.250 (60.279)	Acc@5 100.000 (96.933)
Epoch: [8][500/875]	Time 0.507 (0.513)	Data 0.007 (0.010)	Loss 3.8663 (3.7661)	Loss@kd 2.7783 (2.6927)	Acc@1 67.188 (60.385)	Acc@5 98.438 (96.969)
Epoch: [8][600/875]	Time 0.531 (0.507)	Data 0.008 (0.010)	Loss 3.6577 (3.7596)	Loss@kd 2.6627 (2.6893)	Acc@1 68.750 (60.503)	Acc@5 98.438 (96.995)
Epoch: [8][700/875]	Time 0.496 (0.508)	Data 0.007 (0.009)	Loss 3.6640 (3.7558)	Loss@kd 2.5887 (2.6854)	Acc@1 62.500 (60.585)	Acc@5 96.875 (96.989)
Epoch: [8][800/875]	Time 0.515 (0.508)	Data 0.008 (0.009)	Loss 3.7448 (3.7517)	Loss@kd 2.6317 (2.6817)	Acc@1 59.375 (60.575)	Acc@5 98.438 (97.002)
 * Acc@1 60.466 Acc@5 97.014
epoch 8, total time 445.22
Test: [0/750]	Time 0.695 (0.695)	Loss 0.6057 (0.6057)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.021 (0.034)	Loss 0.5690 (0.5452)	Acc@1 84.375 (82.704)	Acc@5 100.000 (90.532)
Test: [200/750]	Time 0.025 (0.032)	Loss 1.8784 (0.5988)	Acc@1 25.000 (78.762)	Acc@5 71.875 (93.221)
Test: [300/750]	Time 0.039 (0.031)	Loss 1.0866 (0.8985)	Acc@1 53.125 (64.711)	Acc@5 93.750 (91.684)
Test: [400/750]	Time 0.020 (0.031)	Loss 1.5999 (1.0075)	Acc@1 53.125 (59.648)	Acc@5 87.500 (91.311)
Test: [500/750]	Time 0.029 (0.030)	Loss 1.3388 (1.1452)	Acc@1 59.375 (56.649)	Acc@5 78.125 (88.186)
Test: [600/750]	Time 0.028 (0.030)	Loss 0.7182 (1.1696)	Acc@1 78.125 (57.524)	Acc@5 93.750 (87.469)
Test: [700/750]	Time 0.034 (0.030)	Loss 0.9796 (1.1262)	Acc@1 62.500 (58.911)	Acc@5 90.625 (88.521)
 * Acc@1 59.688 Acc@5 88.942
==> training...
Epoch: [9][0/875]	Time 1.853 (1.853)	Data 1.333 (1.333)	Loss 3.6174 (3.6174)	Loss@kd 2.5542 (2.5542)	Acc@1 62.500 (62.500)	Acc@5 95.312 (95.312)
Epoch: [9][100/875]	Time 0.496 (0.523)	Data 0.008 (0.020)	Loss 3.5696 (3.7165)	Loss@kd 2.5862 (2.6657)	Acc@1 60.938 (61.510)	Acc@5 96.875 (96.860)
Epoch: [9][200/875]	Time 0.528 (0.517)	Data 0.008 (0.014)	Loss 3.6014 (3.7062)	Loss@kd 2.6197 (2.6511)	Acc@1 64.062 (61.241)	Acc@5 98.438 (96.945)
Epoch: [9][300/875]	Time 0.465 (0.511)	Data 0.008 (0.012)	Loss 3.8045 (3.6876)	Loss@kd 2.7166 (2.6398)	Acc@1 64.062 (61.259)	Acc@5 96.875 (97.192)
Epoch: [9][400/875]	Time 0.495 (0.507)	Data 0.008 (0.011)	Loss 3.5015 (3.6780)	Loss@kd 2.6686 (2.6314)	Acc@1 73.438 (61.167)	Acc@5 96.875 (97.245)
Epoch: [9][500/875]	Time 0.524 (0.508)	Data 0.010 (0.010)	Loss 3.4922 (3.6772)	Loss@kd 2.5904 (2.6295)	Acc@1 68.750 (61.243)	Acc@5 96.875 (97.199)
Epoch: [9][600/875]	Time 0.510 (0.508)	Data 0.008 (0.010)	Loss 3.6686 (3.6736)	Loss@kd 2.6582 (2.6281)	Acc@1 62.500 (61.408)	Acc@5 96.875 (97.182)
Epoch: [9][700/875]	Time 0.525 (0.509)	Data 0.008 (0.009)	Loss 3.8225 (3.6717)	Loss@kd 2.6913 (2.6243)	Acc@1 56.250 (61.354)	Acc@5 98.438 (97.218)
Epoch: [9][800/875]	Time 0.503 (0.509)	Data 0.007 (0.009)	Loss 3.8164 (3.6712)	Loss@kd 2.6546 (2.6223)	Acc@1 53.125 (61.343)	Acc@5 95.312 (97.197)
 * Acc@1 61.307 Acc@5 97.202
epoch 9, total time 445.63
Test: [0/750]	Time 0.697 (0.697)	Loss 0.6891 (0.6891)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.023 (0.035)	Loss 0.2831 (0.6094)	Acc@1 90.625 (82.519)	Acc@5 100.000 (89.078)
Test: [200/750]	Time 0.025 (0.032)	Loss 2.3286 (0.5479)	Acc@1 12.500 (82.727)	Acc@5 56.250 (92.133)
Test: [300/750]	Time 0.036 (0.031)	Loss 1.7786 (1.0200)	Acc@1 31.250 (62.915)	Acc@5 71.875 (85.050)
Test: [400/750]	Time 0.037 (0.031)	Loss 0.4573 (1.1363)	Acc@1 84.375 (57.622)	Acc@5 100.000 (84.391)
Test: [500/750]	Time 0.028 (0.030)	Loss 1.1376 (1.0588)	Acc@1 56.250 (61.645)	Acc@5 90.625 (86.184)
Test: [600/750]	Time 0.037 (0.030)	Loss 0.8792 (1.0850)	Acc@1 59.375 (60.571)	Acc@5 96.875 (86.990)
Test: [700/750]	Time 0.027 (0.030)	Loss 1.5311 (1.0985)	Acc@1 53.125 (59.313)	Acc@5 75.000 (87.620)
 * Acc@1 59.321 Acc@5 87.292
==> training...
Epoch: [10][0/875]	Time 1.871 (1.871)	Data 1.321 (1.321)	Loss 3.4347 (3.4347)	Loss@kd 2.6593 (2.6593)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [10][100/875]	Time 0.447 (0.504)	Data 0.007 (0.020)	Loss 3.6168 (3.6293)	Loss@kd 2.5077 (2.5720)	Acc@1 57.812 (61.139)	Acc@5 96.875 (96.813)
Epoch: [10][200/875]	Time 0.495 (0.505)	Data 0.008 (0.013)	Loss 3.6322 (3.6389)	Loss@kd 2.5700 (2.5904)	Acc@1 56.250 (61.738)	Acc@5 96.875 (97.023)
Epoch: [10][300/875]	Time 0.519 (0.507)	Data 0.007 (0.011)	Loss 3.6658 (3.6273)	Loss@kd 2.6606 (2.5875)	Acc@1 67.188 (62.163)	Acc@5 96.875 (97.155)
Epoch: [10][400/875]	Time 0.529 (0.507)	Data 0.007 (0.010)	Loss 3.7298 (3.6238)	Loss@kd 2.5635 (2.5856)	Acc@1 59.375 (62.165)	Acc@5 93.750 (97.171)
Epoch: [10][500/875]	Time 0.497 (0.508)	Data 0.010 (0.010)	Loss 3.5853 (3.6237)	Loss@kd 2.5738 (2.5827)	Acc@1 57.812 (61.864)	Acc@5 96.875 (97.221)
Epoch: [10][600/875]	Time 0.499 (0.508)	Data 0.007 (0.009)	Loss 3.3564 (3.6211)	Loss@kd 2.4719 (2.5803)	Acc@1 70.312 (61.827)	Acc@5 98.438 (97.234)
Epoch: [10][700/875]	Time 0.519 (0.509)	Data 0.009 (0.009)	Loss 3.5314 (3.6154)	Loss@kd 2.6462 (2.5764)	Acc@1 71.875 (61.952)	Acc@5 98.438 (97.265)
Epoch: [10][800/875]	Time 0.462 (0.506)	Data 0.007 (0.009)	Loss 3.6712 (3.6118)	Loss@kd 2.5532 (2.5746)	Acc@1 54.688 (62.012)	Acc@5 95.312 (97.285)
 * Acc@1 61.954 Acc@5 97.289
epoch 10, total time 442.42
Test: [0/750]	Time 0.705 (0.705)	Loss 0.6060 (0.6060)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.036 (0.035)	Loss 0.4944 (0.5076)	Acc@1 87.500 (83.632)	Acc@5 93.750 (91.151)
Test: [200/750]	Time 0.034 (0.031)	Loss 1.9531 (0.5608)	Acc@1 15.625 (81.188)	Acc@5 75.000 (92.973)
Test: [300/750]	Time 0.022 (0.030)	Loss 1.1471 (0.9065)	Acc@1 65.625 (65.282)	Acc@5 100.000 (90.781)
Test: [400/750]	Time 0.039 (0.030)	Loss 0.8787 (0.9844)	Acc@1 68.750 (61.050)	Acc@5 90.625 (91.272)
Test: [500/750]	Time 0.032 (0.030)	Loss 0.6260 (0.9673)	Acc@1 81.250 (62.874)	Acc@5 96.875 (90.781)
Test: [600/750]	Time 0.020 (0.029)	Loss 1.0575 (0.9663)	Acc@1 59.375 (63.566)	Acc@5 90.625 (90.781)
Test: [700/750]	Time 0.018 (0.029)	Loss 0.9316 (0.9721)	Acc@1 68.750 (63.209)	Acc@5 90.625 (91.147)
 * Acc@1 64.042 Acc@5 91.279
saving the best model!
==> training...
Epoch: [11][0/875]	Time 1.856 (1.856)	Data 1.361 (1.361)	Loss 3.3411 (3.3411)	Loss@kd 2.3598 (2.3598)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [11][100/875]	Time 0.494 (0.522)	Data 0.007 (0.021)	Loss 3.6435 (3.5565)	Loss@kd 2.6039 (2.5361)	Acc@1 57.812 (62.546)	Acc@5 98.438 (97.463)
Epoch: [11][200/875]	Time 0.525 (0.516)	Data 0.008 (0.014)	Loss 3.7061 (3.5464)	Loss@kd 2.4993 (2.5372)	Acc@1 56.250 (63.052)	Acc@5 98.438 (97.559)
Epoch: [11][300/875]	Time 0.502 (0.514)	Data 0.008 (0.012)	Loss 3.4680 (3.5544)	Loss@kd 2.4617 (2.5389)	Acc@1 60.938 (62.687)	Acc@5 100.000 (97.508)
Epoch: [11][400/875]	Time 0.498 (0.513)	Data 0.007 (0.011)	Loss 3.6309 (3.5607)	Loss@kd 2.4710 (2.5383)	Acc@1 64.062 (62.484)	Acc@5 92.188 (97.456)
Epoch: [11][500/875]	Time 0.520 (0.513)	Data 0.007 (0.010)	Loss 3.5324 (3.5564)	Loss@kd 2.4639 (2.5345)	Acc@1 62.500 (62.544)	Acc@5 95.312 (97.474)
Epoch: [11][600/875]	Time 0.494 (0.508)	Data 0.007 (0.010)	Loss 3.5182 (3.5509)	Loss@kd 2.5174 (2.5306)	Acc@1 67.188 (62.552)	Acc@5 96.875 (97.478)
Epoch: [11][700/875]	Time 0.486 (0.508)	Data 0.008 (0.009)	Loss 3.6991 (3.5474)	Loss@kd 2.6880 (2.5291)	Acc@1 62.500 (62.549)	Acc@5 96.875 (97.517)
Epoch: [11][800/875]	Time 0.497 (0.508)	Data 0.010 (0.009)	Loss 3.4990 (3.5459)	Loss@kd 2.5497 (2.5275)	Acc@1 59.375 (62.560)	Acc@5 100.000 (97.460)
 * Acc@1 62.552 Acc@5 97.439
epoch 11, total time 445.04
Test: [0/750]	Time 0.733 (0.733)	Loss 0.6774 (0.6774)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.031 (0.032)	Loss 0.3380 (0.5835)	Acc@1 90.625 (83.045)	Acc@5 100.000 (89.109)
Test: [200/750]	Time 0.017 (0.029)	Loss 1.6928 (0.5260)	Acc@1 40.625 (83.598)	Acc@5 81.250 (93.330)
Test: [300/750]	Time 0.040 (0.028)	Loss 1.7447 (0.8359)	Acc@1 21.875 (70.193)	Acc@5 78.125 (91.373)
Test: [400/750]	Time 0.033 (0.027)	Loss 0.9259 (1.0177)	Acc@1 68.750 (62.391)	Acc@5 81.250 (88.911)
Test: [500/750]	Time 0.020 (0.027)	Loss 0.8893 (0.9963)	Acc@1 68.750 (63.985)	Acc@5 100.000 (88.617)
Test: [600/750]	Time 0.028 (0.027)	Loss 0.7256 (1.0036)	Acc@1 75.000 (63.878)	Acc@5 96.875 (89.408)
Test: [700/750]	Time 0.027 (0.026)	Loss 1.6906 (1.0163)	Acc@1 40.625 (63.044)	Acc@5 75.000 (89.845)
 * Acc@1 62.425 Acc@5 89.571
==> training...
Epoch: [12][0/875]	Time 1.782 (1.782)	Data 1.293 (1.293)	Loss 3.4214 (3.4214)	Loss@kd 2.4581 (2.4581)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [12][100/875]	Time 0.502 (0.523)	Data 0.007 (0.019)	Loss 3.5321 (3.4992)	Loss@kd 2.4458 (2.4943)	Acc@1 57.812 (63.119)	Acc@5 98.438 (97.478)
Epoch: [12][200/875]	Time 0.506 (0.516)	Data 0.006 (0.013)	Loss 3.3532 (3.5058)	Loss@kd 2.4300 (2.4958)	Acc@1 70.312 (62.865)	Acc@5 100.000 (97.466)
Epoch: [12][300/875]	Time 0.512 (0.514)	Data 0.007 (0.011)	Loss 3.4685 (3.5140)	Loss@kd 2.4958 (2.5012)	Acc@1 64.062 (62.588)	Acc@5 98.438 (97.441)
Epoch: [12][400/875]	Time 0.498 (0.507)	Data 0.006 (0.010)	Loss 3.4253 (3.5063)	Loss@kd 2.4592 (2.4994)	Acc@1 71.875 (62.816)	Acc@5 98.438 (97.428)
Epoch: [12][500/875]	Time 0.526 (0.508)	Data 0.008 (0.010)	Loss 3.2739 (3.5059)	Loss@kd 2.3618 (2.4953)	Acc@1 71.875 (62.818)	Acc@5 100.000 (97.377)
Epoch: [12][600/875]	Time 0.499 (0.508)	Data 0.005 (0.009)	Loss 3.3369 (3.4953)	Loss@kd 2.3859 (2.4890)	Acc@1 68.750 (63.020)	Acc@5 98.438 (97.398)
Epoch: [12][700/875]	Time 0.504 (0.508)	Data 0.008 (0.009)	Loss 3.2176 (3.4917)	Loss@kd 2.4548 (2.4873)	Acc@1 79.688 (63.144)	Acc@5 98.438 (97.374)
Epoch: [12][800/875]	Time 0.502 (0.508)	Data 0.006 (0.009)	Loss 3.5094 (3.4880)	Loss@kd 2.5212 (2.4836)	Acc@1 59.375 (63.113)	Acc@5 98.438 (97.388)
 * Acc@1 63.062 Acc@5 97.405
epoch 12, total time 445.31
Test: [0/750]	Time 0.728 (0.728)	Loss 0.7810 (0.7810)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.038 (0.036)	Loss 0.4680 (0.5772)	Acc@1 78.125 (83.849)	Acc@5 100.000 (90.254)
Test: [200/750]	Time 0.026 (0.033)	Loss 2.4635 (0.5979)	Acc@1 3.125 (80.379)	Acc@5 62.500 (93.019)
Test: [300/750]	Time 0.026 (0.031)	Loss 0.7650 (1.0160)	Acc@1 71.875 (60.569)	Acc@5 100.000 (89.628)
Test: [400/750]	Time 0.041 (0.031)	Loss 1.4424 (1.0326)	Acc@1 59.375 (61.518)	Acc@5 84.375 (90.251)
Test: [500/750]	Time 0.023 (0.030)	Loss 1.2984 (1.1621)	Acc@1 56.250 (58.564)	Acc@5 75.000 (87.319)
Test: [600/750]	Time 0.019 (0.030)	Loss 0.6989 (1.1794)	Acc@1 75.000 (58.600)	Acc@5 93.750 (86.980)
Test: [700/750]	Time 0.031 (0.030)	Loss 1.2270 (1.1431)	Acc@1 50.000 (58.764)	Acc@5 81.250 (88.222)
 * Acc@1 58.921 Acc@5 88.550
==> training...
Epoch: [13][0/875]	Time 1.931 (1.931)	Data 1.424 (1.424)	Loss 3.3881 (3.3881)	Loss@kd 2.4263 (2.4263)	Acc@1 65.625 (65.625)	Acc@5 95.312 (95.312)
Epoch: [13][100/875]	Time 0.463 (0.521)	Data 0.007 (0.021)	Loss 3.7270 (3.4514)	Loss@kd 2.4086 (2.4459)	Acc@1 54.688 (63.119)	Acc@5 96.875 (97.587)
Epoch: [13][200/875]	Time 0.507 (0.504)	Data 0.005 (0.014)	Loss 3.5261 (3.4512)	Loss@kd 2.4385 (2.4528)	Acc@1 64.062 (63.860)	Acc@5 100.000 (97.645)
Epoch: [13][300/875]	Time 0.521 (0.507)	Data 0.010 (0.012)	Loss 3.3095 (3.4470)	Loss@kd 2.4489 (2.4560)	Acc@1 67.188 (64.146)	Acc@5 98.438 (97.623)
Epoch: [13][400/875]	Time 0.504 (0.508)	Data 0.007 (0.011)	Loss 3.3331 (3.4478)	Loss@kd 2.4521 (2.4543)	Acc@1 64.062 (63.747)	Acc@5 98.438 (97.705)
Epoch: [13][500/875]	Time 0.519 (0.508)	Data 0.007 (0.010)	Loss 3.3739 (3.4461)	Loss@kd 2.5092 (2.4506)	Acc@1 71.875 (63.629)	Acc@5 100.000 (97.655)
Epoch: [13][600/875]	Time 0.497 (0.508)	Data 0.005 (0.009)	Loss 3.5246 (3.4429)	Loss@kd 2.7186 (2.4493)	Acc@1 70.312 (63.753)	Acc@5 100.000 (97.621)
Epoch: [13][700/875]	Time 0.526 (0.509)	Data 0.007 (0.009)	Loss 3.4177 (3.4396)	Loss@kd 2.3407 (2.4470)	Acc@1 56.250 (63.864)	Acc@5 96.875 (97.613)
Epoch: [13][800/875]	Time 0.391 (0.508)	Data 0.005 (0.009)	Loss 3.2583 (3.4401)	Loss@kd 2.4701 (2.4451)	Acc@1 73.438 (63.706)	Acc@5 98.438 (97.605)
 * Acc@1 63.768 Acc@5 97.609
epoch 13, total time 442.21
Test: [0/750]	Time 0.619 (0.619)	Loss 0.7087 (0.7087)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.019 (0.033)	Loss 0.5857 (0.6107)	Acc@1 81.250 (82.457)	Acc@5 100.000 (89.264)
Test: [200/750]	Time 0.018 (0.029)	Loss 1.6252 (0.6592)	Acc@1 28.125 (77.596)	Acc@5 87.500 (92.600)
Test: [300/750]	Time 0.019 (0.028)	Loss 1.1735 (0.9211)	Acc@1 53.125 (64.711)	Acc@5 96.875 (92.193)
Test: [400/750]	Time 0.033 (0.027)	Loss 0.5543 (0.9820)	Acc@1 87.500 (61.954)	Acc@5 90.625 (91.513)
Test: [500/750]	Time 0.032 (0.026)	Loss 0.4931 (0.9157)	Acc@1 87.500 (65.999)	Acc@5 100.000 (91.417)
Test: [600/750]	Time 0.017 (0.026)	Loss 0.7083 (0.8940)	Acc@1 81.250 (67.414)	Acc@5 93.750 (91.733)
Test: [700/750]	Time 0.036 (0.026)	Loss 1.1910 (0.9100)	Acc@1 68.750 (66.896)	Acc@5 78.125 (91.873)
 * Acc@1 66.512 Acc@5 91.646
saving the best model!
==> training...
Epoch: [14][0/875]	Time 1.783 (1.783)	Data 1.292 (1.292)	Loss 3.2394 (3.2394)	Loss@kd 2.3959 (2.3959)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [14][100/875]	Time 0.505 (0.523)	Data 0.006 (0.020)	Loss 3.2929 (3.4196)	Loss@kd 2.3760 (2.4307)	Acc@1 65.625 (63.567)	Acc@5 100.000 (97.416)
Epoch: [14][200/875]	Time 0.527 (0.516)	Data 0.005 (0.013)	Loss 3.4249 (3.4119)	Loss@kd 2.5041 (2.4245)	Acc@1 65.625 (63.744)	Acc@5 100.000 (97.466)
Epoch: [14][300/875]	Time 0.497 (0.514)	Data 0.007 (0.011)	Loss 3.4074 (3.3994)	Loss@kd 2.4060 (2.4212)	Acc@1 62.500 (64.078)	Acc@5 98.438 (97.607)
Epoch: [14][400/875]	Time 0.506 (0.513)	Data 0.007 (0.010)	Loss 3.4910 (3.3999)	Loss@kd 2.4610 (2.4212)	Acc@1 68.750 (64.168)	Acc@5 96.875 (97.600)
Epoch: [14][500/875]	Time 0.496 (0.512)	Data 0.006 (0.010)	Loss 3.4290 (3.3998)	Loss@kd 2.3537 (2.4186)	Acc@1 60.938 (64.228)	Acc@5 98.438 (97.592)
Epoch: [14][600/875]	Time 0.454 (0.511)	Data 0.008 (0.009)	Loss 3.6939 (3.3989)	Loss@kd 2.4474 (2.4171)	Acc@1 53.125 (64.213)	Acc@5 95.312 (97.551)
Epoch: [14][700/875]	Time 0.516 (0.507)	Data 0.007 (0.009)	Loss 3.3970 (3.3958)	Loss@kd 2.3227 (2.4150)	Acc@1 54.688 (64.219)	Acc@5 98.438 (97.617)
Epoch: [14][800/875]	Time 0.495 (0.507)	Data 0.005 (0.009)	Loss 3.4737 (3.3974)	Loss@kd 2.3985 (2.4139)	Acc@1 56.250 (64.107)	Acc@5 98.438 (97.649)
 * Acc@1 64.089 Acc@5 97.632
epoch 14, total time 444.44
Test: [0/750]	Time 0.752 (0.752)	Loss 0.5598 (0.5598)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.026 (0.037)	Loss 0.3565 (0.4901)	Acc@1 87.500 (84.561)	Acc@5 100.000 (92.450)
Test: [200/750]	Time 0.039 (0.032)	Loss 1.6472 (0.4872)	Acc@1 31.250 (84.017)	Acc@5 84.375 (95.009)
Test: [300/750]	Time 0.022 (0.031)	Loss 1.2929 (0.7870)	Acc@1 37.500 (71.179)	Acc@5 93.750 (92.951)
Test: [400/750]	Time 0.025 (0.031)	Loss 0.7759 (0.9102)	Acc@1 78.125 (64.861)	Acc@5 87.500 (92.160)
Test: [500/750]	Time 0.023 (0.030)	Loss 0.9871 (0.9212)	Acc@1 65.625 (65.968)	Acc@5 93.750 (91.199)
Test: [600/750]	Time 0.018 (0.030)	Loss 0.7237 (0.9430)	Acc@1 78.125 (65.641)	Acc@5 96.875 (91.181)
Test: [700/750]	Time 0.019 (0.030)	Loss 1.2293 (0.9421)	Acc@1 65.625 (65.603)	Acc@5 81.250 (91.401)
 * Acc@1 65.596 Acc@5 90.992
==> training...
Epoch: [15][0/875]	Time 1.885 (1.885)	Data 1.332 (1.332)	Loss 3.2819 (3.2819)	Loss@kd 2.3870 (2.3870)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [15][100/875]	Time 0.517 (0.522)	Data 0.006 (0.020)	Loss 3.4452 (3.3816)	Loss@kd 2.3719 (2.3933)	Acc@1 64.062 (63.258)	Acc@5 95.312 (97.772)
Epoch: [15][200/875]	Time 0.503 (0.516)	Data 0.007 (0.014)	Loss 3.1531 (3.3694)	Loss@kd 2.3260 (2.3914)	Acc@1 75.000 (63.658)	Acc@5 100.000 (97.792)
Epoch: [15][300/875]	Time 0.508 (0.514)	Data 0.006 (0.011)	Loss 3.6109 (3.3716)	Loss@kd 2.3062 (2.3936)	Acc@1 54.688 (63.896)	Acc@5 92.188 (97.737)
Epoch: [15][400/875]	Time 0.473 (0.509)	Data 0.007 (0.010)	Loss 3.3085 (3.3662)	Loss@kd 2.4090 (2.3917)	Acc@1 67.188 (63.973)	Acc@5 98.438 (97.713)
Epoch: [15][500/875]	Time 0.514 (0.507)	Data 0.007 (0.010)	Loss 3.5960 (3.3678)	Loss@kd 2.4102 (2.3917)	Acc@1 54.688 (64.091)	Acc@5 96.875 (97.639)
Epoch: [15][600/875]	Time 0.518 (0.508)	Data 0.008 (0.009)	Loss 3.2913 (3.3670)	Loss@kd 2.3370 (2.3920)	Acc@1 65.625 (64.208)	Acc@5 96.875 (97.606)
Epoch: [15][700/875]	Time 0.508 (0.508)	Data 0.006 (0.009)	Loss 3.3752 (3.3641)	Loss@kd 2.3373 (2.3904)	Acc@1 65.625 (64.201)	Acc@5 100.000 (97.682)
Epoch: [15][800/875]	Time 0.522 (0.509)	Data 0.007 (0.009)	Loss 3.2342 (3.3599)	Loss@kd 2.3786 (2.3881)	Acc@1 70.312 (64.382)	Acc@5 98.438 (97.683)
 * Acc@1 64.398 Acc@5 97.679
epoch 15, total time 445.26
Test: [0/750]	Time 0.758 (0.758)	Loss 0.8167 (0.8167)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.028 (0.035)	Loss 0.7197 (0.6635)	Acc@1 78.125 (80.446)	Acc@5 96.875 (90.037)
Test: [200/750]	Time 0.039 (0.032)	Loss 1.5505 (0.7747)	Acc@1 25.000 (73.321)	Acc@5 93.750 (90.920)
Test: [300/750]	Time 0.015 (0.031)	Loss 1.2973 (1.0068)	Acc@1 40.625 (60.995)	Acc@5 93.750 (91.103)
Test: [400/750]	Time 0.028 (0.031)	Loss 0.8441 (1.0928)	Acc@1 78.125 (56.920)	Acc@5 90.625 (90.313)
Test: [500/750]	Time 0.026 (0.031)	Loss 0.3646 (1.0205)	Acc@1 90.625 (60.972)	Acc@5 100.000 (90.531)
Test: [600/750]	Time 0.023 (0.031)	Loss 0.9797 (0.9796)	Acc@1 68.750 (63.244)	Acc@5 87.500 (90.828)
Test: [700/750]	Time 0.036 (0.031)	Loss 0.7614 (0.9741)	Acc@1 75.000 (63.668)	Acc@5 90.625 (91.129)
 * Acc@1 64.383 Acc@5 91.412
==> training...
Epoch: [16][0/875]	Time 1.748 (1.748)	Data 1.232 (1.232)	Loss 3.3314 (3.3314)	Loss@kd 2.3131 (2.3131)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
Epoch: [16][100/875]	Time 0.497 (0.523)	Data 0.007 (0.019)	Loss 3.3242 (3.3034)	Loss@kd 2.2904 (2.3580)	Acc@1 60.938 (65.733)	Acc@5 100.000 (97.726)
Epoch: [16][200/875]	Time 0.496 (0.504)	Data 0.005 (0.013)	Loss 3.0232 (3.3207)	Loss@kd 2.2295 (2.3606)	Acc@1 67.188 (64.871)	Acc@5 98.438 (97.715)
Epoch: [16][300/875]	Time 0.512 (0.506)	Data 0.007 (0.011)	Loss 3.2950 (3.3257)	Loss@kd 2.3474 (2.3593)	Acc@1 68.750 (64.327)	Acc@5 100.000 (97.685)
Epoch: [16][400/875]	Time 0.513 (0.507)	Data 0.008 (0.010)	Loss 3.5098 (3.3287)	Loss@kd 2.3833 (2.3634)	Acc@1 57.812 (64.281)	Acc@5 98.438 (97.678)
Epoch: [16][500/875]	Time 0.511 (0.507)	Data 0.007 (0.010)	Loss 3.4366 (3.3295)	Loss@kd 2.5248 (2.3623)	Acc@1 68.750 (64.418)	Acc@5 98.438 (97.658)
Epoch: [16][600/875]	Time 0.499 (0.508)	Data 0.008 (0.009)	Loss 3.0825 (3.3226)	Loss@kd 2.2820 (2.3596)	Acc@1 75.000 (64.458)	Acc@5 100.000 (97.725)
Epoch: [16][700/875]	Time 0.514 (0.508)	Data 0.007 (0.009)	Loss 3.2641 (3.3220)	Loss@kd 2.3856 (2.3587)	Acc@1 65.625 (64.464)	Acc@5 100.000 (97.697)
Epoch: [16][800/875]	Time 0.496 (0.508)	Data 0.007 (0.009)	Loss 3.3707 (3.3195)	Loss@kd 2.2858 (2.3573)	Acc@1 54.688 (64.533)	Acc@5 100.000 (97.706)
 * Acc@1 64.552 Acc@5 97.679
epoch 16, total time 443.71
Test: [0/750]	Time 0.759 (0.759)	Loss 0.7257 (0.7257)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.018 (0.029)	Loss 0.5833 (0.5479)	Acc@1 78.125 (82.797)	Acc@5 96.875 (91.522)
Test: [200/750]	Time 0.015 (0.024)	Loss 1.3083 (0.6109)	Acc@1 43.750 (78.389)	Acc@5 93.750 (93.766)
Test: [300/750]	Time 0.033 (0.023)	Loss 1.1206 (0.8249)	Acc@1 46.875 (68.075)	Acc@5 96.875 (93.719)
Test: [400/750]	Time 0.025 (0.023)	Loss 0.7391 (0.9104)	Acc@1 81.250 (64.433)	Acc@5 87.500 (92.877)
Test: [500/750]	Time 0.023 (0.024)	Loss 0.4765 (0.8786)	Acc@1 87.500 (67.053)	Acc@5 100.000 (92.328)
Test: [600/750]	Time 0.017 (0.024)	Loss 0.7294 (0.8583)	Acc@1 84.375 (68.526)	Acc@5 93.750 (92.502)
Test: [700/750]	Time 0.034 (0.024)	Loss 1.2889 (0.8680)	Acc@1 59.375 (68.184)	Acc@5 78.125 (92.546)
 * Acc@1 67.883 Acc@5 92.325
saving the best model!
==> training...
Epoch: [17][0/875]	Time 1.828 (1.828)	Data 1.323 (1.323)	Loss 3.0890 (3.0890)	Loss@kd 2.3145 (2.3145)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [17][100/875]	Time 0.496 (0.522)	Data 0.008 (0.020)	Loss 3.2262 (3.3031)	Loss@kd 2.3040 (2.3450)	Acc@1 67.188 (64.743)	Acc@5 96.875 (97.788)
Epoch: [17][200/875]	Time 0.527 (0.516)	Data 0.008 (0.014)	Loss 3.1458 (3.3047)	Loss@kd 2.3548 (2.3431)	Acc@1 68.750 (64.754)	Acc@5 100.000 (97.886)
Epoch: [17][300/875]	Time 0.495 (0.514)	Data 0.007 (0.012)	Loss 3.3026 (3.2964)	Loss@kd 2.2252 (2.3424)	Acc@1 64.062 (64.898)	Acc@5 95.312 (97.892)
Epoch: [17][400/875]	Time 0.526 (0.513)	Data 0.007 (0.011)	Loss 3.4265 (3.3003)	Loss@kd 2.5567 (2.3418)	Acc@1 65.625 (64.776)	Acc@5 100.000 (97.752)
Epoch: [17][500/875]	Time 0.497 (0.512)	Data 0.007 (0.010)	Loss 3.4662 (3.2939)	Loss@kd 2.2725 (2.3403)	Acc@1 56.250 (64.930)	Acc@5 98.438 (97.764)
Epoch: [17][600/875]	Time 0.526 (0.512)	Data 0.008 (0.010)	Loss 3.3192 (3.2891)	Loss@kd 2.5144 (2.3342)	Acc@1 68.750 (64.848)	Acc@5 100.000 (97.769)
Epoch: [17][700/875]	Time 0.615 (0.507)	Data 0.008 (0.009)	Loss 3.1799 (3.2877)	Loss@kd 2.3859 (2.3322)	Acc@1 71.875 (64.938)	Acc@5 100.000 (97.755)
Epoch: [17][800/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss 3.2843 (3.2874)	Loss@kd 2.3064 (2.3326)	Acc@1 60.938 (64.975)	Acc@5 100.000 (97.765)
 * Acc@1 65.029 Acc@5 97.762
epoch 17, total time 444.27
Test: [0/750]	Time 0.720 (0.720)	Loss 0.5595 (0.5595)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.040 (0.034)	Loss 0.4534 (0.3816)	Acc@1 87.500 (88.459)	Acc@5 100.000 (93.564)
Test: [200/750]	Time 0.035 (0.031)	Loss 1.5821 (0.4785)	Acc@1 28.125 (84.608)	Acc@5 84.375 (94.916)
Test: [300/750]	Time 0.035 (0.030)	Loss 1.2990 (0.7715)	Acc@1 37.500 (71.024)	Acc@5 90.625 (93.636)
Test: [400/750]	Time 0.028 (0.029)	Loss 0.8836 (0.8789)	Acc@1 68.750 (65.929)	Acc@5 87.500 (92.986)
Test: [500/750]	Time 0.025 (0.029)	Loss 0.7329 (0.8890)	Acc@1 81.250 (66.954)	Acc@5 96.875 (91.611)
Test: [600/750]	Time 0.031 (0.029)	Loss 0.9077 (0.9060)	Acc@1 68.750 (66.816)	Acc@5 93.750 (91.535)
Test: [700/750]	Time 0.026 (0.029)	Loss 1.0278 (0.9171)	Acc@1 71.875 (66.374)	Acc@5 87.500 (91.744)
 * Acc@1 66.533 Acc@5 91.737
==> training...
Epoch: [18][0/875]	Time 1.808 (1.808)	Data 1.311 (1.311)	Loss 3.0485 (3.0485)	Loss@kd 2.2448 (2.2448)	Acc@1 75.000 (75.000)	Acc@5 100.000 (100.000)
Epoch: [18][100/875]	Time 0.505 (0.523)	Data 0.006 (0.020)	Loss 3.4139 (3.2526)	Loss@kd 2.3324 (2.3128)	Acc@1 51.562 (65.424)	Acc@5 98.438 (97.803)
Epoch: [18][200/875]	Time 0.529 (0.517)	Data 0.008 (0.014)	Loss 3.5319 (3.2503)	Loss@kd 2.4967 (2.3112)	Acc@1 62.500 (65.555)	Acc@5 98.438 (97.948)
Epoch: [18][300/875]	Time 0.514 (0.515)	Data 0.007 (0.011)	Loss 3.1432 (3.2588)	Loss@kd 2.3402 (2.3135)	Acc@1 70.312 (65.251)	Acc@5 100.000 (98.001)
Epoch: [18][400/875]	Time 0.524 (0.514)	Data 0.006 (0.010)	Loss 3.1634 (3.2631)	Loss@kd 2.2459 (2.3151)	Acc@1 64.062 (65.200)	Acc@5 96.875 (97.892)
Epoch: [18][500/875]	Time 0.488 (0.507)	Data 0.008 (0.010)	Loss 3.1641 (3.2603)	Loss@kd 2.2748 (2.3123)	Acc@1 65.625 (65.163)	Acc@5 98.438 (97.857)
Epoch: [18][600/875]	Time 0.601 (0.508)	Data 0.007 (0.009)	Loss 3.2236 (3.2626)	Loss@kd 2.3273 (2.3133)	Acc@1 64.062 (65.167)	Acc@5 98.438 (97.816)
Epoch: [18][700/875]	Time 0.521 (0.508)	Data 0.007 (0.009)	Loss 3.2882 (3.2609)	Loss@kd 2.2628 (2.3102)	Acc@1 64.062 (65.070)	Acc@5 96.875 (97.809)
Epoch: [18][800/875]	Time 0.496 (0.508)	Data 0.008 (0.009)	Loss 3.5470 (3.2576)	Loss@kd 2.5549 (2.3097)	Acc@1 62.500 (65.147)	Acc@5 96.875 (97.831)
 * Acc@1 65.223 Acc@5 97.838
epoch 18, total time 444.73
Test: [0/750]	Time 0.768 (0.768)	Loss 0.6407 (0.6407)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.044 (0.037)	Loss 0.6598 (0.5917)	Acc@1 75.000 (81.683)	Acc@5 100.000 (91.863)
Test: [200/750]	Time 0.028 (0.033)	Loss 1.8537 (0.6558)	Acc@1 21.875 (76.104)	Acc@5 81.250 (94.061)
Test: [300/750]	Time 0.032 (0.032)	Loss 0.9440 (0.9430)	Acc@1 75.000 (62.552)	Acc@5 93.750 (92.265)
Test: [400/750]	Time 0.026 (0.031)	Loss 0.4309 (0.9489)	Acc@1 90.625 (62.858)	Acc@5 100.000 (92.667)
Test: [500/750]	Time 0.043 (0.031)	Loss 0.5377 (0.8657)	Acc@1 81.250 (67.309)	Acc@5 100.000 (93.083)
Test: [600/750]	Time 0.024 (0.030)	Loss 0.7933 (0.8555)	Acc@1 75.000 (68.506)	Acc@5 90.625 (92.949)
Test: [700/750]	Time 0.025 (0.030)	Loss 1.5597 (0.8798)	Acc@1 43.750 (67.435)	Acc@5 75.000 (92.765)
 * Acc@1 66.333 Acc@5 92.304
==> training...
Epoch: [19][0/875]	Time 1.848 (1.848)	Data 1.352 (1.352)	Loss 3.0733 (3.0733)	Loss@kd 2.3194 (2.3194)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [19][100/875]	Time 0.519 (0.523)	Data 0.007 (0.020)	Loss 3.0418 (3.2588)	Loss@kd 2.2114 (2.3019)	Acc@1 70.312 (65.919)	Acc@5 96.875 (97.463)
Epoch: [19][200/875]	Time 0.465 (0.511)	Data 0.008 (0.014)	Loss 3.0647 (3.2350)	Loss@kd 2.2635 (2.2942)	Acc@1 73.438 (65.866)	Acc@5 100.000 (97.769)
Epoch: [19][300/875]	Time 0.491 (0.505)	Data 0.007 (0.011)	Loss 3.2718 (3.2344)	Loss@kd 2.3625 (2.2940)	Acc@1 60.938 (65.718)	Acc@5 100.000 (97.856)
Epoch: [19][400/875]	Time 0.502 (0.506)	Data 0.007 (0.010)	Loss 3.3246 (3.2323)	Loss@kd 2.2544 (2.2913)	Acc@1 56.250 (65.863)	Acc@5 95.312 (97.771)
Epoch: [19][500/875]	Time 0.505 (0.506)	Data 0.007 (0.010)	Loss 3.1465 (3.2366)	Loss@kd 2.2476 (2.2922)	Acc@1 64.062 (65.538)	Acc@5 96.875 (97.808)
Epoch: [19][600/875]	Time 0.499 (0.507)	Data 0.007 (0.009)	Loss 3.6396 (3.2301)	Loss@kd 2.3584 (2.2894)	Acc@1 50.000 (65.599)	Acc@5 93.750 (97.834)
Epoch: [19][700/875]	Time 0.532 (0.507)	Data 0.007 (0.009)	Loss 3.1959 (3.2299)	Loss@kd 2.2998 (2.2889)	Acc@1 68.750 (65.558)	Acc@5 96.875 (97.838)
Epoch: [19][800/875]	Time 0.500 (0.507)	Data 0.007 (0.009)	Loss 3.4090 (3.2305)	Loss@kd 2.3023 (2.2890)	Acc@1 67.188 (65.492)	Acc@5 96.875 (97.856)
 * Acc@1 65.600 Acc@5 97.871
epoch 19, total time 444.21
Test: [0/750]	Time 0.646 (0.646)	Loss 0.6491 (0.6491)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.049 (0.034)	Loss 0.5155 (0.5866)	Acc@1 78.125 (81.683)	Acc@5 96.875 (90.501)
Test: [200/750]	Time 0.020 (0.030)	Loss 2.0915 (0.6401)	Acc@1 15.625 (77.830)	Acc@5 68.750 (92.413)
Test: [300/750]	Time 0.025 (0.028)	Loss 1.0549 (0.9993)	Acc@1 65.625 (61.244)	Acc@5 96.875 (89.701)
Test: [400/750]	Time 0.027 (0.026)	Loss 0.8838 (1.0017)	Acc@1 68.750 (61.167)	Acc@5 93.750 (90.734)
Test: [500/750]	Time 0.024 (0.026)	Loss 0.5783 (0.9887)	Acc@1 78.125 (62.812)	Acc@5 93.750 (90.637)
Test: [600/750]	Time 0.023 (0.025)	Loss 0.7170 (0.9658)	Acc@1 75.000 (64.320)	Acc@5 93.750 (90.875)
Test: [700/750]	Time 0.022 (0.025)	Loss 0.7399 (0.9406)	Acc@1 71.875 (65.041)	Acc@5 93.750 (91.717)
 * Acc@1 65.863 Acc@5 92.054
==> training...
Epoch: [20][0/875]	Time 1.658 (1.658)	Data 1.214 (1.214)	Loss 3.3359 (3.3359)	Loss@kd 2.3892 (2.3892)	Acc@1 60.938 (60.938)	Acc@5 98.438 (98.438)
Epoch: [20][100/875]	Time 0.503 (0.510)	Data 0.007 (0.018)	Loss 3.2826 (3.2326)	Loss@kd 2.2989 (2.2906)	Acc@1 64.062 (65.470)	Acc@5 96.875 (97.942)
Epoch: [20][200/875]	Time 0.507 (0.510)	Data 0.007 (0.013)	Loss 3.1305 (3.2170)	Loss@kd 2.1870 (2.2864)	Acc@1 68.750 (65.889)	Acc@5 98.438 (97.870)
Epoch: [20][300/875]	Time 0.492 (0.510)	Data 0.007 (0.011)	Loss 2.9791 (3.2075)	Loss@kd 2.1824 (2.2827)	Acc@1 75.000 (65.921)	Acc@5 100.000 (97.950)
Epoch: [20][400/875]	Time 0.527 (0.510)	Data 0.005 (0.010)	Loss 3.0541 (3.2053)	Loss@kd 2.2411 (2.2774)	Acc@1 70.312 (65.890)	Acc@5 98.438 (97.888)
Epoch: [20][500/875]	Time 0.506 (0.510)	Data 0.009 (0.009)	Loss 3.0908 (3.2008)	Loss@kd 2.1804 (2.2738)	Acc@1 67.188 (65.931)	Acc@5 100.000 (97.907)
Epoch: [20][600/875]	Time 0.524 (0.510)	Data 0.007 (0.009)	Loss 3.2758 (3.2045)	Loss@kd 2.3359 (2.2743)	Acc@1 68.750 (65.927)	Acc@5 98.438 (97.897)
Epoch: [20][700/875]	Time 0.469 (0.508)	Data 0.007 (0.009)	Loss 3.3479 (3.2024)	Loss@kd 2.2830 (2.2703)	Acc@1 60.938 (65.917)	Acc@5 98.438 (97.914)
Epoch: [20][800/875]	Time 0.510 (0.507)	Data 0.005 (0.008)	Loss 3.1736 (3.1981)	Loss@kd 2.2815 (2.2682)	Acc@1 64.062 (65.898)	Acc@5 96.875 (97.940)
 * Acc@1 65.857 Acc@5 97.895
epoch 20, total time 444.18
Test: [0/750]	Time 0.769 (0.769)	Loss 0.6458 (0.6458)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.019 (0.037)	Loss 0.4573 (0.5434)	Acc@1 81.250 (83.354)	Acc@5 100.000 (89.882)
Test: [200/750]	Time 0.030 (0.032)	Loss 1.4131 (0.5408)	Acc@1 31.250 (83.053)	Acc@5 100.000 (93.579)
Test: [300/750]	Time 0.024 (0.031)	Loss 0.8253 (0.7806)	Acc@1 68.750 (70.162)	Acc@5 96.875 (93.833)
Test: [400/750]	Time 0.024 (0.031)	Loss 0.7215 (0.8077)	Acc@1 81.250 (69.724)	Acc@5 100.000 (94.023)
Test: [500/750]	Time 0.019 (0.030)	Loss 0.9840 (0.8233)	Acc@1 59.375 (70.066)	Acc@5 90.625 (93.426)
Test: [600/750]	Time 0.041 (0.030)	Loss 0.9389 (0.8812)	Acc@1 68.750 (67.918)	Acc@5 96.875 (92.502)
Test: [700/750]	Time 0.033 (0.030)	Loss 1.3369 (0.9253)	Acc@1 50.000 (65.514)	Acc@5 78.125 (92.216)
 * Acc@1 64.854 Acc@5 91.875
==> training...
Epoch: [21][0/875]	Time 1.826 (1.826)	Data 1.275 (1.275)	Loss 3.1072 (3.1072)	Loss@kd 2.1745 (2.1745)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [21][100/875]	Time 0.504 (0.524)	Data 0.009 (0.020)	Loss 3.1047 (3.1900)	Loss@kd 2.2194 (2.2542)	Acc@1 71.875 (65.780)	Acc@5 96.875 (98.066)
Epoch: [21][200/875]	Time 0.527 (0.517)	Data 0.006 (0.014)	Loss 3.1603 (3.1757)	Loss@kd 2.2529 (2.2459)	Acc@1 71.875 (65.633)	Acc@5 98.438 (98.033)
Epoch: [21][300/875]	Time 0.510 (0.515)	Data 0.006 (0.011)	Loss 3.0299 (3.1825)	Loss@kd 2.1879 (2.2525)	Acc@1 76.562 (65.765)	Acc@5 95.312 (97.918)
Epoch: [21][400/875]	Time 0.514 (0.514)	Data 0.007 (0.010)	Loss 3.2933 (3.1770)	Loss@kd 2.2282 (2.2523)	Acc@1 62.500 (65.976)	Acc@5 98.438 (98.001)
Epoch: [21][500/875]	Time 0.531 (0.508)	Data 0.007 (0.010)	Loss 3.0489 (3.1699)	Loss@kd 2.1858 (2.2506)	Acc@1 64.062 (66.211)	Acc@5 100.000 (98.020)
Epoch: [21][600/875]	Time 0.500 (0.508)	Data 0.007 (0.009)	Loss 3.4271 (3.1730)	Loss@kd 2.1850 (2.2497)	Acc@1 56.250 (66.184)	Acc@5 96.875 (97.980)
Epoch: [21][700/875]	Time 0.526 (0.509)	Data 0.007 (0.009)	Loss 2.9994 (3.1747)	Loss@kd 2.2047 (2.2493)	Acc@1 65.625 (66.144)	Acc@5 100.000 (97.965)
Epoch: [21][800/875]	Time 0.498 (0.509)	Data 0.007 (0.009)	Loss 3.1647 (3.1721)	Loss@kd 2.1884 (2.2472)	Acc@1 60.938 (66.171)	Acc@5 100.000 (97.975)
 * Acc@1 66.238 Acc@5 97.982
epoch 21, total time 445.67
Test: [0/750]	Time 0.729 (0.729)	Loss 0.6993 (0.6993)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.023 (0.033)	Loss 0.4243 (0.5643)	Acc@1 87.500 (83.818)	Acc@5 96.875 (90.316)
Test: [200/750]	Time 0.017 (0.029)	Loss 1.6567 (0.5587)	Acc@1 28.125 (82.074)	Acc@5 84.375 (93.579)
Test: [300/750]	Time 0.024 (0.028)	Loss 1.1033 (0.8341)	Acc@1 65.625 (68.262)	Acc@5 93.750 (93.418)
Test: [400/750]	Time 0.017 (0.027)	Loss 1.1674 (0.9240)	Acc@1 68.750 (64.324)	Acc@5 84.375 (93.002)
Test: [500/750]	Time 0.018 (0.027)	Loss 0.5674 (0.9540)	Acc@1 81.250 (64.789)	Acc@5 93.750 (91.436)
Test: [600/750]	Time 0.017 (0.026)	Loss 0.9433 (0.9444)	Acc@1 62.500 (65.667)	Acc@5 87.500 (91.306)
Test: [700/750]	Time 0.028 (0.026)	Loss 0.7591 (0.9385)	Acc@1 75.000 (65.607)	Acc@5 90.625 (91.771)
 * Acc@1 66.308 Acc@5 92.071
==> training...
Epoch: [22][0/875]	Time 1.792 (1.792)	Data 1.317 (1.317)	Loss 3.0775 (3.0775)	Loss@kd 2.2538 (2.2538)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [22][100/875]	Time 0.510 (0.523)	Data 0.007 (0.020)	Loss 3.0693 (3.1479)	Loss@kd 2.1745 (2.2273)	Acc@1 67.188 (66.166)	Acc@5 98.438 (97.788)
Epoch: [22][200/875]	Time 0.524 (0.517)	Data 0.006 (0.014)	Loss 3.1197 (3.1567)	Loss@kd 2.2200 (2.2370)	Acc@1 67.188 (66.177)	Acc@5 100.000 (97.816)
Epoch: [22][300/875]	Time 0.506 (0.504)	Data 0.008 (0.011)	Loss 3.0372 (3.1658)	Loss@kd 2.2422 (2.2392)	Acc@1 68.750 (66.020)	Acc@5 100.000 (97.783)
Epoch: [22][400/875]	Time 0.500 (0.505)	Data 0.006 (0.010)	Loss 3.3006 (3.1605)	Loss@kd 2.2022 (2.2352)	Acc@1 62.500 (66.221)	Acc@5 95.312 (97.845)
Epoch: [22][500/875]	Time 0.477 (0.506)	Data 0.008 (0.010)	Loss 2.8378 (3.1552)	Loss@kd 2.1787 (2.2331)	Acc@1 73.438 (66.280)	Acc@5 100.000 (97.867)
Epoch: [22][600/875]	Time 0.493 (0.507)	Data 0.007 (0.009)	Loss 3.0723 (3.1590)	Loss@kd 2.3121 (2.2328)	Acc@1 70.312 (66.158)	Acc@5 100.000 (97.842)
Epoch: [22][700/875]	Time 0.519 (0.507)	Data 0.008 (0.009)	Loss 3.0010 (3.1540)	Loss@kd 2.1519 (2.2322)	Acc@1 73.438 (66.376)	Acc@5 98.438 (97.854)
Epoch: [22][800/875]	Time 0.500 (0.508)	Data 0.007 (0.009)	Loss 3.1965 (3.1463)	Loss@kd 2.2628 (2.2292)	Acc@1 70.312 (66.593)	Acc@5 95.312 (97.903)
 * Acc@1 66.600 Acc@5 97.918
epoch 22, total time 444.67
Test: [0/750]	Time 0.753 (0.753)	Loss 0.5072 (0.5072)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.026 (0.035)	Loss 0.6817 (0.4501)	Acc@1 78.125 (85.427)	Acc@5 96.875 (93.595)
Test: [200/750]	Time 0.041 (0.032)	Loss 1.6759 (0.6002)	Acc@1 25.000 (78.762)	Acc@5 84.375 (93.688)
Test: [300/750]	Time 0.025 (0.031)	Loss 0.7597 (0.8755)	Acc@1 81.250 (65.044)	Acc@5 100.000 (92.504)
Test: [400/750]	Time 0.026 (0.031)	Loss 0.7775 (0.8749)	Acc@1 75.000 (65.867)	Acc@5 84.375 (93.173)
Test: [500/750]	Time 0.016 (0.030)	Loss 0.7011 (0.8669)	Acc@1 81.250 (67.128)	Acc@5 96.875 (92.515)
Test: [600/750]	Time 0.034 (0.030)	Loss 0.7797 (0.8870)	Acc@1 78.125 (67.076)	Acc@5 90.625 (91.993)
Test: [700/750]	Time 0.023 (0.030)	Loss 1.0031 (0.8883)	Acc@1 65.625 (66.789)	Acc@5 84.375 (92.239)
 * Acc@1 67.221 Acc@5 92.321
==> training...
Epoch: [23][0/875]	Time 1.958 (1.958)	Data 1.450 (1.450)	Loss 3.0400 (3.0400)	Loss@kd 2.2421 (2.2421)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [23][100/875]	Time 0.501 (0.502)	Data 0.007 (0.021)	Loss 3.1300 (3.1324)	Loss@kd 2.3879 (2.2208)	Acc@1 76.562 (66.414)	Acc@5 98.438 (98.175)
Epoch: [23][200/875]	Time 0.495 (0.507)	Data 0.007 (0.014)	Loss 2.9531 (3.1360)	Loss@kd 2.1185 (2.2272)	Acc@1 67.188 (66.690)	Acc@5 98.438 (98.142)
Epoch: [23][300/875]	Time 0.526 (0.508)	Data 0.010 (0.012)	Loss 3.0989 (3.1424)	Loss@kd 2.1982 (2.2272)	Acc@1 64.062 (66.357)	Acc@5 100.000 (98.136)
Epoch: [23][400/875]	Time 0.508 (0.509)	Data 0.006 (0.011)	Loss 3.0806 (3.1342)	Loss@kd 2.1562 (2.2232)	Acc@1 71.875 (66.712)	Acc@5 98.438 (98.145)
Epoch: [23][500/875]	Time 0.526 (0.509)	Data 0.005 (0.010)	Loss 3.5048 (3.1320)	Loss@kd 2.2548 (2.2218)	Acc@1 56.250 (66.679)	Acc@5 96.875 (98.157)
Epoch: [23][600/875]	Time 0.510 (0.509)	Data 0.007 (0.009)	Loss 3.1588 (3.1326)	Loss@kd 2.1710 (2.2226)	Acc@1 57.812 (66.655)	Acc@5 98.438 (98.136)
Epoch: [23][700/875]	Time 0.507 (0.510)	Data 0.007 (0.009)	Loss 2.9873 (3.1338)	Loss@kd 2.2079 (2.2214)	Acc@1 73.438 (66.624)	Acc@5 98.438 (98.070)
Epoch: [23][800/875]	Time 0.533 (0.506)	Data 0.007 (0.009)	Loss 3.0807 (3.1320)	Loss@kd 2.3174 (2.2200)	Acc@1 70.312 (66.708)	Acc@5 100.000 (98.045)
 * Acc@1 66.764 Acc@5 98.029
epoch 23, total time 443.14
Test: [0/750]	Time 0.691 (0.691)	Loss 0.5244 (0.5244)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.021 (0.034)	Loss 0.5678 (0.5030)	Acc@1 81.250 (84.097)	Acc@5 100.000 (92.574)
Test: [200/750]	Time 0.036 (0.032)	Loss 1.4136 (0.6037)	Acc@1 31.250 (77.907)	Acc@5 96.875 (94.372)
Test: [300/750]	Time 0.023 (0.031)	Loss 1.0832 (0.8404)	Acc@1 59.375 (66.528)	Acc@5 93.750 (94.134)
Test: [400/750]	Time 0.025 (0.030)	Loss 0.9106 (0.9270)	Acc@1 71.875 (63.747)	Acc@5 87.500 (92.815)
Test: [500/750]	Time 0.035 (0.030)	Loss 0.3965 (0.8993)	Acc@1 87.500 (66.149)	Acc@5 100.000 (91.954)
Test: [600/750]	Time 0.027 (0.030)	Loss 0.6202 (0.8602)	Acc@1 81.250 (68.178)	Acc@5 90.625 (92.492)
Test: [700/750]	Time 0.026 (0.029)	Loss 1.5430 (0.8742)	Acc@1 46.875 (67.863)	Acc@5 78.125 (92.145)
 * Acc@1 66.975 Acc@5 91.404
==> training...
Epoch: [24][0/875]	Time 1.846 (1.846)	Data 1.315 (1.315)	Loss 3.2114 (3.2114)	Loss@kd 2.3213 (2.3213)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [24][100/875]	Time 0.515 (0.524)	Data 0.007 (0.020)	Loss 3.0582 (3.1006)	Loss@kd 2.2253 (2.2056)	Acc@1 75.000 (67.141)	Acc@5 98.438 (98.175)
Epoch: [24][200/875]	Time 0.500 (0.517)	Data 0.007 (0.013)	Loss 3.0029 (3.1048)	Loss@kd 2.1056 (2.2014)	Acc@1 65.625 (67.141)	Acc@5 98.438 (98.103)
Epoch: [24][300/875]	Time 0.532 (0.515)	Data 0.006 (0.011)	Loss 2.8443 (3.1092)	Loss@kd 2.1509 (2.2004)	Acc@1 73.438 (66.975)	Acc@5 100.000 (98.012)
Epoch: [24][400/875]	Time 0.496 (0.513)	Data 0.006 (0.010)	Loss 2.9295 (3.1082)	Loss@kd 2.2298 (2.1991)	Acc@1 73.438 (66.884)	Acc@5 100.000 (97.947)
Epoch: [24][500/875]	Time 0.453 (0.511)	Data 0.007 (0.010)	Loss 3.2615 (3.1152)	Loss@kd 2.1370 (2.2015)	Acc@1 59.375 (66.707)	Acc@5 98.438 (97.960)
Epoch: [24][600/875]	Time 0.500 (0.507)	Data 0.007 (0.009)	Loss 3.2234 (3.1122)	Loss@kd 2.3211 (2.2010)	Acc@1 65.625 (66.748)	Acc@5 96.875 (97.996)
Epoch: [24][700/875]	Time 0.526 (0.508)	Data 0.007 (0.009)	Loss 3.1196 (3.1108)	Loss@kd 2.1122 (2.2013)	Acc@1 67.188 (66.871)	Acc@5 96.875 (98.010)
Epoch: [24][800/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss 3.0921 (3.1096)	Loss@kd 2.1392 (2.2013)	Acc@1 68.750 (66.936)	Acc@5 95.312 (98.016)
 * Acc@1 66.923 Acc@5 98.055
epoch 24, total time 444.60
Test: [0/750]	Time 0.793 (0.793)	Loss 0.6473 (0.6473)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.025 (0.037)	Loss 0.4090 (0.5427)	Acc@1 78.125 (84.251)	Acc@5 100.000 (91.925)
Test: [200/750]	Time 0.020 (0.033)	Loss 2.3012 (0.5618)	Acc@1 25.000 (81.110)	Acc@5 56.250 (93.734)
Test: [300/750]	Time 0.020 (0.032)	Loss 1.0583 (0.9667)	Acc@1 59.375 (64.898)	Acc@5 96.875 (88.175)
Test: [400/750]	Time 0.033 (0.031)	Loss 1.0260 (0.9893)	Acc@1 68.750 (63.451)	Acc@5 87.500 (89.433)
Test: [500/750]	Time 0.035 (0.030)	Loss 1.6378 (1.0398)	Acc@1 40.625 (62.625)	Acc@5 78.125 (88.429)
Test: [600/750]	Time 0.036 (0.030)	Loss 0.4560 (1.0877)	Acc@1 87.500 (61.876)	Acc@5 100.000 (87.802)
Test: [700/750]	Time 0.020 (0.030)	Loss 1.5973 (1.0605)	Acc@1 46.875 (62.504)	Acc@5 75.000 (88.521)
 * Acc@1 62.138 Acc@5 88.258
==> training...
Epoch: [25][0/875]	Time 1.941 (1.941)	Data 1.384 (1.384)	Loss 2.9945 (2.9945)	Loss@kd 2.2722 (2.2722)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [25][100/875]	Time 0.498 (0.525)	Data 0.007 (0.021)	Loss 3.1530 (3.1013)	Loss@kd 2.2372 (2.1853)	Acc@1 60.938 (66.955)	Acc@5 98.438 (97.942)
Epoch: [25][200/875]	Time 0.517 (0.518)	Data 0.007 (0.014)	Loss 3.0074 (3.0943)	Loss@kd 2.1276 (2.1837)	Acc@1 70.312 (66.845)	Acc@5 95.312 (98.095)
Epoch: [25][300/875]	Time 0.455 (0.509)	Data 0.005 (0.012)	Loss 3.1455 (3.0947)	Loss@kd 2.2211 (2.1849)	Acc@1 57.812 (66.679)	Acc@5 98.438 (98.142)
Epoch: [25][400/875]	Time 0.500 (0.507)	Data 0.006 (0.010)	Loss 3.1873 (3.0947)	Loss@kd 2.2853 (2.1861)	Acc@1 67.188 (66.794)	Acc@5 100.000 (98.188)
Epoch: [25][500/875]	Time 0.521 (0.507)	Data 0.008 (0.010)	Loss 2.8446 (3.0889)	Loss@kd 2.1480 (2.1840)	Acc@1 75.000 (66.888)	Acc@5 100.000 (98.129)
Epoch: [25][600/875]	Time 0.498 (0.508)	Data 0.008 (0.009)	Loss 3.3074 (3.0891)	Loss@kd 2.2186 (2.1848)	Acc@1 67.188 (66.904)	Acc@5 95.312 (98.113)
Epoch: [25][700/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 3.1287 (3.0907)	Loss@kd 2.1836 (2.1849)	Acc@1 59.375 (66.956)	Acc@5 96.875 (98.076)
Epoch: [25][800/875]	Time 0.524 (0.508)	Data 0.007 (0.009)	Loss 2.9833 (3.0900)	Loss@kd 2.1614 (2.1852)	Acc@1 67.188 (66.983)	Acc@5 98.438 (98.079)
 * Acc@1 66.912 Acc@5 98.082
epoch 25, total time 444.97
Test: [0/750]	Time 0.773 (0.773)	Loss 0.7214 (0.7214)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.016 (0.034)	Loss 0.6692 (0.5418)	Acc@1 84.375 (83.756)	Acc@5 93.750 (91.244)
Test: [200/750]	Time 0.038 (0.032)	Loss 1.4728 (0.6400)	Acc@1 40.625 (77.985)	Acc@5 84.375 (92.693)
Test: [300/750]	Time 0.037 (0.030)	Loss 1.2784 (0.8534)	Acc@1 46.875 (67.276)	Acc@5 87.500 (92.930)
Test: [400/750]	Time 0.015 (0.029)	Loss 0.7172 (0.9140)	Acc@1 81.250 (64.316)	Acc@5 87.500 (92.799)
Test: [500/750]	Time 0.015 (0.028)	Loss 0.4885 (0.8736)	Acc@1 87.500 (66.972)	Acc@5 100.000 (92.546)
Test: [600/750]	Time 0.041 (0.028)	Loss 1.0442 (0.8686)	Acc@1 68.750 (67.850)	Acc@5 84.375 (92.424)
Test: [700/750]	Time 0.036 (0.027)	Loss 0.8911 (0.8796)	Acc@1 71.875 (67.609)	Acc@5 90.625 (92.368)
 * Acc@1 68.021 Acc@5 92.500
saving the best model!
==> training...
Epoch: [26][0/875]	Time 1.777 (1.777)	Data 1.261 (1.261)	Loss 2.9722 (2.9722)	Loss@kd 2.1138 (2.1138)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [26][100/875]	Time 0.387 (0.492)	Data 0.006 (0.019)	Loss 3.2671 (3.0636)	Loss@kd 2.3098 (2.1829)	Acc@1 60.938 (68.549)	Acc@5 98.438 (98.267)
Epoch: [26][200/875]	Time 0.510 (0.497)	Data 0.007 (0.013)	Loss 3.3781 (3.0713)	Loss@kd 2.1908 (2.1834)	Acc@1 60.938 (68.035)	Acc@5 92.188 (98.212)
Epoch: [26][300/875]	Time 0.490 (0.500)	Data 0.004 (0.011)	Loss 3.2600 (3.0761)	Loss@kd 2.1750 (2.1852)	Acc@1 62.500 (67.681)	Acc@5 98.438 (98.199)
Epoch: [26][400/875]	Time 0.496 (0.502)	Data 0.007 (0.010)	Loss 3.0781 (3.0710)	Loss@kd 2.1616 (2.1781)	Acc@1 67.188 (67.612)	Acc@5 100.000 (98.134)
Epoch: [26][500/875]	Time 0.520 (0.503)	Data 0.007 (0.009)	Loss 2.7450 (3.0688)	Loss@kd 2.1205 (2.1772)	Acc@1 79.688 (67.649)	Acc@5 100.000 (98.169)
Epoch: [26][600/875]	Time 0.500 (0.504)	Data 0.007 (0.009)	Loss 3.0009 (3.0701)	Loss@kd 2.1030 (2.1760)	Acc@1 67.188 (67.463)	Acc@5 95.312 (98.146)
Epoch: [26][700/875]	Time 0.524 (0.505)	Data 0.005 (0.009)	Loss 3.1724 (3.0675)	Loss@kd 2.2236 (2.1752)	Acc@1 65.625 (67.493)	Acc@5 93.750 (98.150)
Epoch: [26][800/875]	Time 0.459 (0.503)	Data 0.005 (0.009)	Loss 3.1897 (3.0687)	Loss@kd 2.2712 (2.1743)	Acc@1 62.500 (67.416)	Acc@5 98.438 (98.139)
 * Acc@1 67.412 Acc@5 98.102
epoch 26, total time 440.29
Test: [0/750]	Time 0.680 (0.680)	Loss 0.5752 (0.5752)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.033 (0.032)	Loss 0.4700 (0.5327)	Acc@1 81.250 (84.127)	Acc@5 100.000 (91.460)
Test: [200/750]	Time 0.016 (0.029)	Loss 1.3143 (0.5114)	Acc@1 50.000 (82.929)	Acc@5 93.750 (94.667)
Test: [300/750]	Time 0.020 (0.028)	Loss 0.9660 (0.7414)	Acc@1 62.500 (72.020)	Acc@5 93.750 (94.767)
Test: [400/750]	Time 0.032 (0.027)	Loss 0.7070 (0.8150)	Acc@1 81.250 (68.867)	Acc@5 87.500 (94.436)
Test: [500/750]	Time 0.036 (0.026)	Loss 0.7674 (0.8281)	Acc@1 65.625 (69.174)	Acc@5 96.875 (93.525)
Test: [600/750]	Time 0.027 (0.026)	Loss 0.7610 (0.8548)	Acc@1 71.875 (68.584)	Acc@5 93.750 (93.339)
Test: [700/750]	Time 0.018 (0.026)	Loss 1.2263 (0.8678)	Acc@1 53.125 (67.760)	Acc@5 81.250 (93.224)
 * Acc@1 67.625 Acc@5 92.879
==> training...
Epoch: [27][0/875]	Time 1.743 (1.743)	Data 1.236 (1.236)	Loss 3.2071 (3.2071)	Loss@kd 2.1785 (2.1785)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [27][100/875]	Time 0.524 (0.521)	Data 0.008 (0.019)	Loss 2.8772 (3.0559)	Loss@kd 2.1257 (2.1714)	Acc@1 76.562 (67.280)	Acc@5 100.000 (98.407)
Epoch: [27][200/875]	Time 0.511 (0.516)	Data 0.008 (0.013)	Loss 2.9264 (3.0486)	Loss@kd 2.0938 (2.1592)	Acc@1 68.750 (67.359)	Acc@5 100.000 (98.189)
Epoch: [27][300/875]	Time 0.522 (0.514)	Data 0.007 (0.011)	Loss 3.0084 (3.0507)	Loss@kd 2.1985 (2.1626)	Acc@1 75.000 (67.670)	Acc@5 100.000 (98.085)
Epoch: [27][400/875]	Time 0.502 (0.512)	Data 0.007 (0.010)	Loss 3.2818 (3.0532)	Loss@kd 2.2135 (2.1677)	Acc@1 59.375 (67.741)	Acc@5 95.312 (98.126)
Epoch: [27][500/875]	Time 0.521 (0.512)	Data 0.007 (0.010)	Loss 2.8765 (3.0573)	Loss@kd 2.1229 (2.1690)	Acc@1 73.438 (67.621)	Acc@5 98.438 (98.135)
Epoch: [27][600/875]	Time 0.500 (0.508)	Data 0.008 (0.009)	Loss 2.9213 (3.0548)	Loss@kd 2.1019 (2.1663)	Acc@1 75.000 (67.585)	Acc@5 96.875 (98.120)
Epoch: [27][700/875]	Time 0.521 (0.508)	Data 0.005 (0.009)	Loss 3.2087 (3.0534)	Loss@kd 2.1721 (2.1638)	Acc@1 62.500 (67.591)	Acc@5 98.438 (98.134)
Epoch: [27][800/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 2.9799 (3.0538)	Loss@kd 2.1097 (2.1623)	Acc@1 68.750 (67.478)	Acc@5 98.438 (98.129)
 * Acc@1 67.395 Acc@5 98.148
epoch 27, total time 445.30
Test: [0/750]	Time 0.701 (0.701)	Loss 0.6055 (0.6055)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.021 (0.036)	Loss 0.6500 (0.5445)	Acc@1 75.000 (82.519)	Acc@5 93.750 (91.584)
Test: [200/750]	Time 0.039 (0.033)	Loss 1.2570 (0.6387)	Acc@1 40.625 (77.410)	Acc@5 96.875 (93.004)
Test: [300/750]	Time 0.018 (0.031)	Loss 0.9810 (0.8254)	Acc@1 59.375 (68.345)	Acc@5 93.750 (93.439)
Test: [400/750]	Time 0.036 (0.031)	Loss 0.3842 (0.8474)	Acc@1 84.375 (67.184)	Acc@5 100.000 (93.703)
Test: [500/750]	Time 0.033 (0.030)	Loss 0.7636 (0.7934)	Acc@1 71.875 (70.316)	Acc@5 93.750 (93.844)
Test: [600/750]	Time 0.045 (0.030)	Loss 0.9344 (0.8272)	Acc@1 65.625 (69.660)	Acc@5 90.625 (92.960)
Test: [700/750]	Time 0.031 (0.030)	Loss 1.1601 (0.8658)	Acc@1 56.250 (68.215)	Acc@5 84.375 (92.515)
 * Acc@1 67.600 Acc@5 92.354
==> training...
Epoch: [28][0/875]	Time 1.715 (1.715)	Data 1.209 (1.209)	Loss 3.0858 (3.0858)	Loss@kd 2.1005 (2.1005)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)
Epoch: [28][100/875]	Time 0.531 (0.522)	Data 0.006 (0.019)	Loss 2.8983 (3.0633)	Loss@kd 2.0563 (2.1701)	Acc@1 65.625 (67.311)	Acc@5 100.000 (98.221)
Epoch: [28][200/875]	Time 0.509 (0.516)	Data 0.007 (0.013)	Loss 3.0154 (3.0505)	Loss@kd 2.1580 (2.1664)	Acc@1 65.625 (67.289)	Acc@5 98.438 (98.406)
Epoch: [28][300/875]	Time 0.496 (0.514)	Data 0.007 (0.011)	Loss 2.9494 (3.0525)	Loss@kd 2.1059 (2.1642)	Acc@1 68.750 (67.006)	Acc@5 98.438 (98.277)
Epoch: [28][400/875]	Time 0.521 (0.505)	Data 0.006 (0.010)	Loss 3.0992 (3.0412)	Loss@kd 2.1398 (2.1573)	Acc@1 65.625 (67.386)	Acc@5 98.438 (98.250)
Epoch: [28][500/875]	Time 0.493 (0.506)	Data 0.005 (0.010)	Loss 2.9772 (3.0430)	Loss@kd 2.1729 (2.1579)	Acc@1 70.312 (67.269)	Acc@5 98.438 (98.216)
Epoch: [28][600/875]	Time 0.524 (0.506)	Data 0.007 (0.009)	Loss 3.0709 (3.0419)	Loss@kd 2.1754 (2.1567)	Acc@1 71.875 (67.432)	Acc@5 98.438 (98.157)
Epoch: [28][700/875]	Time 0.493 (0.507)	Data 0.007 (0.009)	Loss 3.0923 (3.0389)	Loss@kd 2.1397 (2.1535)	Acc@1 64.062 (67.602)	Acc@5 100.000 (98.217)
Epoch: [28][800/875]	Time 0.493 (0.507)	Data 0.005 (0.009)	Loss 3.0922 (3.0388)	Loss@kd 2.1403 (2.1517)	Acc@1 56.250 (67.576)	Acc@5 96.875 (98.194)
 * Acc@1 67.445 Acc@5 98.182
epoch 28, total time 444.44
Test: [0/750]	Time 0.753 (0.753)	Loss 0.5035 (0.5035)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.015 (0.031)	Loss 0.3273 (0.4762)	Acc@1 84.375 (86.015)	Acc@5 100.000 (92.605)
Test: [200/750]	Time 0.039 (0.029)	Loss 1.9762 (0.4688)	Acc@1 21.875 (85.386)	Acc@5 71.875 (94.512)
Test: [300/750]	Time 0.026 (0.028)	Loss 1.5482 (0.8483)	Acc@1 43.750 (69.923)	Acc@5 90.625 (90.272)
Test: [400/750]	Time 0.035 (0.027)	Loss 0.6156 (0.9709)	Acc@1 84.375 (64.152)	Acc@5 87.500 (89.620)
Test: [500/750]	Time 0.017 (0.027)	Loss 1.1690 (0.9493)	Acc@1 56.250 (65.775)	Acc@5 90.625 (89.646)
Test: [600/750]	Time 0.037 (0.026)	Loss 0.6284 (0.9831)	Acc@1 75.000 (64.335)	Acc@5 93.750 (89.658)
Test: [700/750]	Time 0.017 (0.026)	Loss 0.9658 (0.9651)	Acc@1 68.750 (64.626)	Acc@5 84.375 (90.456)
 * Acc@1 65.021 Acc@5 90.504
==> training...
Epoch: [29][0/875]	Time 1.865 (1.865)	Data 1.374 (1.374)	Loss 3.0893 (3.0893)	Loss@kd 2.1340 (2.1340)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [29][100/875]	Time 0.522 (0.523)	Data 0.007 (0.021)	Loss 3.0171 (3.0293)	Loss@kd 2.2926 (2.1434)	Acc@1 70.312 (68.363)	Acc@5 98.438 (98.144)
Epoch: [29][200/875]	Time 0.525 (0.503)	Data 0.008 (0.014)	Loss 2.9993 (3.0106)	Loss@kd 2.0983 (2.1377)	Acc@1 67.188 (68.346)	Acc@5 96.875 (98.298)
Epoch: [29][300/875]	Time 0.493 (0.505)	Data 0.007 (0.012)	Loss 3.0587 (3.0140)	Loss@kd 2.1633 (2.1367)	Acc@1 67.188 (68.215)	Acc@5 96.875 (98.251)
Epoch: [29][400/875]	Time 0.507 (0.506)	Data 0.008 (0.011)	Loss 2.9991 (3.0163)	Loss@kd 2.1754 (2.1386)	Acc@1 70.312 (68.216)	Acc@5 100.000 (98.180)
Epoch: [29][500/875]	Time 0.495 (0.507)	Data 0.008 (0.010)	Loss 2.8978 (3.0133)	Loss@kd 2.0322 (2.1369)	Acc@1 68.750 (68.320)	Acc@5 100.000 (98.185)
Epoch: [29][600/875]	Time 0.501 (0.508)	Data 0.005 (0.010)	Loss 2.9166 (3.0162)	Loss@kd 2.0918 (2.1371)	Acc@1 71.875 (68.175)	Acc@5 96.875 (98.188)
Epoch: [29][700/875]	Time 0.607 (0.508)	Data 0.008 (0.009)	Loss 3.3255 (3.0200)	Loss@kd 2.0750 (2.1372)	Acc@1 60.938 (68.023)	Acc@5 93.750 (98.188)
Epoch: [29][800/875]	Time 0.529 (0.508)	Data 0.006 (0.009)	Loss 2.8134 (3.0188)	Loss@kd 2.0819 (2.1379)	Acc@1 70.312 (68.020)	Acc@5 100.000 (98.207)
 * Acc@1 67.988 Acc@5 98.227
epoch 29, total time 442.87
Test: [0/750]	Time 0.789 (0.789)	Loss 0.4379 (0.4379)	Acc@1 87.500 (87.500)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.022 (0.034)	Loss 0.4551 (0.3748)	Acc@1 81.250 (87.469)	Acc@5 96.875 (94.771)
Test: [200/750]	Time 0.021 (0.031)	Loss 1.2308 (0.4541)	Acc@1 62.500 (84.919)	Acc@5 96.875 (96.175)
Test: [300/750]	Time 0.037 (0.030)	Loss 1.5362 (0.7126)	Acc@1 37.500 (73.983)	Acc@5 90.625 (95.141)
Test: [400/750]	Time 0.025 (0.030)	Loss 1.0439 (0.9145)	Acc@1 62.500 (65.228)	Acc@5 87.500 (92.581)
Test: [500/750]	Time 0.034 (0.030)	Loss 0.6424 (0.9286)	Acc@1 71.875 (65.563)	Acc@5 100.000 (91.717)
Test: [600/750]	Time 0.029 (0.030)	Loss 1.0039 (0.9291)	Acc@1 62.500 (65.859)	Acc@5 84.375 (91.769)
Test: [700/750]	Time 0.028 (0.029)	Loss 0.7278 (0.9123)	Acc@1 78.125 (66.365)	Acc@5 90.625 (92.163)
 * Acc@1 67.321 Acc@5 92.421
==> training...
Epoch: [30][0/875]	Time 1.713 (1.713)	Data 1.194 (1.194)	Loss 3.1814 (3.1814)	Loss@kd 2.1768 (2.1768)	Acc@1 62.500 (62.500)	Acc@5 96.875 (96.875)
Epoch: [30][100/875]	Time 0.509 (0.522)	Data 0.007 (0.019)	Loss 3.1510 (3.0134)	Loss@kd 2.3087 (2.1406)	Acc@1 70.312 (68.456)	Acc@5 100.000 (98.298)
Epoch: [30][200/875]	Time 0.525 (0.516)	Data 0.008 (0.013)	Loss 3.0188 (3.0173)	Loss@kd 2.1801 (2.1468)	Acc@1 70.312 (68.532)	Acc@5 98.438 (98.305)
Epoch: [30][300/875]	Time 0.493 (0.514)	Data 0.005 (0.011)	Loss 2.8769 (3.0226)	Loss@kd 2.2247 (2.1446)	Acc@1 73.438 (68.195)	Acc@5 100.000 (98.225)
Epoch: [30][400/875]	Time 0.523 (0.513)	Data 0.007 (0.010)	Loss 2.6655 (3.0156)	Loss@kd 1.9669 (2.1391)	Acc@1 71.875 (68.279)	Acc@5 100.000 (98.243)
Epoch: [30][500/875]	Time 0.505 (0.513)	Data 0.007 (0.009)	Loss 2.7258 (3.0133)	Loss@kd 2.0395 (2.1366)	Acc@1 76.562 (68.220)	Acc@5 100.000 (98.238)
Epoch: [30][600/875]	Time 0.525 (0.511)	Data 0.006 (0.009)	Loss 2.8889 (3.0144)	Loss@kd 2.0804 (2.1348)	Acc@1 71.875 (68.040)	Acc@5 98.438 (98.211)
Epoch: [30][700/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 3.3406 (3.0101)	Loss@kd 2.2788 (2.1300)	Acc@1 67.188 (68.059)	Acc@5 95.312 (98.195)
Epoch: [30][800/875]	Time 0.502 (0.508)	Data 0.007 (0.008)	Loss 2.9751 (3.0089)	Loss@kd 1.9763 (2.1287)	Acc@1 62.500 (67.991)	Acc@5 95.312 (98.188)
 * Acc@1 67.986 Acc@5 98.157
epoch 30, total time 444.97
Test: [0/750]	Time 0.797 (0.797)	Loss 0.7208 (0.7208)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.038 (0.037)	Loss 0.5640 (0.5294)	Acc@1 75.000 (83.973)	Acc@5 96.875 (91.708)
Test: [200/750]	Time 0.022 (0.033)	Loss 2.0517 (0.6399)	Acc@1 18.750 (78.296)	Acc@5 75.000 (92.615)
Test: [300/750]	Time 0.027 (0.032)	Loss 0.8587 (0.9810)	Acc@1 71.875 (62.220)	Acc@5 100.000 (89.628)
Test: [400/750]	Time 0.039 (0.031)	Loss 0.6630 (0.9582)	Acc@1 81.250 (63.139)	Acc@5 87.500 (91.209)
Test: [500/750]	Time 0.026 (0.031)	Loss 1.0049 (0.9338)	Acc@1 65.625 (65.351)	Acc@5 90.625 (91.161)
Test: [600/750]	Time 0.026 (0.030)	Loss 0.7409 (0.9587)	Acc@1 78.125 (65.136)	Acc@5 93.750 (90.713)
Test: [700/750]	Time 0.035 (0.030)	Loss 0.7176 (0.9375)	Acc@1 75.000 (65.349)	Acc@5 93.750 (91.606)
 * Acc@1 66.133 Acc@5 91.992
==> training...
Epoch: [31][0/875]	Time 1.825 (1.825)	Data 1.313 (1.313)	Loss 2.8656 (2.8656)	Loss@kd 2.1035 (2.1035)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [31][100/875]	Time 0.494 (0.525)	Data 0.007 (0.020)	Loss 2.9847 (2.9829)	Loss@kd 2.1432 (2.1161)	Acc@1 75.000 (68.750)	Acc@5 98.438 (98.236)
Epoch: [31][200/875]	Time 0.500 (0.518)	Data 0.007 (0.014)	Loss 3.1358 (3.0001)	Loss@kd 2.1791 (2.1221)	Acc@1 59.375 (68.221)	Acc@5 100.000 (98.220)
Epoch: [31][300/875]	Time 0.521 (0.515)	Data 0.007 (0.012)	Loss 3.0307 (2.9904)	Loss@kd 2.0965 (2.1185)	Acc@1 67.188 (68.501)	Acc@5 95.312 (98.225)
Epoch: [31][400/875]	Time 0.469 (0.509)	Data 0.007 (0.010)	Loss 2.9179 (2.9842)	Loss@kd 2.0867 (2.1130)	Acc@1 67.188 (68.450)	Acc@5 100.000 (98.262)
Epoch: [31][500/875]	Time 0.507 (0.508)	Data 0.005 (0.010)	Loss 3.0245 (2.9893)	Loss@kd 2.1446 (2.1172)	Acc@1 68.750 (68.394)	Acc@5 98.438 (98.253)
Epoch: [31][600/875]	Time 0.523 (0.508)	Data 0.010 (0.009)	Loss 3.1525 (2.9894)	Loss@kd 2.2050 (2.1155)	Acc@1 60.938 (68.248)	Acc@5 98.438 (98.243)
Epoch: [31][700/875]	Time 0.501 (0.508)	Data 0.007 (0.009)	Loss 3.0504 (2.9924)	Loss@kd 2.1460 (2.1175)	Acc@1 73.438 (68.311)	Acc@5 98.438 (98.259)
Epoch: [31][800/875]	Time 0.522 (0.509)	Data 0.008 (0.009)	Loss 2.8579 (2.9929)	Loss@kd 2.0454 (2.1158)	Acc@1 68.750 (68.212)	Acc@5 98.438 (98.248)
 * Acc@1 68.268 Acc@5 98.246
epoch 31, total time 445.41
Test: [0/750]	Time 0.780 (0.780)	Loss 0.4669 (0.4669)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.028 (0.036)	Loss 0.3522 (0.3939)	Acc@1 90.625 (87.624)	Acc@5 96.875 (94.802)
Test: [200/750]	Time 0.016 (0.031)	Loss 1.4686 (0.4238)	Acc@1 31.250 (85.945)	Acc@5 90.625 (95.927)
Test: [300/750]	Time 0.017 (0.029)	Loss 0.9571 (0.6981)	Acc@1 65.625 (73.858)	Acc@5 100.000 (94.695)
Test: [400/750]	Time 0.033 (0.029)	Loss 0.8304 (0.7521)	Acc@1 81.250 (71.540)	Acc@5 87.500 (94.670)
Test: [500/750]	Time 0.018 (0.028)	Loss 1.0143 (0.7818)	Acc@1 68.750 (71.301)	Acc@5 87.500 (93.607)
Test: [600/750]	Time 0.019 (0.027)	Loss 0.9201 (0.8509)	Acc@1 65.625 (69.078)	Acc@5 87.500 (92.700)
Test: [700/750]	Time 0.031 (0.027)	Loss 1.0322 (0.8692)	Acc@1 62.500 (67.872)	Acc@5 90.625 (92.832)
 * Acc@1 67.950 Acc@5 92.800
==> training...
Epoch: [32][0/875]	Time 1.811 (1.811)	Data 1.319 (1.319)	Loss 3.0604 (3.0604)	Loss@kd 2.1556 (2.1556)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [32][100/875]	Time 0.499 (0.522)	Data 0.007 (0.020)	Loss 3.0529 (2.9787)	Loss@kd 2.1409 (2.1263)	Acc@1 64.062 (68.332)	Acc@5 98.438 (98.345)
Epoch: [32][200/875]	Time 0.560 (0.501)	Data 0.007 (0.014)	Loss 2.9405 (2.9736)	Loss@kd 2.1611 (2.1129)	Acc@1 70.312 (68.447)	Acc@5 96.875 (98.282)
Epoch: [32][300/875]	Time 0.501 (0.504)	Data 0.007 (0.012)	Loss 2.8940 (2.9843)	Loss@kd 2.1197 (2.1137)	Acc@1 62.500 (68.293)	Acc@5 98.438 (98.240)
Epoch: [32][400/875]	Time 0.503 (0.506)	Data 0.006 (0.011)	Loss 2.9561 (2.9875)	Loss@kd 2.1101 (2.1146)	Acc@1 67.188 (68.169)	Acc@5 100.000 (98.231)
Epoch: [32][500/875]	Time 0.506 (0.507)	Data 0.006 (0.010)	Loss 3.0368 (2.9816)	Loss@kd 2.1088 (2.1095)	Acc@1 62.500 (68.167)	Acc@5 98.438 (98.213)
Epoch: [32][600/875]	Time 0.527 (0.507)	Data 0.008 (0.010)	Loss 3.1931 (2.9819)	Loss@kd 2.1596 (2.1102)	Acc@1 57.812 (68.227)	Acc@5 100.000 (98.183)
Epoch: [32][700/875]	Time 0.515 (0.508)	Data 0.011 (0.009)	Loss 2.9101 (2.9802)	Loss@kd 1.9803 (2.1100)	Acc@1 65.625 (68.251)	Acc@5 98.438 (98.201)
Epoch: [32][800/875]	Time 0.503 (0.508)	Data 0.008 (0.009)	Loss 3.0554 (2.9801)	Loss@kd 2.1396 (2.1091)	Acc@1 67.188 (68.235)	Acc@5 98.438 (98.239)
 * Acc@1 68.216 Acc@5 98.207
epoch 32, total time 443.34
Test: [0/750]	Time 0.651 (0.651)	Loss 0.4688 (0.4688)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.024 (0.027)	Loss 0.4239 (0.4500)	Acc@1 84.375 (84.653)	Acc@5 100.000 (95.080)
Test: [200/750]	Time 0.027 (0.025)	Loss 1.0138 (0.4939)	Acc@1 56.250 (83.225)	Acc@5 96.875 (96.284)
Test: [300/750]	Time 0.017 (0.024)	Loss 1.6067 (0.6853)	Acc@1 31.250 (75.613)	Acc@5 87.500 (95.432)
Test: [400/750]	Time 0.028 (0.023)	Loss 0.8699 (0.9062)	Acc@1 78.125 (65.555)	Acc@5 87.500 (91.615)
Test: [500/750]	Time 0.025 (0.025)	Loss 0.6454 (0.9096)	Acc@1 81.250 (66.860)	Acc@5 100.000 (91.087)
Test: [600/750]	Time 0.038 (0.025)	Loss 0.9728 (0.9018)	Acc@1 62.500 (67.512)	Acc@5 90.625 (91.525)
Test: [700/750]	Time 0.039 (0.026)	Loss 1.2044 (0.9068)	Acc@1 59.375 (67.190)	Acc@5 81.250 (91.713)
 * Acc@1 67.117 Acc@5 91.500
==> training...
Epoch: [33][0/875]	Time 1.900 (1.900)	Data 1.399 (1.399)	Loss 2.9294 (2.9294)	Loss@kd 2.1274 (2.1274)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [33][100/875]	Time 0.529 (0.524)	Data 0.008 (0.021)	Loss 3.3072 (2.9778)	Loss@kd 2.1673 (2.1042)	Acc@1 59.375 (68.286)	Acc@5 96.875 (98.314)
Epoch: [33][200/875]	Time 0.512 (0.517)	Data 0.007 (0.014)	Loss 2.8180 (2.9671)	Loss@kd 2.1127 (2.1018)	Acc@1 70.312 (68.595)	Acc@5 98.438 (98.119)
Epoch: [33][300/875]	Time 0.531 (0.515)	Data 0.007 (0.011)	Loss 2.7196 (2.9604)	Loss@kd 1.9616 (2.1017)	Acc@1 67.188 (68.776)	Acc@5 98.438 (98.219)
Epoch: [33][400/875]	Time 0.499 (0.514)	Data 0.006 (0.010)	Loss 3.0863 (2.9642)	Loss@kd 2.0694 (2.1020)	Acc@1 64.062 (68.641)	Acc@5 98.438 (98.243)
Epoch: [33][500/875]	Time 0.506 (0.513)	Data 0.007 (0.010)	Loss 2.8380 (2.9665)	Loss@kd 2.0953 (2.1024)	Acc@1 68.750 (68.582)	Acc@5 98.438 (98.225)
Epoch: [33][600/875]	Time 0.530 (0.512)	Data 0.006 (0.009)	Loss 2.8955 (2.9682)	Loss@kd 2.0410 (2.1041)	Acc@1 70.312 (68.521)	Acc@5 98.438 (98.258)
Epoch: [33][700/875]	Time 0.526 (0.508)	Data 0.006 (0.009)	Loss 2.9395 (2.9689)	Loss@kd 2.2557 (2.1037)	Acc@1 78.125 (68.456)	Acc@5 100.000 (98.270)
Epoch: [33][800/875]	Time 0.510 (0.508)	Data 0.007 (0.009)	Loss 2.7033 (2.9727)	Loss@kd 1.9366 (2.1037)	Acc@1 75.000 (68.299)	Acc@5 96.875 (98.285)
 * Acc@1 68.307 Acc@5 98.291
epoch 33, total time 444.86
Test: [0/750]	Time 0.744 (0.744)	Loss 0.4625 (0.4625)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.037 (0.035)	Loss 0.5208 (0.4382)	Acc@1 81.250 (85.582)	Acc@5 100.000 (94.462)
Test: [200/750]	Time 0.016 (0.029)	Loss 1.3451 (0.5117)	Acc@1 34.375 (81.981)	Acc@5 90.625 (95.631)
Test: [300/750]	Time 0.019 (0.028)	Loss 1.5337 (0.7932)	Acc@1 37.500 (70.131)	Acc@5 78.125 (93.719)
Test: [400/750]	Time 0.027 (0.028)	Loss 0.8118 (0.9625)	Acc@1 81.250 (63.459)	Acc@5 90.625 (90.641)
Test: [500/750]	Time 0.016 (0.027)	Loss 0.3091 (0.9036)	Acc@1 96.875 (66.386)	Acc@5 100.000 (90.868)
Test: [600/750]	Time 0.036 (0.027)	Loss 0.8323 (0.8639)	Acc@1 65.625 (68.334)	Acc@5 93.750 (91.753)
Test: [700/750]	Time 0.019 (0.027)	Loss 1.0982 (0.8649)	Acc@1 62.500 (68.411)	Acc@5 81.250 (91.927)
 * Acc@1 68.254 Acc@5 91.658
saving the best model!
==> training...
Epoch: [34][0/875]	Time 1.866 (1.866)	Data 1.354 (1.354)	Loss 2.7211 (2.7211)	Loss@kd 2.1821 (2.1821)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [34][100/875]	Time 0.490 (0.522)	Data 0.007 (0.020)	Loss 3.0346 (2.9291)	Loss@kd 2.1154 (2.0987)	Acc@1 65.625 (70.220)	Acc@5 98.438 (98.577)
Epoch: [34][200/875]	Time 0.506 (0.516)	Data 0.007 (0.014)	Loss 3.0841 (2.9482)	Loss@kd 2.0841 (2.0948)	Acc@1 64.062 (68.820)	Acc@5 98.438 (98.406)
Epoch: [34][300/875]	Time 0.524 (0.514)	Data 0.008 (0.012)	Loss 2.8404 (2.9446)	Loss@kd 2.0514 (2.0895)	Acc@1 67.188 (68.859)	Acc@5 100.000 (98.339)
Epoch: [34][400/875]	Time 0.516 (0.513)	Data 0.007 (0.011)	Loss 2.9848 (2.9494)	Loss@kd 2.1034 (2.0900)	Acc@1 67.188 (68.727)	Acc@5 96.875 (98.309)
Epoch: [34][500/875]	Time 0.495 (0.506)	Data 0.005 (0.010)	Loss 2.9109 (2.9510)	Loss@kd 2.1893 (2.0907)	Acc@1 73.438 (68.738)	Acc@5 100.000 (98.316)
Epoch: [34][600/875]	Time 0.508 (0.507)	Data 0.007 (0.009)	Loss 2.7329 (2.9513)	Loss@kd 2.0437 (2.0901)	Acc@1 78.125 (68.766)	Acc@5 98.438 (98.300)
Epoch: [34][700/875]	Time 0.498 (0.507)	Data 0.007 (0.009)	Loss 3.1841 (2.9515)	Loss@kd 2.2423 (2.0899)	Acc@1 62.500 (68.786)	Acc@5 92.188 (98.273)
Epoch: [34][800/875]	Time 0.497 (0.507)	Data 0.007 (0.009)	Loss 2.9445 (2.9554)	Loss@kd 1.9983 (2.0900)	Acc@1 67.188 (68.571)	Acc@5 96.875 (98.256)
 * Acc@1 68.570 Acc@5 98.271
epoch 34, total time 444.48
Test: [0/750]	Time 0.699 (0.699)	Loss 0.5530 (0.5530)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.042 (0.034)	Loss 0.5534 (0.4440)	Acc@1 71.875 (86.355)	Acc@5 100.000 (93.874)
Test: [200/750]	Time 0.038 (0.031)	Loss 1.7176 (0.5504)	Acc@1 25.000 (80.613)	Acc@5 78.125 (94.854)
Test: [300/750]	Time 0.022 (0.030)	Loss 1.0430 (0.8433)	Acc@1 68.750 (67.390)	Acc@5 93.750 (92.930)
Test: [400/750]	Time 0.042 (0.030)	Loss 0.6629 (0.8965)	Acc@1 78.125 (64.815)	Acc@5 87.500 (93.173)
Test: [500/750]	Time 0.040 (0.030)	Loss 0.8039 (0.8593)	Acc@1 75.000 (67.259)	Acc@5 93.750 (92.958)
Test: [600/750]	Time 0.027 (0.030)	Loss 0.6919 (0.8652)	Acc@1 75.000 (68.017)	Acc@5 90.625 (92.726)
Test: [700/750]	Time 0.041 (0.029)	Loss 0.9077 (0.8487)	Acc@1 71.875 (68.799)	Acc@5 87.500 (93.050)
 * Acc@1 69.208 Acc@5 93.067
saving the best model!
==> training...
Epoch: [35][0/875]	Time 1.858 (1.858)	Data 1.333 (1.333)	Loss 2.9006 (2.9006)	Loss@kd 2.0975 (2.0975)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [35][100/875]	Time 0.524 (0.524)	Data 0.007 (0.020)	Loss 2.8620 (2.9323)	Loss@kd 2.0942 (2.0824)	Acc@1 71.875 (68.967)	Acc@5 98.438 (98.530)
Epoch: [35][200/875]	Time 0.466 (0.515)	Data 0.007 (0.014)	Loss 2.6857 (2.9358)	Loss@kd 2.1085 (2.0841)	Acc@1 76.562 (68.859)	Acc@5 100.000 (98.406)
Epoch: [35][300/875]	Time 0.503 (0.505)	Data 0.008 (0.012)	Loss 2.9078 (2.9454)	Loss@kd 2.0989 (2.0866)	Acc@1 71.875 (68.646)	Acc@5 100.000 (98.323)
Epoch: [35][400/875]	Time 0.530 (0.506)	Data 0.011 (0.010)	Loss 2.9771 (2.9471)	Loss@kd 2.1498 (2.0862)	Acc@1 65.625 (68.649)	Acc@5 98.438 (98.309)
Epoch: [35][500/875]	Time 0.500 (0.507)	Data 0.007 (0.010)	Loss 2.8490 (2.9425)	Loss@kd 2.0583 (2.0847)	Acc@1 68.750 (68.691)	Acc@5 98.438 (98.353)
Epoch: [35][600/875]	Time 0.524 (0.507)	Data 0.008 (0.009)	Loss 3.0478 (2.9449)	Loss@kd 2.0435 (2.0854)	Acc@1 62.500 (68.745)	Acc@5 98.438 (98.318)
Epoch: [35][700/875]	Time 0.532 (0.508)	Data 0.008 (0.009)	Loss 3.1984 (2.9458)	Loss@kd 2.2839 (2.0854)	Acc@1 60.938 (68.712)	Acc@5 96.875 (98.288)
Epoch: [35][800/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss 2.9675 (2.9426)	Loss@kd 1.9391 (2.0835)	Acc@1 60.938 (68.678)	Acc@5 98.438 (98.330)
 * Acc@1 68.657 Acc@5 98.355
epoch 35, total time 444.92
Test: [0/750]	Time 0.769 (0.769)	Loss 0.5211 (0.5211)	Acc@1 84.375 (84.375)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.025 (0.032)	Loss 0.4469 (0.4468)	Acc@1 87.500 (85.551)	Acc@5 100.000 (93.781)
Test: [200/750]	Time 0.017 (0.029)	Loss 1.3203 (0.4776)	Acc@1 43.750 (83.458)	Acc@5 87.500 (95.553)
Test: [300/750]	Time 0.017 (0.027)	Loss 1.1272 (0.7148)	Acc@1 50.000 (73.152)	Acc@5 93.750 (94.539)
Test: [400/750]	Time 0.034 (0.027)	Loss 0.5923 (0.7933)	Acc@1 81.250 (69.927)	Acc@5 96.875 (94.023)
Test: [500/750]	Time 0.015 (0.026)	Loss 0.7514 (0.7716)	Acc@1 71.875 (71.532)	Acc@5 93.750 (93.775)
Test: [600/750]	Time 0.021 (0.026)	Loss 0.7546 (0.7930)	Acc@1 68.750 (71.189)	Acc@5 93.750 (93.480)
Test: [700/750]	Time 0.020 (0.025)	Loss 1.1660 (0.8082)	Acc@1 65.625 (70.475)	Acc@5 87.500 (93.465)
 * Acc@1 70.075 Acc@5 93.192
saving the best model!
==> training...
Epoch: [36][0/875]	Time 1.671 (1.671)	Data 1.215 (1.215)	Loss 3.0067 (3.0067)	Loss@kd 2.0052 (2.0052)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [36][100/875]	Time 0.503 (0.510)	Data 0.006 (0.019)	Loss 2.7095 (2.9125)	Loss@kd 2.0367 (2.0631)	Acc@1 71.875 (68.673)	Acc@5 100.000 (98.329)
Epoch: [36][200/875]	Time 0.497 (0.510)	Data 0.007 (0.013)	Loss 2.9313 (2.9221)	Loss@kd 2.0085 (2.0722)	Acc@1 70.312 (68.804)	Acc@5 100.000 (98.453)
Epoch: [36][300/875]	Time 0.531 (0.510)	Data 0.007 (0.011)	Loss 2.8970 (2.9217)	Loss@kd 2.0551 (2.0741)	Acc@1 62.500 (69.025)	Acc@5 100.000 (98.401)
Epoch: [36][400/875]	Time 0.499 (0.510)	Data 0.008 (0.010)	Loss 2.8203 (2.9233)	Loss@kd 2.1549 (2.0757)	Acc@1 78.125 (69.015)	Acc@5 100.000 (98.375)
Epoch: [36][500/875]	Time 0.524 (0.510)	Data 0.006 (0.010)	Loss 3.2004 (2.9286)	Loss@kd 2.2337 (2.0766)	Acc@1 64.062 (68.859)	Acc@5 96.875 (98.356)
Epoch: [36][600/875]	Time 0.512 (0.510)	Data 0.008 (0.009)	Loss 2.9378 (2.9298)	Loss@kd 2.0114 (2.0753)	Acc@1 64.062 (68.823)	Acc@5 96.875 (98.352)
Epoch: [36][700/875]	Time 0.472 (0.509)	Data 0.007 (0.009)	Loss 2.8129 (2.9295)	Loss@kd 2.0789 (2.0731)	Acc@1 76.562 (68.819)	Acc@5 98.438 (98.346)
Epoch: [36][800/875]	Time 0.528 (0.507)	Data 0.008 (0.009)	Loss 2.9272 (2.9291)	Loss@kd 2.1066 (2.0719)	Acc@1 70.312 (68.781)	Acc@5 100.000 (98.369)
 * Acc@1 68.709 Acc@5 98.350
epoch 36, total time 444.38
Test: [0/750]	Time 0.688 (0.688)	Loss 0.6197 (0.6197)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.020 (0.036)	Loss 0.3773 (0.5504)	Acc@1 87.500 (84.406)	Acc@5 100.000 (91.770)
Test: [200/750]	Time 0.034 (0.033)	Loss 1.4830 (0.5304)	Acc@1 28.125 (83.287)	Acc@5 90.625 (94.325)
Test: [300/750]	Time 0.036 (0.032)	Loss 0.6951 (0.7692)	Acc@1 81.250 (72.093)	Acc@5 96.875 (93.553)
Test: [400/750]	Time 0.022 (0.031)	Loss 0.6021 (0.7691)	Acc@1 75.000 (71.548)	Acc@5 93.750 (94.296)
Test: [500/750]	Time 0.035 (0.031)	Loss 1.3254 (0.7805)	Acc@1 56.250 (72.081)	Acc@5 81.250 (93.513)
Test: [600/750]	Time 0.026 (0.030)	Loss 0.8072 (0.8585)	Acc@1 68.750 (69.899)	Acc@5 90.625 (92.284)
Test: [700/750]	Time 0.040 (0.030)	Loss 1.1357 (0.8733)	Acc@1 62.500 (68.594)	Acc@5 81.250 (92.569)
 * Acc@1 68.292 Acc@5 92.412
==> training...
Epoch: [37][0/875]	Time 1.852 (1.852)	Data 1.341 (1.341)	Loss 3.0399 (3.0399)	Loss@kd 2.0940 (2.0940)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [37][100/875]	Time 0.496 (0.524)	Data 0.007 (0.021)	Loss 3.0815 (2.9502)	Loss@kd 2.0692 (2.0903)	Acc@1 59.375 (68.704)	Acc@5 95.312 (98.422)
Epoch: [37][200/875]	Time 0.511 (0.517)	Data 0.006 (0.014)	Loss 2.7803 (2.9295)	Loss@kd 2.0337 (2.0730)	Acc@1 76.562 (68.952)	Acc@5 98.438 (98.313)
Epoch: [37][300/875]	Time 0.497 (0.515)	Data 0.007 (0.012)	Loss 2.7954 (2.9299)	Loss@kd 1.9861 (2.0683)	Acc@1 73.438 (68.828)	Acc@5 98.438 (98.282)
Epoch: [37][400/875]	Time 0.511 (0.514)	Data 0.007 (0.011)	Loss 3.0074 (2.9248)	Loss@kd 2.0733 (2.0674)	Acc@1 67.188 (68.875)	Acc@5 96.875 (98.375)
Epoch: [37][500/875]	Time 0.512 (0.509)	Data 0.007 (0.010)	Loss 2.7677 (2.9193)	Loss@kd 2.0029 (2.0653)	Acc@1 68.750 (68.890)	Acc@5 100.000 (98.388)
Epoch: [37][600/875]	Time 0.527 (0.509)	Data 0.006 (0.010)	Loss 3.0001 (2.9217)	Loss@kd 2.0200 (2.0659)	Acc@1 65.625 (68.794)	Acc@5 100.000 (98.383)
Epoch: [37][700/875]	Time 0.503 (0.509)	Data 0.007 (0.009)	Loss 2.9689 (2.9205)	Loss@kd 2.1449 (2.0656)	Acc@1 79.688 (68.873)	Acc@5 100.000 (98.411)
Epoch: [37][800/875]	Time 0.529 (0.509)	Data 0.008 (0.009)	Loss 2.9375 (2.9237)	Loss@kd 2.1868 (2.0667)	Acc@1 71.875 (68.840)	Acc@5 100.000 (98.410)
 * Acc@1 68.843 Acc@5 98.404
epoch 37, total time 445.98
Test: [0/750]	Time 0.675 (0.675)	Loss 0.5468 (0.5468)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.038 (0.034)	Loss 0.4188 (0.4770)	Acc@1 84.375 (85.489)	Acc@5 96.875 (92.543)
Test: [200/750]	Time 0.037 (0.032)	Loss 1.4122 (0.5072)	Acc@1 28.125 (82.680)	Acc@5 87.500 (94.932)
Test: [300/750]	Time 0.024 (0.031)	Loss 1.0686 (0.7742)	Acc@1 59.375 (69.923)	Acc@5 93.750 (94.030)
Test: [400/750]	Time 0.021 (0.031)	Loss 0.5630 (0.8281)	Acc@1 84.375 (67.721)	Acc@5 90.625 (93.960)
Test: [500/750]	Time 0.025 (0.030)	Loss 0.6450 (0.7986)	Acc@1 78.125 (69.998)	Acc@5 96.875 (93.619)
Test: [600/750]	Time 0.023 (0.030)	Loss 0.6566 (0.8044)	Acc@1 78.125 (70.554)	Acc@5 96.875 (93.376)
Test: [700/750]	Time 0.025 (0.030)	Loss 0.9455 (0.8031)	Acc@1 68.750 (70.587)	Acc@5 87.500 (93.572)
 * Acc@1 70.646 Acc@5 93.371
saving the best model!
==> training...
Epoch: [38][0/875]	Time 1.832 (1.832)	Data 1.323 (1.323)	Loss 3.0585 (3.0585)	Loss@kd 2.0810 (2.0810)	Acc@1 70.312 (70.312)	Acc@5 95.312 (95.312)
Epoch: [38][100/875]	Time 0.500 (0.523)	Data 0.006 (0.020)	Loss 2.8127 (2.9167)	Loss@kd 2.0965 (2.0648)	Acc@1 70.312 (69.028)	Acc@5 100.000 (98.376)
Epoch: [38][200/875]	Time 0.507 (0.516)	Data 0.010 (0.014)	Loss 2.8884 (2.9105)	Loss@kd 2.0853 (2.0597)	Acc@1 75.000 (68.968)	Acc@5 96.875 (98.375)
Epoch: [38][300/875]	Time 0.502 (0.503)	Data 0.006 (0.011)	Loss 2.8021 (2.8911)	Loss@kd 2.0414 (2.0575)	Acc@1 71.875 (69.544)	Acc@5 98.438 (98.489)
Epoch: [38][400/875]	Time 0.521 (0.505)	Data 0.008 (0.010)	Loss 2.8176 (2.9037)	Loss@kd 2.0776 (2.0589)	Acc@1 71.875 (69.120)	Acc@5 98.438 (98.473)
Epoch: [38][500/875]	Time 0.499 (0.506)	Data 0.007 (0.010)	Loss 2.7371 (2.9073)	Loss@kd 1.9883 (2.0598)	Acc@1 78.125 (69.056)	Acc@5 100.000 (98.459)
Epoch: [38][600/875]	Time 0.525 (0.506)	Data 0.008 (0.009)	Loss 3.1602 (2.9066)	Loss@kd 2.1010 (2.0604)	Acc@1 59.375 (69.059)	Acc@5 98.438 (98.461)
Epoch: [38][700/875]	Time 0.495 (0.507)	Data 0.007 (0.009)	Loss 2.7533 (2.9097)	Loss@kd 2.0339 (2.0599)	Acc@1 79.688 (68.904)	Acc@5 100.000 (98.446)
Epoch: [38][800/875]	Time 0.530 (0.507)	Data 0.006 (0.009)	Loss 3.0515 (2.9123)	Loss@kd 2.1184 (2.0625)	Acc@1 67.188 (68.947)	Acc@5 100.000 (98.428)
 * Acc@1 68.861 Acc@5 98.420
epoch 38, total time 444.53
Test: [0/750]	Time 0.698 (0.698)	Loss 0.5457 (0.5457)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.050 (0.035)	Loss 0.2488 (0.5282)	Acc@1 90.625 (84.715)	Acc@5 100.000 (92.760)
Test: [200/750]	Time 0.024 (0.032)	Loss 1.3646 (0.4599)	Acc@1 43.750 (85.681)	Acc@5 87.500 (95.351)
Test: [300/750]	Time 0.020 (0.031)	Loss 1.3601 (0.7149)	Acc@1 43.750 (74.979)	Acc@5 84.375 (93.802)
Test: [400/750]	Time 0.033 (0.031)	Loss 0.5245 (0.8420)	Acc@1 84.375 (68.921)	Acc@5 87.500 (93.181)
Test: [500/750]	Time 0.040 (0.030)	Loss 0.8681 (0.8175)	Acc@1 68.750 (70.521)	Acc@5 90.625 (92.727)
Test: [600/750]	Time 0.027 (0.030)	Loss 0.7300 (0.8489)	Acc@1 71.875 (69.670)	Acc@5 100.000 (92.523)
Test: [700/750]	Time 0.025 (0.030)	Loss 0.9220 (0.8504)	Acc@1 65.625 (69.116)	Acc@5 87.500 (92.854)
 * Acc@1 69.221 Acc@5 92.771
==> training...
Epoch: [39][0/875]	Time 1.776 (1.776)	Data 1.266 (1.266)	Loss 2.9498 (2.9498)	Loss@kd 2.0292 (2.0292)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [39][100/875]	Time 0.522 (0.498)	Data 0.007 (0.019)	Loss 3.0187 (2.8964)	Loss@kd 2.1307 (2.0570)	Acc@1 68.750 (69.214)	Acc@5 95.312 (98.453)
Epoch: [39][200/875]	Time 0.524 (0.504)	Data 0.007 (0.013)	Loss 3.0156 (2.8907)	Loss@kd 2.0579 (2.0486)	Acc@1 67.188 (69.636)	Acc@5 100.000 (98.321)
Epoch: [39][300/875]	Time 0.508 (0.506)	Data 0.007 (0.011)	Loss 2.9840 (2.8937)	Loss@kd 1.9742 (2.0481)	Acc@1 59.375 (69.305)	Acc@5 98.438 (98.360)
Epoch: [39][400/875]	Time 0.495 (0.508)	Data 0.005 (0.010)	Loss 2.9422 (2.8956)	Loss@kd 2.0436 (2.0512)	Acc@1 67.188 (69.463)	Acc@5 96.875 (98.266)
Epoch: [39][500/875]	Time 0.495 (0.508)	Data 0.007 (0.009)	Loss 2.8826 (2.8973)	Loss@kd 2.1490 (2.0509)	Acc@1 76.562 (69.555)	Acc@5 98.438 (98.278)
Epoch: [39][600/875]	Time 0.521 (0.509)	Data 0.007 (0.009)	Loss 3.0694 (2.9006)	Loss@kd 2.0852 (2.0496)	Acc@1 70.312 (69.314)	Acc@5 96.875 (98.235)
Epoch: [39][700/875]	Time 0.492 (0.509)	Data 0.007 (0.009)	Loss 2.8020 (2.8991)	Loss@kd 1.9994 (2.0496)	Acc@1 71.875 (69.361)	Acc@5 100.000 (98.266)
Epoch: [39][800/875]	Time 0.509 (0.506)	Data 0.006 (0.009)	Loss 3.0570 (2.9017)	Loss@kd 2.0617 (2.0500)	Acc@1 68.750 (69.226)	Acc@5 98.438 (98.262)
 * Acc@1 69.184 Acc@5 98.277
epoch 39, total time 443.17
Test: [0/750]	Time 0.655 (0.655)	Loss 0.7533 (0.7533)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.025 (0.036)	Loss 0.4072 (0.6625)	Acc@1 78.125 (81.745)	Acc@5 100.000 (89.264)
Test: [200/750]	Time 0.021 (0.032)	Loss 1.6532 (0.5977)	Acc@1 18.750 (80.892)	Acc@5 81.250 (93.050)
Test: [300/750]	Time 0.024 (0.032)	Loss 0.8599 (0.8531)	Acc@1 71.875 (67.764)	Acc@5 96.875 (91.964)
Test: [400/750]	Time 0.040 (0.031)	Loss 0.4745 (0.8233)	Acc@1 84.375 (69.124)	Acc@5 96.875 (93.267)
Test: [500/750]	Time 0.027 (0.031)	Loss 0.9913 (0.8109)	Acc@1 59.375 (70.322)	Acc@5 93.750 (93.070)
Test: [600/750]	Time 0.027 (0.030)	Loss 0.7996 (0.8552)	Acc@1 71.875 (69.114)	Acc@5 93.750 (92.346)
Test: [700/750]	Time 0.039 (0.030)	Loss 0.9882 (0.8642)	Acc@1 68.750 (68.304)	Acc@5 81.250 (92.667)
 * Acc@1 68.058 Acc@5 92.579
==> training...
Epoch: [40][0/875]	Time 1.883 (1.883)	Data 1.373 (1.373)	Loss 2.9798 (2.9798)	Loss@kd 2.0484 (2.0484)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [40][100/875]	Time 0.496 (0.523)	Data 0.006 (0.020)	Loss 2.8040 (2.8974)	Loss@kd 2.0441 (2.0431)	Acc@1 68.750 (68.487)	Acc@5 98.438 (98.283)
Epoch: [40][200/875]	Time 0.504 (0.516)	Data 0.007 (0.014)	Loss 2.9386 (2.9083)	Loss@kd 2.0654 (2.0570)	Acc@1 68.750 (69.069)	Acc@5 98.438 (98.259)
Epoch: [40][300/875]	Time 0.490 (0.514)	Data 0.007 (0.012)	Loss 3.0842 (2.9086)	Loss@kd 2.0130 (2.0534)	Acc@1 53.125 (68.952)	Acc@5 96.875 (98.261)
Epoch: [40][400/875]	Time 0.496 (0.513)	Data 0.008 (0.010)	Loss 2.9078 (2.9077)	Loss@kd 2.0257 (2.0531)	Acc@1 75.000 (68.992)	Acc@5 95.312 (98.254)
Epoch: [40][500/875]	Time 0.462 (0.510)	Data 0.006 (0.010)	Loss 2.7200 (2.9061)	Loss@kd 1.9370 (2.0519)	Acc@1 70.312 (69.006)	Acc@5 98.438 (98.250)
Epoch: [40][600/875]	Time 0.504 (0.507)	Data 0.007 (0.009)	Loss 2.9722 (2.8967)	Loss@kd 2.0438 (2.0491)	Acc@1 67.188 (69.187)	Acc@5 100.000 (98.287)
Epoch: [40][700/875]	Time 0.499 (0.508)	Data 0.008 (0.009)	Loss 2.7589 (2.8937)	Loss@kd 2.0659 (2.0473)	Acc@1 73.438 (69.174)	Acc@5 100.000 (98.313)
Epoch: [40][800/875]	Time 0.520 (0.508)	Data 0.007 (0.009)	Loss 3.0878 (2.8975)	Loss@kd 2.1008 (2.0479)	Acc@1 64.062 (69.103)	Acc@5 100.000 (98.317)
 * Acc@1 69.116 Acc@5 98.348
epoch 40, total time 445.15
Test: [0/750]	Time 0.684 (0.684)	Loss 0.7290 (0.7290)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.022 (0.034)	Loss 0.3539 (0.5707)	Acc@1 87.500 (84.530)	Acc@5 100.000 (91.399)
Test: [200/750]	Time 0.017 (0.031)	Loss 1.2677 (0.5330)	Acc@1 46.875 (83.411)	Acc@5 93.750 (94.372)
Test: [300/750]	Time 0.022 (0.031)	Loss 1.1655 (0.7431)	Acc@1 56.250 (73.526)	Acc@5 93.750 (94.342)
Test: [400/750]	Time 0.031 (0.030)	Loss 0.8650 (0.8319)	Acc@1 75.000 (68.805)	Acc@5 87.500 (93.695)
Test: [500/750]	Time 0.036 (0.030)	Loss 0.3052 (0.8100)	Acc@1 93.750 (70.366)	Acc@5 100.000 (93.039)
Test: [600/750]	Time 0.040 (0.030)	Loss 0.9315 (0.7929)	Acc@1 62.500 (71.178)	Acc@5 93.750 (93.433)
Test: [700/750]	Time 0.026 (0.029)	Loss 1.3426 (0.8190)	Acc@1 56.250 (69.882)	Acc@5 78.125 (93.456)
 * Acc@1 69.321 Acc@5 93.150
==> Saving...
==> training...
Epoch: [41][0/875]	Time 1.846 (1.846)	Data 1.303 (1.303)	Loss 3.0760 (3.0760)	Loss@kd 2.0619 (2.0619)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [41][100/875]	Time 0.526 (0.522)	Data 0.008 (0.020)	Loss 3.0149 (2.8966)	Loss@kd 2.0283 (2.0409)	Acc@1 64.062 (69.369)	Acc@5 95.312 (97.927)
Epoch: [41][200/875]	Time 0.496 (0.516)	Data 0.007 (0.014)	Loss 3.2070 (2.8954)	Loss@kd 2.0921 (2.0415)	Acc@1 54.688 (68.975)	Acc@5 96.875 (98.251)
Epoch: [41][300/875]	Time 0.458 (0.507)	Data 0.007 (0.012)	Loss 2.8687 (2.9008)	Loss@kd 2.0262 (2.0422)	Acc@1 68.750 (68.672)	Acc@5 98.438 (98.318)
Epoch: [41][400/875]	Time 0.511 (0.506)	Data 0.007 (0.011)	Loss 2.9351 (2.8878)	Loss@kd 1.9922 (2.0368)	Acc@1 62.500 (68.945)	Acc@5 100.000 (98.367)
Epoch: [41][500/875]	Time 0.493 (0.507)	Data 0.006 (0.010)	Loss 2.8344 (2.8931)	Loss@kd 2.0799 (2.0405)	Acc@1 71.875 (68.806)	Acc@5 98.438 (98.313)
Epoch: [41][600/875]	Time 0.521 (0.507)	Data 0.005 (0.010)	Loss 2.9351 (2.8893)	Loss@kd 2.0809 (2.0405)	Acc@1 75.000 (69.137)	Acc@5 96.875 (98.339)
Epoch: [41][700/875]	Time 0.606 (0.508)	Data 0.007 (0.009)	Loss 2.9382 (2.8843)	Loss@kd 2.0981 (2.0385)	Acc@1 75.000 (69.307)	Acc@5 96.875 (98.337)
Epoch: [41][800/875]	Time 0.505 (0.508)	Data 0.007 (0.009)	Loss 2.9359 (2.8853)	Loss@kd 1.9991 (2.0396)	Acc@1 70.312 (69.284)	Acc@5 96.875 (98.336)
 * Acc@1 69.311 Acc@5 98.359
epoch 41, total time 444.76
Test: [0/750]	Time 0.679 (0.679)	Loss 0.6829 (0.6829)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.020 (0.035)	Loss 0.3505 (0.5506)	Acc@1 81.250 (84.097)	Acc@5 100.000 (92.265)
Test: [200/750]	Time 0.036 (0.031)	Loss 1.2976 (0.5263)	Acc@1 40.625 (82.882)	Acc@5 90.625 (94.745)
Test: [300/750]	Time 0.024 (0.029)	Loss 0.9410 (0.7421)	Acc@1 68.750 (72.155)	Acc@5 93.750 (94.311)
Test: [400/750]	Time 0.022 (0.029)	Loss 1.0731 (0.8170)	Acc@1 71.875 (68.664)	Acc@5 84.375 (93.890)
Test: [500/750]	Time 0.019 (0.029)	Loss 0.8439 (0.8812)	Acc@1 71.875 (68.189)	Acc@5 100.000 (91.791)
Test: [600/750]	Time 0.019 (0.029)	Loss 0.6545 (0.8824)	Acc@1 78.125 (68.495)	Acc@5 96.875 (91.878)
Test: [700/750]	Time 0.017 (0.029)	Loss 1.1363 (0.8753)	Acc@1 53.125 (68.420)	Acc@5 87.500 (92.248)
 * Acc@1 68.304 Acc@5 92.112
==> training...
Epoch: [42][0/875]	Time 1.717 (1.717)	Data 1.227 (1.227)	Loss 2.7555 (2.7555)	Loss@kd 1.9608 (1.9608)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [42][100/875]	Time 0.503 (0.496)	Data 0.008 (0.019)	Loss 2.6529 (2.8629)	Loss@kd 2.0047 (2.0245)	Acc@1 82.812 (69.384)	Acc@5 100.000 (98.407)
Epoch: [42][200/875]	Time 0.525 (0.503)	Data 0.005 (0.013)	Loss 2.7783 (2.8646)	Loss@kd 1.9643 (2.0279)	Acc@1 64.062 (69.294)	Acc@5 96.875 (98.406)
Epoch: [42][300/875]	Time 0.504 (0.505)	Data 0.006 (0.011)	Loss 2.8321 (2.8713)	Loss@kd 2.0264 (2.0323)	Acc@1 70.312 (69.290)	Acc@5 98.438 (98.469)
Epoch: [42][400/875]	Time 0.521 (0.507)	Data 0.007 (0.010)	Loss 2.8662 (2.8719)	Loss@kd 2.0526 (2.0315)	Acc@1 70.312 (69.424)	Acc@5 96.875 (98.402)
Epoch: [42][500/875]	Time 0.497 (0.507)	Data 0.007 (0.010)	Loss 3.1107 (2.8753)	Loss@kd 2.1776 (2.0339)	Acc@1 64.062 (69.308)	Acc@5 98.438 (98.366)
Epoch: [42][600/875]	Time 0.612 (0.508)	Data 0.007 (0.009)	Loss 2.7750 (2.8717)	Loss@kd 2.0314 (2.0322)	Acc@1 70.312 (69.366)	Acc@5 98.438 (98.404)
Epoch: [42][700/875]	Time 0.520 (0.508)	Data 0.008 (0.009)	Loss 2.9186 (2.8714)	Loss@kd 2.0130 (2.0313)	Acc@1 60.938 (69.240)	Acc@5 100.000 (98.458)
Epoch: [42][800/875]	Time 0.496 (0.504)	Data 0.007 (0.009)	Loss 2.8762 (2.8723)	Loss@kd 2.0347 (2.0313)	Acc@1 68.750 (69.298)	Acc@5 100.000 (98.441)
 * Acc@1 69.155 Acc@5 98.411
epoch 42, total time 441.96
Test: [0/750]	Time 0.677 (0.677)	Loss 0.5668 (0.5668)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.033 (0.033)	Loss 0.4106 (0.5008)	Acc@1 84.375 (85.551)	Acc@5 100.000 (92.853)
Test: [200/750]	Time 0.040 (0.029)	Loss 1.6134 (0.5185)	Acc@1 31.250 (82.867)	Acc@5 81.250 (94.745)
Test: [300/750]	Time 0.017 (0.028)	Loss 0.9495 (0.8279)	Acc@1 68.750 (68.937)	Acc@5 96.875 (92.525)
Test: [400/750]	Time 0.017 (0.027)	Loss 0.5156 (0.8490)	Acc@1 84.375 (68.243)	Acc@5 90.625 (92.752)
Test: [500/750]	Time 0.014 (0.027)	Loss 0.6710 (0.8017)	Acc@1 78.125 (70.846)	Acc@5 93.750 (92.952)
Test: [600/750]	Time 0.038 (0.026)	Loss 0.8229 (0.8127)	Acc@1 71.875 (71.126)	Acc@5 90.625 (93.022)
Test: [700/750]	Time 0.016 (0.026)	Loss 1.2857 (0.8398)	Acc@1 56.250 (69.655)	Acc@5 78.125 (93.197)
 * Acc@1 68.871 Acc@5 92.938
==> training...
Epoch: [43][0/875]	Time 1.809 (1.809)	Data 1.307 (1.307)	Loss 2.6743 (2.6743)	Loss@kd 1.9460 (1.9460)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [43][100/875]	Time 0.491 (0.522)	Data 0.007 (0.020)	Loss 2.9653 (2.8556)	Loss@kd 2.0525 (2.0324)	Acc@1 62.500 (70.467)	Acc@5 98.438 (98.314)
Epoch: [43][200/875]	Time 0.504 (0.516)	Data 0.007 (0.014)	Loss 2.7642 (2.8527)	Loss@kd 2.0150 (2.0269)	Acc@1 79.688 (70.367)	Acc@5 98.438 (98.406)
Epoch: [43][300/875]	Time 0.522 (0.514)	Data 0.008 (0.011)	Loss 2.6591 (2.8556)	Loss@kd 1.9968 (2.0238)	Acc@1 73.438 (69.928)	Acc@5 100.000 (98.344)
Epoch: [43][400/875]	Time 0.501 (0.513)	Data 0.006 (0.010)	Loss 3.3402 (2.8656)	Loss@kd 2.2332 (2.0253)	Acc@1 57.812 (69.525)	Acc@5 96.875 (98.344)
Epoch: [43][500/875]	Time 0.532 (0.513)	Data 0.006 (0.010)	Loss 2.7602 (2.8690)	Loss@kd 2.0223 (2.0249)	Acc@1 76.562 (69.374)	Acc@5 98.438 (98.350)
Epoch: [43][600/875]	Time 0.522 (0.507)	Data 0.007 (0.009)	Loss 2.6849 (2.8697)	Loss@kd 2.0106 (2.0248)	Acc@1 67.188 (69.410)	Acc@5 100.000 (98.339)
Epoch: [43][700/875]	Time 0.499 (0.507)	Data 0.008 (0.009)	Loss 2.6822 (2.8690)	Loss@kd 2.0030 (2.0261)	Acc@1 81.250 (69.508)	Acc@5 98.438 (98.348)
Epoch: [43][800/875]	Time 0.528 (0.508)	Data 0.009 (0.009)	Loss 2.9488 (2.8670)	Loss@kd 2.0423 (2.0256)	Acc@1 73.438 (69.567)	Acc@5 98.438 (98.344)
 * Acc@1 69.463 Acc@5 98.332
epoch 43, total time 444.60
Test: [0/750]	Time 0.683 (0.683)	Loss 0.4819 (0.4819)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.040 (0.034)	Loss 0.2806 (0.4290)	Acc@1 87.500 (86.510)	Acc@5 100.000 (94.585)
Test: [200/750]	Time 0.019 (0.033)	Loss 1.5238 (0.4397)	Acc@1 43.750 (85.790)	Acc@5 84.375 (95.678)
Test: [300/750]	Time 0.034 (0.032)	Loss 0.8262 (0.7460)	Acc@1 75.000 (72.290)	Acc@5 96.875 (93.501)
Test: [400/750]	Time 0.024 (0.031)	Loss 0.8528 (0.7852)	Acc@1 71.875 (70.909)	Acc@5 84.375 (93.485)
Test: [500/750]	Time 0.021 (0.030)	Loss 0.6122 (0.7829)	Acc@1 84.375 (71.950)	Acc@5 100.000 (92.895)
Test: [600/750]	Time 0.027 (0.030)	Loss 0.8403 (0.7993)	Acc@1 56.250 (71.573)	Acc@5 96.875 (93.006)
Test: [700/750]	Time 0.032 (0.030)	Loss 1.2138 (0.8289)	Acc@1 53.125 (69.798)	Acc@5 90.625 (93.126)
 * Acc@1 69.404 Acc@5 92.958
==> training...
Epoch: [44][0/875]	Time 1.836 (1.836)	Data 1.337 (1.337)	Loss 3.0359 (3.0359)	Loss@kd 2.0461 (2.0461)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [44][100/875]	Time 0.513 (0.523)	Data 0.008 (0.020)	Loss 2.9634 (2.8813)	Loss@kd 2.0134 (2.0355)	Acc@1 70.312 (68.843)	Acc@5 95.312 (98.561)
Epoch: [44][200/875]	Time 0.524 (0.516)	Data 0.007 (0.014)	Loss 2.9283 (2.8849)	Loss@kd 2.0087 (2.0307)	Acc@1 68.750 (68.921)	Acc@5 100.000 (98.539)
Epoch: [44][300/875]	Time 0.493 (0.514)	Data 0.007 (0.011)	Loss 2.9527 (2.8727)	Loss@kd 2.0154 (2.0269)	Acc@1 70.312 (69.082)	Acc@5 93.750 (98.500)
Epoch: [44][400/875]	Time 0.517 (0.505)	Data 0.007 (0.010)	Loss 2.9796 (2.8718)	Loss@kd 2.0550 (2.0258)	Acc@1 70.312 (69.190)	Acc@5 98.438 (98.438)
Epoch: [44][500/875]	Time 0.512 (0.506)	Data 0.006 (0.010)	Loss 2.6544 (2.8711)	Loss@kd 1.9915 (2.0245)	Acc@1 84.375 (69.296)	Acc@5 98.438 (98.444)
Epoch: [44][600/875]	Time 0.529 (0.507)	Data 0.007 (0.009)	Loss 2.8275 (2.8670)	Loss@kd 2.0477 (2.0228)	Acc@1 71.875 (69.384)	Acc@5 98.438 (98.435)
Epoch: [44][700/875]	Time 0.508 (0.507)	Data 0.007 (0.009)	Loss 2.9281 (2.8649)	Loss@kd 2.0280 (2.0210)	Acc@1 75.000 (69.376)	Acc@5 96.875 (98.433)
Epoch: [44][800/875]	Time 0.494 (0.508)	Data 0.007 (0.009)	Loss 2.6980 (2.8621)	Loss@kd 1.9923 (2.0196)	Acc@1 70.312 (69.439)	Acc@5 100.000 (98.445)
 * Acc@1 69.521 Acc@5 98.405
epoch 44, total time 444.75
Test: [0/750]	Time 0.759 (0.759)	Loss 0.6648 (0.6648)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.017 (0.032)	Loss 0.6601 (0.5966)	Acc@1 68.750 (82.488)	Acc@5 100.000 (91.337)
Test: [200/750]	Time 0.018 (0.028)	Loss 1.2748 (0.6222)	Acc@1 46.875 (78.125)	Acc@5 93.750 (94.279)
Test: [300/750]	Time 0.038 (0.028)	Loss 1.0728 (0.8038)	Acc@1 50.000 (69.850)	Acc@5 90.625 (94.238)
Test: [400/750]	Time 0.024 (0.027)	Loss 0.5370 (0.8617)	Acc@1 81.250 (66.997)	Acc@5 93.750 (93.836)
Test: [500/750]	Time 0.019 (0.027)	Loss 0.5881 (0.8064)	Acc@1 81.250 (69.704)	Acc@5 93.750 (93.887)
Test: [600/750]	Time 0.029 (0.027)	Loss 0.6562 (0.7915)	Acc@1 78.125 (70.887)	Acc@5 96.875 (94.000)
Test: [700/750]	Time 0.017 (0.027)	Loss 1.1288 (0.7942)	Acc@1 62.500 (70.957)	Acc@5 84.375 (93.928)
 * Acc@1 70.567 Acc@5 93.662
==> training...
Epoch: [45][0/875]	Time 1.886 (1.886)	Data 1.426 (1.426)	Loss 3.0806 (3.0806)	Loss@kd 2.0599 (2.0599)	Acc@1 54.688 (54.688)	Acc@5 95.312 (95.312)
Epoch: [45][100/875]	Time 0.464 (0.519)	Data 0.006 (0.021)	Loss 2.9282 (2.8458)	Loss@kd 2.0094 (2.0177)	Acc@1 67.188 (69.972)	Acc@5 100.000 (98.329)
Epoch: [45][200/875]	Time 0.523 (0.500)	Data 0.006 (0.014)	Loss 2.9585 (2.8643)	Loss@kd 2.0343 (2.0249)	Acc@1 68.750 (69.450)	Acc@5 96.875 (98.274)
Epoch: [45][300/875]	Time 0.511 (0.503)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (61.130)	Acc@5 67.188 (92.956)
Epoch: [45][400/875]	Time 0.529 (0.505)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (49.041)	Acc@5 57.812 (85.423)
Epoch: [45][500/875]	Time 0.504 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (41.751)	Acc@5 73.438 (80.976)
Epoch: [45][600/875]	Time 0.496 (0.507)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (36.814)	Acc@5 56.250 (77.951)
Epoch: [45][700/875]	Time 0.522 (0.507)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (33.359)	Acc@5 68.750 (75.568)
Epoch: [45][800/875]	Time 0.513 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (30.735)	Acc@5 62.500 (73.947)
 * Acc@1 29.179 Acc@5 72.880
epoch 45, total time 441.69
Test: [0/750]	Time 0.761 (0.761)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.017 (0.035)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.026 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.028 (0.030)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.021 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.023 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.037 (0.030)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [46][0/875]	Time 1.817 (1.817)	Data 1.303 (1.303)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 60.938 (60.938)
Epoch: [46][100/875]	Time 0.507 (0.522)	Data 0.006 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.949)	Acc@5 60.938 (63.072)
Epoch: [46][200/875]	Time 0.520 (0.516)	Data 0.005 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.663)	Acc@5 53.125 (62.578)
Epoch: [46][300/875]	Time 0.496 (0.514)	Data 0.005 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.754)	Acc@5 71.875 (62.718)
Epoch: [46][400/875]	Time 0.508 (0.512)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.695)	Acc@5 56.250 (62.539)
Epoch: [46][500/875]	Time 0.494 (0.512)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.672)	Acc@5 81.250 (62.693)
Epoch: [46][600/875]	Time 0.460 (0.510)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.604)	Acc@5 56.250 (62.661)
Epoch: [46][700/875]	Time 0.502 (0.507)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.553)	Acc@5 60.938 (62.663)
Epoch: [46][800/875]	Time 0.501 (0.507)	Data 0.009 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.531)	Acc@5 70.312 (62.638)
 * Acc@1 12.500 Acc@5 62.500
epoch 46, total time 444.26
Test: [0/750]	Time 0.722 (0.722)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.034)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.025 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.027 (0.030)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.026 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.025 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.024 (0.029)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.024 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [47][0/875]	Time 1.794 (1.794)	Data 1.297 (1.297)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (7.812)	Acc@5 46.875 (46.875)
Epoch: [47][100/875]	Time 0.531 (0.523)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.546)	Acc@5 67.188 (63.830)
Epoch: [47][200/875]	Time 0.464 (0.516)	Data 0.007 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.710)	Acc@5 45.312 (63.285)
Epoch: [47][300/875]	Time 0.528 (0.514)	Data 0.008 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.625)	Acc@5 62.500 (63.118)
Epoch: [47][400/875]	Time 0.468 (0.509)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.551)	Acc@5 65.625 (62.929)
Epoch: [47][500/875]	Time 0.526 (0.508)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.488)	Acc@5 51.562 (62.774)
Epoch: [47][600/875]	Time 0.507 (0.508)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.412)	Acc@5 64.062 (62.687)
Epoch: [47][700/875]	Time 0.526 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.451)	Acc@5 60.938 (62.529)
Epoch: [47][800/875]	Time 0.497 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.459)	Acc@5 54.688 (62.533)
 * Acc@1 12.500 Acc@5 62.500
epoch 47, total time 445.39
Test: [0/750]	Time 0.656 (0.656)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.035)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.047 (0.032)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.034 (0.031)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.028 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.038 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.023 (0.030)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.020 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [48][0/875]	Time 1.757 (1.757)	Data 1.278 (1.278)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 60.938 (60.938)
Epoch: [48][100/875]	Time 0.508 (0.522)	Data 0.008 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.515)	Acc@5 59.375 (62.778)
Epoch: [48][200/875]	Time 0.511 (0.500)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.640)	Acc@5 60.938 (62.174)
Epoch: [48][300/875]	Time 0.508 (0.503)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 50.000 (62.225)
Epoch: [48][400/875]	Time 0.525 (0.505)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.492)	Acc@5 54.688 (62.142)
Epoch: [48][500/875]	Time 0.502 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.581)	Acc@5 62.500 (62.219)
Epoch: [48][600/875]	Time 0.525 (0.506)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.539)	Acc@5 59.375 (62.373)
Epoch: [48][700/875]	Time 0.502 (0.507)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.440)	Acc@5 75.000 (62.418)
Epoch: [48][800/875]	Time 0.508 (0.507)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.471)	Acc@5 68.750 (62.482)
 * Acc@1 12.500 Acc@5 62.500
epoch 48, total time 443.42
Test: [0/750]	Time 0.726 (0.726)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.021 (0.028)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.024 (0.025)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.020 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.023)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.027 (0.024)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.031 (0.024)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.037 (0.024)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [49][0/875]	Time 1.835 (1.835)	Data 1.284 (1.284)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (7.812)	Acc@5 57.812 (57.812)
Epoch: [49][100/875]	Time 0.520 (0.523)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.717)	Acc@5 70.312 (61.974)
Epoch: [49][200/875]	Time 0.507 (0.517)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.547)	Acc@5 53.125 (62.710)
Epoch: [49][300/875]	Time 0.518 (0.514)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.542)	Acc@5 60.938 (62.895)
Epoch: [49][400/875]	Time 0.502 (0.513)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.360)	Acc@5 60.938 (62.870)
Epoch: [49][500/875]	Time 0.516 (0.513)	Data 0.009 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.366)	Acc@5 67.188 (62.771)
Epoch: [49][600/875]	Time 0.514 (0.512)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.391)	Acc@5 57.812 (62.708)
Epoch: [49][700/875]	Time 0.524 (0.507)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.491)	Acc@5 64.062 (62.689)
Epoch: [49][800/875]	Time 0.503 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.541)	Acc@5 57.812 (62.705)
 * Acc@1 12.500 Acc@5 62.500
epoch 49, total time 444.67
Test: [0/750]	Time 0.705 (0.705)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.024 (0.034)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.041 (0.030)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.037 (0.028)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.015 (0.028)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.032 (0.027)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.017 (0.026)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.016 (0.026)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [50][0/875]	Time 1.716 (1.716)	Data 1.200 (1.200)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 62.500 (62.500)
Epoch: [50][100/875]	Time 0.495 (0.522)	Data 0.007 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (11.804)	Acc@5 60.938 (61.711)
Epoch: [50][200/875]	Time 0.503 (0.515)	Data 0.008 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.174)	Acc@5 56.250 (62.360)
Epoch: [50][300/875]	Time 0.499 (0.514)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.173)	Acc@5 56.250 (62.547)
Epoch: [50][400/875]	Time 0.509 (0.513)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.142)	Acc@5 53.125 (62.477)
Epoch: [50][500/875]	Time 0.495 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.360)	Acc@5 70.312 (62.378)
Epoch: [50][600/875]	Time 0.519 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.297)	Acc@5 50.000 (62.510)
Epoch: [50][700/875]	Time 0.493 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.426)	Acc@5 56.250 (62.533)
Epoch: [50][800/875]	Time 0.526 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.469)	Acc@5 62.500 (62.506)
 * Acc@1 12.500 Acc@5 62.500
epoch 50, total time 445.38
Test: [0/750]	Time 0.700 (0.700)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.048 (0.036)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.028 (0.034)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.026 (0.032)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.025 (0.032)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.033 (0.031)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.017 (0.031)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.028 (0.031)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [51][0/875]	Time 2.020 (2.020)	Data 1.495 (1.495)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 67.188 (67.188)
Epoch: [51][100/875]	Time 0.496 (0.526)	Data 0.006 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.423)	Acc@5 65.625 (62.717)
Epoch: [51][200/875]	Time 0.461 (0.516)	Data 0.005 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.492)	Acc@5 57.812 (62.865)
Epoch: [51][300/875]	Time 0.497 (0.505)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.458)	Acc@5 65.625 (62.775)
Epoch: [51][400/875]	Time 0.535 (0.506)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.527)	Acc@5 62.500 (62.594)
Epoch: [51][500/875]	Time 0.495 (0.507)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.603)	Acc@5 56.250 (62.463)
Epoch: [51][600/875]	Time 0.503 (0.507)	Data 0.004 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.586)	Acc@5 64.062 (62.617)
Epoch: [51][700/875]	Time 0.495 (0.508)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.578)	Acc@5 70.312 (62.674)
Epoch: [51][800/875]	Time 0.528 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.506)	Acc@5 70.312 (62.650)
 * Acc@1 12.500 Acc@5 62.500
epoch 51, total time 445.07
Test: [0/750]	Time 0.672 (0.672)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.041 (0.035)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.021 (0.032)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.027 (0.031)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.023 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.021 (0.028)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.021 (0.027)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.022 (0.027)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [52][0/875]	Time 1.764 (1.764)	Data 1.321 (1.321)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 62.500 (62.500)
Epoch: [52][100/875]	Time 0.503 (0.508)	Data 0.007 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.423)	Acc@5 54.688 (62.995)
Epoch: [52][200/875]	Time 0.498 (0.509)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.376)	Acc@5 53.125 (62.764)
Epoch: [52][300/875]	Time 0.518 (0.510)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.469)	Acc@5 67.188 (62.806)
Epoch: [52][400/875]	Time 0.517 (0.510)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.418)	Acc@5 60.938 (62.707)
Epoch: [52][500/875]	Time 0.516 (0.510)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.435)	Acc@5 59.375 (62.541)
Epoch: [52][600/875]	Time 0.495 (0.510)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.435)	Acc@5 54.688 (62.422)
Epoch: [52][700/875]	Time 0.461 (0.508)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.402)	Acc@5 59.375 (62.377)
Epoch: [52][800/875]	Time 0.495 (0.506)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.434)	Acc@5 57.812 (62.426)
 * Acc@1 12.500 Acc@5 62.500
epoch 52, total time 443.15
Test: [0/750]	Time 0.723 (0.723)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.021 (0.034)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.021 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.030 (0.030)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.019 (0.029)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.028)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.025 (0.028)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.027)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [53][0/875]	Time 1.771 (1.771)	Data 1.283 (1.283)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 64.062 (64.062)
Epoch: [53][100/875]	Time 0.498 (0.522)	Data 0.006 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.624)	Acc@5 62.500 (63.366)
Epoch: [53][200/875]	Time 0.532 (0.516)	Data 0.008 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.531)	Acc@5 56.250 (62.733)
Epoch: [53][300/875]	Time 0.499 (0.514)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.692)	Acc@5 53.125 (62.728)
Epoch: [53][400/875]	Time 0.524 (0.513)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.636)	Acc@5 59.375 (62.625)
Epoch: [53][500/875]	Time 0.470 (0.510)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.584)	Acc@5 64.062 (62.600)
Epoch: [53][600/875]	Time 0.510 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.622)	Acc@5 54.688 (62.487)
Epoch: [53][700/875]	Time 0.498 (0.509)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.549)	Acc@5 68.750 (62.562)
Epoch: [53][800/875]	Time 0.502 (0.509)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.539)	Acc@5 65.625 (62.594)
 * Acc@1 12.500 Acc@5 62.500
epoch 53, total time 445.57
Test: [0/750]	Time 0.747 (0.747)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.034)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.033 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.036 (0.030)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.032 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.029)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.021 (0.029)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.029 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [54][0/875]	Time 1.931 (1.931)	Data 1.459 (1.459)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 59.375 (59.375)
Epoch: [54][100/875]	Time 0.496 (0.525)	Data 0.006 (0.022)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.252)	Acc@5 68.750 (62.392)
Epoch: [54][200/875]	Time 0.520 (0.518)	Data 0.008 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.236)	Acc@5 51.562 (62.189)
Epoch: [54][300/875]	Time 0.497 (0.505)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.277)	Acc@5 64.062 (62.458)
Epoch: [54][400/875]	Time 0.502 (0.506)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.325)	Acc@5 54.688 (62.332)
Epoch: [54][500/875]	Time 0.517 (0.507)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.375)	Acc@5 59.375 (62.494)
Epoch: [54][600/875]	Time 0.498 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.399)	Acc@5 71.875 (62.617)
Epoch: [54][700/875]	Time 0.506 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.502)	Acc@5 56.250 (62.576)
Epoch: [54][800/875]	Time 0.503 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.471)	Acc@5 62.500 (62.537)
 * Acc@1 12.500 Acc@5 62.500
epoch 54, total time 445.18
Test: [0/750]	Time 0.707 (0.707)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.042 (0.034)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.020 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.032 (0.030)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.019 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.021 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.021 (0.029)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [55][0/875]	Time 1.810 (1.810)	Data 1.287 (1.287)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 59.375 (59.375)
Epoch: [55][100/875]	Time 0.500 (0.492)	Data 0.007 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.825)	Acc@5 68.750 (62.222)
Epoch: [55][200/875]	Time 0.514 (0.501)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.414)	Acc@5 65.625 (62.609)
Epoch: [55][300/875]	Time 0.502 (0.504)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.510)	Acc@5 51.562 (62.718)
Epoch: [55][400/875]	Time 0.511 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.671)	Acc@5 68.750 (62.710)
Epoch: [55][500/875]	Time 0.532 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.565)	Acc@5 60.938 (62.553)
Epoch: [55][600/875]	Time 0.509 (0.507)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.695)	Acc@5 67.188 (62.690)
Epoch: [55][700/875]	Time 0.498 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.629)	Acc@5 62.500 (62.672)
Epoch: [55][800/875]	Time 0.531 (0.504)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.512)	Acc@5 65.625 (62.525)
 * Acc@1 12.500 Acc@5 62.500
epoch 55, total time 441.79
Test: [0/750]	Time 0.767 (0.767)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.028 (0.036)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.038 (0.033)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.024 (0.032)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.040 (0.031)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.021 (0.031)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.022 (0.030)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.031 (0.030)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [56][0/875]	Time 1.980 (1.980)	Data 1.472 (1.472)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 56.250 (56.250)
Epoch: [56][100/875]	Time 0.499 (0.524)	Data 0.006 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.840)	Acc@5 65.625 (62.206)
Epoch: [56][200/875]	Time 0.506 (0.517)	Data 0.005 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.290)	Acc@5 57.812 (62.554)
Epoch: [56][300/875]	Time 0.526 (0.514)	Data 0.008 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.282)	Acc@5 57.812 (62.448)
Epoch: [56][400/875]	Time 0.504 (0.513)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.231)	Acc@5 62.500 (62.453)
Epoch: [56][500/875]	Time 0.500 (0.513)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.285)	Acc@5 67.188 (62.332)
Epoch: [56][600/875]	Time 0.508 (0.507)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.521)	Acc@5 65.625 (62.435)
Epoch: [56][700/875]	Time 0.493 (0.508)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.440)	Acc@5 56.250 (62.346)
Epoch: [56][800/875]	Time 0.519 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.477)	Acc@5 67.188 (62.447)
 * Acc@1 12.500 Acc@5 62.500
epoch 56, total time 445.03
Test: [0/750]	Time 0.724 (0.724)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.036 (0.036)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.041 (0.032)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.021 (0.031)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.033 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.035 (0.029)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.017 (0.029)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.020 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [57][0/875]	Time 1.932 (1.932)	Data 1.388 (1.388)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 23.438 (23.438)	Acc@5 71.875 (71.875)
Epoch: [57][100/875]	Time 0.520 (0.523)	Data 0.008 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.949)	Acc@5 68.750 (61.696)
Epoch: [57][200/875]	Time 0.494 (0.516)	Data 0.006 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.702)	Acc@5 51.562 (62.850)
Epoch: [57][300/875]	Time 0.453 (0.512)	Data 0.006 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.526)	Acc@5 57.812 (62.806)
Epoch: [57][400/875]	Time 0.498 (0.506)	Data 0.008 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.679)	Acc@5 62.500 (62.909)
Epoch: [57][500/875]	Time 0.509 (0.507)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.619)	Acc@5 60.938 (62.675)
Epoch: [57][600/875]	Time 0.531 (0.508)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.640)	Acc@5 71.875 (62.542)
Epoch: [57][700/875]	Time 0.510 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.603)	Acc@5 62.500 (62.545)
Epoch: [57][800/875]	Time 0.521 (0.508)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.545)	Acc@5 67.188 (62.459)
 * Acc@1 12.500 Acc@5 62.500
epoch 57, total time 445.16
Test: [0/750]	Time 0.718 (0.718)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.035)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.026 (0.031)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.025 (0.031)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.036 (0.030)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.033 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.027 (0.030)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.033 (0.030)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [58][0/875]	Time 1.818 (1.818)	Data 1.310 (1.310)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 51.562 (51.562)
Epoch: [58][100/875]	Time 0.453 (0.505)	Data 0.005 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.639)	Acc@5 57.812 (62.562)
Epoch: [58][200/875]	Time 0.496 (0.500)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.617)	Acc@5 64.062 (62.733)
Epoch: [58][300/875]	Time 0.500 (0.504)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.697)	Acc@5 62.500 (62.547)
Epoch: [58][400/875]	Time 0.513 (0.505)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.629)	Acc@5 53.125 (62.449)
Epoch: [58][500/875]	Time 0.522 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.659)	Acc@5 54.688 (62.550)
Epoch: [58][600/875]	Time 0.499 (0.507)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.653)	Acc@5 54.688 (62.586)
Epoch: [58][700/875]	Time 0.521 (0.507)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.571)	Acc@5 54.688 (62.422)
Epoch: [58][800/875]	Time 0.466 (0.506)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.572)	Acc@5 65.625 (62.559)
 * Acc@1 12.500 Acc@5 62.500
epoch 58, total time 441.55
Test: [0/750]	Time 0.663 (0.663)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.042 (0.032)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.015 (0.030)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.039 (0.029)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.027 (0.028)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.023 (0.028)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.026 (0.028)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.033 (0.028)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [59][0/875]	Time 1.944 (1.944)	Data 1.411 (1.411)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (20.312)	Acc@5 68.750 (68.750)
Epoch: [59][100/875]	Time 0.499 (0.525)	Data 0.007 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.933)	Acc@5 65.625 (62.593)
Epoch: [59][200/875]	Time 0.524 (0.518)	Data 0.005 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.609)	Acc@5 56.250 (62.438)
Epoch: [59][300/875]	Time 0.494 (0.515)	Data 0.006 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.526)	Acc@5 67.188 (62.225)
Epoch: [59][400/875]	Time 0.503 (0.514)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.594)	Acc@5 59.375 (62.481)
Epoch: [59][500/875]	Time 0.500 (0.513)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.587)	Acc@5 59.375 (62.519)
Epoch: [59][600/875]	Time 0.395 (0.510)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.614)	Acc@5 62.500 (62.643)
Epoch: [59][700/875]	Time 0.524 (0.509)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.618)	Acc@5 65.625 (62.614)
Epoch: [59][800/875]	Time 0.520 (0.509)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.596)	Acc@5 51.562 (62.541)
 * Acc@1 12.500 Acc@5 62.500
epoch 59, total time 446.25
Test: [0/750]	Time 0.762 (0.762)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.036 (0.035)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.033 (0.032)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.022 (0.031)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.018 (0.031)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.021 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.021 (0.029)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.028 (0.029)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [60][0/875]	Time 1.901 (1.901)	Data 1.365 (1.365)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (20.312)	Acc@5 59.375 (59.375)
Epoch: [60][100/875]	Time 0.500 (0.525)	Data 0.008 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.701)	Acc@5 60.938 (62.252)
Epoch: [60][200/875]	Time 0.531 (0.518)	Data 0.007 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.508)	Acc@5 71.875 (62.609)
Epoch: [60][300/875]	Time 0.496 (0.515)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.318)	Acc@5 56.250 (62.837)
Epoch: [60][400/875]	Time 0.528 (0.506)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.527)	Acc@5 59.375 (62.629)
Epoch: [60][500/875]	Time 0.499 (0.507)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.537)	Acc@5 64.062 (62.456)
Epoch: [60][600/875]	Time 0.525 (0.507)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.482)	Acc@5 75.000 (62.536)
Epoch: [60][700/875]	Time 0.500 (0.508)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.478)	Acc@5 59.375 (62.487)
Epoch: [60][800/875]	Time 0.532 (0.508)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 21.875 (12.516)	Acc@5 67.188 (62.523)
 * Acc@1 12.500 Acc@5 62.500
epoch 60, total time 444.94
Test: [0/750]	Time 0.703 (0.703)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.027 (0.036)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.026 (0.032)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.022 (0.032)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.018 (0.031)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.025 (0.030)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.038 (0.030)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.022 (0.030)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [61][0/875]	Time 1.802 (1.802)	Data 1.341 (1.341)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (7.812)	Acc@5 57.812 (57.812)
Epoch: [61][100/875]	Time 0.526 (0.523)	Data 0.009 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.624)	Acc@5 59.375 (62.686)
Epoch: [61][200/875]	Time 0.514 (0.503)	Data 0.006 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.345)	Acc@5 56.250 (62.399)
Epoch: [61][300/875]	Time 0.495 (0.505)	Data 0.007 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.349)	Acc@5 65.625 (62.339)
Epoch: [61][400/875]	Time 0.508 (0.507)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.406)	Acc@5 51.562 (62.142)
Epoch: [61][500/875]	Time 0.499 (0.508)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.344)	Acc@5 67.188 (62.222)
Epoch: [61][600/875]	Time 0.505 (0.508)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.406)	Acc@5 68.750 (62.443)
Epoch: [61][700/875]	Time 0.496 (0.508)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.395)	Acc@5 62.500 (62.313)
Epoch: [61][800/875]	Time 0.512 (0.509)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.531)	Acc@5 59.375 (62.393)
 * Acc@1 12.500 Acc@5 62.500
epoch 61, total time 441.70
Test: [0/750]	Time 0.711 (0.711)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.029)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.026 (0.027)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.020 (0.026)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.024)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.018 (0.023)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.020 (0.022)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [62][0/875]	Time 1.831 (1.831)	Data 1.418 (1.418)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (17.188)	Acc@5 67.188 (67.188)
Epoch: [62][100/875]	Time 0.396 (0.414)	Data 0.006 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (13.072)	Acc@5 64.062 (62.856)
Epoch: [62][200/875]	Time 0.398 (0.406)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.943)	Acc@5 60.938 (62.640)
Epoch: [62][300/875]	Time 0.397 (0.404)	Data 0.005 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (13.024)	Acc@5 62.500 (62.848)
Epoch: [62][400/875]	Time 0.401 (0.402)	Data 0.009 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.808)	Acc@5 59.375 (62.652)
Epoch: [62][500/875]	Time 0.401 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.687)	Acc@5 53.125 (62.559)
Epoch: [62][600/875]	Time 0.401 (0.401)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.698)	Acc@5 59.375 (62.653)
Epoch: [62][700/875]	Time 0.397 (0.401)	Data 0.004 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.652)	Acc@5 57.812 (62.725)
Epoch: [62][800/875]	Time 0.393 (0.400)	Data 0.004 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.574)	Acc@5 71.875 (62.596)
 * Acc@1 12.500 Acc@5 62.500
epoch 62, total time 350.63
Test: [0/750]	Time 0.819 (0.819)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.030)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.020 (0.026)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.016 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.023)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.018 (0.023)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.022 (0.023)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.021 (0.022)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [63][0/875]	Time 1.772 (1.772)	Data 1.362 (1.362)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 57.812 (57.812)
Epoch: [63][100/875]	Time 0.396 (0.413)	Data 0.008 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.252)	Acc@5 59.375 (61.402)
Epoch: [63][200/875]	Time 0.393 (0.406)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.601)	Acc@5 57.812 (62.453)
Epoch: [63][300/875]	Time 0.398 (0.404)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.505)	Acc@5 73.438 (62.282)
Epoch: [63][400/875]	Time 0.400 (0.403)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.387)	Acc@5 60.938 (62.290)
Epoch: [63][500/875]	Time 0.399 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 0.000 (12.438)	Acc@5 64.062 (62.310)
Epoch: [63][600/875]	Time 0.405 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.438)	Acc@5 65.625 (62.341)
Epoch: [63][700/875]	Time 0.398 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.478)	Acc@5 67.188 (62.431)
Epoch: [63][800/875]	Time 0.405 (0.401)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.492)	Acc@5 62.500 (62.461)
 * Acc@1 12.500 Acc@5 62.500
epoch 63, total time 351.56
Test: [0/750]	Time 0.772 (0.772)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.025 (0.026)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.023 (0.022)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.020 (0.020)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.014 (0.020)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.016 (0.020)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.016 (0.019)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [64][0/875]	Time 1.750 (1.750)	Data 1.341 (1.341)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (6.250)	Acc@5 62.500 (62.500)
Epoch: [64][100/875]	Time 0.400 (0.413)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.686)	Acc@5 62.500 (62.175)
Epoch: [64][200/875]	Time 0.399 (0.406)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.492)	Acc@5 68.750 (62.531)
Epoch: [64][300/875]	Time 0.398 (0.403)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.713)	Acc@5 54.688 (62.666)
Epoch: [64][400/875]	Time 0.401 (0.402)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.601)	Acc@5 62.500 (62.738)
Epoch: [64][500/875]	Time 0.398 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.581)	Acc@5 60.938 (62.715)
Epoch: [64][600/875]	Time 0.398 (0.401)	Data 0.008 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.516)	Acc@5 59.375 (62.565)
Epoch: [64][700/875]	Time 0.400 (0.401)	Data 0.009 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.529)	Acc@5 68.750 (62.469)
Epoch: [64][800/875]	Time 0.399 (0.401)	Data 0.009 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.559)	Acc@5 64.062 (62.496)
 * Acc@1 12.500 Acc@5 62.500
epoch 64, total time 350.63
Test: [0/750]	Time 0.812 (0.812)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.027 (0.033)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.015 (0.026)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.018 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.022 (0.023)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.023 (0.022)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [65][0/875]	Time 1.731 (1.731)	Data 1.323 (1.323)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 68.750 (68.750)
Epoch: [65][100/875]	Time 0.415 (0.413)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.376)	Acc@5 57.812 (62.361)
Epoch: [65][200/875]	Time 0.397 (0.406)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.733)	Acc@5 60.938 (62.275)
Epoch: [65][300/875]	Time 0.394 (0.403)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.573)	Acc@5 64.062 (62.479)
Epoch: [65][400/875]	Time 0.398 (0.402)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.594)	Acc@5 62.500 (62.274)
Epoch: [65][500/875]	Time 0.397 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.475)	Acc@5 59.375 (62.272)
Epoch: [65][600/875]	Time 0.398 (0.401)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 23.438 (12.448)	Acc@5 62.500 (62.360)
Epoch: [65][700/875]	Time 0.400 (0.401)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.493)	Acc@5 64.062 (62.409)
Epoch: [65][800/875]	Time 0.398 (0.400)	Data 0.008 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.508)	Acc@5 64.062 (62.467)
 * Acc@1 12.500 Acc@5 62.500
epoch 65, total time 350.72
Test: [0/750]	Time 0.740 (0.740)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.017 (0.031)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.017 (0.027)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.015 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.022 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.017 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [66][0/875]	Time 1.713 (1.713)	Data 1.302 (1.302)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (14.062)	Acc@5 60.938 (60.938)
Epoch: [66][100/875]	Time 0.400 (0.413)	Data 0.007 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.546)	Acc@5 60.938 (62.748)
Epoch: [66][200/875]	Time 0.396 (0.407)	Data 0.005 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.477)	Acc@5 54.688 (62.547)
Epoch: [66][300/875]	Time 0.402 (0.404)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.583)	Acc@5 68.750 (62.500)
Epoch: [66][400/875]	Time 0.401 (0.403)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.465)	Acc@5 65.625 (62.406)
Epoch: [66][500/875]	Time 0.396 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.481)	Acc@5 57.812 (62.319)
Epoch: [66][600/875]	Time 0.399 (0.402)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.510)	Acc@5 65.625 (62.565)
Epoch: [66][700/875]	Time 0.391 (0.401)	Data 0.004 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.542)	Acc@5 65.625 (62.533)
Epoch: [66][800/875]	Time 0.399 (0.401)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.498)	Acc@5 60.938 (62.397)
 * Acc@1 12.500 Acc@5 62.500
epoch 66, total time 351.42
Test: [0/750]	Time 0.748 (0.748)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.017 (0.029)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.016 (0.023)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.021 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.021)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.019 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.019 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [67][0/875]	Time 1.756 (1.756)	Data 1.348 (1.348)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 64.062 (64.062)
Epoch: [67][100/875]	Time 0.400 (0.413)	Data 0.006 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.778)	Acc@5 46.875 (62.160)
Epoch: [67][200/875]	Time 0.395 (0.406)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.422)	Acc@5 67.188 (62.640)
Epoch: [67][300/875]	Time 0.393 (0.403)	Data 0.004 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.349)	Acc@5 53.125 (62.510)
Epoch: [67][400/875]	Time 0.400 (0.402)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.403)	Acc@5 56.250 (62.488)
Epoch: [67][500/875]	Time 0.400 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.381)	Acc@5 59.375 (62.472)
Epoch: [67][600/875]	Time 0.399 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.414)	Acc@5 65.625 (62.531)
Epoch: [67][700/875]	Time 0.392 (0.401)	Data 0.005 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.449)	Acc@5 57.812 (62.571)
Epoch: [67][800/875]	Time 0.400 (0.400)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.457)	Acc@5 71.875 (62.500)
 * Acc@1 12.500 Acc@5 62.500
epoch 67, total time 350.72
Test: [0/750]	Time 0.799 (0.799)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.032)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.016 (0.026)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.018 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.025 (0.024)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.022 (0.024)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.018 (0.023)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [68][0/875]	Time 1.703 (1.703)	Data 1.290 (1.290)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 65.625 (65.625)
Epoch: [68][100/875]	Time 0.397 (0.413)	Data 0.006 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (13.041)	Acc@5 57.812 (61.989)
Epoch: [68][200/875]	Time 0.399 (0.405)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (13.005)	Acc@5 64.062 (62.313)
Epoch: [68][300/875]	Time 0.408 (0.403)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.926)	Acc@5 59.375 (62.235)
Epoch: [68][400/875]	Time 0.396 (0.402)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.905)	Acc@5 67.188 (62.586)
Epoch: [68][500/875]	Time 0.404 (0.401)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.665)	Acc@5 56.250 (62.491)
Epoch: [68][600/875]	Time 0.397 (0.401)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.560)	Acc@5 56.250 (62.492)
Epoch: [68][700/875]	Time 0.406 (0.401)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.527)	Acc@5 62.500 (62.540)
Epoch: [68][800/875]	Time 0.398 (0.400)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.510)	Acc@5 71.875 (62.488)
 * Acc@1 12.500 Acc@5 62.500
epoch 68, total time 350.62
Test: [0/750]	Time 0.802 (0.802)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.015 (0.027)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.018 (0.019)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.018 (0.019)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.019)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.019)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [69][0/875]	Time 1.805 (1.805)	Data 1.389 (1.389)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 65.625 (65.625)
Epoch: [69][100/875]	Time 0.398 (0.413)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.655)	Acc@5 73.438 (61.897)
Epoch: [69][200/875]	Time 0.394 (0.406)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.298)	Acc@5 51.562 (62.259)
Epoch: [69][300/875]	Time 0.397 (0.404)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.526)	Acc@5 54.688 (62.318)
Epoch: [69][400/875]	Time 0.398 (0.402)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.512)	Acc@5 73.438 (62.188)
Epoch: [69][500/875]	Time 0.397 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.463)	Acc@5 70.312 (62.369)
Epoch: [69][600/875]	Time 0.395 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.482)	Acc@5 57.812 (62.445)
Epoch: [69][700/875]	Time 0.399 (0.400)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.491)	Acc@5 68.750 (62.487)
Epoch: [69][800/875]	Time 0.398 (0.400)	Data 0.006 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.502)	Acc@5 67.188 (62.629)
 * Acc@1 12.500 Acc@5 62.500
epoch 69, total time 350.56
Test: [0/750]	Time 0.773 (0.773)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.015 (0.028)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.018 (0.024)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [70][0/875]	Time 1.788 (1.788)	Data 1.382 (1.382)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 71.875 (71.875)
Epoch: [70][100/875]	Time 0.398 (0.414)	Data 0.005 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.206)	Acc@5 60.938 (62.454)
Epoch: [70][200/875]	Time 0.399 (0.406)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.687)	Acc@5 57.812 (62.220)
Epoch: [70][300/875]	Time 0.398 (0.404)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.651)	Acc@5 57.812 (62.121)
Epoch: [70][400/875]	Time 0.395 (0.403)	Data 0.004 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.660)	Acc@5 56.250 (62.574)
Epoch: [70][500/875]	Time 0.394 (0.402)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.565)	Acc@5 60.938 (62.435)
Epoch: [70][600/875]	Time 0.400 (0.401)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.643)	Acc@5 53.125 (62.448)
Epoch: [70][700/875]	Time 0.400 (0.401)	Data 0.005 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.611)	Acc@5 59.375 (62.400)
Epoch: [70][800/875]	Time 0.402 (0.401)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.537)	Acc@5 57.812 (62.463)
 * Acc@1 12.500 Acc@5 62.500
epoch 70, total time 351.01
Test: [0/750]	Time 0.800 (0.800)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.015 (0.028)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.016 (0.024)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.025 (0.021)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.023 (0.021)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.016 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [71][0/875]	Time 1.623 (1.623)	Data 1.208 (1.208)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 60.938 (60.938)
Epoch: [71][100/875]	Time 0.399 (0.413)	Data 0.005 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.871)	Acc@5 51.562 (62.577)
Epoch: [71][200/875]	Time 0.403 (0.406)	Data 0.005 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.562)	Acc@5 56.250 (62.718)
Epoch: [71][300/875]	Time 0.396 (0.404)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.526)	Acc@5 53.125 (62.547)
Epoch: [71][400/875]	Time 0.404 (0.403)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.605)	Acc@5 65.625 (62.586)
Epoch: [71][500/875]	Time 0.403 (0.402)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.425)	Acc@5 68.750 (62.565)
Epoch: [71][600/875]	Time 0.399 (0.401)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.500)	Acc@5 67.188 (62.500)
Epoch: [71][700/875]	Time 0.397 (0.401)	Data 0.008 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.507)	Acc@5 57.812 (62.480)
Epoch: [71][800/875]	Time 0.400 (0.401)	Data 0.006 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.498)	Acc@5 64.062 (62.492)
 * Acc@1 12.500 Acc@5 62.500
epoch 71, total time 351.09
Test: [0/750]	Time 0.670 (0.670)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.020 (0.027)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.016 (0.022)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.016 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.020)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.014 (0.019)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.016 (0.019)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [72][0/875]	Time 1.809 (1.809)	Data 1.398 (1.398)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 3.125 (3.125)	Acc@5 64.062 (64.062)
Epoch: [72][100/875]	Time 0.399 (0.414)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.949)	Acc@5 60.938 (62.639)
Epoch: [72][200/875]	Time 0.397 (0.406)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.523)	Acc@5 68.750 (62.414)
Epoch: [72][300/875]	Time 0.399 (0.404)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.391)	Acc@5 60.938 (62.557)
Epoch: [72][400/875]	Time 0.399 (0.403)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.551)	Acc@5 71.875 (62.804)
Epoch: [72][500/875]	Time 0.396 (0.402)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.578)	Acc@5 70.312 (62.625)
Epoch: [72][600/875]	Time 0.401 (0.402)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.432)	Acc@5 57.812 (62.518)
Epoch: [72][700/875]	Time 0.396 (0.401)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.422)	Acc@5 73.438 (62.438)
Epoch: [72][800/875]	Time 0.401 (0.401)	Data 0.006 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.510)	Acc@5 60.938 (62.459)
 * Acc@1 12.500 Acc@5 62.500
epoch 72, total time 351.30
Test: [0/750]	Time 0.769 (0.769)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.016 (0.030)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.017 (0.024)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.019 (0.023)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.020 (0.022)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.020 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [73][0/875]	Time 1.762 (1.762)	Data 1.355 (1.355)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (4.688)	Acc@5 45.312 (45.312)
Epoch: [73][100/875]	Time 0.404 (0.414)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.051)	Acc@5 59.375 (62.252)
Epoch: [73][200/875]	Time 0.399 (0.408)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.034)	Acc@5 59.375 (62.057)
Epoch: [73][300/875]	Time 0.400 (0.405)	Data 0.005 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.287)	Acc@5 54.688 (62.339)
Epoch: [73][400/875]	Time 0.406 (0.404)	Data 0.008 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 4.688 (12.336)	Acc@5 57.812 (62.309)
Epoch: [73][500/875]	Time 0.403 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.307)	Acc@5 60.938 (62.254)
Epoch: [73][600/875]	Time 0.398 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.422)	Acc@5 65.625 (62.440)
Epoch: [73][700/875]	Time 0.401 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.451)	Acc@5 57.812 (62.489)
Epoch: [73][800/875]	Time 0.402 (0.403)	Data 0.006 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.486)	Acc@5 65.625 (62.461)
 * Acc@1 12.500 Acc@5 62.500
epoch 73, total time 352.58
Test: [0/750]	Time 0.810 (0.810)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.019 (0.028)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.019 (0.024)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.018 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.019 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.016 (0.020)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [74][0/875]	Time 1.670 (1.670)	Data 1.250 (1.250)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.500)	Acc@5 65.625 (65.625)
Epoch: [74][100/875]	Time 0.397 (0.414)	Data 0.006 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.763)	Acc@5 73.438 (63.103)
Epoch: [74][200/875]	Time 0.400 (0.407)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.788)	Acc@5 65.625 (63.036)
Epoch: [74][300/875]	Time 0.401 (0.405)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.521)	Acc@5 65.625 (62.905)
Epoch: [74][400/875]	Time 0.399 (0.404)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.336)	Acc@5 54.688 (62.660)
Epoch: [74][500/875]	Time 0.401 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.335)	Acc@5 68.750 (62.378)
Epoch: [74][600/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.383)	Acc@5 57.812 (62.414)
Epoch: [74][700/875]	Time 0.401 (0.403)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.431)	Acc@5 62.500 (62.507)
Epoch: [74][800/875]	Time 0.403 (0.402)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.506)	Acc@5 59.375 (62.482)
 * Acc@1 12.500 Acc@5 62.500
epoch 74, total time 352.49
Test: [0/750]	Time 0.772 (0.772)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.016 (0.030)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.020 (0.023)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.025 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.021 (0.021)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [75][0/875]	Time 1.839 (1.839)	Data 1.424 (1.424)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (6.250)	Acc@5 68.750 (68.750)
Epoch: [75][100/875]	Time 0.401 (0.414)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.624)	Acc@5 62.500 (63.320)
Epoch: [75][200/875]	Time 0.402 (0.408)	Data 0.008 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.725)	Acc@5 62.500 (63.099)
Epoch: [75][300/875]	Time 0.399 (0.405)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.495)	Acc@5 62.500 (62.775)
Epoch: [75][400/875]	Time 0.398 (0.404)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.453)	Acc@5 62.500 (62.340)
Epoch: [75][500/875]	Time 0.402 (0.404)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.525)	Acc@5 62.500 (62.294)
Epoch: [75][600/875]	Time 0.400 (0.403)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.526)	Acc@5 62.500 (62.310)
Epoch: [75][700/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.533)	Acc@5 62.500 (62.471)
Epoch: [75][800/875]	Time 0.403 (0.402)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.480)	Acc@5 68.750 (62.453)
 * Acc@1 12.500 Acc@5 62.500
epoch 75, total time 352.49
Test: [0/750]	Time 0.769 (0.769)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.015 (0.025)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.020 (0.021)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.015 (0.020)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.019)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.019 (0.019)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.020 (0.019)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.019)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [76][0/875]	Time 1.777 (1.777)	Data 1.362 (1.362)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (6.250)	Acc@5 56.250 (56.250)
Epoch: [76][100/875]	Time 0.394 (0.415)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.407)	Acc@5 70.312 (62.252)
Epoch: [76][200/875]	Time 0.401 (0.408)	Data 0.007 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.687)	Acc@5 60.938 (62.516)
Epoch: [76][300/875]	Time 0.399 (0.406)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.500)	Acc@5 68.750 (62.443)
Epoch: [76][400/875]	Time 0.400 (0.405)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.508)	Acc@5 54.688 (62.566)
Epoch: [76][500/875]	Time 0.400 (0.404)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 20.312 (12.494)	Acc@5 65.625 (62.715)
Epoch: [76][600/875]	Time 0.396 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 3.125 (12.474)	Acc@5 54.688 (62.601)
Epoch: [76][700/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.451)	Acc@5 56.250 (62.574)
Epoch: [76][800/875]	Time 0.399 (0.403)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.492)	Acc@5 62.500 (62.560)
 * Acc@1 12.500 Acc@5 62.500
epoch 76, total time 352.75
Test: [0/750]	Time 0.764 (0.764)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.016 (0.028)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.015 (0.024)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.022 (0.022)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.018 (0.022)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.027 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [77][0/875]	Time 1.776 (1.776)	Data 1.366 (1.366)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (10.938)	Acc@5 65.625 (65.625)
Epoch: [77][100/875]	Time 0.396 (0.415)	Data 0.007 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.160)	Acc@5 67.188 (63.181)
Epoch: [77][200/875]	Time 0.403 (0.408)	Data 0.006 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.018)	Acc@5 57.812 (62.935)
Epoch: [77][300/875]	Time 0.398 (0.405)	Data 0.005 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.266)	Acc@5 62.500 (62.479)
Epoch: [77][400/875]	Time 0.399 (0.404)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.508)	Acc@5 59.375 (62.473)
Epoch: [77][500/875]	Time 0.399 (0.404)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.512)	Acc@5 54.688 (62.428)
Epoch: [77][600/875]	Time 0.399 (0.403)	Data 0.004 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.417)	Acc@5 65.625 (62.479)
Epoch: [77][700/875]	Time 0.401 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 12.500 (12.418)	Acc@5 60.938 (62.589)
Epoch: [77][800/875]	Time 0.402 (0.403)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.445)	Acc@5 75.000 (62.557)
 * Acc@1 12.500 Acc@5 62.500
epoch 77, total time 352.61
Test: [0/750]	Time 0.706 (0.706)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.016 (0.027)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.021 (0.025)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.017 (0.024)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.016 (0.023)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.017 (0.022)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.015 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [78][0/875]	Time 1.666 (1.666)	Data 1.240 (1.240)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (15.625)	Acc@5 59.375 (59.375)
Epoch: [78][100/875]	Time 0.404 (0.414)	Data 0.007 (0.019)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 6.250 (12.175)	Acc@5 57.812 (61.928)
Epoch: [78][200/875]	Time 0.401 (0.407)	Data 0.005 (0.013)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.243)	Acc@5 60.938 (62.096)
Epoch: [78][300/875]	Time 0.400 (0.405)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.298)	Acc@5 60.938 (62.287)
Epoch: [78][400/875]	Time 0.397 (0.404)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.282)	Acc@5 65.625 (62.274)
Epoch: [78][500/875]	Time 0.401 (0.404)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.332)	Acc@5 64.062 (62.244)
Epoch: [78][600/875]	Time 0.397 (0.403)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.360)	Acc@5 70.312 (62.510)
Epoch: [78][700/875]	Time 0.399 (0.403)	Data 0.006 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.435)	Acc@5 65.625 (62.467)
Epoch: [78][800/875]	Time 0.399 (0.403)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.455)	Acc@5 67.188 (62.504)
 * Acc@1 12.500 Acc@5 62.500
epoch 78, total time 352.82
Test: [0/750]	Time 0.768 (0.768)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.023 (0.031)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.019 (0.026)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.018 (0.025)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.018 (0.024)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.016 (0.023)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.014 (0.022)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.024 (0.022)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [79][0/875]	Time 1.895 (1.895)	Data 1.490 (1.490)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 68.750 (68.750)
Epoch: [79][100/875]	Time 0.403 (0.418)	Data 0.007 (0.021)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 10.938 (12.593)	Acc@5 59.375 (62.639)
Epoch: [79][200/875]	Time 0.400 (0.410)	Data 0.007 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.438)	Acc@5 62.500 (62.282)
Epoch: [79][300/875]	Time 0.399 (0.408)	Data 0.006 (0.012)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.557)	Acc@5 65.625 (62.360)
Epoch: [79][400/875]	Time 0.404 (0.406)	Data 0.006 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.461)	Acc@5 59.375 (62.290)
Epoch: [79][500/875]	Time 0.402 (0.406)	Data 0.006 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.403)	Acc@5 57.812 (62.307)
Epoch: [79][600/875]	Time 0.404 (0.405)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 18.750 (12.425)	Acc@5 53.125 (62.516)
Epoch: [79][700/875]	Time 0.407 (0.405)	Data 0.007 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.368)	Acc@5 51.562 (62.574)
Epoch: [79][800/875]	Time 0.400 (0.404)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.449)	Acc@5 54.688 (62.523)
 * Acc@1 12.500 Acc@5 62.500
epoch 79, total time 353.87
Test: [0/750]	Time 0.806 (0.806)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.015 (0.027)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.019 (0.023)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.028 (0.023)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.020 (0.022)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.019 (0.021)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.018 (0.021)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> training...
Epoch: [80][0/875]	Time 1.758 (1.758)	Data 1.354 (1.354)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (9.375)	Acc@5 59.375 (59.375)
Epoch: [80][100/875]	Time 0.400 (0.416)	Data 0.006 (0.020)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.392)	Acc@5 65.625 (63.134)
Epoch: [80][200/875]	Time 0.400 (0.409)	Data 0.007 (0.014)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 9.375 (12.422)	Acc@5 59.375 (62.586)
Epoch: [80][300/875]	Time 0.398 (0.406)	Data 0.007 (0.011)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.635)	Acc@5 60.938 (62.651)
Epoch: [80][400/875]	Time 0.403 (0.405)	Data 0.007 (0.010)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 17.188 (12.523)	Acc@5 57.812 (62.336)
Epoch: [80][500/875]	Time 0.399 (0.404)	Data 0.005 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.531)	Acc@5 54.688 (62.500)
Epoch: [80][600/875]	Time 0.403 (0.404)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 7.812 (12.503)	Acc@5 64.062 (62.549)
Epoch: [80][700/875]	Time 0.398 (0.403)	Data 0.006 (0.009)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 15.625 (12.522)	Acc@5 62.500 (62.549)
Epoch: [80][800/875]	Time 0.395 (0.403)	Data 0.007 (0.008)	Loss nan (nan)	Loss@kd nan (nan)	Acc@1 14.062 (12.531)	Acc@5 64.062 (62.518)
 * Acc@1 12.500 Acc@5 62.500
epoch 80, total time 352.75
Test: [0/750]	Time 0.720 (0.720)	Loss nan (nan)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Test: [100/750]	Time 0.018 (0.026)	Loss nan (nan)	Acc@1 100.000 (7.178)	Acc@5 100.000 (7.178)
Test: [200/750]	Time 0.015 (0.022)	Loss nan (nan)	Acc@1 0.000 (46.642)	Acc@5 0.000 (46.642)
Test: [300/750]	Time 0.018 (0.020)	Loss nan (nan)	Acc@1 0.000 (31.146)	Acc@5 0.000 (31.146)
Test: [400/750]	Time 0.018 (0.020)	Loss nan (nan)	Acc@1 0.000 (23.379)	Acc@5 0.000 (23.379)
Test: [500/750]	Time 0.016 (0.020)	Loss nan (nan)	Acc@1 0.000 (18.713)	Acc@5 100.000 (25.150)
Test: [600/750]	Time 0.016 (0.019)	Loss nan (nan)	Acc@1 0.000 (15.599)	Acc@5 100.000 (37.604)
Test: [700/750]	Time 0.019 (0.019)	Loss nan (nan)	Acc@1 0.000 (13.374)	Acc@5 0.000 (40.121)
 * Acc@1 12.500 Acc@5 37.500
==> Saving...
best accuracy: tensor(70.6458, device='cuda:0')
