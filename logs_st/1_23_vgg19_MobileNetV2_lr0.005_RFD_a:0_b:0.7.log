==> loading teacher model
==> done
6 0.5
Test: [0/750]	Time 21.593 (21.593)	Loss 0.5613 (0.5613)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.073 (0.263)	Loss 0.6912 (0.4886)	Acc@1 75.000 (87.098)	Acc@5 100.000 (95.235)
Test: [200/750]	Time 0.044 (0.156)	Loss 1.2877 (0.4868)	Acc@1 50.000 (85.106)	Acc@5 93.750 (96.253)
Test: [300/750]	Time 0.040 (0.121)	Loss 1.1032 (0.6946)	Acc@1 56.250 (76.412)	Acc@5 93.750 (95.515)
Test: [400/750]	Time 0.043 (0.103)	Loss 0.5579 (0.7766)	Acc@1 84.375 (73.208)	Acc@5 93.750 (94.966)
Test: [500/750]	Time 0.044 (0.092)	Loss 0.4078 (0.7378)	Acc@1 84.375 (75.087)	Acc@5 100.000 (94.966)
Test: [600/750]	Time 0.041 (0.085)	Loss 0.5665 (0.7392)	Acc@1 71.875 (75.151)	Acc@5 96.875 (94.982)
Test: [700/750]	Time 0.043 (0.080)	Loss 1.0252 (0.7310)	Acc@1 68.750 (75.334)	Acc@5 81.250 (95.136)
 * Acc@1 75.533 Acc@5 95.092
teacher accuracy:  tensor(75.5333, device='cuda:1')
==> training...
Epoch: [1][0/875]	Time 2.296 (2.296)	Data 1.026 (1.026)	Loss 17.9231 (17.9231)	Loss@kd 22.1591 (22.1591)	Acc@1 14.062 (14.062)	Acc@5 62.500 (62.500)
Epoch: [1][100/875]	Time 0.481 (0.409)	Data 0.005 (0.016)	Loss 6.0584 (13.1402)	Loss@kd 5.8268 (10.8838)	Acc@1 35.938 (24.536)	Acc@5 90.625 (76.764)
Epoch: [1][200/875]	Time 0.391 (0.398)	Data 0.007 (0.011)	Loss 4.1984 (9.0520)	Loss@kd 3.7649 (7.7360)	Acc@1 35.938 (29.392)	Acc@5 90.625 (82.346)
Epoch: [1][300/875]	Time 0.370 (0.394)	Data 0.007 (0.010)	Loss 3.9106 (7.3985)	Loss@kd 3.2671 (6.3231)	Acc@1 39.062 (31.484)	Acc@5 95.312 (85.185)
Epoch: [1][400/875]	Time 0.383 (0.393)	Data 0.007 (0.009)	Loss 3.7253 (6.4931)	Loss@kd 3.0401 (5.5427)	Acc@1 35.938 (33.837)	Acc@5 93.750 (86.873)
Epoch: [1][500/875]	Time 0.357 (0.390)	Data 0.008 (0.009)	Loss 3.5513 (5.9348)	Loss@kd 3.0420 (5.0521)	Acc@1 40.625 (35.058)	Acc@5 95.312 (88.005)
Epoch: [1][600/875]	Time 0.355 (0.387)	Data 0.007 (0.008)	Loss 3.5134 (5.5447)	Loss@kd 3.0353 (4.7099)	Acc@1 50.000 (36.174)	Acc@5 92.188 (88.821)
Epoch: [1][700/875]	Time 0.361 (0.385)	Data 0.007 (0.008)	Loss 3.5568 (5.2630)	Loss@kd 2.9195 (4.4628)	Acc@1 35.938 (37.048)	Acc@5 92.188 (89.408)
Epoch: [1][800/875]	Time 0.403 (0.385)	Data 0.007 (0.008)	Loss 3.5245 (5.0475)	Loss@kd 2.8713 (4.2756)	Acc@1 37.500 (37.826)	Acc@5 92.188 (89.841)
 * Acc@1 38.379 Acc@5 90.230
epoch 1, total time 337.66
Test: [0/750]	Time 1.070 (1.070)	Loss 0.9444 (0.9444)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.105 (0.121)	Loss 0.8285 (0.8586)	Acc@1 59.375 (74.134)	Acc@5 100.000 (85.179)
Test: [200/750]	Time 0.099 (0.113)	Loss 1.8709 (0.8737)	Acc@1 12.500 (68.159)	Acc@5 81.250 (89.785)
Test: [300/750]	Time 0.106 (0.112)	Loss 2.1724 (1.1952)	Acc@1 3.125 (53.073)	Acc@5 34.375 (84.853)
Test: [400/750]	Time 0.088 (0.111)	Loss 1.5095 (1.3744)	Acc@1 28.125 (42.285)	Acc@5 75.000 (78.733)
Test: [500/750]	Time 0.127 (0.111)	Loss 1.6055 (1.3937)	Acc@1 37.500 (41.517)	Acc@5 81.250 (78.948)
Test: [600/750]	Time 0.097 (0.110)	Loss 1.1652 (1.3864)	Acc@1 59.375 (42.996)	Acc@5 81.250 (79.690)
Test: [700/750]	Time 0.107 (0.110)	Loss 1.3082 (1.3572)	Acc@1 65.625 (45.890)	Acc@5 87.500 (81.125)
 * Acc@1 47.317 Acc@5 81.654
saving the best model!
==> training...
Epoch: [2][0/875]	Time 1.806 (1.806)	Data 1.272 (1.272)	Loss 3.4795 (3.4795)	Loss@kd 2.8807 (2.8807)	Acc@1 39.062 (39.062)	Acc@5 93.750 (93.750)
Epoch: [2][100/875]	Time 0.415 (0.404)	Data 0.006 (0.019)	Loss 3.2332 (3.4507)	Loss@kd 2.7964 (2.9048)	Acc@1 53.125 (44.864)	Acc@5 96.875 (94.291)
Epoch: [2][200/875]	Time 0.378 (0.397)	Data 0.006 (0.013)	Loss 3.3012 (3.4344)	Loss@kd 2.9396 (2.8949)	Acc@1 45.312 (45.608)	Acc@5 96.875 (94.162)
Epoch: [2][300/875]	Time 0.394 (0.396)	Data 0.006 (0.011)	Loss 3.6366 (3.4156)	Loss@kd 2.9006 (2.8797)	Acc@1 39.062 (45.780)	Acc@5 90.625 (94.326)
Epoch: [2][400/875]	Time 0.373 (0.395)	Data 0.007 (0.010)	Loss 3.4167 (3.4062)	Loss@kd 2.9607 (2.8686)	Acc@1 48.438 (45.827)	Acc@5 96.875 (94.342)
Epoch: [2][500/875]	Time 0.370 (0.395)	Data 0.007 (0.009)	Loss 3.3368 (3.3964)	Loss@kd 2.8545 (2.8588)	Acc@1 45.312 (45.865)	Acc@5 100.000 (94.374)
Epoch: [2][600/875]	Time 0.374 (0.395)	Data 0.006 (0.009)	Loss 3.2414 (3.3833)	Loss@kd 2.7152 (2.8469)	Acc@1 53.125 (46.001)	Acc@5 96.875 (94.499)
Epoch: [2][700/875]	Time 0.374 (0.394)	Data 0.005 (0.008)	Loss 3.3528 (3.3727)	Loss@kd 2.7081 (2.8361)	Acc@1 40.625 (46.097)	Acc@5 95.312 (94.597)
Epoch: [2][800/875]	Time 0.392 (0.394)	Data 0.007 (0.008)	Loss 3.2838 (3.3614)	Loss@kd 2.7829 (2.8247)	Acc@1 42.188 (46.216)	Acc@5 98.438 (94.649)
 * Acc@1 46.429 Acc@5 94.675
epoch 2, total time 345.12
Test: [0/750]	Time 0.824 (0.824)	Loss 0.7079 (0.7079)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.094 (0.112)	Loss 0.7150 (0.6155)	Acc@1 71.875 (80.693)	Acc@5 100.000 (88.057)
Test: [200/750]	Time 0.079 (0.107)	Loss 1.6215 (0.7252)	Acc@1 40.625 (74.285)	Acc@5 84.375 (91.169)
Test: [300/750]	Time 0.106 (0.106)	Loss 1.7735 (1.0184)	Acc@1 25.000 (62.895)	Acc@5 84.375 (88.227)
Test: [400/750]	Time 0.108 (0.106)	Loss 1.9658 (1.2181)	Acc@1 21.875 (52.096)	Acc@5 43.750 (83.970)
Test: [500/750]	Time 0.107 (0.106)	Loss 0.8501 (1.2831)	Acc@1 68.750 (49.763)	Acc@5 87.500 (80.364)
Test: [600/750]	Time 0.101 (0.106)	Loss 1.2245 (1.2472)	Acc@1 43.750 (51.617)	Acc@5 96.875 (82.155)
Test: [700/750]	Time 0.101 (0.106)	Loss 1.8008 (1.2761)	Acc@1 34.375 (50.263)	Acc@5 75.000 (82.859)
 * Acc@1 49.392 Acc@5 82.467
saving the best model!
==> training...
Epoch: [3][0/875]	Time 1.503 (1.503)	Data 1.157 (1.157)	Loss 3.1926 (3.1926)	Loss@kd 2.7283 (2.7283)	Acc@1 45.312 (45.312)	Acc@5 98.438 (98.438)
Epoch: [3][100/875]	Time 0.376 (0.385)	Data 0.007 (0.018)	Loss 3.3862 (3.2546)	Loss@kd 2.7224 (2.7355)	Acc@1 50.000 (47.927)	Acc@5 90.625 (95.220)
Epoch: [3][200/875]	Time 0.488 (0.386)	Data 0.006 (0.012)	Loss 3.1697 (3.2471)	Loss@kd 2.7028 (2.7233)	Acc@1 42.188 (47.901)	Acc@5 98.438 (95.320)
Epoch: [3][300/875]	Time 0.386 (0.388)	Data 0.007 (0.010)	Loss 3.0635 (3.2319)	Loss@kd 2.7389 (2.7130)	Acc@1 64.062 (48.484)	Acc@5 96.875 (95.240)
Epoch: [3][400/875]	Time 0.364 (0.388)	Data 0.007 (0.009)	Loss 3.3311 (3.2237)	Loss@kd 2.6622 (2.7045)	Acc@1 48.438 (48.586)	Acc@5 93.750 (95.207)
Epoch: [3][500/875]	Time 0.385 (0.389)	Data 0.007 (0.009)	Loss 2.9407 (3.2200)	Loss@kd 2.5607 (2.6960)	Acc@1 62.500 (48.659)	Acc@5 98.438 (95.194)
Epoch: [3][600/875]	Time 0.387 (0.389)	Data 0.007 (0.009)	Loss 3.0383 (3.2125)	Loss@kd 2.7177 (2.6902)	Acc@1 59.375 (48.723)	Acc@5 96.875 (95.232)
Epoch: [3][700/875]	Time 0.389 (0.390)	Data 0.006 (0.008)	Loss 2.9547 (3.2014)	Loss@kd 2.6422 (2.6810)	Acc@1 59.375 (48.845)	Acc@5 98.438 (95.330)
Epoch: [3][800/875]	Time 0.361 (0.390)	Data 0.006 (0.008)	Loss 3.1191 (3.1930)	Loss@kd 2.6613 (2.6759)	Acc@1 45.312 (48.906)	Acc@5 96.875 (95.430)
 * Acc@1 48.877 Acc@5 95.459
epoch 3, total time 341.37
Test: [0/750]	Time 0.780 (0.780)	Loss 0.7569 (0.7569)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.101 (0.117)	Loss 0.5774 (0.6635)	Acc@1 78.125 (81.188)	Acc@5 100.000 (87.531)
Test: [200/750]	Time 0.079 (0.110)	Loss 1.9751 (0.7171)	Acc@1 9.375 (75.466)	Acc@5 71.875 (89.630)
Test: [300/750]	Time 0.098 (0.110)	Loss 1.5403 (1.0979)	Acc@1 34.375 (55.887)	Acc@5 96.875 (83.482)
Test: [400/750]	Time 0.095 (0.108)	Loss 1.6581 (1.2362)	Acc@1 25.000 (49.377)	Acc@5 59.375 (84.617)
Test: [500/750]	Time 0.101 (0.108)	Loss 1.2764 (1.3052)	Acc@1 59.375 (47.386)	Acc@5 71.875 (82.317)
Test: [600/750]	Time 0.109 (0.108)	Loss 1.3032 (1.3190)	Acc@1 46.875 (48.253)	Acc@5 96.875 (82.202)
Test: [700/750]	Time 0.102 (0.108)	Loss 1.1944 (1.2998)	Acc@1 50.000 (49.305)	Acc@5 84.375 (83.461)
 * Acc@1 50.617 Acc@5 83.887
saving the best model!
==> training...
Epoch: [4][0/875]	Time 1.670 (1.670)	Data 1.217 (1.217)	Loss 3.2234 (3.2234)	Loss@kd 2.5379 (2.5379)	Acc@1 45.312 (45.312)	Acc@5 92.188 (92.188)
Epoch: [4][100/875]	Time 0.360 (0.401)	Data 0.007 (0.019)	Loss 3.2122 (3.1228)	Loss@kd 2.8292 (2.6171)	Acc@1 48.438 (50.758)	Acc@5 96.875 (95.869)
Epoch: [4][200/875]	Time 0.374 (0.395)	Data 0.007 (0.013)	Loss 3.1443 (3.1142)	Loss@kd 2.4934 (2.6130)	Acc@1 45.312 (50.381)	Acc@5 92.188 (96.090)
Epoch: [4][300/875]	Time 0.369 (0.392)	Data 0.009 (0.011)	Loss 3.1842 (3.1145)	Loss@kd 2.5793 (2.6084)	Acc@1 50.000 (50.119)	Acc@5 95.312 (95.972)
Epoch: [4][400/875]	Time 0.363 (0.387)	Data 0.007 (0.010)	Loss 3.0660 (3.1081)	Loss@kd 2.6239 (2.6034)	Acc@1 53.125 (50.253)	Acc@5 98.438 (95.971)
Epoch: [4][500/875]	Time 0.371 (0.385)	Data 0.007 (0.009)	Loss 3.1328 (3.1071)	Loss@kd 2.5766 (2.5977)	Acc@1 46.875 (50.178)	Acc@5 96.875 (95.833)
Epoch: [4][600/875]	Time 0.373 (0.383)	Data 0.006 (0.009)	Loss 3.1446 (3.1052)	Loss@kd 2.5373 (2.5960)	Acc@1 37.500 (50.156)	Acc@5 96.875 (95.760)
Epoch: [4][700/875]	Time 0.380 (0.384)	Data 0.007 (0.008)	Loss 3.0245 (3.1055)	Loss@kd 2.4672 (2.5923)	Acc@1 40.625 (49.955)	Acc@5 100.000 (95.754)
Epoch: [4][800/875]	Time 0.366 (0.385)	Data 0.007 (0.008)	Loss 3.0615 (3.1029)	Loss@kd 2.6278 (2.5915)	Acc@1 64.062 (50.125)	Acc@5 93.750 (95.747)
 * Acc@1 50.179 Acc@5 95.827
epoch 4, total time 337.58
Test: [0/750]	Time 0.845 (0.845)	Loss 0.7157 (0.7157)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.108 (0.118)	Loss 0.7228 (0.5948)	Acc@1 71.875 (81.157)	Acc@5 100.000 (88.614)
Test: [200/750]	Time 0.101 (0.111)	Loss 1.8126 (0.6758)	Acc@1 34.375 (75.311)	Acc@5 81.250 (91.682)
Test: [300/750]	Time 0.076 (0.110)	Loss 1.7337 (1.0155)	Acc@1 21.875 (61.462)	Acc@5 84.375 (87.656)
Test: [400/750]	Time 0.111 (0.108)	Loss 1.4544 (1.1951)	Acc@1 34.375 (50.920)	Acc@5 75.000 (86.183)
Test: [500/750]	Time 0.163 (0.109)	Loss 1.1742 (1.2466)	Acc@1 62.500 (48.908)	Acc@5 81.250 (84.119)
Test: [600/750]	Time 0.097 (0.107)	Loss 0.9705 (1.2342)	Acc@1 65.625 (50.380)	Acc@5 93.750 (84.656)
Test: [700/750]	Time 0.081 (0.107)	Loss 1.4349 (1.2227)	Acc@1 53.125 (51.748)	Acc@5 78.125 (85.405)
 * Acc@1 52.475 Acc@5 85.308
saving the best model!
==> training...
Epoch: [5][0/875]	Time 1.607 (1.607)	Data 1.149 (1.149)	Loss 3.0316 (3.0316)	Loss@kd 2.5306 (2.5306)	Acc@1 53.125 (53.125)	Acc@5 93.750 (93.750)
Epoch: [5][100/875]	Time 0.369 (0.400)	Data 0.007 (0.018)	Loss 3.0150 (3.0502)	Loss@kd 2.4561 (2.5458)	Acc@1 46.875 (51.222)	Acc@5 93.750 (95.931)
Epoch: [5][200/875]	Time 0.363 (0.395)	Data 0.007 (0.012)	Loss 3.1761 (3.0591)	Loss@kd 2.5898 (2.5455)	Acc@1 43.750 (51.283)	Acc@5 96.875 (95.864)
Epoch: [5][300/875]	Time 0.354 (0.393)	Data 0.007 (0.010)	Loss 3.0811 (3.0402)	Loss@kd 2.5213 (2.5422)	Acc@1 43.750 (51.739)	Acc@5 96.875 (96.086)
Epoch: [5][400/875]	Time 0.360 (0.393)	Data 0.007 (0.009)	Loss 2.8769 (3.0420)	Loss@kd 2.4623 (2.5408)	Acc@1 57.812 (51.485)	Acc@5 96.875 (96.072)
Epoch: [5][500/875]	Time 0.382 (0.392)	Data 0.007 (0.009)	Loss 2.8889 (3.0489)	Loss@kd 2.6348 (2.5389)	Acc@1 59.375 (50.989)	Acc@5 98.438 (95.967)
Epoch: [5][600/875]	Time 0.380 (0.392)	Data 0.006 (0.008)	Loss 2.7765 (3.0445)	Loss@kd 2.4668 (2.5373)	Acc@1 60.938 (51.079)	Acc@5 98.438 (95.994)
Epoch: [5][700/875]	Time 0.385 (0.391)	Data 0.007 (0.008)	Loss 3.2044 (3.0409)	Loss@kd 2.4539 (2.5366)	Acc@1 45.312 (51.152)	Acc@5 93.750 (96.028)
Epoch: [5][800/875]	Time 0.361 (0.389)	Data 0.007 (0.008)	Loss 2.8743 (3.0376)	Loss@kd 2.3331 (2.5333)	Acc@1 53.125 (51.243)	Acc@5 98.438 (96.077)
 * Acc@1 51.298 Acc@5 96.114
epoch 5, total time 339.22
Test: [0/750]	Time 0.767 (0.767)	Loss 0.8087 (0.8087)	Acc@1 75.000 (75.000)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.091 (0.114)	Loss 0.6159 (0.7259)	Acc@1 78.125 (79.455)	Acc@5 100.000 (86.572)
Test: [200/750]	Time 0.111 (0.109)	Loss 1.8467 (0.7355)	Acc@1 31.250 (75.389)	Acc@5 75.000 (90.423)
Test: [300/750]	Time 0.102 (0.109)	Loss 1.7664 (1.0791)	Acc@1 18.750 (59.261)	Acc@5 75.000 (85.704)
Test: [400/750]	Time 0.103 (0.108)	Loss 1.3517 (1.2311)	Acc@1 62.500 (50.553)	Acc@5 87.500 (84.461)
Test: [500/750]	Time 0.153 (0.108)	Loss 0.9939 (1.2391)	Acc@1 68.750 (50.873)	Acc@5 87.500 (84.356)
Test: [600/750]	Time 0.102 (0.106)	Loss 1.0441 (1.2090)	Acc@1 59.375 (52.948)	Acc@5 93.750 (85.342)
Test: [700/750]	Time 0.101 (0.106)	Loss 1.5907 (1.2142)	Acc@1 37.500 (52.982)	Acc@5 71.875 (85.579)
 * Acc@1 52.946 Acc@5 85.012
saving the best model!
==> training...
Epoch: [6][0/875]	Time 1.701 (1.701)	Data 1.173 (1.173)	Loss 3.4699 (3.4699)	Loss@kd 2.8204 (2.8204)	Acc@1 37.500 (37.500)	Acc@5 95.312 (95.312)
Epoch: [6][100/875]	Time 0.403 (0.402)	Data 0.007 (0.018)	Loss 2.9232 (3.0162)	Loss@kd 2.4015 (2.5220)	Acc@1 53.125 (51.996)	Acc@5 98.438 (96.395)
Epoch: [6][200/875]	Time 0.430 (0.395)	Data 0.006 (0.012)	Loss 2.9656 (3.0074)	Loss@kd 2.4403 (2.5018)	Acc@1 56.250 (51.290)	Acc@5 95.312 (96.206)
Epoch: [6][300/875]	Time 0.402 (0.393)	Data 0.010 (0.010)	Loss 2.8749 (2.9937)	Loss@kd 2.5387 (2.4999)	Acc@1 68.750 (52.004)	Acc@5 95.312 (96.413)
Epoch: [6][400/875]	Time 0.367 (0.393)	Data 0.008 (0.009)	Loss 2.9345 (2.9976)	Loss@kd 2.5753 (2.5008)	Acc@1 54.688 (51.773)	Acc@5 100.000 (96.423)
Epoch: [6][500/875]	Time 0.369 (0.392)	Data 0.006 (0.009)	Loss 2.7993 (2.9947)	Loss@kd 2.4635 (2.4968)	Acc@1 54.688 (51.943)	Acc@5 98.438 (96.417)
Epoch: [6][600/875]	Time 0.386 (0.393)	Data 0.007 (0.009)	Loss 3.2246 (2.9901)	Loss@kd 2.5139 (2.4944)	Acc@1 45.312 (52.041)	Acc@5 95.312 (96.397)
Epoch: [6][700/875]	Time 0.397 (0.392)	Data 0.007 (0.008)	Loss 2.8936 (2.9870)	Loss@kd 2.5094 (2.4915)	Acc@1 60.938 (52.089)	Acc@5 93.750 (96.362)
Epoch: [6][800/875]	Time 0.350 (0.392)	Data 0.006 (0.008)	Loss 3.1099 (2.9841)	Loss@kd 2.5105 (2.4893)	Acc@1 50.000 (52.267)	Acc@5 93.750 (96.354)
 * Acc@1 52.300 Acc@5 96.354
epoch 6, total time 343.18
Test: [0/750]	Time 0.805 (0.805)	Loss 0.6427 (0.6427)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.107 (0.118)	Loss 0.7168 (0.5308)	Acc@1 75.000 (83.911)	Acc@5 96.875 (89.449)
Test: [200/750]	Time 0.109 (0.113)	Loss 1.7573 (0.6846)	Acc@1 18.750 (76.819)	Acc@5 75.000 (91.402)
Test: [300/750]	Time 0.082 (0.112)	Loss 1.9152 (1.0228)	Acc@1 9.375 (61.140)	Acc@5 87.500 (87.946)
Test: [400/750]	Time 0.119 (0.110)	Loss 1.5164 (1.2162)	Acc@1 37.500 (49.564)	Acc@5 81.250 (85.793)
Test: [500/750]	Time 0.169 (0.110)	Loss 0.9743 (1.2540)	Acc@1 65.625 (48.110)	Acc@5 84.375 (84.550)
Test: [600/750]	Time 0.107 (0.110)	Loss 1.3081 (1.2354)	Acc@1 50.000 (50.369)	Acc@5 87.500 (84.926)
Test: [700/750]	Time 0.098 (0.110)	Loss 1.1994 (1.2276)	Acc@1 59.375 (51.614)	Acc@5 81.250 (85.605)
 * Acc@1 52.850 Acc@5 85.850
==> training...
Epoch: [7][0/875]	Time 1.682 (1.682)	Data 1.193 (1.193)	Loss 2.6238 (2.6238)	Loss@kd 2.3216 (2.3216)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [7][100/875]	Time 0.395 (0.403)	Data 0.007 (0.018)	Loss 3.1269 (2.9487)	Loss@kd 2.4509 (2.4647)	Acc@1 43.750 (53.744)	Acc@5 93.750 (95.931)
Epoch: [7][200/875]	Time 0.360 (0.388)	Data 0.006 (0.013)	Loss 2.9224 (2.9521)	Loss@kd 2.3769 (2.4665)	Acc@1 48.438 (53.382)	Acc@5 98.438 (96.191)
Epoch: [7][300/875]	Time 0.357 (0.381)	Data 0.007 (0.011)	Loss 3.1263 (2.9527)	Loss@kd 2.7038 (2.4670)	Acc@1 56.250 (53.187)	Acc@5 96.875 (96.226)
Epoch: [7][400/875]	Time 0.358 (0.378)	Data 0.007 (0.010)	Loss 2.7623 (2.9513)	Loss@kd 2.4118 (2.4642)	Acc@1 60.938 (53.168)	Acc@5 98.438 (96.267)
Epoch: [7][500/875]	Time 0.405 (0.377)	Data 0.006 (0.009)	Loss 3.0768 (2.9520)	Loss@kd 2.5240 (2.4611)	Acc@1 56.250 (53.060)	Acc@5 95.312 (96.264)
Epoch: [7][600/875]	Time 0.377 (0.378)	Data 0.006 (0.009)	Loss 3.1341 (2.9489)	Loss@kd 2.4507 (2.4590)	Acc@1 53.125 (53.039)	Acc@5 93.750 (96.319)
Epoch: [7][700/875]	Time 0.382 (0.379)	Data 0.007 (0.008)	Loss 3.1750 (2.9475)	Loss@kd 2.4636 (2.4577)	Acc@1 43.750 (52.971)	Acc@5 95.312 (96.373)
Epoch: [7][800/875]	Time 0.422 (0.380)	Data 0.006 (0.008)	Loss 3.0439 (2.9440)	Loss@kd 2.5052 (2.4566)	Acc@1 53.125 (53.022)	Acc@5 96.875 (96.372)
 * Acc@1 53.070 Acc@5 96.371
epoch 7, total time 332.47
Test: [0/750]	Time 0.799 (0.799)	Loss 0.6754 (0.6754)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.083 (0.114)	Loss 0.5411 (0.5733)	Acc@1 81.250 (82.859)	Acc@5 96.875 (88.428)
Test: [200/750]	Time 0.081 (0.109)	Loss 1.9053 (0.6338)	Acc@1 21.875 (79.493)	Acc@5 71.875 (91.433)
Test: [300/750]	Time 0.109 (0.108)	Loss 1.8630 (0.9968)	Acc@1 18.750 (62.562)	Acc@5 71.875 (87.355)
Test: [400/750]	Time 0.105 (0.107)	Loss 0.9876 (1.1529)	Acc@1 75.000 (54.715)	Acc@5 93.750 (85.287)
Test: [500/750]	Time 0.140 (0.107)	Loss 0.8949 (1.1250)	Acc@1 68.750 (57.441)	Acc@5 87.500 (86.209)
Test: [600/750]	Time 0.078 (0.106)	Loss 1.3070 (1.1245)	Acc@1 43.750 (57.935)	Acc@5 84.375 (86.528)
Test: [700/750]	Time 0.101 (0.106)	Loss 1.4373 (1.1593)	Acc@1 34.375 (56.250)	Acc@5 81.250 (86.595)
 * Acc@1 56.013 Acc@5 86.350
saving the best model!
==> training...
Epoch: [8][0/875]	Time 1.628 (1.628)	Data 1.170 (1.170)	Loss 2.8954 (2.8954)	Loss@kd 2.4053 (2.4053)	Acc@1 53.125 (53.125)	Acc@5 98.438 (98.438)
Epoch: [8][100/875]	Time 0.396 (0.396)	Data 0.007 (0.018)	Loss 3.2247 (2.9275)	Loss@kd 2.6186 (2.4464)	Acc@1 43.750 (53.311)	Acc@5 100.000 (96.504)
Epoch: [8][200/875]	Time 0.380 (0.389)	Data 0.007 (0.012)	Loss 2.9183 (2.9461)	Loss@kd 2.3640 (2.4456)	Acc@1 50.000 (52.596)	Acc@5 100.000 (96.479)
Epoch: [8][300/875]	Time 0.374 (0.390)	Data 0.007 (0.010)	Loss 2.9387 (2.9349)	Loss@kd 2.5140 (2.4395)	Acc@1 54.688 (53.281)	Acc@5 98.438 (96.382)
Epoch: [8][400/875]	Time 0.378 (0.391)	Data 0.006 (0.009)	Loss 2.8933 (2.9228)	Loss@kd 2.4941 (2.4337)	Acc@1 59.375 (53.784)	Acc@5 96.875 (96.372)
Epoch: [8][500/875]	Time 0.405 (0.391)	Data 0.006 (0.009)	Loss 2.7170 (2.9173)	Loss@kd 2.3814 (2.4340)	Acc@1 68.750 (53.780)	Acc@5 98.438 (96.473)
Epoch: [8][600/875]	Time 0.383 (0.391)	Data 0.007 (0.009)	Loss 2.8499 (2.9099)	Loss@kd 2.3414 (2.4314)	Acc@1 56.250 (54.012)	Acc@5 98.438 (96.488)
Epoch: [8][700/875]	Time 0.358 (0.389)	Data 0.007 (0.008)	Loss 2.8771 (2.9075)	Loss@kd 2.4479 (2.4278)	Acc@1 50.000 (54.119)	Acc@5 98.438 (96.456)
Epoch: [8][800/875]	Time 0.356 (0.387)	Data 0.007 (0.008)	Loss 2.7908 (2.9051)	Loss@kd 2.3101 (2.4250)	Acc@1 56.250 (54.180)	Acc@5 96.875 (96.504)
 * Acc@1 54.241 Acc@5 96.505
epoch 8, total time 337.28
Test: [0/750]	Time 0.830 (0.830)	Loss 0.7049 (0.7049)	Acc@1 81.250 (81.250)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.112 (0.115)	Loss 0.4539 (0.5975)	Acc@1 87.500 (81.188)	Acc@5 96.875 (88.243)
Test: [200/750]	Time 0.111 (0.106)	Loss 1.7546 (0.6198)	Acc@1 37.500 (79.011)	Acc@5 87.500 (92.211)
Test: [300/750]	Time 0.114 (0.106)	Loss 2.1020 (0.9712)	Acc@1 12.500 (64.628)	Acc@5 56.250 (89.452)
Test: [400/750]	Time 0.095 (0.105)	Loss 1.0012 (1.1934)	Acc@1 75.000 (54.123)	Acc@5 87.500 (84.546)
Test: [500/750]	Time 0.172 (0.106)	Loss 0.9357 (1.1713)	Acc@1 62.500 (56.705)	Acc@5 93.750 (84.830)
Test: [600/750]	Time 0.113 (0.106)	Loss 0.9994 (1.1382)	Acc@1 68.750 (58.283)	Acc@5 90.625 (86.143)
Test: [700/750]	Time 0.098 (0.107)	Loss 1.8434 (1.1637)	Acc@1 25.000 (56.263)	Acc@5 68.750 (86.296)
 * Acc@1 54.754 Acc@5 85.596
==> training...
Epoch: [9][0/875]	Time 1.576 (1.576)	Data 1.134 (1.134)	Loss 2.6947 (2.6947)	Loss@kd 2.3625 (2.3625)	Acc@1 59.375 (59.375)	Acc@5 96.875 (96.875)
Epoch: [9][100/875]	Time 0.423 (0.397)	Data 0.009 (0.018)	Loss 2.9840 (2.8956)	Loss@kd 2.3280 (2.4159)	Acc@1 51.562 (53.991)	Acc@5 93.750 (96.581)
Epoch: [9][200/875]	Time 0.400 (0.392)	Data 0.006 (0.012)	Loss 2.8674 (2.8829)	Loss@kd 2.4921 (2.4018)	Acc@1 67.188 (54.190)	Acc@5 95.312 (96.463)
Epoch: [9][300/875]	Time 0.374 (0.391)	Data 0.006 (0.010)	Loss 2.6667 (2.8678)	Loss@kd 2.3697 (2.3975)	Acc@1 60.938 (54.485)	Acc@5 96.875 (96.605)
Epoch: [9][400/875]	Time 0.389 (0.391)	Data 0.007 (0.009)	Loss 2.7659 (2.8754)	Loss@kd 2.3687 (2.3980)	Acc@1 56.250 (54.438)	Acc@5 96.875 (96.520)
Epoch: [9][500/875]	Time 0.390 (0.391)	Data 0.006 (0.009)	Loss 2.9706 (2.8732)	Loss@kd 2.4132 (2.4001)	Acc@1 48.438 (54.681)	Acc@5 95.312 (96.569)
Epoch: [9][600/875]	Time 0.350 (0.391)	Data 0.004 (0.008)	Loss 2.7951 (2.8687)	Loss@kd 2.2650 (2.3972)	Acc@1 50.000 (54.797)	Acc@5 95.312 (96.633)
Epoch: [9][700/875]	Time 0.376 (0.391)	Data 0.006 (0.008)	Loss 2.5674 (2.8676)	Loss@kd 2.3590 (2.3961)	Acc@1 65.625 (54.763)	Acc@5 98.438 (96.681)
Epoch: [9][800/875]	Time 0.379 (0.391)	Data 0.007 (0.008)	Loss 3.1091 (2.8644)	Loss@kd 2.4715 (2.3936)	Acc@1 54.688 (54.844)	Acc@5 93.750 (96.678)
 * Acc@1 54.852 Acc@5 96.732
epoch 9, total time 342.24
Test: [0/750]	Time 0.831 (0.831)	Loss 0.8055 (0.8055)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.096 (0.116)	Loss 0.6851 (0.7012)	Acc@1 75.000 (80.569)	Acc@5 100.000 (87.005)
Test: [200/750]	Time 0.118 (0.111)	Loss 1.6184 (0.7527)	Acc@1 40.625 (75.964)	Acc@5 90.625 (90.470)
Test: [300/750]	Time 0.099 (0.111)	Loss 1.5928 (0.9767)	Acc@1 18.750 (65.428)	Acc@5 84.375 (90.978)
Test: [400/750]	Time 0.102 (0.110)	Loss 1.1237 (1.1121)	Acc@1 75.000 (55.899)	Acc@5 81.250 (89.737)
Test: [500/750]	Time 0.098 (0.110)	Loss 0.9851 (1.1257)	Acc@1 65.625 (56.512)	Acc@5 84.375 (87.824)
Test: [600/750]	Time 0.082 (0.109)	Loss 1.0446 (1.1107)	Acc@1 56.250 (57.914)	Acc@5 84.375 (87.937)
Test: [700/750]	Time 0.110 (0.109)	Loss 1.5123 (1.1141)	Acc@1 40.625 (57.962)	Acc@5 78.125 (88.120)
 * Acc@1 58.025 Acc@5 87.758
saving the best model!
==> training...
Epoch: [10][0/875]	Time 1.579 (1.579)	Data 1.199 (1.199)	Loss 2.7878 (2.7878)	Loss@kd 2.3999 (2.3999)	Acc@1 57.812 (57.812)	Acc@5 96.875 (96.875)
Epoch: [10][100/875]	Time 0.360 (0.386)	Data 0.006 (0.019)	Loss 2.7945 (2.8560)	Loss@kd 2.4295 (2.3768)	Acc@1 57.812 (54.657)	Acc@5 100.000 (96.395)
Epoch: [10][200/875]	Time 0.443 (0.380)	Data 0.008 (0.013)	Loss 2.5449 (2.8443)	Loss@kd 2.3764 (2.3775)	Acc@1 65.625 (55.146)	Acc@5 100.000 (96.541)
Epoch: [10][300/875]	Time 0.363 (0.377)	Data 0.007 (0.011)	Loss 2.6016 (2.8394)	Loss@kd 2.3880 (2.3706)	Acc@1 62.500 (55.056)	Acc@5 96.875 (96.641)
Epoch: [10][400/875]	Time 0.396 (0.380)	Data 0.006 (0.010)	Loss 2.9114 (2.8314)	Loss@kd 2.3839 (2.3655)	Acc@1 60.938 (55.478)	Acc@5 95.312 (96.707)
Epoch: [10][500/875]	Time 0.407 (0.382)	Data 0.006 (0.009)	Loss 2.8288 (2.8274)	Loss@kd 2.4593 (2.3654)	Acc@1 56.250 (55.654)	Acc@5 95.312 (96.747)
Epoch: [10][600/875]	Time 0.367 (0.384)	Data 0.006 (0.009)	Loss 2.7533 (2.8303)	Loss@kd 2.3074 (2.3647)	Acc@1 62.500 (55.701)	Acc@5 98.438 (96.745)
Epoch: [10][700/875]	Time 0.400 (0.385)	Data 0.007 (0.008)	Loss 2.7453 (2.8312)	Loss@kd 2.4300 (2.3650)	Acc@1 62.500 (55.693)	Acc@5 96.875 (96.748)
Epoch: [10][800/875]	Time 0.372 (0.386)	Data 0.007 (0.008)	Loss 2.9733 (2.8314)	Loss@kd 2.3266 (2.3663)	Acc@1 45.312 (55.743)	Acc@5 95.312 (96.752)
 * Acc@1 55.763 Acc@5 96.793
epoch 10, total time 338.25
Test: [0/750]	Time 0.784 (0.784)	Loss 0.7658 (0.7658)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.099 (0.116)	Loss 0.5432 (0.6460)	Acc@1 81.250 (81.250)	Acc@5 100.000 (87.562)
Test: [200/750]	Time 0.102 (0.111)	Loss 1.8093 (0.6733)	Acc@1 28.125 (77.938)	Acc@5 75.000 (90.936)
Test: [300/750]	Time 0.108 (0.111)	Loss 1.6947 (0.9927)	Acc@1 18.750 (61.638)	Acc@5 93.750 (88.777)
Test: [400/750]	Time 0.110 (0.110)	Loss 1.0560 (1.1298)	Acc@1 71.875 (53.522)	Acc@5 87.500 (88.560)
Test: [500/750]	Time 0.090 (0.110)	Loss 1.2471 (1.1499)	Acc@1 62.500 (54.397)	Acc@5 81.250 (87.325)
Test: [600/750]	Time 0.105 (0.109)	Loss 1.1160 (1.1625)	Acc@1 59.375 (54.908)	Acc@5 87.500 (86.902)
Test: [700/750]	Time 0.085 (0.109)	Loss 1.0984 (1.1531)	Acc@1 65.625 (55.546)	Acc@5 81.250 (87.340)
 * Acc@1 56.504 Acc@5 87.642
==> training...
Epoch: [11][0/875]	Time 1.757 (1.757)	Data 1.264 (1.264)	Loss 2.8773 (2.8773)	Loss@kd 2.3246 (2.3246)	Acc@1 51.562 (51.562)	Acc@5 100.000 (100.000)
Epoch: [11][100/875]	Time 0.355 (0.403)	Data 0.007 (0.019)	Loss 3.1880 (2.8178)	Loss@kd 2.3463 (2.3501)	Acc@1 39.062 (55.523)	Acc@5 90.625 (96.643)
Epoch: [11][200/875]	Time 0.421 (0.395)	Data 0.006 (0.013)	Loss 2.7903 (2.8248)	Loss@kd 2.3437 (2.3627)	Acc@1 59.375 (55.255)	Acc@5 93.750 (97.015)
Epoch: [11][300/875]	Time 0.361 (0.394)	Data 0.007 (0.011)	Loss 2.9246 (2.8251)	Loss@kd 2.3909 (2.3590)	Acc@1 53.125 (55.295)	Acc@5 95.312 (96.989)
Epoch: [11][400/875]	Time 0.361 (0.394)	Data 0.007 (0.010)	Loss 2.8514 (2.8148)	Loss@kd 2.3036 (2.3539)	Acc@1 50.000 (55.685)	Acc@5 98.438 (97.027)
Epoch: [11][500/875]	Time 0.367 (0.392)	Data 0.007 (0.009)	Loss 2.8338 (2.8101)	Loss@kd 2.3674 (2.3513)	Acc@1 54.688 (55.788)	Acc@5 98.438 (97.071)
Epoch: [11][600/875]	Time 0.364 (0.388)	Data 0.009 (0.009)	Loss 2.7965 (2.8092)	Loss@kd 2.2866 (2.3514)	Acc@1 57.812 (55.896)	Acc@5 96.875 (97.034)
Epoch: [11][700/875]	Time 0.375 (0.386)	Data 0.007 (0.008)	Loss 2.6135 (2.8094)	Loss@kd 2.2475 (2.3487)	Acc@1 60.938 (55.795)	Acc@5 98.438 (96.989)
Epoch: [11][800/875]	Time 0.357 (0.385)	Data 0.006 (0.008)	Loss 2.6824 (2.8042)	Loss@kd 2.3191 (2.3457)	Acc@1 57.812 (55.934)	Acc@5 100.000 (97.021)
 * Acc@1 55.996 Acc@5 97.002
epoch 11, total time 337.77
Test: [0/750]	Time 0.750 (0.750)	Loss 0.6245 (0.6245)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.106 (0.114)	Loss 0.6044 (0.5976)	Acc@1 78.125 (80.662)	Acc@5 100.000 (88.861)
Test: [200/750]	Time 0.096 (0.109)	Loss 1.5970 (0.6694)	Acc@1 34.375 (76.384)	Acc@5 75.000 (92.304)
Test: [300/750]	Time 0.101 (0.109)	Loss 1.8173 (0.9507)	Acc@1 15.625 (64.535)	Acc@5 68.750 (90.957)
Test: [400/750]	Time 0.104 (0.107)	Loss 1.0780 (1.1411)	Acc@1 71.875 (54.730)	Acc@5 90.625 (87.329)
Test: [500/750]	Time 0.142 (0.107)	Loss 0.8012 (1.1451)	Acc@1 75.000 (56.549)	Acc@5 87.500 (86.072)
Test: [600/750]	Time 0.116 (0.107)	Loss 1.0384 (1.1151)	Acc@1 65.625 (58.439)	Acc@5 90.625 (86.814)
Test: [700/750]	Time 0.105 (0.107)	Loss 1.4536 (1.1268)	Acc@1 40.625 (57.623)	Acc@5 78.125 (87.353)
 * Acc@1 57.058 Acc@5 87.342
==> training...
Epoch: [12][0/875]	Time 1.639 (1.639)	Data 1.167 (1.167)	Loss 2.6771 (2.6771)	Loss@kd 2.2116 (2.2116)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)
Epoch: [12][100/875]	Time 0.365 (0.403)	Data 0.006 (0.018)	Loss 2.6981 (2.7809)	Loss@kd 2.3874 (2.3228)	Acc@1 57.812 (56.513)	Acc@5 100.000 (96.782)
Epoch: [12][200/875]	Time 0.400 (0.397)	Data 0.007 (0.012)	Loss 2.8895 (2.7874)	Loss@kd 2.3571 (2.3314)	Acc@1 54.688 (56.273)	Acc@5 98.438 (96.914)
Epoch: [12][300/875]	Time 0.402 (0.396)	Data 0.007 (0.010)	Loss 2.8562 (2.7846)	Loss@kd 2.2354 (2.3263)	Acc@1 57.812 (56.271)	Acc@5 93.750 (96.880)
Epoch: [12][400/875]	Time 0.417 (0.394)	Data 0.007 (0.010)	Loss 2.8256 (2.7828)	Loss@kd 2.3259 (2.3282)	Acc@1 53.125 (56.297)	Acc@5 96.875 (96.937)
Epoch: [12][500/875]	Time 0.372 (0.394)	Data 0.008 (0.009)	Loss 2.7589 (2.7793)	Loss@kd 2.2098 (2.3247)	Acc@1 42.188 (56.387)	Acc@5 98.438 (97.034)
Epoch: [12][600/875]	Time 0.374 (0.393)	Data 0.007 (0.009)	Loss 2.8904 (2.7763)	Loss@kd 2.2667 (2.3245)	Acc@1 53.125 (56.492)	Acc@5 96.875 (97.083)
Epoch: [12][700/875]	Time 0.370 (0.393)	Data 0.007 (0.008)	Loss 2.8386 (2.7772)	Loss@kd 2.3028 (2.3245)	Acc@1 56.250 (56.515)	Acc@5 98.438 (97.047)
Epoch: [12][800/875]	Time 0.397 (0.393)	Data 0.006 (0.008)	Loss 2.6883 (2.7764)	Loss@kd 2.3160 (2.3230)	Acc@1 59.375 (56.543)	Acc@5 98.438 (97.017)
 * Acc@1 56.561 Acc@5 97.025
epoch 12, total time 344.17
Test: [0/750]	Time 0.921 (0.921)	Loss 0.8569 (0.8569)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.105 (0.118)	Loss 0.6588 (0.7356)	Acc@1 75.000 (77.785)	Acc@5 96.875 (86.819)
Test: [200/750]	Time 0.107 (0.111)	Loss 1.5289 (0.7344)	Acc@1 46.875 (75.451)	Acc@5 87.500 (90.641)
Test: [300/750]	Time 0.112 (0.110)	Loss 1.4230 (0.9447)	Acc@1 25.000 (65.116)	Acc@5 90.625 (90.822)
Test: [400/750]	Time 0.104 (0.109)	Loss 1.0214 (1.0676)	Acc@1 71.875 (56.757)	Acc@5 84.375 (90.157)
Test: [500/750]	Time 0.167 (0.109)	Loss 1.2222 (1.1051)	Acc@1 62.500 (57.067)	Acc@5 81.250 (88.005)
Test: [600/750]	Time 0.107 (0.108)	Loss 1.1392 (1.1257)	Acc@1 53.125 (57.217)	Acc@5 81.250 (87.531)
Test: [700/750]	Time 0.113 (0.109)	Loss 1.2553 (1.1333)	Acc@1 50.000 (57.017)	Acc@5 78.125 (87.589)
 * Acc@1 57.321 Acc@5 87.679
==> training...
Epoch: [13][0/875]	Time 1.579 (1.579)	Data 1.130 (1.130)	Loss 2.9171 (2.9171)	Loss@kd 2.3388 (2.3388)	Acc@1 48.438 (48.438)	Acc@5 95.312 (95.312)
Epoch: [13][100/875]	Time 0.355 (0.382)	Data 0.007 (0.018)	Loss 2.6035 (2.7763)	Loss@kd 2.2449 (2.3151)	Acc@1 64.062 (56.188)	Acc@5 95.312 (96.875)
Epoch: [13][200/875]	Time 0.388 (0.380)	Data 0.006 (0.012)	Loss 2.9605 (2.7615)	Loss@kd 2.3473 (2.3057)	Acc@1 46.875 (56.584)	Acc@5 92.188 (97.054)
Epoch: [13][300/875]	Time 0.366 (0.382)	Data 0.007 (0.010)	Loss 2.8157 (2.7618)	Loss@kd 2.2982 (2.3091)	Acc@1 56.250 (56.665)	Acc@5 93.750 (96.994)
Epoch: [13][400/875]	Time 0.394 (0.384)	Data 0.007 (0.009)	Loss 2.5342 (2.7581)	Loss@kd 2.2720 (2.3073)	Acc@1 65.625 (56.823)	Acc@5 98.438 (97.000)
Epoch: [13][500/875]	Time 0.367 (0.384)	Data 0.007 (0.009)	Loss 2.7419 (2.7590)	Loss@kd 2.2929 (2.3066)	Acc@1 60.938 (56.680)	Acc@5 100.000 (97.047)
Epoch: [13][600/875]	Time 0.388 (0.384)	Data 0.007 (0.009)	Loss 2.9756 (2.7578)	Loss@kd 2.4503 (2.3073)	Acc@1 51.562 (56.723)	Acc@5 95.312 (97.073)
Epoch: [13][700/875]	Time 0.387 (0.383)	Data 0.007 (0.008)	Loss 2.8710 (2.7576)	Loss@kd 2.3108 (2.3061)	Acc@1 59.375 (56.633)	Acc@5 96.875 (97.100)
Epoch: [13][800/875]	Time 0.382 (0.383)	Data 0.007 (0.008)	Loss 3.1255 (2.7593)	Loss@kd 2.3494 (2.3075)	Acc@1 46.875 (56.595)	Acc@5 95.312 (97.072)
 * Acc@1 56.618 Acc@5 97.088
epoch 13, total time 335.05
Test: [0/750]	Time 0.725 (0.725)	Loss 0.6989 (0.6989)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.092 (0.114)	Loss 0.3916 (0.5714)	Acc@1 81.250 (82.704)	Acc@5 100.000 (88.645)
Test: [200/750]	Time 0.089 (0.109)	Loss 1.7276 (0.5755)	Acc@1 34.375 (81.126)	Acc@5 71.875 (92.086)
Test: [300/750]	Time 0.115 (0.109)	Loss 1.4558 (0.8847)	Acc@1 43.750 (66.788)	Acc@5 93.750 (90.864)
Test: [400/750]	Time 0.095 (0.108)	Loss 0.9828 (1.0192)	Acc@1 71.875 (59.967)	Acc@5 87.500 (90.228)
Test: [500/750]	Time 0.103 (0.108)	Loss 0.9365 (1.0415)	Acc@1 65.625 (61.165)	Acc@5 87.500 (88.479)
Test: [600/750]	Time 0.096 (0.107)	Loss 1.1191 (1.0570)	Acc@1 56.250 (61.179)	Acc@5 87.500 (88.535)
Test: [700/750]	Time 0.103 (0.107)	Loss 1.4590 (1.0929)	Acc@1 46.875 (59.397)	Acc@5 78.125 (88.503)
 * Acc@1 58.792 Acc@5 88.425
saving the best model!
==> training...
Epoch: [14][0/875]	Time 1.681 (1.681)	Data 1.261 (1.261)	Loss 2.8156 (2.8156)	Loss@kd 2.3628 (2.3628)	Acc@1 53.125 (53.125)	Acc@5 96.875 (96.875)
Epoch: [14][100/875]	Time 0.367 (0.402)	Data 0.007 (0.019)	Loss 2.5526 (2.7072)	Loss@kd 2.2207 (2.2849)	Acc@1 64.062 (57.457)	Acc@5 96.875 (97.525)
Epoch: [14][200/875]	Time 0.373 (0.394)	Data 0.010 (0.013)	Loss 2.6171 (2.7252)	Loss@kd 2.3249 (2.2915)	Acc@1 65.625 (57.214)	Acc@5 98.438 (97.411)
Epoch: [14][300/875]	Time 0.359 (0.392)	Data 0.007 (0.011)	Loss 2.7756 (2.7221)	Loss@kd 2.1927 (2.2888)	Acc@1 59.375 (57.532)	Acc@5 95.312 (97.389)
Epoch: [14][400/875]	Time 0.350 (0.388)	Data 0.007 (0.010)	Loss 2.7471 (2.7247)	Loss@kd 2.2006 (2.2873)	Acc@1 57.812 (57.403)	Acc@5 95.312 (97.269)
Epoch: [14][500/875]	Time 0.362 (0.384)	Data 0.007 (0.009)	Loss 2.9764 (2.7226)	Loss@kd 2.3218 (2.2892)	Acc@1 51.562 (57.566)	Acc@5 93.750 (97.312)
Epoch: [14][600/875]	Time 0.378 (0.381)	Data 0.007 (0.009)	Loss 2.7518 (2.7300)	Loss@kd 2.2881 (2.2904)	Acc@1 50.000 (57.306)	Acc@5 98.438 (97.257)
Epoch: [14][700/875]	Time 0.329 (0.380)	Data 0.004 (0.009)	Loss 3.0960 (2.7309)	Loss@kd 2.6212 (2.2899)	Acc@1 56.250 (57.367)	Acc@5 98.438 (97.218)
Epoch: [14][800/875]	Time 0.381 (0.381)	Data 0.007 (0.008)	Loss 2.7591 (2.7306)	Loss@kd 2.3209 (2.2887)	Acc@1 57.812 (57.313)	Acc@5 98.438 (97.187)
 * Acc@1 57.382 Acc@5 97.182
epoch 14, total time 333.79
Test: [0/750]	Time 0.703 (0.703)	Loss 0.7027 (0.7027)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.099 (0.111)	Loss 0.5993 (0.5915)	Acc@1 71.875 (81.436)	Acc@5 100.000 (88.459)
Test: [200/750]	Time 0.089 (0.107)	Loss 1.7886 (0.6743)	Acc@1 34.375 (75.855)	Acc@5 81.250 (91.760)
Test: [300/750]	Time 0.091 (0.107)	Loss 1.5517 (0.9934)	Acc@1 31.250 (61.784)	Acc@5 90.625 (89.670)
Test: [400/750]	Time 0.115 (0.106)	Loss 1.0321 (1.1194)	Acc@1 68.750 (54.029)	Acc@5 90.625 (89.222)
Test: [500/750]	Time 0.114 (0.107)	Loss 0.8238 (1.1101)	Acc@1 71.875 (55.976)	Acc@5 90.625 (88.286)
Test: [600/750]	Time 0.138 (0.106)	Loss 0.9793 (1.0860)	Acc@1 71.875 (58.085)	Acc@5 87.500 (88.628)
Test: [700/750]	Time 0.094 (0.106)	Loss 1.2974 (1.0772)	Acc@1 53.125 (58.702)	Acc@5 81.250 (89.002)
 * Acc@1 59.162 Acc@5 88.946
saving the best model!
==> training...
Epoch: [15][0/875]	Time 1.731 (1.731)	Data 1.263 (1.263)	Loss 2.5750 (2.5750)	Loss@kd 2.3625 (2.3625)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [15][100/875]	Time 0.357 (0.394)	Data 0.007 (0.019)	Loss 2.5655 (2.6992)	Loss@kd 2.2523 (2.2699)	Acc@1 59.375 (57.580)	Acc@5 100.000 (97.509)
Epoch: [15][200/875]	Time 0.368 (0.385)	Data 0.007 (0.013)	Loss 2.9767 (2.7182)	Loss@kd 2.3319 (2.2764)	Acc@1 42.188 (57.074)	Acc@5 95.312 (97.380)
Epoch: [15][300/875]	Time 0.355 (0.383)	Data 0.006 (0.011)	Loss 2.5998 (2.7124)	Loss@kd 2.3126 (2.2734)	Acc@1 64.062 (57.236)	Acc@5 96.875 (97.254)
Epoch: [15][400/875]	Time 0.360 (0.382)	Data 0.007 (0.010)	Loss 2.6432 (2.7206)	Loss@kd 2.2529 (2.2777)	Acc@1 53.125 (57.357)	Acc@5 98.438 (97.124)
Epoch: [15][500/875]	Time 0.375 (0.382)	Data 0.004 (0.009)	Loss 2.7449 (2.7174)	Loss@kd 2.2112 (2.2763)	Acc@1 57.812 (57.507)	Acc@5 93.750 (97.103)
Epoch: [15][600/875]	Time 0.357 (0.382)	Data 0.007 (0.009)	Loss 2.8432 (2.7142)	Loss@kd 2.2657 (2.2742)	Acc@1 48.438 (57.576)	Acc@5 96.875 (97.122)
Epoch: [15][700/875]	Time 0.389 (0.382)	Data 0.007 (0.008)	Loss 2.6826 (2.7078)	Loss@kd 2.2284 (2.2725)	Acc@1 60.938 (57.750)	Acc@5 95.312 (97.163)
Epoch: [15][800/875]	Time 0.354 (0.382)	Data 0.005 (0.008)	Loss 2.5717 (2.7043)	Loss@kd 2.2665 (2.2709)	Acc@1 65.625 (57.902)	Acc@5 95.312 (97.214)
 * Acc@1 57.802 Acc@5 97.243
epoch 15, total time 333.75
Test: [0/750]	Time 0.788 (0.788)	Loss 0.7038 (0.7038)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.097 (0.113)	Loss 0.6073 (0.5622)	Acc@1 75.000 (81.467)	Acc@5 96.875 (89.790)
Test: [200/750]	Time 0.095 (0.107)	Loss 1.7205 (0.6442)	Acc@1 40.625 (77.114)	Acc@5 87.500 (92.506)
Test: [300/750]	Time 0.104 (0.107)	Loss 1.5354 (0.9733)	Acc@1 40.625 (62.407)	Acc@5 84.375 (90.365)
Test: [400/750]	Time 0.101 (0.106)	Loss 1.2295 (1.1152)	Acc@1 53.125 (54.910)	Acc@5 81.250 (88.988)
Test: [500/750]	Time 0.174 (0.106)	Loss 0.7669 (1.1224)	Acc@1 81.250 (56.687)	Acc@5 87.500 (87.132)
Test: [600/750]	Time 0.104 (0.105)	Loss 1.0976 (1.0968)	Acc@1 62.500 (58.611)	Acc@5 90.625 (87.620)
Test: [700/750]	Time 0.109 (0.105)	Loss 1.4136 (1.0963)	Acc@1 46.875 (58.755)	Acc@5 78.125 (88.124)
 * Acc@1 58.942 Acc@5 88.054
==> training...
Epoch: [16][0/875]	Time 1.513 (1.513)	Data 1.108 (1.108)	Loss 2.8015 (2.8015)	Loss@kd 2.2651 (2.2651)	Acc@1 54.688 (54.688)	Acc@5 93.750 (93.750)
Epoch: [16][100/875]	Time 0.377 (0.392)	Data 0.007 (0.018)	Loss 2.9403 (2.7008)	Loss@kd 2.4523 (2.2763)	Acc@1 46.875 (57.998)	Acc@5 98.438 (97.308)
Epoch: [16][200/875]	Time 0.354 (0.393)	Data 0.006 (0.012)	Loss 2.6611 (2.6830)	Loss@kd 2.2137 (2.2637)	Acc@1 60.938 (58.022)	Acc@5 98.438 (97.388)
Epoch: [16][300/875]	Time 0.370 (0.391)	Data 0.007 (0.010)	Loss 2.9512 (2.6845)	Loss@kd 2.3927 (2.2642)	Acc@1 53.125 (58.160)	Acc@5 100.000 (97.316)
Epoch: [16][400/875]	Time 0.423 (0.391)	Data 0.007 (0.009)	Loss 2.5626 (2.6853)	Loss@kd 2.1896 (2.2630)	Acc@1 62.500 (58.198)	Acc@5 96.875 (97.315)
Epoch: [16][500/875]	Time 0.401 (0.391)	Data 0.007 (0.009)	Loss 2.6968 (2.6825)	Loss@kd 2.2714 (2.2597)	Acc@1 57.812 (58.274)	Acc@5 98.438 (97.333)
Epoch: [16][600/875]	Time 0.413 (0.391)	Data 0.006 (0.009)	Loss 2.5526 (2.6846)	Loss@kd 2.2277 (2.2594)	Acc@1 64.062 (58.257)	Acc@5 98.438 (97.333)
Epoch: [16][700/875]	Time 0.400 (0.391)	Data 0.008 (0.008)	Loss 2.6914 (2.6825)	Loss@kd 2.1617 (2.2586)	Acc@1 56.250 (58.301)	Acc@5 95.312 (97.359)
Epoch: [16][800/875]	Time 0.348 (0.391)	Data 0.005 (0.008)	Loss 2.7854 (2.6832)	Loss@kd 2.2321 (2.2562)	Acc@1 50.000 (58.189)	Acc@5 95.312 (97.324)
 * Acc@1 58.218 Acc@5 97.329
epoch 16, total time 342.37
Test: [0/750]	Time 0.905 (0.905)	Loss 0.6525 (0.6525)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.112 (0.117)	Loss 0.3364 (0.5228)	Acc@1 87.500 (83.694)	Acc@5 100.000 (89.233)
Test: [200/750]	Time 0.104 (0.110)	Loss 1.6536 (0.5290)	Acc@1 34.375 (82.136)	Acc@5 81.250 (92.413)
Test: [300/750]	Time 0.105 (0.109)	Loss 1.5630 (0.8739)	Acc@1 37.500 (66.767)	Acc@5 84.375 (90.210)
Test: [400/750]	Time 0.113 (0.107)	Loss 0.8843 (1.0099)	Acc@1 81.250 (59.648)	Acc@5 90.625 (89.869)
Test: [500/750]	Time 0.166 (0.107)	Loss 0.9125 (1.0222)	Acc@1 75.000 (61.078)	Acc@5 90.625 (88.760)
Test: [600/750]	Time 0.099 (0.106)	Loss 1.3055 (1.0515)	Acc@1 46.875 (60.779)	Acc@5 87.500 (88.452)
Test: [700/750]	Time 0.105 (0.106)	Loss 1.5686 (1.0851)	Acc@1 43.750 (58.911)	Acc@5 75.000 (88.775)
 * Acc@1 58.712 Acc@5 88.817
==> training...
Epoch: [17][0/875]	Time 1.535 (1.535)	Data 1.103 (1.103)	Loss 2.4588 (2.4588)	Loss@kd 2.1358 (2.1358)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [17][100/875]	Time 0.345 (0.401)	Data 0.006 (0.018)	Loss 2.6569 (2.6693)	Loss@kd 2.2070 (2.2636)	Acc@1 51.562 (58.431)	Acc@5 98.438 (97.293)
Epoch: [17][200/875]	Time 0.424 (0.394)	Data 0.006 (0.012)	Loss 2.7059 (2.6682)	Loss@kd 2.2889 (2.2572)	Acc@1 62.500 (58.559)	Acc@5 96.875 (97.303)
Epoch: [17][300/875]	Time 0.367 (0.385)	Data 0.007 (0.010)	Loss 2.6045 (2.6669)	Loss@kd 2.2540 (2.2489)	Acc@1 56.250 (58.570)	Acc@5 98.438 (97.342)
Epoch: [17][400/875]	Time 0.352 (0.380)	Data 0.007 (0.009)	Loss 2.8111 (2.6695)	Loss@kd 2.2777 (2.2498)	Acc@1 50.000 (58.611)	Acc@5 95.312 (97.382)
Epoch: [17][500/875]	Time 0.377 (0.380)	Data 0.004 (0.009)	Loss 2.6765 (2.6694)	Loss@kd 2.2487 (2.2470)	Acc@1 64.062 (58.661)	Acc@5 100.000 (97.411)
Epoch: [17][600/875]	Time 0.377 (0.382)	Data 0.007 (0.009)	Loss 2.7555 (2.6741)	Loss@kd 2.2207 (2.2474)	Acc@1 57.812 (58.559)	Acc@5 98.438 (97.392)
Epoch: [17][700/875]	Time 0.421 (0.386)	Data 0.009 (0.008)	Loss 2.5067 (2.6668)	Loss@kd 2.1906 (2.2433)	Acc@1 59.375 (58.686)	Acc@5 98.438 (97.401)
Epoch: [17][800/875]	Time 0.399 (0.387)	Data 0.007 (0.008)	Loss 2.6646 (2.6628)	Loss@kd 2.2353 (2.2449)	Acc@1 56.250 (58.850)	Acc@5 98.438 (97.449)
 * Acc@1 58.689 Acc@5 97.425
epoch 17, total time 338.75
Test: [0/750]	Time 0.788 (0.788)	Loss 0.7364 (0.7364)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/750]	Time 0.111 (0.114)	Loss 0.4166 (0.5767)	Acc@1 93.750 (82.240)	Acc@5 100.000 (88.428)
Test: [200/750]	Time 0.107 (0.109)	Loss 2.0297 (0.6196)	Acc@1 31.250 (78.949)	Acc@5 78.125 (91.651)
Test: [300/750]	Time 0.098 (0.108)	Loss 1.5369 (0.9774)	Acc@1 31.250 (63.092)	Acc@5 90.625 (88.891)
Test: [400/750]	Time 0.106 (0.107)	Loss 0.7972 (1.0857)	Acc@1 78.125 (56.905)	Acc@5 90.625 (88.934)
Test: [500/750]	Time 0.108 (0.106)	Loss 0.9496 (1.0449)	Acc@1 71.875 (60.186)	Acc@5 87.500 (88.772)
Test: [600/750]	Time 0.195 (0.106)	Loss 0.9860 (1.0448)	Acc@1 59.375 (60.743)	Acc@5 93.750 (89.148)
Test: [700/750]	Time 0.102 (0.106)	Loss 1.5568 (1.0569)	Acc@1 43.750 (60.017)	Acc@5 71.875 (89.225)
 * Acc@1 59.754 Acc@5 88.688
saving the best model!
==> training...
Epoch: [18][0/875]	Time 1.540 (1.540)	Data 1.091 (1.091)	Loss 2.8086 (2.8086)	Loss@kd 2.5211 (2.5211)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)
Epoch: [18][100/875]	Time 0.345 (0.402)	Data 0.007 (0.018)	Loss 2.6927 (2.6526)	Loss@kd 2.2854 (2.2367)	Acc@1 62.500 (58.478)	Acc@5 96.875 (97.571)
Epoch: [18][200/875]	Time 0.416 (0.394)	Data 0.007 (0.012)	Loss 2.5741 (2.6597)	Loss@kd 2.2185 (2.2366)	Acc@1 68.750 (58.753)	Acc@5 98.438 (97.590)
Epoch: [18][300/875]	Time 0.375 (0.393)	Data 0.007 (0.011)	Loss 2.4858 (2.6538)	Loss@kd 2.2727 (2.2346)	Acc@1 64.062 (58.866)	Acc@5 100.000 (97.524)
Epoch: [18][400/875]	Time 0.394 (0.393)	Data 0.007 (0.010)	Loss 2.5942 (2.6549)	Loss@kd 2.1896 (2.2330)	Acc@1 56.250 (58.600)	Acc@5 98.438 (97.498)
Epoch: [18][500/875]	Time 0.360 (0.393)	Data 0.008 (0.009)	Loss 2.6589 (2.6554)	Loss@kd 2.1287 (2.2324)	Acc@1 59.375 (58.527)	Acc@5 98.438 (97.464)
Epoch: [18][600/875]	Time 0.404 (0.393)	Data 0.007 (0.009)	Loss 2.8732 (2.6545)	Loss@kd 2.1981 (2.2312)	Acc@1 54.688 (58.642)	Acc@5 96.875 (97.452)
Epoch: [18][700/875]	Time 0.338 (0.393)	Data 0.006 (0.009)	Loss 2.4498 (2.6513)	Loss@kd 2.2185 (2.2288)	Acc@1 68.750 (58.717)	Acc@5 98.438 (97.501)
Epoch: [18][800/875]	Time 0.373 (0.390)	Data 0.008 (0.008)	Loss 2.9052 (2.6523)	Loss@kd 2.1289 (2.2304)	Acc@1 45.312 (58.741)	Acc@5 96.875 (97.507)
 * Acc@1 58.827 Acc@5 97.480
epoch 18, total time 339.96
Test: [0/750]	Time 0.821 (0.821)	Loss 0.7168 (0.7168)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.082 (0.116)	Loss 0.6778 (0.6534)	Acc@1 65.625 (79.672)	Acc@5 100.000 (88.274)
Test: [200/750]	Time 0.098 (0.108)	Loss 1.6919 (0.7218)	Acc@1 43.750 (74.238)	Acc@5 87.500 (91.682)
Test: [300/750]	Time 0.108 (0.108)	Loss 1.4858 (1.0023)	Acc@1 25.000 (61.836)	Acc@5 96.875 (90.334)
Test: [400/750]	Time 0.101 (0.105)	Loss 1.1748 (1.1255)	Acc@1 53.125 (54.512)	Acc@5 87.500 (89.978)
Test: [500/750]	Time 0.173 (0.105)	Loss 0.9869 (1.1259)	Acc@1 65.625 (56.025)	Acc@5 87.500 (88.573)
Test: [600/750]	Time 0.102 (0.104)	Loss 0.7371 (1.1017)	Acc@1 78.125 (58.002)	Acc@5 96.875 (88.701)
Test: [700/750]	Time 0.076 (0.105)	Loss 1.4085 (1.0735)	Acc@1 53.125 (59.437)	Acc@5 75.000 (89.172)
 * Acc@1 59.721 Acc@5 88.942
==> training...
Epoch: [19][0/875]	Time 1.626 (1.626)	Data 1.193 (1.193)	Loss 2.3227 (2.3227)	Loss@kd 2.1712 (2.1712)	Acc@1 73.438 (73.438)	Acc@5 96.875 (96.875)
Epoch: [19][100/875]	Time 0.374 (0.401)	Data 0.006 (0.019)	Loss 2.3773 (2.6376)	Loss@kd 2.2350 (2.2227)	Acc@1 67.188 (59.158)	Acc@5 100.000 (97.679)
Epoch: [19][200/875]	Time 0.354 (0.395)	Data 0.007 (0.013)	Loss 2.3889 (2.6308)	Loss@kd 2.1685 (2.2198)	Acc@1 68.750 (59.492)	Acc@5 98.438 (97.676)
Epoch: [19][300/875]	Time 0.393 (0.394)	Data 0.007 (0.011)	Loss 2.6279 (2.6321)	Loss@kd 2.3400 (2.2196)	Acc@1 64.062 (59.474)	Acc@5 96.875 (97.659)
Epoch: [19][400/875]	Time 0.370 (0.393)	Data 0.010 (0.010)	Loss 2.6333 (2.6343)	Loss@kd 2.2270 (2.2222)	Acc@1 67.188 (59.500)	Acc@5 95.312 (97.627)
Epoch: [19][500/875]	Time 0.374 (0.392)	Data 0.007 (0.009)	Loss 2.5788 (2.6337)	Loss@kd 2.1346 (2.2208)	Acc@1 57.812 (59.543)	Acc@5 98.438 (97.536)
Epoch: [19][600/875]	Time 0.390 (0.392)	Data 0.009 (0.009)	Loss 2.3893 (2.6350)	Loss@kd 2.1903 (2.2217)	Acc@1 65.625 (59.541)	Acc@5 100.000 (97.525)
Epoch: [19][700/875]	Time 0.401 (0.392)	Data 0.007 (0.009)	Loss 2.4992 (2.6348)	Loss@kd 2.2124 (2.2191)	Acc@1 68.750 (59.433)	Acc@5 96.875 (97.490)
Epoch: [19][800/875]	Time 0.391 (0.393)	Data 0.007 (0.009)	Loss 2.5402 (2.6342)	Loss@kd 2.1704 (2.2185)	Acc@1 62.500 (59.467)	Acc@5 96.875 (97.462)
 * Acc@1 59.414 Acc@5 97.459
epoch 19, total time 343.55
Test: [0/750]	Time 0.801 (0.801)	Loss 0.6620 (0.6620)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.094 (0.113)	Loss 0.4028 (0.5699)	Acc@1 87.500 (82.271)	Acc@5 100.000 (89.047)
Test: [200/750]	Time 0.107 (0.107)	Loss 1.6846 (0.5727)	Acc@1 43.750 (80.100)	Acc@5 81.250 (92.802)
Test: [300/750]	Time 0.098 (0.107)	Loss 1.4890 (0.8724)	Acc@1 28.125 (67.172)	Acc@5 84.375 (91.373)
Test: [400/750]	Time 0.120 (0.106)	Loss 0.9942 (1.0066)	Acc@1 68.750 (59.539)	Acc@5 87.500 (90.415)
Test: [500/750]	Time 0.154 (0.106)	Loss 0.9311 (1.0155)	Acc@1 71.875 (60.872)	Acc@5 87.500 (88.891)
Test: [600/750]	Time 0.113 (0.106)	Loss 0.8772 (1.0205)	Acc@1 71.875 (61.439)	Acc@5 93.750 (89.216)
Test: [700/750]	Time 0.117 (0.106)	Loss 1.5414 (1.0299)	Acc@1 37.500 (60.886)	Acc@5 75.000 (89.604)
 * Acc@1 60.521 Acc@5 89.442
saving the best model!
==> training...
Epoch: [20][0/875]	Time 1.716 (1.716)	Data 1.251 (1.251)	Loss 2.7521 (2.7521)	Loss@kd 2.3006 (2.3006)	Acc@1 54.688 (54.688)	Acc@5 95.312 (95.312)
Epoch: [20][100/875]	Time 0.360 (0.394)	Data 0.008 (0.019)	Loss 2.6525 (2.6296)	Loss@kd 2.2462 (2.2138)	Acc@1 54.688 (59.236)	Acc@5 98.438 (97.494)
Epoch: [20][200/875]	Time 0.358 (0.383)	Data 0.007 (0.013)	Loss 2.5480 (2.6297)	Loss@kd 2.1695 (2.2132)	Acc@1 57.812 (59.142)	Acc@5 100.000 (97.318)
Epoch: [20][300/875]	Time 0.344 (0.379)	Data 0.005 (0.011)	Loss 2.5400 (2.6185)	Loss@kd 2.2312 (2.2114)	Acc@1 67.188 (59.588)	Acc@5 98.438 (97.404)
Epoch: [20][400/875]	Time 0.400 (0.379)	Data 0.007 (0.010)	Loss 2.4920 (2.6140)	Loss@kd 2.1492 (2.2078)	Acc@1 64.062 (59.671)	Acc@5 100.000 (97.483)
Epoch: [20][500/875]	Time 0.400 (0.379)	Data 0.007 (0.009)	Loss 2.8459 (2.6133)	Loss@kd 2.2733 (2.2038)	Acc@1 51.562 (59.509)	Acc@5 98.438 (97.493)
Epoch: [20][600/875]	Time 0.375 (0.380)	Data 0.007 (0.009)	Loss 2.5989 (2.6113)	Loss@kd 2.1830 (2.2024)	Acc@1 59.375 (59.630)	Acc@5 95.312 (97.502)
Epoch: [20][700/875]	Time 0.342 (0.381)	Data 0.007 (0.009)	Loss 2.7829 (2.6124)	Loss@kd 2.2228 (2.2030)	Acc@1 51.562 (59.451)	Acc@5 98.438 (97.504)
Epoch: [20][800/875]	Time 0.423 (0.381)	Data 0.008 (0.008)	Loss 2.8998 (2.6141)	Loss@kd 2.5514 (2.2023)	Acc@1 60.938 (59.486)	Acc@5 98.438 (97.458)
 * Acc@1 59.470 Acc@5 97.427
epoch 20, total time 334.08
Test: [0/750]	Time 0.841 (0.841)	Loss 0.7228 (0.7228)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.093 (0.112)	Loss 0.5756 (0.6445)	Acc@1 78.125 (80.074)	Acc@5 96.875 (88.459)
Test: [200/750]	Time 0.092 (0.105)	Loss 1.8064 (0.6639)	Acc@1 25.000 (76.726)	Acc@5 84.375 (92.102)
Test: [300/750]	Time 0.097 (0.105)	Loss 1.4427 (0.9612)	Acc@1 37.500 (62.832)	Acc@5 90.625 (90.625)
Test: [400/750]	Time 0.107 (0.103)	Loss 0.8093 (1.0540)	Acc@1 81.250 (57.754)	Acc@5 90.625 (90.493)
Test: [500/750]	Time 0.159 (0.103)	Loss 0.8001 (1.0349)	Acc@1 78.125 (60.242)	Acc@5 93.750 (89.621)
Test: [600/750]	Time 0.105 (0.103)	Loss 0.9284 (1.0224)	Acc@1 62.500 (61.756)	Acc@5 90.625 (89.673)
Test: [700/750]	Time 0.093 (0.103)	Loss 1.3336 (1.0265)	Acc@1 50.000 (61.408)	Acc@5 78.125 (89.938)
 * Acc@1 61.250 Acc@5 89.862
saving the best model!
==> training...
Epoch: [21][0/875]	Time 1.556 (1.556)	Data 1.113 (1.113)	Loss 2.6510 (2.6510)	Loss@kd 2.1966 (2.1966)	Acc@1 54.688 (54.688)	Acc@5 95.312 (95.312)
Epoch: [21][100/875]	Time 0.421 (0.401)	Data 0.008 (0.018)	Loss 2.6004 (2.6235)	Loss@kd 2.2915 (2.1906)	Acc@1 65.625 (59.267)	Acc@5 96.875 (97.308)
Epoch: [21][200/875]	Time 0.396 (0.395)	Data 0.007 (0.012)	Loss 2.8034 (2.6162)	Loss@kd 2.1505 (2.1941)	Acc@1 50.000 (59.600)	Acc@5 95.312 (97.474)
Epoch: [21][300/875]	Time 0.355 (0.393)	Data 0.007 (0.011)	Loss 2.4991 (2.6081)	Loss@kd 2.2121 (2.1922)	Acc@1 68.750 (59.738)	Acc@5 98.438 (97.560)
Epoch: [21][400/875]	Time 0.388 (0.391)	Data 0.007 (0.010)	Loss 2.3744 (2.6000)	Loss@kd 2.2192 (2.1905)	Acc@1 75.000 (60.049)	Acc@5 98.438 (97.565)
Epoch: [21][500/875]	Time 0.380 (0.389)	Data 0.007 (0.009)	Loss 2.6873 (2.5992)	Loss@kd 2.1686 (2.1900)	Acc@1 59.375 (60.055)	Acc@5 98.438 (97.539)
Epoch: [21][600/875]	Time 0.363 (0.388)	Data 0.007 (0.009)	Loss 2.3811 (2.6000)	Loss@kd 2.1362 (2.1924)	Acc@1 67.188 (59.983)	Acc@5 96.875 (97.564)
Epoch: [21][700/875]	Time 0.365 (0.385)	Data 0.007 (0.008)	Loss 2.5561 (2.5991)	Loss@kd 2.1682 (2.1909)	Acc@1 57.812 (59.930)	Acc@5 95.312 (97.582)
Epoch: [21][800/875]	Time 0.365 (0.383)	Data 0.007 (0.008)	Loss 2.6824 (2.5985)	Loss@kd 2.3480 (2.1919)	Acc@1 53.125 (60.011)	Acc@5 98.438 (97.573)
 * Acc@1 60.029 Acc@5 97.593
epoch 21, total time 334.52
Test: [0/750]	Time 0.867 (0.867)	Loss 0.6833 (0.6833)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.105 (0.117)	Loss 0.6525 (0.5695)	Acc@1 68.750 (81.838)	Acc@5 96.875 (89.325)
Test: [200/750]	Time 0.102 (0.111)	Loss 1.8151 (0.6641)	Acc@1 21.875 (75.793)	Acc@5 84.375 (91.962)
Test: [300/750]	Time 0.118 (0.110)	Loss 1.2507 (0.9630)	Acc@1 53.125 (61.109)	Acc@5 100.000 (90.345)
Test: [400/750]	Time 0.091 (0.108)	Loss 0.8016 (1.0203)	Acc@1 71.875 (58.245)	Acc@5 93.750 (91.295)
Test: [500/750]	Time 0.148 (0.108)	Loss 1.0580 (1.0059)	Acc@1 75.000 (60.385)	Acc@5 84.375 (90.195)
Test: [600/750]	Time 0.093 (0.107)	Loss 0.9314 (1.0235)	Acc@1 71.875 (60.997)	Acc@5 93.750 (89.554)
Test: [700/750]	Time 0.111 (0.107)	Loss 1.3125 (1.0133)	Acc@1 53.125 (61.470)	Acc@5 81.250 (89.988)
 * Acc@1 61.521 Acc@5 89.996
saving the best model!
==> training...
Epoch: [22][0/875]	Time 1.671 (1.671)	Data 1.151 (1.151)	Loss 2.4406 (2.4406)	Loss@kd 2.1337 (2.1337)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [22][100/875]	Time 0.394 (0.401)	Data 0.007 (0.018)	Loss 2.5469 (2.5984)	Loss@kd 2.0663 (2.1838)	Acc@1 62.500 (59.700)	Acc@5 96.875 (97.633)
Epoch: [22][200/875]	Time 0.365 (0.394)	Data 0.007 (0.012)	Loss 2.3836 (2.5839)	Loss@kd 2.1686 (2.1786)	Acc@1 71.875 (60.160)	Acc@5 96.875 (97.707)
Epoch: [22][300/875]	Time 0.380 (0.390)	Data 0.007 (0.010)	Loss 2.5996 (2.5775)	Loss@kd 2.1802 (2.1780)	Acc@1 54.688 (60.169)	Acc@5 96.875 (97.628)
Epoch: [22][400/875]	Time 0.381 (0.393)	Data 0.008 (0.010)	Loss 2.6445 (2.5790)	Loss@kd 2.2233 (2.1786)	Acc@1 59.375 (60.298)	Acc@5 96.875 (97.670)
Epoch: [22][500/875]	Time 0.391 (0.392)	Data 0.007 (0.009)	Loss 2.7440 (2.5804)	Loss@kd 2.1496 (2.1798)	Acc@1 57.812 (60.258)	Acc@5 100.000 (97.630)
Epoch: [22][600/875]	Time 0.377 (0.392)	Data 0.006 (0.009)	Loss 2.6705 (2.5815)	Loss@kd 2.1717 (2.1808)	Acc@1 59.375 (60.267)	Acc@5 98.438 (97.650)
Epoch: [22][700/875]	Time 0.376 (0.391)	Data 0.007 (0.008)	Loss 2.5485 (2.5817)	Loss@kd 2.1503 (2.1805)	Acc@1 56.250 (60.282)	Acc@5 100.000 (97.608)
Epoch: [22][800/875]	Time 0.449 (0.392)	Data 0.008 (0.008)	Loss 2.3682 (2.5839)	Loss@kd 2.1290 (2.1802)	Acc@1 59.375 (60.204)	Acc@5 98.438 (97.616)
 * Acc@1 60.170 Acc@5 97.637
epoch 22, total time 343.54
Test: [0/750]	Time 0.875 (0.875)	Loss 0.6474 (0.6474)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.106 (0.116)	Loss 0.6754 (0.5832)	Acc@1 68.750 (82.209)	Acc@5 100.000 (88.830)
Test: [200/750]	Time 0.099 (0.112)	Loss 1.8106 (0.6501)	Acc@1 40.625 (76.664)	Acc@5 78.125 (92.040)
Test: [300/750]	Time 0.100 (0.111)	Loss 1.5593 (0.9358)	Acc@1 25.000 (64.410)	Acc@5 96.875 (90.729)
Test: [400/750]	Time 0.112 (0.110)	Loss 1.0602 (1.0632)	Acc@1 62.500 (56.507)	Acc@5 87.500 (90.485)
Test: [500/750]	Time 0.175 (0.110)	Loss 1.2300 (1.0827)	Acc@1 53.125 (57.391)	Acc@5 81.250 (88.841)
Test: [600/750]	Time 0.071 (0.109)	Loss 0.7765 (1.0977)	Acc@1 68.750 (57.753)	Acc@5 96.875 (88.514)
Test: [700/750]	Time 0.105 (0.109)	Loss 1.2597 (1.0700)	Acc@1 56.250 (59.183)	Acc@5 84.375 (89.141)
 * Acc@1 59.688 Acc@5 89.121
==> training...
Epoch: [23][0/875]	Time 1.618 (1.618)	Data 1.197 (1.197)	Loss 2.2179 (2.2179)	Loss@kd 2.0549 (2.0549)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [23][100/875]	Time 0.334 (0.381)	Data 0.007 (0.019)	Loss 2.4827 (2.5630)	Loss@kd 2.1321 (2.1768)	Acc@1 64.062 (60.814)	Acc@5 98.438 (97.803)
Epoch: [23][200/875]	Time 0.372 (0.374)	Data 0.007 (0.013)	Loss 2.5304 (2.5609)	Loss@kd 2.1681 (2.1662)	Acc@1 65.625 (60.510)	Acc@5 96.875 (97.613)
Epoch: [23][300/875]	Time 0.352 (0.375)	Data 0.007 (0.011)	Loss 2.6900 (2.5686)	Loss@kd 2.1897 (2.1616)	Acc@1 53.125 (60.107)	Acc@5 95.312 (97.597)
Epoch: [23][400/875]	Time 0.385 (0.378)	Data 0.005 (0.010)	Loss 2.5540 (2.5704)	Loss@kd 2.1392 (2.1682)	Acc@1 59.375 (60.497)	Acc@5 98.438 (97.572)
Epoch: [23][500/875]	Time 0.372 (0.381)	Data 0.008 (0.009)	Loss 2.6248 (2.5664)	Loss@kd 2.2621 (2.1677)	Acc@1 59.375 (60.563)	Acc@5 100.000 (97.552)
Epoch: [23][600/875]	Time 0.364 (0.383)	Data 0.007 (0.009)	Loss 2.4823 (2.5683)	Loss@kd 2.1528 (2.1683)	Acc@1 62.500 (60.524)	Acc@5 93.750 (97.559)
Epoch: [23][700/875]	Time 0.346 (0.384)	Data 0.007 (0.009)	Loss 2.6125 (2.5683)	Loss@kd 2.2029 (2.1695)	Acc@1 54.688 (60.527)	Acc@5 98.438 (97.586)
Epoch: [23][800/875]	Time 0.379 (0.385)	Data 0.007 (0.008)	Loss 2.8545 (2.5689)	Loss@kd 2.1811 (2.1686)	Acc@1 43.750 (60.403)	Acc@5 93.750 (97.585)
 * Acc@1 60.443 Acc@5 97.598
epoch 23, total time 337.37
Test: [0/750]	Time 0.836 (0.836)	Loss 0.6832 (0.6832)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.098 (0.114)	Loss 0.6116 (0.6127)	Acc@1 75.000 (80.817)	Acc@5 100.000 (89.697)
Test: [200/750]	Time 0.084 (0.107)	Loss 1.7484 (0.6942)	Acc@1 34.375 (75.389)	Acc@5 84.375 (92.351)
Test: [300/750]	Time 0.102 (0.106)	Loss 1.2618 (0.9666)	Acc@1 53.125 (62.905)	Acc@5 100.000 (91.040)
Test: [400/750]	Time 0.108 (0.105)	Loss 0.8866 (1.0325)	Acc@1 75.000 (58.650)	Acc@5 84.375 (91.607)
Test: [500/750]	Time 0.116 (0.105)	Loss 0.9940 (1.0129)	Acc@1 65.625 (60.753)	Acc@5 84.375 (90.669)
Test: [600/750]	Time 0.111 (0.104)	Loss 0.9152 (1.0164)	Acc@1 65.625 (61.590)	Acc@5 87.500 (90.240)
Test: [700/750]	Time 0.093 (0.104)	Loss 1.2908 (1.0042)	Acc@1 50.000 (62.041)	Acc@5 84.375 (90.540)
 * Acc@1 62.129 Acc@5 90.550
saving the best model!
==> training...
Epoch: [24][0/875]	Time 1.647 (1.647)	Data 1.275 (1.275)	Loss 2.4566 (2.4566)	Loss@kd 2.0808 (2.0808)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [24][100/875]	Time 0.376 (0.401)	Data 0.006 (0.019)	Loss 2.6176 (2.5387)	Loss@kd 2.2044 (2.1533)	Acc@1 51.562 (60.984)	Acc@5 100.000 (97.973)
Epoch: [24][200/875]	Time 0.461 (0.396)	Data 0.007 (0.013)	Loss 2.3679 (2.5394)	Loss@kd 2.1238 (2.1533)	Acc@1 67.188 (61.054)	Acc@5 98.438 (97.909)
Epoch: [24][300/875]	Time 0.433 (0.394)	Data 0.007 (0.011)	Loss 2.7149 (2.5527)	Loss@kd 2.1793 (2.1581)	Acc@1 54.688 (60.668)	Acc@5 98.438 (97.809)
Epoch: [24][400/875]	Time 0.368 (0.392)	Data 0.007 (0.010)	Loss 2.7883 (2.5537)	Loss@kd 2.2122 (2.1586)	Acc@1 56.250 (60.782)	Acc@5 100.000 (97.748)
Epoch: [24][500/875]	Time 0.361 (0.389)	Data 0.007 (0.010)	Loss 2.5209 (2.5513)	Loss@kd 2.1973 (2.1563)	Acc@1 62.500 (60.841)	Acc@5 96.875 (97.692)
Epoch: [24][600/875]	Time 0.373 (0.385)	Data 0.007 (0.009)	Loss 2.7297 (2.5514)	Loss@kd 2.4370 (2.1575)	Acc@1 64.062 (60.901)	Acc@5 98.438 (97.684)
Epoch: [24][700/875]	Time 0.373 (0.384)	Data 0.007 (0.009)	Loss 2.7204 (2.5535)	Loss@kd 2.1095 (2.1572)	Acc@1 50.000 (60.859)	Acc@5 100.000 (97.693)
Epoch: [24][800/875]	Time 0.398 (0.383)	Data 0.007 (0.009)	Loss 2.3526 (2.5524)	Loss@kd 2.0659 (2.1570)	Acc@1 59.375 (60.861)	Acc@5 100.000 (97.702)
 * Acc@1 60.907 Acc@5 97.700
epoch 24, total time 335.95
Test: [0/750]	Time 0.693 (0.693)	Loss 0.6613 (0.6613)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.104 (0.111)	Loss 0.6438 (0.5392)	Acc@1 71.875 (82.580)	Acc@5 100.000 (90.625)
Test: [200/750]	Time 0.109 (0.106)	Loss 1.7775 (0.6726)	Acc@1 28.125 (74.891)	Acc@5 81.250 (92.304)
Test: [300/750]	Time 0.094 (0.105)	Loss 1.5000 (0.9794)	Acc@1 28.125 (61.316)	Acc@5 87.500 (90.293)
Test: [400/750]	Time 0.100 (0.104)	Loss 0.6906 (1.0881)	Acc@1 81.250 (55.440)	Acc@5 93.750 (90.282)
Test: [500/750]	Time 0.104 (0.104)	Loss 0.9083 (1.0419)	Acc@1 68.750 (58.926)	Acc@5 93.750 (89.833)
Test: [600/750]	Time 0.071 (0.103)	Loss 0.8571 (1.0368)	Acc@1 68.750 (60.269)	Acc@5 90.625 (89.653)
Test: [700/750]	Time 0.090 (0.103)	Loss 1.1786 (1.0132)	Acc@1 59.375 (61.604)	Acc@5 81.250 (90.188)
 * Acc@1 62.000 Acc@5 90.258
==> training...
Epoch: [25][0/875]	Time 1.576 (1.576)	Data 1.108 (1.108)	Loss 2.6201 (2.6201)	Loss@kd 2.1712 (2.1712)	Acc@1 60.938 (60.938)	Acc@5 96.875 (96.875)
Epoch: [25][100/875]	Time 0.374 (0.394)	Data 0.007 (0.018)	Loss 2.2887 (2.5632)	Loss@kd 2.0982 (2.1632)	Acc@1 71.875 (60.551)	Acc@5 100.000 (97.819)
Epoch: [25][200/875]	Time 0.366 (0.388)	Data 0.007 (0.012)	Loss 2.4887 (2.5582)	Loss@kd 2.1042 (2.1549)	Acc@1 62.500 (60.533)	Acc@5 98.438 (97.637)
Epoch: [25][300/875]	Time 0.389 (0.388)	Data 0.007 (0.011)	Loss 2.5485 (2.5564)	Loss@kd 2.1434 (2.1548)	Acc@1 56.250 (60.730)	Acc@5 100.000 (97.659)
Epoch: [25][400/875]	Time 0.372 (0.387)	Data 0.007 (0.010)	Loss 2.5446 (2.5464)	Loss@kd 2.1333 (2.1538)	Acc@1 64.062 (61.121)	Acc@5 95.312 (97.795)
Epoch: [25][500/875]	Time 0.397 (0.387)	Data 0.007 (0.009)	Loss 2.4299 (2.5460)	Loss@kd 2.2192 (2.1497)	Acc@1 70.312 (61.015)	Acc@5 95.312 (97.733)
Epoch: [25][600/875]	Time 0.358 (0.388)	Data 0.010 (0.009)	Loss 2.4497 (2.5396)	Loss@kd 2.0964 (2.1477)	Acc@1 62.500 (61.307)	Acc@5 98.438 (97.741)
Epoch: [25][700/875]	Time 0.376 (0.388)	Data 0.008 (0.009)	Loss 2.6632 (2.5356)	Loss@kd 2.0830 (2.1449)	Acc@1 53.125 (61.339)	Acc@5 98.438 (97.780)
Epoch: [25][800/875]	Time 0.370 (0.388)	Data 0.005 (0.008)	Loss 2.4204 (2.5356)	Loss@kd 2.2206 (2.1447)	Acc@1 62.500 (61.316)	Acc@5 100.000 (97.784)
 * Acc@1 61.259 Acc@5 97.784
epoch 25, total time 340.36
Test: [0/750]	Time 0.888 (0.888)	Loss 0.5484 (0.5484)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.101 (0.114)	Loss 0.5562 (0.5092)	Acc@1 78.125 (83.478)	Acc@5 100.000 (90.780)
Test: [200/750]	Time 0.108 (0.109)	Loss 1.6654 (0.6216)	Acc@1 43.750 (77.394)	Acc@5 81.250 (92.910)
Test: [300/750]	Time 0.112 (0.107)	Loss 1.5829 (0.9206)	Acc@1 34.375 (64.877)	Acc@5 87.500 (91.040)
Test: [400/750]	Time 0.110 (0.106)	Loss 0.6933 (1.0381)	Acc@1 84.375 (58.713)	Acc@5 93.750 (90.142)
Test: [500/750]	Time 0.189 (0.106)	Loss 0.7259 (0.9910)	Acc@1 81.250 (62.076)	Acc@5 93.750 (90.114)
Test: [600/750]	Time 0.092 (0.106)	Loss 0.8404 (0.9842)	Acc@1 75.000 (63.218)	Acc@5 90.625 (90.323)
Test: [700/750]	Time 0.113 (0.106)	Loss 1.4771 (0.9887)	Acc@1 50.000 (63.218)	Acc@5 81.250 (90.540)
 * Acc@1 62.763 Acc@5 90.312
saving the best model!
==> training...
Epoch: [26][0/875]	Time 1.676 (1.676)	Data 1.256 (1.256)	Loss 2.6801 (2.6801)	Loss@kd 2.2116 (2.2116)	Acc@1 59.375 (59.375)	Acc@5 96.875 (96.875)
Epoch: [26][100/875]	Time 0.374 (0.385)	Data 0.007 (0.019)	Loss 2.5350 (2.5319)	Loss@kd 2.1404 (2.1300)	Acc@1 54.688 (60.984)	Acc@5 98.438 (97.602)
Epoch: [26][200/875]	Time 0.399 (0.384)	Data 0.007 (0.013)	Loss 2.2679 (2.5132)	Loss@kd 2.1039 (2.1310)	Acc@1 71.875 (61.373)	Acc@5 100.000 (97.940)
Epoch: [26][300/875]	Time 0.390 (0.385)	Data 0.006 (0.011)	Loss 2.5662 (2.5193)	Loss@kd 2.0625 (2.1305)	Acc@1 53.125 (61.353)	Acc@5 98.438 (97.778)
Epoch: [26][400/875]	Time 0.410 (0.386)	Data 0.007 (0.010)	Loss 2.3348 (2.5208)	Loss@kd 2.1121 (2.1332)	Acc@1 67.188 (61.401)	Acc@5 100.000 (97.810)
Epoch: [26][500/875]	Time 0.377 (0.387)	Data 0.007 (0.009)	Loss 2.4079 (2.5244)	Loss@kd 2.1403 (2.1324)	Acc@1 65.625 (61.168)	Acc@5 98.438 (97.823)
Epoch: [26][600/875]	Time 0.359 (0.387)	Data 0.007 (0.009)	Loss 2.7207 (2.5258)	Loss@kd 2.1261 (2.1349)	Acc@1 57.812 (61.127)	Acc@5 96.875 (97.806)
Epoch: [26][700/875]	Time 0.344 (0.388)	Data 0.006 (0.009)	Loss 2.5888 (2.5254)	Loss@kd 2.1135 (2.1358)	Acc@1 62.500 (61.254)	Acc@5 95.312 (97.822)
Epoch: [26][800/875]	Time 0.361 (0.388)	Data 0.007 (0.009)	Loss 2.4276 (2.5248)	Loss@kd 2.1300 (2.1353)	Acc@1 60.938 (61.316)	Acc@5 100.000 (97.804)
 * Acc@1 61.396 Acc@5 97.761
epoch 26, total time 339.75
Test: [0/750]	Time 0.771 (0.771)	Loss 0.5750 (0.5750)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.104 (0.113)	Loss 0.4985 (0.4847)	Acc@1 78.125 (82.859)	Acc@5 100.000 (91.584)
Test: [200/750]	Time 0.105 (0.106)	Loss 1.5359 (0.5678)	Acc@1 34.375 (79.431)	Acc@5 96.875 (93.999)
Test: [300/750]	Time 0.102 (0.105)	Loss 1.5923 (0.8638)	Acc@1 25.000 (67.172)	Acc@5 87.500 (92.307)
Test: [400/750]	Time 0.098 (0.104)	Loss 0.7829 (1.0113)	Acc@1 78.125 (59.539)	Acc@5 90.625 (90.360)
Test: [500/750]	Time 0.136 (0.104)	Loss 0.6521 (0.9721)	Acc@1 87.500 (62.488)	Acc@5 96.875 (90.182)
Test: [600/750]	Time 0.095 (0.103)	Loss 1.1917 (0.9648)	Acc@1 50.000 (63.784)	Acc@5 81.250 (90.386)
Test: [700/750]	Time 0.085 (0.103)	Loss 1.2921 (0.9838)	Acc@1 59.375 (63.338)	Acc@5 87.500 (90.594)
 * Acc@1 63.429 Acc@5 90.579
saving the best model!
==> training...
Epoch: [27][0/875]	Time 1.719 (1.719)	Data 1.239 (1.239)	Loss 2.5151 (2.5151)	Loss@kd 2.1711 (2.1711)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [27][100/875]	Time 0.418 (0.400)	Data 0.007 (0.019)	Loss 2.5514 (2.5539)	Loss@kd 2.1115 (2.1351)	Acc@1 57.812 (59.638)	Acc@5 93.750 (97.602)
Epoch: [27][200/875]	Time 0.386 (0.394)	Data 0.007 (0.013)	Loss 2.4988 (2.5249)	Loss@kd 2.1490 (2.1301)	Acc@1 60.938 (60.953)	Acc@5 100.000 (97.785)
Epoch: [27][300/875]	Time 0.376 (0.393)	Data 0.006 (0.011)	Loss 2.3759 (2.5203)	Loss@kd 2.1301 (2.1307)	Acc@1 67.188 (61.254)	Acc@5 100.000 (97.841)
Epoch: [27][400/875]	Time 0.356 (0.387)	Data 0.007 (0.010)	Loss 2.5885 (2.5130)	Loss@kd 2.1471 (2.1260)	Acc@1 56.250 (61.510)	Acc@5 98.438 (97.873)
Epoch: [27][500/875]	Time 0.352 (0.383)	Data 0.005 (0.009)	Loss 2.5451 (2.5126)	Loss@kd 2.0850 (2.1233)	Acc@1 64.062 (61.533)	Acc@5 96.875 (97.820)
Epoch: [27][600/875]	Time 0.395 (0.381)	Data 0.007 (0.009)	Loss 2.4261 (2.5126)	Loss@kd 2.0655 (2.1233)	Acc@1 62.500 (61.533)	Acc@5 96.875 (97.832)
Epoch: [27][700/875]	Time 0.374 (0.382)	Data 0.007 (0.009)	Loss 2.5693 (2.5130)	Loss@kd 2.1218 (2.1219)	Acc@1 60.938 (61.470)	Acc@5 95.312 (97.842)
Epoch: [27][800/875]	Time 0.358 (0.383)	Data 0.007 (0.009)	Loss 2.5671 (2.5123)	Loss@kd 2.1757 (2.1215)	Acc@1 59.375 (61.558)	Acc@5 96.875 (97.835)
 * Acc@1 61.607 Acc@5 97.811
epoch 27, total time 335.62
Test: [0/750]	Time 0.927 (0.927)	Loss 0.7048 (0.7048)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.109 (0.116)	Loss 0.6643 (0.6423)	Acc@1 68.750 (80.879)	Acc@5 100.000 (89.016)
Test: [200/750]	Time 0.107 (0.110)	Loss 1.6516 (0.7317)	Acc@1 31.250 (74.067)	Acc@5 90.625 (91.822)
Test: [300/750]	Time 0.096 (0.110)	Loss 1.2329 (0.9753)	Acc@1 53.125 (61.534)	Acc@5 96.875 (91.165)
Test: [400/750]	Time 0.089 (0.107)	Loss 1.0453 (1.0523)	Acc@1 71.875 (57.567)	Acc@5 90.625 (91.272)
Test: [500/750]	Time 0.094 (0.107)	Loss 1.2523 (1.0666)	Acc@1 59.375 (58.533)	Acc@5 84.375 (89.552)
Test: [600/750]	Time 0.103 (0.106)	Loss 0.7072 (1.0771)	Acc@1 65.625 (59.235)	Acc@5 90.625 (88.753)
Test: [700/750]	Time 0.085 (0.106)	Loss 1.0099 (1.0465)	Acc@1 56.250 (60.547)	Acc@5 96.875 (89.404)
 * Acc@1 60.825 Acc@5 89.604
==> training...
Epoch: [28][0/875]	Time 1.576 (1.576)	Data 1.137 (1.137)	Loss 2.4614 (2.4614)	Loss@kd 2.2253 (2.2253)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [28][100/875]	Time 0.378 (0.403)	Data 0.010 (0.018)	Loss 3.0091 (2.4869)	Loss@kd 2.0950 (2.1147)	Acc@1 45.312 (62.701)	Acc@5 93.750 (97.896)
Epoch: [28][200/875]	Time 0.376 (0.394)	Data 0.007 (0.013)	Loss 2.5697 (2.4958)	Loss@kd 2.1842 (2.1130)	Acc@1 57.812 (62.002)	Acc@5 96.875 (97.660)
Epoch: [28][300/875]	Time 0.480 (0.393)	Data 0.007 (0.011)	Loss 2.3514 (2.4819)	Loss@kd 2.1222 (2.1128)	Acc@1 70.312 (62.531)	Acc@5 98.438 (97.763)
Epoch: [28][400/875]	Time 0.417 (0.392)	Data 0.007 (0.010)	Loss 2.4235 (2.4937)	Loss@kd 2.0627 (2.1148)	Acc@1 68.750 (62.153)	Acc@5 96.875 (97.763)
Epoch: [28][500/875]	Time 0.376 (0.391)	Data 0.007 (0.009)	Loss 2.5197 (2.4965)	Loss@kd 2.1054 (2.1139)	Acc@1 53.125 (62.023)	Acc@5 98.438 (97.745)
Epoch: [28][600/875]	Time 0.363 (0.391)	Data 0.006 (0.009)	Loss 2.3703 (2.4937)	Loss@kd 2.0740 (2.1121)	Acc@1 65.625 (62.089)	Acc@5 98.438 (97.749)
Epoch: [28][700/875]	Time 0.375 (0.391)	Data 0.007 (0.009)	Loss 2.5860 (2.4939)	Loss@kd 2.1774 (2.1107)	Acc@1 62.500 (62.036)	Acc@5 96.875 (97.742)
Epoch: [28][800/875]	Time 0.358 (0.390)	Data 0.007 (0.008)	Loss 2.6129 (2.4967)	Loss@kd 2.2001 (2.1123)	Acc@1 57.812 (61.921)	Acc@5 98.438 (97.745)
 * Acc@1 61.834 Acc@5 97.762
epoch 28, total time 340.37
Test: [0/750]	Time 0.756 (0.756)	Loss 0.5720 (0.5720)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.106 (0.115)	Loss 0.5575 (0.4903)	Acc@1 78.125 (83.261)	Acc@5 100.000 (91.708)
Test: [200/750]	Time 0.104 (0.108)	Loss 1.5735 (0.6119)	Acc@1 43.750 (78.078)	Acc@5 84.375 (93.190)
Test: [300/750]	Time 0.105 (0.108)	Loss 1.5725 (0.9120)	Acc@1 25.000 (65.926)	Acc@5 93.750 (91.040)
Test: [400/750]	Time 0.109 (0.106)	Loss 0.7255 (1.0419)	Acc@1 81.250 (58.323)	Acc@5 87.500 (90.134)
Test: [500/750]	Time 0.090 (0.106)	Loss 0.6716 (1.0110)	Acc@1 87.500 (61.209)	Acc@5 93.750 (89.783)
Test: [600/750]	Time 0.094 (0.105)	Loss 0.9591 (0.9946)	Acc@1 59.375 (62.869)	Acc@5 93.750 (90.173)
Test: [700/750]	Time 0.077 (0.104)	Loss 1.3916 (1.0023)	Acc@1 56.250 (62.924)	Acc@5 84.375 (90.166)
 * Acc@1 62.875 Acc@5 89.887
==> training...
Epoch: [29][0/875]	Time 1.825 (1.825)	Data 1.309 (1.309)	Loss 2.6757 (2.6757)	Loss@kd 2.2008 (2.2008)	Acc@1 56.250 (56.250)	Acc@5 95.312 (95.312)
Epoch: [29][100/875]	Time 0.382 (0.406)	Data 0.007 (0.020)	Loss 2.5748 (2.4901)	Loss@kd 2.1052 (2.1109)	Acc@1 51.562 (60.968)	Acc@5 96.875 (98.082)
Epoch: [29][200/875]	Time 0.421 (0.399)	Data 0.007 (0.013)	Loss 2.5707 (2.4929)	Loss@kd 2.1128 (2.1075)	Acc@1 62.500 (61.217)	Acc@5 100.000 (97.893)
Epoch: [29][300/875]	Time 0.379 (0.395)	Data 0.007 (0.011)	Loss 2.3880 (2.4916)	Loss@kd 2.1203 (2.1057)	Acc@1 68.750 (61.410)	Acc@5 100.000 (97.773)
Epoch: [29][400/875]	Time 0.369 (0.394)	Data 0.007 (0.010)	Loss 2.2599 (2.4873)	Loss@kd 2.0596 (2.1044)	Acc@1 60.938 (61.666)	Acc@5 98.438 (97.884)
Epoch: [29][500/875]	Time 0.402 (0.394)	Data 0.010 (0.010)	Loss 2.5609 (2.4869)	Loss@kd 2.1230 (2.1013)	Acc@1 60.938 (61.611)	Acc@5 96.875 (97.914)
Epoch: [29][600/875]	Time 0.361 (0.393)	Data 0.007 (0.009)	Loss 2.4347 (2.4845)	Loss@kd 2.1318 (2.1016)	Acc@1 65.625 (61.842)	Acc@5 96.875 (97.912)
Epoch: [29][700/875]	Time 0.394 (0.392)	Data 0.007 (0.009)	Loss 2.4629 (2.4853)	Loss@kd 2.0420 (2.1016)	Acc@1 65.625 (61.885)	Acc@5 100.000 (97.871)
Epoch: [29][800/875]	Time 0.393 (0.391)	Data 0.007 (0.009)	Loss 2.4628 (2.4836)	Loss@kd 2.0559 (2.1005)	Acc@1 57.812 (61.938)	Acc@5 98.438 (97.829)
 * Acc@1 61.996 Acc@5 97.852
epoch 29, total time 342.68
Test: [0/750]	Time 0.811 (0.811)	Loss 0.7063 (0.7063)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.091 (0.111)	Loss 0.5082 (0.6038)	Acc@1 78.125 (81.405)	Acc@5 100.000 (89.171)
Test: [200/750]	Time 0.076 (0.107)	Loss 1.7667 (0.6177)	Acc@1 34.375 (78.172)	Acc@5 78.125 (92.693)
Test: [300/750]	Time 0.113 (0.107)	Loss 1.3861 (0.9311)	Acc@1 40.625 (64.826)	Acc@5 96.875 (90.812)
Test: [400/750]	Time 0.114 (0.105)	Loss 1.0218 (1.0294)	Acc@1 68.750 (59.406)	Acc@5 81.250 (91.178)
Test: [500/750]	Time 0.162 (0.105)	Loss 1.0784 (1.0408)	Acc@1 65.625 (60.323)	Acc@5 84.375 (89.608)
Test: [600/750]	Time 0.103 (0.104)	Loss 0.7300 (1.0382)	Acc@1 75.000 (60.982)	Acc@5 93.750 (89.471)
Test: [700/750]	Time 0.104 (0.104)	Loss 1.3173 (1.0106)	Acc@1 56.250 (62.099)	Acc@5 81.250 (90.072)
 * Acc@1 62.442 Acc@5 90.150
==> training...
Epoch: [30][0/875]	Time 1.524 (1.524)	Data 1.095 (1.095)	Loss 2.6725 (2.6725)	Loss@kd 2.1068 (2.1068)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [30][100/875]	Time 0.399 (0.399)	Data 0.007 (0.018)	Loss 2.6058 (2.4633)	Loss@kd 2.0556 (2.1012)	Acc@1 56.250 (62.655)	Acc@5 95.312 (97.989)
Epoch: [30][200/875]	Time 0.303 (0.393)	Data 0.005 (0.012)	Loss 2.2886 (2.4700)	Loss@kd 1.9823 (2.0945)	Acc@1 68.750 (62.345)	Acc@5 98.438 (97.963)
Epoch: [30][300/875]	Time 0.369 (0.384)	Data 0.007 (0.011)	Loss 2.3149 (2.4697)	Loss@kd 2.0460 (2.0962)	Acc@1 62.500 (62.469)	Acc@5 98.438 (97.960)
Epoch: [30][400/875]	Time 0.374 (0.380)	Data 0.007 (0.010)	Loss 2.3912 (2.4751)	Loss@kd 2.1313 (2.0943)	Acc@1 64.062 (62.083)	Acc@5 98.438 (97.970)
Epoch: [30][500/875]	Time 0.390 (0.378)	Data 0.007 (0.009)	Loss 2.6115 (2.4724)	Loss@kd 2.1352 (2.0933)	Acc@1 57.812 (62.076)	Acc@5 98.438 (97.976)
Epoch: [30][600/875]	Time 0.368 (0.379)	Data 0.006 (0.009)	Loss 2.6177 (2.4685)	Loss@kd 2.0818 (2.0910)	Acc@1 57.812 (62.287)	Acc@5 96.875 (97.923)
Epoch: [30][700/875]	Time 0.351 (0.379)	Data 0.007 (0.008)	Loss 2.6129 (2.4651)	Loss@kd 2.1299 (2.0884)	Acc@1 64.062 (62.409)	Acc@5 100.000 (97.896)
Epoch: [30][800/875]	Time 0.428 (0.380)	Data 0.007 (0.008)	Loss 2.6665 (2.4655)	Loss@kd 2.1299 (2.0876)	Acc@1 57.812 (62.389)	Acc@5 96.875 (97.901)
 * Acc@1 62.357 Acc@5 97.880
epoch 30, total time 333.30
Test: [0/750]	Time 0.696 (0.696)	Loss 0.7039 (0.7039)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.094 (0.113)	Loss 0.4324 (0.6257)	Acc@1 81.250 (80.198)	Acc@5 100.000 (90.594)
Test: [200/750]	Time 0.088 (0.108)	Loss 1.5510 (0.6040)	Acc@1 37.500 (80.193)	Acc@5 90.625 (93.657)
Test: [300/750]	Time 0.108 (0.107)	Loss 1.4827 (0.8911)	Acc@1 43.750 (67.753)	Acc@5 90.625 (91.881)
Test: [400/750]	Time 0.114 (0.106)	Loss 0.8813 (1.0050)	Acc@1 78.125 (61.853)	Acc@5 84.375 (90.508)
Test: [500/750]	Time 0.091 (0.106)	Loss 0.5858 (0.9836)	Acc@1 81.250 (63.510)	Acc@5 93.750 (89.845)
Test: [600/750]	Time 0.097 (0.105)	Loss 1.0545 (0.9697)	Acc@1 59.375 (64.486)	Acc@5 90.625 (90.261)
Test: [700/750]	Time 0.094 (0.105)	Loss 1.5483 (0.9981)	Acc@1 40.625 (62.830)	Acc@5 84.375 (90.308)
 * Acc@1 62.121 Acc@5 90.100
==> training...
Epoch: [31][0/875]	Time 1.518 (1.518)	Data 1.140 (1.140)	Loss 2.8115 (2.8115)	Loss@kd 2.0920 (2.0920)	Acc@1 43.750 (43.750)	Acc@5 93.750 (93.750)
Epoch: [31][100/875]	Time 0.402 (0.396)	Data 0.007 (0.018)	Loss 2.3410 (2.4608)	Loss@kd 1.9999 (2.0896)	Acc@1 62.500 (62.361)	Acc@5 98.438 (98.128)
Epoch: [31][200/875]	Time 0.388 (0.391)	Data 0.007 (0.013)	Loss 2.3133 (2.4636)	Loss@kd 2.1755 (2.0868)	Acc@1 75.000 (61.824)	Acc@5 98.438 (98.041)
Epoch: [31][300/875]	Time 0.402 (0.390)	Data 0.006 (0.011)	Loss 2.4459 (2.4647)	Loss@kd 2.0358 (2.0905)	Acc@1 62.500 (62.266)	Acc@5 98.438 (97.861)
Epoch: [31][400/875]	Time 0.373 (0.389)	Data 0.007 (0.010)	Loss 2.3192 (2.4597)	Loss@kd 2.0714 (2.0911)	Acc@1 68.750 (62.481)	Acc@5 100.000 (97.888)
Epoch: [31][500/875]	Time 0.397 (0.387)	Data 0.007 (0.009)	Loss 2.5716 (2.4587)	Loss@kd 2.0678 (2.0873)	Acc@1 54.688 (62.447)	Acc@5 100.000 (97.917)
Epoch: [31][600/875]	Time 0.376 (0.387)	Data 0.007 (0.009)	Loss 2.4678 (2.4579)	Loss@kd 2.0542 (2.0859)	Acc@1 59.375 (62.510)	Acc@5 95.312 (97.868)
Epoch: [31][700/875]	Time 0.358 (0.387)	Data 0.010 (0.009)	Loss 2.3410 (2.4564)	Loss@kd 2.0647 (2.0836)	Acc@1 70.312 (62.536)	Acc@5 100.000 (97.885)
Epoch: [31][800/875]	Time 0.339 (0.384)	Data 0.005 (0.008)	Loss 2.4635 (2.4534)	Loss@kd 2.0772 (2.0818)	Acc@1 60.938 (62.578)	Acc@5 96.875 (97.895)
 * Acc@1 62.607 Acc@5 97.889
epoch 31, total time 334.97
Test: [0/750]	Time 0.708 (0.708)	Loss 0.6637 (0.6637)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.112 (0.108)	Loss 0.7472 (0.6508)	Acc@1 59.375 (80.105)	Acc@5 100.000 (89.202)
Test: [200/750]	Time 0.086 (0.101)	Loss 1.5471 (0.7487)	Acc@1 31.250 (72.450)	Acc@5 90.625 (92.040)
Test: [300/750]	Time 0.104 (0.103)	Loss 1.0826 (0.9614)	Acc@1 50.000 (61.867)	Acc@5 100.000 (92.047)
Test: [400/750]	Time 0.084 (0.100)	Loss 1.1728 (1.0291)	Acc@1 53.125 (58.518)	Acc@5 81.250 (91.849)
Test: [500/750]	Time 0.095 (0.101)	Loss 0.9099 (1.0672)	Acc@1 65.625 (58.439)	Acc@5 87.500 (89.970)
Test: [600/750]	Time 0.172 (0.101)	Loss 0.7052 (1.0551)	Acc@1 81.250 (60.004)	Acc@5 96.875 (89.673)
Test: [700/750]	Time 0.083 (0.102)	Loss 1.2917 (1.0321)	Acc@1 40.625 (60.855)	Acc@5 84.375 (90.095)
 * Acc@1 60.833 Acc@5 90.154
==> training...
Epoch: [32][0/875]	Time 1.646 (1.646)	Data 1.150 (1.150)	Loss 2.5286 (2.5286)	Loss@kd 2.0348 (2.0348)	Acc@1 59.375 (59.375)	Acc@5 95.312 (95.312)
Epoch: [32][100/875]	Time 0.362 (0.403)	Data 0.008 (0.018)	Loss 2.2740 (2.4649)	Loss@kd 2.1401 (2.0753)	Acc@1 65.625 (62.423)	Acc@5 100.000 (98.113)
Epoch: [32][200/875]	Time 0.375 (0.395)	Data 0.007 (0.013)	Loss 2.5866 (2.4426)	Loss@kd 1.9966 (2.0682)	Acc@1 57.812 (63.075)	Acc@5 98.438 (98.072)
Epoch: [32][300/875]	Time 0.359 (0.393)	Data 0.007 (0.011)	Loss 2.4871 (2.4464)	Loss@kd 2.0341 (2.0719)	Acc@1 65.625 (62.967)	Acc@5 98.438 (98.012)
Epoch: [32][400/875]	Time 0.402 (0.392)	Data 0.007 (0.010)	Loss 2.3122 (2.4421)	Loss@kd 2.0546 (2.0706)	Acc@1 71.875 (62.855)	Acc@5 98.438 (98.036)
Epoch: [32][500/875]	Time 0.352 (0.391)	Data 0.005 (0.009)	Loss 2.4850 (2.4414)	Loss@kd 2.1113 (2.0672)	Acc@1 62.500 (62.653)	Acc@5 98.438 (97.985)
Epoch: [32][600/875]	Time 0.372 (0.390)	Data 0.007 (0.009)	Loss 2.6654 (2.4426)	Loss@kd 2.1037 (2.0675)	Acc@1 57.812 (62.643)	Acc@5 95.312 (98.003)
Epoch: [32][700/875]	Time 0.368 (0.391)	Data 0.007 (0.009)	Loss 2.4951 (2.4450)	Loss@kd 1.9812 (2.0683)	Acc@1 60.938 (62.589)	Acc@5 95.312 (97.972)
Epoch: [32][800/875]	Time 0.393 (0.391)	Data 0.010 (0.008)	Loss 2.5413 (2.4436)	Loss@kd 2.0777 (2.0676)	Acc@1 57.812 (62.594)	Acc@5 96.875 (97.989)
 * Acc@1 62.607 Acc@5 97.977
epoch 32, total time 342.48
Test: [0/750]	Time 0.823 (0.823)	Loss 0.6418 (0.6418)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.110 (0.115)	Loss 0.3771 (0.5173)	Acc@1 84.375 (83.478)	Acc@5 100.000 (91.182)
Test: [200/750]	Time 0.104 (0.107)	Loss 1.6765 (0.5291)	Acc@1 34.375 (82.432)	Acc@5 78.125 (93.703)
Test: [300/750]	Time 0.104 (0.107)	Loss 1.4197 (0.8548)	Acc@1 46.875 (68.355)	Acc@5 96.875 (91.103)
Test: [400/750]	Time 0.105 (0.106)	Loss 0.6444 (0.9673)	Acc@1 84.375 (61.986)	Acc@5 90.625 (90.820)
Test: [500/750]	Time 0.166 (0.106)	Loss 0.7820 (0.9359)	Acc@1 78.125 (64.508)	Acc@5 96.875 (90.737)
Test: [600/750]	Time 0.073 (0.105)	Loss 1.0656 (0.9427)	Acc@1 59.375 (64.647)	Acc@5 87.500 (90.812)
Test: [700/750]	Time 0.112 (0.106)	Loss 1.5805 (0.9693)	Acc@1 56.250 (63.463)	Acc@5 78.125 (90.772)
 * Acc@1 62.912 Acc@5 90.479
==> training...
Epoch: [33][0/875]	Time 1.527 (1.527)	Data 1.058 (1.058)	Loss 2.3080 (2.3080)	Loss@kd 1.9946 (1.9946)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [33][100/875]	Time 0.357 (0.401)	Data 0.007 (0.017)	Loss 2.4931 (2.4297)	Loss@kd 2.0677 (2.0679)	Acc@1 59.375 (63.196)	Acc@5 98.438 (98.051)
Epoch: [33][200/875]	Time 0.364 (0.386)	Data 0.007 (0.012)	Loss 2.3228 (2.4418)	Loss@kd 2.1020 (2.0679)	Acc@1 65.625 (62.586)	Acc@5 98.438 (97.909)
Epoch: [33][300/875]	Time 0.336 (0.381)	Data 0.005 (0.011)	Loss 2.3949 (2.4332)	Loss@kd 2.1543 (2.0636)	Acc@1 73.438 (62.713)	Acc@5 98.438 (97.913)
Epoch: [33][400/875]	Time 0.396 (0.379)	Data 0.007 (0.010)	Loss 2.2148 (2.4342)	Loss@kd 2.0380 (2.0610)	Acc@1 68.750 (62.547)	Acc@5 98.438 (97.904)
Epoch: [33][500/875]	Time 0.399 (0.381)	Data 0.007 (0.009)	Loss 2.4863 (2.4285)	Loss@kd 2.0391 (2.0599)	Acc@1 59.375 (62.728)	Acc@5 98.438 (97.907)
Epoch: [33][600/875]	Time 0.393 (0.383)	Data 0.007 (0.009)	Loss 2.3319 (2.4299)	Loss@kd 2.0244 (2.0592)	Acc@1 62.500 (62.583)	Acc@5 96.875 (97.868)
Epoch: [33][700/875]	Time 0.364 (0.384)	Data 0.008 (0.008)	Loss 2.5186 (2.4291)	Loss@kd 2.1036 (2.0589)	Acc@1 65.625 (62.756)	Acc@5 98.438 (97.876)
Epoch: [33][800/875]	Time 0.398 (0.385)	Data 0.008 (0.008)	Loss 2.2584 (2.4279)	Loss@kd 1.9942 (2.0601)	Acc@1 67.188 (62.830)	Acc@5 98.438 (97.911)
 * Acc@1 62.839 Acc@5 97.925
epoch 33, total time 337.72
Test: [0/750]	Time 0.868 (0.868)	Loss 0.5669 (0.5669)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.095 (0.111)	Loss 0.4315 (0.5507)	Acc@1 81.250 (83.168)	Acc@5 100.000 (90.780)
Test: [200/750]	Time 0.092 (0.104)	Loss 1.3945 (0.5647)	Acc@1 46.875 (81.234)	Acc@5 93.750 (93.905)
Test: [300/750]	Time 0.075 (0.104)	Loss 1.6143 (0.8322)	Acc@1 31.250 (70.048)	Acc@5 90.625 (93.137)
Test: [400/750]	Time 0.112 (0.103)	Loss 0.5783 (0.9511)	Acc@1 84.375 (63.007)	Acc@5 87.500 (92.441)
Test: [500/750]	Time 0.170 (0.103)	Loss 0.8348 (0.9168)	Acc@1 71.875 (65.375)	Acc@5 93.750 (91.935)
Test: [600/750]	Time 0.101 (0.102)	Loss 1.0600 (0.9355)	Acc@1 68.750 (65.032)	Acc@5 87.500 (91.857)
Test: [700/750]	Time 0.119 (0.102)	Loss 1.5648 (0.9587)	Acc@1 46.875 (64.243)	Acc@5 84.375 (91.557)
 * Acc@1 63.767 Acc@5 91.008
saving the best model!
==> training...
Epoch: [34][0/875]	Time 1.680 (1.680)	Data 1.215 (1.215)	Loss 2.4768 (2.4768)	Loss@kd 2.0005 (2.0005)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [34][100/875]	Time 0.420 (0.404)	Data 0.007 (0.019)	Loss 2.2218 (2.3996)	Loss@kd 1.9957 (2.0553)	Acc@1 75.000 (64.078)	Acc@5 100.000 (98.267)
Epoch: [34][200/875]	Time 0.344 (0.398)	Data 0.006 (0.013)	Loss 2.1786 (2.4020)	Loss@kd 2.0108 (2.0462)	Acc@1 75.000 (63.899)	Acc@5 96.875 (98.220)
Epoch: [34][300/875]	Time 0.388 (0.397)	Data 0.007 (0.011)	Loss 2.3645 (2.4036)	Loss@kd 2.0787 (2.0477)	Acc@1 59.375 (63.725)	Acc@5 98.438 (98.188)
Epoch: [34][400/875]	Time 0.393 (0.395)	Data 0.007 (0.010)	Loss 2.6686 (2.4133)	Loss@kd 2.0342 (2.0520)	Acc@1 56.250 (63.423)	Acc@5 95.312 (98.056)
Epoch: [34][500/875]	Time 0.391 (0.395)	Data 0.008 (0.009)	Loss 2.2791 (2.4119)	Loss@kd 2.0061 (2.0506)	Acc@1 73.438 (63.376)	Acc@5 98.438 (97.992)
Epoch: [34][600/875]	Time 0.350 (0.394)	Data 0.007 (0.009)	Loss 2.6222 (2.4127)	Loss@kd 2.0333 (2.0496)	Acc@1 56.250 (63.392)	Acc@5 98.438 (98.009)
Epoch: [34][700/875]	Time 0.359 (0.390)	Data 0.007 (0.009)	Loss 2.3916 (2.4096)	Loss@kd 1.9941 (2.0491)	Acc@1 56.250 (63.432)	Acc@5 98.438 (98.050)
Epoch: [34][800/875]	Time 0.358 (0.388)	Data 0.007 (0.008)	Loss 2.3740 (2.4139)	Loss@kd 2.1863 (2.0496)	Acc@1 68.750 (63.288)	Acc@5 98.438 (98.022)
 * Acc@1 63.279 Acc@5 97.984
epoch 34, total time 338.62
Test: [0/750]	Time 0.786 (0.786)	Loss 0.6480 (0.6480)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.075 (0.116)	Loss 0.5163 (0.5841)	Acc@1 78.125 (81.962)	Acc@5 100.000 (89.511)
Test: [200/750]	Time 0.105 (0.110)	Loss 1.6047 (0.6523)	Acc@1 37.500 (77.612)	Acc@5 90.625 (92.009)
Test: [300/750]	Time 0.110 (0.109)	Loss 1.4209 (0.9369)	Acc@1 40.625 (64.275)	Acc@5 93.750 (90.417)
Test: [400/750]	Time 0.100 (0.107)	Loss 0.6458 (1.0282)	Acc@1 78.125 (59.375)	Acc@5 96.875 (90.399)
Test: [500/750]	Time 0.094 (0.107)	Loss 0.7175 (0.9830)	Acc@1 81.250 (62.219)	Acc@5 93.750 (90.313)
Test: [600/750]	Time 0.099 (0.107)	Loss 0.9447 (0.9715)	Acc@1 62.500 (63.530)	Acc@5 87.500 (90.365)
Test: [700/750]	Time 0.093 (0.107)	Loss 1.1039 (0.9563)	Acc@1 56.250 (64.301)	Acc@5 90.625 (90.937)
 * Acc@1 64.842 Acc@5 91.196
saving the best model!
==> training...
Epoch: [35][0/875]	Time 1.590 (1.590)	Data 1.190 (1.190)	Loss 2.4351 (2.4351)	Loss@kd 2.0719 (2.0719)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [35][100/875]	Time 0.370 (0.401)	Data 0.007 (0.018)	Loss 2.2808 (2.4142)	Loss@kd 2.0464 (2.0373)	Acc@1 67.188 (63.475)	Acc@5 98.438 (97.757)
Epoch: [35][200/875]	Time 0.466 (0.397)	Data 0.007 (0.013)	Loss 2.2432 (2.4019)	Loss@kd 2.0070 (2.0408)	Acc@1 65.625 (63.573)	Acc@5 100.000 (98.010)
Epoch: [35][300/875]	Time 0.395 (0.394)	Data 0.007 (0.011)	Loss 2.6739 (2.4047)	Loss@kd 2.0270 (2.0407)	Acc@1 53.125 (63.460)	Acc@5 96.875 (97.981)
Epoch: [35][400/875]	Time 0.338 (0.392)	Data 0.005 (0.010)	Loss 2.3697 (2.4072)	Loss@kd 1.9573 (2.0414)	Acc@1 64.062 (63.392)	Acc@5 100.000 (97.982)
Epoch: [35][500/875]	Time 0.389 (0.392)	Data 0.007 (0.009)	Loss 2.3000 (2.4091)	Loss@kd 2.0617 (2.0378)	Acc@1 71.875 (63.302)	Acc@5 98.438 (97.938)
Epoch: [35][600/875]	Time 0.372 (0.391)	Data 0.007 (0.009)	Loss 2.2519 (2.4072)	Loss@kd 2.0296 (2.0390)	Acc@1 68.750 (63.322)	Acc@5 96.875 (97.996)
Epoch: [35][700/875]	Time 0.373 (0.391)	Data 0.007 (0.009)	Loss 2.3407 (2.4054)	Loss@kd 2.0080 (2.0377)	Acc@1 59.375 (63.336)	Acc@5 96.875 (98.010)
Epoch: [35][800/875]	Time 0.345 (0.390)	Data 0.007 (0.008)	Loss 2.3603 (2.4065)	Loss@kd 2.0196 (2.0378)	Acc@1 65.625 (63.360)	Acc@5 96.875 (97.993)
 * Acc@1 63.345 Acc@5 98.005
epoch 35, total time 341.59
Test: [0/750]	Time 0.738 (0.738)	Loss 0.6675 (0.6675)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.103 (0.115)	Loss 0.3963 (0.5761)	Acc@1 84.375 (82.147)	Acc@5 100.000 (89.851)
Test: [200/750]	Time 0.112 (0.111)	Loss 1.4980 (0.5984)	Acc@1 37.500 (79.384)	Acc@5 93.750 (92.957)
Test: [300/750]	Time 0.104 (0.109)	Loss 1.7552 (0.8787)	Acc@1 28.125 (67.369)	Acc@5 87.500 (91.331)
Test: [400/750]	Time 0.099 (0.108)	Loss 0.7914 (1.0104)	Acc@1 75.000 (61.012)	Acc@5 93.750 (90.165)
Test: [500/750]	Time 0.101 (0.108)	Loss 0.8016 (0.9923)	Acc@1 71.875 (62.868)	Acc@5 87.500 (89.883)
Test: [600/750]	Time 0.106 (0.107)	Loss 0.7695 (0.9833)	Acc@1 71.875 (63.691)	Acc@5 96.875 (90.256)
Test: [700/750]	Time 0.086 (0.107)	Loss 1.3331 (0.9863)	Acc@1 40.625 (63.325)	Acc@5 84.375 (90.754)
 * Acc@1 62.487 Acc@5 90.696
==> training...
Epoch: [36][0/875]	Time 1.493 (1.493)	Data 1.130 (1.130)	Loss 2.3163 (2.3163)	Loss@kd 2.0412 (2.0412)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [36][100/875]	Time 0.371 (0.379)	Data 0.007 (0.018)	Loss 2.2847 (2.3950)	Loss@kd 2.0500 (2.0368)	Acc@1 62.500 (64.124)	Acc@5 96.875 (97.896)
Epoch: [36][200/875]	Time 0.376 (0.373)	Data 0.007 (0.012)	Loss 2.3843 (2.4043)	Loss@kd 2.0239 (2.0335)	Acc@1 68.750 (63.783)	Acc@5 98.438 (97.839)
Epoch: [36][300/875]	Time 0.396 (0.373)	Data 0.008 (0.011)	Loss 2.3448 (2.4013)	Loss@kd 2.0430 (2.0319)	Acc@1 68.750 (63.569)	Acc@5 100.000 (97.939)
Epoch: [36][400/875]	Time 0.371 (0.374)	Data 0.005 (0.010)	Loss 2.4188 (2.4018)	Loss@kd 2.0727 (2.0314)	Acc@1 67.188 (63.385)	Acc@5 96.875 (97.935)
Epoch: [36][500/875]	Time 0.378 (0.375)	Data 0.006 (0.009)	Loss 2.3589 (2.3980)	Loss@kd 2.0010 (2.0287)	Acc@1 64.062 (63.582)	Acc@5 98.438 (97.976)
Epoch: [36][600/875]	Time 0.335 (0.376)	Data 0.006 (0.009)	Loss 2.1995 (2.3958)	Loss@kd 1.9927 (2.0294)	Acc@1 71.875 (63.649)	Acc@5 100.000 (98.032)
Epoch: [36][700/875]	Time 0.506 (0.377)	Data 0.007 (0.008)	Loss 2.3869 (2.3946)	Loss@kd 1.9130 (2.0286)	Acc@1 53.125 (63.603)	Acc@5 96.875 (98.005)
Epoch: [36][800/875]	Time 0.411 (0.377)	Data 0.008 (0.008)	Loss 2.7113 (2.3918)	Loss@kd 2.1279 (2.0289)	Acc@1 60.938 (63.667)	Acc@5 93.750 (97.999)
 * Acc@1 63.682 Acc@5 98.000
epoch 36, total time 330.21
Test: [0/750]	Time 0.804 (0.804)	Loss 0.5618 (0.5618)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.094 (0.113)	Loss 0.6923 (0.5689)	Acc@1 68.750 (81.745)	Acc@5 100.000 (90.347)
Test: [200/750]	Time 0.140 (0.107)	Loss 1.5366 (0.6754)	Acc@1 43.750 (74.705)	Acc@5 87.500 (93.004)
Test: [300/750]	Time 0.098 (0.106)	Loss 1.3581 (0.9230)	Acc@1 50.000 (63.808)	Acc@5 100.000 (92.535)
Test: [400/750]	Time 0.092 (0.104)	Loss 1.1058 (1.0151)	Acc@1 68.750 (59.009)	Acc@5 87.500 (92.300)
Test: [500/750]	Time 0.102 (0.104)	Loss 0.7101 (1.0319)	Acc@1 78.125 (59.812)	Acc@5 93.750 (91.012)
Test: [600/750]	Time 0.096 (0.103)	Loss 0.7763 (1.0134)	Acc@1 68.750 (61.564)	Acc@5 90.625 (90.869)
Test: [700/750]	Time 0.092 (0.103)	Loss 1.0022 (0.9807)	Acc@1 62.500 (63.124)	Acc@5 90.625 (91.387)
 * Acc@1 63.829 Acc@5 91.521
==> training...
Epoch: [37][0/875]	Time 1.527 (1.527)	Data 1.108 (1.108)	Loss 2.5061 (2.5061)	Loss@kd 2.0337 (2.0337)	Acc@1 56.250 (56.250)	Acc@5 100.000 (100.000)
Epoch: [37][100/875]	Time 0.356 (0.394)	Data 0.007 (0.018)	Loss 2.4604 (2.3682)	Loss@kd 1.9443 (2.0260)	Acc@1 60.938 (64.047)	Acc@5 95.312 (97.942)
Epoch: [37][200/875]	Time 0.362 (0.385)	Data 0.007 (0.012)	Loss 2.3005 (2.3676)	Loss@kd 1.9773 (2.0226)	Acc@1 62.500 (64.272)	Acc@5 100.000 (98.057)
Epoch: [37][300/875]	Time 0.375 (0.383)	Data 0.007 (0.011)	Loss 2.5598 (2.3675)	Loss@kd 2.0915 (2.0176)	Acc@1 62.500 (64.395)	Acc@5 95.312 (98.001)
Epoch: [37][400/875]	Time 0.376 (0.381)	Data 0.007 (0.010)	Loss 2.4417 (2.3710)	Loss@kd 2.0240 (2.0178)	Acc@1 59.375 (64.378)	Acc@5 98.438 (98.063)
Epoch: [37][500/875]	Time 0.341 (0.380)	Data 0.007 (0.009)	Loss 2.4378 (2.3738)	Loss@kd 1.9718 (2.0195)	Acc@1 62.500 (64.312)	Acc@5 96.875 (98.104)
Epoch: [37][600/875]	Time 0.362 (0.376)	Data 0.010 (0.009)	Loss 2.3336 (2.3731)	Loss@kd 1.9263 (2.0197)	Acc@1 59.375 (64.283)	Acc@5 96.875 (98.094)
Epoch: [37][700/875]	Time 0.361 (0.374)	Data 0.007 (0.008)	Loss 2.2209 (2.3752)	Loss@kd 1.9510 (2.0204)	Acc@1 65.625 (64.201)	Acc@5 100.000 (98.101)
Epoch: [37][800/875]	Time 0.364 (0.371)	Data 0.007 (0.008)	Loss 2.3089 (2.3758)	Loss@kd 2.0059 (2.0200)	Acc@1 73.438 (64.191)	Acc@5 100.000 (98.084)
 * Acc@1 64.150 Acc@5 98.059
epoch 37, total time 324.90
Test: [0/750]	Time 0.661 (0.661)	Loss 0.5729 (0.5729)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.094 (0.114)	Loss 0.5128 (0.5279)	Acc@1 84.375 (83.292)	Acc@5 96.875 (91.832)
Test: [200/750]	Time 0.086 (0.109)	Loss 1.8360 (0.5807)	Acc@1 31.250 (79.773)	Acc@5 81.250 (93.455)
Test: [300/750]	Time 0.101 (0.108)	Loss 1.4527 (0.9405)	Acc@1 46.875 (65.044)	Acc@5 90.625 (89.431)
Test: [400/750]	Time 0.111 (0.107)	Loss 0.7940 (1.0470)	Acc@1 71.875 (59.461)	Acc@5 90.625 (89.807)
Test: [500/750]	Time 0.089 (0.106)	Loss 0.7622 (1.0130)	Acc@1 78.125 (61.695)	Acc@5 100.000 (90.001)
Test: [600/750]	Time 0.107 (0.106)	Loss 0.9075 (1.0157)	Acc@1 59.375 (62.183)	Acc@5 93.750 (89.991)
Test: [700/750]	Time 0.099 (0.106)	Loss 0.9116 (0.9969)	Acc@1 75.000 (62.874)	Acc@5 90.625 (90.665)
 * Acc@1 63.758 Acc@5 90.933
==> training...
Epoch: [38][0/875]	Time 1.562 (1.562)	Data 1.094 (1.094)	Loss 2.6502 (2.6502)	Loss@kd 1.9542 (1.9542)	Acc@1 48.438 (48.438)	Acc@5 100.000 (100.000)
Epoch: [38][100/875]	Time 0.350 (0.389)	Data 0.005 (0.017)	Loss 2.1894 (2.3703)	Loss@kd 1.9280 (2.0225)	Acc@1 65.625 (64.186)	Acc@5 100.000 (98.391)
Epoch: [38][200/875]	Time 0.326 (0.380)	Data 0.005 (0.012)	Loss 2.7996 (2.3792)	Loss@kd 2.0055 (2.0204)	Acc@1 56.250 (63.775)	Acc@5 92.188 (98.158)
Epoch: [38][300/875]	Time 0.354 (0.378)	Data 0.006 (0.010)	Loss 2.5175 (2.3783)	Loss@kd 2.0393 (2.0188)	Acc@1 60.938 (63.948)	Acc@5 98.438 (98.131)
Epoch: [38][400/875]	Time 0.354 (0.378)	Data 0.005 (0.009)	Loss 2.4001 (2.3746)	Loss@kd 1.9741 (2.0172)	Acc@1 65.625 (64.027)	Acc@5 98.438 (98.137)
Epoch: [38][500/875]	Time 0.360 (0.377)	Data 0.007 (0.009)	Loss 2.5942 (2.3746)	Loss@kd 2.1200 (2.0148)	Acc@1 59.375 (64.009)	Acc@5 95.312 (98.088)
Epoch: [38][600/875]	Time 0.397 (0.379)	Data 0.007 (0.008)	Loss 2.1093 (2.3698)	Loss@kd 1.9270 (2.0128)	Acc@1 75.000 (64.112)	Acc@5 100.000 (98.120)
Epoch: [38][700/875]	Time 0.396 (0.380)	Data 0.007 (0.008)	Loss 2.5464 (2.3663)	Loss@kd 2.1233 (2.0111)	Acc@1 57.812 (64.178)	Acc@5 98.438 (98.117)
Epoch: [38][800/875]	Time 0.369 (0.382)	Data 0.006 (0.008)	Loss 2.2876 (2.3672)	Loss@kd 1.9999 (2.0089)	Acc@1 59.375 (64.023)	Acc@5 98.438 (98.084)
 * Acc@1 64.095 Acc@5 98.109
epoch 38, total time 334.70
Test: [0/750]	Time 0.693 (0.693)	Loss 0.6325 (0.6325)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.115)	Loss 0.6682 (0.5884)	Acc@1 71.875 (81.219)	Acc@5 100.000 (90.377)
Test: [200/750]	Time 0.094 (0.110)	Loss 1.5738 (0.6486)	Acc@1 34.375 (76.135)	Acc@5 90.625 (92.848)
Test: [300/750]	Time 0.103 (0.109)	Loss 1.2572 (0.9173)	Acc@1 40.625 (63.549)	Acc@5 96.875 (91.819)
Test: [400/750]	Time 0.090 (0.107)	Loss 0.8346 (0.9689)	Acc@1 78.125 (61.004)	Acc@5 87.500 (92.043)
Test: [500/750]	Time 0.162 (0.107)	Loss 0.7046 (0.9503)	Acc@1 71.875 (63.086)	Acc@5 96.875 (91.161)
Test: [600/750]	Time 0.106 (0.107)	Loss 1.0046 (0.9475)	Acc@1 62.500 (64.049)	Acc@5 90.625 (90.869)
Test: [700/750]	Time 0.075 (0.107)	Loss 1.0154 (0.9414)	Acc@1 62.500 (64.332)	Acc@5 87.500 (91.356)
 * Acc@1 64.654 Acc@5 91.554
==> training...
Epoch: [39][0/875]	Time 1.685 (1.685)	Data 1.192 (1.192)	Loss 2.6074 (2.6074)	Loss@kd 2.0702 (2.0702)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [39][100/875]	Time 0.357 (0.381)	Data 0.007 (0.018)	Loss 2.2981 (2.3394)	Loss@kd 1.9649 (1.9949)	Acc@1 70.312 (64.743)	Acc@5 95.312 (98.159)
Epoch: [39][200/875]	Time 0.362 (0.374)	Data 0.007 (0.013)	Loss 2.4618 (2.3501)	Loss@kd 2.0294 (1.9963)	Acc@1 60.938 (64.272)	Acc@5 95.312 (98.127)
Epoch: [39][300/875]	Time 0.376 (0.379)	Data 0.007 (0.011)	Loss 2.6599 (2.3476)	Loss@kd 2.2467 (1.9982)	Acc@1 60.938 (64.634)	Acc@5 95.312 (98.131)
Epoch: [39][400/875]	Time 0.345 (0.380)	Data 0.006 (0.010)	Loss 2.5368 (2.3476)	Loss@kd 2.1058 (1.9989)	Acc@1 62.500 (64.522)	Acc@5 92.188 (98.118)
Epoch: [39][500/875]	Time 0.391 (0.381)	Data 0.007 (0.009)	Loss 2.5123 (2.3511)	Loss@kd 1.9714 (2.0007)	Acc@1 62.500 (64.415)	Acc@5 95.312 (98.094)
Epoch: [39][600/875]	Time 0.355 (0.383)	Data 0.009 (0.009)	Loss 2.4554 (2.3508)	Loss@kd 2.0479 (2.0010)	Acc@1 65.625 (64.476)	Acc@5 95.312 (98.100)
Epoch: [39][700/875]	Time 0.358 (0.383)	Data 0.007 (0.009)	Loss 2.5131 (2.3522)	Loss@kd 2.1722 (2.0007)	Acc@1 60.938 (64.475)	Acc@5 95.312 (98.101)
Epoch: [39][800/875]	Time 0.369 (0.383)	Data 0.007 (0.008)	Loss 2.1093 (2.3528)	Loss@kd 1.9886 (2.0005)	Acc@1 75.000 (64.449)	Acc@5 100.000 (98.110)
 * Acc@1 64.436 Acc@5 98.123
epoch 39, total time 336.39
Test: [0/750]	Time 0.834 (0.834)	Loss 0.5862 (0.5862)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.106 (0.113)	Loss 0.4023 (0.5016)	Acc@1 78.125 (84.344)	Acc@5 100.000 (91.677)
Test: [200/750]	Time 0.099 (0.105)	Loss 1.3736 (0.5058)	Acc@1 50.000 (82.307)	Acc@5 87.500 (94.341)
Test: [300/750]	Time 0.113 (0.105)	Loss 1.4541 (0.7979)	Acc@1 40.625 (69.591)	Acc@5 96.875 (92.951)
Test: [400/750]	Time 0.093 (0.103)	Loss 0.7399 (0.9130)	Acc@1 78.125 (64.487)	Acc@5 90.625 (92.075)
Test: [500/750]	Time 0.099 (0.103)	Loss 0.7688 (0.8990)	Acc@1 75.000 (66.143)	Acc@5 96.875 (91.748)
Test: [600/750]	Time 0.107 (0.103)	Loss 0.8314 (0.9101)	Acc@1 78.125 (66.426)	Acc@5 93.750 (91.686)
Test: [700/750]	Time 0.102 (0.104)	Loss 1.1998 (0.9158)	Acc@1 62.500 (66.080)	Acc@5 84.375 (92.136)
 * Acc@1 65.883 Acc@5 92.108
saving the best model!
==> training...
Epoch: [40][0/875]	Time 1.716 (1.716)	Data 1.295 (1.295)	Loss 2.4870 (2.4870)	Loss@kd 1.9577 (1.9577)	Acc@1 57.812 (57.812)	Acc@5 98.438 (98.438)
Epoch: [40][100/875]	Time 0.419 (0.403)	Data 0.007 (0.019)	Loss 2.3298 (2.3416)	Loss@kd 2.0001 (1.9974)	Acc@1 67.188 (63.908)	Acc@5 96.875 (98.267)
Epoch: [40][200/875]	Time 0.488 (0.395)	Data 0.007 (0.013)	Loss 2.6195 (2.3430)	Loss@kd 2.0181 (1.9969)	Acc@1 45.312 (64.148)	Acc@5 96.875 (98.243)
Epoch: [40][300/875]	Time 0.374 (0.392)	Data 0.007 (0.011)	Loss 2.6049 (2.3470)	Loss@kd 1.9611 (1.9975)	Acc@1 53.125 (64.343)	Acc@5 100.000 (98.266)
Epoch: [40][400/875]	Time 0.372 (0.391)	Data 0.007 (0.010)	Loss 2.1994 (2.3432)	Loss@kd 1.8844 (1.9934)	Acc@1 70.312 (64.207)	Acc@5 98.438 (98.332)
Epoch: [40][500/875]	Time 0.359 (0.387)	Data 0.008 (0.009)	Loss 2.2227 (2.3440)	Loss@kd 1.9376 (1.9904)	Acc@1 57.812 (64.134)	Acc@5 98.438 (98.285)
Epoch: [40][600/875]	Time 0.362 (0.383)	Data 0.007 (0.009)	Loss 2.3745 (2.3447)	Loss@kd 2.0540 (1.9916)	Acc@1 67.188 (64.312)	Acc@5 96.875 (98.250)
Epoch: [40][700/875]	Time 0.351 (0.382)	Data 0.007 (0.009)	Loss 2.3109 (2.3430)	Loss@kd 1.9590 (1.9912)	Acc@1 68.750 (64.404)	Acc@5 98.438 (98.253)
Epoch: [40][800/875]	Time 0.377 (0.382)	Data 0.007 (0.008)	Loss 2.2468 (2.3436)	Loss@kd 1.9010 (1.9921)	Acc@1 56.250 (64.418)	Acc@5 100.000 (98.244)
 * Acc@1 64.386 Acc@5 98.237
epoch 40, total time 334.84
Test: [0/750]	Time 0.771 (0.771)	Loss 0.6106 (0.6106)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.108 (0.114)	Loss 0.5087 (0.5205)	Acc@1 84.375 (83.849)	Acc@5 96.875 (91.646)
Test: [200/750]	Time 0.073 (0.107)	Loss 1.6760 (0.5951)	Acc@1 31.250 (79.011)	Acc@5 87.500 (94.045)
Test: [300/750]	Time 0.105 (0.106)	Loss 1.4953 (0.9074)	Acc@1 34.375 (64.597)	Acc@5 96.875 (92.743)
Test: [400/750]	Time 0.102 (0.104)	Loss 1.0644 (1.0323)	Acc@1 68.750 (59.624)	Acc@5 84.375 (91.989)
Test: [500/750]	Time 0.104 (0.104)	Loss 0.6504 (1.0415)	Acc@1 78.125 (60.510)	Acc@5 93.750 (90.687)
Test: [600/750]	Time 0.092 (0.104)	Loss 0.8479 (1.0185)	Acc@1 62.500 (62.048)	Acc@5 90.625 (90.563)
Test: [700/750]	Time 0.083 (0.104)	Loss 0.8934 (0.9856)	Acc@1 75.000 (63.347)	Acc@5 93.750 (91.178)
 * Acc@1 64.217 Acc@5 91.396
==> Saving...
==> training...
Epoch: [41][0/875]	Time 1.541 (1.541)	Data 1.057 (1.057)	Loss 2.5923 (2.5923)	Loss@kd 1.8981 (1.8981)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
Epoch: [41][100/875]	Time 0.407 (0.402)	Data 0.007 (0.017)	Loss 2.2010 (2.3494)	Loss@kd 2.0423 (1.9821)	Acc@1 75.000 (63.769)	Acc@5 100.000 (98.082)
Epoch: [41][200/875]	Time 0.388 (0.395)	Data 0.008 (0.012)	Loss 2.1969 (2.3349)	Loss@kd 1.9920 (1.9896)	Acc@1 62.500 (65.003)	Acc@5 100.000 (98.119)
Epoch: [41][300/875]	Time 0.363 (0.393)	Data 0.007 (0.010)	Loss 2.3403 (2.3369)	Loss@kd 1.9712 (1.9900)	Acc@1 65.625 (64.852)	Acc@5 98.438 (98.074)
Epoch: [41][400/875]	Time 0.389 (0.392)	Data 0.007 (0.010)	Loss 2.2981 (2.3325)	Loss@kd 1.9300 (1.9867)	Acc@1 64.062 (64.818)	Acc@5 96.875 (98.137)
Epoch: [41][500/875]	Time 0.380 (0.391)	Data 0.005 (0.009)	Loss 2.5964 (2.3313)	Loss@kd 2.0010 (1.9864)	Acc@1 57.812 (64.930)	Acc@5 95.312 (98.151)
Epoch: [41][600/875]	Time 0.342 (0.391)	Data 0.007 (0.009)	Loss 2.2650 (2.3326)	Loss@kd 2.0705 (1.9847)	Acc@1 71.875 (64.822)	Acc@5 98.438 (98.131)
Epoch: [41][700/875]	Time 0.376 (0.390)	Data 0.005 (0.008)	Loss 2.1395 (2.3329)	Loss@kd 1.9208 (1.9831)	Acc@1 78.125 (64.731)	Acc@5 98.438 (98.128)
Epoch: [41][800/875]	Time 0.392 (0.390)	Data 0.007 (0.008)	Loss 2.0522 (2.3307)	Loss@kd 1.8966 (1.9824)	Acc@1 75.000 (64.786)	Acc@5 96.875 (98.137)
 * Acc@1 64.684 Acc@5 98.120
epoch 41, total time 340.96
Test: [0/750]	Time 0.765 (0.765)	Loss 0.7469 (0.7469)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.112)	Loss 0.6484 (0.7124)	Acc@1 71.875 (78.806)	Acc@5 100.000 (89.821)
Test: [200/750]	Time 0.107 (0.106)	Loss 1.6512 (0.7217)	Acc@1 37.500 (74.813)	Acc@5 90.625 (92.662)
Test: [300/750]	Time 0.116 (0.106)	Loss 1.1898 (0.9803)	Acc@1 46.875 (62.614)	Acc@5 100.000 (91.570)
Test: [400/750]	Time 0.104 (0.105)	Loss 0.7554 (1.0113)	Acc@1 81.250 (60.957)	Acc@5 87.500 (91.880)
Test: [500/750]	Time 0.170 (0.106)	Loss 0.4829 (0.9710)	Acc@1 87.500 (63.498)	Acc@5 100.000 (91.405)
Test: [600/750]	Time 0.112 (0.105)	Loss 0.7180 (0.9459)	Acc@1 65.625 (65.256)	Acc@5 93.750 (91.363)
Test: [700/750]	Time 0.110 (0.106)	Loss 1.0041 (0.9328)	Acc@1 71.875 (65.567)	Acc@5 90.625 (91.802)
 * Acc@1 65.608 Acc@5 91.892
==> training...
Epoch: [42][0/875]	Time 1.663 (1.663)	Data 1.197 (1.197)	Loss 2.2449 (2.2449)	Loss@kd 1.9781 (1.9781)	Acc@1 73.438 (73.438)	Acc@5 96.875 (96.875)
Epoch: [42][100/875]	Time 0.385 (0.383)	Data 0.006 (0.019)	Loss 2.2854 (2.3118)	Loss@kd 1.9638 (1.9640)	Acc@1 67.188 (64.867)	Acc@5 98.438 (98.113)
Epoch: [42][200/875]	Time 0.372 (0.384)	Data 0.007 (0.013)	Loss 2.2917 (2.3135)	Loss@kd 2.0030 (1.9636)	Acc@1 65.625 (65.182)	Acc@5 100.000 (98.134)
Epoch: [42][300/875]	Time 0.396 (0.385)	Data 0.007 (0.011)	Loss 2.0864 (2.3176)	Loss@kd 1.8987 (1.9707)	Acc@1 73.438 (65.376)	Acc@5 98.438 (98.069)
Epoch: [42][400/875]	Time 0.398 (0.384)	Data 0.004 (0.010)	Loss 2.3188 (2.3142)	Loss@kd 1.9086 (1.9699)	Acc@1 57.812 (65.570)	Acc@5 96.875 (98.157)
Epoch: [42][500/875]	Time 0.373 (0.385)	Data 0.007 (0.009)	Loss 2.6299 (2.3159)	Loss@kd 1.9621 (1.9704)	Acc@1 56.250 (65.503)	Acc@5 92.188 (98.144)
Epoch: [42][600/875]	Time 0.391 (0.385)	Data 0.007 (0.009)	Loss 2.3073 (2.3179)	Loss@kd 1.8981 (1.9700)	Acc@1 62.500 (65.336)	Acc@5 98.438 (98.206)
Epoch: [42][700/875]	Time 0.374 (0.385)	Data 0.007 (0.009)	Loss 2.3104 (2.3212)	Loss@kd 2.0198 (1.9706)	Acc@1 65.625 (65.251)	Acc@5 100.000 (98.197)
Epoch: [42][800/875]	Time 0.370 (0.385)	Data 0.008 (0.008)	Loss 2.0759 (2.3182)	Loss@kd 1.8921 (1.9700)	Acc@1 65.625 (65.250)	Acc@5 100.000 (98.198)
 * Acc@1 65.284 Acc@5 98.216
epoch 42, total time 337.34
Test: [0/750]	Time 0.791 (0.791)	Loss 0.6566 (0.6566)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.082 (0.113)	Loss 0.5830 (0.5503)	Acc@1 78.125 (83.601)	Acc@5 100.000 (91.151)
Test: [200/750]	Time 0.093 (0.106)	Loss 1.7270 (0.6189)	Acc@1 21.875 (78.902)	Acc@5 93.750 (93.097)
Test: [300/750]	Time 0.109 (0.106)	Loss 1.5036 (0.9626)	Acc@1 40.625 (64.265)	Acc@5 90.625 (90.563)
Test: [400/750]	Time 0.102 (0.104)	Loss 0.4640 (1.0067)	Acc@1 84.375 (61.884)	Acc@5 96.875 (91.061)
Test: [500/750]	Time 0.094 (0.105)	Loss 0.6971 (0.9352)	Acc@1 84.375 (65.319)	Acc@5 93.750 (91.455)
Test: [600/750]	Time 0.158 (0.104)	Loss 0.8823 (0.9381)	Acc@1 75.000 (66.083)	Acc@5 93.750 (91.379)
Test: [700/750]	Time 0.094 (0.104)	Loss 1.2954 (0.9412)	Acc@1 56.250 (65.892)	Acc@5 81.250 (91.686)
 * Acc@1 65.525 Acc@5 91.504
==> training...
Epoch: [43][0/875]	Time 1.662 (1.662)	Data 1.192 (1.192)	Loss 2.5020 (2.5020)	Loss@kd 1.9676 (1.9676)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)
Epoch: [43][100/875]	Time 0.377 (0.404)	Data 0.007 (0.019)	Loss 2.4300 (2.2868)	Loss@kd 1.9493 (1.9632)	Acc@1 65.625 (65.718)	Acc@5 98.438 (98.530)
Epoch: [43][200/875]	Time 0.408 (0.397)	Data 0.007 (0.013)	Loss 2.4525 (2.2997)	Loss@kd 1.9819 (1.9676)	Acc@1 67.188 (65.438)	Acc@5 98.438 (98.438)
Epoch: [43][300/875]	Time 0.399 (0.394)	Data 0.007 (0.011)	Loss 2.4469 (2.3036)	Loss@kd 1.9266 (1.9648)	Acc@1 59.375 (65.210)	Acc@5 98.438 (98.412)
Epoch: [43][400/875]	Time 0.362 (0.388)	Data 0.007 (0.010)	Loss 2.2856 (2.3057)	Loss@kd 1.9535 (1.9664)	Acc@1 67.188 (65.196)	Acc@5 100.000 (98.336)
Epoch: [43][500/875]	Time 0.355 (0.384)	Data 0.007 (0.009)	Loss 2.2398 (2.3062)	Loss@kd 1.8904 (1.9643)	Acc@1 65.625 (65.095)	Acc@5 100.000 (98.319)
Epoch: [43][600/875]	Time 0.387 (0.381)	Data 0.007 (0.009)	Loss 2.2922 (2.3048)	Loss@kd 1.9885 (1.9631)	Acc@1 65.625 (65.217)	Acc@5 98.438 (98.279)
Epoch: [43][700/875]	Time 0.401 (0.382)	Data 0.007 (0.009)	Loss 2.1970 (2.3062)	Loss@kd 1.9349 (1.9621)	Acc@1 68.750 (65.219)	Acc@5 100.000 (98.232)
Epoch: [43][800/875]	Time 0.390 (0.383)	Data 0.008 (0.008)	Loss 1.9725 (2.3038)	Loss@kd 1.8952 (1.9620)	Acc@1 78.125 (65.364)	Acc@5 100.000 (98.219)
 * Acc@1 65.255 Acc@5 98.200
epoch 43, total time 335.89
Test: [0/750]	Time 0.802 (0.802)	Loss 0.5744 (0.5744)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.095 (0.114)	Loss 0.5003 (0.5532)	Acc@1 78.125 (82.488)	Acc@5 100.000 (90.811)
Test: [200/750]	Time 0.091 (0.108)	Loss 1.1981 (0.5622)	Acc@1 46.875 (81.887)	Acc@5 100.000 (93.874)
Test: [300/750]	Time 0.102 (0.106)	Loss 1.2637 (0.7795)	Acc@1 50.000 (71.709)	Acc@5 96.875 (94.186)
Test: [400/750]	Time 0.100 (0.105)	Loss 1.0202 (0.9176)	Acc@1 59.375 (64.690)	Acc@5 84.375 (92.776)
Test: [500/750]	Time 0.100 (0.105)	Loss 0.7362 (0.9463)	Acc@1 78.125 (64.328)	Acc@5 96.875 (91.087)
Test: [600/750]	Time 0.104 (0.104)	Loss 0.8544 (0.9462)	Acc@1 71.875 (64.939)	Acc@5 96.875 (91.067)
Test: [700/750]	Time 0.097 (0.104)	Loss 1.2350 (0.9467)	Acc@1 46.875 (64.653)	Acc@5 87.500 (91.463)
 * Acc@1 64.562 Acc@5 91.500
==> training...
Epoch: [44][0/875]	Time 1.628 (1.628)	Data 1.194 (1.194)	Loss 2.3157 (2.3157)	Loss@kd 2.0217 (2.0217)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [44][100/875]	Time 0.386 (0.402)	Data 0.007 (0.019)	Loss 2.2863 (2.2872)	Loss@kd 2.0200 (1.9482)	Acc@1 71.875 (65.486)	Acc@5 98.438 (98.175)
Epoch: [44][200/875]	Time 0.375 (0.397)	Data 0.005 (0.013)	Loss 2.4020 (2.2853)	Loss@kd 1.9555 (1.9441)	Acc@1 64.062 (65.524)	Acc@5 100.000 (98.142)
Epoch: [44][300/875]	Time 0.420 (0.395)	Data 0.009 (0.011)	Loss 2.3819 (2.2909)	Loss@kd 1.8836 (1.9484)	Acc@1 57.812 (65.423)	Acc@5 96.875 (98.245)
Epoch: [44][400/875]	Time 0.360 (0.393)	Data 0.007 (0.010)	Loss 2.5350 (2.2920)	Loss@kd 1.9232 (1.9499)	Acc@1 59.375 (65.531)	Acc@5 98.438 (98.293)
Epoch: [44][500/875]	Time 0.375 (0.392)	Data 0.007 (0.009)	Loss 2.0721 (2.2883)	Loss@kd 1.9318 (1.9490)	Acc@1 68.750 (65.478)	Acc@5 98.438 (98.282)
Epoch: [44][600/875]	Time 0.369 (0.391)	Data 0.007 (0.009)	Loss 2.3809 (2.2895)	Loss@kd 2.0445 (1.9501)	Acc@1 64.062 (65.531)	Acc@5 98.438 (98.289)
Epoch: [44][700/875]	Time 0.383 (0.391)	Data 0.008 (0.009)	Loss 2.4602 (2.2906)	Loss@kd 2.0675 (1.9519)	Acc@1 60.938 (65.473)	Acc@5 100.000 (98.304)
Epoch: [44][800/875]	Time 0.365 (0.390)	Data 0.007 (0.008)	Loss 2.2722 (2.2911)	Loss@kd 1.9286 (1.9513)	Acc@1 64.062 (65.522)	Acc@5 100.000 (98.303)
 * Acc@1 65.477 Acc@5 98.305
epoch 44, total time 339.82
Test: [0/750]	Time 0.656 (0.656)	Loss 0.6828 (0.6828)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.107 (0.114)	Loss 0.5503 (0.6869)	Acc@1 78.125 (78.496)	Acc@5 96.875 (90.161)
Test: [200/750]	Time 0.102 (0.107)	Loss 1.5709 (0.7127)	Acc@1 34.375 (74.705)	Acc@5 87.500 (92.739)
Test: [300/750]	Time 0.094 (0.106)	Loss 1.2311 (0.9648)	Acc@1 56.250 (62.407)	Acc@5 96.875 (91.985)
Test: [400/750]	Time 0.092 (0.104)	Loss 0.9043 (1.0152)	Acc@1 65.625 (60.373)	Acc@5 93.750 (92.082)
Test: [500/750]	Time 0.102 (0.104)	Loss 0.7330 (1.0119)	Acc@1 68.750 (61.359)	Acc@5 93.750 (91.074)
Test: [600/750]	Time 0.115 (0.103)	Loss 0.8551 (1.0050)	Acc@1 68.750 (62.178)	Acc@5 93.750 (90.765)
Test: [700/750]	Time 0.103 (0.103)	Loss 0.8731 (0.9851)	Acc@1 65.625 (62.897)	Acc@5 96.875 (91.298)
 * Acc@1 63.425 Acc@5 91.521
==> training...
Epoch: [45][0/875]	Time 1.713 (1.713)	Data 1.195 (1.195)	Loss 2.0918 (2.0918)	Loss@kd 1.9440 (1.9440)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [45][100/875]	Time 0.368 (0.398)	Data 0.007 (0.019)	Loss 2.3685 (2.2883)	Loss@kd 1.9134 (1.9532)	Acc@1 62.500 (66.151)	Acc@5 96.875 (98.484)
Epoch: [45][200/875]	Time 0.401 (0.392)	Data 0.007 (0.013)	Loss 2.0986 (2.2846)	Loss@kd 1.9145 (1.9533)	Acc@1 75.000 (66.192)	Acc@5 98.438 (98.368)
Epoch: [45][300/875]	Time 0.343 (0.391)	Data 0.007 (0.011)	Loss 2.2744 (2.2877)	Loss@kd 1.9990 (1.9529)	Acc@1 70.312 (65.942)	Acc@5 98.438 (98.391)
Epoch: [45][400/875]	Time 0.389 (0.391)	Data 0.007 (0.010)	Loss 2.3069 (2.2860)	Loss@kd 1.9768 (1.9502)	Acc@1 67.188 (65.641)	Acc@5 98.438 (98.391)
Epoch: [45][500/875]	Time 0.393 (0.390)	Data 0.007 (0.009)	Loss 2.1612 (2.2835)	Loss@kd 1.9652 (1.9484)	Acc@1 73.438 (65.731)	Acc@5 96.875 (98.406)
Epoch: [45][600/875]	Time 0.377 (0.390)	Data 0.007 (0.009)	Loss 2.1617 (2.2825)	Loss@kd 2.0501 (1.9485)	Acc@1 70.312 (65.732)	Acc@5 100.000 (98.414)
Epoch: [45][700/875]	Time 0.411 (0.390)	Data 0.007 (0.009)	Loss 2.5100 (2.2842)	Loss@kd 2.0103 (1.9486)	Acc@1 57.812 (65.678)	Acc@5 100.000 (98.420)
Epoch: [45][800/875]	Time 0.398 (0.390)	Data 0.007 (0.008)	Loss 2.2488 (2.2868)	Loss@kd 1.9149 (1.9469)	Acc@1 59.375 (65.506)	Acc@5 96.875 (98.354)
 * Acc@1 65.505 Acc@5 98.355
epoch 45, total time 341.54
Test: [0/750]	Time 0.861 (0.861)	Loss 0.7089 (0.7089)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.094 (0.116)	Loss 0.5890 (0.5354)	Acc@1 81.250 (84.282)	Acc@5 96.875 (91.615)
Test: [200/750]	Time 0.107 (0.110)	Loss 1.3282 (0.5640)	Acc@1 53.125 (81.654)	Acc@5 90.625 (94.294)
Test: [300/750]	Time 0.085 (0.108)	Loss 1.2541 (0.8071)	Acc@1 53.125 (70.556)	Acc@5 100.000 (93.511)
Test: [400/750]	Time 0.078 (0.106)	Loss 0.6272 (0.8955)	Acc@1 78.125 (66.038)	Acc@5 100.000 (93.134)
Test: [500/750]	Time 0.185 (0.105)	Loss 0.5961 (0.8646)	Acc@1 81.250 (67.964)	Acc@5 96.875 (92.808)
Test: [600/750]	Time 0.105 (0.104)	Loss 1.0634 (0.8735)	Acc@1 56.250 (68.006)	Acc@5 87.500 (92.575)
Test: [700/750]	Time 0.094 (0.104)	Loss 1.2240 (0.8937)	Acc@1 59.375 (67.136)	Acc@5 87.500 (92.542)
 * Acc@1 66.812 Acc@5 92.433
saving the best model!
==> training...
Epoch: [46][0/875]	Time 1.657 (1.657)	Data 1.155 (1.155)	Loss 2.2781 (2.2781)	Loss@kd 1.9682 (1.9682)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [46][100/875]	Time 0.399 (0.401)	Data 0.007 (0.018)	Loss 2.3985 (2.2672)	Loss@kd 1.9930 (1.9463)	Acc@1 59.375 (67.095)	Acc@5 95.312 (98.267)
Epoch: [46][200/875]	Time 0.311 (0.394)	Data 0.008 (0.013)	Loss 2.3688 (2.2751)	Loss@kd 1.9604 (1.9507)	Acc@1 51.562 (66.472)	Acc@5 98.438 (98.329)
Epoch: [46][300/875]	Time 0.357 (0.385)	Data 0.007 (0.011)	Loss 2.0272 (2.2694)	Loss@kd 1.9001 (1.9438)	Acc@1 70.312 (66.258)	Acc@5 100.000 (98.432)
Epoch: [46][400/875]	Time 0.361 (0.381)	Data 0.007 (0.010)	Loss 2.1098 (2.2736)	Loss@kd 1.9520 (1.9432)	Acc@1 76.562 (66.147)	Acc@5 100.000 (98.426)
Epoch: [46][500/875]	Time 0.418 (0.380)	Data 0.007 (0.009)	Loss 2.1554 (2.2746)	Loss@kd 1.8983 (1.9419)	Acc@1 64.062 (66.108)	Acc@5 98.438 (98.350)
Epoch: [46][600/875]	Time 0.387 (0.382)	Data 0.008 (0.009)	Loss 2.3309 (2.2735)	Loss@kd 1.9432 (1.9400)	Acc@1 62.500 (66.103)	Acc@5 96.875 (98.357)
Epoch: [46][700/875]	Time 0.393 (0.383)	Data 0.005 (0.009)	Loss 2.1335 (2.2730)	Loss@kd 1.9416 (1.9396)	Acc@1 70.312 (66.073)	Acc@5 100.000 (98.382)
Epoch: [46][800/875]	Time 0.413 (0.384)	Data 0.007 (0.008)	Loss 2.2061 (2.2698)	Loss@kd 1.9205 (1.9366)	Acc@1 67.188 (66.068)	Acc@5 100.000 (98.402)
 * Acc@1 66.096 Acc@5 98.384
epoch 46, total time 336.38
Test: [0/750]	Time 0.831 (0.831)	Loss 0.5700 (0.5700)	Acc@1 84.375 (84.375)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.099 (0.119)	Loss 0.4890 (0.5003)	Acc@1 81.250 (84.839)	Acc@5 100.000 (92.574)
Test: [200/750]	Time 0.103 (0.111)	Loss 1.4414 (0.5356)	Acc@1 40.625 (81.996)	Acc@5 90.625 (94.761)
Test: [300/750]	Time 0.099 (0.110)	Loss 1.5626 (0.8267)	Acc@1 46.875 (69.248)	Acc@5 93.750 (93.086)
Test: [400/750]	Time 0.105 (0.108)	Loss 0.6725 (0.9567)	Acc@1 75.000 (62.929)	Acc@5 87.500 (92.223)
Test: [500/750]	Time 0.189 (0.108)	Loss 0.4967 (0.9175)	Acc@1 84.375 (65.569)	Acc@5 100.000 (91.891)
Test: [600/750]	Time 0.099 (0.108)	Loss 0.8257 (0.9046)	Acc@1 65.625 (66.577)	Acc@5 96.875 (92.086)
Test: [700/750]	Time 0.102 (0.108)	Loss 0.9975 (0.9016)	Acc@1 65.625 (66.575)	Acc@5 93.750 (92.439)
 * Acc@1 66.771 Acc@5 92.450
==> training...
Epoch: [47][0/875]	Time 1.647 (1.647)	Data 1.218 (1.218)	Loss 2.2140 (2.2140)	Loss@kd 2.0254 (2.0254)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [47][100/875]	Time 0.408 (0.398)	Data 0.007 (0.019)	Loss 2.2578 (2.2440)	Loss@kd 1.9497 (1.9295)	Acc@1 62.500 (66.646)	Acc@5 98.438 (98.530)
Epoch: [47][200/875]	Time 0.367 (0.395)	Data 0.007 (0.013)	Loss 2.2434 (2.2529)	Loss@kd 1.9199 (1.9335)	Acc@1 64.062 (66.558)	Acc@5 100.000 (98.290)
Epoch: [47][300/875]	Time 0.374 (0.392)	Data 0.007 (0.011)	Loss 2.1746 (2.2624)	Loss@kd 1.9091 (1.9324)	Acc@1 64.062 (66.103)	Acc@5 100.000 (98.261)
Epoch: [47][400/875]	Time 0.383 (0.391)	Data 0.008 (0.010)	Loss 2.3175 (2.2608)	Loss@kd 1.8630 (1.9299)	Acc@1 64.062 (66.026)	Acc@5 100.000 (98.325)
Epoch: [47][500/875]	Time 0.358 (0.391)	Data 0.007 (0.009)	Loss 2.2891 (2.2635)	Loss@kd 2.0423 (1.9299)	Acc@1 65.625 (65.987)	Acc@5 98.438 (98.294)
Epoch: [47][600/875]	Time 0.357 (0.391)	Data 0.007 (0.009)	Loss 2.2444 (2.2663)	Loss@kd 1.8638 (1.9308)	Acc@1 65.625 (65.880)	Acc@5 96.875 (98.266)
Epoch: [47][700/875]	Time 0.373 (0.390)	Data 0.007 (0.009)	Loss 2.4240 (2.2677)	Loss@kd 1.9131 (1.9309)	Acc@1 59.375 (65.884)	Acc@5 100.000 (98.277)
Epoch: [47][800/875]	Time 0.358 (0.387)	Data 0.007 (0.009)	Loss 2.3829 (2.2663)	Loss@kd 1.9885 (1.9298)	Acc@1 62.500 (65.925)	Acc@5 95.312 (98.254)
 * Acc@1 65.995 Acc@5 98.282
epoch 47, total time 338.02
Test: [0/750]	Time 0.824 (0.824)	Loss 0.4883 (0.4883)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.105 (0.111)	Loss 0.9430 (0.5631)	Acc@1 56.250 (82.333)	Acc@5 100.000 (92.884)
Test: [200/750]	Time 0.107 (0.105)	Loss 2.0171 (0.7779)	Acc@1 9.375 (71.300)	Acc@5 81.250 (92.848)
Test: [300/750]	Time 0.097 (0.103)	Loss 1.5218 (1.1532)	Acc@1 43.750 (55.554)	Acc@5 100.000 (89.016)
Test: [400/750]	Time 0.093 (0.102)	Loss 1.0002 (1.1646)	Acc@1 71.875 (54.902)	Acc@5 90.625 (90.181)
Test: [500/750]	Time 0.159 (0.103)	Loss 0.8279 (1.1466)	Acc@1 68.750 (56.811)	Acc@5 96.875 (89.795)
Test: [600/750]	Time 0.091 (0.102)	Loss 0.8026 (1.1240)	Acc@1 71.875 (58.886)	Acc@5 90.625 (89.361)
Test: [700/750]	Time 0.119 (0.102)	Loss 0.7074 (1.0641)	Acc@1 75.000 (61.252)	Acc@5 96.875 (90.210)
 * Acc@1 62.362 Acc@5 90.483
==> training...
Epoch: [48][0/875]	Time 1.753 (1.753)	Data 1.306 (1.306)	Loss 2.1736 (2.1736)	Loss@kd 1.9249 (1.9249)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [48][100/875]	Time 0.380 (0.404)	Data 0.008 (0.020)	Loss 2.0994 (2.2425)	Loss@kd 1.8782 (1.9293)	Acc@1 70.312 (66.863)	Acc@5 100.000 (98.561)
Epoch: [48][200/875]	Time 0.383 (0.398)	Data 0.007 (0.013)	Loss 2.4467 (2.2350)	Loss@kd 1.8992 (1.9223)	Acc@1 53.125 (66.877)	Acc@5 100.000 (98.531)
Epoch: [48][300/875]	Time 0.395 (0.395)	Data 0.007 (0.011)	Loss 2.1100 (2.2420)	Loss@kd 1.8192 (1.9213)	Acc@1 68.750 (66.398)	Acc@5 98.438 (98.515)
Epoch: [48][400/875]	Time 0.384 (0.393)	Data 0.007 (0.010)	Loss 2.1644 (2.2435)	Loss@kd 1.9784 (1.9207)	Acc@1 68.750 (66.424)	Acc@5 100.000 (98.484)
Epoch: [48][500/875]	Time 0.372 (0.392)	Data 0.007 (0.010)	Loss 2.2990 (2.2475)	Loss@kd 1.8902 (1.9203)	Acc@1 59.375 (66.383)	Acc@5 98.438 (98.438)
Epoch: [48][600/875]	Time 0.392 (0.391)	Data 0.007 (0.009)	Loss 2.4005 (2.2503)	Loss@kd 1.9395 (1.9210)	Acc@1 65.625 (66.267)	Acc@5 100.000 (98.388)
Epoch: [48][700/875]	Time 0.366 (0.391)	Data 0.008 (0.009)	Loss 2.2723 (2.2532)	Loss@kd 1.8981 (1.9201)	Acc@1 65.625 (66.122)	Acc@5 93.750 (98.364)
Epoch: [48][800/875]	Time 0.359 (0.390)	Data 0.005 (0.009)	Loss 2.1353 (2.2546)	Loss@kd 1.8559 (1.9214)	Acc@1 78.125 (66.117)	Acc@5 100.000 (98.363)
 * Acc@1 66.109 Acc@5 98.350
epoch 48, total time 341.93
Test: [0/750]	Time 0.795 (0.795)	Loss 0.5829 (0.5829)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.099 (0.112)	Loss 0.5948 (0.5223)	Acc@1 78.125 (83.478)	Acc@5 100.000 (92.110)
Test: [200/750]	Time 0.101 (0.108)	Loss 1.4316 (0.5900)	Acc@1 37.500 (78.731)	Acc@5 90.625 (94.092)
Test: [300/750]	Time 0.089 (0.108)	Loss 1.3163 (0.8698)	Acc@1 56.250 (65.916)	Acc@5 93.750 (92.307)
Test: [400/750]	Time 0.103 (0.106)	Loss 0.7225 (0.9515)	Acc@1 75.000 (63.256)	Acc@5 87.500 (91.677)
Test: [500/750]	Time 0.090 (0.106)	Loss 0.6214 (0.9201)	Acc@1 81.250 (65.656)	Acc@5 93.750 (91.461)
Test: [600/750]	Time 0.100 (0.106)	Loss 0.7537 (0.9142)	Acc@1 75.000 (66.551)	Acc@5 96.875 (91.571)
Test: [700/750]	Time 0.093 (0.106)	Loss 1.2227 (0.9025)	Acc@1 56.250 (66.967)	Acc@5 84.375 (92.105)
 * Acc@1 66.988 Acc@5 92.154
saving the best model!
==> training...
Epoch: [49][0/875]	Time 1.489 (1.489)	Data 1.092 (1.092)	Loss 2.1314 (2.1314)	Loss@kd 1.8708 (1.8708)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [49][100/875]	Time 0.368 (0.394)	Data 0.007 (0.018)	Loss 2.1972 (2.2404)	Loss@kd 1.8645 (1.9134)	Acc@1 67.188 (67.002)	Acc@5 100.000 (98.221)
Epoch: [49][200/875]	Time 0.359 (0.379)	Data 0.007 (0.012)	Loss 2.1998 (2.2419)	Loss@kd 1.9751 (1.9187)	Acc@1 67.188 (66.558)	Acc@5 100.000 (98.220)
Epoch: [49][300/875]	Time 0.341 (0.373)	Data 0.006 (0.010)	Loss 2.2811 (2.2479)	Loss@kd 1.9238 (1.9107)	Acc@1 64.062 (65.936)	Acc@5 98.438 (98.214)
Epoch: [49][400/875]	Time 0.388 (0.370)	Data 0.007 (0.009)	Loss 2.1608 (2.2515)	Loss@kd 1.9482 (1.9122)	Acc@1 67.188 (65.785)	Acc@5 100.000 (98.200)
Epoch: [49][500/875]	Time 0.346 (0.370)	Data 0.007 (0.009)	Loss 2.1275 (2.2433)	Loss@kd 1.9240 (1.9124)	Acc@1 70.312 (66.174)	Acc@5 100.000 (98.241)
Epoch: [49][600/875]	Time 0.361 (0.370)	Data 0.007 (0.008)	Loss 2.0213 (2.2444)	Loss@kd 1.8208 (1.9133)	Acc@1 73.438 (66.220)	Acc@5 100.000 (98.201)
Epoch: [49][700/875]	Time 0.353 (0.370)	Data 0.007 (0.008)	Loss 2.0620 (2.2442)	Loss@kd 1.8424 (1.9129)	Acc@1 73.438 (66.176)	Acc@5 98.438 (98.230)
Epoch: [49][800/875]	Time 0.389 (0.370)	Data 0.005 (0.008)	Loss 2.3274 (2.2437)	Loss@kd 1.8937 (1.9136)	Acc@1 57.812 (66.150)	Acc@5 100.000 (98.285)
 * Acc@1 66.154 Acc@5 98.295
epoch 49, total time 324.47
Test: [0/750]	Time 0.763 (0.763)	Loss 0.6268 (0.6268)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.078 (0.110)	Loss 0.8640 (0.6452)	Acc@1 68.750 (80.755)	Acc@5 96.875 (91.615)
Test: [200/750]	Time 0.111 (0.107)	Loss 1.2846 (0.7429)	Acc@1 37.500 (75.171)	Acc@5 90.625 (92.771)
Test: [300/750]	Time 0.097 (0.107)	Loss 1.2624 (0.9247)	Acc@1 50.000 (64.597)	Acc@5 96.875 (92.566)
Test: [400/750]	Time 0.089 (0.104)	Loss 1.1376 (1.0088)	Acc@1 65.625 (61.393)	Acc@5 87.500 (91.552)
Test: [500/750]	Time 0.091 (0.104)	Loss 0.6710 (1.0309)	Acc@1 75.000 (61.234)	Acc@5 93.750 (89.883)
Test: [600/750]	Time 0.113 (0.103)	Loss 0.9068 (1.0158)	Acc@1 71.875 (62.406)	Acc@5 84.375 (89.783)
Test: [700/750]	Time 0.099 (0.103)	Loss 1.3096 (1.0291)	Acc@1 37.500 (61.742)	Acc@5 96.875 (89.707)
 * Acc@1 61.554 Acc@5 89.704
==> training...
Epoch: [50][0/875]	Time 1.600 (1.600)	Data 1.154 (1.154)	Loss 2.0866 (2.0866)	Loss@kd 1.9993 (1.9993)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [50][100/875]	Time 0.411 (0.383)	Data 0.007 (0.018)	Loss 2.0300 (2.2311)	Loss@kd 1.8251 (1.9036)	Acc@1 71.875 (67.141)	Acc@5 98.438 (98.438)
Epoch: [50][200/875]	Time 0.407 (0.381)	Data 0.007 (0.012)	Loss 2.1065 (2.2190)	Loss@kd 1.8860 (1.9067)	Acc@1 67.188 (67.475)	Acc@5 98.438 (98.453)
Epoch: [50][300/875]	Time 0.400 (0.384)	Data 0.007 (0.010)	Loss 2.4843 (2.2287)	Loss@kd 1.9829 (1.9114)	Acc@1 60.938 (67.348)	Acc@5 95.312 (98.386)
Epoch: [50][400/875]	Time 0.370 (0.385)	Data 0.007 (0.010)	Loss 2.2765 (2.2298)	Loss@kd 1.9993 (1.9114)	Acc@1 70.312 (67.141)	Acc@5 98.438 (98.406)
Epoch: [50][500/875]	Time 0.372 (0.386)	Data 0.008 (0.009)	Loss 2.3464 (2.2270)	Loss@kd 1.9166 (1.9090)	Acc@1 64.062 (67.212)	Acc@5 96.875 (98.469)
Epoch: [50][600/875]	Time 0.408 (0.386)	Data 0.007 (0.009)	Loss 2.1629 (2.2308)	Loss@kd 1.7885 (1.9095)	Acc@1 65.625 (67.042)	Acc@5 100.000 (98.443)
Epoch: [50][700/875]	Time 0.357 (0.384)	Data 0.006 (0.009)	Loss 2.1487 (2.2308)	Loss@kd 1.9853 (1.9083)	Acc@1 76.562 (66.931)	Acc@5 100.000 (98.422)
Epoch: [50][800/875]	Time 0.331 (0.382)	Data 0.005 (0.008)	Loss 2.3572 (2.2294)	Loss@kd 1.8155 (1.9070)	Acc@1 51.562 (66.899)	Acc@5 96.875 (98.432)
 * Acc@1 66.939 Acc@5 98.409
epoch 50, total time 334.08
Test: [0/750]	Time 0.764 (0.764)	Loss 0.5797 (0.5797)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.064 (0.109)	Loss 0.5722 (0.5738)	Acc@1 75.000 (82.054)	Acc@5 100.000 (92.017)
Test: [200/750]	Time 0.103 (0.103)	Loss 1.5463 (0.5882)	Acc@1 28.125 (79.960)	Acc@5 90.625 (94.279)
Test: [300/750]	Time 0.111 (0.103)	Loss 1.0165 (0.8540)	Acc@1 71.875 (67.369)	Acc@5 93.750 (92.784)
Test: [400/750]	Time 0.097 (0.103)	Loss 0.8349 (0.9001)	Acc@1 75.000 (65.383)	Acc@5 90.625 (92.706)
Test: [500/750]	Time 0.168 (0.104)	Loss 0.4782 (0.8857)	Acc@1 90.625 (67.103)	Acc@5 100.000 (91.922)
Test: [600/750]	Time 0.087 (0.103)	Loss 0.9050 (0.8778)	Acc@1 68.750 (67.840)	Acc@5 93.750 (92.154)
Test: [700/750]	Time 0.082 (0.104)	Loss 1.2320 (0.8959)	Acc@1 53.125 (66.931)	Acc@5 84.375 (92.297)
 * Acc@1 66.604 Acc@5 92.100
==> training...
Epoch: [51][0/875]	Time 1.737 (1.737)	Data 1.190 (1.190)	Loss 2.5207 (2.5207)	Loss@kd 2.0256 (2.0256)	Acc@1 56.250 (56.250)	Acc@5 98.438 (98.438)
Epoch: [51][100/875]	Time 0.410 (0.401)	Data 0.007 (0.019)	Loss 2.2168 (2.2155)	Loss@kd 1.9358 (1.9005)	Acc@1 68.750 (67.636)	Acc@5 98.438 (98.329)
Epoch: [51][200/875]	Time 0.377 (0.395)	Data 0.007 (0.013)	Loss 2.0200 (2.2117)	Loss@kd 1.9332 (1.8985)	Acc@1 84.375 (67.848)	Acc@5 100.000 (98.329)
Epoch: [51][300/875]	Time 0.401 (0.393)	Data 0.007 (0.011)	Loss 2.2643 (2.2176)	Loss@kd 1.9051 (1.8995)	Acc@1 71.875 (67.603)	Acc@5 98.438 (98.406)
Epoch: [51][400/875]	Time 0.353 (0.391)	Data 0.007 (0.010)	Loss 2.1416 (2.2183)	Loss@kd 1.8550 (1.9002)	Acc@1 65.625 (67.437)	Acc@5 100.000 (98.430)
Epoch: [51][500/875]	Time 0.361 (0.391)	Data 0.007 (0.009)	Loss 2.3543 (2.2264)	Loss@kd 2.0545 (1.9026)	Acc@1 68.750 (67.097)	Acc@5 100.000 (98.403)
Epoch: [51][600/875]	Time 0.412 (0.390)	Data 0.007 (0.009)	Loss 2.1638 (2.2299)	Loss@kd 1.9590 (1.9029)	Acc@1 62.500 (66.883)	Acc@5 100.000 (98.365)
Epoch: [51][700/875]	Time 0.354 (0.390)	Data 0.007 (0.009)	Loss 2.3085 (2.2293)	Loss@kd 1.8418 (1.9026)	Acc@1 57.812 (66.900)	Acc@5 100.000 (98.380)
Epoch: [51][800/875]	Time 0.384 (0.390)	Data 0.007 (0.008)	Loss 1.9574 (2.2260)	Loss@kd 1.8912 (1.9018)	Acc@1 78.125 (66.918)	Acc@5 98.438 (98.422)
 * Acc@1 66.884 Acc@5 98.411
epoch 51, total time 341.40
Test: [0/750]	Time 0.912 (0.912)	Loss 0.5721 (0.5721)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.102 (0.115)	Loss 0.4111 (0.5741)	Acc@1 84.375 (82.673)	Acc@5 100.000 (91.491)
Test: [200/750]	Time 0.103 (0.107)	Loss 1.3505 (0.5459)	Acc@1 46.875 (82.261)	Acc@5 87.500 (94.356)
Test: [300/750]	Time 0.103 (0.107)	Loss 1.3379 (0.7908)	Acc@1 43.750 (71.252)	Acc@5 93.750 (93.449)
Test: [400/750]	Time 0.105 (0.106)	Loss 0.5449 (0.8719)	Acc@1 81.250 (66.747)	Acc@5 90.625 (93.119)
Test: [500/750]	Time 0.108 (0.106)	Loss 0.6109 (0.8372)	Acc@1 81.250 (69.062)	Acc@5 100.000 (92.871)
Test: [600/750]	Time 0.096 (0.105)	Loss 0.9783 (0.8439)	Acc@1 68.750 (69.228)	Acc@5 87.500 (92.762)
Test: [700/750]	Time 0.080 (0.106)	Loss 1.4140 (0.8629)	Acc@1 46.875 (68.246)	Acc@5 78.125 (92.885)
 * Acc@1 67.463 Acc@5 92.642
saving the best model!
==> training...
Epoch: [52][0/875]	Time 1.644 (1.644)	Data 1.233 (1.233)	Loss 2.5162 (2.5162)	Loss@kd 1.9233 (1.9233)	Acc@1 54.688 (54.688)	Acc@5 96.875 (96.875)
Epoch: [52][100/875]	Time 0.362 (0.391)	Data 0.007 (0.019)	Loss 2.2463 (2.2076)	Loss@kd 1.8731 (1.8945)	Acc@1 62.500 (66.615)	Acc@5 96.875 (98.886)
Epoch: [52][200/875]	Time 0.462 (0.382)	Data 0.007 (0.013)	Loss 2.2392 (2.2232)	Loss@kd 1.8580 (1.9007)	Acc@1 68.750 (66.325)	Acc@5 95.312 (98.609)
Epoch: [52][300/875]	Time 0.352 (0.376)	Data 0.007 (0.011)	Loss 2.1845 (2.2239)	Loss@kd 1.8325 (1.8985)	Acc@1 73.438 (66.497)	Acc@5 95.312 (98.541)
Epoch: [52][400/875]	Time 0.359 (0.378)	Data 0.007 (0.010)	Loss 2.1034 (2.2178)	Loss@kd 1.8568 (1.8941)	Acc@1 68.750 (66.661)	Acc@5 98.438 (98.480)
Epoch: [52][500/875]	Time 0.417 (0.380)	Data 0.009 (0.009)	Loss 2.2471 (2.2173)	Loss@kd 1.9183 (1.8944)	Acc@1 64.062 (66.717)	Acc@5 98.438 (98.453)
Epoch: [52][600/875]	Time 0.361 (0.380)	Data 0.007 (0.009)	Loss 2.1918 (2.2161)	Loss@kd 1.9167 (1.8938)	Acc@1 75.000 (66.813)	Acc@5 98.438 (98.453)
Epoch: [52][700/875]	Time 0.363 (0.380)	Data 0.007 (0.009)	Loss 1.8891 (2.2159)	Loss@kd 1.8541 (1.8944)	Acc@1 75.000 (66.826)	Acc@5 100.000 (98.422)
Epoch: [52][800/875]	Time 0.343 (0.382)	Data 0.007 (0.008)	Loss 2.0391 (2.2169)	Loss@kd 1.9370 (1.8932)	Acc@1 76.562 (66.782)	Acc@5 100.000 (98.418)
 * Acc@1 66.854 Acc@5 98.425
epoch 52, total time 335.31
Test: [0/750]	Time 0.733 (0.733)	Loss 0.5420 (0.5420)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.103 (0.117)	Loss 0.6340 (0.5404)	Acc@1 75.000 (83.509)	Acc@5 100.000 (92.915)
Test: [200/750]	Time 0.097 (0.111)	Loss 1.2562 (0.5886)	Acc@1 53.125 (79.944)	Acc@5 87.500 (94.636)
Test: [300/750]	Time 0.118 (0.110)	Loss 0.9541 (0.8007)	Acc@1 62.500 (70.089)	Acc@5 100.000 (93.802)
Test: [400/750]	Time 0.097 (0.109)	Loss 0.6432 (0.8506)	Acc@1 81.250 (67.885)	Acc@5 90.625 (93.680)
Test: [500/750]	Time 0.113 (0.109)	Loss 0.4440 (0.8297)	Acc@1 84.375 (69.199)	Acc@5 100.000 (93.288)
Test: [600/750]	Time 0.113 (0.108)	Loss 0.9578 (0.8305)	Acc@1 71.875 (69.629)	Acc@5 90.625 (93.240)
Test: [700/750]	Time 0.108 (0.108)	Loss 1.8555 (0.8686)	Acc@1 34.375 (68.050)	Acc@5 65.625 (92.832)
 * Acc@1 66.988 Acc@5 92.371
==> training...
Epoch: [53][0/875]	Time 1.757 (1.757)	Data 1.260 (1.260)	Loss 2.0292 (2.0292)	Loss@kd 1.8652 (1.8652)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [53][100/875]	Time 0.356 (0.404)	Data 0.006 (0.019)	Loss 2.2828 (2.1929)	Loss@kd 1.8922 (1.8932)	Acc@1 60.938 (68.147)	Acc@5 96.875 (98.453)
Epoch: [53][200/875]	Time 0.392 (0.397)	Data 0.006 (0.013)	Loss 2.4063 (2.2051)	Loss@kd 1.9379 (1.8902)	Acc@1 68.750 (67.390)	Acc@5 98.438 (98.484)
Epoch: [53][300/875]	Time 0.371 (0.394)	Data 0.008 (0.011)	Loss 2.1782 (2.2010)	Loss@kd 1.8004 (1.8867)	Acc@1 68.750 (67.509)	Acc@5 96.875 (98.432)
Epoch: [53][400/875]	Time 0.363 (0.393)	Data 0.005 (0.010)	Loss 2.2580 (2.1974)	Loss@kd 1.8213 (1.8869)	Acc@1 60.938 (67.456)	Acc@5 95.312 (98.488)
Epoch: [53][500/875]	Time 0.384 (0.392)	Data 0.007 (0.009)	Loss 2.2078 (2.2035)	Loss@kd 1.8202 (1.8877)	Acc@1 64.062 (67.206)	Acc@5 100.000 (98.453)
Epoch: [53][600/875]	Time 0.343 (0.389)	Data 0.005 (0.009)	Loss 2.1835 (2.2059)	Loss@kd 1.9671 (1.8870)	Acc@1 68.750 (67.071)	Acc@5 100.000 (98.458)
Epoch: [53][700/875]	Time 0.375 (0.386)	Data 0.007 (0.009)	Loss 2.2052 (2.2044)	Loss@kd 1.8661 (1.8862)	Acc@1 67.188 (67.190)	Acc@5 98.438 (98.455)
Epoch: [53][800/875]	Time 0.371 (0.384)	Data 0.007 (0.009)	Loss 2.2363 (2.2045)	Loss@kd 1.9296 (1.8855)	Acc@1 70.312 (67.182)	Acc@5 100.000 (98.455)
 * Acc@1 67.037 Acc@5 98.438
epoch 53, total time 336.79
Test: [0/750]	Time 0.736 (0.736)	Loss 0.6247 (0.6247)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.086 (0.115)	Loss 0.6953 (0.5070)	Acc@1 65.625 (83.292)	Acc@5 100.000 (92.574)
Test: [200/750]	Time 0.096 (0.108)	Loss 1.3322 (0.5987)	Acc@1 53.125 (78.001)	Acc@5 90.625 (94.450)
Test: [300/750]	Time 0.104 (0.108)	Loss 1.2431 (0.8157)	Acc@1 53.125 (68.553)	Acc@5 90.625 (93.978)
Test: [400/750]	Time 0.105 (0.107)	Loss 0.7499 (0.8897)	Acc@1 71.875 (65.243)	Acc@5 90.625 (93.524)
Test: [500/750]	Time 0.109 (0.107)	Loss 0.7757 (0.8930)	Acc@1 75.000 (66.255)	Acc@5 93.750 (92.353)
Test: [600/750]	Time 0.110 (0.106)	Loss 1.0008 (0.9014)	Acc@1 62.500 (66.623)	Acc@5 87.500 (92.081)
Test: [700/750]	Time 0.106 (0.106)	Loss 1.4365 (0.9063)	Acc@1 50.000 (66.753)	Acc@5 81.250 (91.980)
 * Acc@1 66.713 Acc@5 91.904
==> training...
Epoch: [54][0/875]	Time 1.705 (1.705)	Data 1.182 (1.182)	Loss 2.2649 (2.2649)	Loss@kd 1.9116 (1.9116)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [54][100/875]	Time 0.366 (0.404)	Data 0.007 (0.018)	Loss 2.4121 (2.1679)	Loss@kd 1.8274 (1.8731)	Acc@1 57.812 (67.915)	Acc@5 98.438 (98.855)
Epoch: [54][200/875]	Time 0.377 (0.396)	Data 0.007 (0.013)	Loss 2.3732 (2.1921)	Loss@kd 1.8781 (1.8813)	Acc@1 60.938 (67.390)	Acc@5 100.000 (98.640)
Epoch: [54][300/875]	Time 0.361 (0.394)	Data 0.007 (0.011)	Loss 2.1518 (2.1869)	Loss@kd 1.7894 (1.8814)	Acc@1 71.875 (67.743)	Acc@5 98.438 (98.541)
Epoch: [54][400/875]	Time 0.394 (0.392)	Data 0.007 (0.010)	Loss 2.3695 (2.1880)	Loss@kd 1.9117 (1.8799)	Acc@1 62.500 (67.562)	Acc@5 100.000 (98.582)
Epoch: [54][500/875]	Time 0.399 (0.391)	Data 0.007 (0.009)	Loss 2.2814 (2.1879)	Loss@kd 1.8523 (1.8787)	Acc@1 56.250 (67.559)	Acc@5 100.000 (98.559)
Epoch: [54][600/875]	Time 0.384 (0.390)	Data 0.007 (0.009)	Loss 2.0494 (2.1904)	Loss@kd 1.8468 (1.8801)	Acc@1 71.875 (67.473)	Acc@5 100.000 (98.557)
Epoch: [54][700/875]	Time 0.355 (0.389)	Data 0.007 (0.009)	Loss 2.2713 (2.1919)	Loss@kd 1.8461 (1.8801)	Acc@1 59.375 (67.381)	Acc@5 98.438 (98.527)
Epoch: [54][800/875]	Time 0.409 (0.389)	Data 0.007 (0.008)	Loss 2.2419 (2.1941)	Loss@kd 1.8244 (1.8798)	Acc@1 62.500 (67.396)	Acc@5 96.875 (98.512)
 * Acc@1 67.312 Acc@5 98.487
epoch 54, total time 340.60
Test: [0/750]	Time 0.699 (0.699)	Loss 0.5369 (0.5369)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.101 (0.113)	Loss 0.5093 (0.4918)	Acc@1 71.875 (84.746)	Acc@5 100.000 (92.636)
Test: [200/750]	Time 0.114 (0.108)	Loss 1.3422 (0.5375)	Acc@1 50.000 (81.732)	Acc@5 96.875 (94.947)
Test: [300/750]	Time 0.104 (0.107)	Loss 1.5211 (0.8034)	Acc@1 34.375 (70.982)	Acc@5 84.375 (93.200)
Test: [400/750]	Time 0.075 (0.106)	Loss 0.6651 (0.9362)	Acc@1 81.250 (63.926)	Acc@5 87.500 (92.051)
Test: [500/750]	Time 0.110 (0.105)	Loss 0.8961 (0.9206)	Acc@1 75.000 (65.506)	Acc@5 96.875 (91.754)
Test: [600/750]	Time 0.175 (0.105)	Loss 0.7333 (0.9322)	Acc@1 71.875 (65.469)	Acc@5 96.875 (91.852)
Test: [700/750]	Time 0.091 (0.105)	Loss 1.3756 (0.9280)	Acc@1 65.625 (65.496)	Acc@5 78.125 (92.025)
 * Acc@1 65.200 Acc@5 91.700
==> training...
Epoch: [55][0/875]	Time 1.810 (1.810)	Data 1.327 (1.327)	Loss 2.2923 (2.2923)	Loss@kd 1.7828 (1.7828)	Acc@1 59.375 (59.375)	Acc@5 98.438 (98.438)
Epoch: [55][100/875]	Time 0.357 (0.386)	Data 0.007 (0.020)	Loss 2.2358 (2.1937)	Loss@kd 1.8615 (1.8885)	Acc@1 68.750 (67.713)	Acc@5 95.312 (98.546)
Epoch: [55][200/875]	Time 0.362 (0.380)	Data 0.007 (0.013)	Loss 2.1780 (2.1892)	Loss@kd 1.8028 (1.8854)	Acc@1 64.062 (67.669)	Acc@5 96.875 (98.453)
Epoch: [55][300/875]	Time 0.399 (0.383)	Data 0.005 (0.011)	Loss 2.1092 (2.1928)	Loss@kd 1.8498 (1.8813)	Acc@1 70.312 (67.406)	Acc@5 98.438 (98.489)
Epoch: [55][400/875]	Time 0.387 (0.385)	Data 0.007 (0.010)	Loss 2.2840 (2.1908)	Loss@kd 1.8841 (1.8771)	Acc@1 65.625 (67.339)	Acc@5 98.438 (98.535)
Epoch: [55][500/875]	Time 0.376 (0.386)	Data 0.007 (0.009)	Loss 1.9920 (2.1855)	Loss@kd 1.8624 (1.8755)	Acc@1 75.000 (67.615)	Acc@5 98.438 (98.525)
Epoch: [55][600/875]	Time 0.392 (0.386)	Data 0.007 (0.009)	Loss 2.3446 (2.1840)	Loss@kd 1.9224 (1.8733)	Acc@1 65.625 (67.681)	Acc@5 95.312 (98.518)
Epoch: [55][700/875]	Time 0.363 (0.387)	Data 0.008 (0.009)	Loss 2.3322 (2.1849)	Loss@kd 1.9071 (1.8731)	Acc@1 64.062 (67.615)	Acc@5 98.438 (98.507)
Epoch: [55][800/875]	Time 0.366 (0.388)	Data 0.007 (0.009)	Loss 2.3839 (2.1872)	Loss@kd 1.8697 (1.8738)	Acc@1 59.375 (67.593)	Acc@5 98.438 (98.516)
 * Acc@1 67.686 Acc@5 98.525
epoch 55, total time 339.65
Test: [0/750]	Time 0.892 (0.892)	Loss 0.8277 (0.8277)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.118 (0.115)	Loss 0.4425 (0.6208)	Acc@1 84.375 (82.054)	Acc@5 96.875 (92.234)
Test: [200/750]	Time 0.109 (0.109)	Loss 0.8474 (0.5596)	Acc@1 68.750 (82.572)	Acc@5 96.875 (94.667)
Test: [300/750]	Time 0.110 (0.109)	Loss 1.1179 (0.7213)	Acc@1 43.750 (74.730)	Acc@5 93.750 (94.736)
Test: [400/750]	Time 0.114 (0.108)	Loss 0.8367 (0.8585)	Acc@1 81.250 (67.597)	Acc@5 84.375 (93.672)
Test: [500/750]	Time 0.096 (0.108)	Loss 0.4307 (0.8745)	Acc@1 87.500 (68.008)	Acc@5 100.000 (92.453)
Test: [600/750]	Time 0.101 (0.108)	Loss 1.0795 (0.8696)	Acc@1 68.750 (68.532)	Acc@5 87.500 (92.601)
Test: [700/750]	Time 0.097 (0.108)	Loss 1.5202 (0.9015)	Acc@1 43.750 (67.101)	Acc@5 90.625 (92.551)
 * Acc@1 66.600 Acc@5 92.446
==> training...
Epoch: [56][0/875]	Time 1.678 (1.678)	Data 1.305 (1.305)	Loss 1.9985 (1.9985)	Loss@kd 1.8328 (1.8328)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [56][100/875]	Time 0.335 (0.403)	Data 0.005 (0.020)	Loss 2.3388 (2.1712)	Loss@kd 1.9197 (1.8710)	Acc@1 64.062 (67.930)	Acc@5 96.875 (98.716)
Epoch: [56][200/875]	Time 0.390 (0.395)	Data 0.007 (0.013)	Loss 1.8932 (2.1703)	Loss@kd 1.8111 (1.8689)	Acc@1 78.125 (67.809)	Acc@5 100.000 (98.640)
Epoch: [56][300/875]	Time 0.460 (0.391)	Data 0.007 (0.011)	Loss 2.1663 (2.1704)	Loss@kd 1.8332 (1.8679)	Acc@1 64.062 (67.821)	Acc@5 96.875 (98.614)
Epoch: [56][400/875]	Time 0.361 (0.387)	Data 0.007 (0.010)	Loss 2.2621 (2.1720)	Loss@kd 1.9972 (1.8645)	Acc@1 68.750 (67.694)	Acc@5 100.000 (98.683)
Epoch: [56][500/875]	Time 0.367 (0.384)	Data 0.007 (0.010)	Loss 2.1188 (2.1724)	Loss@kd 1.8611 (1.8634)	Acc@1 62.500 (67.590)	Acc@5 100.000 (98.659)
Epoch: [56][600/875]	Time 0.371 (0.382)	Data 0.008 (0.009)	Loss 1.9713 (2.1749)	Loss@kd 1.8834 (1.8647)	Acc@1 76.562 (67.471)	Acc@5 98.438 (98.601)
Epoch: [56][700/875]	Time 0.395 (0.381)	Data 0.007 (0.009)	Loss 2.2095 (2.1792)	Loss@kd 1.8170 (1.8651)	Acc@1 64.062 (67.330)	Acc@5 98.438 (98.569)
Epoch: [56][800/875]	Time 0.366 (0.382)	Data 0.007 (0.009)	Loss 2.0730 (2.1794)	Loss@kd 1.8125 (1.8654)	Acc@1 73.438 (67.377)	Acc@5 100.000 (98.545)
 * Acc@1 67.425 Acc@5 98.545
epoch 56, total time 335.24
Test: [0/750]	Time 0.710 (0.710)	Loss 0.6641 (0.6641)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/750]	Time 0.117 (0.115)	Loss 0.3326 (0.5224)	Acc@1 84.375 (84.097)	Acc@5 100.000 (92.358)
Test: [200/750]	Time 0.098 (0.109)	Loss 1.2759 (0.4814)	Acc@1 46.875 (84.002)	Acc@5 90.625 (94.963)
Test: [300/750]	Time 0.100 (0.109)	Loss 1.0330 (0.6933)	Acc@1 50.000 (74.907)	Acc@5 96.875 (94.591)
Test: [400/750]	Time 0.092 (0.107)	Loss 0.9574 (0.8121)	Acc@1 71.875 (69.038)	Acc@5 87.500 (94.038)
Test: [500/750]	Time 0.112 (0.107)	Loss 0.8218 (0.8410)	Acc@1 75.000 (68.594)	Acc@5 93.750 (93.332)
Test: [600/750]	Time 0.084 (0.106)	Loss 1.1680 (0.8820)	Acc@1 53.125 (67.705)	Acc@5 90.625 (92.720)
Test: [700/750]	Time 0.093 (0.106)	Loss 1.4583 (0.9116)	Acc@1 50.000 (66.387)	Acc@5 87.500 (92.524)
 * Acc@1 66.050 Acc@5 92.321
==> training...
Epoch: [57][0/875]	Time 1.706 (1.706)	Data 1.190 (1.190)	Loss 1.9494 (1.9494)	Loss@kd 1.8593 (1.8593)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Epoch: [57][100/875]	Time 0.430 (0.401)	Data 0.007 (0.019)	Loss 2.1325 (2.1642)	Loss@kd 1.8846 (1.8628)	Acc@1 68.750 (68.626)	Acc@5 100.000 (98.283)
Epoch: [57][200/875]	Time 0.371 (0.395)	Data 0.007 (0.013)	Loss 2.0102 (2.1710)	Loss@kd 1.8386 (1.8607)	Acc@1 70.312 (67.988)	Acc@5 100.000 (98.422)
Epoch: [57][300/875]	Time 0.386 (0.393)	Data 0.007 (0.011)	Loss 2.1889 (2.1702)	Loss@kd 1.8262 (1.8604)	Acc@1 64.062 (67.992)	Acc@5 98.438 (98.396)
Epoch: [57][400/875]	Time 0.390 (0.391)	Data 0.007 (0.010)	Loss 2.1997 (2.1718)	Loss@kd 1.7657 (1.8607)	Acc@1 62.500 (67.955)	Acc@5 100.000 (98.422)
Epoch: [57][500/875]	Time 0.371 (0.391)	Data 0.007 (0.009)	Loss 2.4107 (2.1711)	Loss@kd 1.8686 (1.8597)	Acc@1 65.625 (67.933)	Acc@5 95.312 (98.428)
Epoch: [57][600/875]	Time 0.397 (0.391)	Data 0.007 (0.009)	Loss 2.0731 (2.1717)	Loss@kd 1.7457 (1.8603)	Acc@1 75.000 (67.882)	Acc@5 98.438 (98.469)
Epoch: [57][700/875]	Time 0.381 (0.391)	Data 0.007 (0.009)	Loss 2.1468 (2.1716)	Loss@kd 1.9128 (1.8601)	Acc@1 70.312 (67.923)	Acc@5 100.000 (98.460)
Epoch: [57][800/875]	Time 0.405 (0.391)	Data 0.008 (0.008)	Loss 2.2022 (2.1705)	Loss@kd 1.8852 (1.8596)	Acc@1 71.875 (67.894)	Acc@5 96.875 (98.482)
 * Acc@1 67.752 Acc@5 98.496
epoch 57, total time 341.44
Test: [0/750]	Time 0.788 (0.788)	Loss 0.4745 (0.4745)	Acc@1 87.500 (87.500)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.097 (0.113)	Loss 0.8495 (0.5078)	Acc@1 56.250 (84.870)	Acc@5 100.000 (92.389)
Test: [200/750]	Time 0.096 (0.107)	Loss 1.4021 (0.6098)	Acc@1 46.875 (77.907)	Acc@5 90.625 (94.496)
Test: [300/750]	Time 0.104 (0.106)	Loss 1.4637 (0.8678)	Acc@1 43.750 (67.400)	Acc@5 87.500 (92.276)
Test: [400/750]	Time 0.094 (0.104)	Loss 0.4878 (0.9557)	Acc@1 87.500 (63.053)	Acc@5 93.750 (91.849)
Test: [500/750]	Time 0.145 (0.104)	Loss 1.0164 (0.9205)	Acc@1 53.125 (65.195)	Acc@5 96.875 (91.885)
Test: [600/750]	Time 0.106 (0.103)	Loss 0.7192 (0.9301)	Acc@1 71.875 (65.303)	Acc@5 93.750 (91.712)
Test: [700/750]	Time 0.098 (0.104)	Loss 1.6781 (0.9354)	Acc@1 43.750 (65.233)	Acc@5 81.250 (91.766)
 * Acc@1 64.125 Acc@5 91.254
==> training...
Epoch: [58][0/875]	Time 1.538 (1.538)	Data 1.109 (1.109)	Loss 2.1390 (2.1390)	Loss@kd 1.8812 (1.8812)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [58][100/875]	Time 0.401 (0.386)	Data 0.007 (0.018)	Loss 1.9850 (2.1577)	Loss@kd 1.7406 (1.8584)	Acc@1 65.625 (67.915)	Acc@5 98.438 (98.778)
Epoch: [58][200/875]	Time 0.351 (0.381)	Data 0.007 (0.012)	Loss 2.0612 (2.1636)	Loss@kd 1.8666 (1.8609)	Acc@1 70.312 (67.864)	Acc@5 100.000 (98.632)
Epoch: [58][300/875]	Time 0.377 (0.381)	Data 0.007 (0.010)	Loss 2.3118 (2.1620)	Loss@kd 1.9675 (1.8620)	Acc@1 60.938 (68.226)	Acc@5 98.438 (98.614)
Epoch: [58][400/875]	Time 0.378 (0.383)	Data 0.009 (0.010)	Loss 1.9886 (2.1569)	Loss@kd 1.7883 (1.8582)	Acc@1 79.688 (68.501)	Acc@5 98.438 (98.621)
Epoch: [58][500/875]	Time 0.394 (0.384)	Data 0.007 (0.009)	Loss 2.0916 (2.1609)	Loss@kd 1.8252 (1.8560)	Acc@1 71.875 (68.335)	Acc@5 100.000 (98.568)
Epoch: [58][600/875]	Time 0.375 (0.385)	Data 0.007 (0.009)	Loss 2.1971 (2.1584)	Loss@kd 1.8493 (1.8548)	Acc@1 68.750 (68.394)	Acc@5 100.000 (98.599)
Epoch: [58][700/875]	Time 0.381 (0.386)	Data 0.007 (0.008)	Loss 2.1952 (2.1592)	Loss@kd 1.8128 (1.8527)	Acc@1 65.625 (68.253)	Acc@5 98.438 (98.596)
Epoch: [58][800/875]	Time 0.378 (0.386)	Data 0.010 (0.008)	Loss 2.1854 (2.1612)	Loss@kd 1.8071 (1.8523)	Acc@1 64.062 (68.081)	Acc@5 96.875 (98.584)
 * Acc@1 68.018 Acc@5 98.580
epoch 58, total time 338.37
Test: [0/750]	Time 0.824 (0.824)	Loss 0.6206 (0.6206)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.101 (0.115)	Loss 0.6664 (0.5154)	Acc@1 78.125 (84.561)	Acc@5 93.750 (93.286)
Test: [200/750]	Time 0.096 (0.111)	Loss 1.1528 (0.5818)	Acc@1 40.625 (81.390)	Acc@5 100.000 (94.310)
Test: [300/750]	Time 0.107 (0.111)	Loss 0.9046 (0.7944)	Acc@1 68.750 (70.743)	Acc@5 96.875 (94.020)
Test: [400/750]	Time 0.103 (0.110)	Loss 0.6434 (0.8433)	Acc@1 81.250 (68.119)	Acc@5 87.500 (93.844)
Test: [500/750]	Time 0.178 (0.110)	Loss 0.5752 (0.8315)	Acc@1 75.000 (69.268)	Acc@5 96.875 (93.189)
Test: [600/750]	Time 0.101 (0.109)	Loss 1.4048 (0.8577)	Acc@1 53.125 (68.615)	Acc@5 87.500 (92.648)
Test: [700/750]	Time 0.089 (0.109)	Loss 0.9525 (0.8962)	Acc@1 62.500 (66.695)	Acc@5 87.500 (92.404)
 * Acc@1 66.554 Acc@5 92.442
==> training...
Epoch: [59][0/875]	Time 1.655 (1.655)	Data 1.155 (1.155)	Loss 2.1253 (2.1253)	Loss@kd 1.8290 (1.8290)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [59][100/875]	Time 0.390 (0.402)	Data 0.007 (0.018)	Loss 2.0718 (2.1609)	Loss@kd 1.8654 (1.8505)	Acc@1 73.438 (67.373)	Acc@5 100.000 (98.700)
Epoch: [59][200/875]	Time 0.366 (0.396)	Data 0.007 (0.013)	Loss 2.0348 (2.1472)	Loss@kd 1.8183 (1.8433)	Acc@1 79.688 (68.050)	Acc@5 100.000 (98.702)
Epoch: [59][300/875]	Time 0.334 (0.389)	Data 0.005 (0.011)	Loss 2.4201 (2.1450)	Loss@kd 1.8565 (1.8434)	Acc@1 60.938 (68.314)	Acc@5 98.438 (98.656)
Epoch: [59][400/875]	Time 0.359 (0.385)	Data 0.007 (0.010)	Loss 1.9734 (2.1504)	Loss@kd 1.7970 (1.8480)	Acc@1 71.875 (68.310)	Acc@5 98.438 (98.632)
Epoch: [59][500/875]	Time 0.358 (0.382)	Data 0.006 (0.009)	Loss 2.1834 (2.1510)	Loss@kd 1.9166 (1.8471)	Acc@1 68.750 (68.288)	Acc@5 100.000 (98.606)
Epoch: [59][600/875]	Time 0.410 (0.382)	Data 0.007 (0.009)	Loss 2.3307 (2.1517)	Loss@kd 1.9038 (1.8485)	Acc@1 62.500 (68.246)	Acc@5 95.312 (98.567)
Epoch: [59][700/875]	Time 0.363 (0.383)	Data 0.007 (0.009)	Loss 2.1868 (2.1518)	Loss@kd 1.8298 (1.8478)	Acc@1 60.938 (68.153)	Acc@5 98.438 (98.580)
Epoch: [59][800/875]	Time 0.366 (0.383)	Data 0.005 (0.008)	Loss 2.2346 (2.1554)	Loss@kd 2.0594 (1.8474)	Acc@1 70.312 (67.962)	Acc@5 98.438 (98.578)
 * Acc@1 68.105 Acc@5 98.595
epoch 59, total time 336.04
Test: [0/750]	Time 0.892 (0.892)	Loss 0.4307 (0.4307)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.093 (0.111)	Loss 0.5946 (0.4982)	Acc@1 75.000 (83.725)	Acc@5 100.000 (93.472)
Test: [200/750]	Time 0.073 (0.106)	Loss 1.6854 (0.5760)	Acc@1 21.875 (79.073)	Acc@5 81.250 (94.621)
Test: [300/750]	Time 0.106 (0.105)	Loss 1.3869 (0.8984)	Acc@1 46.875 (64.390)	Acc@5 96.875 (91.809)
Test: [400/750]	Time 0.120 (0.104)	Loss 0.6622 (0.9452)	Acc@1 75.000 (62.975)	Acc@5 96.875 (92.324)
Test: [500/750]	Time 0.178 (0.104)	Loss 0.7796 (0.9305)	Acc@1 71.875 (64.508)	Acc@5 100.000 (91.947)
Test: [600/750]	Time 0.095 (0.103)	Loss 0.8500 (0.9428)	Acc@1 71.875 (64.741)	Acc@5 93.750 (91.493)
Test: [700/750]	Time 0.113 (0.104)	Loss 1.1231 (0.9321)	Acc@1 62.500 (65.148)	Acc@5 87.500 (91.731)
 * Acc@1 65.333 Acc@5 91.688
==> training...
Epoch: [60][0/875]	Time 1.687 (1.687)	Data 1.172 (1.172)	Loss 1.9850 (1.9850)	Loss@kd 1.7917 (1.7917)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Epoch: [60][100/875]	Time 0.377 (0.400)	Data 0.007 (0.018)	Loss 2.7020 (2.1591)	Loss@kd 2.0087 (1.8479)	Acc@1 56.250 (68.085)	Acc@5 93.750 (98.407)
Epoch: [60][200/875]	Time 0.396 (0.396)	Data 0.007 (0.013)	Loss 2.0726 (2.1543)	Loss@kd 1.8755 (1.8500)	Acc@1 73.438 (68.385)	Acc@5 100.000 (98.554)
Epoch: [60][300/875]	Time 0.368 (0.395)	Data 0.008 (0.011)	Loss 2.1508 (2.1453)	Loss@kd 1.9113 (1.8513)	Acc@1 73.438 (68.750)	Acc@5 100.000 (98.583)
Epoch: [60][400/875]	Time 0.367 (0.393)	Data 0.007 (0.010)	Loss 1.9139 (2.1460)	Loss@kd 1.7837 (1.8468)	Acc@1 75.000 (68.586)	Acc@5 100.000 (98.582)
Epoch: [60][500/875]	Time 0.411 (0.393)	Data 0.007 (0.009)	Loss 2.0030 (2.1462)	Loss@kd 1.7724 (1.8459)	Acc@1 75.000 (68.631)	Acc@5 100.000 (98.581)
Epoch: [60][600/875]	Time 0.372 (0.393)	Data 0.007 (0.009)	Loss 2.1292 (2.1476)	Loss@kd 1.8345 (1.8443)	Acc@1 67.188 (68.381)	Acc@5 100.000 (98.560)
Epoch: [60][700/875]	Time 0.381 (0.392)	Data 0.007 (0.009)	Loss 2.0978 (2.1461)	Loss@kd 1.8301 (1.8426)	Acc@1 71.875 (68.273)	Acc@5 98.438 (98.576)
Epoch: [60][800/875]	Time 0.376 (0.390)	Data 0.007 (0.008)	Loss 2.1507 (2.1470)	Loss@kd 1.8143 (1.8420)	Acc@1 68.750 (68.182)	Acc@5 96.875 (98.599)
 * Acc@1 68.198 Acc@5 98.580
epoch 60, total time 340.02
Test: [0/750]	Time 0.758 (0.758)	Loss 0.6122 (0.6122)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.074 (0.111)	Loss 0.6890 (0.6210)	Acc@1 75.000 (80.755)	Acc@5 96.875 (91.863)
Test: [200/750]	Time 0.082 (0.106)	Loss 1.3405 (0.7262)	Acc@1 43.750 (74.767)	Acc@5 100.000 (93.221)
Test: [300/750]	Time 0.082 (0.105)	Loss 1.2881 (0.9687)	Acc@1 62.500 (63.559)	Acc@5 93.750 (92.265)
Test: [400/750]	Time 0.104 (0.104)	Loss 0.6273 (1.0226)	Acc@1 71.875 (60.832)	Acc@5 100.000 (92.262)
Test: [500/750]	Time 0.172 (0.102)	Loss 0.5518 (0.9751)	Acc@1 75.000 (63.367)	Acc@5 100.000 (92.091)
Test: [600/750]	Time 0.087 (0.101)	Loss 0.7369 (0.9499)	Acc@1 75.000 (64.980)	Acc@5 93.750 (91.951)
Test: [700/750]	Time 0.095 (0.102)	Loss 0.7777 (0.9214)	Acc@1 75.000 (66.133)	Acc@5 90.625 (92.364)
 * Acc@1 66.900 Acc@5 92.583
==> training...
Epoch: [61][0/875]	Time 1.731 (1.731)	Data 1.265 (1.265)	Loss 1.9648 (1.9648)	Loss@kd 1.8113 (1.8113)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [61][100/875]	Time 0.374 (0.401)	Data 0.007 (0.019)	Loss 1.9984 (2.1146)	Loss@kd 1.7694 (1.8196)	Acc@1 71.875 (68.905)	Acc@5 98.438 (98.623)
Epoch: [61][200/875]	Time 0.384 (0.395)	Data 0.008 (0.013)	Loss 2.1571 (2.1256)	Loss@kd 1.7662 (1.8306)	Acc@1 65.625 (68.734)	Acc@5 98.438 (98.609)
Epoch: [61][300/875]	Time 0.362 (0.392)	Data 0.007 (0.011)	Loss 2.1848 (2.1352)	Loss@kd 1.7700 (1.8367)	Acc@1 60.938 (68.693)	Acc@5 100.000 (98.562)
Epoch: [61][400/875]	Time 0.409 (0.391)	Data 0.007 (0.010)	Loss 2.3806 (2.1345)	Loss@kd 1.8789 (1.8371)	Acc@1 54.688 (68.715)	Acc@5 98.438 (98.609)
Epoch: [61][500/875]	Time 0.407 (0.391)	Data 0.007 (0.009)	Loss 2.3132 (2.1357)	Loss@kd 1.8575 (1.8371)	Acc@1 67.188 (68.635)	Acc@5 98.438 (98.593)
Epoch: [61][600/875]	Time 0.373 (0.390)	Data 0.007 (0.009)	Loss 2.1643 (2.1394)	Loss@kd 1.9639 (1.8370)	Acc@1 71.875 (68.485)	Acc@5 95.312 (98.604)
Epoch: [61][700/875]	Time 0.388 (0.390)	Data 0.007 (0.009)	Loss 1.9493 (2.1384)	Loss@kd 1.8255 (1.8375)	Acc@1 70.312 (68.516)	Acc@5 96.875 (98.643)
Epoch: [61][800/875]	Time 0.380 (0.390)	Data 0.007 (0.009)	Loss 2.3837 (2.1378)	Loss@kd 1.8566 (1.8371)	Acc@1 62.500 (68.537)	Acc@5 98.438 (98.636)
 * Acc@1 68.593 Acc@5 98.650
epoch 61, total time 341.54
Test: [0/750]	Time 0.823 (0.823)	Loss 0.5186 (0.5186)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.103 (0.114)	Loss 0.5715 (0.5790)	Acc@1 75.000 (82.085)	Acc@5 100.000 (92.667)
Test: [200/750]	Time 0.081 (0.107)	Loss 1.2669 (0.6092)	Acc@1 46.875 (78.560)	Acc@5 90.625 (94.776)
Test: [300/750]	Time 0.106 (0.106)	Loss 1.4395 (0.8591)	Acc@1 40.625 (68.241)	Acc@5 90.625 (92.951)
Test: [400/750]	Time 0.080 (0.104)	Loss 0.7247 (0.9666)	Acc@1 78.125 (63.256)	Acc@5 84.375 (91.810)
Test: [500/750]	Time 0.175 (0.104)	Loss 0.4897 (0.9284)	Acc@1 87.500 (65.538)	Acc@5 100.000 (91.536)
Test: [600/750]	Time 0.092 (0.103)	Loss 0.6181 (0.9111)	Acc@1 78.125 (66.613)	Acc@5 96.875 (91.790)
Test: [700/750]	Time 0.086 (0.103)	Loss 1.4175 (0.8972)	Acc@1 50.000 (67.257)	Acc@5 81.250 (92.074)
 * Acc@1 67.208 Acc@5 91.933
==> training...
Epoch: [62][0/875]	Time 1.710 (1.710)	Data 1.192 (1.192)	Loss 1.9478 (1.9478)	Loss@kd 1.8346 (1.8346)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [62][100/875]	Time 0.385 (0.401)	Data 0.007 (0.018)	Loss 2.1591 (2.0930)	Loss@kd 1.8134 (1.8264)	Acc@1 68.750 (69.941)	Acc@5 95.312 (98.855)
Epoch: [62][200/875]	Time 0.357 (0.388)	Data 0.007 (0.013)	Loss 2.1975 (2.1157)	Loss@kd 2.0568 (1.8332)	Acc@1 75.000 (69.178)	Acc@5 100.000 (98.663)
Epoch: [62][300/875]	Time 0.361 (0.382)	Data 0.007 (0.011)	Loss 2.2983 (2.1188)	Loss@kd 1.8132 (1.8311)	Acc@1 60.938 (69.056)	Acc@5 96.875 (98.619)
Epoch: [62][400/875]	Time 0.369 (0.379)	Data 0.007 (0.010)	Loss 2.2524 (2.1129)	Loss@kd 1.8985 (1.8292)	Acc@1 75.000 (69.120)	Acc@5 93.750 (98.640)
Epoch: [62][500/875]	Time 0.356 (0.381)	Data 0.007 (0.009)	Loss 2.1135 (2.1179)	Loss@kd 1.8349 (1.8283)	Acc@1 73.438 (68.787)	Acc@5 96.875 (98.615)
Epoch: [62][600/875]	Time 0.398 (0.381)	Data 0.007 (0.009)	Loss 2.1374 (2.1227)	Loss@kd 1.7931 (1.8288)	Acc@1 67.188 (68.633)	Acc@5 100.000 (98.643)
Epoch: [62][700/875]	Time 0.388 (0.383)	Data 0.008 (0.009)	Loss 2.1807 (2.1263)	Loss@kd 1.7764 (1.8284)	Acc@1 65.625 (68.440)	Acc@5 100.000 (98.640)
Epoch: [62][800/875]	Time 0.384 (0.384)	Data 0.007 (0.008)	Loss 2.2006 (2.1259)	Loss@kd 1.8784 (1.8278)	Acc@1 62.500 (68.409)	Acc@5 96.875 (98.629)
 * Acc@1 68.366 Acc@5 98.618
epoch 62, total time 336.67
Test: [0/750]	Time 0.921 (0.921)	Loss 0.5744 (0.5744)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.096 (0.115)	Loss 0.4523 (0.6372)	Acc@1 81.250 (82.519)	Acc@5 100.000 (90.780)
Test: [200/750]	Time 0.104 (0.108)	Loss 1.3252 (0.5794)	Acc@1 50.000 (81.981)	Acc@5 87.500 (94.108)
Test: [300/750]	Time 0.102 (0.107)	Loss 1.2872 (0.8215)	Acc@1 34.375 (71.107)	Acc@5 93.750 (92.556)
Test: [400/750]	Time 0.091 (0.105)	Loss 0.4772 (0.9283)	Acc@1 87.500 (65.095)	Acc@5 90.625 (92.433)
Test: [500/750]	Time 0.101 (0.105)	Loss 0.6562 (0.8935)	Acc@1 81.250 (67.178)	Acc@5 100.000 (92.290)
Test: [600/750]	Time 0.095 (0.104)	Loss 0.6388 (0.9015)	Acc@1 78.125 (67.310)	Acc@5 93.750 (92.315)
Test: [700/750]	Time 0.092 (0.104)	Loss 1.7038 (0.9101)	Acc@1 46.875 (66.927)	Acc@5 71.875 (92.408)
 * Acc@1 66.175 Acc@5 91.958
==> training...
Epoch: [63][0/875]	Time 1.595 (1.595)	Data 1.183 (1.183)	Loss 2.1060 (2.1060)	Loss@kd 1.8696 (1.8696)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [63][100/875]	Time 0.365 (0.402)	Data 0.007 (0.018)	Loss 2.0753 (2.1097)	Loss@kd 1.7731 (1.8292)	Acc@1 65.625 (69.106)	Acc@5 100.000 (98.871)
Epoch: [63][200/875]	Time 0.361 (0.395)	Data 0.007 (0.013)	Loss 2.1609 (2.1269)	Loss@kd 1.8051 (1.8358)	Acc@1 68.750 (68.711)	Acc@5 96.875 (98.741)
Epoch: [63][300/875]	Time 0.481 (0.394)	Data 0.007 (0.011)	Loss 2.1021 (2.1257)	Loss@kd 1.8141 (1.8282)	Acc@1 71.875 (68.594)	Acc@5 100.000 (98.692)
Epoch: [63][400/875]	Time 0.421 (0.393)	Data 0.007 (0.010)	Loss 2.1864 (2.1234)	Loss@kd 1.7976 (1.8270)	Acc@1 64.062 (68.567)	Acc@5 98.438 (98.663)
Epoch: [63][500/875]	Time 0.368 (0.392)	Data 0.010 (0.009)	Loss 2.1251 (2.1228)	Loss@kd 1.9174 (1.8261)	Acc@1 65.625 (68.435)	Acc@5 100.000 (98.687)
Epoch: [63][600/875]	Time 0.384 (0.391)	Data 0.007 (0.009)	Loss 2.1710 (2.1205)	Loss@kd 1.7857 (1.8257)	Acc@1 59.375 (68.526)	Acc@5 96.875 (98.664)
Epoch: [63][700/875]	Time 0.377 (0.389)	Data 0.007 (0.008)	Loss 2.1851 (2.1245)	Loss@kd 2.1783 (1.8276)	Acc@1 75.000 (68.411)	Acc@5 98.438 (98.640)
Epoch: [63][800/875]	Time 0.363 (0.387)	Data 0.007 (0.008)	Loss 2.0646 (2.1224)	Loss@kd 1.7865 (1.8274)	Acc@1 65.625 (68.491)	Acc@5 98.438 (98.638)
 * Acc@1 68.559 Acc@5 98.652
epoch 63, total time 337.34
Test: [0/750]	Time 0.612 (0.612)	Loss 0.4158 (0.4158)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.098 (0.114)	Loss 0.7110 (0.4209)	Acc@1 78.125 (86.603)	Acc@5 96.875 (94.554)
Test: [200/750]	Time 0.093 (0.109)	Loss 1.2820 (0.5338)	Acc@1 46.875 (81.623)	Acc@5 84.375 (95.538)
Test: [300/750]	Time 0.121 (0.108)	Loss 1.4521 (0.7944)	Acc@1 31.250 (70.546)	Acc@5 90.625 (94.093)
Test: [400/750]	Time 0.107 (0.106)	Loss 0.7755 (0.9348)	Acc@1 71.875 (64.355)	Acc@5 87.500 (92.721)
Test: [500/750]	Time 0.119 (0.106)	Loss 0.4673 (0.9169)	Acc@1 90.625 (66.180)	Acc@5 100.000 (92.434)
Test: [600/750]	Time 0.086 (0.106)	Loss 0.5945 (0.8979)	Acc@1 75.000 (67.174)	Acc@5 96.875 (92.575)
Test: [700/750]	Time 0.112 (0.106)	Loss 1.0452 (0.8795)	Acc@1 71.875 (67.890)	Acc@5 84.375 (92.876)
 * Acc@1 68.017 Acc@5 92.808
saving the best model!
==> training...
Epoch: [64][0/875]	Time 1.688 (1.688)	Data 1.151 (1.151)	Loss 2.2096 (2.2096)	Loss@kd 2.0024 (2.0024)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)
Epoch: [64][100/875]	Time 0.407 (0.403)	Data 0.008 (0.018)	Loss 2.2805 (2.0887)	Loss@kd 1.8042 (1.8109)	Acc@1 68.750 (69.554)	Acc@5 96.875 (98.948)
Epoch: [64][200/875]	Time 0.372 (0.396)	Data 0.007 (0.013)	Loss 1.9038 (2.1018)	Loss@kd 1.7926 (1.8191)	Acc@1 75.000 (69.178)	Acc@5 98.438 (98.803)
Epoch: [64][300/875]	Time 0.433 (0.395)	Data 0.007 (0.011)	Loss 2.0504 (2.1044)	Loss@kd 1.7727 (1.8197)	Acc@1 67.188 (69.191)	Acc@5 98.438 (98.796)
Epoch: [64][400/875]	Time 0.419 (0.393)	Data 0.005 (0.010)	Loss 2.3260 (2.1108)	Loss@kd 1.8624 (1.8188)	Acc@1 62.500 (68.984)	Acc@5 98.438 (98.734)
Epoch: [64][500/875]	Time 0.400 (0.392)	Data 0.007 (0.009)	Loss 1.9873 (2.1149)	Loss@kd 1.8327 (1.8214)	Acc@1 75.000 (68.828)	Acc@5 100.000 (98.662)
Epoch: [64][600/875]	Time 0.365 (0.392)	Data 0.007 (0.009)	Loss 2.0809 (2.1149)	Loss@kd 1.8092 (1.8198)	Acc@1 71.875 (68.807)	Acc@5 98.438 (98.664)
Epoch: [64][700/875]	Time 0.355 (0.392)	Data 0.007 (0.009)	Loss 2.0077 (2.1127)	Loss@kd 1.8434 (1.8187)	Acc@1 75.000 (68.775)	Acc@5 96.875 (98.678)
Epoch: [64][800/875]	Time 0.414 (0.391)	Data 0.006 (0.008)	Loss 2.0445 (2.1126)	Loss@kd 1.8256 (1.8179)	Acc@1 79.688 (68.750)	Acc@5 100.000 (98.687)
 * Acc@1 68.800 Acc@5 98.655
epoch 64, total time 342.66
Test: [0/750]	Time 0.846 (0.846)	Loss 0.5481 (0.5481)	Acc@1 84.375 (84.375)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.100 (0.114)	Loss 0.6723 (0.4965)	Acc@1 75.000 (84.004)	Acc@5 96.875 (93.998)
Test: [200/750]	Time 0.074 (0.107)	Loss 1.3688 (0.5883)	Acc@1 34.375 (80.333)	Acc@5 93.750 (94.496)
Test: [300/750]	Time 0.111 (0.107)	Loss 1.1530 (0.8409)	Acc@1 62.500 (68.117)	Acc@5 90.625 (93.480)
Test: [400/750]	Time 0.117 (0.105)	Loss 0.8637 (0.9140)	Acc@1 65.625 (64.939)	Acc@5 96.875 (93.368)
Test: [500/750]	Time 0.087 (0.105)	Loss 0.4943 (0.9065)	Acc@1 81.250 (66.211)	Acc@5 100.000 (92.864)
Test: [600/750]	Time 0.082 (0.104)	Loss 1.3869 (0.9189)	Acc@1 50.000 (66.426)	Acc@5 84.375 (92.284)
Test: [700/750]	Time 0.093 (0.104)	Loss 0.8253 (0.9326)	Acc@1 71.875 (66.044)	Acc@5 93.750 (91.962)
 * Acc@1 66.775 Acc@5 92.096
==> training...
Epoch: [65][0/875]	Time 1.508 (1.508)	Data 1.162 (1.162)	Loss 2.0293 (2.0293)	Loss@kd 1.7132 (1.7132)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)
Epoch: [65][100/875]	Time 0.377 (0.383)	Data 0.008 (0.018)	Loss 2.3827 (2.1074)	Loss@kd 1.8443 (1.8107)	Acc@1 60.938 (68.735)	Acc@5 95.312 (98.577)
Epoch: [65][200/875]	Time 0.341 (0.378)	Data 0.006 (0.013)	Loss 2.0917 (2.1032)	Loss@kd 1.7390 (1.8083)	Acc@1 59.375 (68.781)	Acc@5 100.000 (98.663)
Epoch: [65][300/875]	Time 0.484 (0.377)	Data 0.005 (0.011)	Loss 2.0490 (2.1028)	Loss@kd 1.7675 (1.8110)	Acc@1 65.625 (68.854)	Acc@5 100.000 (98.713)
Epoch: [65][400/875]	Time 0.370 (0.379)	Data 0.007 (0.010)	Loss 2.2167 (2.1051)	Loss@kd 1.8369 (1.8113)	Acc@1 73.438 (68.797)	Acc@5 95.312 (98.761)
Epoch: [65][500/875]	Time 0.366 (0.380)	Data 0.007 (0.009)	Loss 2.0352 (2.1043)	Loss@kd 1.7634 (1.8117)	Acc@1 65.625 (68.993)	Acc@5 98.438 (98.743)
Epoch: [65][600/875]	Time 0.373 (0.382)	Data 0.007 (0.009)	Loss 2.1486 (2.1065)	Loss@kd 1.7100 (1.8111)	Acc@1 60.938 (68.831)	Acc@5 96.875 (98.723)
Epoch: [65][700/875]	Time 0.382 (0.384)	Data 0.007 (0.009)	Loss 2.1036 (2.1101)	Loss@kd 1.7593 (1.8132)	Acc@1 65.625 (68.837)	Acc@5 100.000 (98.647)
Epoch: [65][800/875]	Time 0.398 (0.385)	Data 0.007 (0.008)	Loss 1.9647 (2.1104)	Loss@kd 1.7780 (1.8136)	Acc@1 71.875 (68.883)	Acc@5 98.438 (98.658)
 * Acc@1 68.907 Acc@5 98.657
epoch 65, total time 337.34
Test: [0/750]	Time 0.825 (0.825)	Loss 0.5797 (0.5797)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.105 (0.114)	Loss 0.7658 (0.6369)	Acc@1 71.875 (82.178)	Acc@5 96.875 (91.275)
Test: [200/750]	Time 0.092 (0.108)	Loss 1.0756 (0.6424)	Acc@1 62.500 (79.182)	Acc@5 96.875 (93.797)
Test: [300/750]	Time 0.095 (0.106)	Loss 0.9745 (0.8337)	Acc@1 59.375 (70.214)	Acc@5 100.000 (93.200)
Test: [400/750]	Time 0.094 (0.104)	Loss 0.5645 (0.8684)	Acc@1 81.250 (68.080)	Acc@5 100.000 (93.243)
Test: [500/750]	Time 0.118 (0.104)	Loss 0.9581 (0.8570)	Acc@1 65.625 (69.093)	Acc@5 96.875 (92.920)
Test: [600/750]	Time 0.099 (0.103)	Loss 1.0743 (0.8931)	Acc@1 62.500 (67.975)	Acc@5 93.750 (92.492)
Test: [700/750]	Time 0.117 (0.104)	Loss 1.3995 (0.9118)	Acc@1 62.500 (66.860)	Acc@5 81.250 (92.720)
 * Acc@1 66.367 Acc@5 92.646
==> training...
Epoch: [66][0/875]	Time 1.806 (1.806)	Data 1.239 (1.239)	Loss 2.1826 (2.1826)	Loss@kd 2.0832 (2.0832)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [66][100/875]	Time 0.371 (0.404)	Data 0.006 (0.019)	Loss 2.1731 (2.1023)	Loss@kd 1.9649 (1.8186)	Acc@1 67.188 (69.477)	Acc@5 96.875 (98.577)
Epoch: [66][200/875]	Time 0.419 (0.397)	Data 0.007 (0.013)	Loss 2.0242 (2.1051)	Loss@kd 1.7544 (1.8169)	Acc@1 65.625 (69.216)	Acc@5 100.000 (98.609)
Epoch: [66][300/875]	Time 0.365 (0.395)	Data 0.007 (0.011)	Loss 2.1725 (2.0927)	Loss@kd 1.7731 (1.8131)	Acc@1 62.500 (69.705)	Acc@5 100.000 (98.645)
Epoch: [66][400/875]	Time 0.383 (0.393)	Data 0.007 (0.010)	Loss 2.1397 (2.1004)	Loss@kd 1.8715 (1.8116)	Acc@1 67.188 (69.237)	Acc@5 98.438 (98.667)
Epoch: [66][500/875]	Time 0.356 (0.392)	Data 0.007 (0.010)	Loss 1.9188 (2.0980)	Loss@kd 1.7506 (1.8086)	Acc@1 79.688 (69.102)	Acc@5 100.000 (98.703)
Epoch: [66][600/875]	Time 0.362 (0.389)	Data 0.008 (0.009)	Loss 2.1166 (2.1013)	Loss@kd 1.8227 (1.8090)	Acc@1 70.312 (68.940)	Acc@5 100.000 (98.708)
Epoch: [66][700/875]	Time 0.374 (0.387)	Data 0.008 (0.009)	Loss 1.8744 (2.0987)	Loss@kd 1.8285 (1.8089)	Acc@1 78.125 (69.069)	Acc@5 100.000 (98.729)
Epoch: [66][800/875]	Time 0.346 (0.385)	Data 0.005 (0.009)	Loss 2.2455 (2.0993)	Loss@kd 1.7780 (1.8073)	Acc@1 62.500 (69.015)	Acc@5 98.438 (98.728)
 * Acc@1 69.064 Acc@5 98.737
epoch 66, total time 337.11
Test: [0/750]	Time 0.852 (0.852)	Loss 0.7363 (0.7363)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.108 (0.116)	Loss 0.5584 (0.5932)	Acc@1 84.375 (82.364)	Acc@5 100.000 (93.502)
Test: [200/750]	Time 0.112 (0.108)	Loss 1.1421 (0.6131)	Acc@1 56.250 (79.680)	Acc@5 93.750 (94.838)
Test: [300/750]	Time 0.092 (0.107)	Loss 1.3968 (0.8622)	Acc@1 50.000 (68.355)	Acc@5 93.750 (93.532)
Test: [400/750]	Time 0.096 (0.105)	Loss 1.1235 (1.0239)	Acc@1 62.500 (60.809)	Acc@5 90.625 (91.997)
Test: [500/750]	Time 0.149 (0.104)	Loss 0.4893 (1.0074)	Acc@1 87.500 (62.363)	Acc@5 100.000 (91.492)
Test: [600/750]	Time 0.095 (0.103)	Loss 0.8384 (0.9795)	Acc@1 65.625 (63.966)	Acc@5 90.625 (91.545)
Test: [700/750]	Time 0.112 (0.103)	Loss 0.9835 (0.9604)	Acc@1 56.250 (64.680)	Acc@5 81.250 (91.811)
 * Acc@1 65.383 Acc@5 91.883
==> training...
Epoch: [67][0/875]	Time 1.621 (1.621)	Data 1.148 (1.148)	Loss 1.9719 (1.9719)	Loss@kd 1.8375 (1.8375)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [67][100/875]	Time 0.381 (0.392)	Data 0.005 (0.018)	Loss 2.0265 (2.0885)	Loss@kd 1.7780 (1.8003)	Acc@1 67.188 (68.533)	Acc@5 100.000 (98.670)
Epoch: [67][200/875]	Time 0.386 (0.385)	Data 0.007 (0.012)	Loss 2.0117 (2.0868)	Loss@kd 1.7598 (1.8059)	Acc@1 73.438 (68.937)	Acc@5 100.000 (98.803)
Epoch: [67][300/875]	Time 0.415 (0.383)	Data 0.007 (0.011)	Loss 2.1583 (2.0900)	Loss@kd 1.7915 (1.8035)	Acc@1 59.375 (69.259)	Acc@5 100.000 (98.739)
Epoch: [67][400/875]	Time 0.401 (0.383)	Data 0.008 (0.010)	Loss 2.0460 (2.0946)	Loss@kd 1.7718 (1.8059)	Acc@1 73.438 (69.159)	Acc@5 98.438 (98.738)
Epoch: [67][500/875]	Time 0.352 (0.383)	Data 0.007 (0.009)	Loss 2.0873 (2.0966)	Loss@kd 1.8245 (1.8074)	Acc@1 75.000 (69.059)	Acc@5 100.000 (98.737)
Epoch: [67][600/875]	Time 0.352 (0.382)	Data 0.007 (0.009)	Loss 1.8325 (2.0967)	Loss@kd 1.7581 (1.8046)	Acc@1 76.562 (69.007)	Acc@5 100.000 (98.690)
Epoch: [67][700/875]	Time 0.398 (0.382)	Data 0.007 (0.008)	Loss 2.0657 (2.0970)	Loss@kd 1.7795 (1.8025)	Acc@1 62.500 (68.942)	Acc@5 100.000 (98.698)
Epoch: [67][800/875]	Time 0.384 (0.382)	Data 0.007 (0.008)	Loss 2.0469 (2.0952)	Loss@kd 1.7822 (1.8036)	Acc@1 70.312 (69.103)	Acc@5 98.438 (98.703)
 * Acc@1 69.154 Acc@5 98.707
epoch 67, total time 334.25
Test: [0/750]	Time 0.859 (0.859)	Loss 0.7284 (0.7284)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.107 (0.114)	Loss 0.5593 (0.7178)	Acc@1 81.250 (79.889)	Acc@5 96.875 (91.986)
Test: [200/750]	Time 0.109 (0.109)	Loss 1.2768 (0.6964)	Acc@1 43.750 (76.617)	Acc@5 93.750 (94.030)
Test: [300/750]	Time 0.107 (0.108)	Loss 1.5291 (0.9015)	Acc@1 40.625 (66.310)	Acc@5 93.750 (93.034)
Test: [400/750]	Time 0.093 (0.106)	Loss 0.4969 (0.9423)	Acc@1 87.500 (64.222)	Acc@5 96.875 (92.940)
Test: [500/750]	Time 0.141 (0.105)	Loss 0.6751 (0.8979)	Acc@1 62.500 (66.667)	Acc@5 100.000 (92.889)
Test: [600/750]	Time 0.099 (0.105)	Loss 0.6770 (0.8993)	Acc@1 71.875 (67.325)	Acc@5 96.875 (92.622)
Test: [700/750]	Time 0.106 (0.105)	Loss 0.9974 (0.8804)	Acc@1 65.625 (68.086)	Acc@5 87.500 (92.845)
 * Acc@1 68.208 Acc@5 92.746
saving the best model!
==> training...
Epoch: [68][0/875]	Time 1.577 (1.577)	Data 1.108 (1.108)	Loss 2.0825 (2.0825)	Loss@kd 1.7282 (1.7282)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [68][100/875]	Time 0.361 (0.375)	Data 0.007 (0.018)	Loss 1.9655 (2.0361)	Loss@kd 1.7834 (1.7908)	Acc@1 71.875 (71.225)	Acc@5 100.000 (98.793)
Epoch: [68][200/875]	Time 0.360 (0.374)	Data 0.007 (0.012)	Loss 2.0065 (2.0611)	Loss@kd 1.7737 (1.7980)	Acc@1 70.312 (70.297)	Acc@5 100.000 (98.896)
Epoch: [68][300/875]	Time 0.373 (0.377)	Data 0.007 (0.011)	Loss 2.2790 (2.0751)	Loss@kd 1.8175 (1.7993)	Acc@1 67.188 (69.669)	Acc@5 98.438 (98.853)
Epoch: [68][400/875]	Time 0.332 (0.378)	Data 0.005 (0.010)	Loss 2.6949 (2.0794)	Loss@kd 2.1570 (1.7997)	Acc@1 60.938 (69.720)	Acc@5 95.312 (98.812)
Epoch: [68][500/875]	Time 0.393 (0.379)	Data 0.007 (0.009)	Loss 2.0730 (2.0799)	Loss@kd 1.8393 (1.7982)	Acc@1 70.312 (69.651)	Acc@5 96.875 (98.784)
Epoch: [68][600/875]	Time 0.370 (0.382)	Data 0.007 (0.009)	Loss 1.9616 (2.0817)	Loss@kd 1.7702 (1.7984)	Acc@1 79.688 (69.496)	Acc@5 96.875 (98.801)
Epoch: [68][700/875]	Time 0.379 (0.383)	Data 0.007 (0.009)	Loss 2.0157 (2.0842)	Loss@kd 1.7371 (1.7985)	Acc@1 70.312 (69.477)	Acc@5 98.438 (98.785)
Epoch: [68][800/875]	Time 0.366 (0.384)	Data 0.007 (0.008)	Loss 2.1227 (2.0894)	Loss@kd 1.7648 (1.7987)	Acc@1 68.750 (69.216)	Acc@5 100.000 (98.748)
 * Acc@1 69.254 Acc@5 98.736
epoch 68, total time 337.03
Test: [0/750]	Time 0.772 (0.772)	Loss 0.5361 (0.5361)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.097 (0.116)	Loss 0.8081 (0.5647)	Acc@1 71.875 (82.704)	Acc@5 96.875 (92.265)
Test: [200/750]	Time 0.098 (0.109)	Loss 1.5635 (0.6442)	Acc@1 31.250 (77.690)	Acc@5 93.750 (93.937)
Test: [300/750]	Time 0.101 (0.107)	Loss 1.1954 (0.8890)	Acc@1 56.250 (65.604)	Acc@5 96.875 (93.169)
Test: [400/750]	Time 0.089 (0.105)	Loss 1.0389 (0.9505)	Acc@1 65.625 (63.669)	Acc@5 81.250 (92.456)
Test: [500/750]	Time 0.164 (0.105)	Loss 0.5170 (0.9843)	Acc@1 75.000 (63.211)	Acc@5 100.000 (91.049)
Test: [600/750]	Time 0.099 (0.104)	Loss 0.7676 (0.9566)	Acc@1 71.875 (64.741)	Acc@5 90.625 (91.259)
Test: [700/750]	Time 0.113 (0.104)	Loss 0.9130 (0.9405)	Acc@1 65.625 (65.291)	Acc@5 87.500 (91.641)
 * Acc@1 65.633 Acc@5 91.746
==> training...
Epoch: [69][0/875]	Time 1.822 (1.822)	Data 1.292 (1.292)	Loss 1.9682 (1.9682)	Loss@kd 1.7541 (1.7541)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [69][100/875]	Time 0.400 (0.408)	Data 0.007 (0.020)	Loss 2.0921 (2.0729)	Loss@kd 1.8509 (1.7961)	Acc@1 68.750 (70.065)	Acc@5 98.438 (98.840)
Epoch: [69][200/875]	Time 0.390 (0.401)	Data 0.007 (0.013)	Loss 2.3131 (2.0797)	Loss@kd 2.0807 (1.8012)	Acc@1 60.938 (69.815)	Acc@5 98.438 (98.772)
Epoch: [69][300/875]	Time 0.373 (0.399)	Data 0.007 (0.011)	Loss 2.2253 (2.0741)	Loss@kd 1.8134 (1.7992)	Acc@1 60.938 (70.037)	Acc@5 100.000 (98.780)
Epoch: [69][400/875]	Time 0.300 (0.397)	Data 0.005 (0.010)	Loss 1.9960 (2.0700)	Loss@kd 1.7853 (1.7975)	Acc@1 76.562 (70.102)	Acc@5 96.875 (98.776)
Epoch: [69][500/875]	Time 0.371 (0.392)	Data 0.007 (0.010)	Loss 2.2219 (2.0737)	Loss@kd 1.8171 (1.7943)	Acc@1 67.188 (69.773)	Acc@5 96.875 (98.749)
Epoch: [69][600/875]	Time 0.373 (0.389)	Data 0.007 (0.009)	Loss 2.0740 (2.0773)	Loss@kd 1.7711 (1.7936)	Acc@1 68.750 (69.722)	Acc@5 100.000 (98.731)
Epoch: [69][700/875]	Time 0.406 (0.388)	Data 0.007 (0.009)	Loss 2.0533 (2.0774)	Loss@kd 1.8072 (1.7942)	Acc@1 67.188 (69.715)	Acc@5 100.000 (98.732)
Epoch: [69][800/875]	Time 0.374 (0.388)	Data 0.007 (0.009)	Loss 2.0038 (2.0773)	Loss@kd 1.7280 (1.7938)	Acc@1 75.000 (69.655)	Acc@5 98.438 (98.740)
 * Acc@1 69.632 Acc@5 98.737
epoch 69, total time 340.02
Test: [0/750]	Time 0.815 (0.815)	Loss 0.5901 (0.5901)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/750]	Time 0.110 (0.112)	Loss 0.4269 (0.5932)	Acc@1 87.500 (83.416)	Acc@5 100.000 (92.203)
Test: [200/750]	Time 0.102 (0.108)	Loss 1.4947 (0.5623)	Acc@1 34.375 (82.556)	Acc@5 87.500 (94.761)
Test: [300/750]	Time 0.096 (0.108)	Loss 1.4193 (0.8407)	Acc@1 59.375 (69.373)	Acc@5 93.750 (93.106)
Test: [400/750]	Time 0.086 (0.107)	Loss 0.5553 (0.9062)	Acc@1 81.250 (66.771)	Acc@5 100.000 (92.862)
Test: [500/750]	Time 0.131 (0.107)	Loss 0.5218 (0.8663)	Acc@1 81.250 (68.731)	Acc@5 100.000 (92.640)
Test: [600/750]	Time 0.091 (0.106)	Loss 0.8993 (0.8655)	Acc@1 65.625 (68.823)	Acc@5 93.750 (92.658)
Test: [700/750]	Time 0.109 (0.106)	Loss 0.9583 (0.8660)	Acc@1 71.875 (68.594)	Acc@5 87.500 (92.965)
 * Acc@1 68.429 Acc@5 92.904
saving the best model!
==> training...
Epoch: [70][0/875]	Time 1.680 (1.680)	Data 1.180 (1.180)	Loss 2.1107 (2.1107)	Loss@kd 1.8360 (1.8360)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [70][100/875]	Time 0.377 (0.401)	Data 0.008 (0.018)	Loss 2.1571 (2.0542)	Loss@kd 1.8312 (1.8009)	Acc@1 73.438 (71.241)	Acc@5 96.875 (98.654)
Epoch: [70][200/875]	Time 0.392 (0.394)	Data 0.007 (0.013)	Loss 1.9805 (2.0631)	Loss@kd 1.7723 (1.7939)	Acc@1 68.750 (70.460)	Acc@5 100.000 (98.616)
Epoch: [70][300/875]	Time 0.383 (0.393)	Data 0.007 (0.011)	Loss 1.9660 (2.0654)	Loss@kd 1.7373 (1.7902)	Acc@1 68.750 (70.074)	Acc@5 100.000 (98.728)
Epoch: [70][400/875]	Time 0.396 (0.391)	Data 0.007 (0.010)	Loss 1.8611 (2.0672)	Loss@kd 1.6851 (1.7874)	Acc@1 73.438 (69.962)	Acc@5 100.000 (98.718)
Epoch: [70][500/875]	Time 0.393 (0.391)	Data 0.007 (0.009)	Loss 1.9406 (2.0664)	Loss@kd 1.7723 (1.7888)	Acc@1 71.875 (69.891)	Acc@5 100.000 (98.777)
Epoch: [70][600/875]	Time 0.366 (0.391)	Data 0.007 (0.009)	Loss 2.2907 (2.0684)	Loss@kd 1.7259 (1.7890)	Acc@1 62.500 (69.806)	Acc@5 98.438 (98.791)
Epoch: [70][700/875]	Time 0.393 (0.391)	Data 0.007 (0.009)	Loss 1.9459 (2.0698)	Loss@kd 1.7405 (1.7884)	Acc@1 68.750 (69.708)	Acc@5 100.000 (98.785)
Epoch: [70][800/875]	Time 0.376 (0.391)	Data 0.008 (0.008)	Loss 2.0120 (2.0715)	Loss@kd 1.7918 (1.7889)	Acc@1 71.875 (69.638)	Acc@5 98.438 (98.781)
 * Acc@1 69.611 Acc@5 98.786
epoch 70, total time 342.43
Test: [0/750]	Time 0.770 (0.770)	Loss 0.3827 (0.3827)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.100 (0.113)	Loss 0.3247 (0.4956)	Acc@1 90.625 (84.375)	Acc@5 100.000 (93.348)
Test: [200/750]	Time 0.108 (0.106)	Loss 1.7712 (0.4689)	Acc@1 31.250 (83.986)	Acc@5 78.125 (95.180)
Test: [300/750]	Time 0.112 (0.106)	Loss 1.3553 (0.8300)	Acc@1 59.375 (68.750)	Acc@5 96.875 (91.767)
Test: [400/750]	Time 0.108 (0.104)	Loss 0.5562 (0.9482)	Acc@1 84.375 (64.417)	Acc@5 90.625 (90.680)
Test: [500/750]	Time 0.171 (0.105)	Loss 0.4374 (0.9028)	Acc@1 93.750 (67.097)	Acc@5 96.875 (91.105)
Test: [600/750]	Time 0.102 (0.104)	Loss 0.8420 (0.9025)	Acc@1 71.875 (67.575)	Acc@5 93.750 (91.587)
Test: [700/750]	Time 0.110 (0.104)	Loss 0.9712 (0.9221)	Acc@1 59.375 (66.561)	Acc@5 90.625 (92.065)
 * Acc@1 66.604 Acc@5 92.075
==> training...
Epoch: [71][0/875]	Time 1.658 (1.658)	Data 1.187 (1.187)	Loss 2.2044 (2.2044)	Loss@kd 1.7675 (1.7675)	Acc@1 59.375 (59.375)	Acc@5 95.312 (95.312)
Epoch: [71][100/875]	Time 0.361 (0.389)	Data 0.007 (0.019)	Loss 2.1104 (2.0724)	Loss@kd 1.7152 (1.7836)	Acc@1 59.375 (68.456)	Acc@5 100.000 (98.762)
Epoch: [71][200/875]	Time 0.389 (0.390)	Data 0.007 (0.013)	Loss 2.1007 (2.0625)	Loss@kd 1.8082 (1.7849)	Acc@1 68.750 (69.294)	Acc@5 96.875 (98.764)
Epoch: [71][300/875]	Time 0.365 (0.389)	Data 0.006 (0.011)	Loss 1.9581 (2.0611)	Loss@kd 1.8472 (1.7830)	Acc@1 75.000 (69.607)	Acc@5 98.438 (98.666)
Epoch: [71][400/875]	Time 0.368 (0.389)	Data 0.007 (0.010)	Loss 2.0763 (2.0590)	Loss@kd 1.7888 (1.7824)	Acc@1 70.312 (69.490)	Acc@5 100.000 (98.726)
Epoch: [71][500/875]	Time 0.385 (0.389)	Data 0.007 (0.009)	Loss 1.9850 (2.0607)	Loss@kd 1.9119 (1.7811)	Acc@1 81.250 (69.499)	Acc@5 98.438 (98.752)
Epoch: [71][600/875]	Time 0.436 (0.389)	Data 0.007 (0.009)	Loss 2.0491 (2.0592)	Loss@kd 1.8202 (1.7792)	Acc@1 71.875 (69.663)	Acc@5 100.000 (98.739)
Epoch: [71][700/875]	Time 0.406 (0.389)	Data 0.007 (0.009)	Loss 2.0672 (2.0620)	Loss@kd 1.8537 (1.7812)	Acc@1 67.188 (69.679)	Acc@5 96.875 (98.752)
Epoch: [71][800/875]	Time 0.359 (0.388)	Data 0.007 (0.008)	Loss 2.2158 (2.0641)	Loss@kd 1.7894 (1.7803)	Acc@1 62.500 (69.597)	Acc@5 98.438 (98.757)
 * Acc@1 69.555 Acc@5 98.743
epoch 71, total time 339.62
Test: [0/750]	Time 0.838 (0.838)	Loss 2.5957 (2.5957)	Acc@1 21.875 (21.875)	Acc@5 46.875 (46.875)
Test: [100/750]	Time 0.109 (0.115)	Loss 1.1364 (2.6753)	Acc@1 56.250 (25.650)	Acc@5 90.625 (43.719)
Test: [200/750]	Time 0.117 (0.108)	Loss 1.6722 (1.9904)	Acc@1 21.875 (40.470)	Acc@5 84.375 (64.910)
Test: [300/750]	Time 0.080 (0.107)	Loss 1.4522 (1.8601)	Acc@1 50.000 (38.787)	Acc@5 90.625 (72.353)
Test: [400/750]	Time 0.106 (0.104)	Loss 0.6360 (1.6896)	Acc@1 71.875 (42.994)	Acc@5 96.875 (77.174)
Test: [500/750]	Time 0.164 (0.104)	Loss 0.7561 (1.5045)	Acc@1 68.750 (49.470)	Acc@5 93.750 (80.233)
Test: [600/750]	Time 0.083 (0.103)	Loss 1.5108 (1.4610)	Acc@1 53.125 (51.321)	Acc@5 68.750 (80.948)
Test: [700/750]	Time 0.099 (0.103)	Loss 1.0903 (1.4328)	Acc@1 68.750 (52.247)	Acc@5 87.500 (81.509)
 * Acc@1 53.529 Acc@5 82.338
==> training...
Epoch: [72][0/875]	Time 1.739 (1.739)	Data 1.293 (1.293)	Loss 2.0967 (2.0967)	Loss@kd 1.7295 (1.7295)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [72][100/875]	Time 0.408 (0.399)	Data 0.007 (0.019)	Loss 2.1157 (2.0450)	Loss@kd 1.7501 (1.7736)	Acc@1 65.625 (70.282)	Acc@5 100.000 (98.608)
Epoch: [72][200/875]	Time 0.343 (0.391)	Data 0.006 (0.013)	Loss 1.9728 (2.0469)	Loss@kd 1.7509 (1.7764)	Acc@1 73.438 (70.351)	Acc@5 98.438 (98.678)
Epoch: [72][300/875]	Time 0.335 (0.386)	Data 0.007 (0.011)	Loss 2.0162 (2.0463)	Loss@kd 1.7334 (1.7786)	Acc@1 73.438 (70.598)	Acc@5 100.000 (98.775)
Epoch: [72][400/875]	Time 0.329 (0.379)	Data 0.006 (0.010)	Loss 2.0904 (2.0479)	Loss@kd 1.8307 (1.7775)	Acc@1 62.500 (70.476)	Acc@5 100.000 (98.773)
Epoch: [72][500/875]	Time 0.376 (0.377)	Data 0.008 (0.009)	Loss 2.2146 (2.0516)	Loss@kd 1.7238 (1.7771)	Acc@1 62.500 (70.231)	Acc@5 100.000 (98.818)
Epoch: [72][600/875]	Time 0.376 (0.376)	Data 0.007 (0.009)	Loss 1.9234 (2.0536)	Loss@kd 1.8548 (1.7778)	Acc@1 75.000 (70.071)	Acc@5 100.000 (98.812)
Epoch: [72][700/875]	Time 0.385 (0.378)	Data 0.007 (0.009)	Loss 2.1638 (2.0520)	Loss@kd 1.7518 (1.7758)	Acc@1 67.188 (70.150)	Acc@5 93.750 (98.814)
Epoch: [72][800/875]	Time 0.365 (0.379)	Data 0.007 (0.009)	Loss 1.9735 (2.0553)	Loss@kd 1.7577 (1.7764)	Acc@1 78.125 (70.059)	Acc@5 98.438 (98.761)
 * Acc@1 69.988 Acc@5 98.793
epoch 72, total time 332.70
Test: [0/750]	Time 0.883 (0.883)	Loss 0.6520 (0.6520)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.101 (0.115)	Loss 0.4612 (0.6436)	Acc@1 81.250 (80.322)	Acc@5 100.000 (92.729)
Test: [200/750]	Time 0.084 (0.109)	Loss 1.2117 (0.6104)	Acc@1 46.875 (79.244)	Acc@5 90.625 (94.869)
Test: [300/750]	Time 0.114 (0.108)	Loss 1.0777 (0.8328)	Acc@1 71.875 (69.331)	Acc@5 93.750 (93.729)
Test: [400/750]	Time 0.103 (0.106)	Loss 0.8815 (0.8991)	Acc@1 65.625 (66.895)	Acc@5 90.625 (93.064)
Test: [500/750]	Time 0.147 (0.106)	Loss 0.4485 (0.8789)	Acc@1 81.250 (68.189)	Acc@5 100.000 (92.764)
Test: [600/750]	Time 0.108 (0.105)	Loss 0.9680 (0.8675)	Acc@1 68.750 (69.130)	Acc@5 90.625 (92.902)
Test: [700/750]	Time 0.114 (0.105)	Loss 0.9859 (0.8719)	Acc@1 53.125 (68.558)	Acc@5 96.875 (93.202)
 * Acc@1 68.521 Acc@5 93.246
saving the best model!
==> training...
Epoch: [73][0/875]	Time 1.716 (1.716)	Data 1.198 (1.198)	Loss 1.9843 (1.9843)	Loss@kd 1.7939 (1.7939)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [73][100/875]	Time 0.402 (0.403)	Data 0.007 (0.019)	Loss 2.0819 (2.0306)	Loss@kd 1.7973 (1.7848)	Acc@1 65.625 (71.009)	Acc@5 100.000 (98.902)
Epoch: [73][200/875]	Time 0.384 (0.395)	Data 0.007 (0.013)	Loss 1.9437 (2.0392)	Loss@kd 1.7484 (1.7810)	Acc@1 70.312 (70.406)	Acc@5 96.875 (98.888)
Epoch: [73][300/875]	Time 0.430 (0.393)	Data 0.010 (0.011)	Loss 2.0582 (2.0403)	Loss@kd 1.7745 (1.7816)	Acc@1 71.875 (70.411)	Acc@5 98.438 (98.920)
Epoch: [73][400/875]	Time 0.385 (0.392)	Data 0.007 (0.010)	Loss 2.2059 (2.0461)	Loss@kd 1.7459 (1.7807)	Acc@1 60.938 (70.137)	Acc@5 98.438 (98.878)
Epoch: [73][500/875]	Time 0.396 (0.392)	Data 0.006 (0.009)	Loss 2.0655 (2.0526)	Loss@kd 1.7510 (1.7799)	Acc@1 68.750 (69.913)	Acc@5 98.438 (98.843)
Epoch: [73][600/875]	Time 0.388 (0.392)	Data 0.007 (0.009)	Loss 2.1049 (2.0550)	Loss@kd 1.7137 (1.7784)	Acc@1 65.625 (69.855)	Acc@5 95.312 (98.809)
Epoch: [73][700/875]	Time 0.391 (0.392)	Data 0.007 (0.009)	Loss 2.0188 (2.0514)	Loss@kd 1.7233 (1.7760)	Acc@1 75.000 (69.891)	Acc@5 96.875 (98.852)
Epoch: [73][800/875]	Time 0.370 (0.391)	Data 0.008 (0.008)	Loss 2.2821 (2.0510)	Loss@kd 2.0470 (1.7741)	Acc@1 65.625 (69.870)	Acc@5 96.875 (98.871)
 * Acc@1 69.932 Acc@5 98.871
epoch 73, total time 340.59
Test: [0/750]	Time 0.714 (0.714)	Loss 0.3992 (0.3992)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.111 (0.109)	Loss 0.9027 (0.5150)	Acc@1 68.750 (84.406)	Acc@5 90.625 (93.936)
Test: [200/750]	Time 0.086 (0.104)	Loss 1.4274 (0.6883)	Acc@1 43.750 (75.093)	Acc@5 93.750 (94.434)
Test: [300/750]	Time 0.084 (0.104)	Loss 0.9273 (0.8960)	Acc@1 65.625 (65.189)	Acc@5 93.750 (93.501)
Test: [400/750]	Time 0.075 (0.103)	Loss 0.6633 (0.8901)	Acc@1 78.125 (66.171)	Acc@5 93.750 (93.766)
Test: [500/750]	Time 0.165 (0.103)	Loss 0.6943 (0.8832)	Acc@1 68.750 (67.272)	Acc@5 100.000 (93.295)
Test: [600/750]	Time 0.073 (0.102)	Loss 0.8016 (0.8958)	Acc@1 65.625 (67.440)	Acc@5 93.750 (92.788)
Test: [700/750]	Time 0.091 (0.102)	Loss 1.4059 (0.9126)	Acc@1 43.750 (66.646)	Acc@5 81.250 (92.537)
 * Acc@1 65.821 Acc@5 92.379
==> training...
Epoch: [74][0/875]	Time 1.649 (1.649)	Data 1.155 (1.155)	Loss 2.1273 (2.1273)	Loss@kd 1.7259 (1.7259)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [74][100/875]	Time 0.398 (0.403)	Data 0.007 (0.018)	Loss 2.1248 (2.0472)	Loss@kd 1.8126 (1.7654)	Acc@1 65.625 (69.539)	Acc@5 100.000 (98.917)
Epoch: [74][200/875]	Time 0.392 (0.395)	Data 0.007 (0.013)	Loss 1.9327 (2.0463)	Loss@kd 1.7534 (1.7692)	Acc@1 76.562 (70.009)	Acc@5 98.438 (98.834)
Epoch: [74][300/875]	Time 0.357 (0.393)	Data 0.008 (0.011)	Loss 2.2613 (2.0462)	Loss@kd 1.8778 (1.7705)	Acc@1 60.938 (70.094)	Acc@5 100.000 (98.837)
Epoch: [74][400/875]	Time 0.411 (0.392)	Data 0.007 (0.010)	Loss 2.3206 (2.0500)	Loss@kd 1.7865 (1.7703)	Acc@1 70.312 (69.931)	Acc@5 96.875 (98.753)
Epoch: [74][500/875]	Time 0.387 (0.391)	Data 0.007 (0.009)	Loss 2.3466 (2.0480)	Loss@kd 1.8412 (1.7700)	Acc@1 59.375 (69.976)	Acc@5 98.438 (98.802)
Epoch: [74][600/875]	Time 0.373 (0.391)	Data 0.006 (0.009)	Loss 2.0254 (2.0472)	Loss@kd 1.7878 (1.7676)	Acc@1 67.188 (69.891)	Acc@5 100.000 (98.817)
Epoch: [74][700/875]	Time 0.380 (0.391)	Data 0.007 (0.009)	Loss 2.1156 (2.0484)	Loss@kd 1.9494 (1.7667)	Acc@1 75.000 (69.829)	Acc@5 96.875 (98.836)
Epoch: [74][800/875]	Time 0.389 (0.391)	Data 0.007 (0.008)	Loss 2.0513 (2.0491)	Loss@kd 1.8205 (1.7677)	Acc@1 71.875 (69.809)	Acc@5 100.000 (98.818)
 * Acc@1 69.880 Acc@5 98.804
epoch 74, total time 342.19
Test: [0/750]	Time 0.764 (0.764)	Loss 0.4495 (0.4495)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.105 (0.113)	Loss 0.2402 (0.4850)	Acc@1 87.500 (85.551)	Acc@5 100.000 (93.348)
Test: [200/750]	Time 0.106 (0.107)	Loss 1.3369 (0.4490)	Acc@1 43.750 (85.743)	Acc@5 87.500 (95.351)
Test: [300/750]	Time 0.105 (0.105)	Loss 1.5106 (0.7340)	Acc@1 43.750 (73.931)	Acc@5 93.750 (93.823)
Test: [400/750]	Time 0.094 (0.104)	Loss 0.4506 (0.8522)	Acc@1 87.500 (68.789)	Acc@5 93.750 (93.033)
Test: [500/750]	Time 0.162 (0.104)	Loss 0.5675 (0.8161)	Acc@1 84.375 (70.690)	Acc@5 96.875 (92.989)
Test: [600/750]	Time 0.105 (0.103)	Loss 0.8842 (0.8272)	Acc@1 71.875 (70.362)	Acc@5 93.750 (93.126)
Test: [700/750]	Time 0.088 (0.103)	Loss 1.0194 (0.8331)	Acc@1 68.750 (69.873)	Acc@5 87.500 (93.429)
 * Acc@1 70.046 Acc@5 93.454
saving the best model!
==> training...
Epoch: [75][0/875]	Time 1.776 (1.776)	Data 1.278 (1.278)	Loss 1.8558 (1.8558)	Loss@kd 1.6833 (1.6833)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [75][100/875]	Time 0.417 (0.403)	Data 0.007 (0.019)	Loss 2.0697 (2.0072)	Loss@kd 1.7993 (1.7642)	Acc@1 71.875 (70.993)	Acc@5 98.438 (99.010)
Epoch: [75][200/875]	Time 0.372 (0.393)	Data 0.007 (0.013)	Loss 2.0587 (2.0295)	Loss@kd 1.7695 (1.7681)	Acc@1 65.625 (70.623)	Acc@5 96.875 (98.896)
Epoch: [75][300/875]	Time 0.369 (0.386)	Data 0.007 (0.011)	Loss 2.0573 (2.0374)	Loss@kd 1.8199 (1.7683)	Acc@1 67.188 (70.261)	Acc@5 100.000 (98.931)
Epoch: [75][400/875]	Time 0.359 (0.382)	Data 0.007 (0.010)	Loss 2.0769 (2.0370)	Loss@kd 1.7450 (1.7649)	Acc@1 70.312 (70.094)	Acc@5 95.312 (98.936)
Epoch: [75][500/875]	Time 0.426 (0.383)	Data 0.007 (0.009)	Loss 2.1010 (2.0365)	Loss@kd 1.8053 (1.7657)	Acc@1 68.750 (70.200)	Acc@5 100.000 (98.949)
Epoch: [75][600/875]	Time 0.368 (0.385)	Data 0.009 (0.009)	Loss 2.0509 (2.0370)	Loss@kd 1.7621 (1.7656)	Acc@1 64.062 (70.092)	Acc@5 100.000 (98.937)
Epoch: [75][700/875]	Time 0.375 (0.386)	Data 0.007 (0.009)	Loss 2.1395 (2.0404)	Loss@kd 1.7819 (1.7662)	Acc@1 65.625 (70.007)	Acc@5 96.875 (98.923)
Epoch: [75][800/875]	Time 0.365 (0.386)	Data 0.007 (0.009)	Loss 1.9520 (2.0411)	Loss@kd 1.7785 (1.7666)	Acc@1 79.688 (70.059)	Acc@5 100.000 (98.912)
 * Acc@1 70.064 Acc@5 98.896
epoch 75, total time 338.61
Test: [0/750]	Time 0.848 (0.848)	Loss 0.3518 (0.3518)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/750]	Time 0.086 (0.113)	Loss 0.7051 (0.5142)	Acc@1 62.500 (83.725)	Acc@5 96.875 (93.533)
Test: [200/750]	Time 0.074 (0.106)	Loss 1.6571 (0.6578)	Acc@1 40.625 (75.840)	Acc@5 90.625 (94.916)
Test: [300/750]	Time 0.103 (0.106)	Loss 1.6106 (0.9663)	Acc@1 46.875 (63.497)	Acc@5 90.625 (92.193)
Test: [400/750]	Time 0.097 (0.105)	Loss 0.4121 (1.0649)	Acc@1 87.500 (59.780)	Acc@5 100.000 (91.389)
Test: [500/750]	Time 0.187 (0.105)	Loss 0.6111 (0.9862)	Acc@1 71.875 (63.461)	Acc@5 100.000 (91.729)
Test: [600/750]	Time 0.102 (0.104)	Loss 0.7079 (0.9442)	Acc@1 78.125 (65.615)	Acc@5 90.625 (92.169)
Test: [700/750]	Time 0.101 (0.104)	Loss 1.0707 (0.9057)	Acc@1 71.875 (67.319)	Acc@5 84.375 (92.542)
 * Acc@1 67.787 Acc@5 92.492
==> training...
Epoch: [76][0/875]	Time 1.746 (1.746)	Data 1.295 (1.295)	Loss 2.0373 (2.0373)	Loss@kd 1.7263 (1.7263)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [76][100/875]	Time 0.391 (0.404)	Data 0.008 (0.020)	Loss 1.9050 (1.9325)	Loss@kd 1.7274 (1.7233)	Acc@1 71.875 (72.989)	Acc@5 100.000 (99.165)
Epoch: [76][200/875]	Time 0.398 (0.398)	Data 0.007 (0.013)	Loss 1.9288 (1.9240)	Loss@kd 1.7761 (1.7209)	Acc@1 71.875 (73.570)	Acc@5 98.438 (99.067)
Epoch: [76][300/875]	Time 0.396 (0.395)	Data 0.007 (0.011)	Loss 2.1483 (1.9194)	Loss@kd 1.7586 (1.7176)	Acc@1 68.750 (73.749)	Acc@5 100.000 (99.076)
Epoch: [76][400/875]	Time 0.367 (0.394)	Data 0.008 (0.010)	Loss 1.8425 (1.9097)	Loss@kd 1.6436 (1.7181)	Acc@1 71.875 (74.045)	Acc@5 100.000 (99.096)
Epoch: [76][500/875]	Time 0.382 (0.393)	Data 0.007 (0.010)	Loss 1.9594 (1.9097)	Loss@kd 1.7326 (1.7168)	Acc@1 70.312 (73.834)	Acc@5 100.000 (99.102)
Epoch: [76][600/875]	Time 0.395 (0.392)	Data 0.007 (0.009)	Loss 1.7835 (1.9046)	Loss@kd 1.6771 (1.7152)	Acc@1 78.125 (73.989)	Acc@5 98.438 (99.126)
Epoch: [76][700/875]	Time 0.371 (0.390)	Data 0.007 (0.009)	Loss 1.6436 (1.9018)	Loss@kd 1.6471 (1.7143)	Acc@1 82.812 (74.111)	Acc@5 100.000 (99.153)
Epoch: [76][800/875]	Time 0.345 (0.387)	Data 0.005 (0.009)	Loss 1.7935 (1.9017)	Loss@kd 1.6911 (1.7139)	Acc@1 78.125 (74.112)	Acc@5 100.000 (99.163)
 * Acc@1 74.259 Acc@5 99.166
epoch 76, total time 336.90
Test: [0/750]	Time 0.742 (0.742)	Loss 0.3038 (0.3038)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.083 (0.107)	Loss 0.3959 (0.4528)	Acc@1 84.375 (86.510)	Acc@5 100.000 (94.524)
Test: [200/750]	Time 0.101 (0.101)	Loss 1.0914 (0.4626)	Acc@1 53.125 (85.012)	Acc@5 93.750 (95.911)
Test: [300/750]	Time 0.104 (0.103)	Loss 1.0322 (0.6843)	Acc@1 62.500 (75.197)	Acc@5 96.875 (94.965)
Test: [400/750]	Time 0.105 (0.102)	Loss 0.5065 (0.7628)	Acc@1 81.250 (71.548)	Acc@5 93.750 (94.786)
Test: [500/750]	Time 0.178 (0.103)	Loss 0.4240 (0.7410)	Acc@1 87.500 (73.010)	Acc@5 100.000 (94.442)
Test: [600/750]	Time 0.103 (0.103)	Loss 0.8236 (0.7531)	Acc@1 71.875 (73.029)	Acc@5 90.625 (94.379)
Test: [700/750]	Time 0.119 (0.104)	Loss 1.0102 (0.7591)	Acc@1 62.500 (72.669)	Acc@5 87.500 (94.486)
 * Acc@1 72.746 Acc@5 94.433
saving the best model!
==> training...
Epoch: [77][0/875]	Time 1.761 (1.761)	Data 1.240 (1.240)	Loss 1.7901 (1.7901)	Loss@kd 1.5965 (1.5965)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [77][100/875]	Time 0.418 (0.404)	Data 0.007 (0.019)	Loss 1.7619 (1.8660)	Loss@kd 1.6922 (1.7045)	Acc@1 81.250 (74.660)	Acc@5 98.438 (99.103)
Epoch: [77][200/875]	Time 0.367 (0.398)	Data 0.007 (0.013)	Loss 1.9926 (1.8749)	Loss@kd 1.6817 (1.7061)	Acc@1 70.312 (74.588)	Acc@5 100.000 (99.106)
Epoch: [77][300/875]	Time 0.360 (0.395)	Data 0.007 (0.011)	Loss 2.0111 (1.8717)	Loss@kd 1.7393 (1.7076)	Acc@1 73.438 (74.730)	Acc@5 100.000 (99.107)
Epoch: [77][400/875]	Time 0.414 (0.394)	Data 0.007 (0.010)	Loss 1.9807 (1.8714)	Loss@kd 1.7415 (1.7043)	Acc@1 75.000 (74.696)	Acc@5 100.000 (99.162)
Epoch: [77][500/875]	Time 0.339 (0.393)	Data 0.005 (0.009)	Loss 1.7853 (1.8708)	Loss@kd 1.6235 (1.7026)	Acc@1 78.125 (74.710)	Acc@5 100.000 (99.177)
Epoch: [77][600/875]	Time 0.395 (0.393)	Data 0.007 (0.009)	Loss 1.7545 (1.8680)	Loss@kd 1.6593 (1.7023)	Acc@1 76.562 (74.870)	Acc@5 100.000 (99.194)
Epoch: [77][700/875]	Time 0.370 (0.392)	Data 0.007 (0.009)	Loss 1.8393 (1.8662)	Loss@kd 1.6894 (1.7015)	Acc@1 78.125 (74.942)	Acc@5 98.438 (99.202)
Epoch: [77][800/875]	Time 0.382 (0.391)	Data 0.006 (0.009)	Loss 1.9567 (1.8667)	Loss@kd 1.7181 (1.7005)	Acc@1 75.000 (74.904)	Acc@5 98.438 (99.208)
 * Acc@1 74.880 Acc@5 99.221
epoch 77, total time 342.95
Test: [0/750]	Time 0.859 (0.859)	Loss 0.3452 (0.3452)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.091 (0.113)	Loss 0.4693 (0.5162)	Acc@1 84.375 (85.365)	Acc@5 100.000 (93.905)
Test: [200/750]	Time 0.094 (0.107)	Loss 1.1627 (0.5153)	Acc@1 53.125 (83.629)	Acc@5 90.625 (95.507)
Test: [300/750]	Time 0.100 (0.106)	Loss 1.1937 (0.7336)	Acc@1 53.125 (74.169)	Acc@5 93.750 (94.331)
Test: [400/750]	Time 0.088 (0.105)	Loss 0.5582 (0.8183)	Acc@1 84.375 (70.418)	Acc@5 93.750 (94.303)
Test: [500/750]	Time 0.152 (0.105)	Loss 0.3637 (0.7866)	Acc@1 87.500 (72.037)	Acc@5 100.000 (94.168)
Test: [600/750]	Time 0.094 (0.104)	Loss 0.7636 (0.7826)	Acc@1 75.000 (72.473)	Acc@5 93.750 (94.254)
Test: [700/750]	Time 0.091 (0.104)	Loss 0.9963 (0.7736)	Acc@1 62.500 (72.637)	Acc@5 87.500 (94.450)
 * Acc@1 72.783 Acc@5 94.433
saving the best model!
==> training...
Epoch: [78][0/875]	Time 1.787 (1.787)	Data 1.246 (1.246)	Loss 1.7410 (1.7410)	Loss@kd 1.6515 (1.6515)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [78][100/875]	Time 0.360 (0.395)	Data 0.008 (0.019)	Loss 1.6568 (1.8504)	Loss@kd 1.6668 (1.7047)	Acc@1 82.812 (75.480)	Acc@5 100.000 (99.335)
Epoch: [78][200/875]	Time 0.375 (0.384)	Data 0.007 (0.013)	Loss 1.8450 (1.8493)	Loss@kd 1.7112 (1.7016)	Acc@1 71.875 (75.910)	Acc@5 98.438 (99.277)
Epoch: [78][300/875]	Time 0.356 (0.381)	Data 0.007 (0.011)	Loss 1.8730 (1.8559)	Loss@kd 1.7674 (1.7016)	Acc@1 75.000 (75.649)	Acc@5 100.000 (99.221)
Epoch: [78][400/875]	Time 0.384 (0.382)	Data 0.007 (0.010)	Loss 1.7846 (1.8535)	Loss@kd 1.7474 (1.7004)	Acc@1 75.000 (75.670)	Acc@5 100.000 (99.217)
Epoch: [78][500/875]	Time 0.410 (0.384)	Data 0.007 (0.009)	Loss 1.8432 (1.8586)	Loss@kd 1.7130 (1.7013)	Acc@1 76.562 (75.549)	Acc@5 98.438 (99.208)
Epoch: [78][600/875]	Time 0.375 (0.386)	Data 0.007 (0.009)	Loss 1.6559 (1.8543)	Loss@kd 1.6528 (1.7003)	Acc@1 85.938 (75.668)	Acc@5 100.000 (99.233)
Epoch: [78][700/875]	Time 0.352 (0.387)	Data 0.007 (0.009)	Loss 1.7690 (1.8536)	Loss@kd 1.6723 (1.6988)	Acc@1 76.562 (75.588)	Acc@5 100.000 (99.227)
Epoch: [78][800/875]	Time 0.390 (0.388)	Data 0.007 (0.009)	Loss 1.9090 (1.8538)	Loss@kd 1.8519 (1.6976)	Acc@1 76.562 (75.533)	Acc@5 100.000 (99.231)
 * Acc@1 75.612 Acc@5 99.232
epoch 78, total time 339.88
Test: [0/750]	Time 0.777 (0.777)	Loss 0.3358 (0.3358)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.104 (0.112)	Loss 0.4162 (0.4924)	Acc@1 84.375 (86.200)	Acc@5 100.000 (94.307)
Test: [200/750]	Time 0.094 (0.106)	Loss 1.0851 (0.4866)	Acc@1 59.375 (84.950)	Acc@5 90.625 (95.787)
Test: [300/750]	Time 0.079 (0.106)	Loss 1.0217 (0.6977)	Acc@1 59.375 (75.488)	Acc@5 96.875 (95.183)
Test: [400/750]	Time 0.097 (0.104)	Loss 0.7214 (0.7733)	Acc@1 78.125 (72.140)	Acc@5 96.875 (94.872)
Test: [500/750]	Time 0.160 (0.104)	Loss 0.4383 (0.7738)	Acc@1 84.375 (72.686)	Acc@5 100.000 (94.349)
Test: [600/750]	Time 0.114 (0.103)	Loss 0.8629 (0.7817)	Acc@1 71.875 (72.712)	Acc@5 90.625 (94.275)
Test: [700/750]	Time 0.107 (0.103)	Loss 0.8370 (0.7776)	Acc@1 71.875 (72.611)	Acc@5 90.625 (94.477)
 * Acc@1 72.983 Acc@5 94.558
saving the best model!
==> training...
Epoch: [79][0/875]	Time 1.674 (1.674)	Data 1.168 (1.168)	Loss 2.0741 (2.0741)	Loss@kd 1.9987 (1.9987)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [79][100/875]	Time 0.403 (0.405)	Data 0.007 (0.018)	Loss 1.6776 (1.8377)	Loss@kd 1.6864 (1.7044)	Acc@1 85.938 (76.207)	Acc@5 100.000 (99.366)
Epoch: [79][200/875]	Time 0.362 (0.398)	Data 0.006 (0.013)	Loss 1.7896 (1.8445)	Loss@kd 1.6254 (1.6990)	Acc@1 76.562 (75.886)	Acc@5 98.438 (99.339)
Epoch: [79][300/875]	Time 0.359 (0.394)	Data 0.007 (0.011)	Loss 1.9567 (1.8440)	Loss@kd 1.7357 (1.6988)	Acc@1 78.125 (75.934)	Acc@5 98.438 (99.346)
Epoch: [79][400/875]	Time 0.372 (0.392)	Data 0.007 (0.010)	Loss 1.9813 (1.8451)	Loss@kd 1.7064 (1.6969)	Acc@1 68.750 (75.799)	Acc@5 100.000 (99.334)
Epoch: [79][500/875]	Time 0.394 (0.392)	Data 0.009 (0.009)	Loss 1.7661 (1.8428)	Loss@kd 1.6668 (1.6974)	Acc@1 76.562 (75.904)	Acc@5 98.438 (99.317)
Epoch: [79][600/875]	Time 0.354 (0.389)	Data 0.007 (0.009)	Loss 1.9964 (1.8418)	Loss@kd 1.7674 (1.6968)	Acc@1 70.312 (75.965)	Acc@5 100.000 (99.321)
Epoch: [79][700/875]	Time 0.369 (0.387)	Data 0.007 (0.009)	Loss 1.8076 (1.8432)	Loss@kd 1.6702 (1.6959)	Acc@1 79.688 (75.851)	Acc@5 100.000 (99.322)
Epoch: [79][800/875]	Time 0.395 (0.385)	Data 0.007 (0.008)	Loss 1.8250 (1.8433)	Loss@kd 1.6231 (1.6946)	Acc@1 75.000 (75.804)	Acc@5 100.000 (99.300)
 * Acc@1 75.762 Acc@5 99.298
epoch 79, total time 336.79
Test: [0/750]	Time 0.856 (0.856)	Loss 0.3451 (0.3451)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.095 (0.114)	Loss 0.5099 (0.4913)	Acc@1 84.375 (86.015)	Acc@5 100.000 (94.554)
Test: [200/750]	Time 0.104 (0.108)	Loss 0.9851 (0.5130)	Acc@1 56.250 (83.722)	Acc@5 93.750 (95.725)
Test: [300/750]	Time 0.104 (0.107)	Loss 1.2531 (0.7068)	Acc@1 53.125 (75.176)	Acc@5 87.500 (94.954)
Test: [400/750]	Time 0.105 (0.106)	Loss 0.6781 (0.8058)	Acc@1 78.125 (70.924)	Acc@5 93.750 (94.584)
Test: [500/750]	Time 0.111 (0.106)	Loss 0.3759 (0.7889)	Acc@1 87.500 (72.025)	Acc@5 100.000 (94.368)
Test: [600/750]	Time 0.098 (0.106)	Loss 0.7775 (0.7842)	Acc@1 71.875 (72.499)	Acc@5 93.750 (94.343)
Test: [700/750]	Time 0.100 (0.106)	Loss 1.0290 (0.7831)	Acc@1 65.625 (72.419)	Acc@5 84.375 (94.428)
 * Acc@1 72.546 Acc@5 94.375
==> training...
Epoch: [80][0/875]	Time 1.490 (1.490)	Data 1.104 (1.104)	Loss 1.9355 (1.9355)	Loss@kd 1.7062 (1.7062)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [80][100/875]	Time 0.375 (0.396)	Data 0.005 (0.018)	Loss 1.8796 (1.8342)	Loss@kd 1.7277 (1.6922)	Acc@1 76.562 (76.067)	Acc@5 100.000 (99.257)
Epoch: [80][200/875]	Time 0.344 (0.389)	Data 0.007 (0.012)	Loss 1.6515 (1.8297)	Loss@kd 1.6355 (1.6939)	Acc@1 78.125 (76.384)	Acc@5 100.000 (99.370)
Epoch: [80][300/875]	Time 0.459 (0.387)	Data 0.007 (0.010)	Loss 1.9950 (1.8272)	Loss@kd 1.7363 (1.6928)	Acc@1 73.438 (76.298)	Acc@5 98.438 (99.413)
Epoch: [80][400/875]	Time 0.357 (0.385)	Data 0.006 (0.009)	Loss 1.7618 (1.8322)	Loss@kd 1.5912 (1.6929)	Acc@1 76.562 (76.161)	Acc@5 100.000 (99.338)
Epoch: [80][500/875]	Time 0.348 (0.385)	Data 0.007 (0.009)	Loss 1.8451 (1.8299)	Loss@kd 1.6570 (1.6926)	Acc@1 70.312 (76.101)	Acc@5 98.438 (99.376)
Epoch: [80][600/875]	Time 0.396 (0.385)	Data 0.007 (0.009)	Loss 1.9411 (1.8315)	Loss@kd 1.6772 (1.6923)	Acc@1 67.188 (75.983)	Acc@5 96.875 (99.371)
Epoch: [80][700/875]	Time 0.352 (0.385)	Data 0.005 (0.008)	Loss 1.6808 (1.8320)	Loss@kd 1.7069 (1.6931)	Acc@1 82.812 (76.039)	Acc@5 98.438 (99.354)
Epoch: [80][800/875]	Time 0.381 (0.385)	Data 0.005 (0.008)	Loss 2.0231 (1.8333)	Loss@kd 1.7365 (1.6934)	Acc@1 71.875 (76.114)	Acc@5 100.000 (99.348)
 * Acc@1 76.070 Acc@5 99.354
epoch 80, total time 337.47
Test: [0/750]	Time 0.822 (0.822)	Loss 0.2960 (0.2960)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.087 (0.116)	Loss 0.4151 (0.5026)	Acc@1 81.250 (85.427)	Acc@5 100.000 (94.183)
Test: [200/750]	Time 0.095 (0.110)	Loss 1.0647 (0.5022)	Acc@1 53.125 (83.893)	Acc@5 93.750 (95.600)
Test: [300/750]	Time 0.106 (0.110)	Loss 1.0606 (0.7091)	Acc@1 65.625 (74.699)	Acc@5 93.750 (94.736)
Test: [400/750]	Time 0.113 (0.108)	Loss 0.4633 (0.7740)	Acc@1 81.250 (71.891)	Acc@5 96.875 (94.786)
Test: [500/750]	Time 0.108 (0.108)	Loss 0.4765 (0.7607)	Acc@1 84.375 (72.861)	Acc@5 100.000 (94.436)
Test: [600/750]	Time 0.111 (0.107)	Loss 0.7665 (0.7740)	Acc@1 75.000 (72.697)	Acc@5 93.750 (94.296)
Test: [700/750]	Time 0.101 (0.107)	Loss 0.8449 (0.7679)	Acc@1 71.875 (72.686)	Acc@5 90.625 (94.521)
 * Acc@1 72.912 Acc@5 94.600
==> Saving...
==> training...
Epoch: [81][0/875]	Time 1.634 (1.634)	Data 1.245 (1.245)	Loss 2.1820 (2.1820)	Loss@kd 1.6993 (1.6993)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [81][100/875]	Time 0.405 (0.386)	Data 0.005 (0.019)	Loss 1.8080 (1.8311)	Loss@kd 1.6094 (1.6876)	Acc@1 62.500 (75.526)	Acc@5 98.438 (99.226)
Epoch: [81][200/875]	Time 0.392 (0.380)	Data 0.007 (0.013)	Loss 1.7508 (1.8228)	Loss@kd 1.6188 (1.6883)	Acc@1 78.125 (76.174)	Acc@5 100.000 (99.370)
Epoch: [81][300/875]	Time 0.403 (0.383)	Data 0.007 (0.011)	Loss 1.5317 (1.8244)	Loss@kd 1.6422 (1.6915)	Acc@1 87.500 (76.376)	Acc@5 100.000 (99.377)
Epoch: [81][400/875]	Time 0.372 (0.385)	Data 0.007 (0.010)	Loss 1.9761 (1.8250)	Loss@kd 1.7096 (1.6914)	Acc@1 73.438 (76.430)	Acc@5 98.438 (99.377)
Epoch: [81][500/875]	Time 0.365 (0.386)	Data 0.007 (0.009)	Loss 1.8912 (1.8247)	Loss@kd 1.7042 (1.6918)	Acc@1 73.438 (76.525)	Acc@5 100.000 (99.382)
Epoch: [81][600/875]	Time 0.394 (0.387)	Data 0.006 (0.009)	Loss 1.7274 (1.8252)	Loss@kd 1.6626 (1.6912)	Acc@1 76.562 (76.459)	Acc@5 98.438 (99.373)
Epoch: [81][700/875]	Time 0.379 (0.387)	Data 0.007 (0.009)	Loss 1.9895 (1.8243)	Loss@kd 1.6352 (1.6906)	Acc@1 68.750 (76.513)	Acc@5 95.312 (99.369)
Epoch: [81][800/875]	Time 0.363 (0.387)	Data 0.007 (0.009)	Loss 1.8484 (1.8263)	Loss@kd 1.6822 (1.6906)	Acc@1 76.562 (76.430)	Acc@5 98.438 (99.345)
 * Acc@1 76.400 Acc@5 99.343
epoch 81, total time 339.35
Test: [0/750]	Time 0.702 (0.702)	Loss 0.2557 (0.2557)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.093 (0.110)	Loss 0.5393 (0.4907)	Acc@1 78.125 (86.077)	Acc@5 96.875 (94.771)
Test: [200/750]	Time 0.110 (0.106)	Loss 0.9859 (0.5128)	Acc@1 56.250 (83.271)	Acc@5 93.750 (95.973)
Test: [300/750]	Time 0.114 (0.105)	Loss 1.1341 (0.7098)	Acc@1 59.375 (74.740)	Acc@5 90.625 (95.006)
Test: [400/750]	Time 0.099 (0.105)	Loss 0.4967 (0.7851)	Acc@1 84.375 (71.213)	Acc@5 96.875 (94.880)
Test: [500/750]	Time 0.114 (0.104)	Loss 0.5526 (0.7715)	Acc@1 81.250 (72.343)	Acc@5 100.000 (94.561)
Test: [600/750]	Time 0.103 (0.104)	Loss 0.7154 (0.7823)	Acc@1 75.000 (72.421)	Acc@5 93.750 (94.338)
Test: [700/750]	Time 0.105 (0.104)	Loss 0.9047 (0.7726)	Acc@1 65.625 (72.642)	Acc@5 90.625 (94.521)
 * Acc@1 72.775 Acc@5 94.467
==> training...
Epoch: [82][0/875]	Time 1.478 (1.478)	Data 1.065 (1.065)	Loss 1.7638 (1.7638)	Loss@kd 1.6292 (1.6292)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [82][100/875]	Time 0.473 (0.403)	Data 0.007 (0.018)	Loss 1.5969 (1.8108)	Loss@kd 1.6476 (1.6972)	Acc@1 81.250 (77.181)	Acc@5 100.000 (99.505)
Epoch: [82][200/875]	Time 0.373 (0.399)	Data 0.007 (0.012)	Loss 1.6212 (1.8102)	Loss@kd 1.6477 (1.6933)	Acc@1 81.250 (77.293)	Acc@5 100.000 (99.409)
Epoch: [82][300/875]	Time 0.371 (0.396)	Data 0.007 (0.011)	Loss 1.7465 (1.8191)	Loss@kd 1.6873 (1.6943)	Acc@1 81.250 (76.900)	Acc@5 100.000 (99.367)
Epoch: [82][400/875]	Time 0.362 (0.393)	Data 0.007 (0.010)	Loss 2.0213 (1.8181)	Loss@kd 1.6560 (1.6894)	Acc@1 70.312 (76.851)	Acc@5 98.438 (99.349)
Epoch: [82][500/875]	Time 0.372 (0.388)	Data 0.007 (0.009)	Loss 1.9564 (1.8165)	Loss@kd 1.7123 (1.6879)	Acc@1 68.750 (76.768)	Acc@5 100.000 (99.348)
Epoch: [82][600/875]	Time 0.369 (0.384)	Data 0.007 (0.009)	Loss 1.7565 (1.8177)	Loss@kd 1.7001 (1.6904)	Acc@1 78.125 (76.843)	Acc@5 100.000 (99.306)
Epoch: [82][700/875]	Time 0.369 (0.382)	Data 0.007 (0.008)	Loss 1.8969 (1.8211)	Loss@kd 1.7211 (1.6911)	Acc@1 75.000 (76.696)	Acc@5 100.000 (99.305)
Epoch: [82][800/875]	Time 0.362 (0.381)	Data 0.007 (0.008)	Loss 1.9651 (1.8211)	Loss@kd 1.7153 (1.6901)	Acc@1 75.000 (76.625)	Acc@5 98.438 (99.331)
 * Acc@1 76.532 Acc@5 99.330
epoch 82, total time 333.82
Test: [0/750]	Time 0.663 (0.663)	Loss 0.3786 (0.3786)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.108 (0.110)	Loss 0.5093 (0.5279)	Acc@1 75.000 (84.901)	Acc@5 100.000 (93.719)
Test: [200/750]	Time 0.116 (0.107)	Loss 1.0411 (0.5275)	Acc@1 65.625 (83.085)	Acc@5 93.750 (95.289)
Test: [300/750]	Time 0.079 (0.105)	Loss 1.0807 (0.7452)	Acc@1 59.375 (73.432)	Acc@5 90.625 (94.373)
Test: [400/750]	Time 0.101 (0.105)	Loss 0.6048 (0.8152)	Acc@1 81.250 (70.519)	Acc@5 96.875 (94.264)
Test: [500/750]	Time 0.114 (0.105)	Loss 0.4500 (0.7984)	Acc@1 84.375 (71.601)	Acc@5 100.000 (93.975)
Test: [600/750]	Time 0.099 (0.105)	Loss 0.8032 (0.7996)	Acc@1 75.000 (72.000)	Acc@5 93.750 (93.953)
Test: [700/750]	Time 0.119 (0.105)	Loss 0.8916 (0.7900)	Acc@1 62.500 (72.071)	Acc@5 90.625 (94.227)
 * Acc@1 72.292 Acc@5 94.292
==> training...
Epoch: [83][0/875]	Time 1.764 (1.764)	Data 1.294 (1.294)	Loss 1.9623 (1.9623)	Loss@kd 1.6883 (1.6883)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [83][100/875]	Time 0.420 (0.392)	Data 0.005 (0.019)	Loss 2.0058 (1.8224)	Loss@kd 1.7984 (1.6880)	Acc@1 75.000 (76.238)	Acc@5 98.438 (99.335)
Epoch: [83][200/875]	Time 0.367 (0.387)	Data 0.007 (0.013)	Loss 1.7999 (1.8168)	Loss@kd 1.7089 (1.6882)	Acc@1 81.250 (76.477)	Acc@5 100.000 (99.440)
Epoch: [83][300/875]	Time 0.357 (0.385)	Data 0.007 (0.011)	Loss 1.6653 (1.8177)	Loss@kd 1.6162 (1.6888)	Acc@1 82.812 (76.433)	Acc@5 100.000 (99.413)
Epoch: [83][400/875]	Time 0.394 (0.384)	Data 0.007 (0.010)	Loss 2.0143 (1.8155)	Loss@kd 1.9483 (1.6893)	Acc@1 71.875 (76.598)	Acc@5 98.438 (99.439)
Epoch: [83][500/875]	Time 0.395 (0.383)	Data 0.007 (0.009)	Loss 1.7892 (1.8140)	Loss@kd 1.6930 (1.6903)	Acc@1 78.125 (76.718)	Acc@5 100.000 (99.404)
Epoch: [83][600/875]	Time 0.411 (0.384)	Data 0.007 (0.009)	Loss 1.7639 (1.8138)	Loss@kd 1.6515 (1.6891)	Acc@1 78.125 (76.752)	Acc@5 100.000 (99.376)
Epoch: [83][700/875]	Time 0.365 (0.383)	Data 0.007 (0.009)	Loss 1.7556 (1.8161)	Loss@kd 1.6623 (1.6889)	Acc@1 75.000 (76.658)	Acc@5 100.000 (99.371)
Epoch: [83][800/875]	Time 0.404 (0.383)	Data 0.006 (0.008)	Loss 1.7443 (1.8130)	Loss@kd 1.6700 (1.6881)	Acc@1 79.688 (76.752)	Acc@5 100.000 (99.378)
 * Acc@1 76.732 Acc@5 99.373
epoch 83, total time 334.94
Test: [0/750]	Time 0.797 (0.797)	Loss 0.3019 (0.3019)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.069 (0.106)	Loss 0.5663 (0.5101)	Acc@1 78.125 (85.644)	Acc@5 96.875 (94.802)
Test: [200/750]	Time 0.098 (0.102)	Loss 1.2062 (0.5375)	Acc@1 56.250 (82.882)	Acc@5 93.750 (95.911)
Test: [300/750]	Time 0.096 (0.103)	Loss 1.0497 (0.7419)	Acc@1 62.500 (73.848)	Acc@5 90.625 (94.809)
Test: [400/750]	Time 0.090 (0.103)	Loss 0.3802 (0.7986)	Acc@1 87.500 (71.368)	Acc@5 96.875 (94.740)
Test: [500/750]	Time 0.100 (0.103)	Loss 0.5210 (0.7672)	Acc@1 84.375 (73.066)	Acc@5 100.000 (94.517)
Test: [600/750]	Time 0.097 (0.103)	Loss 0.7760 (0.7737)	Acc@1 78.125 (73.196)	Acc@5 93.750 (94.343)
Test: [700/750]	Time 0.084 (0.103)	Loss 1.0185 (0.7701)	Acc@1 62.500 (73.186)	Acc@5 93.750 (94.512)
 * Acc@1 73.304 Acc@5 94.496
saving the best model!
==> training...
Epoch: [84][0/875]	Time 1.538 (1.538)	Data 1.154 (1.154)	Loss 1.6291 (1.6291)	Loss@kd 1.6280 (1.6280)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [84][100/875]	Time 0.461 (0.380)	Data 0.007 (0.018)	Loss 1.7418 (1.8137)	Loss@kd 1.6972 (1.6907)	Acc@1 78.125 (77.413)	Acc@5 100.000 (99.273)
Epoch: [84][200/875]	Time 0.363 (0.374)	Data 0.007 (0.013)	Loss 1.9069 (1.8060)	Loss@kd 1.8440 (1.6914)	Acc@1 79.688 (77.387)	Acc@5 100.000 (99.355)
Epoch: [84][300/875]	Time 0.358 (0.373)	Data 0.007 (0.011)	Loss 1.7807 (1.8079)	Loss@kd 1.6390 (1.6916)	Acc@1 71.875 (77.144)	Acc@5 98.438 (99.351)
Epoch: [84][400/875]	Time 0.357 (0.370)	Data 0.007 (0.010)	Loss 1.8590 (1.8042)	Loss@kd 1.6876 (1.6894)	Acc@1 82.812 (77.221)	Acc@5 98.438 (99.365)
Epoch: [84][500/875]	Time 0.343 (0.367)	Data 0.006 (0.009)	Loss 1.8620 (1.8044)	Loss@kd 1.6696 (1.6877)	Acc@1 78.125 (77.211)	Acc@5 98.438 (99.358)
Epoch: [84][600/875]	Time 0.348 (0.364)	Data 0.007 (0.009)	Loss 1.8627 (1.8072)	Loss@kd 1.6358 (1.6869)	Acc@1 73.438 (77.140)	Acc@5 100.000 (99.360)
Epoch: [84][700/875]	Time 0.341 (0.364)	Data 0.006 (0.008)	Loss 1.8982 (1.8076)	Loss@kd 1.6778 (1.6871)	Acc@1 73.438 (77.131)	Acc@5 98.438 (99.387)
Epoch: [84][800/875]	Time 0.353 (0.363)	Data 0.007 (0.008)	Loss 1.9414 (1.8086)	Loss@kd 1.7109 (1.6882)	Acc@1 73.438 (77.105)	Acc@5 100.000 (99.403)
 * Acc@1 77.071 Acc@5 99.398
epoch 84, total time 323.28
Test: [0/750]	Time 0.794 (0.794)	Loss 0.4219 (0.4219)	Acc@1 87.500 (87.500)	Acc@5 93.750 (93.750)
Test: [100/750]	Time 0.097 (0.103)	Loss 0.4791 (0.5291)	Acc@1 81.250 (85.489)	Acc@5 100.000 (94.121)
Test: [200/750]	Time 0.107 (0.105)	Loss 1.0350 (0.5163)	Acc@1 56.250 (84.157)	Acc@5 93.750 (95.740)
Test: [300/750]	Time 0.104 (0.108)	Loss 1.0981 (0.7137)	Acc@1 65.625 (75.457)	Acc@5 96.875 (94.944)
Test: [400/750]	Time 0.107 (0.109)	Loss 0.5033 (0.7721)	Acc@1 84.375 (72.561)	Acc@5 96.875 (95.075)
Test: [500/750]	Time 0.114 (0.109)	Loss 0.5187 (0.7610)	Acc@1 81.250 (73.497)	Acc@5 100.000 (94.717)
Test: [600/750]	Time 0.100 (0.110)	Loss 0.7420 (0.7809)	Acc@1 75.000 (73.113)	Acc@5 93.750 (94.442)
Test: [700/750]	Time 0.101 (0.110)	Loss 0.9624 (0.7754)	Acc@1 65.625 (72.998)	Acc@5 93.750 (94.597)
 * Acc@1 73.258 Acc@5 94.642
==> training...
Epoch: [85][0/875]	Time 1.688 (1.688)	Data 1.202 (1.202)	Loss 1.6842 (1.6842)	Loss@kd 1.6831 (1.6831)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [85][100/875]	Time 0.488 (0.434)	Data 0.007 (0.019)	Loss 1.7097 (1.8038)	Loss@kd 1.6649 (1.6906)	Acc@1 81.250 (77.073)	Acc@5 100.000 (99.505)
Epoch: [85][200/875]	Time 0.418 (0.426)	Data 0.007 (0.013)	Loss 1.7768 (1.7986)	Loss@kd 1.6657 (1.6884)	Acc@1 78.125 (77.456)	Acc@5 98.438 (99.433)
Epoch: [85][300/875]	Time 0.416 (0.423)	Data 0.007 (0.011)	Loss 2.2518 (1.8064)	Loss@kd 1.7338 (1.6873)	Acc@1 67.188 (77.009)	Acc@5 98.438 (99.372)
Epoch: [85][400/875]	Time 0.389 (0.421)	Data 0.006 (0.010)	Loss 1.7370 (1.8073)	Loss@kd 1.6464 (1.6881)	Acc@1 76.562 (76.972)	Acc@5 100.000 (99.349)
Epoch: [85][500/875]	Time 0.427 (0.420)	Data 0.008 (0.009)	Loss 1.7116 (1.8044)	Loss@kd 1.6330 (1.6864)	Acc@1 79.688 (77.008)	Acc@5 98.438 (99.354)
Epoch: [85][600/875]	Time 0.424 (0.419)	Data 0.007 (0.009)	Loss 1.7408 (1.8067)	Loss@kd 1.6387 (1.6867)	Acc@1 78.125 (76.978)	Acc@5 100.000 (99.363)
Epoch: [85][700/875]	Time 0.374 (0.419)	Data 0.007 (0.009)	Loss 1.9030 (1.8053)	Loss@kd 1.6484 (1.6858)	Acc@1 75.000 (77.039)	Acc@5 100.000 (99.376)
Epoch: [85][800/875]	Time 0.378 (0.418)	Data 0.005 (0.008)	Loss 1.6462 (1.8053)	Loss@kd 1.6359 (1.6856)	Acc@1 87.500 (77.062)	Acc@5 100.000 (99.389)
 * Acc@1 77.070 Acc@5 99.396
epoch 85, total time 365.80
Test: [0/750]	Time 0.778 (0.778)	Loss 0.3114 (0.3114)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.104 (0.115)	Loss 0.4255 (0.5013)	Acc@1 84.375 (86.015)	Acc@5 100.000 (94.554)
Test: [200/750]	Time 0.104 (0.111)	Loss 1.2791 (0.5047)	Acc@1 59.375 (84.157)	Acc@5 90.625 (95.771)
Test: [300/750]	Time 0.105 (0.110)	Loss 1.1108 (0.7463)	Acc@1 59.375 (73.630)	Acc@5 90.625 (94.352)
Test: [400/750]	Time 0.105 (0.108)	Loss 0.5939 (0.8121)	Acc@1 78.125 (70.675)	Acc@5 96.875 (94.529)
Test: [500/750]	Time 0.114 (0.107)	Loss 0.4625 (0.7940)	Acc@1 90.625 (72.043)	Acc@5 100.000 (94.330)
Test: [600/750]	Time 0.102 (0.107)	Loss 0.9101 (0.8097)	Acc@1 71.875 (71.802)	Acc@5 90.625 (94.072)
Test: [700/750]	Time 0.100 (0.107)	Loss 0.8581 (0.7997)	Acc@1 71.875 (71.915)	Acc@5 93.750 (94.280)
 * Acc@1 72.217 Acc@5 94.321
==> training...
Epoch: [86][0/875]	Time 1.781 (1.781)	Data 1.288 (1.288)	Loss 1.7588 (1.7588)	Loss@kd 1.6695 (1.6695)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [86][100/875]	Time 0.460 (0.420)	Data 0.007 (0.019)	Loss 1.7920 (1.7984)	Loss@kd 1.7150 (1.6895)	Acc@1 79.688 (77.228)	Acc@5 100.000 (99.288)
Epoch: [86][200/875]	Time 0.371 (0.411)	Data 0.007 (0.013)	Loss 1.9309 (1.7916)	Loss@kd 1.6655 (1.6849)	Acc@1 73.438 (77.247)	Acc@5 98.438 (99.394)
Epoch: [86][300/875]	Time 0.377 (0.398)	Data 0.007 (0.011)	Loss 1.8202 (1.7919)	Loss@kd 1.6778 (1.6828)	Acc@1 75.000 (77.403)	Acc@5 100.000 (99.398)
Epoch: [86][400/875]	Time 0.356 (0.393)	Data 0.007 (0.010)	Loss 1.9255 (1.7943)	Loss@kd 1.6435 (1.6824)	Acc@1 79.688 (77.287)	Acc@5 96.875 (99.345)
Epoch: [86][500/875]	Time 0.357 (0.395)	Data 0.007 (0.010)	Loss 1.8191 (1.7983)	Loss@kd 1.6677 (1.6835)	Acc@1 76.562 (77.146)	Acc@5 98.438 (99.339)
Epoch: [86][600/875]	Time 0.416 (0.398)	Data 0.007 (0.009)	Loss 1.7351 (1.7999)	Loss@kd 1.6172 (1.6835)	Acc@1 76.562 (77.114)	Acc@5 100.000 (99.334)
Epoch: [86][700/875]	Time 0.440 (0.400)	Data 0.007 (0.009)	Loss 1.8140 (1.7975)	Loss@kd 1.7744 (1.6831)	Acc@1 79.688 (77.126)	Acc@5 100.000 (99.342)
Epoch: [86][800/875]	Time 0.429 (0.402)	Data 0.007 (0.009)	Loss 1.9517 (1.7990)	Loss@kd 1.8971 (1.6843)	Acc@1 81.250 (77.152)	Acc@5 100.000 (99.347)
 * Acc@1 77.129 Acc@5 99.348
epoch 86, total time 352.69
Test: [0/750]	Time 0.817 (0.817)	Loss 0.3164 (0.3164)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.092 (0.112)	Loss 0.4483 (0.4891)	Acc@1 81.250 (86.510)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.108 (0.107)	Loss 1.0468 (0.4891)	Acc@1 65.625 (84.888)	Acc@5 93.750 (96.020)
Test: [300/750]	Time 0.098 (0.105)	Loss 1.2820 (0.6904)	Acc@1 56.250 (75.955)	Acc@5 90.625 (95.193)
Test: [400/750]	Time 0.095 (0.105)	Loss 0.4573 (0.7792)	Acc@1 87.500 (72.101)	Acc@5 96.875 (94.623)
Test: [500/750]	Time 0.109 (0.105)	Loss 0.3998 (0.7601)	Acc@1 90.625 (73.391)	Acc@5 100.000 (94.330)
Test: [600/750]	Time 0.068 (0.104)	Loss 0.9141 (0.7705)	Acc@1 71.875 (73.341)	Acc@5 93.750 (94.280)
Test: [700/750]	Time 0.091 (0.104)	Loss 0.7687 (0.7641)	Acc@1 75.000 (73.319)	Acc@5 96.875 (94.512)
 * Acc@1 73.679 Acc@5 94.592
saving the best model!
==> training...
Epoch: [87][0/875]	Time 1.860 (1.860)	Data 1.412 (1.412)	Loss 1.9290 (1.9290)	Loss@kd 1.7302 (1.7302)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [87][100/875]	Time 0.494 (0.434)	Data 0.007 (0.021)	Loss 1.8113 (1.7973)	Loss@kd 1.6617 (1.6881)	Acc@1 75.000 (77.614)	Acc@5 100.000 (99.520)
Epoch: [87][200/875]	Time 0.418 (0.422)	Data 0.007 (0.014)	Loss 1.8713 (1.7917)	Loss@kd 1.7054 (1.6826)	Acc@1 73.438 (77.511)	Acc@5 100.000 (99.510)
Epoch: [87][300/875]	Time 0.423 (0.417)	Data 0.007 (0.011)	Loss 1.7972 (1.7939)	Loss@kd 1.7222 (1.6843)	Acc@1 81.250 (77.326)	Acc@5 98.438 (99.445)
Epoch: [87][400/875]	Time 0.370 (0.416)	Data 0.007 (0.010)	Loss 1.8774 (1.7930)	Loss@kd 1.6937 (1.6825)	Acc@1 73.438 (77.408)	Acc@5 98.438 (99.439)
Epoch: [87][500/875]	Time 0.427 (0.416)	Data 0.006 (0.010)	Loss 1.7325 (1.7980)	Loss@kd 1.6575 (1.6831)	Acc@1 78.125 (77.249)	Acc@5 100.000 (99.454)
Epoch: [87][600/875]	Time 0.420 (0.415)	Data 0.007 (0.009)	Loss 1.8125 (1.7954)	Loss@kd 1.6903 (1.6836)	Acc@1 78.125 (77.366)	Acc@5 100.000 (99.451)
Epoch: [87][700/875]	Time 0.425 (0.415)	Data 0.007 (0.009)	Loss 1.8142 (1.7948)	Loss@kd 1.7108 (1.6827)	Acc@1 76.562 (77.329)	Acc@5 100.000 (99.465)
Epoch: [87][800/875]	Time 0.387 (0.413)	Data 0.007 (0.009)	Loss 1.8288 (1.7980)	Loss@kd 1.6510 (1.6839)	Acc@1 75.000 (77.224)	Acc@5 98.438 (99.462)
 * Acc@1 77.227 Acc@5 99.434
epoch 87, total time 358.62
Test: [0/750]	Time 0.864 (0.864)	Loss 0.2774 (0.2774)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.086 (0.109)	Loss 0.4213 (0.4959)	Acc@1 84.375 (86.324)	Acc@5 100.000 (95.019)
Test: [200/750]	Time 0.120 (0.103)	Loss 1.1978 (0.5110)	Acc@1 53.125 (84.344)	Acc@5 87.500 (95.911)
Test: [300/750]	Time 0.065 (0.103)	Loss 1.0362 (0.7386)	Acc@1 65.625 (74.242)	Acc@5 93.750 (94.653)
Test: [400/750]	Time 0.116 (0.102)	Loss 0.5066 (0.7975)	Acc@1 87.500 (71.446)	Acc@5 96.875 (94.685)
Test: [500/750]	Time 0.095 (0.102)	Loss 0.4592 (0.7832)	Acc@1 87.500 (72.692)	Acc@5 96.875 (94.349)
Test: [600/750]	Time 0.110 (0.100)	Loss 0.8202 (0.7969)	Acc@1 75.000 (72.489)	Acc@5 93.750 (94.182)
Test: [700/750]	Time 0.108 (0.101)	Loss 0.9456 (0.7878)	Acc@1 65.625 (72.548)	Acc@5 90.625 (94.392)
 * Acc@1 72.879 Acc@5 94.425
==> training...
Epoch: [88][0/875]	Time 1.863 (1.863)	Data 1.385 (1.385)	Loss 1.6624 (1.6624)	Loss@kd 1.6393 (1.6393)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [88][100/875]	Time 0.455 (0.424)	Data 0.005 (0.020)	Loss 1.6245 (1.8102)	Loss@kd 1.6488 (1.6965)	Acc@1 82.812 (77.986)	Acc@5 100.000 (99.304)
Epoch: [88][200/875]	Time 0.454 (0.417)	Data 0.007 (0.014)	Loss 1.7539 (1.7895)	Loss@kd 1.7687 (1.6882)	Acc@1 79.688 (78.133)	Acc@5 100.000 (99.417)
Epoch: [88][300/875]	Time 0.435 (0.416)	Data 0.007 (0.011)	Loss 1.7993 (1.7869)	Loss@kd 1.6155 (1.6834)	Acc@1 78.125 (77.793)	Acc@5 98.438 (99.445)
Epoch: [88][400/875]	Time 0.377 (0.413)	Data 0.007 (0.010)	Loss 1.7359 (1.7919)	Loss@kd 1.6137 (1.6835)	Acc@1 71.875 (77.521)	Acc@5 100.000 (99.443)
Epoch: [88][500/875]	Time 0.376 (0.413)	Data 0.007 (0.010)	Loss 1.7504 (1.7922)	Loss@kd 1.6443 (1.6830)	Acc@1 75.000 (77.476)	Acc@5 98.438 (99.445)
Epoch: [88][600/875]	Time 0.404 (0.412)	Data 0.007 (0.009)	Loss 1.6258 (1.7929)	Loss@kd 1.6549 (1.6835)	Acc@1 79.688 (77.467)	Acc@5 100.000 (99.412)
Epoch: [88][700/875]	Time 0.407 (0.412)	Data 0.007 (0.009)	Loss 1.8054 (1.7927)	Loss@kd 1.6909 (1.6827)	Acc@1 78.125 (77.523)	Acc@5 100.000 (99.427)
Epoch: [88][800/875]	Time 0.417 (0.413)	Data 0.007 (0.009)	Loss 2.3141 (1.7907)	Loss@kd 2.0928 (1.6824)	Acc@1 67.188 (77.569)	Acc@5 98.438 (99.434)
 * Acc@1 77.588 Acc@5 99.432
epoch 88, total time 361.48
Test: [0/750]	Time 0.796 (0.796)	Loss 0.3368 (0.3368)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.107 (0.116)	Loss 0.4943 (0.4943)	Acc@1 81.250 (86.077)	Acc@5 100.000 (95.019)
Test: [200/750]	Time 0.102 (0.111)	Loss 1.2100 (0.5190)	Acc@1 53.125 (83.396)	Acc@5 90.625 (96.082)
Test: [300/750]	Time 0.099 (0.110)	Loss 1.0423 (0.7361)	Acc@1 68.750 (73.661)	Acc@5 96.875 (95.058)
Test: [400/750]	Time 0.105 (0.110)	Loss 0.5017 (0.7953)	Acc@1 84.375 (71.244)	Acc@5 96.875 (94.825)
Test: [500/750]	Time 0.107 (0.110)	Loss 0.4488 (0.7763)	Acc@1 87.500 (72.599)	Acc@5 100.000 (94.586)
Test: [600/750]	Time 0.095 (0.110)	Loss 0.7090 (0.7806)	Acc@1 78.125 (72.785)	Acc@5 90.625 (94.468)
Test: [700/750]	Time 0.110 (0.110)	Loss 0.8322 (0.7728)	Acc@1 68.750 (72.847)	Acc@5 93.750 (94.637)
 * Acc@1 73.083 Acc@5 94.688
==> training...
Epoch: [89][0/875]	Time 1.899 (1.899)	Data 1.391 (1.391)	Loss 2.0928 (2.0928)	Loss@kd 1.8990 (1.8990)	Acc@1 75.000 (75.000)	Acc@5 98.438 (98.438)
Epoch: [89][100/875]	Time 0.489 (0.429)	Data 0.008 (0.020)	Loss 1.6319 (1.7742)	Loss@kd 1.7185 (1.6759)	Acc@1 82.812 (78.295)	Acc@5 100.000 (99.412)
Epoch: [89][200/875]	Time 0.418 (0.420)	Data 0.005 (0.013)	Loss 1.9715 (1.7862)	Loss@kd 1.7687 (1.6773)	Acc@1 67.188 (77.791)	Acc@5 98.438 (99.417)
Epoch: [89][300/875]	Time 0.414 (0.418)	Data 0.007 (0.011)	Loss 1.7341 (1.7839)	Loss@kd 1.6771 (1.6793)	Acc@1 79.688 (77.907)	Acc@5 100.000 (99.367)
Epoch: [89][400/875]	Time 0.368 (0.406)	Data 0.007 (0.010)	Loss 1.8851 (1.7885)	Loss@kd 1.7552 (1.6806)	Acc@1 76.562 (77.809)	Acc@5 100.000 (99.369)
Epoch: [89][500/875]	Time 0.363 (0.400)	Data 0.005 (0.009)	Loss 1.7089 (1.7881)	Loss@kd 1.6416 (1.6813)	Acc@1 85.938 (77.872)	Acc@5 100.000 (99.376)
Epoch: [89][600/875]	Time 0.416 (0.397)	Data 0.007 (0.009)	Loss 1.7283 (1.7913)	Loss@kd 1.6650 (1.6827)	Acc@1 79.688 (77.795)	Acc@5 98.438 (99.358)
Epoch: [89][700/875]	Time 0.384 (0.399)	Data 0.007 (0.009)	Loss 1.7298 (1.7928)	Loss@kd 1.6674 (1.6822)	Acc@1 78.125 (77.666)	Acc@5 100.000 (99.365)
Epoch: [89][800/875]	Time 0.414 (0.399)	Data 0.007 (0.008)	Loss 1.8167 (1.7920)	Loss@kd 1.7128 (1.6813)	Acc@1 79.688 (77.540)	Acc@5 100.000 (99.393)
 * Acc@1 77.604 Acc@5 99.418
epoch 89, total time 350.35
Test: [0/750]	Time 0.840 (0.840)	Loss 0.3649 (0.3649)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.112 (0.115)	Loss 0.5238 (0.5355)	Acc@1 75.000 (85.396)	Acc@5 100.000 (94.369)
Test: [200/750]	Time 0.108 (0.109)	Loss 1.2004 (0.5365)	Acc@1 62.500 (83.209)	Acc@5 90.625 (95.756)
Test: [300/750]	Time 0.100 (0.108)	Loss 1.1622 (0.7363)	Acc@1 59.375 (74.294)	Acc@5 90.625 (94.747)
Test: [400/750]	Time 0.107 (0.107)	Loss 0.5087 (0.8032)	Acc@1 84.375 (71.407)	Acc@5 96.875 (94.623)
Test: [500/750]	Time 0.089 (0.107)	Loss 0.5137 (0.7793)	Acc@1 84.375 (72.761)	Acc@5 100.000 (94.436)
Test: [600/750]	Time 0.103 (0.106)	Loss 0.8151 (0.7928)	Acc@1 71.875 (72.525)	Acc@5 93.750 (94.265)
Test: [700/750]	Time 0.093 (0.106)	Loss 0.9927 (0.7872)	Acc@1 59.375 (72.517)	Acc@5 93.750 (94.494)
 * Acc@1 72.725 Acc@5 94.512
==> training...
Epoch: [90][0/875]	Time 2.088 (2.088)	Data 1.596 (1.596)	Loss 1.7882 (1.7882)	Loss@kd 1.6047 (1.6047)	Acc@1 68.750 (68.750)	Acc@5 100.000 (100.000)
Epoch: [90][100/875]	Time 0.360 (0.419)	Data 0.004 (0.022)	Loss 1.5882 (1.7554)	Loss@kd 1.6550 (1.6798)	Acc@1 85.938 (78.311)	Acc@5 100.000 (99.613)
Epoch: [90][200/875]	Time 0.432 (0.413)	Data 0.007 (0.014)	Loss 1.8054 (1.7670)	Loss@kd 1.6417 (1.6825)	Acc@1 75.000 (78.280)	Acc@5 100.000 (99.518)
Epoch: [90][300/875]	Time 0.472 (0.410)	Data 0.007 (0.012)	Loss 1.6449 (1.7705)	Loss@kd 1.6395 (1.6823)	Acc@1 81.250 (78.058)	Acc@5 100.000 (99.491)
Epoch: [90][400/875]	Time 0.402 (0.409)	Data 0.007 (0.011)	Loss 1.7663 (1.7734)	Loss@kd 1.7240 (1.6826)	Acc@1 82.812 (78.008)	Acc@5 100.000 (99.478)
Epoch: [90][500/875]	Time 0.383 (0.407)	Data 0.013 (0.010)	Loss 1.6005 (1.7775)	Loss@kd 1.6225 (1.6828)	Acc@1 81.250 (77.885)	Acc@5 100.000 (99.460)
Epoch: [90][600/875]	Time 0.414 (0.406)	Data 0.008 (0.009)	Loss 1.9253 (1.7768)	Loss@kd 1.8281 (1.6804)	Acc@1 73.438 (77.857)	Acc@5 100.000 (99.446)
Epoch: [90][700/875]	Time 0.346 (0.406)	Data 0.006 (0.009)	Loss 1.6903 (1.7803)	Loss@kd 1.6797 (1.6809)	Acc@1 81.250 (77.764)	Acc@5 100.000 (99.407)
Epoch: [90][800/875]	Time 0.358 (0.406)	Data 0.007 (0.009)	Loss 1.7604 (1.7792)	Loss@kd 1.6916 (1.6816)	Acc@1 78.125 (77.788)	Acc@5 100.000 (99.425)
 * Acc@1 77.679 Acc@5 99.430
epoch 90, total time 355.50
Test: [0/750]	Time 0.944 (0.944)	Loss 0.3556 (0.3556)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.116 (0.121)	Loss 0.4455 (0.4558)	Acc@1 84.375 (87.067)	Acc@5 100.000 (94.926)
Test: [200/750]	Time 0.117 (0.115)	Loss 1.2104 (0.4822)	Acc@1 53.125 (85.152)	Acc@5 93.750 (96.051)
Test: [300/750]	Time 0.112 (0.113)	Loss 1.1314 (0.7102)	Acc@1 56.250 (75.228)	Acc@5 100.000 (95.017)
Test: [400/750]	Time 0.105 (0.111)	Loss 0.7136 (0.7784)	Acc@1 78.125 (72.241)	Acc@5 93.750 (94.950)
Test: [500/750]	Time 0.087 (0.110)	Loss 0.5188 (0.7774)	Acc@1 84.375 (72.698)	Acc@5 96.875 (94.523)
Test: [600/750]	Time 0.171 (0.109)	Loss 0.8345 (0.7933)	Acc@1 75.000 (72.317)	Acc@5 90.625 (94.244)
Test: [700/750]	Time 0.180 (0.109)	Loss 0.7683 (0.7861)	Acc@1 68.750 (72.325)	Acc@5 93.750 (94.401)
 * Acc@1 72.642 Acc@5 94.450
==> training...
Epoch: [91][0/875]	Time 1.650 (1.650)	Data 1.275 (1.275)	Loss 1.7105 (1.7105)	Loss@kd 1.6298 (1.6298)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [91][100/875]	Time 0.433 (0.387)	Data 0.007 (0.019)	Loss 1.8537 (1.7655)	Loss@kd 1.6697 (1.6726)	Acc@1 75.000 (78.079)	Acc@5 100.000 (99.397)
Epoch: [91][200/875]	Time 0.437 (0.402)	Data 0.007 (0.013)	Loss 1.5249 (1.7583)	Loss@kd 1.6549 (1.6740)	Acc@1 85.938 (78.280)	Acc@5 98.438 (99.557)
Epoch: [91][300/875]	Time 0.451 (0.406)	Data 0.007 (0.011)	Loss 1.7707 (1.7579)	Loss@kd 1.6025 (1.6774)	Acc@1 76.562 (78.525)	Acc@5 98.438 (99.533)
Epoch: [91][400/875]	Time 0.424 (0.408)	Data 0.008 (0.010)	Loss 1.6168 (1.7533)	Loss@kd 1.6324 (1.6764)	Acc@1 81.250 (78.503)	Acc@5 100.000 (99.532)
Epoch: [91][500/875]	Time 0.429 (0.409)	Data 0.007 (0.009)	Loss 1.7524 (1.7509)	Loss@kd 1.5861 (1.6754)	Acc@1 75.000 (78.705)	Acc@5 100.000 (99.535)
Epoch: [91][600/875]	Time 0.420 (0.410)	Data 0.007 (0.009)	Loss 1.6871 (1.7526)	Loss@kd 1.7521 (1.6755)	Acc@1 79.688 (78.606)	Acc@5 100.000 (99.542)
Epoch: [91][700/875]	Time 0.436 (0.410)	Data 0.006 (0.009)	Loss 1.6683 (1.7548)	Loss@kd 1.5794 (1.6750)	Acc@1 82.812 (78.557)	Acc@5 100.000 (99.527)
Epoch: [91][800/875]	Time 0.378 (0.410)	Data 0.008 (0.008)	Loss 1.6037 (1.7546)	Loss@kd 1.6562 (1.6751)	Acc@1 82.812 (78.599)	Acc@5 100.000 (99.524)
 * Acc@1 78.661 Acc@5 99.516
epoch 91, total time 359.50
Test: [0/750]	Time 0.816 (0.816)	Loss 0.2936 (0.2936)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.093 (0.115)	Loss 0.4631 (0.5117)	Acc@1 84.375 (86.448)	Acc@5 100.000 (94.524)
Test: [200/750]	Time 0.105 (0.107)	Loss 1.0567 (0.5120)	Acc@1 59.375 (84.577)	Acc@5 93.750 (95.880)
Test: [300/750]	Time 0.114 (0.107)	Loss 1.1022 (0.7146)	Acc@1 59.375 (75.311)	Acc@5 93.750 (94.985)
Test: [400/750]	Time 0.134 (0.105)	Loss 0.5428 (0.7775)	Acc@1 81.250 (72.311)	Acc@5 93.750 (94.919)
Test: [500/750]	Time 0.103 (0.105)	Loss 0.4435 (0.7598)	Acc@1 87.500 (73.553)	Acc@5 100.000 (94.661)
Test: [600/750]	Time 0.087 (0.104)	Loss 0.8075 (0.7686)	Acc@1 71.875 (73.492)	Acc@5 90.625 (94.546)
Test: [700/750]	Time 0.093 (0.105)	Loss 0.8199 (0.7630)	Acc@1 68.750 (73.471)	Acc@5 93.750 (94.749)
 * Acc@1 73.737 Acc@5 94.779
saving the best model!
==> training...
Epoch: [92][0/875]	Time 1.818 (1.818)	Data 1.392 (1.392)	Loss 1.7030 (1.7030)	Loss@kd 1.6348 (1.6348)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [92][100/875]	Time 0.451 (0.429)	Data 0.006 (0.021)	Loss 1.5683 (1.7444)	Loss@kd 1.6456 (1.6748)	Acc@1 82.812 (78.388)	Acc@5 100.000 (99.551)
Epoch: [92][200/875]	Time 0.392 (0.420)	Data 0.006 (0.014)	Loss 1.7052 (1.7484)	Loss@kd 1.6992 (1.6774)	Acc@1 79.688 (78.451)	Acc@5 100.000 (99.495)
Epoch: [92][300/875]	Time 0.425 (0.418)	Data 0.007 (0.012)	Loss 1.5972 (1.7483)	Loss@kd 1.6448 (1.6771)	Acc@1 85.938 (78.551)	Acc@5 98.438 (99.455)
Epoch: [92][400/875]	Time 0.405 (0.416)	Data 0.006 (0.010)	Loss 1.7281 (1.7514)	Loss@kd 1.6667 (1.6788)	Acc@1 78.125 (78.569)	Acc@5 100.000 (99.497)
Epoch: [92][500/875]	Time 0.364 (0.411)	Data 0.009 (0.010)	Loss 1.7860 (1.7484)	Loss@kd 1.6381 (1.6782)	Acc@1 78.125 (78.699)	Acc@5 100.000 (99.520)
Epoch: [92][600/875]	Time 0.405 (0.406)	Data 0.009 (0.009)	Loss 1.7143 (1.7476)	Loss@kd 1.6069 (1.6756)	Acc@1 81.250 (78.611)	Acc@5 96.875 (99.501)
Epoch: [92][700/875]	Time 0.412 (0.402)	Data 0.007 (0.009)	Loss 1.5688 (1.7465)	Loss@kd 1.6072 (1.6744)	Acc@1 84.375 (78.783)	Acc@5 100.000 (99.514)
Epoch: [92][800/875]	Time 0.380 (0.403)	Data 0.006 (0.009)	Loss 1.6319 (1.7483)	Loss@kd 1.6812 (1.6735)	Acc@1 85.938 (78.745)	Acc@5 100.000 (99.506)
 * Acc@1 78.625 Acc@5 99.509
epoch 92, total time 353.73
Test: [0/750]	Time 0.901 (0.901)	Loss 0.3123 (0.3123)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.117 (0.119)	Loss 0.4581 (0.5038)	Acc@1 84.375 (86.386)	Acc@5 100.000 (94.740)
Test: [200/750]	Time 0.106 (0.113)	Loss 1.1189 (0.5042)	Acc@1 56.250 (84.624)	Acc@5 90.625 (95.973)
Test: [300/750]	Time 0.115 (0.112)	Loss 1.1314 (0.7135)	Acc@1 59.375 (75.249)	Acc@5 93.750 (94.913)
Test: [400/750]	Time 0.104 (0.111)	Loss 0.5260 (0.7654)	Acc@1 84.375 (72.849)	Acc@5 96.875 (95.005)
Test: [500/750]	Time 0.091 (0.110)	Loss 0.5036 (0.7480)	Acc@1 81.250 (74.008)	Acc@5 100.000 (94.748)
Test: [600/750]	Time 0.122 (0.110)	Loss 0.8332 (0.7624)	Acc@1 71.875 (73.684)	Acc@5 90.625 (94.618)
Test: [700/750]	Time 0.115 (0.110)	Loss 0.9499 (0.7619)	Acc@1 59.375 (73.475)	Acc@5 93.750 (94.695)
 * Acc@1 73.508 Acc@5 94.683
==> training...
Epoch: [93][0/875]	Time 1.858 (1.858)	Data 1.377 (1.377)	Loss 1.7867 (1.7867)	Loss@kd 1.6200 (1.6200)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [93][100/875]	Time 0.437 (0.424)	Data 0.007 (0.020)	Loss 1.8255 (1.7395)	Loss@kd 1.6852 (1.6689)	Acc@1 76.562 (79.069)	Acc@5 100.000 (99.551)
Epoch: [93][200/875]	Time 0.434 (0.417)	Data 0.007 (0.014)	Loss 1.6892 (1.7504)	Loss@kd 1.6584 (1.6766)	Acc@1 81.250 (78.926)	Acc@5 100.000 (99.565)
Epoch: [93][300/875]	Time 0.423 (0.414)	Data 0.007 (0.011)	Loss 1.7469 (1.7497)	Loss@kd 1.6333 (1.6783)	Acc@1 78.125 (79.013)	Acc@5 98.438 (99.512)
Epoch: [93][400/875]	Time 0.451 (0.414)	Data 0.008 (0.010)	Loss 1.8350 (1.7500)	Loss@kd 1.7659 (1.6765)	Acc@1 76.562 (78.873)	Acc@5 100.000 (99.423)
Epoch: [93][500/875]	Time 0.419 (0.414)	Data 0.007 (0.010)	Loss 1.6277 (1.7474)	Loss@kd 1.6846 (1.6746)	Acc@1 84.375 (78.914)	Acc@5 100.000 (99.454)
Epoch: [93][600/875]	Time 0.384 (0.413)	Data 0.008 (0.009)	Loss 1.6671 (1.7458)	Loss@kd 1.6810 (1.6727)	Acc@1 79.688 (78.928)	Acc@5 100.000 (99.475)
Epoch: [93][700/875]	Time 0.422 (0.414)	Data 0.007 (0.009)	Loss 1.5279 (1.7477)	Loss@kd 1.6335 (1.6733)	Acc@1 85.938 (78.845)	Acc@5 100.000 (99.474)
Epoch: [93][800/875]	Time 0.420 (0.413)	Data 0.007 (0.009)	Loss 1.7403 (1.7480)	Loss@kd 1.6510 (1.6725)	Acc@1 79.688 (78.782)	Acc@5 96.875 (99.466)
 * Acc@1 78.795 Acc@5 99.484
epoch 93, total time 362.00
Test: [0/750]	Time 1.006 (1.006)	Loss 0.2839 (0.2839)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.101 (0.115)	Loss 0.4657 (0.5090)	Acc@1 84.375 (86.541)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.110 (0.110)	Loss 1.0268 (0.5037)	Acc@1 62.500 (84.826)	Acc@5 93.750 (96.067)
Test: [300/750]	Time 0.081 (0.110)	Loss 1.1938 (0.6941)	Acc@1 59.375 (76.360)	Acc@5 93.750 (95.411)
Test: [400/750]	Time 0.097 (0.108)	Loss 0.5423 (0.7680)	Acc@1 84.375 (72.974)	Acc@5 96.875 (95.215)
Test: [500/750]	Time 0.131 (0.108)	Loss 0.4257 (0.7551)	Acc@1 87.500 (74.014)	Acc@5 100.000 (94.785)
Test: [600/750]	Time 0.111 (0.107)	Loss 0.8241 (0.7640)	Acc@1 78.125 (73.887)	Acc@5 93.750 (94.743)
Test: [700/750]	Time 0.111 (0.108)	Loss 0.9468 (0.7621)	Acc@1 62.500 (73.703)	Acc@5 90.625 (94.847)
 * Acc@1 73.900 Acc@5 94.842
saving the best model!
==> training...
Epoch: [94][0/875]	Time 1.923 (1.923)	Data 1.435 (1.435)	Loss 1.7707 (1.7707)	Loss@kd 1.7078 (1.7078)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [94][100/875]	Time 0.378 (0.393)	Data 0.007 (0.021)	Loss 2.0092 (1.7643)	Loss@kd 1.7008 (1.6756)	Acc@1 65.625 (78.125)	Acc@5 96.875 (99.335)
Epoch: [94][200/875]	Time 0.353 (0.386)	Data 0.007 (0.014)	Loss 1.8521 (1.7554)	Loss@kd 1.6390 (1.6710)	Acc@1 68.750 (78.389)	Acc@5 100.000 (99.456)
Epoch: [94][300/875]	Time 0.399 (0.394)	Data 0.007 (0.012)	Loss 1.9559 (1.7565)	Loss@kd 1.6892 (1.6752)	Acc@1 71.875 (78.494)	Acc@5 100.000 (99.481)
Epoch: [94][400/875]	Time 0.420 (0.398)	Data 0.007 (0.011)	Loss 1.8020 (1.7549)	Loss@kd 1.6477 (1.6769)	Acc@1 73.438 (78.624)	Acc@5 100.000 (99.490)
Epoch: [94][500/875]	Time 0.364 (0.401)	Data 0.007 (0.010)	Loss 1.5749 (1.7511)	Loss@kd 1.6004 (1.6734)	Acc@1 85.938 (78.736)	Acc@5 98.438 (99.476)
Epoch: [94][600/875]	Time 0.388 (0.402)	Data 0.007 (0.009)	Loss 1.6590 (1.7489)	Loss@kd 1.6164 (1.6723)	Acc@1 78.125 (78.775)	Acc@5 100.000 (99.506)
Epoch: [94][700/875]	Time 0.399 (0.404)	Data 0.007 (0.009)	Loss 1.8825 (1.7462)	Loss@kd 1.7180 (1.6713)	Acc@1 73.438 (78.836)	Acc@5 100.000 (99.494)
Epoch: [94][800/875]	Time 0.353 (0.405)	Data 0.007 (0.009)	Loss 1.6715 (1.7460)	Loss@kd 1.7000 (1.6719)	Acc@1 81.250 (78.903)	Acc@5 100.000 (99.487)
 * Acc@1 78.852 Acc@5 99.486
epoch 94, total time 355.14
Test: [0/750]	Time 0.886 (0.886)	Loss 0.3098 (0.3098)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.105 (0.115)	Loss 0.4738 (0.5173)	Acc@1 81.250 (86.170)	Acc@5 96.875 (94.616)
Test: [200/750]	Time 0.096 (0.109)	Loss 1.0192 (0.5085)	Acc@1 68.750 (84.375)	Acc@5 93.750 (96.067)
Test: [300/750]	Time 0.102 (0.108)	Loss 1.1290 (0.6889)	Acc@1 59.375 (76.132)	Acc@5 93.750 (95.577)
Test: [400/750]	Time 0.117 (0.106)	Loss 0.5977 (0.7598)	Acc@1 78.125 (72.880)	Acc@5 93.750 (95.363)
Test: [500/750]	Time 0.103 (0.106)	Loss 0.4719 (0.7551)	Acc@1 84.375 (73.671)	Acc@5 100.000 (94.923)
Test: [600/750]	Time 0.095 (0.106)	Loss 0.8546 (0.7683)	Acc@1 71.875 (73.430)	Acc@5 90.625 (94.780)
Test: [700/750]	Time 0.099 (0.106)	Loss 0.8847 (0.7662)	Acc@1 62.500 (73.297)	Acc@5 93.750 (94.891)
 * Acc@1 73.475 Acc@5 94.883
==> training...
Epoch: [95][0/875]	Time 2.046 (2.046)	Data 1.600 (1.600)	Loss 1.6782 (1.6782)	Loss@kd 1.6568 (1.6568)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [95][100/875]	Time 0.417 (0.432)	Data 0.007 (0.023)	Loss 1.6670 (1.7520)	Loss@kd 1.7290 (1.6719)	Acc@1 84.375 (78.280)	Acc@5 100.000 (99.335)
Epoch: [95][200/875]	Time 0.418 (0.423)	Data 0.007 (0.015)	Loss 1.6634 (1.7537)	Loss@kd 1.6589 (1.6686)	Acc@1 79.688 (78.630)	Acc@5 100.000 (99.401)
Epoch: [95][300/875]	Time 0.480 (0.419)	Data 0.007 (0.012)	Loss 2.1281 (1.7447)	Loss@kd 1.6627 (1.6694)	Acc@1 64.062 (78.924)	Acc@5 96.875 (99.439)
Epoch: [95][400/875]	Time 0.419 (0.416)	Data 0.007 (0.011)	Loss 1.7301 (1.7478)	Loss@kd 1.7227 (1.6737)	Acc@1 79.688 (78.842)	Acc@5 100.000 (99.443)
Epoch: [95][500/875]	Time 0.402 (0.416)	Data 0.008 (0.010)	Loss 1.7937 (1.7396)	Loss@kd 1.6640 (1.6718)	Acc@1 79.688 (79.014)	Acc@5 100.000 (99.489)
Epoch: [95][600/875]	Time 0.368 (0.413)	Data 0.007 (0.010)	Loss 1.8322 (1.7463)	Loss@kd 1.7342 (1.6730)	Acc@1 71.875 (78.733)	Acc@5 100.000 (99.451)
Epoch: [95][700/875]	Time 0.361 (0.408)	Data 0.007 (0.009)	Loss 1.6450 (1.7456)	Loss@kd 1.6938 (1.6739)	Acc@1 82.812 (78.765)	Acc@5 100.000 (99.470)
Epoch: [95][800/875]	Time 0.356 (0.404)	Data 0.005 (0.009)	Loss 1.7247 (1.7467)	Loss@kd 1.6063 (1.6741)	Acc@1 79.688 (78.722)	Acc@5 100.000 (99.491)
 * Acc@1 78.736 Acc@5 99.502
epoch 95, total time 353.66
Test: [0/750]	Time 0.855 (0.855)	Loss 0.2831 (0.2831)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.101 (0.115)	Loss 0.5009 (0.5072)	Acc@1 81.250 (86.541)	Acc@5 100.000 (94.585)
Test: [200/750]	Time 0.116 (0.109)	Loss 1.0869 (0.5221)	Acc@1 62.500 (84.002)	Acc@5 93.750 (95.849)
Test: [300/750]	Time 0.109 (0.108)	Loss 1.1589 (0.7101)	Acc@1 65.625 (75.280)	Acc@5 93.750 (95.245)
Test: [400/750]	Time 0.086 (0.106)	Loss 0.4877 (0.7756)	Acc@1 81.250 (72.319)	Acc@5 96.875 (95.137)
Test: [500/750]	Time 0.119 (0.106)	Loss 0.4645 (0.7556)	Acc@1 84.375 (73.634)	Acc@5 100.000 (94.848)
Test: [600/750]	Time 0.073 (0.104)	Loss 0.7756 (0.7683)	Acc@1 71.875 (73.409)	Acc@5 90.625 (94.691)
Test: [700/750]	Time 0.100 (0.105)	Loss 0.7553 (0.7627)	Acc@1 71.875 (73.391)	Acc@5 93.750 (94.820)
 * Acc@1 73.683 Acc@5 94.862
==> training...
Epoch: [96][0/875]	Time 1.893 (1.893)	Data 1.372 (1.372)	Loss 1.7221 (1.7221)	Loss@kd 1.6785 (1.6785)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [96][100/875]	Time 0.413 (0.427)	Data 0.007 (0.020)	Loss 1.6826 (1.7598)	Loss@kd 1.6937 (1.6857)	Acc@1 84.375 (78.620)	Acc@5 100.000 (99.598)
Epoch: [96][200/875]	Time 0.410 (0.418)	Data 0.007 (0.014)	Loss 1.6851 (1.7457)	Loss@kd 1.6511 (1.6753)	Acc@1 78.125 (79.066)	Acc@5 100.000 (99.596)
Epoch: [96][300/875]	Time 0.345 (0.417)	Data 0.006 (0.011)	Loss 1.7371 (1.7440)	Loss@kd 1.6281 (1.6769)	Acc@1 81.250 (79.309)	Acc@5 98.438 (99.590)
Epoch: [96][400/875]	Time 0.393 (0.413)	Data 0.007 (0.010)	Loss 1.8388 (1.7491)	Loss@kd 1.7266 (1.6755)	Acc@1 75.000 (79.021)	Acc@5 100.000 (99.564)
Epoch: [96][500/875]	Time 0.398 (0.411)	Data 0.007 (0.010)	Loss 1.6910 (1.7472)	Loss@kd 1.6425 (1.6772)	Acc@1 84.375 (79.223)	Acc@5 100.000 (99.545)
Epoch: [96][600/875]	Time 0.423 (0.410)	Data 0.007 (0.009)	Loss 1.7419 (1.7469)	Loss@kd 1.6828 (1.6767)	Acc@1 78.125 (79.144)	Acc@5 98.438 (99.527)
Epoch: [96][700/875]	Time 0.406 (0.409)	Data 0.005 (0.009)	Loss 1.6746 (1.7462)	Loss@kd 1.5682 (1.6762)	Acc@1 79.688 (79.119)	Acc@5 100.000 (99.514)
Epoch: [96][800/875]	Time 0.369 (0.408)	Data 0.005 (0.008)	Loss 1.8030 (1.7466)	Loss@kd 1.6535 (1.6754)	Acc@1 79.688 (79.007)	Acc@5 98.438 (99.506)
 * Acc@1 79.048 Acc@5 99.509
epoch 96, total time 357.10
Test: [0/750]	Time 0.992 (0.992)	Loss 0.2748 (0.2748)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.107 (0.119)	Loss 0.4554 (0.4985)	Acc@1 81.250 (86.572)	Acc@5 100.000 (94.926)
Test: [200/750]	Time 0.104 (0.112)	Loss 1.1627 (0.5118)	Acc@1 53.125 (84.204)	Acc@5 90.625 (96.082)
Test: [300/750]	Time 0.107 (0.112)	Loss 1.1087 (0.7187)	Acc@1 62.500 (74.875)	Acc@5 93.750 (95.110)
Test: [400/750]	Time 0.092 (0.110)	Loss 0.4994 (0.7773)	Acc@1 84.375 (72.327)	Acc@5 96.875 (95.075)
Test: [500/750]	Time 0.170 (0.110)	Loss 0.4340 (0.7536)	Acc@1 84.375 (73.721)	Acc@5 100.000 (94.860)
Test: [600/750]	Time 0.101 (0.109)	Loss 0.8311 (0.7623)	Acc@1 71.875 (73.638)	Acc@5 90.625 (94.712)
Test: [700/750]	Time 0.094 (0.109)	Loss 0.7754 (0.7560)	Acc@1 71.875 (73.658)	Acc@5 93.750 (94.896)
 * Acc@1 73.912 Acc@5 94.929
saving the best model!
==> training...
Epoch: [97][0/875]	Time 1.915 (1.915)	Data 1.335 (1.335)	Loss 1.7836 (1.7836)	Loss@kd 1.6837 (1.6837)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)
Epoch: [97][100/875]	Time 0.419 (0.409)	Data 0.007 (0.020)	Loss 1.7926 (1.7457)	Loss@kd 1.7022 (1.6783)	Acc@1 79.688 (79.022)	Acc@5 98.438 (99.598)
Epoch: [97][200/875]	Time 0.380 (0.390)	Data 0.006 (0.013)	Loss 1.7072 (1.7510)	Loss@kd 1.6552 (1.6838)	Acc@1 84.375 (78.910)	Acc@5 98.438 (99.604)
Epoch: [97][300/875]	Time 0.334 (0.383)	Data 0.008 (0.011)	Loss 1.7042 (1.7478)	Loss@kd 1.6251 (1.6786)	Acc@1 76.562 (78.784)	Acc@5 100.000 (99.590)
Epoch: [97][400/875]	Time 0.369 (0.384)	Data 0.007 (0.010)	Loss 1.6724 (1.7507)	Loss@kd 1.6191 (1.6792)	Acc@1 78.125 (78.733)	Acc@5 100.000 (99.567)
Epoch: [97][500/875]	Time 0.403 (0.390)	Data 0.007 (0.009)	Loss 1.7576 (1.7489)	Loss@kd 1.6575 (1.6770)	Acc@1 76.562 (78.640)	Acc@5 100.000 (99.563)
Epoch: [97][600/875]	Time 0.449 (0.394)	Data 0.007 (0.009)	Loss 1.8084 (1.7458)	Loss@kd 1.6645 (1.6759)	Acc@1 76.562 (78.801)	Acc@5 100.000 (99.568)
Epoch: [97][700/875]	Time 0.438 (0.396)	Data 0.008 (0.009)	Loss 1.6951 (1.7441)	Loss@kd 1.6886 (1.6752)	Acc@1 82.812 (78.843)	Acc@5 100.000 (99.556)
Epoch: [97][800/875]	Time 0.354 (0.399)	Data 0.007 (0.008)	Loss 1.7725 (1.7431)	Loss@kd 1.6869 (1.6740)	Acc@1 75.000 (78.843)	Acc@5 100.000 (99.553)
 * Acc@1 78.911 Acc@5 99.561
epoch 97, total time 350.10
Test: [0/750]	Time 0.894 (0.894)	Loss 0.3088 (0.3088)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.100 (0.121)	Loss 0.4643 (0.5065)	Acc@1 84.375 (85.767)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.101 (0.113)	Loss 1.0980 (0.5084)	Acc@1 62.500 (83.986)	Acc@5 90.625 (96.020)
Test: [300/750]	Time 0.116 (0.111)	Loss 1.2334 (0.7132)	Acc@1 56.250 (74.907)	Acc@5 93.750 (95.172)
Test: [400/750]	Time 0.108 (0.111)	Loss 0.6169 (0.7876)	Acc@1 84.375 (71.680)	Acc@5 93.750 (94.974)
Test: [500/750]	Time 0.174 (0.110)	Loss 0.4015 (0.7743)	Acc@1 93.750 (72.786)	Acc@5 100.000 (94.692)
Test: [600/750]	Time 0.109 (0.109)	Loss 0.7297 (0.7755)	Acc@1 71.875 (72.905)	Acc@5 93.750 (94.598)
Test: [700/750]	Time 0.118 (0.110)	Loss 0.8193 (0.7657)	Acc@1 68.750 (73.065)	Acc@5 93.750 (94.780)
 * Acc@1 73.354 Acc@5 94.796
==> training...
Epoch: [98][0/875]	Time 1.943 (1.943)	Data 1.372 (1.372)	Loss 1.8884 (1.8884)	Loss@kd 1.7174 (1.7174)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [98][100/875]	Time 0.393 (0.425)	Data 0.007 (0.020)	Loss 1.9153 (1.7512)	Loss@kd 1.6363 (1.6684)	Acc@1 73.438 (78.589)	Acc@5 96.875 (99.428)
Epoch: [98][200/875]	Time 0.383 (0.416)	Data 0.007 (0.014)	Loss 1.7689 (1.7422)	Loss@kd 1.6708 (1.6696)	Acc@1 76.562 (78.895)	Acc@5 98.438 (99.471)
Epoch: [98][300/875]	Time 0.374 (0.414)	Data 0.007 (0.011)	Loss 1.6654 (1.7414)	Loss@kd 1.6474 (1.6683)	Acc@1 78.125 (78.821)	Acc@5 100.000 (99.445)
Epoch: [98][400/875]	Time 0.399 (0.412)	Data 0.007 (0.010)	Loss 1.7998 (1.7412)	Loss@kd 1.6703 (1.6675)	Acc@1 76.562 (78.760)	Acc@5 100.000 (99.466)
Epoch: [98][500/875]	Time 0.423 (0.412)	Data 0.007 (0.010)	Loss 1.7108 (1.7373)	Loss@kd 1.6626 (1.6675)	Acc@1 81.250 (78.939)	Acc@5 100.000 (99.501)
Epoch: [98][600/875]	Time 0.434 (0.412)	Data 0.007 (0.009)	Loss 1.8921 (1.7412)	Loss@kd 1.6871 (1.6698)	Acc@1 73.438 (78.858)	Acc@5 100.000 (99.509)
Epoch: [98][700/875]	Time 0.395 (0.412)	Data 0.007 (0.009)	Loss 1.7713 (1.7452)	Loss@kd 1.7618 (1.6713)	Acc@1 79.688 (78.736)	Acc@5 98.438 (99.507)
Epoch: [98][800/875]	Time 0.369 (0.409)	Data 0.007 (0.009)	Loss 1.6418 (1.7444)	Loss@kd 1.6648 (1.6712)	Acc@1 78.125 (78.845)	Acc@5 100.000 (99.503)
 * Acc@1 78.859 Acc@5 99.500
epoch 98, total time 355.74
Test: [0/750]	Time 0.907 (0.907)	Loss 0.2836 (0.2836)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.097 (0.113)	Loss 0.4778 (0.5027)	Acc@1 84.375 (86.386)	Acc@5 100.000 (94.678)
Test: [200/750]	Time 0.101 (0.107)	Loss 1.0194 (0.5007)	Acc@1 65.625 (84.655)	Acc@5 93.750 (96.035)
Test: [300/750]	Time 0.106 (0.106)	Loss 1.1416 (0.6909)	Acc@1 59.375 (76.152)	Acc@5 93.750 (95.380)
Test: [400/750]	Time 0.078 (0.102)	Loss 0.5242 (0.7710)	Acc@1 84.375 (72.615)	Acc@5 93.750 (95.106)
Test: [500/750]	Time 0.182 (0.103)	Loss 0.4594 (0.7500)	Acc@1 84.375 (73.933)	Acc@5 100.000 (94.823)
Test: [600/750]	Time 0.096 (0.102)	Loss 0.7413 (0.7606)	Acc@1 71.875 (73.773)	Acc@5 93.750 (94.717)
Test: [700/750]	Time 0.097 (0.103)	Loss 0.8672 (0.7546)	Acc@1 68.750 (73.783)	Acc@5 93.750 (94.873)
 * Acc@1 74.004 Acc@5 94.883
saving the best model!
==> training...
Epoch: [99][0/875]	Time 2.143 (2.143)	Data 1.572 (1.572)	Loss 1.8755 (1.8755)	Loss@kd 1.5699 (1.5699)	Acc@1 62.500 (62.500)	Acc@5 100.000 (100.000)
Epoch: [99][100/875]	Time 0.431 (0.427)	Data 0.007 (0.022)	Loss 1.6798 (1.7464)	Loss@kd 1.6792 (1.6640)	Acc@1 84.375 (78.373)	Acc@5 100.000 (99.428)
Epoch: [99][200/875]	Time 0.391 (0.420)	Data 0.007 (0.015)	Loss 1.9108 (1.7439)	Loss@kd 1.6578 (1.6647)	Acc@1 75.000 (78.863)	Acc@5 98.438 (99.495)
Epoch: [99][300/875]	Time 0.380 (0.417)	Data 0.007 (0.012)	Loss 1.8014 (1.7471)	Loss@kd 1.6658 (1.6673)	Acc@1 81.250 (78.836)	Acc@5 100.000 (99.481)
Epoch: [99][400/875]	Time 0.407 (0.416)	Data 0.007 (0.011)	Loss 1.7230 (1.7433)	Loss@kd 1.6626 (1.6696)	Acc@1 79.688 (79.048)	Acc@5 100.000 (99.497)
Epoch: [99][500/875]	Time 0.390 (0.415)	Data 0.007 (0.010)	Loss 1.6811 (1.7426)	Loss@kd 1.6697 (1.6707)	Acc@1 84.375 (79.145)	Acc@5 100.000 (99.495)
Epoch: [99][600/875]	Time 0.430 (0.415)	Data 0.007 (0.010)	Loss 1.5963 (1.7407)	Loss@kd 1.5819 (1.6714)	Acc@1 82.812 (79.227)	Acc@5 100.000 (99.511)
Epoch: [99][700/875]	Time 0.432 (0.414)	Data 0.007 (0.009)	Loss 1.8616 (1.7405)	Loss@kd 1.7278 (1.6716)	Acc@1 75.000 (79.202)	Acc@5 98.438 (99.523)
Epoch: [99][800/875]	Time 0.372 (0.414)	Data 0.007 (0.009)	Loss 1.6724 (1.7419)	Loss@kd 1.6209 (1.6709)	Acc@1 79.688 (79.110)	Acc@5 100.000 (99.522)
 * Acc@1 79.096 Acc@5 99.534
epoch 99, total time 362.62
Test: [0/750]	Time 0.995 (0.995)	Loss 0.3303 (0.3303)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.085 (0.117)	Loss 0.4106 (0.5261)	Acc@1 84.375 (85.984)	Acc@5 100.000 (94.616)
Test: [200/750]	Time 0.116 (0.111)	Loss 1.1114 (0.5019)	Acc@1 62.500 (85.012)	Acc@5 87.500 (95.958)
Test: [300/750]	Time 0.098 (0.110)	Loss 1.2155 (0.7138)	Acc@1 59.375 (75.561)	Acc@5 93.750 (94.923)
Test: [400/750]	Time 0.106 (0.108)	Loss 0.5464 (0.7920)	Acc@1 84.375 (72.148)	Acc@5 93.750 (94.802)
Test: [500/750]	Time 0.166 (0.108)	Loss 0.4408 (0.7723)	Acc@1 84.375 (73.441)	Acc@5 100.000 (94.536)
Test: [600/750]	Time 0.090 (0.107)	Loss 0.7813 (0.7776)	Acc@1 71.875 (73.409)	Acc@5 93.750 (94.462)
Test: [700/750]	Time 0.099 (0.107)	Loss 0.7967 (0.7667)	Acc@1 75.000 (73.533)	Acc@5 93.750 (94.726)
 * Acc@1 73.854 Acc@5 94.771
==> training...
Epoch: [100][0/875]	Time 2.050 (2.050)	Data 1.473 (1.473)	Loss 1.9280 (1.9280)	Loss@kd 1.6891 (1.6891)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)
Epoch: [100][100/875]	Time 0.451 (0.432)	Data 0.007 (0.021)	Loss 1.8795 (1.7272)	Loss@kd 1.6692 (1.6717)	Acc@1 79.688 (79.254)	Acc@5 96.875 (99.520)
Epoch: [100][200/875]	Time 0.377 (0.424)	Data 0.007 (0.014)	Loss 1.7079 (1.7349)	Loss@kd 1.6229 (1.6728)	Acc@1 81.250 (79.081)	Acc@5 100.000 (99.588)
Epoch: [100][300/875]	Time 0.367 (0.414)	Data 0.007 (0.012)	Loss 1.6126 (1.7460)	Loss@kd 1.8124 (1.6753)	Acc@1 87.500 (78.841)	Acc@5 100.000 (99.574)
Epoch: [100][400/875]	Time 0.372 (0.405)	Data 0.007 (0.010)	Loss 1.7352 (1.7419)	Loss@kd 1.6782 (1.6734)	Acc@1 82.812 (79.037)	Acc@5 100.000 (99.552)
Epoch: [100][500/875]	Time 0.438 (0.398)	Data 0.006 (0.010)	Loss 1.6875 (1.7420)	Loss@kd 1.5826 (1.6721)	Acc@1 78.125 (78.989)	Acc@5 100.000 (99.510)
Epoch: [100][600/875]	Time 0.439 (0.400)	Data 0.007 (0.009)	Loss 1.6672 (1.7430)	Loss@kd 1.6623 (1.6724)	Acc@1 81.250 (79.105)	Acc@5 100.000 (99.527)
Epoch: [100][700/875]	Time 0.372 (0.402)	Data 0.010 (0.009)	Loss 1.7160 (1.7443)	Loss@kd 1.6446 (1.6732)	Acc@1 76.562 (79.017)	Acc@5 100.000 (99.510)
Epoch: [100][800/875]	Time 0.417 (0.404)	Data 0.007 (0.008)	Loss 1.6346 (1.7413)	Loss@kd 1.6290 (1.6738)	Acc@1 76.562 (79.089)	Acc@5 100.000 (99.514)
 * Acc@1 79.130 Acc@5 99.502
epoch 100, total time 354.61
Test: [0/750]	Time 0.899 (0.899)	Loss 0.2979 (0.2979)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.093 (0.116)	Loss 0.4366 (0.5267)	Acc@1 84.375 (86.293)	Acc@5 100.000 (94.864)
Test: [200/750]	Time 0.109 (0.111)	Loss 1.1050 (0.5171)	Acc@1 59.375 (84.297)	Acc@5 90.625 (96.191)
Test: [300/750]	Time 0.114 (0.111)	Loss 1.1398 (0.7145)	Acc@1 65.625 (75.550)	Acc@5 93.750 (95.453)
Test: [400/750]	Time 0.080 (0.109)	Loss 0.5815 (0.7800)	Acc@1 84.375 (72.639)	Acc@5 96.875 (95.223)
Test: [500/750]	Time 0.170 (0.109)	Loss 0.3872 (0.7649)	Acc@1 93.750 (73.777)	Acc@5 100.000 (94.867)
Test: [600/750]	Time 0.101 (0.109)	Loss 0.8855 (0.7690)	Acc@1 71.875 (73.877)	Acc@5 90.625 (94.759)
Test: [700/750]	Time 0.101 (0.109)	Loss 0.9879 (0.7677)	Acc@1 65.625 (73.716)	Acc@5 93.750 (94.838)
 * Acc@1 73.796 Acc@5 94.825
==> training...
Epoch: [101][0/875]	Time 2.164 (2.164)	Data 1.605 (1.605)	Loss 1.8644 (1.8644)	Loss@kd 1.6858 (1.6858)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [101][100/875]	Time 0.407 (0.431)	Data 0.007 (0.023)	Loss 1.9433 (1.7488)	Loss@kd 1.7397 (1.6719)	Acc@1 76.562 (78.775)	Acc@5 96.875 (99.582)
Epoch: [101][200/875]	Time 0.411 (0.421)	Data 0.007 (0.015)	Loss 1.9923 (1.7388)	Loss@kd 1.6625 (1.6723)	Acc@1 65.625 (79.190)	Acc@5 100.000 (99.642)
Epoch: [101][300/875]	Time 0.391 (0.416)	Data 0.007 (0.012)	Loss 1.8981 (1.7460)	Loss@kd 1.6665 (1.6770)	Acc@1 71.875 (78.950)	Acc@5 100.000 (99.626)
Epoch: [101][400/875]	Time 0.379 (0.415)	Data 0.007 (0.011)	Loss 1.5659 (1.7445)	Loss@kd 1.6299 (1.6764)	Acc@1 82.812 (79.052)	Acc@5 100.000 (99.618)
Epoch: [101][500/875]	Time 0.415 (0.414)	Data 0.007 (0.010)	Loss 1.8807 (1.7416)	Loss@kd 1.6466 (1.6748)	Acc@1 78.125 (79.076)	Acc@5 98.438 (99.585)
Epoch: [101][600/875]	Time 0.359 (0.413)	Data 0.007 (0.010)	Loss 1.8772 (1.7446)	Loss@kd 1.6082 (1.6745)	Acc@1 70.312 (78.999)	Acc@5 100.000 (99.571)
Epoch: [101][700/875]	Time 0.400 (0.413)	Data 0.005 (0.009)	Loss 1.8437 (1.7449)	Loss@kd 1.6957 (1.6733)	Acc@1 78.125 (78.925)	Acc@5 98.438 (99.570)
Epoch: [101][800/875]	Time 0.393 (0.413)	Data 0.007 (0.009)	Loss 2.0333 (1.7439)	Loss@kd 1.7162 (1.6729)	Acc@1 68.750 (78.913)	Acc@5 98.438 (99.557)
 * Acc@1 79.011 Acc@5 99.550
epoch 101, total time 360.04
Test: [0/750]	Time 0.797 (0.797)	Loss 0.2890 (0.2890)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.086 (0.113)	Loss 0.4087 (0.5191)	Acc@1 84.375 (86.077)	Acc@5 100.000 (94.740)
Test: [200/750]	Time 0.102 (0.107)	Loss 1.1072 (0.4955)	Acc@1 65.625 (85.075)	Acc@5 90.625 (96.160)
Test: [300/750]	Time 0.093 (0.106)	Loss 1.1229 (0.7069)	Acc@1 59.375 (75.685)	Acc@5 93.750 (95.100)
Test: [400/750]	Time 0.093 (0.104)	Loss 0.5960 (0.7815)	Acc@1 81.250 (72.319)	Acc@5 93.750 (94.857)
Test: [500/750]	Time 0.102 (0.104)	Loss 0.4579 (0.7683)	Acc@1 87.500 (73.372)	Acc@5 100.000 (94.580)
Test: [600/750]	Time 0.107 (0.103)	Loss 0.9491 (0.7780)	Acc@1 68.750 (73.227)	Acc@5 90.625 (94.494)
Test: [700/750]	Time 0.098 (0.103)	Loss 0.9338 (0.7748)	Acc@1 65.625 (73.123)	Acc@5 93.750 (94.673)
 * Acc@1 73.379 Acc@5 94.650
==> training...
Epoch: [102][0/875]	Time 2.025 (2.025)	Data 1.504 (1.504)	Loss 1.9416 (1.9416)	Loss@kd 1.6653 (1.6653)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)
Epoch: [102][100/875]	Time 0.398 (0.421)	Data 0.007 (0.022)	Loss 1.8741 (1.7397)	Loss@kd 1.6996 (1.6705)	Acc@1 75.000 (78.945)	Acc@5 98.438 (99.505)
Epoch: [102][200/875]	Time 0.408 (0.415)	Data 0.008 (0.014)	Loss 1.6526 (1.7437)	Loss@kd 1.6467 (1.6776)	Acc@1 82.812 (78.949)	Acc@5 100.000 (99.471)
Epoch: [102][300/875]	Time 0.414 (0.412)	Data 0.007 (0.012)	Loss 1.6865 (1.7415)	Loss@kd 1.6880 (1.6752)	Acc@1 78.125 (78.691)	Acc@5 100.000 (99.507)
Epoch: [102][400/875]	Time 0.424 (0.411)	Data 0.007 (0.011)	Loss 1.9377 (1.7480)	Loss@kd 1.7653 (1.6739)	Acc@1 71.875 (78.534)	Acc@5 100.000 (99.536)
Epoch: [102][500/875]	Time 0.415 (0.412)	Data 0.007 (0.010)	Loss 1.8599 (1.7467)	Loss@kd 1.6909 (1.6725)	Acc@1 70.312 (78.568)	Acc@5 100.000 (99.535)
Epoch: [102][600/875]	Time 0.363 (0.410)	Data 0.005 (0.009)	Loss 1.5643 (1.7423)	Loss@kd 1.6431 (1.6720)	Acc@1 85.938 (78.700)	Acc@5 100.000 (99.537)
Epoch: [102][700/875]	Time 0.368 (0.410)	Data 0.007 (0.009)	Loss 1.7832 (1.7399)	Loss@kd 1.6302 (1.6704)	Acc@1 79.688 (78.816)	Acc@5 98.438 (99.519)
Epoch: [102][800/875]	Time 0.387 (0.409)	Data 0.008 (0.009)	Loss 1.7895 (1.7392)	Loss@kd 1.8504 (1.6717)	Acc@1 82.812 (78.909)	Acc@5 100.000 (99.512)
 * Acc@1 78.975 Acc@5 99.523
epoch 102, total time 358.59
Test: [0/750]	Time 0.809 (0.809)	Loss 0.2686 (0.2686)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.094 (0.115)	Loss 0.5173 (0.5119)	Acc@1 84.375 (86.262)	Acc@5 96.875 (94.957)
Test: [200/750]	Time 0.111 (0.109)	Loss 1.1025 (0.5147)	Acc@1 62.500 (84.157)	Acc@5 90.625 (96.175)
Test: [300/750]	Time 0.102 (0.107)	Loss 1.1369 (0.7105)	Acc@1 59.375 (75.509)	Acc@5 93.750 (95.463)
Test: [400/750]	Time 0.085 (0.106)	Loss 0.5088 (0.7868)	Acc@1 84.375 (72.132)	Acc@5 93.750 (95.161)
Test: [500/750]	Time 0.103 (0.106)	Loss 0.3917 (0.7627)	Acc@1 87.500 (73.653)	Acc@5 100.000 (94.823)
Test: [600/750]	Time 0.111 (0.106)	Loss 0.7956 (0.7650)	Acc@1 75.000 (73.809)	Acc@5 90.625 (94.785)
Test: [700/750]	Time 0.103 (0.106)	Loss 0.9709 (0.7581)	Acc@1 68.750 (73.859)	Acc@5 90.625 (94.927)
 * Acc@1 74.037 Acc@5 94.921
saving the best model!
==> training...
Epoch: [103][0/875]	Time 1.864 (1.864)	Data 1.278 (1.278)	Loss 1.7804 (1.7804)	Loss@kd 1.6988 (1.6988)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [103][100/875]	Time 0.422 (0.426)	Data 0.007 (0.019)	Loss 1.5330 (1.7393)	Loss@kd 1.6394 (1.6674)	Acc@1 82.812 (78.960)	Acc@5 100.000 (99.536)
Epoch: [103][200/875]	Time 0.405 (0.422)	Data 0.007 (0.013)	Loss 1.8047 (1.7339)	Loss@kd 1.7155 (1.6672)	Acc@1 84.375 (79.190)	Acc@5 98.438 (99.549)
Epoch: [103][300/875]	Time 0.434 (0.420)	Data 0.007 (0.011)	Loss 1.8748 (1.7369)	Loss@kd 1.6881 (1.6702)	Acc@1 70.312 (79.142)	Acc@5 100.000 (99.522)
Epoch: [103][400/875]	Time 0.361 (0.416)	Data 0.007 (0.010)	Loss 1.7868 (1.7393)	Loss@kd 1.6405 (1.6720)	Acc@1 75.000 (79.056)	Acc@5 100.000 (99.536)
Epoch: [103][500/875]	Time 0.359 (0.407)	Data 0.007 (0.009)	Loss 1.8977 (1.7348)	Loss@kd 1.7926 (1.6720)	Acc@1 73.438 (79.260)	Acc@5 100.000 (99.548)
Epoch: [103][600/875]	Time 0.348 (0.400)	Data 0.006 (0.009)	Loss 1.8584 (1.7340)	Loss@kd 1.7043 (1.6709)	Acc@1 81.250 (79.396)	Acc@5 95.312 (99.529)
Epoch: [103][700/875]	Time 0.376 (0.398)	Data 0.007 (0.009)	Loss 1.6924 (1.7345)	Loss@kd 1.6823 (1.6706)	Acc@1 81.250 (79.449)	Acc@5 100.000 (99.525)
Epoch: [103][800/875]	Time 0.416 (0.400)	Data 0.007 (0.008)	Loss 1.7663 (1.7356)	Loss@kd 1.6565 (1.6712)	Acc@1 81.250 (79.395)	Acc@5 100.000 (99.520)
 * Acc@1 79.427 Acc@5 99.527
epoch 103, total time 350.69
Test: [0/750]	Time 0.839 (0.839)	Loss 0.2815 (0.2815)	Acc@1 93.750 (93.750)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.107 (0.114)	Loss 0.4800 (0.5100)	Acc@1 84.375 (86.665)	Acc@5 96.875 (94.709)
Test: [200/750]	Time 0.107 (0.109)	Loss 1.0554 (0.5060)	Acc@1 65.625 (84.484)	Acc@5 93.750 (96.160)
Test: [300/750]	Time 0.103 (0.109)	Loss 1.2270 (0.6983)	Acc@1 59.375 (76.038)	Acc@5 90.625 (95.411)
Test: [400/750]	Time 0.110 (0.108)	Loss 0.5272 (0.7773)	Acc@1 84.375 (72.639)	Acc@5 96.875 (95.176)
Test: [500/750]	Time 0.107 (0.108)	Loss 0.4284 (0.7587)	Acc@1 81.250 (73.902)	Acc@5 100.000 (94.842)
Test: [600/750]	Time 0.190 (0.107)	Loss 0.8191 (0.7648)	Acc@1 71.875 (73.830)	Acc@5 90.625 (94.748)
Test: [700/750]	Time 0.080 (0.107)	Loss 0.8219 (0.7561)	Acc@1 68.750 (73.979)	Acc@5 93.750 (94.896)
 * Acc@1 74.246 Acc@5 94.929
saving the best model!
==> training...
Epoch: [104][0/875]	Time 1.874 (1.874)	Data 1.340 (1.340)	Loss 1.6715 (1.6715)	Loss@kd 1.6772 (1.6772)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [104][100/875]	Time 0.416 (0.421)	Data 0.007 (0.020)	Loss 1.6542 (1.7040)	Loss@kd 1.6672 (1.6645)	Acc@1 81.250 (80.260)	Acc@5 100.000 (99.598)
Epoch: [104][200/875]	Time 0.418 (0.417)	Data 0.007 (0.013)	Loss 1.8230 (1.7190)	Loss@kd 1.6811 (1.6674)	Acc@1 84.375 (80.006)	Acc@5 100.000 (99.541)
Epoch: [104][300/875]	Time 0.356 (0.414)	Data 0.007 (0.011)	Loss 1.7039 (1.7227)	Loss@kd 1.7974 (1.6685)	Acc@1 78.125 (79.833)	Acc@5 100.000 (99.528)
Epoch: [104][400/875]	Time 0.432 (0.414)	Data 0.007 (0.010)	Loss 1.7662 (1.7248)	Loss@kd 1.6520 (1.6695)	Acc@1 84.375 (79.676)	Acc@5 98.438 (99.509)
Epoch: [104][500/875]	Time 0.411 (0.414)	Data 0.007 (0.009)	Loss 1.9084 (1.7306)	Loss@kd 1.8446 (1.6701)	Acc@1 76.562 (79.485)	Acc@5 100.000 (99.507)
Epoch: [104][600/875]	Time 0.431 (0.414)	Data 0.007 (0.009)	Loss 1.6947 (1.7338)	Loss@kd 1.6529 (1.6700)	Acc@1 81.250 (79.415)	Acc@5 98.438 (99.488)
Epoch: [104][700/875]	Time 0.421 (0.414)	Data 0.007 (0.009)	Loss 1.7432 (1.7343)	Loss@kd 1.7103 (1.6710)	Acc@1 78.125 (79.429)	Acc@5 100.000 (99.498)
Epoch: [104][800/875]	Time 0.429 (0.414)	Data 0.006 (0.008)	Loss 1.8317 (1.7378)	Loss@kd 1.6869 (1.6719)	Acc@1 81.250 (79.215)	Acc@5 98.438 (99.481)
 * Acc@1 79.289 Acc@5 99.480
epoch 104, total time 362.45
Test: [0/750]	Time 0.968 (0.968)	Loss 0.2923 (0.2923)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.109 (0.118)	Loss 0.4149 (0.5184)	Acc@1 84.375 (86.479)	Acc@5 96.875 (94.957)
Test: [200/750]	Time 0.097 (0.110)	Loss 1.0815 (0.5010)	Acc@1 62.500 (85.183)	Acc@5 90.625 (96.222)
Test: [300/750]	Time 0.101 (0.109)	Loss 1.1855 (0.7082)	Acc@1 59.375 (76.017)	Acc@5 93.750 (95.297)
Test: [400/750]	Time 0.084 (0.107)	Loss 0.6393 (0.7943)	Acc@1 81.250 (72.421)	Acc@5 93.750 (94.911)
Test: [500/750]	Time 0.132 (0.106)	Loss 0.4229 (0.7864)	Acc@1 87.500 (73.278)	Acc@5 100.000 (94.536)
Test: [600/750]	Time 0.088 (0.105)	Loss 0.8329 (0.7893)	Acc@1 71.875 (73.321)	Acc@5 93.750 (94.514)
Test: [700/750]	Time 0.087 (0.105)	Loss 0.8649 (0.7790)	Acc@1 71.875 (73.377)	Acc@5 93.750 (94.731)
 * Acc@1 73.654 Acc@5 94.762
==> training...
Epoch: [105][0/875]	Time 1.775 (1.775)	Data 1.269 (1.269)	Loss 1.7948 (1.7948)	Loss@kd 1.6312 (1.6312)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)
Epoch: [105][100/875]	Time 0.371 (0.387)	Data 0.007 (0.019)	Loss 1.6035 (1.7583)	Loss@kd 1.6528 (1.6763)	Acc@1 84.375 (78.868)	Acc@5 100.000 (99.536)
Epoch: [105][200/875]	Time 0.426 (0.385)	Data 0.007 (0.013)	Loss 1.6185 (1.7434)	Loss@kd 1.5709 (1.6735)	Acc@1 79.688 (79.151)	Acc@5 100.000 (99.534)
Epoch: [105][300/875]	Time 0.378 (0.393)	Data 0.010 (0.011)	Loss 1.8228 (1.7365)	Loss@kd 1.6845 (1.6715)	Acc@1 79.688 (79.257)	Acc@5 96.875 (99.517)
Epoch: [105][400/875]	Time 0.410 (0.398)	Data 0.007 (0.010)	Loss 1.7353 (1.7357)	Loss@kd 1.6904 (1.6700)	Acc@1 81.250 (79.107)	Acc@5 98.438 (99.532)
Epoch: [105][500/875]	Time 0.435 (0.400)	Data 0.007 (0.009)	Loss 1.6220 (1.7402)	Loss@kd 1.7071 (1.6708)	Acc@1 82.812 (78.989)	Acc@5 100.000 (99.517)
Epoch: [105][600/875]	Time 0.432 (0.401)	Data 0.007 (0.009)	Loss 1.7189 (1.7373)	Loss@kd 1.6298 (1.6706)	Acc@1 81.250 (79.199)	Acc@5 100.000 (99.516)
Epoch: [105][700/875]	Time 0.432 (0.403)	Data 0.007 (0.009)	Loss 1.7267 (1.7366)	Loss@kd 1.6591 (1.6713)	Acc@1 76.562 (79.268)	Acc@5 100.000 (99.514)
Epoch: [105][800/875]	Time 0.431 (0.404)	Data 0.007 (0.009)	Loss 1.6467 (1.7368)	Loss@kd 1.6422 (1.6714)	Acc@1 81.250 (79.311)	Acc@5 100.000 (99.485)
 * Acc@1 79.227 Acc@5 99.486
epoch 105, total time 354.08
Test: [0/750]	Time 0.922 (0.922)	Loss 0.2679 (0.2679)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.125 (0.115)	Loss 0.4921 (0.5099)	Acc@1 84.375 (86.479)	Acc@5 100.000 (94.926)
Test: [200/750]	Time 0.094 (0.109)	Loss 1.1248 (0.5151)	Acc@1 59.375 (84.359)	Acc@5 93.750 (96.082)
Test: [300/750]	Time 0.086 (0.109)	Loss 1.0524 (0.7149)	Acc@1 65.625 (75.363)	Acc@5 93.750 (95.214)
Test: [400/750]	Time 0.106 (0.107)	Loss 0.5453 (0.7790)	Acc@1 84.375 (72.475)	Acc@5 96.875 (95.067)
Test: [500/750]	Time 0.163 (0.107)	Loss 0.4490 (0.7610)	Acc@1 84.375 (73.653)	Acc@5 100.000 (94.823)
Test: [600/750]	Time 0.101 (0.106)	Loss 0.8368 (0.7679)	Acc@1 75.000 (73.596)	Acc@5 90.625 (94.712)
Test: [700/750]	Time 0.097 (0.107)	Loss 1.0151 (0.7639)	Acc@1 65.625 (73.498)	Acc@5 93.750 (94.833)
 * Acc@1 73.612 Acc@5 94.821
==> training...
Epoch: [106][0/875]	Time 1.806 (1.806)	Data 1.273 (1.273)	Loss 1.7567 (1.7567)	Loss@kd 1.6859 (1.6859)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [106][100/875]	Time 0.419 (0.430)	Data 0.007 (0.020)	Loss 1.6470 (1.7352)	Loss@kd 1.6390 (1.6754)	Acc@1 82.812 (78.821)	Acc@5 100.000 (99.629)
Epoch: [106][200/875]	Time 0.412 (0.424)	Data 0.007 (0.013)	Loss 1.5866 (1.7404)	Loss@kd 1.5844 (1.6713)	Acc@1 82.812 (78.692)	Acc@5 100.000 (99.549)
Epoch: [106][300/875]	Time 0.406 (0.421)	Data 0.007 (0.011)	Loss 1.6525 (1.7371)	Loss@kd 1.5752 (1.6723)	Acc@1 75.000 (79.059)	Acc@5 100.000 (99.574)
Epoch: [106][400/875]	Time 0.359 (0.418)	Data 0.007 (0.010)	Loss 1.8767 (1.7339)	Loss@kd 1.7693 (1.6712)	Acc@1 76.562 (79.158)	Acc@5 100.000 (99.548)
Epoch: [106][500/875]	Time 0.382 (0.417)	Data 0.007 (0.009)	Loss 1.7232 (1.7328)	Loss@kd 1.6348 (1.6699)	Acc@1 76.562 (79.126)	Acc@5 100.000 (99.542)
Epoch: [106][600/875]	Time 0.365 (0.413)	Data 0.007 (0.009)	Loss 1.8428 (1.7326)	Loss@kd 1.6756 (1.6694)	Acc@1 75.000 (79.131)	Acc@5 100.000 (99.535)
Epoch: [106][700/875]	Time 0.369 (0.407)	Data 0.007 (0.009)	Loss 1.8317 (1.7333)	Loss@kd 1.6473 (1.6702)	Acc@1 73.438 (79.097)	Acc@5 100.000 (99.536)
Epoch: [106][800/875]	Time 0.416 (0.404)	Data 0.007 (0.008)	Loss 1.5958 (1.7331)	Loss@kd 1.6399 (1.6695)	Acc@1 85.938 (79.057)	Acc@5 100.000 (99.553)
 * Acc@1 79.136 Acc@5 99.554
epoch 106, total time 354.31
Test: [0/750]	Time 0.999 (0.999)	Loss 0.2983 (0.2983)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.105 (0.120)	Loss 0.4813 (0.5191)	Acc@1 81.250 (86.293)	Acc@5 100.000 (94.524)
Test: [200/750]	Time 0.104 (0.114)	Loss 1.1263 (0.5166)	Acc@1 53.125 (84.453)	Acc@5 90.625 (95.849)
Test: [300/750]	Time 0.099 (0.113)	Loss 1.0491 (0.7104)	Acc@1 65.625 (75.571)	Acc@5 93.750 (95.172)
Test: [400/750]	Time 0.112 (0.111)	Loss 0.5918 (0.7738)	Acc@1 81.250 (72.654)	Acc@5 93.750 (95.028)
Test: [500/750]	Time 0.162 (0.111)	Loss 0.5137 (0.7658)	Acc@1 81.250 (73.572)	Acc@5 100.000 (94.661)
Test: [600/750]	Time 0.113 (0.110)	Loss 0.8579 (0.7781)	Acc@1 71.875 (73.326)	Acc@5 90.625 (94.530)
Test: [700/750]	Time 0.105 (0.110)	Loss 0.8669 (0.7703)	Acc@1 68.750 (73.422)	Acc@5 93.750 (94.771)
 * Acc@1 73.662 Acc@5 94.783
==> training...
Epoch: [107][0/875]	Time 1.999 (1.999)	Data 1.450 (1.450)	Loss 1.6882 (1.6882)	Loss@kd 1.6663 (1.6663)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [107][100/875]	Time 0.414 (0.430)	Data 0.007 (0.021)	Loss 1.6104 (1.7166)	Loss@kd 1.7042 (1.6733)	Acc@1 79.688 (80.167)	Acc@5 100.000 (99.598)
Epoch: [107][200/875]	Time 0.362 (0.420)	Data 0.007 (0.014)	Loss 1.8277 (1.7213)	Loss@kd 1.7116 (1.6730)	Acc@1 75.000 (80.107)	Acc@5 100.000 (99.557)
Epoch: [107][300/875]	Time 0.424 (0.417)	Data 0.007 (0.012)	Loss 1.9905 (1.7314)	Loss@kd 1.9373 (1.6741)	Acc@1 68.750 (79.698)	Acc@5 98.438 (99.502)
Epoch: [107][400/875]	Time 0.424 (0.415)	Data 0.007 (0.011)	Loss 1.8472 (1.7339)	Loss@kd 1.7039 (1.6716)	Acc@1 73.438 (79.524)	Acc@5 100.000 (99.525)
Epoch: [107][500/875]	Time 0.420 (0.414)	Data 0.007 (0.010)	Loss 1.7594 (1.7346)	Loss@kd 1.6222 (1.6717)	Acc@1 73.438 (79.357)	Acc@5 100.000 (99.538)
Epoch: [107][600/875]	Time 0.411 (0.414)	Data 0.006 (0.009)	Loss 1.7159 (1.7325)	Loss@kd 1.6185 (1.6704)	Acc@1 81.250 (79.420)	Acc@5 100.000 (99.537)
Epoch: [107][700/875]	Time 0.412 (0.413)	Data 0.007 (0.009)	Loss 2.1115 (1.7325)	Loss@kd 2.0664 (1.6700)	Acc@1 75.000 (79.333)	Acc@5 98.438 (99.541)
Epoch: [107][800/875]	Time 0.426 (0.412)	Data 0.007 (0.009)	Loss 1.7442 (1.7337)	Loss@kd 1.7090 (1.6706)	Acc@1 82.812 (79.344)	Acc@5 100.000 (99.545)
 * Acc@1 79.321 Acc@5 99.545
epoch 107, total time 360.84
Test: [0/750]	Time 0.826 (0.826)	Loss 0.3044 (0.3044)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.112 (0.115)	Loss 0.4070 (0.5240)	Acc@1 84.375 (86.108)	Acc@5 100.000 (94.554)
Test: [200/750]	Time 0.105 (0.109)	Loss 1.0377 (0.5029)	Acc@1 65.625 (84.997)	Acc@5 93.750 (95.911)
Test: [300/750]	Time 0.102 (0.109)	Loss 1.1597 (0.6888)	Acc@1 65.625 (76.485)	Acc@5 93.750 (95.349)
Test: [400/750]	Time 0.110 (0.107)	Loss 0.5117 (0.7677)	Acc@1 84.375 (73.114)	Acc@5 93.750 (95.067)
Test: [500/750]	Time 0.108 (0.107)	Loss 0.4460 (0.7488)	Acc@1 87.500 (74.351)	Acc@5 100.000 (94.779)
Test: [600/750]	Time 0.101 (0.106)	Loss 0.8811 (0.7618)	Acc@1 71.875 (73.981)	Acc@5 90.625 (94.644)
Test: [700/750]	Time 0.112 (0.106)	Loss 0.8539 (0.7611)	Acc@1 71.875 (73.796)	Acc@5 93.750 (94.789)
 * Acc@1 74.033 Acc@5 94.838
==> training...
Epoch: [108][0/875]	Time 1.928 (1.928)	Data 1.363 (1.363)	Loss 1.5501 (1.5501)	Loss@kd 1.6235 (1.6235)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [108][100/875]	Time 0.390 (0.409)	Data 0.007 (0.020)	Loss 1.7524 (1.7316)	Loss@kd 1.6669 (1.6732)	Acc@1 78.125 (79.997)	Acc@5 96.875 (99.412)
Epoch: [108][200/875]	Time 0.361 (0.394)	Data 0.006 (0.014)	Loss 1.7318 (1.7201)	Loss@kd 1.5985 (1.6703)	Acc@1 79.688 (80.092)	Acc@5 98.438 (99.495)
Epoch: [108][300/875]	Time 0.374 (0.387)	Data 0.007 (0.011)	Loss 1.6661 (1.7206)	Loss@kd 1.6597 (1.6697)	Acc@1 79.688 (80.160)	Acc@5 100.000 (99.512)
Epoch: [108][400/875]	Time 0.372 (0.391)	Data 0.007 (0.010)	Loss 1.6559 (1.7216)	Loss@kd 1.6553 (1.6693)	Acc@1 78.125 (80.034)	Acc@5 100.000 (99.548)
Epoch: [108][500/875]	Time 0.368 (0.394)	Data 0.007 (0.010)	Loss 1.7683 (1.7268)	Loss@kd 1.5879 (1.6691)	Acc@1 71.875 (79.765)	Acc@5 100.000 (99.532)
Epoch: [108][600/875]	Time 0.343 (0.397)	Data 0.007 (0.009)	Loss 1.7054 (1.7277)	Loss@kd 1.6565 (1.6695)	Acc@1 82.812 (79.641)	Acc@5 100.000 (99.558)
Epoch: [108][700/875]	Time 0.400 (0.399)	Data 0.007 (0.009)	Loss 1.8464 (1.7268)	Loss@kd 1.6219 (1.6688)	Acc@1 73.438 (79.670)	Acc@5 100.000 (99.565)
Epoch: [108][800/875]	Time 0.425 (0.401)	Data 0.007 (0.009)	Loss 1.7145 (1.7309)	Loss@kd 1.7210 (1.6695)	Acc@1 79.688 (79.498)	Acc@5 100.000 (99.567)
 * Acc@1 79.475 Acc@5 99.554
epoch 108, total time 351.93
Test: [0/750]	Time 0.988 (0.988)	Loss 0.2647 (0.2647)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.095 (0.119)	Loss 0.4481 (0.5103)	Acc@1 84.375 (86.665)	Acc@5 100.000 (94.616)
Test: [200/750]	Time 0.101 (0.112)	Loss 1.0913 (0.5013)	Acc@1 62.500 (84.935)	Acc@5 93.750 (96.035)
Test: [300/750]	Time 0.100 (0.111)	Loss 1.1285 (0.6969)	Acc@1 65.625 (75.955)	Acc@5 93.750 (95.276)
Test: [400/750]	Time 0.112 (0.109)	Loss 0.5128 (0.7587)	Acc@1 84.375 (73.293)	Acc@5 96.875 (95.122)
Test: [500/750]	Time 0.143 (0.109)	Loss 0.4337 (0.7408)	Acc@1 84.375 (74.501)	Acc@5 100.000 (94.867)
Test: [600/750]	Time 0.089 (0.107)	Loss 0.8717 (0.7537)	Acc@1 71.875 (74.277)	Acc@5 90.625 (94.722)
Test: [700/750]	Time 0.107 (0.107)	Loss 0.8984 (0.7567)	Acc@1 68.750 (73.921)	Acc@5 93.750 (94.847)
 * Acc@1 74.104 Acc@5 94.875
==> training...
Epoch: [109][0/875]	Time 1.904 (1.904)	Data 1.398 (1.398)	Loss 1.5656 (1.5656)	Loss@kd 1.6655 (1.6655)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [109][100/875]	Time 0.370 (0.419)	Data 0.007 (0.021)	Loss 1.5785 (1.7626)	Loss@kd 1.6860 (1.6802)	Acc@1 85.938 (78.775)	Acc@5 100.000 (99.520)
Epoch: [109][200/875]	Time 0.402 (0.416)	Data 0.005 (0.014)	Loss 1.7226 (1.7347)	Loss@kd 1.5916 (1.6715)	Acc@1 75.000 (79.485)	Acc@5 100.000 (99.502)
Epoch: [109][300/875]	Time 0.427 (0.415)	Data 0.007 (0.011)	Loss 1.7753 (1.7297)	Loss@kd 1.6183 (1.6688)	Acc@1 78.125 (79.532)	Acc@5 100.000 (99.533)
Epoch: [109][400/875]	Time 0.429 (0.414)	Data 0.007 (0.010)	Loss 1.6549 (1.7302)	Loss@kd 1.7270 (1.6677)	Acc@1 84.375 (79.520)	Acc@5 100.000 (99.509)
Epoch: [109][500/875]	Time 0.360 (0.413)	Data 0.007 (0.010)	Loss 1.9297 (1.7315)	Loss@kd 1.6779 (1.6691)	Acc@1 75.000 (79.466)	Acc@5 100.000 (99.510)
Epoch: [109][600/875]	Time 0.427 (0.413)	Data 0.007 (0.009)	Loss 1.9122 (1.7337)	Loss@kd 1.7218 (1.6700)	Acc@1 76.562 (79.417)	Acc@5 100.000 (99.511)
Epoch: [109][700/875]	Time 0.454 (0.411)	Data 0.007 (0.009)	Loss 1.5924 (1.7309)	Loss@kd 1.7279 (1.6690)	Acc@1 87.500 (79.456)	Acc@5 100.000 (99.519)
Epoch: [109][800/875]	Time 0.355 (0.405)	Data 0.007 (0.009)	Loss 1.5512 (1.7311)	Loss@kd 1.6753 (1.6698)	Acc@1 84.375 (79.418)	Acc@5 100.000 (99.528)
 * Acc@1 79.354 Acc@5 99.534
epoch 109, total time 351.23
Test: [0/750]	Time 0.871 (0.871)	Loss 0.2905 (0.2905)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.107 (0.114)	Loss 0.4013 (0.5107)	Acc@1 81.250 (86.417)	Acc@5 96.875 (94.833)
Test: [200/750]	Time 0.092 (0.106)	Loss 1.0371 (0.4931)	Acc@1 65.625 (85.199)	Acc@5 90.625 (96.206)
Test: [300/750]	Time 0.098 (0.106)	Loss 1.1264 (0.6893)	Acc@1 62.500 (76.443)	Acc@5 93.750 (95.401)
Test: [400/750]	Time 0.095 (0.105)	Loss 0.5646 (0.7621)	Acc@1 81.250 (73.153)	Acc@5 96.875 (95.215)
Test: [500/750]	Time 0.095 (0.105)	Loss 0.4797 (0.7524)	Acc@1 84.375 (74.177)	Acc@5 100.000 (94.817)
Test: [600/750]	Time 0.095 (0.104)	Loss 0.8739 (0.7680)	Acc@1 71.875 (73.820)	Acc@5 93.750 (94.696)
Test: [700/750]	Time 0.110 (0.105)	Loss 0.8536 (0.7666)	Acc@1 71.875 (73.654)	Acc@5 93.750 (94.833)
 * Acc@1 73.904 Acc@5 94.846
==> training...
Epoch: [110][0/875]	Time 1.948 (1.948)	Data 1.388 (1.388)	Loss 1.8195 (1.8195)	Loss@kd 1.7632 (1.7632)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [110][100/875]	Time 0.401 (0.424)	Data 0.007 (0.020)	Loss 1.6314 (1.7200)	Loss@kd 1.6128 (1.6726)	Acc@1 84.375 (80.152)	Acc@5 98.438 (99.412)
Epoch: [110][200/875]	Time 0.410 (0.416)	Data 0.007 (0.014)	Loss 1.8363 (1.7252)	Loss@kd 1.6600 (1.6731)	Acc@1 79.688 (80.022)	Acc@5 100.000 (99.534)
Epoch: [110][300/875]	Time 0.379 (0.413)	Data 0.007 (0.011)	Loss 1.6273 (1.7275)	Loss@kd 1.7261 (1.6736)	Acc@1 79.688 (79.885)	Acc@5 100.000 (99.548)
Epoch: [110][400/875]	Time 0.429 (0.413)	Data 0.005 (0.010)	Loss 1.8225 (1.7284)	Loss@kd 1.6732 (1.6743)	Acc@1 78.125 (79.808)	Acc@5 100.000 (99.556)
Epoch: [110][500/875]	Time 0.422 (0.413)	Data 0.007 (0.009)	Loss 1.5068 (1.7254)	Loss@kd 1.5584 (1.6708)	Acc@1 87.500 (79.663)	Acc@5 100.000 (99.557)
Epoch: [110][600/875]	Time 0.375 (0.412)	Data 0.007 (0.009)	Loss 1.7426 (1.7288)	Loss@kd 1.6873 (1.6708)	Acc@1 79.688 (79.560)	Acc@5 100.000 (99.555)
Epoch: [110][700/875]	Time 0.440 (0.412)	Data 0.007 (0.009)	Loss 1.7489 (1.7301)	Loss@kd 1.6810 (1.6699)	Acc@1 81.250 (79.451)	Acc@5 100.000 (99.536)
Epoch: [110][800/875]	Time 0.418 (0.412)	Data 0.008 (0.009)	Loss 1.6577 (1.7310)	Loss@kd 1.6744 (1.6711)	Acc@1 85.938 (79.479)	Acc@5 98.438 (99.530)
 * Acc@1 79.407 Acc@5 99.530
epoch 110, total time 360.40
Test: [0/750]	Time 1.004 (1.004)	Loss 0.3166 (0.3166)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.090 (0.113)	Loss 0.4551 (0.5510)	Acc@1 84.375 (85.179)	Acc@5 100.000 (94.214)
Test: [200/750]	Time 0.095 (0.108)	Loss 1.1775 (0.5341)	Acc@1 53.125 (83.784)	Acc@5 87.500 (95.631)
Test: [300/750]	Time 0.087 (0.107)	Loss 1.0461 (0.7402)	Acc@1 62.500 (74.522)	Acc@5 93.750 (94.674)
Test: [400/750]	Time 0.099 (0.106)	Loss 0.5390 (0.7945)	Acc@1 84.375 (72.171)	Acc@5 96.875 (94.716)
Test: [500/750]	Time 0.156 (0.106)	Loss 0.4693 (0.7740)	Acc@1 90.625 (73.391)	Acc@5 100.000 (94.548)
Test: [600/750]	Time 0.111 (0.105)	Loss 0.8478 (0.7798)	Acc@1 71.875 (73.331)	Acc@5 90.625 (94.426)
Test: [700/750]	Time 0.096 (0.106)	Loss 0.8930 (0.7734)	Acc@1 68.750 (73.270)	Acc@5 93.750 (94.642)
 * Acc@1 73.379 Acc@5 94.646
==> training...
Epoch: [111][0/875]	Time 2.061 (2.061)	Data 1.503 (1.503)	Loss 1.6588 (1.6588)	Loss@kd 1.6142 (1.6142)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [111][100/875]	Time 0.434 (0.433)	Data 0.007 (0.021)	Loss 1.7279 (1.7244)	Loss@kd 1.5834 (1.6691)	Acc@1 82.812 (79.626)	Acc@5 98.438 (99.582)
Epoch: [111][200/875]	Time 0.405 (0.425)	Data 0.007 (0.014)	Loss 1.6700 (1.7291)	Loss@kd 1.6722 (1.6680)	Acc@1 82.812 (79.485)	Acc@5 100.000 (99.534)
Epoch: [111][300/875]	Time 0.392 (0.411)	Data 0.007 (0.012)	Loss 1.7645 (1.7269)	Loss@kd 1.6101 (1.6696)	Acc@1 78.125 (79.682)	Acc@5 100.000 (99.528)
Epoch: [111][400/875]	Time 0.369 (0.401)	Data 0.008 (0.010)	Loss 1.8022 (1.7286)	Loss@kd 1.5989 (1.6690)	Acc@1 75.000 (79.625)	Acc@5 100.000 (99.529)
Epoch: [111][500/875]	Time 0.402 (0.398)	Data 0.005 (0.010)	Loss 1.8415 (1.7292)	Loss@kd 1.6325 (1.6702)	Acc@1 71.875 (79.557)	Acc@5 100.000 (99.542)
Epoch: [111][600/875]	Time 0.434 (0.401)	Data 0.010 (0.009)	Loss 1.5492 (1.7301)	Loss@kd 1.6611 (1.6695)	Acc@1 87.500 (79.521)	Acc@5 100.000 (99.542)
Epoch: [111][700/875]	Time 0.392 (0.402)	Data 0.005 (0.009)	Loss 1.5697 (1.7295)	Loss@kd 1.6283 (1.6694)	Acc@1 85.938 (79.509)	Acc@5 98.438 (99.548)
Epoch: [111][800/875]	Time 0.423 (0.404)	Data 0.007 (0.009)	Loss 1.7144 (1.7297)	Loss@kd 1.5990 (1.6685)	Acc@1 81.250 (79.489)	Acc@5 98.438 (99.544)
 * Acc@1 79.441 Acc@5 99.546
epoch 111, total time 354.34
Test: [0/750]	Time 0.927 (0.927)	Loss 0.2914 (0.2914)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.106 (0.116)	Loss 0.4696 (0.5081)	Acc@1 84.375 (86.479)	Acc@5 96.875 (94.864)
Test: [200/750]	Time 0.117 (0.109)	Loss 1.1418 (0.5140)	Acc@1 56.250 (84.375)	Acc@5 90.625 (96.051)
Test: [300/750]	Time 0.108 (0.109)	Loss 1.0561 (0.7101)	Acc@1 65.625 (75.405)	Acc@5 93.750 (95.349)
Test: [400/750]	Time 0.093 (0.108)	Loss 0.6114 (0.7718)	Acc@1 81.250 (72.639)	Acc@5 93.750 (95.168)
Test: [500/750]	Time 0.104 (0.108)	Loss 0.4211 (0.7655)	Acc@1 84.375 (73.547)	Acc@5 100.000 (94.692)
Test: [600/750]	Time 0.108 (0.107)	Loss 0.8391 (0.7735)	Acc@1 75.000 (73.502)	Acc@5 90.625 (94.572)
Test: [700/750]	Time 0.110 (0.107)	Loss 0.8952 (0.7698)	Acc@1 71.875 (73.422)	Acc@5 93.750 (94.708)
 * Acc@1 73.562 Acc@5 94.700
==> training...
Epoch: [112][0/875]	Time 1.775 (1.775)	Data 1.306 (1.306)	Loss 1.7816 (1.7816)	Loss@kd 1.6598 (1.6598)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [112][100/875]	Time 0.364 (0.422)	Data 0.009 (0.020)	Loss 1.7318 (1.7311)	Loss@kd 1.6537 (1.6644)	Acc@1 78.125 (79.069)	Acc@5 100.000 (99.459)
Epoch: [112][200/875]	Time 0.349 (0.417)	Data 0.005 (0.013)	Loss 1.8610 (1.7358)	Loss@kd 1.6304 (1.6660)	Acc@1 76.562 (78.996)	Acc@5 98.438 (99.495)
Epoch: [112][300/875]	Time 0.493 (0.417)	Data 0.007 (0.011)	Loss 1.7672 (1.7303)	Loss@kd 1.6105 (1.6655)	Acc@1 75.000 (79.148)	Acc@5 100.000 (99.543)
Epoch: [112][400/875]	Time 0.389 (0.414)	Data 0.007 (0.010)	Loss 1.7284 (1.7299)	Loss@kd 1.5841 (1.6649)	Acc@1 75.000 (79.228)	Acc@5 100.000 (99.548)
Epoch: [112][500/875]	Time 0.407 (0.412)	Data 0.007 (0.010)	Loss 1.6188 (1.7330)	Loss@kd 1.6138 (1.6686)	Acc@1 79.688 (79.223)	Acc@5 100.000 (99.532)
Epoch: [112][600/875]	Time 0.356 (0.411)	Data 0.007 (0.009)	Loss 1.6866 (1.7328)	Loss@kd 1.5950 (1.6699)	Acc@1 76.562 (79.246)	Acc@5 100.000 (99.535)
Epoch: [112][700/875]	Time 0.401 (0.410)	Data 0.007 (0.009)	Loss 1.8018 (1.7346)	Loss@kd 1.6522 (1.6714)	Acc@1 81.250 (79.233)	Acc@5 100.000 (99.525)
Epoch: [112][800/875]	Time 0.396 (0.409)	Data 0.006 (0.008)	Loss 1.7014 (1.7313)	Loss@kd 1.6626 (1.6702)	Acc@1 81.250 (79.354)	Acc@5 100.000 (99.532)
 * Acc@1 79.396 Acc@5 99.532
epoch 112, total time 355.90
Test: [0/750]	Time 0.866 (0.866)	Loss 0.2640 (0.2640)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.099 (0.115)	Loss 0.4421 (0.4960)	Acc@1 84.375 (86.634)	Acc@5 96.875 (94.957)
Test: [200/750]	Time 0.102 (0.107)	Loss 1.0908 (0.4950)	Acc@1 59.375 (84.935)	Acc@5 93.750 (96.175)
Test: [300/750]	Time 0.095 (0.107)	Loss 1.1535 (0.6992)	Acc@1 65.625 (75.934)	Acc@5 93.750 (95.318)
Test: [400/750]	Time 0.101 (0.105)	Loss 0.5028 (0.7800)	Acc@1 84.375 (72.584)	Acc@5 96.875 (94.997)
Test: [500/750]	Time 0.101 (0.105)	Loss 0.4713 (0.7584)	Acc@1 87.500 (73.927)	Acc@5 100.000 (94.729)
Test: [600/750]	Time 0.081 (0.104)	Loss 0.8553 (0.7674)	Acc@1 71.875 (73.716)	Acc@5 90.625 (94.660)
Test: [700/750]	Time 0.100 (0.105)	Loss 0.8406 (0.7638)	Acc@1 71.875 (73.618)	Acc@5 93.750 (94.820)
 * Acc@1 73.896 Acc@5 94.854
==> training...
Epoch: [113][0/875]	Time 1.905 (1.905)	Data 1.360 (1.360)	Loss 1.5990 (1.5990)	Loss@kd 1.6503 (1.6503)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [113][100/875]	Time 0.403 (0.418)	Data 0.007 (0.020)	Loss 1.6131 (1.7435)	Loss@kd 1.6532 (1.6726)	Acc@1 79.688 (79.115)	Acc@5 100.000 (99.489)
Epoch: [113][200/875]	Time 0.392 (0.409)	Data 0.006 (0.013)	Loss 1.6480 (1.7289)	Loss@kd 1.7078 (1.6716)	Acc@1 87.500 (79.633)	Acc@5 100.000 (99.502)
Epoch: [113][300/875]	Time 0.363 (0.410)	Data 0.007 (0.011)	Loss 1.5315 (1.7259)	Loss@kd 1.6471 (1.6693)	Acc@1 90.625 (79.672)	Acc@5 100.000 (99.528)
Epoch: [113][400/875]	Time 0.349 (0.411)	Data 0.007 (0.010)	Loss 1.5835 (1.7248)	Loss@kd 1.5814 (1.6704)	Acc@1 82.812 (79.684)	Acc@5 100.000 (99.529)
Epoch: [113][500/875]	Time 0.415 (0.411)	Data 0.007 (0.010)	Loss 1.9474 (1.7259)	Loss@kd 2.0664 (1.6708)	Acc@1 82.812 (79.619)	Acc@5 100.000 (99.532)
Epoch: [113][600/875]	Time 0.349 (0.411)	Data 0.007 (0.009)	Loss 1.6489 (1.7279)	Loss@kd 1.6131 (1.6691)	Acc@1 79.688 (79.435)	Acc@5 100.000 (99.527)
Epoch: [113][700/875]	Time 0.429 (0.412)	Data 0.007 (0.009)	Loss 1.6724 (1.7285)	Loss@kd 1.6079 (1.6682)	Acc@1 79.688 (79.456)	Acc@5 100.000 (99.514)
Epoch: [113][800/875]	Time 0.435 (0.411)	Data 0.007 (0.009)	Loss 1.5380 (1.7292)	Loss@kd 1.6115 (1.6683)	Acc@1 85.938 (79.473)	Acc@5 100.000 (99.503)
 * Acc@1 79.507 Acc@5 99.504
epoch 113, total time 360.47
Test: [0/750]	Time 0.940 (0.940)	Loss 0.3052 (0.3052)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.088 (0.115)	Loss 0.4607 (0.5005)	Acc@1 84.375 (86.479)	Acc@5 100.000 (94.709)
Test: [200/750]	Time 0.098 (0.108)	Loss 1.1594 (0.5056)	Acc@1 53.125 (84.422)	Acc@5 93.750 (95.911)
Test: [300/750]	Time 0.110 (0.108)	Loss 1.1123 (0.7097)	Acc@1 65.625 (75.353)	Acc@5 93.750 (94.975)
Test: [400/750]	Time 0.098 (0.106)	Loss 0.5206 (0.7666)	Acc@1 84.375 (72.709)	Acc@5 96.875 (94.966)
Test: [500/750]	Time 0.167 (0.106)	Loss 0.4838 (0.7510)	Acc@1 81.250 (73.877)	Acc@5 96.875 (94.748)
Test: [600/750]	Time 0.095 (0.105)	Loss 0.8054 (0.7652)	Acc@1 75.000 (73.554)	Acc@5 90.625 (94.603)
Test: [700/750]	Time 0.105 (0.106)	Loss 0.8852 (0.7619)	Acc@1 68.750 (73.462)	Acc@5 93.750 (94.740)
 * Acc@1 73.604 Acc@5 94.708
==> training...
Epoch: [114][0/875]	Time 1.956 (1.956)	Data 1.396 (1.396)	Loss 1.7569 (1.7569)	Loss@kd 1.7787 (1.7787)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [114][100/875]	Time 0.413 (0.431)	Data 0.007 (0.021)	Loss 1.5959 (1.7342)	Loss@kd 1.6885 (1.6767)	Acc@1 85.938 (79.610)	Acc@5 98.438 (99.474)
Epoch: [114][200/875]	Time 0.408 (0.421)	Data 0.007 (0.014)	Loss 1.7059 (1.7418)	Loss@kd 1.5978 (1.6745)	Acc@1 75.000 (79.143)	Acc@5 100.000 (99.471)
Epoch: [114][300/875]	Time 0.374 (0.418)	Data 0.007 (0.012)	Loss 1.7160 (1.7388)	Loss@kd 1.5918 (1.6696)	Acc@1 79.688 (79.085)	Acc@5 100.000 (99.502)
Epoch: [114][400/875]	Time 0.387 (0.413)	Data 0.010 (0.010)	Loss 1.9706 (1.7388)	Loss@kd 1.7534 (1.6708)	Acc@1 76.562 (79.154)	Acc@5 100.000 (99.513)
Epoch: [114][500/875]	Time 0.358 (0.405)	Data 0.007 (0.010)	Loss 1.7236 (1.7370)	Loss@kd 1.6251 (1.6703)	Acc@1 75.000 (79.198)	Acc@5 100.000 (99.520)
Epoch: [114][600/875]	Time 0.364 (0.399)	Data 0.007 (0.009)	Loss 1.6333 (1.7365)	Loss@kd 1.6265 (1.6701)	Acc@1 85.938 (79.181)	Acc@5 100.000 (99.529)
Epoch: [114][700/875]	Time 0.369 (0.399)	Data 0.007 (0.009)	Loss 1.7187 (1.7338)	Loss@kd 1.6537 (1.6693)	Acc@1 76.562 (79.164)	Acc@5 100.000 (99.556)
Epoch: [114][800/875]	Time 0.379 (0.401)	Data 0.006 (0.009)	Loss 1.5993 (1.7335)	Loss@kd 1.6557 (1.6700)	Acc@1 81.250 (79.155)	Acc@5 100.000 (99.561)
 * Acc@1 79.182 Acc@5 99.561
epoch 114, total time 351.94
Test: [0/750]	Time 0.976 (0.976)	Loss 0.2935 (0.2935)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.106 (0.114)	Loss 0.4647 (0.5267)	Acc@1 81.250 (86.015)	Acc@5 100.000 (94.369)
Test: [200/750]	Time 0.105 (0.108)	Loss 1.1178 (0.5184)	Acc@1 59.375 (84.391)	Acc@5 93.750 (95.771)
Test: [300/750]	Time 0.092 (0.107)	Loss 1.1299 (0.7127)	Acc@1 68.750 (75.322)	Acc@5 93.750 (95.069)
Test: [400/750]	Time 0.103 (0.106)	Loss 0.4741 (0.7776)	Acc@1 81.250 (72.428)	Acc@5 96.875 (94.903)
Test: [500/750]	Time 0.132 (0.106)	Loss 0.4585 (0.7531)	Acc@1 87.500 (73.883)	Acc@5 100.000 (94.773)
Test: [600/750]	Time 0.096 (0.105)	Loss 0.8159 (0.7646)	Acc@1 71.875 (73.617)	Acc@5 90.625 (94.624)
Test: [700/750]	Time 0.096 (0.105)	Loss 0.8874 (0.7599)	Acc@1 68.750 (73.627)	Acc@5 93.750 (94.824)
 * Acc@1 73.846 Acc@5 94.871
==> training...
Epoch: [115][0/875]	Time 1.963 (1.963)	Data 1.424 (1.424)	Loss 1.6049 (1.6049)	Loss@kd 1.6078 (1.6078)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [115][100/875]	Time 0.422 (0.435)	Data 0.007 (0.021)	Loss 1.8299 (1.7429)	Loss@kd 1.7610 (1.6841)	Acc@1 76.562 (79.641)	Acc@5 100.000 (99.582)
Epoch: [115][200/875]	Time 0.418 (0.425)	Data 0.007 (0.014)	Loss 1.8205 (1.7369)	Loss@kd 1.7100 (1.6833)	Acc@1 76.562 (79.656)	Acc@5 98.438 (99.502)
Epoch: [115][300/875]	Time 0.371 (0.421)	Data 0.007 (0.011)	Loss 1.7776 (1.7314)	Loss@kd 1.6282 (1.6758)	Acc@1 81.250 (79.521)	Acc@5 98.438 (99.496)
Epoch: [115][400/875]	Time 0.410 (0.419)	Data 0.007 (0.010)	Loss 1.8966 (1.7300)	Loss@kd 1.6901 (1.6739)	Acc@1 73.438 (79.489)	Acc@5 98.438 (99.525)
Epoch: [115][500/875]	Time 0.427 (0.417)	Data 0.007 (0.010)	Loss 1.8286 (1.7353)	Loss@kd 1.6192 (1.6733)	Acc@1 75.000 (79.363)	Acc@5 100.000 (99.542)
Epoch: [115][600/875]	Time 0.436 (0.416)	Data 0.007 (0.009)	Loss 1.8201 (1.7363)	Loss@kd 1.6380 (1.6720)	Acc@1 78.125 (79.253)	Acc@5 100.000 (99.535)
Epoch: [115][700/875]	Time 0.408 (0.416)	Data 0.006 (0.009)	Loss 1.9211 (1.7356)	Loss@kd 1.7150 (1.6716)	Acc@1 75.000 (79.226)	Acc@5 100.000 (99.539)
Epoch: [115][800/875]	Time 0.381 (0.416)	Data 0.007 (0.008)	Loss 1.7024 (1.7353)	Loss@kd 1.6473 (1.6712)	Acc@1 81.250 (79.292)	Acc@5 100.000 (99.534)
 * Acc@1 79.291 Acc@5 99.530
epoch 115, total time 364.68
Test: [0/750]	Time 1.005 (1.005)	Loss 0.2713 (0.2713)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.096 (0.119)	Loss 0.5270 (0.5102)	Acc@1 78.125 (86.448)	Acc@5 96.875 (94.771)
Test: [200/750]	Time 0.107 (0.112)	Loss 1.1126 (0.5188)	Acc@1 59.375 (84.033)	Acc@5 90.625 (95.942)
Test: [300/750]	Time 0.109 (0.111)	Loss 1.0763 (0.7124)	Acc@1 62.500 (75.571)	Acc@5 93.750 (95.203)
Test: [400/750]	Time 0.104 (0.109)	Loss 0.5574 (0.7801)	Acc@1 81.250 (72.436)	Acc@5 96.875 (95.036)
Test: [500/750]	Time 0.186 (0.109)	Loss 0.4404 (0.7601)	Acc@1 84.375 (73.734)	Acc@5 100.000 (94.748)
Test: [600/750]	Time 0.104 (0.108)	Loss 0.8325 (0.7673)	Acc@1 71.875 (73.721)	Acc@5 90.625 (94.624)
Test: [700/750]	Time 0.110 (0.108)	Loss 0.9078 (0.7602)	Acc@1 68.750 (73.743)	Acc@5 93.750 (94.798)
 * Acc@1 73.975 Acc@5 94.808
==> training...
Epoch: [116][0/875]	Time 1.842 (1.842)	Data 1.386 (1.386)	Loss 1.7774 (1.7774)	Loss@kd 1.7001 (1.7001)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)
Epoch: [116][100/875]	Time 0.370 (0.390)	Data 0.007 (0.021)	Loss 1.7710 (1.7202)	Loss@kd 1.6704 (1.6708)	Acc@1 76.562 (79.502)	Acc@5 98.438 (99.598)
Epoch: [116][200/875]	Time 0.422 (0.397)	Data 0.007 (0.014)	Loss 2.0116 (1.7280)	Loss@kd 1.9799 (1.6725)	Acc@1 79.688 (79.656)	Acc@5 100.000 (99.541)
Epoch: [116][300/875]	Time 0.416 (0.402)	Data 0.007 (0.011)	Loss 1.7317 (1.7318)	Loss@kd 1.5713 (1.6697)	Acc@1 79.688 (79.480)	Acc@5 100.000 (99.533)
Epoch: [116][400/875]	Time 0.372 (0.404)	Data 0.007 (0.010)	Loss 1.7534 (1.7287)	Loss@kd 1.6341 (1.6694)	Acc@1 79.688 (79.450)	Acc@5 98.438 (99.525)
Epoch: [116][500/875]	Time 0.393 (0.406)	Data 0.007 (0.010)	Loss 1.7155 (1.7283)	Loss@kd 1.6059 (1.6690)	Acc@1 75.000 (79.479)	Acc@5 100.000 (99.523)
Epoch: [116][600/875]	Time 0.358 (0.407)	Data 0.007 (0.009)	Loss 1.5962 (1.7283)	Loss@kd 1.6652 (1.6688)	Acc@1 82.812 (79.524)	Acc@5 100.000 (99.529)
Epoch: [116][700/875]	Time 0.427 (0.407)	Data 0.007 (0.009)	Loss 1.8822 (1.7319)	Loss@kd 1.9310 (1.6694)	Acc@1 78.125 (79.433)	Acc@5 100.000 (99.539)
Epoch: [116][800/875]	Time 0.419 (0.408)	Data 0.007 (0.009)	Loss 1.7464 (1.7356)	Loss@kd 1.8087 (1.6710)	Acc@1 84.375 (79.323)	Acc@5 100.000 (99.544)
 * Acc@1 79.323 Acc@5 99.554
epoch 116, total time 357.75
Test: [0/750]	Time 0.980 (0.980)	Loss 0.2683 (0.2683)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.104 (0.120)	Loss 0.4836 (0.4982)	Acc@1 84.375 (86.881)	Acc@5 100.000 (94.988)
Test: [200/750]	Time 0.112 (0.114)	Loss 1.1371 (0.5013)	Acc@1 59.375 (84.841)	Acc@5 93.750 (96.067)
Test: [300/750]	Time 0.108 (0.114)	Loss 1.1353 (0.7009)	Acc@1 59.375 (75.934)	Acc@5 93.750 (95.172)
Test: [400/750]	Time 0.091 (0.112)	Loss 0.5489 (0.7766)	Acc@1 81.250 (72.631)	Acc@5 96.875 (94.966)
Test: [500/750]	Time 0.104 (0.111)	Loss 0.4625 (0.7612)	Acc@1 84.375 (73.821)	Acc@5 100.000 (94.654)
Test: [600/750]	Time 0.115 (0.111)	Loss 0.8412 (0.7714)	Acc@1 71.875 (73.674)	Acc@5 90.625 (94.520)
Test: [700/750]	Time 0.099 (0.111)	Loss 0.8858 (0.7670)	Acc@1 68.750 (73.565)	Acc@5 93.750 (94.708)
 * Acc@1 73.838 Acc@5 94.737
==> training...
Epoch: [117][0/875]	Time 1.866 (1.866)	Data 1.408 (1.408)	Loss 1.7811 (1.7811)	Loss@kd 1.5535 (1.5535)	Acc@1 73.438 (73.438)	Acc@5 96.875 (96.875)
Epoch: [117][100/875]	Time 0.355 (0.430)	Data 0.007 (0.021)	Loss 1.9150 (1.7289)	Loss@kd 1.6706 (1.6699)	Acc@1 70.312 (79.363)	Acc@5 100.000 (99.551)
Epoch: [117][200/875]	Time 0.401 (0.419)	Data 0.007 (0.014)	Loss 1.8597 (1.7289)	Loss@kd 1.6720 (1.6695)	Acc@1 78.125 (79.501)	Acc@5 100.000 (99.619)
Epoch: [117][300/875]	Time 0.480 (0.419)	Data 0.007 (0.012)	Loss 1.7280 (1.7292)	Loss@kd 1.7202 (1.6705)	Acc@1 81.250 (79.521)	Acc@5 100.000 (99.574)
Epoch: [117][400/875]	Time 0.418 (0.417)	Data 0.008 (0.010)	Loss 1.9602 (1.7330)	Loss@kd 1.7914 (1.6711)	Acc@1 73.438 (79.528)	Acc@5 100.000 (99.536)
Epoch: [117][500/875]	Time 0.360 (0.413)	Data 0.007 (0.010)	Loss 1.8158 (1.7322)	Loss@kd 1.6771 (1.6698)	Acc@1 76.562 (79.447)	Acc@5 100.000 (99.535)
Epoch: [117][600/875]	Time 0.352 (0.407)	Data 0.007 (0.009)	Loss 1.7092 (1.7302)	Loss@kd 1.7061 (1.6702)	Acc@1 81.250 (79.490)	Acc@5 100.000 (99.535)
Epoch: [117][700/875]	Time 0.370 (0.402)	Data 0.007 (0.009)	Loss 1.6502 (1.7302)	Loss@kd 1.6375 (1.6700)	Acc@1 79.688 (79.451)	Acc@5 100.000 (99.530)
Epoch: [117][800/875]	Time 0.390 (0.401)	Data 0.007 (0.009)	Loss 1.7071 (1.7268)	Loss@kd 1.6196 (1.6693)	Acc@1 81.250 (79.535)	Acc@5 96.875 (99.549)
 * Acc@1 79.507 Acc@5 99.559
epoch 117, total time 351.98
Test: [0/750]	Time 0.976 (0.976)	Loss 0.2906 (0.2906)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Test: [100/750]	Time 0.109 (0.115)	Loss 0.4505 (0.5112)	Acc@1 84.375 (86.665)	Acc@5 100.000 (94.926)
Test: [200/750]	Time 0.093 (0.109)	Loss 1.0878 (0.5072)	Acc@1 62.500 (84.997)	Acc@5 93.750 (96.129)
Test: [300/750]	Time 0.088 (0.108)	Loss 1.1059 (0.7035)	Acc@1 65.625 (75.997)	Acc@5 93.750 (95.349)
Test: [400/750]	Time 0.101 (0.107)	Loss 0.5878 (0.7787)	Acc@1 84.375 (72.701)	Acc@5 93.750 (95.083)
Test: [500/750]	Time 0.101 (0.106)	Loss 0.4010 (0.7625)	Acc@1 87.500 (73.827)	Acc@5 100.000 (94.779)
Test: [600/750]	Time 0.101 (0.105)	Loss 0.8238 (0.7685)	Acc@1 71.875 (73.768)	Acc@5 93.750 (94.712)
Test: [700/750]	Time 0.101 (0.105)	Loss 0.9319 (0.7635)	Acc@1 71.875 (73.738)	Acc@5 93.750 (94.873)
 * Acc@1 73.946 Acc@5 94.875
==> training...
Epoch: [118][0/875]	Time 1.813 (1.813)	Data 1.265 (1.265)	Loss 1.7604 (1.7604)	Loss@kd 1.6640 (1.6640)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [118][100/875]	Time 0.447 (0.427)	Data 0.010 (0.019)	Loss 1.7106 (1.7208)	Loss@kd 1.6901 (1.6616)	Acc@1 78.125 (80.337)	Acc@5 100.000 (99.551)
Epoch: [118][200/875]	Time 0.379 (0.419)	Data 0.007 (0.013)	Loss 1.4959 (1.7230)	Loss@kd 1.6132 (1.6700)	Acc@1 82.812 (80.068)	Acc@5 100.000 (99.557)
Epoch: [118][300/875]	Time 0.427 (0.414)	Data 0.006 (0.011)	Loss 1.6639 (1.7246)	Loss@kd 1.6830 (1.6701)	Acc@1 82.812 (80.025)	Acc@5 100.000 (99.574)
Epoch: [118][400/875]	Time 0.369 (0.412)	Data 0.007 (0.010)	Loss 1.8979 (1.7260)	Loss@kd 1.7301 (1.6711)	Acc@1 71.875 (79.988)	Acc@5 100.000 (99.575)
Epoch: [118][500/875]	Time 0.399 (0.410)	Data 0.007 (0.009)	Loss 1.9046 (1.7314)	Loss@kd 1.6632 (1.6707)	Acc@1 75.000 (79.700)	Acc@5 98.438 (99.545)
Epoch: [118][600/875]	Time 0.408 (0.408)	Data 0.007 (0.009)	Loss 1.8955 (1.7301)	Loss@kd 1.5891 (1.6694)	Acc@1 75.000 (79.604)	Acc@5 100.000 (99.548)
Epoch: [118][700/875]	Time 0.374 (0.408)	Data 0.007 (0.009)	Loss 1.9852 (1.7319)	Loss@kd 1.7522 (1.6692)	Acc@1 73.438 (79.565)	Acc@5 98.438 (99.527)
Epoch: [118][800/875]	Time 0.364 (0.409)	Data 0.007 (0.008)	Loss 1.7550 (1.7331)	Loss@kd 1.5790 (1.6693)	Acc@1 75.000 (79.436)	Acc@5 98.438 (99.528)
 * Acc@1 79.434 Acc@5 99.536
epoch 118, total time 358.13
Test: [0/750]	Time 0.914 (0.914)	Loss 0.2892 (0.2892)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.081 (0.118)	Loss 0.4390 (0.5093)	Acc@1 84.375 (86.386)	Acc@5 96.875 (94.864)
Test: [200/750]	Time 0.107 (0.110)	Loss 1.0964 (0.5021)	Acc@1 62.500 (84.717)	Acc@5 93.750 (96.160)
Test: [300/750]	Time 0.102 (0.109)	Loss 1.1543 (0.6953)	Acc@1 59.375 (75.955)	Acc@5 93.750 (95.432)
Test: [400/750]	Time 0.105 (0.108)	Loss 0.5321 (0.7675)	Acc@1 84.375 (72.724)	Acc@5 93.750 (95.231)
Test: [500/750]	Time 0.170 (0.109)	Loss 0.4397 (0.7510)	Acc@1 84.375 (73.977)	Acc@5 100.000 (94.904)
Test: [600/750]	Time 0.103 (0.108)	Loss 0.8404 (0.7617)	Acc@1 71.875 (73.799)	Acc@5 93.750 (94.800)
Test: [700/750]	Time 0.098 (0.109)	Loss 0.8545 (0.7586)	Acc@1 71.875 (73.680)	Acc@5 93.750 (94.936)
 * Acc@1 73.933 Acc@5 94.954
==> training...
Epoch: [119][0/875]	Time 1.770 (1.770)	Data 1.262 (1.262)	Loss 1.5652 (1.5652)	Loss@kd 1.6372 (1.6372)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [119][100/875]	Time 0.382 (0.397)	Data 0.005 (0.019)	Loss 1.7167 (1.7273)	Loss@kd 1.6991 (1.6633)	Acc@1 78.125 (78.821)	Acc@5 100.000 (99.660)
Epoch: [119][200/875]	Time 0.376 (0.386)	Data 0.007 (0.013)	Loss 1.7368 (1.7303)	Loss@kd 1.6362 (1.6672)	Acc@1 82.812 (79.330)	Acc@5 98.438 (99.557)
Epoch: [119][300/875]	Time 0.427 (0.385)	Data 0.007 (0.011)	Loss 1.8571 (1.7256)	Loss@kd 1.6403 (1.6661)	Acc@1 76.562 (79.563)	Acc@5 100.000 (99.600)
Epoch: [119][400/875]	Time 0.420 (0.392)	Data 0.007 (0.010)	Loss 1.6339 (1.7257)	Loss@kd 1.6560 (1.6664)	Acc@1 81.250 (79.536)	Acc@5 100.000 (99.603)
Epoch: [119][500/875]	Time 0.407 (0.396)	Data 0.007 (0.009)	Loss 1.6910 (1.7259)	Loss@kd 1.6888 (1.6677)	Acc@1 76.562 (79.585)	Acc@5 100.000 (99.579)
Epoch: [119][600/875]	Time 0.418 (0.399)	Data 0.007 (0.009)	Loss 1.8034 (1.7225)	Loss@kd 1.6450 (1.6658)	Acc@1 76.562 (79.672)	Acc@5 100.000 (99.563)
Epoch: [119][700/875]	Time 0.361 (0.401)	Data 0.006 (0.009)	Loss 1.6294 (1.7290)	Loss@kd 1.7037 (1.6690)	Acc@1 82.812 (79.503)	Acc@5 100.000 (99.541)
Epoch: [119][800/875]	Time 0.424 (0.403)	Data 0.007 (0.008)	Loss 1.7981 (1.7291)	Loss@kd 1.6891 (1.6694)	Acc@1 78.125 (79.498)	Acc@5 100.000 (99.551)
 * Acc@1 79.505 Acc@5 99.548
epoch 119, total time 353.34
Test: [0/750]	Time 0.913 (0.913)	Loss 0.2831 (0.2831)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.116 (0.118)	Loss 0.4266 (0.5047)	Acc@1 84.375 (86.572)	Acc@5 100.000 (94.895)
Test: [200/750]	Time 0.105 (0.112)	Loss 1.1646 (0.4988)	Acc@1 59.375 (84.997)	Acc@5 90.625 (96.098)
Test: [300/750]	Time 0.087 (0.112)	Loss 1.1523 (0.7116)	Acc@1 65.625 (75.363)	Acc@5 93.750 (95.141)
Test: [400/750]	Time 0.107 (0.110)	Loss 0.5241 (0.7727)	Acc@1 84.375 (72.685)	Acc@5 93.750 (95.020)
Test: [500/750]	Time 0.177 (0.110)	Loss 0.4563 (0.7580)	Acc@1 84.375 (73.883)	Acc@5 100.000 (94.704)
Test: [600/750]	Time 0.113 (0.109)	Loss 0.8161 (0.7714)	Acc@1 75.000 (73.622)	Acc@5 93.750 (94.556)
Test: [700/750]	Time 0.110 (0.109)	Loss 0.8162 (0.7656)	Acc@1 71.875 (73.609)	Acc@5 93.750 (94.735)
 * Acc@1 73.904 Acc@5 94.775
==> training...
Epoch: [120][0/875]	Time 1.885 (1.885)	Data 1.354 (1.354)	Loss 1.5237 (1.5237)	Loss@kd 1.6447 (1.6447)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [120][100/875]	Time 0.409 (0.428)	Data 0.007 (0.020)	Loss 1.7017 (1.7330)	Loss@kd 1.6785 (1.6711)	Acc@1 81.250 (79.223)	Acc@5 100.000 (99.629)
Epoch: [120][200/875]	Time 0.446 (0.419)	Data 0.007 (0.014)	Loss 1.7442 (1.7282)	Loss@kd 1.6516 (1.6668)	Acc@1 73.438 (79.618)	Acc@5 100.000 (99.557)
Epoch: [120][300/875]	Time 0.424 (0.416)	Data 0.008 (0.011)	Loss 1.5952 (1.7324)	Loss@kd 1.6368 (1.6691)	Acc@1 82.812 (79.194)	Acc@5 100.000 (99.496)
Epoch: [120][400/875]	Time 0.432 (0.415)	Data 0.007 (0.010)	Loss 1.6058 (1.7327)	Loss@kd 1.6474 (1.6703)	Acc@1 84.375 (79.321)	Acc@5 100.000 (99.521)
Epoch: [120][500/875]	Time 0.380 (0.414)	Data 0.007 (0.010)	Loss 1.7148 (1.7316)	Loss@kd 1.6221 (1.6700)	Acc@1 76.562 (79.248)	Acc@5 98.438 (99.492)
Epoch: [120][600/875]	Time 0.433 (0.413)	Data 0.007 (0.009)	Loss 1.7880 (1.7285)	Loss@kd 1.7199 (1.6694)	Acc@1 76.562 (79.389)	Acc@5 100.000 (99.506)
Epoch: [120][700/875]	Time 0.354 (0.409)	Data 0.007 (0.009)	Loss 1.7144 (1.7295)	Loss@kd 1.6318 (1.6695)	Acc@1 75.000 (79.317)	Acc@5 98.438 (99.512)
Epoch: [120][800/875]	Time 0.342 (0.405)	Data 0.005 (0.009)	Loss 1.5854 (1.7316)	Loss@kd 1.6729 (1.6702)	Acc@1 87.500 (79.284)	Acc@5 98.438 (99.514)
 * Acc@1 79.345 Acc@5 99.529
epoch 120, total time 351.80
Test: [0/750]	Time 0.778 (0.778)	Loss 0.3022 (0.3022)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Test: [100/750]	Time 0.112 (0.112)	Loss 0.4713 (0.5224)	Acc@1 84.375 (86.262)	Acc@5 100.000 (94.585)
Test: [200/750]	Time 0.107 (0.109)	Loss 1.0515 (0.5186)	Acc@1 62.500 (84.375)	Acc@5 93.750 (95.973)
Test: [300/750]	Time 0.110 (0.110)	Loss 1.1449 (0.7097)	Acc@1 65.625 (75.851)	Acc@5 93.750 (95.245)
Test: [400/750]	Time 0.099 (0.109)	Loss 0.5618 (0.7852)	Acc@1 81.250 (72.483)	Acc@5 96.875 (95.020)
Test: [500/750]	Time 0.113 (0.109)	Loss 0.4282 (0.7673)	Acc@1 90.625 (73.703)	Acc@5 100.000 (94.736)
Test: [600/750]	Time 0.105 (0.109)	Loss 0.8329 (0.7738)	Acc@1 71.875 (73.690)	Acc@5 90.625 (94.639)
Test: [700/750]	Time 0.105 (0.109)	Loss 0.8293 (0.7667)	Acc@1 71.875 (73.685)	Acc@5 93.750 (94.815)
 * Acc@1 73.971 Acc@5 94.875
==> Saving...
best accuracy: tensor(74.2458, device='cuda:1')
